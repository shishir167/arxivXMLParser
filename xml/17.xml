<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:46:16Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|16001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2949</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2949</id><created>2010-09-15</created><authors><author><keyname>Sarangi</keyname><forenames>Sanat</forenames></author><author><keyname>Kar</keyname><forenames>Subrat</forenames></author></authors><title>Performance Analysis of an Improved Graded Precision Localization
  Algorithm for Wireless Sensor Networks</title><categories>cs.NI</categories><comments>10 pages, 10 figures</comments><report-no>0710ijcnc13</report-no><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol.2, No.4, July 2010</journal-ref><doi>10.5121/ijcnc.2010.2413</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper an improved version of the graded precision localization
algorithm GRADELOC, called IGRADELOC is proposed. The performance of GRADELOC
is dependent on the regions formed by the overlapping radio ranges of the nodes
of the underlying sensor network. A different region pattern could
significantly alter the nature and precision of localization. In IGRADELOC, two
improvements are suggested. Firstly, modifications are proposed in the radio
range of the fixed-grid nodes, keeping in mind the actual radio range of
commonly available nodes, to allow for routing through them. Routing is not
addressed by GRADELOC, but is of prime importance to the deployment of any
adhoc network, especially sensor networks. A theoretical model expressing the
radio range in terms of the cell dimensions of the grid infrastructure is
proposed, to help in carrying out a deployment plan which achieves the
desirable precision of coarse-grained localization. Secondly, in GRADELOC it is
observed that fine-grained localization does not achieve significant
performance benefits over coarse-grained localization. In IGRADELOC, this
factor is addressed with the introduction of a parameter that could be used to
improve and fine-tune the precision of fine-grained localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2955</identifier>
 <datestamp>2010-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2955</id><created>2010-09-15</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Throughput Analysis of Buffer-Constrained Wireless Systems in the Finite
  Blocklength Regime</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, wireless systems operating under queueing constraints in the
form of limitations on the buffer violation probabilities are considered. The
throughput under such constraints is captured by the effective capacity
formulation. It is assumed that finite blocklength codes are employed for
transmission. Under this assumption, a recent result on the channel coding rate
in the finite blocklength regime is incorporated into the analysis and the
throughput achieved with such codes in the presence of queueing constraints and
decoding errors is identified. Performance of different transmission strategies
(e.g., variable-rate, variable-power, and fixed-rate transmissions) is studied.
Interactions between the throughput, queueing constraints, coding blocklength,
decoding error probabilities, and signal-to-noise ratio are investigated and
several conclusions with important practical implications are drawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.2997</identifier>
 <datestamp>2013-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.2997</id><created>2010-09-15</created><authors><author><keyname>Atia</keyname><forenames>George K.</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author><author><keyname>Fuemmeler</keyname><forenames>Jason A.</forenames></author></authors><title>Sensor Scheduling for Energy-Efficient Target Tracking in Sensor
  Networks</title><categories>cs.MA</categories><journal-ref>IEEE Trans.Sign.Proc. 59 (2011) 4923-4937</journal-ref><doi>10.1109/TSP.2011.2160055</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of tracking an object moving randomly
through a network of wireless sensors. Our objective is to devise strategies
for scheduling the sensors to optimize the tradeoff between tracking
performance and energy consumption. We cast the scheduling problem as a
Partially Observable Markov Decision Process (POMDP), where the control actions
correspond to the set of sensors to activate at each time step. Using a
bottom-up approach, we consider different sensing, motion and cost models with
increasing levels of difficulty. At the first level, the sensing regions of the
different sensors do not overlap and the target is only observed within the
sensing range of an active sensor. Then, we consider sensors with overlapping
sensing range such that the tracking error, and hence the actions of the
different sensors, are tightly coupled. Finally, we consider scenarios wherein
the target locations and sensors' observations assume values on continuous
spaces. Exact solutions are generally intractable even for the simplest models
due to the dimensionality of the information and action spaces. Hence, we
devise approximate solution techniques, and in some cases derive lower bounds
on the optimal tradeoff curves. The generated scheduling policies, albeit
suboptimal, often provide close-to-optimal energy-tracking tradeoffs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3006</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3006</id><created>2010-09-15</created><updated>2013-05-30</updated><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>De Carufel</keyname><forenames>Jean-Lou</forenames></author></authors><title>Minimum-Area Enclosing Triangle with a Fixed Angle</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set S of n points in the plane and a fixed angle 0 &lt; omega &lt; pi, we
show how to find in O(n log n) time all triangles of minimum area with one
angle omega that enclose S. We prove that in general, the solution cannot be
written without cubic roots. We also prove an Omega(n log n) lower bound for
this problem in the algebraic computation tree model. If the input is a convex
n-gon, our algorithm takes Theta(n) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3029</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3029</id><created>2010-09-15</created><authors><author><keyname>Taquet</keyname><forenames>Maxime</forenames></author><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author><author><keyname>De Vleeschouwer</keyname><forenames>Christophe</forenames></author><author><keyname>Macq</keyname><forenames>Benoit</forenames></author></authors><title>Invariant Spectral Hashing of Image Saliency Graph</title><categories>cs.CV</categories><comments>Keywords: Invariant Hashing, Geometrical Invariant, Spectral Graph,
  Salient Points. Content: 8 pages, 7 figures, 1 table</comments><report-no>TR-LJ-2010.01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image hashing is the process of associating a short vector of bits to an
image. The resulting summaries are useful in many applications including image
indexing, image authentication and pattern recognition. These hashes need to be
invariant under transformations of the image that result in similar visual
content, but should drastically differ for conceptually distinct contents. This
paper proposes an image hashing method that is invariant under rotation,
scaling and translation of the image. The gist of our approach relies on the
geometric characterization of salient point distribution in the image. This is
achieved by the definition of a &quot;saliency graph&quot; connecting these points
jointly with an image intensity function on the graph nodes. An invariant hash
is then obtained by considering the spectrum of this function in the
eigenvector basis of the Laplacian graph, that is, its graph Fourier transform.
Interestingly, this spectrum is invariant under any relabeling of the graph
nodes. The graph reveals geometric information of the image, making the hash
robust to image transformation, yet distinct for different visual content. The
efficiency of the proposed method is assessed on a set of MRI 2-D slices and on
a database of faces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3041</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3041</id><created>2010-09-15</created><updated>2011-01-20</updated><authors><author><keyname>Wong</keyname><forenames>Chan Wong</forenames></author><author><keyname>Wong</keyname><forenames>Tan F.</forenames></author><author><keyname>Shea</keyname><forenames>John M.</forenames></author></authors><title>Secret Sharing LDPC Codes for the BPSK-constrained Gaussian Wiretap
  Channel</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to IEEE Trans. on Information Forensics and Security,
  special issues on using the physical layer for securing the next generation
  of communication systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of secret sharing over the Gaussian wiretap channel is
considered. A source and a destination intend to share secret information over
a Gaussian channel in the presence of a wiretapper who observes the
transmission through another Gaussian channel. Two constraints are imposed on
the source-to-destination channel; namely, the source can transmit only binary
phase shift keyed (BPSK) symbols, and symbol-by-symbol hard-decision
quantization is applied to the received symbols of the destination. An
error-free public channel is also available for the source and destination to
exchange messages in order to help the secret sharing process. The wiretapper
can perfectly observe all messages in the public channel. It is shown that a
secret sharing scheme that employs a random ensemble of regular low density
parity check (LDPC) codes can achieve the key capacity of the BPSK-constrained
Gaussian wiretap channel asymptotically with increasing block length. To
accommodate practical constraints of finite block length and limited decoding
complexity, fixed irregular LDPC codes are also designed to replace the regular
LDPC code ensemble in the proposed secret sharing scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3052</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3052</id><created>2010-09-15</created><updated>2010-09-16</updated><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Secret-key Agreement with Channel State Information at the Transmitter</title><categories>cs.IT math.IT</categories><comments>10 Pages, Submitted to IEEE Transactions on Information Forensics and
  Security, Special Issue on Using the Physical Layer for Securing the Next
  Generation of Communication Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the capacity of secret-key agreement over a wiretap channel with
state parameters. The transmitter communicates to the legitimate receiver and
the eavesdropper over a discrete memoryless wiretap channel with a memoryless
state sequence. The transmitter and the legitimate receiver generate a shared
secret key, that remains secret from the eavesdropper. No public discussion
channel is available. The state sequence is known noncausally to the
transmitter. We derive lower and upper bounds on the secret-key capacity. The
lower bound involves constructing a common state reconstruction sequence at the
legitimate terminals and binning the set of reconstruction sequences to obtain
the secret-key. For the special case of Gaussian channels with additive
interference (secret-keys from dirty paper channel) our bounds differ by 0.5
bit/symbol and coincide in the high signal-to-noise-ratio and high
interference-to-noise-ratio regimes. For the case when the legitimate receiver
is also revealed the state sequence, we establish that our lower bound achieves
the the secret-key capacity. In addition, for this special case, we also
propose another scheme that attains the capacity and requires only causal side
information at the transmitter and the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3078</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3078</id><created>2010-09-15</created><authors><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Barnes</keyname><forenames>Nick</forenames></author><author><keyname>Zheng</keyname><forenames>Hong</forenames></author><author><keyname>Ren</keyname><forenames>Zhang</forenames></author></authors><title>Asymmetric Totally-corrective Boosting for Real-time Object Detection</title><categories>cs.CV</categories><comments>14 pages, published in Asian Conf. Computer Vision 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-time object detection is one of the core problems in computer vision.
The cascade boosting framework proposed by Viola and Jones has become the
standard for this problem. In this framework, the learning goal for each node
is asymmetric, which is required to achieve a high detection rate and a
moderate false positive rate. We develop new boosting algorithms to address
this asymmetric learning problem. We show that our methods explicitly optimize
asymmetric loss objectives in a totally corrective fashion. The methods are
totally corrective in the sense that the coefficients of all selected weak
classifiers are updated at each iteration. In contract, conventional boosting
like AdaBoost is stage-wise in that only the current weak classifier's
coefficient is updated. At the heart of the totally corrective boosting is the
column generation technique. Experiments on face detection show that our
methods outperform the state-of-the-art asymmetric boosting methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3083</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3083</id><created>2010-09-15</created><updated>2010-09-17</updated><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>The Capacity of the Semi-Deterministic Cognitive Interference Channel
  and its Application to Constant Gap Results for the Gaussian Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE International Conference on Communications ICC2011,
  Kyoto, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cognitive interference channel (C-IFC) consists of a classical two-user
interference channel in which the message of one user (the &quot;primary&quot; user) is
non-causally available at the transmitter of the other user (the &quot;cognitive&quot;
user). We obtain the capacity of the semi-deterministic C-IFC: a discrete
memoryless C-IFC in which the cognitive receiver output is a noise-less
deterministic function of the channel inputs. We then use the insights obtained
from the capacity-achieving scheme for the semi-deterministic model to derive
new, unified and tighter constant gap results for the complex-valued Gaussian
C-IFC. We prove: (1) a constant additive gap (difference between inner and
outer bounds) of half a bit/sec/Hz per real dimension, of relevance at high
SNRs, and (b) a constant multiplicative gap (ratio between outer and inner
bounds) of a factor two, of relevance at low SNRs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3088</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3088</id><created>2010-09-16</created><updated>2010-09-25</updated><authors><author><keyname>Chun</keyname><forenames>Byung-Gon</forenames></author><author><keyname>Ihm</keyname><forenames>Sunghwan</forenames></author><author><keyname>Maniatis</keyname><forenames>Petros</forenames></author><author><keyname>Naik</keyname><forenames>Mayur</forenames></author></authors><title>CloneCloud: Boosting Mobile Device Applications Through Cloud Clone
  Execution</title><categories>cs.DC cs.OS</categories><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile applications are becoming increasingly ubiquitous and provide ever
richer functionality on mobile devices. At the same time, such devices often
enjoy strong connectivity with more powerful machines ranging from laptops and
desktops to commercial clouds. This paper presents the design and
implementation of CloneCloud, a system that automatically transforms mobile
applications to benefit from the cloud. The system is a flexible application
partitioner and execution runtime that enables unmodified mobile applications
running in an application-level virtual machine to seamlessly off-load part of
their execution from mobile devices onto device clones operating in a
computational cloud. CloneCloud uses a combination of static analysis and
dynamic profiling to optimally and automatically partition an application so
that it migrates, executes in the cloud, and re-integrates computation in a
fine-grained manner that makes efficient use of resources. Our evaluation shows
that CloneCloud can achieve up to 21.2x speedup of smartphone applications we
tested and it allows different partitioning for different inputs and networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3090</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3090</id><created>2010-09-16</created><updated>2010-09-17</updated><authors><author><keyname>Louie</keyname><forenames>Raymond H. Y.</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Open-Loop Spatial Multiplexing and Diversity Communications in Ad Hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>51 pages, 19 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the performance of open-loop multi-antenna
point-to-point links in ad hoc networks with slotted ALOHA medium access
control (MAC). We consider spatial multiplexing transmission with linear
maximum ratio combining and zero forcing receivers, as well as orthogonal space
time block coded transmission. New closed-form expressions are derived for the
outage probability, throughput and transmission capacity. Our results
demonstrate that both the best performing scheme and the optimum number of
transmit antennas depend on different network parameters, such as the node
intensity and the signal-to-interference-and-noise ratio operating value. We
then compare the performance to a network consisting of single-antenna devices
and an idealized fully centrally coordinated MAC. These results show that
multi-antenna schemes with a simple decentralized slotted ALOHA MAC can
outperform even idealized single-antenna networks in various practical
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3124</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3124</id><created>2010-09-16</created><authors><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>Quantum function computation using sublogarithmic space (abstract &amp;
  poster)</title><categories>cs.CC</categories><comments>2 pages, poster presented at the 13th Workshop on Quantum Information
  Processing (QIP2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that quantum Turing machines are strictly superior to probabilistic
Turing machines in function computation for any space bound $ o(\log(n)) $.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3130</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3130</id><created>2010-09-16</created><updated>2011-02-22</updated><authors><author><keyname>Subramanian</keyname><forenames>Arunkumar</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author><author><keyname>Bloch</keyname><forenames>Matthieu</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steven W.</forenames></author></authors><title>Strong Secrecy on the Binary Erasure Wiretap Channel Using Large-Girth
  LDPC Codes</title><categories>cs.IT math.IT</categories><comments>11 pages, 4 figures. Submitted to the IEEE Transactions on
  Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an arbitrary degree distribution pair (DDP), we construct a sequence of
low-density parity-check (LDPC) code ensembles with girth growing
logarithmically in block-length using Ramanujan graphs. When the DDP has
minimum left degree at least three, we show using density evolution analysis
that the expected bit-error probability of these ensembles, when passed through
a binary erasure channel with erasure probability $\epsilon$, decays as
$\mathcal{O}(\exp(-c_1 n^{c_2}))$ with the block-length $n$ for positive
constants $c_1$ and $c_2$, as long as $\epsilon$ is lesser than the erasure
threshold $\epsilon_\mathrm{th}$ of the DDP. This guarantees that the coset
coding scheme using the dual sequence provides strong secrecy over the binary
erasure wiretap channel for erasure probabilities greater than $1 -
\epsilon_\mathrm{th}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3134</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3134</id><created>2010-09-16</created><updated>2012-03-08</updated><authors><author><keyname>Brodal</keyname><forenames>G. S.</forenames></author><author><keyname>Sioutas</keyname><forenames>S.</forenames></author><author><keyname>Tsichlas</keyname><forenames>K.</forenames></author><author><keyname>Zaroliagis</keyname><forenames>C.</forenames></author></authors><title>D$^2$-Tree: A New Overlay with Deterministic Bounds</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new overlay, called the {\em Deterministic Decentralized tree}
($D^2$-tree). The $D^2$-tree compares favourably to other overlays for the
following reasons: (a) it provides matching and better complexities, which are
deterministic for the supported operations; (b) the management of nodes (peers)
and elements are completely decoupled from each other; and (c) an efficient
deterministic load-balancing mechanism is presented for the uniform
distribution of elements into nodes, while at the same time probabilistic
optimal bounds are provided for the congestion of operations at the nodes. The
load-balancing scheme of elements into nodes is deterministic and general
enough to be applied to other hierarchical tree-based overlays. This
load-balancing mechanism is based on an innovative lazy weight-balancing
mechanism, which is interesting in its own right.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3145</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3145</id><created>2010-09-16</created><updated>2011-07-14</updated><authors><author><keyname>Boufounos</keyname><forenames>Petros T.</forenames></author></authors><title>Universal Rate-Efficient Scalar Quantization</title><categories>cs.IT math.IT</categories><msc-class>94A20, 94A34</msc-class><acm-class>H.1.1; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scalar quantization is the most practical and straightforward approach to
signal quantization. However, it has been shown that scalar quantization of
oversampled or Compressively Sensed signals can be inefficient in terms of the
rate-distortion trade-off, especially as the oversampling rate or the sparsity
of the signal increases. In this paper, we modify the scalar quantizer to have
discontinuous quantization regions. We demonstrate that with this modification
it is possible to achieve exponential decay of the quantization error as a
function of the oversampling rate instead of the quadratic decay exhibited by
current approaches. Our approach is universal in the sense that prior knowledge
of the signal model is not necessary in the quantizer design, only in the
reconstruction. Thus, we demonstrate that it is possible to reduce the
quantization error by incorporating side information on the acquired signal,
such as sparse signal models or signal similarity with known signals. In doing
so, we establish a relationship between quantization performance and the
Kolmogorov entropy of the signal model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3167</identifier>
 <datestamp>2013-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3167</id><created>2010-09-15</created><authors><author><keyname>Fuemmeler</keyname><forenames>Jason A.</forenames></author><author><keyname>Atia</keyname><forenames>George K.</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Sensor Management for Tracking in Sensor Networks</title><categories>cs.NI</categories><journal-ref>IEEE Trans.Sign.Proc. 59 (2011) 4354-4366</journal-ref><doi>10.1109/TSP.2011.2159496</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of tracking an object moving through a network of
wireless sensors. In order to conserve energy, the sensors may be put into a
sleep mode with a timer that determines their sleep duration. It is assumed
that an asleep sensor cannot be communicated with or woken up, and hence the
sleep duration needs to be determined at the time the sensor goes to sleep
based on all the information available to the sensor. Having sleeping sensors
in the network could result in degraded tracking performance, therefore, there
is a tradeoff between energy usage and tracking performance. We design sleeping
policies that attempt to optimize this tradeoff and characterize their
performance. As an extension to our previous work in this area [1], we consider
generalized models for object movement, object sensing, and tracking cost. For
discrete state spaces and continuous Gaussian observations, we derive a lower
bound on the optimal energy-tracking tradeoff. It is shown that in the low
tracking error regime, the generated policies approach the derived lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3174</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3174</id><created>2010-09-16</created><authors><author><keyname>Chang</keyname><forenames>Stephen</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author><author><keyname>Felleisen</keyname><forenames>Matthias</forenames></author></authors><title>Evaluating Call-By-Need on the Control Stack</title><categories>cs.PL</categories><comments>Symposium on Trends in Functional Programming (TFP 2010), Norman,
  Oklahoma, May 2010</comments><acm-class>D.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ariola and Felleisen's call-by-need {\lambda}-calculus replaces a variable
occurrence with its value at the last possible moment. To support this gradual
notion of substitution, function applications-once established-are never
discharged. In this paper we show how to translate this notion of reduction
into an abstract machine that resolves variable references via the control
stack. In particular, the machine uses the static address of a variable
occurrence to extract its current value from the dynamic control stack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3186</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3186</id><created>2010-09-16</created><updated>2011-07-22</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Hormati</keyname><forenames>Ali</forenames></author><author><keyname>Karbasi</keyname><forenames>Amin</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Group Testing with Probabilistic Tests: Theory, Design and Application</title><categories>cs.IT math.IT</categories><comments>Full version of the conference paper &quot;Compressed Sensing with
  Probabilistic Measurements: A Group Testing Solution&quot; appearing in
  proceedings of the 47th Annual Allerton Conference on Communication, Control,
  and Computing, 2009 (arXiv:0909.3508). To appear in IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identification of defective members of large populations has been widely
studied in the statistics community under the name of group testing. It
involves grouping subsets of items into different pools and detecting defective
members based on the set of test results obtained for each pool.
  In a classical noiseless group testing setup, it is assumed that the sampling
procedure is fully known to the reconstruction algorithm, in the sense that the
existence of a defective member in a pool results in the test outcome of that
pool to be positive. However, this may not be always a valid assumption in some
cases of interest. In particular, we consider the case where the defective
items in a pool can become independently inactive with a certain probability.
Hence, one may obtain a negative test result in a pool despite containing some
defective items. As a result, any sampling and reconstruction method should be
able to cope with two different types of uncertainty, i.e., the unknown set of
defective items and the partially unknown, probabilistic testing procedure.
  In this work, motivated by the application of detecting infected people in
viral epidemics, we design non-adaptive sampling procedures that allow
successful identification of the defective items through a set of probabilistic
tests. Our design requires only a small number of tests to single out the
defective items. In particular, for a population of size $N$ and at most $K$
defective items with activation probability $p$, our results show that $M =
O(K^2\log{(N/K)}/p^3)$ tests is sufficient if the sampling procedure should
work for all possible sets of defective items, while $M = O(K\log{(N)}/p^3)$
tests is enough to be successful for any single set of defective items.
Moreover, we show that the defective members can be recovered using a simple
reconstruction algorithm with complexity of $O(MN)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3214</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3214</id><created>2010-09-16</created><updated>2011-01-01</updated><authors><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames></author><author><keyname>Roche</keyname><forenames>Daniel S.</forenames></author><author><keyname>Tilak</keyname><forenames>Hrushikesh</forenames></author></authors><title>Computing sparse multiples of polynomials</title><categories>cs.SC cs.CC cs.DS</categories><comments>Extended abstract appears in Proc. ISAAC 2010, pp. 266-278, LNCS 6506</comments><acm-class>F.2.1; I.1.2; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding a sparse multiple of a polynomial. Given f
in F[x] of degree d over a field F, and a desired sparsity t, our goal is to
determine if there exists a multiple h in F[x] of f such that h has at most t
non-zero terms, and if so, to find such an h. When F=Q and t is constant, we
give a polynomial-time algorithm in d and the size of coefficients in h. When F
is a finite field, we show that the problem is at least as hard as determining
the multiplicative order of elements in an extension field of F (a problem
thought to have complexity similar to that of factoring integers), and this
lower bound is tight when t=2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3217</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3217</id><created>2010-09-16</created><updated>2012-04-25</updated><authors><author><keyname>Bonsma</keyname><forenames>Paul</forenames></author></authors><title>The Complexity of Rerouting Shortest Paths</title><categories>cs.CC</categories><comments>The results on claw-free graphs, chordal graphs and isolated paths
  have been added in version 2 (april 2012). Version 1 (September 2010) only
  contained the PSPACE-hardness result. (Version 2 has been submitted.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shortest Path Reconfiguration problem has as input a graph G (with unit
edge lengths) with vertices s and t, and two shortest st-paths P and Q. The
question is whether there exists a sequence of shortest st-paths that starts
with P and ends with Q, such that subsequent paths differ in only one vertex.
This is called a rerouting sequence.
  This problem is shown to be PSPACE-complete. For claw-free graphs and chordal
graphs, it is shown that the problem can be solved in polynomial time, and that
shortest rerouting sequences have linear length. For these classes, it is also
shown that deciding whether a rerouting sequence exists between all pairs of
shortest st-paths can be done in polynomial time. Finally, a polynomial time
algorithm for counting the number of isolated paths is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3238</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3238</id><created>2010-09-16</created><authors><author><keyname>Bastenhof</keyname><forenames>Arno</forenames></author></authors><title>Tableaux for the Lambek-Grishin calculus</title><categories>cs.CL</categories><comments>Appeared in: Marija Slavkovik, editor, &quot;Proceedings of the 15th
  student session of the European Summer School of Logic, Language and
  Information&quot;, Copenhagen, 2010. (Unpublished.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Categorial type logics, pioneered by Lambek, seek a proof-theoretic
understanding of natural language syntax by identifying categories with
formulas and derivations with proofs. We typically observe an intuitionistic
bias: a structural configuration of hypotheses (a constituent) derives a single
conclusion (the category assigned to it). Acting upon suggestions of Grishin to
dualize the logical vocabulary, Moortgat proposed the Lambek-Grishin calculus
(LG) with the aim of restoring symmetry between hypotheses and conclusions. We
develop a theory of labeled modal tableaux for LG, inspired by the
interpretation of its connectives as binary modal operators in the relational
semantics of Kurtonina and Moortgat. As a linguistic application of our method,
we show that grammars based on LG are context-free through use of an
interpolation lemma. This result complements that of Melissen, who proved that
LG augmented by mixed associativity and -commutativity was exceeds LTAG in
expressive power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3240</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3240</id><created>2010-09-16</created><updated>2011-09-20</updated><authors><author><keyname>McMahan</keyname><forenames>H. Brendan</forenames></author></authors><title>A Unified View of Regularized Dual Averaging and Mirror Descent with
  Implicit Updates</title><categories>cs.LG</categories><comments>Extensively updated version of earlier draft with new analysis
  including a general treatment of composite objectives and experiments. Also
  fixes a small bug in some of one of the proofs in the early version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study three families of online convex optimization algorithms:
follow-the-proximally-regularized-leader (FTRL-Proximal), regularized dual
averaging (RDA), and composite-objective mirror descent. We first prove
equivalence theorems that show all of these algorithms are instantiations of a
general FTRL update. This provides theoretical insight on previous experimental
observations. In particular, even though the FOBOS composite mirror descent
algorithm handles L1 regularization explicitly, it has been observed that RDA
is even more effective at producing sparsity. Our results demonstrate that
FOBOS uses subgradient approximations to the L1 penalty from previous rounds,
leading to less sparsity than RDA, which handles the cumulative penalty in
closed form. The FTRL-Proximal algorithm can be seen as a hybrid of these two,
and outperforms both on a large, real-world dataset.
  Our second contribution is a unified analysis which produces regret bounds
that match (up to logarithmic terms) or improve the best previously known
bounds. This analysis also extends these algorithms in two important ways: we
support a more general type of composite objective and we analyze implicit
updates, which replace the subgradient approximation of the current loss
function with an exact optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3243</identifier>
 <datestamp>2011-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3243</id><created>2010-09-16</created><updated>2011-06-17</updated><authors><author><keyname>Noel</keyname><forenames>Hans</forenames></author><author><keyname>Nyhan</keyname><forenames>Brendan</forenames></author></authors><title>The &quot;Unfriending&quot; Problem: The Consequences of Homophily in Friendship
  Retention for Causal Estimates of Social Influence</title><categories>stat.AP cs.SI physics.data-an physics.soc-ph</categories><comments>26 pages, 4 figures</comments><doi>10.1016/j.socnet.2011.05.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An increasing number of scholars are using longitudinal social network data
to try to obtain estimates of peer or social influence effects. These data may
provide additional statistical leverage, but they can introduce new inferential
problems. In particular, while the confounding effects of homophily in
friendship formation are widely appreciated, homophily in friendship retention
may also confound causal estimates of social influence in longitudinal network
data. We provide evidence for this claim in a Monte Carlo analysis of the
statistical model used by Christakis, Fowler, and their colleagues in numerous
articles estimating &quot;contagion&quot; effects in social networks. Our results
indicate that homophily in friendship retention induces significant upward bias
and decreased coverage levels in the Christakis and Fowler model if there is
non-negligible friendship attrition over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3253</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3253</id><created>2010-09-16</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Transmission Strategies in Multiple Access Fading Channels with
  Statistical QoS Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective capacity, which provides the maximum constant arrival rate that a
given service process can support while satisfying statistical delay
constraints, is analyzed in a multiuser scenario. In particular, the effective
capacity region of fading multiple access channels (MAC) in the presence of
quality of service (QoS) constraints is studied. Perfect channel side
information (CSI) is assumed to be available at both the transmitters and the
receiver. It is initially assumed the transmitters send the information at a
fixed power level and hence do not employ power control policies. Under this
assumption, the performance achieved by superposition coding with successive
decoding techniques is investigated. It is shown that varying the decoding
order with respect to the channel states can significantly increase the
achievable throughput region. In the two-user case, the optimal decoding
strategy is determined for the scenario in which the users have the same QoS
constraints. The performance of orthogonal transmission strategies is also
analyzed. It is shown that for certain QoS constraints, time-division
multiple-access (TDMA) can achieve better performance than superposition coding
if fixed successive decoding order is used at the receiver side.
  In the subsequent analysis, power control policies are incorporated into the
transmission strategies. The optimal power allocation policies for any fixed
decoding order over all channel states are identified. For a given variable
decoding order strategy, the conditions that the optimal power control policies
must satisfy are determined, and an algorithm that can be used to compute these
optimal policies is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3291</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3291</id><created>2010-09-16</created><authors><author><keyname>Wang</keyname><forenames>Zhiying</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author></authors><title>Rebuilding for Array Codes in Distributed Storage Systems</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>7 pages, 3 figures, accepted by workshop on the Application of
  Communication Theory to Emerging Memory Technologies (ACTEMT) 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In distributed storage systems that use coding, the issue of minimizing the
communication required to rebuild a storage node after a failure arises. We
consider the problem of repairing an erased node in a distributed storage
system that uses an EVENODD code. EVENODD codes are maximum distance separable
(MDS) array codes that are used to protect against erasures, and only require
XOR operations for encoding and decoding. We show that when there are two
redundancy nodes, to rebuild one erased systematic node, only 3/4 of the
information needs to be transmitted. Interestingly, in many cases, the required
disk I/O is also minimized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3306</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3306</id><created>2010-09-16</created><authors><author><keyname>Sala&#xfc;n</keyname><forenames>Gwen</forenames></author><author><keyname>Fu</keyname><forenames>Xiang</forenames></author><author><keyname>Hall&#xe9;</keyname><forenames>Sylvain</forenames></author></authors><title>Proceedings Fourth International Workshop on Testing, Analysis and
  Verification of Web Software</title><categories>cs.SE cs.FL cs.LO cs.PL cs.SC</categories><proxy>EPTCS</proxy><acm-class>D.2.2;D.2.4;D.2.5;H.3.5;H.5.3</acm-class><journal-ref>EPTCS 35, 2010</journal-ref><doi>10.4204/EPTCS.35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers presented at the fourth international
workshop on Testing, Analysis and Verification of Software, which was
associated with the 25th IEEE/ACM International Conference on Automated
Software Engineering (ASE 2010). The collection of papers includes research on
formal specification, model-checking, testing, and debugging of Web software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3321</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3321</id><created>2010-09-16</created><updated>2011-06-02</updated><authors><author><keyname>Altmann</keyname><forenames>Eduardo G.</forenames></author><author><keyname>Pierrehumbert</keyname><forenames>Janet B.</forenames></author><author><keyname>Motter</keyname><forenames>Adilson E.</forenames></author></authors><title>Niche as a determinant of word fate in online groups</title><categories>cs.CL cond-mat.dis-nn nlin.AO physics.soc-ph q-bio.PE</categories><comments>Supporting Information is available here:
  http://www.plosone.org/article/fetchSingleRepresentation.action?uri=info:doi/10.1371/journal.pone.0019009.s001</comments><journal-ref>PLoS ONE 6(5), e19009 (2011)</journal-ref><doi>10.1371/journal.pone.0019009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Patterns of word use both reflect and influence a myriad of human activities
and interactions. Like other entities that are reproduced and evolve, words
rise or decline depending upon a complex interplay between {their intrinsic
properties and the environments in which they function}. Using Internet
discussion communities as model systems, we define the concept of a word niche
as the relationship between the word and the characteristic features of the
environments in which it is used. We develop a method to quantify two important
aspects of the size of the word niche: the range of individuals using the word
and the range of topics it is used to discuss. Controlling for word frequency,
we show that these aspects of the word niche are strong determinants of changes
in word frequency. Previous studies have already indicated that word frequency
itself is a correlate of word success at historical time scales. Our analysis
of changes in word frequencies over time reveals that the relative sizes of
word niches are far more important than word frequencies in the dynamics of the
entire vocabulary at shorter time scales, as the language adapts to new
concepts and social groupings. We also distinguish endogenous versus exogenous
factors as additional contributors to the fates of words, and demonstrate the
force of this distinction in the rise of novel words. Our results indicate that
short-term nonstationarity in word statistics is strongly driven by individual
proclivities, including inclinations to provide novel information and to
project a distinctive social identity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3345</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3345</id><created>2010-09-17</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Cooperative Feedback for MIMO Interference Channels</title><categories>cs.IT math.IT</categories><comments>5 pages; submitted to IEEE ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-antenna precoding effectively mitigates the interference in wireless
networks. However, the precoding efficiency can be significantly degraded by
the overhead due to the required feedback of channel state information (CSI).
This paper addresses such an issue by proposing a systematic method of
designing precoders for the two-user multiple-input-multiple-output (MIMO)
interference channels based on finite-rate CSI feedback from receivers to their
interferers, called cooperative feedback. Specifically, each precoder is
decomposed into inner and outer precoders for nulling interference and
improving the data link array gain, respectively. The inner precoders are
further designed to suppress residual interference resulting from finite-rate
cooperative feedback. To regulate residual interference due to precoder
quantization, additional scalar cooperative feedback signals are designed to
control transmitters' power using different criteria including applying
interference margins, maximizing sum throughput, and minimizing outage
probability. Simulation shows that such additional feedback effectively
alleviates performance degradation due to quantized precoder feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3346</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3346</id><created>2010-09-17</created><authors><author><keyname>Shi</keyname><forenames>Qinfeng</forenames></author><author><keyname>Reid</keyname><forenames>Mark D.</forenames></author><author><keyname>Caetano</keyname><forenames>Tiberio</forenames></author></authors><title>Conditional Random Fields and Support Vector Machines: A Hybrid Approach</title><categories>cs.LG</categories><comments>16 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel hybrid loss for multiclass and structured prediction
problems that is a convex combination of log loss for Conditional Random Fields
(CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We
provide a sufficient condition for when the hybrid loss is Fisher consistent
for classification. This condition depends on a measure of dominance between
labels - specifically, the gap in per observation probabilities between the
most likely labels. We also prove Fisher consistency is necessary for
parametric consistency when learning models such as CRFs.
  We demonstrate empirically that the hybrid loss typically performs as least
as well as - and often better than - both of its constituent losses on variety
of tasks. In doing so we also provide an empirical comparison of the efficacy
of probabilistic and margin based approaches to multiclass and structured
prediction and the effects of label dominance on these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3353</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3353</id><created>2010-09-17</created><authors><author><keyname>Schmutzhard</keyname><forenames>Sebastian</forenames></author><author><keyname>Jung</keyname><forenames>Alexander</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author><author><keyname>Ben-Haim</keyname><forenames>Zvika</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>A Lower Bound on the Estimator Variance for the Sparse Linear Model</title><categories>math.ST cs.IT math.IT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of estimators of a sparse nonrandom vector based on
an observation which is linearly transformed and corrupted by additive white
Gaussian noise. Using the reproducing kernel Hilbert space framework, we derive
a new lower bound on the estimator variance for a given differentiable bias
function (including the unbiased case) and an almost arbitrary transformation
matrix (including the underdetermined case considered in compressed sensing
theory). For the special case of a sparse vector corrupted by white Gaussian
noise-i.e., without a linear transformation-and unbiased estimation, our lower
bound improves on previously proposed bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3354</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3354</id><created>2010-09-17</created><authors><author><keyname>Onic</keyname><forenames>Alexander</forenames></author><author><keyname>Huemer</keyname><forenames>Mario</forenames></author></authors><title>Direct vs. Two-Step Approach for Unique Word Generation in UW-OFDM</title><categories>cs.IT math.IT</categories><msc-class>94A14</msc-class><acm-class>B.4.1</acm-class><journal-ref>Proceedings of the 15th International OFDM Workshop, Hamburg, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unique word OFDM is a novel technique for constructing OFDM symbols, that has
many advantages over cyclic prefix OFDM. In this paper we investigate two
different approaches for the generation of an OFDM symbol containing a unique
word in its time domain representation. The two-step and the direct approach
seem very similar at first sight, but actually produce completely different
OFDM symbols. Also the overall system's bit error ratio differs significantly
for the two approaches. We will prove these propositions analytically, and we
will give simulation results for further illustration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3359</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3359</id><created>2010-09-17</created><updated>2010-12-26</updated><authors><author><keyname>Vanclay</keyname><forenames>Jerome K.</forenames></author></authors><title>An evaluation of the Australian Research Council's journal ranking</title><categories>cs.DL</categories><comments>14 pages, 4 figures, 7 tables</comments><journal-ref>Journal of Informetrics (2011) 5:265-274</journal-ref><doi>10.1016/j.joi.2010.12.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As part of its program of 'Excellence in Research for Australia' (ERA), the
Australian Research Council ranked journals into four categories (A*, A, B, C)
in preparation for their performance evaluation of Australian universities. The
ranking is important because it likely to have a major impact on publication
choices and research dissemination in Australia. The ranking is problematic
because it is evident that some disciplines have been treated very differently
than others. This paper reveals weaknesses in the ERA journal ranking and
highlights the poor correlation between ERA rankings and other acknowledged
metrics of journal standing. It highlights the need for a reasonable
representation of journals ranked as A* in each scientific discipline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3387</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3387</id><created>2010-09-17</created><updated>2011-04-28</updated><authors><author><keyname>Natarajan</keyname><forenames>Lakshmi Prasad</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Distributed STBCs with Full-diversity Partial Interference Cancellation
  Decoding</title><categories>cs.IT math.IT</categories><comments>10 pages, 3 figures, 1 table. Expanded the proposed class of
  full-diversity PIC/PIC-SIC decodable DSTBCs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Guo and Xia introduced low complexity decoders called Partial
Interference Cancellation (PIC) and PIC with Successive Interference
Cancellation (PIC-SIC), which include the Zero Forcing (ZF) and ZF-SIC
receivers as special cases, for point-to-point MIMO channels. In this paper, we
show that PIC and PIC-SIC decoders are capable of achieving the full
cooperative diversity available in wireless relay networks. We give sufficient
conditions for a Distributed Space-Time Block Code (DSTBC) to achieve full
diversity with PIC and PIC-SIC decoders and construct a new class of DSTBCs
with low complexity full-diversity PIC-SIC decoding using complex orthogonal
designs. The new class of codes includes a number of known full-diversity
PIC/PIC-SIC decodable Space-Time Block Codes (STBCs) constructed for
point-to-point channels as special cases. The proposed DSTBCs achieve higher
rates (in complex symbols per channel use) than the multigroup ML decodable
DSTBCs available in the literature. Simulation results show that the proposed
codes have better bit error rate performance than the best known low
complexity, full-diversity DSTBCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3391</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3391</id><created>2010-09-17</created><updated>2010-11-04</updated><authors><author><keyname>Bobillo</keyname><forenames>Fernando</forenames></author><author><keyname>Straccia</keyname><forenames>Umberto</forenames></author></authors><title>Fuzzy Ontology Representation using OWL 2</title><categories>cs.LO</categories><comments>v3: 32 pages, LaTeX; the new version includes a restriction in the
  syntax of weighted sum concepts, and changes the order of the paragraph
  &quot;Notation&quot;. v2: 32 pages, LaTeX; the new version extends the previous one
  with fuzzy modified datatypes, which means changes in the syntax (Section
  3.1), semantics (Section 3.2), and their representation using OWL 2 (Section
  4.4)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need to deal with vague information in Semantic Web languages is rising
in importance and, thus, calls for a standard way to represent such
information. We may address this issue by either extending current Semantic Web
languages to cope with vagueness, or by providing a procedure to represent such
information within current standard languages and tools. In this work, we
follow the latter approach, by identifying the syntactic differences that a
fuzzy ontology language has to cope with, and by proposing a concrete
methodology to represent fuzzy ontologies using OWL 2 annotation properties. We
also report on the prototypical implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3394</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3394</id><created>2010-09-17</created><updated>2011-01-25</updated><authors><author><keyname>Kirkland</keyname><forenames>Steve</forenames></author><author><keyname>Severini</keyname><forenames>Simone</forenames></author></authors><title>Spin systems dynamics and faults detection in threshold networks</title><categories>quant-ph cond-mat.dis-nn cs.DM</categories><comments>6 pages</comments><journal-ref>Phys. Rev. A 83, 012310 (2011)</journal-ref><doi>10.1103/PhysRevA.83.012310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an agent on a fixed but arbitrary node of a known threshold
network, with the task of detecting an unknown missing link/node. We obtain
analytic formulas for the probability of success, when the agent's tool is the
free evolution of a single excitation on an XX spin system paired with the
network. We completely characterize the parameters allowing for an advantageous
solution. From the results emerges an optimal (deterministic) algorithm for
quantum search, therefore gaining a quadratic speed-up with respect to the
optimal classical analogue, and in line with well-known results in quantum
computation. When attempting to detect a faulty node, the chosen setting
appears to be very fragile and the probability of success too small to be of
any direct use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3396</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3396</id><created>2010-09-17</created><authors><author><keyname>Kurzweil</keyname><forenames>Hans</forenames></author><author><keyname>Seidl</keyname><forenames>Mathis</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author></authors><title>Collaborative Decoding of Interleaved Reed-Solomon Codes using Gaussian
  Elimination</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an alternative method for collaborative decoding of interleaved
Reed-Solomon codes. Simulation results for a concatenated coding scheme using
polar codes as inner codes are included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3410</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3410</id><created>2010-09-17</created><updated>2011-10-08</updated><authors><author><keyname>van Gool</keyname><forenames>Sam</forenames></author></authors><title>Duality and canonical extensions for stably compact spaces</title><categories>math.GN cs.LO math.CT math.LO</categories><comments>29 pages, 1 figure</comments><msc-class>54H99 (Primary), 03G10 (Secondary), 18A35</msc-class><journal-ref>Topology and its Applications, Vol. 159, No. 1, pp. 341-359 (2012)</journal-ref><doi>10.1016/j.topol.2011.09.040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a canonical extension for strong proximity lattices in order to
give an algebraic, point-free description of a finitary duality for stably
compact spaces. In this setting not only morphisms, but also objects may have
distinct pi- and sigma-extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3415</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3415</id><created>2010-09-17</created><authors><author><keyname>Kai</keyname><forenames>Cai Hong</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Temporal Starvation in CSMA Wireless Networks</title><categories>cs.NI</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that links in CSMA wireless networks are prone to
starvation. Prior works focused almost exclusively on equilibrium starvation.
In this paper, we show that links in CSMA wireless networks are also
susceptible to temporal starvation. Specifically, although some links have good
equilibrium throughputs and do not suffer from equilibrium starvation, they can
still have no throughput for extended periods from time to time. Given its
impact on quality of service, it is important to understand and characterize
temporal starvation. To this end, we develop a &quot;trap theory&quot; to analyze
temporal throughput fluctuation. The trap theory serves two functions. First,
it allows us to derive new mathematical results that shed light on the
transient behavior of CSMA networks. For example, we show that the duration of
a trap, during which some links receive no throughput, is insensitive to the
distributions of the backoff countdown and transmission time (packet duration)
in the CSMA protocol. Second, we can develop analytical tools for computing the
&quot;degrees of starvation&quot; for CSMA networks to aid network design. For example,
given a CSMA network, we can determine whether it suffers from starvation, and
if so, which links will starve. Furthermore, the likelihood and durations of
temporal starvation can also be computed. We believe that the ability to
identify and characterize temporal starvation as established in this paper will
serve as an important first step toward the design of effective remedies for
it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3429</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3429</id><created>2010-09-17</created><updated>2011-03-16</updated><authors><author><keyname>Petit</keyname><forenames>Barbara</forenames><affiliation>LIP - ENS Lyon - Universite de Lyon</affiliation></author></authors><title>Semantics of Typed Lambda-Calculus with Constructors</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.2, F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 1 (March 16,
  2011) lmcs:1067</journal-ref><doi>10.2168/LMCS-6(4:11)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Curry-style second-order type system with union and intersection
types for the lambda-calculus with constructors of Arbiser, Miquel and Rios, an
extension of lambda-calculus with a pattern matching mechanism for variadic
constructors. We then prove the strong normalisation and the absence of match
failure for a restriction of this system, by adapting the standard reducibility
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3448</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3448</id><created>2010-09-16</created><authors><author><keyname>Vhatkar</keyname><forenames>Kapil N.</forenames></author><author><keyname>Bhole</keyname><forenames>G. P.</forenames></author></authors><title>Internal Location Based System for Mobile Devices Using Passive RFID</title><categories>cs.NI</categories><comments>7 pages IEEE format. The original authors of this paper Lect. kapil
  N. Vhatkar &amp; Prof. G. P. Bhole claim for the ownership of the said paper so
  IJCSIS modified authors of the said paper.
  http://sites.google.com/site/ijcsis/vol-6-no-3-december-2009. arXiv admin
  note: this article was plagiarized by arXiv:1001.2258</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS December 2009, ISSN 1947 5500</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have explored our own innovative work about the design &amp; development of
internal location-identification system for mobile devices based on integration
of RFID and wireless technology. The function of our system is based on
strategically located passive RFID tags placed on objects around building which
are identified using an RFID reader attached to a mobile device. The mobile
device reads the RFID tag and through the wireless network, sends the request
to the server. The server resolves the request and sends the desired
location-based information back to the mobile device. We had addressed that we
can go through the RFID technology for internal location identification
(indoor), which provides us better location accuracy because of no contact
between the tag and the reader, and the system requires no line of sight. In
this paper we had also focused on the issues of RFID technologies i.e.
Non-line-of-sight &amp; High inventory speeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3455</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3455</id><created>2010-09-17</created><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Leva</keyname><forenames>Alberto</forenames></author><author><keyname>Maggio</keyname><forenames>Martina</forenames></author><author><keyname>Spoletini</keyname><forenames>Paola</forenames></author></authors><title>A control-theoretical methodology for the scheduling problem</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel methodology to develop scheduling algorithms. The
scheduling problem is phrased as a control problem, and control-theoretical
techniques are used to design a scheduling algorithm that meets specific
requirements. Unlike most approaches to feedback scheduling, where a controller
integrates a &quot;basic&quot; scheduling algorithm and dynamically tunes its parameters
and hence its performances, our methodology essentially reduces the design of a
scheduling algorithm to the synthesis of a controller that closes the feedback
loop. This approach allows the re-use of control-theoretical techniques to
design efficient scheduling algorithms; it frames and solves the scheduling
problem in a general setting; and it can naturally tackle certain peculiar
requirements such as robustness and dynamic performance tuning. A few
experiments demonstrate the feasibility of the approach on a real-time
benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3457</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3457</id><created>2010-09-17</created><updated>2011-03-01</updated><authors><author><keyname>Cruz</keyname><forenames>Felipe A.</forenames></author><author><keyname>Layton</keyname><forenames>Simon K.</forenames></author><author><keyname>Barba</keyname><forenames>Lorena A.</forenames></author></authors><title>How to obtain efficient GPU kernels: an illustration using FMM &amp; FGT
  algorithms</title><categories>cs.MS</categories><journal-ref>Comput. Phys. Commun., 182(10):2084-2098 (2011)</journal-ref><doi>10.1016/j.cpc.2011.05.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing on graphics processors is maybe one of the most important
developments in computational science to happen in decades. Not since the
arrival of the Beowulf cluster, which combined open source software with
commodity hardware to truly democratize high-performance computing, has the
community been so electrified. Like then, the opportunity comes with
challenges. The formulation of scientific algorithms to take advantage of the
performance offered by the new architecture requires rethinking core methods.
Here, we have tackled fast summation algorithms (fast multipole method and fast
Gauss transform), and applied algorithmic redesign for attaining performance on
gpus. The progression of performance improvements attained illustrates the
exercise of formulating algorithms for the massively parallel architecture of
the gpu. The end result has been gpu kernels that run at over 500 Gigaflops on
one nvidia Tesla C1060 card, thereby reaching close to practical peak. We can
confidently say that gpu computing is not just a vogue, it is truly an
irresistible trend in high-performance computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3460</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3460</id><created>2010-09-17</created><updated>2012-06-29</updated><authors><author><keyname>Chakrabarti</keyname><forenames>Amit</forenames></author><author><keyname>Regev</keyname><forenames>Oded</forenames></author></authors><title>An Optimal Lower Bound on the Communication Complexity of
  Gap-Hamming-Distance</title><categories>cs.CC math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an optimal $\Omega(n)$ lower bound on the randomized communication
complexity of the much-studied Gap-Hamming-Distance problem. As a consequence,
we obtain essentially optimal multi-pass space lower bounds in the data stream
model for a number of fundamental problems, including the estimation of
frequency moments.
  The Gap-Hamming-Distance problem is a communication problem, wherein Alice
and Bob receive $n$-bit strings $x$ and $y$, respectively. They are promised
that the Hamming distance between $x$ and $y$ is either at least $n/2+\sqrt{n}$
or at most $n/2-\sqrt{n}$, and their goal is to decide which of these is the
case. Since the formal presentation of the problem by Indyk and Woodruff (FOCS,
2003), it had been conjectured that the naive protocol, which uses $n$ bits of
communication, is asymptotically optimal. The conjecture was shown to be true
in several special cases, e.g., when the communication is deterministic, or
when the number of rounds of communication is limited.
  The proof of our aforementioned result, which settles this conjecture fully,
is based on a new geometric statement regarding correlations in Gaussian space,
related to a result of C. Borell (1985). To prove this geometric statement, we
show that random projections of not-too-small sets in Gaussian space are close
to a mixture of translated normal variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3462</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3462</id><created>2010-09-17</created><authors><author><keyname>Mazzara</keyname><forenames>Manuel</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Anirban</forenames></author></authors><title>On Modelling and Analysis of Dynamic Reconfiguration of Dependable
  Real-Time Systems</title><categories>cs.SE</categories><comments>Presented and published at DEPEND 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper motivates the need for a formalism for the modelling and analysis
of dynamic reconfiguration of dependable real-time systems. We present
requirements that the formalism must meet, and use these to evaluate well
established formalisms and two process algebras that we have been developing,
namely, Webpi and CCSdp. A simple case study is developed to illustrate the
modelling power of these two formalisms. The paper shows how Webpi and CCSdp
represent a significant step forward in modelling adaptive and dependable
real-time systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3468</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3468</id><created>2010-09-17</created><updated>2010-09-22</updated><authors><author><keyname>Sunny</keyname><forenames>Albert</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author><author><keyname>Aggarwal</keyname><forenames>Saurabh</forenames></author></authors><title>Delay Modelling for Single Cell IEEE 802.11 WLANs Using a Random Polling
  System</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of modelling the average delay
experienced by a packet in a single cell IEEE 802.11 DCF wireless local area
network. The packet arrival process at each node i is assumed to be Poisson
with rate parameter \lambda_i. Since the nodes are sharing a single channel,
they have to contend with one another for a successful transmission. The mean
delay for a packet has been approximated by modelling the system as a 1-limited
Random Polling system with zero switchover time. We show that even for
non-homogeneous packet arrival processes, the mean delay of packets across the
queues are same and depends on the system utilization factor and the aggregate
throughput of the MAC. Extensive simulations are conducted to verify the
analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3469</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3469</id><created>2010-09-17</created><updated>2010-09-21</updated><authors><author><keyname>Chambers</keyname><forenames>Erin</forenames></author><author><keyname>Fekete</keyname><forenames>Alejandro Erickson Sandor</forenames></author><author><keyname>Lenchner</keyname><forenames>Jonathan</forenames></author><author><keyname>Sember</keyname><forenames>Jeff</forenames></author><author><keyname>Srinivasan</keyname><forenames>Venkatesh</forenames></author><author><keyname>Stege</keyname><forenames>Ulrike</forenames></author><author><keyname>Stolpner</keyname><forenames>Svetlana</forenames></author><author><keyname>Weibel</keyname><forenames>Christophe</forenames></author><author><keyname>Whitesides</keyname><forenames>Sue</forenames></author></authors><title>Connectivity graphs of uncertainty regions</title><categories>cs.CG</categories><comments>26 pages, 15 figures, full version of extended abstract that is to
  appear in ISAAC 2010. (Modification: added full appendix with proof details.)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a generalization of the well known bottleneck spanning tree problem
called &quot;Best Case Connectivity with Uncertainty&quot;: Given a family of geometric
regions, choose one point per region, such that the length of the longest edge
in a spanning tree of a disc intersection graph is minimized. We show that this
problem is NP-hard even for very simple scenarios such as line segments and
squares. We also give exact and approximation algorithms for the case of line
segments and unit discs respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3481</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3481</id><created>2010-09-17</created><authors><author><keyname>Razaviyayn</keyname><forenames>Meisam</forenames></author><author><keyname>Sanjabi</keyname><forenames>Maziar</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author></authors><title>Linear Transceiver Design for Interference Alignment: Complexity and
  Computation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a MIMO interference channel whereby each transmitter and receiver
are equipped with multiple antennas. The basic problem is to design optimal
linear transceivers (or beamformers) that can maximize system throughput. The
recent work [1] suggests that optimal beamformers should maximize the total
degrees of freedom and achieve interference alignment in high SNR. In this
paper we first consider the interference alignment problem in spatial domain
and prove that the problem of maximizing the total degrees of freedom for a
given MIMO interference channel is NP-hard. Furthermore, we show that even
checking the achievability of a given tuple of degrees of freedom for all
receivers is NP-hard when each receiver is equipped with at least three
antennas. Interestingly, the same problem becomes polynomial time solvable when
each transmit/receive node is equipped with no more than two antennas. Finally,
we propose a distributed algorithm for transmit covariance matrix design, while
assuming each receiver uses a linear MMSE beamformer. The simulation results
show that the proposed algorithm outperforms the existing interference
alignment algorithms in terms of system throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3499</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3499</id><created>2010-09-17</created><updated>2011-04-14</updated><authors><author><keyname>Kim</keyname><forenames>Myunghwan</forenames></author><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author></authors><title>Multiplicative Attribute Graph Model of Real-World Networks</title><categories>cs.SI physics.soc-ph</categories><comments>33 pages, 6 figures</comments><doi>10.1007/978-3-642-18009-5_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large scale real-world network data such as social and information networks
are ubiquitous. The study of such social and information networks seeks to find
patterns and explain their emergence through tractable models. In most
networks, and especially in social networks, nodes have a rich set of
attributes (e.g., age, gender) associated with them.
  Here we present a model that we refer to as the Multiplicative Attribute
Graphs (MAG), which naturally captures the interactions between the network
structure and the node attributes. We consider a model where each node has a
vector of categorical latent attributes associated with it. The probability of
an edge between a pair of nodes then depends on the product of individual
attribute-attribute affinities. The model yields itself to mathematical
analysis and we derive thresholds for the connectivity and the emergence of the
giant connected component, and show that the model gives rise to networks with
a constant diameter. We analyze the degree distribution to show that MAG model
can produce networks with either log-normal or power-law degree distributions
depending on certain conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3502</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3502</id><created>2010-09-17</created><authors><author><keyname>Jampani</keyname><forenames>Krishnam Raju</forenames></author><author><keyname>Lubiw</keyname><forenames>Anna</forenames></author></authors><title>Simultaneous Interval Graphs</title><categories>cs.DS</categories><msc-class>68R10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper, we introduced the simultaneous representation problem
(defined for any graph class C) and studied the problem for chordal,
comparability and permutation graphs. For interval graphs, the problem is
defined as follows. Two interval graphs G_1 and G_2, sharing some vertices I
(and the corresponding induced edges), are said to be `simultaneous interval
graphs' if there exist interval representations R_1 and R_2 of G_1 and G_2,
such that any vertex of I is mapped to the same interval in both R_1 and R_2.
Equivalently, G_1 and G_2 are simultaneous interval graphs if there exist edges
E' between G_1-I and G_2-I such that G_1 \cup G_2 \cup E' is an interval graph.
  Simultaneous representation problems are related to simultaneous planar
embeddings, and have applications in any situation where it is desirable to
consistently represent two related graphs, for example: interval graphs
capturing overlaps of DNA fragments of two similar organisms; or graphs
connected in time, where one is an updated version of the other.
  In this paper we give an O(n^2*logn) time algorithm for recognizing
simultaneous interval graphs,where n = |G_1 \cup G_2|. This result complements
the polynomial time algorithms for recognizing probe interval graphs and
provides an efficient algorithm for the interval graph sandwich problem for the
special case where the set of optional edges induce a complete bipartite graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3514</identifier>
 <datestamp>2012-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3514</id><created>2010-09-17</created><updated>2011-09-14</updated><authors><author><keyname>Li</keyname><forenames>Boyu</forenames></author><author><keyname>Park</keyname><forenames>Hong Ju</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Reduced Complexity Decoding for Bit-Interleaved Coded Multiple
  Beamforming with Constellation Precoding</title><categories>cs.IT math.IT</categories><comments>accepted to conference</comments><doi>10.1109/IWCMC.2011.5982407</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple beamforming is realized by singular value decomposition of the
channel matrix which is assumed to be known to both the transmitter and the
receiver. Bit-Interleaved Coded Multiple Beamforming (BICMB) can achieve full
diversity as long as the code rate Rc and the number of employed subchannels S
satisfy the condition RcS&lt;=1. Bit-Interleaved Coded Multiple Beamforming with
Constellation Precoding (BICMB-CP), on the other hand, can achieve full
diversity without the condition RcS&lt;=1. However, the decoding complexity of
BICMB-CP is much higher than BICMB. In this paper, a reduced complexity
decoding technique, which is based on Sphere Decoding (SD), is proposed to
reduce the complexity of Maximum Likelihood (ML) decoding for BICMB-CP. The
decreased complexity decoding achieves several orders of magnitude reduction,
in terms of the average number of real multiplications needed to acquire one
precoded bit metric, not only with respect to conventional ML decoding, but
also, with respect to conventional SD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3515</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3515</id><created>2010-09-17</created><updated>2010-10-26</updated><authors><author><keyname>Ghaoui</keyname><forenames>Laurent El</forenames></author><author><keyname>Viallon</keyname><forenames>Vivian</forenames></author><author><keyname>Rabbani</keyname><forenames>Tarek</forenames></author></authors><title>Safe Feature Elimination in Sparse Supervised Learning</title><categories>cs.LG math.OC</categories><comments>New version is on arXiv:1009.4219</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate fast methods that allow to quickly eliminate variables
(features) in supervised learning problems involving a convex loss function and
a $l_1$-norm penalty, leading to a potentially substantial reduction in the
number of variables prior to running the supervised learning algorithm. The
methods are not heuristic: they only eliminate features that are {\em
guaranteed} to be absent after solving the learning problem. Our framework
applies to a large class of problems, including support vector machine
classification, logistic regression and least-squares.
  The complexity of the feature elimination step is negligible compared to the
typical computational effort involved in the sparse supervised learning
problem: it grows linearly with the number of features times the number of
examples, with much better count if data is sparse. We apply our method to data
sets arising in text classification and observe a dramatic reduction of the
dimensionality, hence in computational effort required to solve the learning
problem, especially when very sparse classifiers are sought. Our method allows
to immediately extend the scope of existing algorithms, allowing us to run them
on data sets of sizes that were out of their reach before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3520</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3520</id><created>2010-09-17</created><updated>2012-08-15</updated><authors><author><keyname>Li</keyname><forenames>Boyu</forenames></author><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>Bit-Interleaved Coded Multiple Beamforming with Perfect Coding</title><categories>cs.IT math.IT</categories><comments>accepted to conference; Proc. IEEE ICC 2012</comments><doi>10.1109/ICC.2012.6363883</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When the Channel State Information (CSI) is known by both the transmitter and
the receiver, beamforming techniques employing Singular Value Decomposition
(SVD) are commonly used in Multiple-Input Multiple-Output (MIMO) systems.
Without channel coding, there is a trade-off between full diversity and full
multiplexing. When channel coding is added, both of them can be achieved as
long as the code rate Rc and the number of employed subchannels S satisfy the
condition RcS&lt;=1. By adding a properly designed constellation precoder, both
full diversity and full multiplexing can be achieved for both uncoded and coded
systems with the trade-off of a higher decoding complexity, e.g., Fully
Precoded Multiple Beamforming (FPMB) and Bit-Interleaved Coded Multiple
Beamforming with Full Precoding (BICMB-FP) without the condition RcS&lt;=1.
Recently discovered Perfect Space-Time Block Code (PSTBC) is a full-rate
full-diversity space-time code, which achieves efficient shaping and high
coding gain for MIMO systems. In this paper, a new technique, Bit-Interleaved
Coded Multiple Beamforming with Perfect Coding (BICMB-PC), is introduced.
BICMB-PC transmits PSTBCs through convolutional coded SVD systems. Similar to
BICMB-FP, BICMB-PC achieves both full diversity and full multiplexing, and its
performance is almost the same as BICMB-FP. The advantage of BICMB-PC is that
it can provide a much lower decoding complexity than BICMB-FP, since the real
and imaginary parts of the received signal can be separated for BICMB-PC of
dimensions 2 and 4, and only the part corresponding to the coded bit is
required to acquire one bit metric for the Viterbi decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3522</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3522</id><created>2010-09-17</created><authors><author><keyname>Jo</keyname><forenames>Han-Shin</forenames></author><author><keyname>Xia</keyname><forenames>Ping</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Open, Closed, and Shared Access Femtocells in the Downlink</title><categories>cs.NI</categories><comments>26 pages, 8 figures, Submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental choice in femtocell deployments is the set of users which are
allowed to access each femtocell. Closed access restricts the set to
specifically registered users, while open access allows any mobile subscriber
to use any femtocell. Which one is preferable depends strongly on the distance
between the macrocell base station (MBS) and femtocell. The main results of the
paper are lemmas which provide expressions for the SINR distribution for
various zones within a cell as a function of this MBS-femto distance. The
average sum throughput (or any other SINR-based metric) of home users and
cellular users under open and closed access can be readily determined from
these expressions. We show that unlike in the uplink, the interests of home and
cellular users are in conflict, with home users preferring closed access and
cellular users preferring open access. The conflict is most pronounced for
femtocells near the cell edge, when there are many cellular users and fewer
femtocells. To mitigate this conflict, we propose a middle way which we term
shared access in which femtocells allocate an adjustable number of time-slots
between home and cellular users such that a specified minimum rate for each can
be achieved. The optimal such sharing fraction is derived. Analysis shows that
shared access achieves at least the overall throughput of open access while
also satisfying rate requirements, while closed access fails for cellular users
and open access fails for the home user.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3525</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3525</id><created>2010-09-17</created><authors><author><keyname>Khajehnejad</keyname><forenames>M. Amin</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Avestimehr</keyname><forenames>A. Salman</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Analyzing Weighted $\ell_1$ Minimization for Sparse Recovery with
  Nonuniform Sparse Models\footnote{The results of this paper were presented in
  part at the International Symposium on Information Theory, ISIT 2009}</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a nonuniform sparsity model and analyze the
performance of an optimized weighted $\ell_1$ minimization over that sparsity
model. In particular, we focus on a model where the entries of the unknown
vector fall into two sets, with entries of each set having a specific
probability of being nonzero. We propose a weighted $\ell_1$ minimization
recovery algorithm and analyze its performance using a Grassmann angle
approach. We compute explicitly the relationship between the system
parameters-the weights, the number of measurements, the size of the two sets,
the probabilities of being nonzero- so that when i.i.d. random Gaussian
measurement matrices are used, the weighted $\ell_1$ minimization recovers a
randomly selected signal drawn from the considered sparsity model with
overwhelming probability as the problem dimension increases. This allows us to
compute the optimal weights. We demonstrate through rigorous analysis and
simulations that for the case when the support of the signal can be divided
into two different subclasses with unequal sparsity fractions, the optimal
weighted $\ell_1$ minimization outperforms the regular $\ell_1$ minimization
substantially. We also generalize the results to an arbitrary number of
classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3527</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3527</id><created>2010-09-17</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author></authors><title>Priority Range Trees</title><categories>cs.CG</categories><comments>12 pages, 3 figures. To appear at 21st International Symposium on
  Algorithms and Computation (ISAAC 2010)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a data structure, called a priority range tree, which
accommodates fast orthogonal range reporting queries on prioritized points. Let
$S$ be a set of $n$ points in the plane, where each point $p$ in $S$ is
assigned a weight $w(p)$ that is polynomial in $n$, and define the rank of $p$
to be $r(p)=\lfloor \log w(p) \rfloor$. Then the priority range tree can be
used to report all points in a three- or four-sided query range $R$ with rank
at least $\lfloor \log w \rfloor$ in time $O(\log W/w + k)$, and report $k$
highest-rank points in $R$ in time $O(\log\log n + \log W/w' + k)$, where
$W=\sum_{p\in S}{w(p)}$, $w'$ is the smallest weight of any point reported, and
$k$ is the output size. All times assume the standard RAM model of computation.
If the query range of interest is three sided, then the priority range tree
occupies $O(n)$ space, otherwise $O(n\log n)$ space is used to answer
four-sided queries. These queries are motivated by the Weber--Fechner Law,
which states that humans perceive and interpret data on a logarithmic scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3539</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3539</id><created>2010-09-18</created><authors><author><keyname>Xiao</keyname><forenames>Fangying</forenames></author><author><keyname>Chen</keyname><forenames>Hanwu</forenames></author></authors><title>Is A Quantum Stabilizer Code Degenerate or Nondegenerate for Pauli
  Channel?</title><categories>cs.CR quant-ph</categories><comments>7 pages,1 figure</comments><msc-class>03G12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mapping an error syndrome to the error operator is the core of quantum
decoding network and is also the key step of recovery. The definitions of the
bit-flip error syndrome matrix and the phase-flip error syndrome matrix were
presented, and then the error syndromes of quantum errors were expressed in
terms of the columns of the bit-flip error syndrome matrix and the phase-flip
error syndrome matrix. It also showed that the error syndrome matrices of a
stabilizer code are determined by its check matrix, which is similar to the
classical case. So, the error-detection and recovery techniques of classical
linear codes can be applied to quantum stabilizer codes after some
modifications. Some necessary and/or sufficient conditions for the stabilizer
code over GF(2) is degenerate or nondegenerate for Pauli channel based on the
relationship between the error syndrome matrices and the check matrix was
presented. A new way to find the minimum distance of the quantum stabilizer
codes based on their check matrices was presented, and followed from which we
proved that the performance of degenerate quantum code outperform (at least
have the same performance) nondegenerate quantum code for Pauli channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3552</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3552</id><created>2010-09-18</created><authors><author><keyname>Parhizkar</keyname><forenames>Behrang</forenames></author><author><keyname>Alazizi</keyname><forenames>Abdulbasit Mohammad Abdulrahman</forenames></author><author><keyname>Ali</keyname><forenames>Mohammad Nabil Sadegh</forenames></author><author><keyname>Ramachandran</keyname><forenames>Anand</forenames></author><author><keyname>Navaratnam</keyname><forenames>Sujata</forenames></author></authors><title>PC 2 Phone Event Announcer</title><categories>cs.NI</categories><comments>5 pages, 3 figures, IJCSIS Vol. 8 No. 5</comments><journal-ref>International Journal of Computer Science&amp; Information
  Security(IJCSIS) Vol. 8 No. 5, August 2010, ISSN 1947-5500</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, mobile phones are indispensable devices; it has become a trend now
that college and university students are owners of such devices and this
particular factor plays a very important role behind the coming up with the
proposed system. &quot;PC 2 Phone event Announcer&quot;, is the name of the new proposed
system suggested to solve the existing communication problem between the
College staff and students. As the name suggests, it can be deduced that the
system will involve computers and phones, more specifically mobile phones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3567</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3567</id><created>2010-09-18</created><authors><author><keyname>Moon</keyname><forenames>Sungwook</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>Mobile Testbeds with an Attitude</title><categories>cs.NI cs.RO cs.SI</categories><comments>Demonstration of the mobile testbeds presented at MobiCom 2010 and
  GlobeCom 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been significant recent advances in mobile networks, specifically
in multi-hop wireless networks including DTNs and sensor networks. It is
critical to have a testing environment to realistically evaluate such networks
and their protocols and services. Towards this goal, we propose a novel, mobile
testbed of two main components. The first consists of a network of robots with
personality- mimicking, human-encounter behaviors, which will be the focus of
this demo. The personality is build upon behavioral profiling of mobile users
based on extensive wireless-network measurements and analysis. The second
component combines the testbed with the human society using a new concept that
we refer to as participatory testing utilizing crowd sourcing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3589</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3589</id><created>2010-09-18</created><authors><author><keyname>Bastien</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Bergeron</keyname><forenames>Arnaud</forenames></author><author><keyname>Boulanger-Lewandowski</keyname><forenames>Nicolas</forenames></author><author><keyname>Breuel</keyname><forenames>Thomas</forenames></author><author><keyname>Chherawala</keyname><forenames>Youssouf</forenames></author><author><keyname>Cisse</keyname><forenames>Moustapha</forenames></author><author><keyname>C&#xf4;t&#xe9;</keyname><forenames>Myriam</forenames></author><author><keyname>Erhan</keyname><forenames>Dumitru</forenames></author><author><keyname>Eustache</keyname><forenames>Jeremy</forenames></author><author><keyname>Glorot</keyname><forenames>Xavier</forenames></author><author><keyname>Muller</keyname><forenames>Xavier</forenames></author><author><keyname>Lebeuf</keyname><forenames>Sylvain Pannetier</forenames></author><author><keyname>Pascanu</keyname><forenames>Razvan</forenames></author><author><keyname>Rifai</keyname><forenames>Salah</forenames></author><author><keyname>Savard</keyname><forenames>Francois</forenames></author><author><keyname>Sicard</keyname><forenames>Guillaume</forenames></author></authors><title>Deep Self-Taught Learning for Handwritten Character Recognition</title><categories>cs.LG cs.CV cs.NE</categories><report-no>1353, Dept. IRO, U. Montreal</report-no><msc-class>68T05</msc-class><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent theoretical and empirical work in statistical machine learning has
demonstrated the importance of learning algorithms for deep architectures,
i.e., function classes obtained by composing multiple non-linear
transformations. Self-taught learning (exploiting unlabeled examples or
examples from other distributions) has already been applied to deep learners,
but mostly to show the advantage of unlabeled examples. Here we explore the
advantage brought by {\em out-of-distribution examples}. For this purpose we
developed a powerful generator of stochastic variations and noise processes for
character images, including not only affine transformations but also slant,
local elastic deformations, changes in thickness, background images, grey level
changes, contrast, occlusion, and various types of noise. The
out-of-distribution examples are obtained from these highly distorted images or
by including examples of object classes different from those in the target test
set. We show that {\em deep learners benefit more from out-of-distribution
examples than a corresponding shallow learner}, at least in the area of
handwritten character recognition. In fact, we show that they beat previously
published results and reach human-level performance on both handwritten digit
classification and 62-class handwritten character recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3593</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3593</id><created>2010-09-18</created><authors><author><keyname>Maleki</keyname><forenames>Hamed</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames></author></authors><title>Retrospective Interference Alignment</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore similarities and differences in recent works on blind interference
alignment under different models such as staggered block fading model and the
delayed CSIT model. In particular we explore the possibility of achieving
interference alignment with delayed CSIT when the transmitters are distributed.
Our main contribution is an interference alignment scheme, called retrospective
interference alignment in this work, that is specialized to settings with
distributed transmitters. With this scheme we show that the 2 user X channel
with only delayed channel state information at the transmitters can achieve 8/7
DoF, while the interference channel with 3 users is able to achieve 9/8 DoF. We
also consider another setting where delayed channel output feedback is
available to transmitters. In this setting the X channel and the 3 user
interference channel are shown to achieve 4/3 and 6/5 DoF, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3594</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3594</id><created>2010-09-18</created><updated>2011-08-11</updated><authors><author><keyname>Awasthi</keyname><forenames>Pranjal</forenames></author><author><keyname>Blum</keyname><forenames>Avrim</forenames></author><author><keyname>Sheffet</keyname><forenames>Or</forenames></author></authors><title>Center-based Clustering under Perturbation Stability</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering under most popular objective functions is NP-hard, even to
approximate well, and so unlikely to be efficiently solvable in the worst case.
Recently, Bilu and Linial \cite{Bilu09} suggested an approach aimed at
bypassing this computational barrier by using properties of instances one might
hope to hold in practice. In particular, they argue that instances in practice
should be stable to small perturbations in the metric space and give an
efficient algorithm for clustering instances of the Max-Cut problem that are
stable to perturbations of size $O(n^{1/2})$. In addition, they conjecture that
instances stable to as little as O(1) perturbations should be solvable in
polynomial time. In this paper we prove that this conjecture is true for any
center-based clustering objective (such as $k$-median, $k$-means, and
$k$-center). Specifically, we show we can efficiently find the optimal
clustering assuming only stability to factor-3 perturbations of the underlying
metric in spaces without Steiner points, and stability to factor $2+\sqrt{3}$
perturbations for general metrics. In particular, we show for such instances
that the popular Single-Linkage algorithm combined with dynamic programming
will find the optimal clustering. We also present NP-hardness results under a
weaker but related condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3599</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3599</id><created>2010-09-18</created><authors><author><keyname>Gouveia</keyname><forenames>Hugo</forenames></author><author><keyname>Moreira</keyname><forenames>Nelma</forenames></author><author><keyname>Reis</keyname><forenames>Rog&#xe9;rio</forenames></author></authors><title>Small NFAs from Regular Expressions: Some Experimental Results</title><categories>cs.FL</categories><comments>Proceedings of 6th Conference on Computability in Europe (CIE 2010),
  pages 194-203, Ponta Delgada, Azores, Portugal, June/July 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regular expressions (res), because of their succinctness and clear syntax,
are the common choice to represent regular languages. However, efficient
pattern matching or word recognition depend on the size of the equivalent
nondeterministic finite automata (NFA). We present the implementation of
several algorithms for constructing small epsilon-free NFAss from res within
the FAdo system, and a comparison of regular expression measures and NFA sizes
based on experimental results obtained from uniform random generated res. For
this analysis, nonredundant res and reduced res in star normal form were
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3602</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3602</id><created>2010-09-18</created><authors><author><keyname>Liu</keyname><forenames>Fang</forenames></author><author><keyname>Peng</keyname><forenames>Daiyuan</forenames></author><author><keyname>Zhou</keyname><forenames>Zhengchun</forenames></author><author><keyname>Tang</keyname><forenames>Xiaohu</forenames></author></authors><title>Construction of Frequency Hopping Sequence Set Based upon Generalized
  Cyclotomy</title><categories>cs.IT math.IT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency hopping (FH) sequences play a key role in frequency hopping spread
spectrum communication systems. It is important to find FH sequences which have
simultaneously good Hamming correlation, large family size and large period. In
this paper, a new set of FH sequences with large period is proposed, and the
Hamming correlation distribution of the new set is investigated. The
construction of new FH sequences is based upon Whiteman's generalized
cyclotomy. It is shown that the proposed FH sequence set is optimal with
respect to the average Hamming correlation bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3604</identifier>
 <datestamp>2012-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3604</id><created>2010-09-18</created><updated>2012-10-13</updated><authors><author><keyname>Manwani</keyname><forenames>Naresh</forenames></author><author><keyname>Sastry</keyname><forenames>P. S.</forenames></author></authors><title>Geometric Decision Tree</title><categories>cs.LG</categories><comments>Licensed copy is available on IEEE website</comments><report-no>Issue:99</report-no><journal-ref>IEEE Transactions on Systems, Man, and Cybernetics, Part B:
  Cybernetics,2011</journal-ref><doi>10.1109/TSMCB.2011.2163392</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new algorithm for learning oblique decision trees.
Most of the current decision tree algorithms rely on impurity measures to
assess the goodness of hyperplanes at each node while learning a decision tree
in a top-down fashion. These impurity measures do not properly capture the
geometric structures in the data. Motivated by this, our algorithm uses a
strategy to assess the hyperplanes in such a way that the geometric structure
in the data is taken into account. At each node of the decision tree, we find
the clustering hyperplanes for both the classes and use their angle bisectors
as the split rule at that node. We show through empirical studies that this
idea leads to small decision trees and better performance. We also present some
analysis to show that the angle bisectors of clustering hyperplanes that we use
as the split rules at each node, are solutions of an interesting optimization
problem and hence argue that this is a principled method of learning a decision
tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3613</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3613</id><created>2010-09-19</created><updated>2013-08-27</updated><authors><author><keyname>Gao</keyname><forenames>Wei</forenames></author><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author></authors><title>On the Doubt about Margin Explanation of Boosting</title><categories>cs.LG</categories><comments>35 pages</comments><msc-class>68Q01, 68Q32 68Txx</msc-class><journal-ref>Artificial Intelligence 203:1-18 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Margin theory provides one of the most popular explanations to the success of
\texttt{AdaBoost}, where the central point lies in the recognition that
\textit{margin} is the key for characterizing the performance of
\texttt{AdaBoost}. This theory has been very influential, e.g., it has been
used to argue that \texttt{AdaBoost} usually does not overfit since it tends to
enlarge the margin even after the training error reaches zero. Previously the
\textit{minimum margin bound} was established for \texttt{AdaBoost}, however,
\cite{Breiman1999} pointed out that maximizing the minimum margin does not
necessarily lead to a better generalization. Later, \cite{Reyzin:Schapire2006}
emphasized that the margin distribution rather than minimum margin is crucial
to the performance of \texttt{AdaBoost}. In this paper, we first present the
\textit{$k$th margin bound} and further study on its relationship to previous
work such as the minimum margin bound and Emargin bound. Then, we improve the
previous empirical Bernstein bounds
\citep{Maurer:Pontil2009,Audibert:Munos:Szepesvari2009}, and based on such
findings, we defend the margin-based explanation against Breiman's doubts by
proving a new generalization error bound that considers exactly the same
factors as \cite{Schapire:Freund:Bartlett:Lee1998} but is sharper than
\cite{Breiman1999}'s minimum margin bound. By incorporating factors such as
average margin and variance, we present a generalization error bound that is
heavily related to the whole margin distribution. We also provide margin
distribution bounds for generalization error of voting classifiers in finite
VC-dimension space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3619</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3619</id><created>2010-09-19</created><authors><author><keyname>Reichman</keyname><forenames>Daniel</forenames></author></authors><title>Influence is a Matter of Degree: New Algorithms for Activation Problems</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the target set selection problem. In this problem, a vertex is
active either if it belongs to a set of initially activated vertices or if at
some point it has at least $k$ active neighbors ($k$ is identical for all
vertices of the graph). Our goal is to find a set of minimum size whose
activation will result with the entire graph being activated. Call such a set
\emph{contagious}. We prove that if $G=(V,E)$ is an undirected graph, the size
of a contagious set is bounded by $\sum_{v\in V}{\min \{1,\frac{k}{d(v)+1}\}}$
(where $d(v)$ is the degree of $v$). We present a simple and efficient
algorithm that finds a contagious set that is not larger than the
aforementioned bound and discuss algorithmic applications of this algorithm to
finding contagious sets in dense graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3626</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3626</id><created>2010-09-19</created><updated>2012-02-02</updated><authors><author><keyname>Syamsuddin</keyname><forenames>Irfan</forenames></author><author><keyname>Han</keyname><forenames>Song</forenames></author><author><keyname>Potdar</keyname><forenames>Vidyasagar</forenames></author><author><keyname>Dillon</keyname><forenames>Tharam</forenames></author></authors><title>A Survey on Low-cost RFID Authentication Protocols</title><categories>cs.CR</categories><comments>Submitted to the International Journal of Computer Systems Science
  and Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a survey on several RFID authentication protocols under
low cost restrictions. Low cost RFID are mainly addressed with limited security
and privacy protections. In this study, we explore several protocols with
various authentication mechanisms found in literature that satisfy low cost
restrictions. Assessments of these protocols are based on data protection,
tracking protection, forward security. Finally, it is concluded that no single
low cost RFID protocol fully meets the requirement of the given assessments.
While a protocol satisfies one or two assessments, it fails to fully meet the
requirement of the third assessment. This study provides a new insight in RFID
literature which can be used particularly by small and medium industries to
choose the appropriate RFID protocol for their needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3640</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3640</id><created>2010-09-19</created><authors><author><keyname>Klartag</keyname><forenames>Bo'az</forenames></author><author><keyname>Regev</keyname><forenames>Oded</forenames></author></authors><title>Quantum One-Way Communication is Exponentially Stronger Than Classical
  Communication</title><categories>cs.CC math.MG quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In STOC 1999, Raz presented a (partial) function for which there is a quantum
protocol communicating only $O(\log n)$ qubits, but for which any classical
(randomized, bounded-error) protocol requires $\poly(n)$ bits of communication.
That quantum protocol requires two rounds of communication. Ever since Raz's
paper it was open whether the same exponential separation can be achieved with
a quantum protocol that uses only one round of communication. Here we settle
this question in the affirmative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3642</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3642</id><created>2010-09-19</created><authors><author><keyname>Shakir</keyname><forenames>M. Zeeshan</forenames></author><author><keyname>Durrani</keyname><forenames>Tariq S.</forenames></author></authors><title>MIMO Identical Eigenmode Transmission System (IETS) - A Channel
  Decomposition Perspective</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years considerable attention has been given to the design of
Multiple-Input Multiple-Output (MIMO) Eigenmode Transmission Systems (EMTS).
This paper presents an in-depth analysis of a new MIMO eigenmode transmission
strategy. The non-linear decomposition technique called Geometric Mean
Decomposition (GMD) is employed for the formation of eigenmodes over MIMO
flatfading channel. Exploiting GMD technique, identical, parallel and
independent transmission pipes are created for data transmission at higher
rate. The system based on such decomposition technique is referred to as MIMO
Identical Eigenmode Transmission System (IETS). The comparative analysis of the
MIMO transceiver design exploiting nonlinear and linear decomposition
techniques for variable constellation is presented in this paper. The new
transmission strategy is tested in combination with the Vertical Bell Labs
Layered Space Time (V-BLAST) decoding scheme using different number of antennas
on both sides of the communication link. The analysis is supported by various
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3645</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3645</id><created>2010-09-19</created><authors><author><keyname>Scollo</keyname><forenames>Giuseppe</forenames><affiliation>University of Catania, Department of Mathematics and Computer Science</affiliation></author></authors><title>An integration of Euler's pentagonal partition</title><categories>math.CO cs.DM math.NT</categories><comments>22 pages, 2 figures. The recurrence investigated in this paper is
  essentially that proposed in Exercise 5.2.3 of Igor Pak's &quot;Partition
  bijections, a survey&quot;, Ramanujan J. 12 (2006), but casted in a different form
  and, perhaps more interestingly, endowed with a bijective proof which arises
  from a construction by induction on maximal parts</comments><msc-class>05A17 (Primary) 11P81, 11P82, 11P83 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recurrent formula is presented, for the enumeration of the compositions of
positive integers as sums over multisets of positive integers, that closely
resembles Euler's recurrence based on the pentagonal numbers, but where the
coefficients result from a discrete integration of Euler's coefficients. Both a
bijective proof and one based on generating functions show the equivalence of
the subject recurrences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3657</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3657</id><created>2010-09-19</created><authors><author><keyname>Bachoc</keyname><forenames>Christine</forenames></author><author><keyname>Chandar</keyname><forenames>Venkat</forenames></author><author><keyname>Cohen</keyname><forenames>Gerard</forenames></author><author><keyname>Sole</keyname><forenames>Patrick</forenames></author><author><keyname>Tchamkerten</keyname><forenames>Aslan</forenames></author></authors><title>On Bounded Weight Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximum size of a binary code is studied as a function of its length N,
minimum distance D, and minimum codeword weight W. This function B(N,D,W) is
first characterized in terms of its exponential growth rate in the limit as N
tends to infinity for fixed d=D/N and w=W/N. The exponential growth rate of
B(N,D,W) is shown to be equal to the exponential growth rate of A(N,D) for w &lt;=
1/2, and equal to the exponential growth rate of A(N,D,W) for 1/2&lt; w &lt;= 1.
Second, analytic and numerical upper bounds on B(N,D,W) are derived using the
semidefinite programming (SDP) method. These bounds yield a non-asymptotic
improvement of the second Johnson bound and are tight for certain values of the
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3663</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3663</id><created>2010-09-19</created><updated>2011-06-28</updated><authors><author><keyname>Casazza</keyname><forenames>Peter G.</forenames></author><author><keyname>Heinecke</keyname><forenames>Andreas</forenames></author><author><keyname>Krahmer</keyname><forenames>Felix</forenames></author><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author></authors><title>Optimally Sparse Frames</title><categories>math.NA cs.IT math.FA math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frames have established themselves as a means to derive redundant, yet stable
decompositions of a signal for analysis or transmission, while also promoting
sparse expansions. However, when the signal dimension is large, the computation
of the frame measurements of a signal typically requires a large number of
additions and multiplications, and this makes a frame decomposition intractable
in applications with limited computing budget. To address this problem, in this
paper, we focus on frames in finite-dimensional Hilbert spaces and introduce
sparsity for such frames as a new paradigm. In our terminology, a sparse frame
is a frame whose elements have a sparse representation in an orthonormal basis,
thereby enabling low-complexity frame decompositions. To introduce a precise
meaning of optimality, we take the sum of the numbers of vectors needed of this
orthonormal basis when expanding each frame vector as sparsity measure. We then
analyze the recently introduced algorithm Spectral Tetris for construction of
unit norm tight frames and prove that the tight frames generated by this
algorithm are in fact optimally sparse with respect to the standard unit vector
basis. Finally, we show that even the generalization of Spectral Tetris for the
construction of unit norm frames associated with a given frame operator
produces optimally sparse frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3665</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3665</id><created>2010-09-19</created><authors><author><keyname>Malik</keyname><forenames>Tanu</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Little</keyname><forenames>Philip</forenames></author><author><keyname>Chaudhary</keyname><forenames>Amitabh</forenames></author><author><keyname>Thakar</keyname><forenames>Ani</forenames></author></authors><title>A Dynamic Data Middleware Cache for Rapidly-growing Scientific
  Repositories</title><categories>cs.DC cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern scientific repositories are growing rapidly in size. Scientists are
increasingly interested in viewing the latest data as part of query results.
Current scientific middleware cache systems, however, assume repositories are
static. Thus, they cannot answer scientific queries with the latest data. The
queries, instead, are routed to the repository until data at the cache is
refreshed. In data-intensive scientific disciplines, such as astronomy,
indiscriminate query routing or data refreshing often results in runaway
network costs. This severely affects the performance and scalability of the
repositories and makes poor use of the cache system. We present Delta, a
dynamic data middleware cache system for rapidly-growing scientific
repositories. Delta's key component is a decision framework that adaptively
decouples data objects---choosing to keep some data object at the cache, when
they are heavily queried, and keeping some data objects at the repository, when
they are heavily updated. Our algorithm profiles incoming workload to search
for optimal data decoupling that reduces network costs. It leverages formal
concepts from the network flow problem, and is robust to evolving scientific
workloads. We evaluate the efficacy of Delta, through a prototype
implementation, by running query traces collected from a real astronomy survey.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3681</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3681</id><created>2010-09-19</created><authors><author><keyname>Grunthal</keyname><forenames>Aaron</forenames></author></authors><title>Efficient Indexing of the BitTorrent Distributed Hash Table</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following paper presents various methods and implementation techniques
used to harvest metadata efficiently from a Kademlia Distributed Hashtable
(DHT) as used in the BitTorrent P2P network to build an index of publicly
available files in the BitTorrent ecosystem. The indexer design makes various
tradeoffs between throughput and fairness towards other DHT nodes while also
being scaleable in a distributed environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3682</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3682</id><created>2010-09-19</created><updated>2011-10-14</updated><authors><author><keyname>Garner</keyname><forenames>Richard</forenames></author></authors><title>An abstract view on syntax with sharing</title><categories>cs.LO math.CT</categories><comments>26 pages; v2: final journal version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of term graph encodes a refinement of inductively generated syntax
in which regard is paid to the the sharing and discard of subterms. Inductively
generated syntax has an abstract expression in terms of initial algebras for
certain endofunctors on the category of sets, which permits one to go beyond
the set-based case, and speak of inductively generated syntax in other
settings. In this paper we give a similar abstract expression to the notion of
term graph. Aspects of the concrete theory are redeveloped in this setting, and
applications beyond the realm of sets discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3687</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3687</id><created>2010-09-19</created><updated>2010-12-09</updated><authors><author><keyname>Han</keyname><forenames>Xiaowen</forenames></author><author><keyname>Zhu</keyname><forenames>David</forenames></author><author><keyname>Zhou</keyname><forenames>Cuifeng</forenames></author></authors><title>3-SAT Polynomial Solution of Knowledge Recognition Algorithm</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a knowledge recognition algorithm (KRA) for solving the
3SAT problem in polynomial time. KRA learns member-class relations and
retrieves information through deductive and reductive iterative reasoning. It
applies the principle of Chinese COVA* (equivalent to a set of eight 3-variable
conjunctive clauses) and eliminates the &quot;OR&quot; operation to solve 3-SAT problem.
That is, KRA does not search the assignment directly. It recognizes the
complements as rejections at each level of the set through iterative set
relation recognition. KRA recognizes which conjunctive 3-variable-clause is not
satisfiable. If all the eight clauses of any set of 3-variable clauses are
rejected, then there is not an assignment for the formula. If there is at least
one clause in each set that remains, then there is at least one assignment that
is the union of clauses of each set. If there is more than one clause in each
set that remains, then there are multiple assignments that are the unions of
the clauses of each set respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3702</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3702</id><created>2010-09-20</created><authors><author><keyname>Hao</keyname><forenames>Zhihui</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Barnes</keyname><forenames>Nick</forenames></author><author><keyname>Wang</keyname><forenames>Bo</forenames></author></authors><title>Totally Corrective Multiclass Boosting with Binary Weak Learners</title><categories>cs.LG</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a new optimization framework for multiclass boosting
learning. In the literature, AdaBoost.MO and AdaBoost.ECC are the two
successful multiclass boosting algorithms, which can use binary weak learners.
We explicitly derive these two algorithms' Lagrange dual problems based on
their regularized loss functions. We show that the Lagrange dual formulations
enable us to design totally-corrective multiclass algorithms by using the
primal-dual optimization technique. Experiments on benchmark data sets suggest
that our multiclass boosting can achieve a comparable generalization capability
with state-of-the-art, but the convergence speed is much faster than stage-wise
gradient descent boosting. In other words, the new totally corrective
algorithms can maximize the margin more aggressively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3710</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3710</id><created>2010-09-20</created><authors><author><keyname>Simmonds</keyname><forenames>Jocelyn</forenames></author><author><keyname>Ben-David</keyname><forenames>Shoham</forenames></author><author><keyname>Chechik</keyname><forenames>Marsha</forenames></author></authors><title>Optimizing Computation of Recovery Plans for BPEL Applications</title><categories>cs.SE</categories><comments>In Proceedings TAV-WEB 2010, arXiv:1009.3306</comments><proxy>EPTCS</proxy><acm-class>D.2.2;D.2.5;H.3.5</acm-class><journal-ref>EPTCS 35, 2010, pp. 3-14</journal-ref><doi>10.4204/EPTCS.35.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web service applications are distributed processes that are composed of
dynamically bounded services. In our previous work [15], we have described a
framework for performing runtime monitoring of web service against behavioural
correctness properties (described using property patterns and converted into
finite state automata). These specify forbidden behavior (safety properties)
and desired behavior (bounded liveness properties). Finite execution traces of
web services described in BPEL are checked for conformance at runtime. When
violations are discovered, our framework automatically proposes and ranks
recovery plans which users can then select for execution. Such plans for safety
violations essentially involve &quot;going back&quot; - compensating the executed actions
until an alternative behaviour of the application is possible. For bounded
liveness violations, recovery plans include both &quot;going back&quot; and &quot;re-planning&quot;
- guiding the application towards a desired behaviour. Our experience, reported
in [16], identified a drawback in this approach: we compute too many plans due
to (a) overapproximating the number of program points where an alternative
behaviour is possible and (b) generating recovery plans for bounded liveness
properties which can potentially violate safety properties. In this paper, we
describe improvements to our framework that remedy these problems and describe
their effectiveness on a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3711</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3711</id><created>2010-09-20</created><authors><author><keyname>Wang</keyname><forenames>Yi-Hsun</forenames></author><author><keyname>Mao</keyname><forenames>Ching-Hao</forenames></author><author><keyname>Lee</keyname><forenames>Hahn-Ming</forenames></author></authors><title>Structural Learning of Attack Vectors for Generating Mutated XSS Attacks</title><categories>cs.SE cs.CR cs.LG</categories><comments>In Proceedings TAV-WEB 2010, arXiv:1009.3306</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 35, 2010, pp. 15-26</journal-ref><doi>10.4204/EPTCS.35.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web applications suffer from cross-site scripting (XSS) attacks that
resulting from incomplete or incorrect input sanitization. Learning the
structure of attack vectors could enrich the variety of manifestations in
generated XSS attacks. In this study, we focus on generating more threatening
XSS attacks for the state-of-the-art detection approaches that can find
potential XSS vulnerabilities in Web applications, and propose a mechanism for
structural learning of attack vectors with the aim of generating mutated XSS
attacks in a fully automatic way. Mutated XSS attack generation depends on the
analysis of attack vectors and the structural learning mechanism. For the
kernel of the learning mechanism, we use a Hidden Markov model (HMM) as the
structure of the attack vector model to capture the implicit manner of the
attack vector, and this manner is benefited from the syntax meanings that are
labeled by the proposed tokenizing mechanism. Bayes theorem is used to
determine the number of hidden states in the model for generalizing the
structure model. The paper has the contributions as following: (1)
automatically learn the structure of attack vectors from practical data
analysis to modeling a structure model of attack vectors, (2) mimic the manners
and the elements of attack vectors to extend the ability of testing tool for
identifying XSS vulnerabilities, (3) be helpful to verify the flaws of
blacklist sanitization procedures of Web applications. We evaluated the
proposed mechanism by Burp Intruder with a dataset collected from public XSS
archives. The results show that mutated XSS attack generation can identify
potential vulnerabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3712</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3712</id><created>2010-09-20</created><authors><author><keyname>Mui</keyname><forenames>Raymond</forenames></author><author><keyname>Frankl</keyname><forenames>Phyllis</forenames></author></authors><title>Preventing SQL Injection through Automatic Query Sanitization with
  ASSIST</title><categories>cs.SE cs.DB</categories><comments>In Proceedings TAV-WEB 2010, arXiv:1009.3306</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 35, 2010, pp. 27-38</journal-ref><doi>10.4204/EPTCS.35.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web applications are becoming an essential part of our everyday lives. Many
of our activities are dependent on the functionality and security of these
applications. As the scale of these applications grows, injection
vulnerabilities such as SQL injection are major security challenges for
developers today. This paper presents the technique of automatic query
sanitization to automatically remove SQL injection vulnerabilities in code. In
our technique, a combination of static analysis and program transformation are
used to automatically instrument web applications with sanitization code. We
have implemented this technique in a tool named ASSIST (Automatic and Static
SQL Injection Sanitization Tool) for protecting Java-based web applications.
Our experimental evaluation showed that our technique is effective against SQL
injection vulnerabilities and has a low overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3713</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3713</id><created>2010-09-20</created><authors><author><keyname>Fu</keyname><forenames>Xiang</forenames></author></authors><title>Relational Constraint Driven Test Case Synthesis for Web Applications</title><categories>cs.SE cs.DB</categories><comments>In Proceedings TAV-WEB 2010, arXiv:1009.3306</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 35, 2010, pp. 39-50</journal-ref><doi>10.4204/EPTCS.35.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a relational constraint driven technique that synthesizes
test cases automatically for web applications. Using a static analysis,
servlets can be modeled as relational transducers, which manipulate backend
databases. We present a synthesis algorithm that generates a sequence of HTTP
requests for simulating a user session. The algorithm relies on backward
symbolic image computation for reaching a certain database state, given a code
coverage objective. With a slight adaptation, the technique can be used for
discovering workflow attacks on web applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3714</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3714</id><created>2010-09-20</created><authors><author><keyname>Kersten</keyname><forenames>Benjamin</forenames></author><author><keyname>Goedicke</keyname><forenames>Michael</forenames></author></authors><title>Browser-based Analysis of Web Framework Applications</title><categories>cs.SE</categories><comments>In Proceedings TAV-WEB 2010, arXiv:1009.3306</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 35, 2010, pp. 51-62</journal-ref><doi>10.4204/EPTCS.35.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although web applications evolved to mature solutions providing sophisticated
user experience, they also became complex for the same reason. Complexity
primarily affects the server-side generation of dynamic pages as they are
aggregated from multiple sources and as there are lots of possible processing
paths depending on parameters. Browser-based tests are an adequate instrument
to detect errors within generated web pages considering the server-side process
and path complexity a black box. However, these tests do not detect the cause
of an error which has to be located manually instead. This paper proposes to
generate metadata on the paths and parts involved during server-side processing
to facilitate backtracking origins of detected errors at development time.
While there are several possible points of interest to observe for
backtracking, this paper focuses user interface components of web frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3715</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3715</id><created>2010-09-20</created><authors><author><keyname>Rubinger</keyname><forenames>Ben</forenames></author><author><keyname>Bultan</keyname><forenames>Tevfik</forenames></author></authors><title>Contracting the Facebook API</title><categories>cs.SE</categories><comments>In Proceedings TAV-WEB 2010, arXiv:1009.3306</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 35, 2010, pp. 63-74</journal-ref><doi>10.4204/EPTCS.35.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been an explosive growth in the popularity of
online social networks such as Facebook. In a new twist, third party developers
are now able to create their own web applications which plug into Facebook and
work with Facebook's &quot;social&quot; data, enabling the entire Facebook user base of
more than 400 million active users to use such applications. These client
applications can contain subtle errors that can be hard to debug if they misuse
the Facebook API. In this paper we present an experience report on applying
Microsoft's new code contract system for the .NET framework to the Facebook
API.We wrote contracts for several classes in the Facebook API wrapper which
allows Microsoft .NET developers to implement Facebook applications. We
evaluated the usefulness of these contracts during implementation of a new
Facebook application. Our experience indicates that having code contracts
provides a better and quicker software development experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3716</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3716</id><created>2010-09-20</created><authors><author><keyname>Sala&#xfc;n</keyname><forenames>Gwen</forenames></author></authors><title>Analysis and Verification of Service Interaction Protocols - A Brief
  Survey</title><categories>cs.SE cs.LO</categories><comments>In Proceedings TAV-WEB 2010, arXiv:1009.3306</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 35, 2010, pp. 75-86</journal-ref><doi>10.4204/EPTCS.35.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling and analysis of interactions among services is a crucial issue in
Service-Oriented Computing. Composing Web services is a complicated task which
requires techniques and tools to verify that the new system will behave
correctly. In this paper, we first overview some formal models proposed in the
literature to describe services. Second, we give a brief survey of verification
techniques that can be used to analyse services and their interaction. Last, we
focus on the realizability and conformance of choreographies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3728</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3728</id><created>2010-09-20</created><updated>2013-07-06</updated><authors><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Network-Error Correcting Codes using Small Fields</title><categories>cs.IT math.IT</categories><comments>Minor changes from previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing construction algorithms of block network-error correcting codes
require a rather large field size, which grows with the size of the network and
the number of sinks, and thereby can be prohibitive in large networks. In this
work, we give an algorithm which, starting from a given network-error
correcting code, can obtain another network code using a small field, with the
same error correcting capability as the original code. An algorithm for
designing network codes using small field sizes proposed recently by Ebrahimi
and Fragouli can be seen as a special case of our algorithm. The major step in
our algorithm is to find a least degree irreducible polynomial which is coprime
to another large degree polynomial. We utilize the algebraic properties of
finite fields to implement this step so that it becomes much faster than the
brute-force method. As a result the algorithm given by Ebrahimi and Fragouli is
also quickened.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3751</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3751</id><created>2010-09-20</created><updated>2010-12-31</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>Matching Dyadic Distributions to Channels</title><categories>cs.IT math.IT math.PR</categories><comments>to be presented at DCC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many communication channels with discrete input have non-uniform capacity
achieving probability mass functions (PMF). By parsing a stream of independent
and equiprobable bits according to a full prefix-free code, a modu-lator can
generate dyadic PMFs at the channel input. In this work, we show that for
discrete memoryless channels and for memoryless discrete noiseless channels,
searching for good dyadic input PMFs is equivalent to minimizing the
Kullback-Leibler distance between a dyadic PMF and a weighted version of the
capacity achieving PMF. We define a new algorithm called Geometric Huffman
Coding (GHC) and prove that GHC finds the optimal dyadic PMF in O(m \log m)
steps where m is the number of input symbols of the considered channel.
Furthermore, we prove that by generating dyadic PMFs of blocks of consecutive
input symbols, GHC achieves capacity when the block length goes to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3763</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3763</id><created>2010-09-20</created><authors><author><keyname>Bethke</keyname><forenames>Siegfried</forenames></author></authors><title>Data Preservation in High Energy Physics - why, how and when?</title><categories>hep-ex cs.DL physics.data-an</categories><comments>5 pages, 3 figures; presentation given at the QCD10, Montpellier,
  France, June 2010</comments><journal-ref>Nucl.Phys.Proc.Suppl.207-208:156-159,2010</journal-ref><doi>10.1016/j.nuclphysbps.2010.10.040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Long-term preservation of data and software of large experiments and
detectors in high energy physics is of utmost importance to secure the heritage
of (mostly unique) data and to allow advanced physics (re-)analyses at later
times. Summarising the work of an international study group, motivation, use
cases and technical details are given for an organised effort to secure and
enable future use of past, present and future experimental data. As a practical
use case and motivation, the revival of JADE data and the corresponding latest
results on measuring $\alpha_s$ in NNLO QCD are reviewed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3765</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3765</id><created>2010-09-20</created><authors><author><keyname>Biener</keyname><forenames>Peter</forenames></author><author><keyname>Degrave</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Vanhoof</keyname><forenames>Wim</forenames></author></authors><title>A Test Automation Framework for Mercury</title><categories>cs.LO</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><journal-ref>Proceedings of CICLOPS-WLPE 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a test automation framework for Mercury programs. We
developed a method that generates runnable Mercury code from a formalized test
suite, and which code provides a report on execution about the success of test
cases. We also developed a coverage tool for the framework, which identifies
and provide a visualization of the reached parts of the program when executing
a given test suite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3770</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3770</id><created>2010-09-20</created><authors><author><keyname>Hofstedt</keyname><forenames>Petra</forenames></author></authors><title>Realizing evaluation strategies by hierarchical graph rewriting</title><categories>cs.LO cs.PL</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the realization of evaluation strategies for the concurrent
constraint-based functional language CCFL within the translation schemata when
compiling CCFL programs into the hierarchical graph rewriting language LMNtal.
  The support of LMNtal to express local computations and to describe the
migration of processes and rules between local computation spaces allows a
clear and simple encoding of typical evaluation strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3771</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3771</id><created>2010-09-20</created><authors><author><keyname>Angelopoulos</keyname><forenames>Nicos</forenames></author><author><keyname>Taylor</keyname><forenames>Paul</forenames></author></authors><title>An extensible web interface for databases and its application to storing
  biochemical data</title><categories>cs.PL cs.CE</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a generic web-based database interface implemented in
Prolog. We discuss the advantages of the implementation platform and
demonstrate the system's applicability in providing access to integrated
biochemical data. Our system exploits two libraries of SWI-Prolog to create a
schema-transparent interface within a relational setting. As is expected in
declarative programming, the interface was written with minimal programming
effort due to the high level of the language and its suitability to the task.
We highlight two of Prolog's features that are well suited to the task at hand:
term representation of structured documents and relational nature of Prolog
which facilitates transparent integration of relational databases. Although we
developed the system for accessing in-house biochemical and genomic data the
interface is generic and provides a number of extensible features. We describe
some of these features with references to our research databases. Finally we
outline an in-house library that facilitates interaction between Prolog and the
R statistical package. We describe how it has been employed in the present
context to store output from statistical analysis on to the database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3773</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3773</id><created>2010-09-20</created><authors><author><keyname>Moura</keyname><forenames>Paulo</forenames></author></authors><title>Towards a Study of Meta-Predicate Semantics</title><categories>cs.PL</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe and compare design choices for meta-predicate semantics, as found
in representative Prolog module systems and in Logtalk. We look at the
consequences of these design choices from a pragmatic perspective, discussing
explicit qualification semantics, computational reflection support,
expressiveness of meta-predicate declarations, safety of meta-predicate
definitions, portability of meta-predicate definitions, and meta-predicate
performance. Our aim is to provide useful insight for debating meta-predicate
semantics and portability issues based on actual implementations and common
usage patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3779</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3779</id><created>2010-09-20</created><authors><author><keyname>Chowdhury</keyname><forenames>Mostafa Zaman</forenames></author><author><keyname>Jang</keyname><forenames>Yeong Min</forenames></author></authors><title>Handover Control for WCDMA Femtocell Networks</title><categories>cs.NI cs.MM</categories><comments>Published in &quot;The Journal of Korea Information and Communication
  Society&quot; for the volume of May 2010</comments><journal-ref>The Journal of Korea Information and Communication Society, May
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to seamlessly switch between the macro networks and femtocell
networks is a key driver for femtocell network deployment. The handover
procedures for the integrated femtocell/macrocell networks differ from the
existing handovers. Some modifications of existing network and protocol
architecture for the integration of femtocell networks with the existing
macrocell networks are also essential. These modifications change the signal
flow for handover procedures due to different 2-tier cell (macrocell and
femtocell) environment. The handover between two networks should be performed
with minimum signaling. A frequent and unnecessary handover is another problem
for hierarchical femtocell/macrocell network environment that must be
minimized. This work studies the details mobility management schemes for small
and medium scale femtocell network deployment. To do that, firstly we present
two different network architectures for small scale and medium scale WCDMA
femtocell deployment. The details handover call flow for these two network
architectures and CAC scheme to minimize the unnecessary handovers are proposed
for the integrated femtocell/macrocell networks. The numerical analysis for the
proposed M/M/N/N queuing scheme and the simulation results of the proposed CAC
scheme demonstrate the handover call control performances for femtocell
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3785</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3785</id><created>2010-09-20</created><authors><author><keyname>ParandehGheibi</keyname><forenames>A.</forenames></author><author><keyname>Akhaee</keyname><forenames>M. A.</forenames></author><author><keyname>Ayremlou</keyname><forenames>A.</forenames></author><author><keyname>Rahimian</keyname><forenames>M. A.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author></authors><title>Improved Iterative Techniques to Compensate for Interpolation
  Distortions</title><categories>cs.MM</categories><comments>Submitted on Signal Processing, Elsevier</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel hybrid approach for compensating the distortion of any
interpolation has been proposed. In this hybrid method, a modular approach was
incorporated in an iterative fashion. By using this approach we can get drastic
improvement with less computational complexity. The extension of the proposed
approach to two dimensions was also studied. Both the simulation results and
mathematical analyses confirmed the superiority of the hybrid method. The
proposed method was also shown to be robust against additive noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3796</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3796</id><created>2010-09-20</created><authors><author><keyname>Wielemaker</keyname><forenames>Jan</forenames></author><author><keyname>Costa</keyname><forenames>V&#xed;tor Santos</forenames></author></authors><title>Portability of Prolog programs: theory and case-studies</title><categories>cs.PL</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (Non-)portability of Prolog programs is widely considered as an important
factor in the lack of acceptance of the language. Since 1995, the core of the
language is covered by the ISO standard 13211-1. Since 2007, YAP and SWI-Prolog
have established a basic compatibility framework. This article describes and
evaluates this framework. The aim of the framework is running the same code on
both systems rather than migrating an application. We show that today, the
portability within the family of Edinburgh/Quintus derived Prolog
implementations is good enough to allow for maintaining portable real-world
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3797</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3797</id><created>2010-09-20</created><authors><author><keyname>Rahimian</keyname><forenames>M. Amin</forenames></author><author><keyname>Ayremlou</keyname><forenames>Ali</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>A General Analog Network Coding for Wireless Systems with Fading and
  Noisy Channels</title><categories>cs.NI</categories><comments>Submitted on ICC2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been recently brought into spotlight that through the exploitation of
network coding concepts at physical-layer, the interference property of the
wireless media can be proven to be a blessing in disguise. Nonetheless, most of
the previous studies on this subject have either held unrealistic assumptions
about the network properties, thus making them basically theoretical, or have
otherwise been limited to fairly simple network topologies. We, on the other
hand, believe to have devised a novel scheme, called Real Amplitude Scaling
(RAS), that relaxes the aforementioned restrictions, and works with a wider
range of network topologies and in circumstances that are closer to practice,
for instance in lack of symbol-level synchronization and in the presence of
noise, channel distortion and severe interference from other sources. The
simulation results confirmed the superior performance of the proposed method in
low SNRs, as well as the high SNR limits, where the effect of quantization
error in the digital techniques becomes comparable to the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3798</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3798</id><created>2010-09-20</created><updated>2010-09-21</updated><authors><author><keyname>Shterionov</keyname><forenames>Dimitar Sht.</forenames></author><author><keyname>Kimmig</keyname><forenames>Angelika</forenames></author><author><keyname>Mantadelis</keyname><forenames>Theofrastos</forenames></author><author><keyname>Janssens</keyname><forenames>Gerda</forenames></author></authors><title>DNF Sampling for ProbLog Inference</title><categories>cs.LO</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><journal-ref>Proceedings of CICLOPS-WLPE 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference in probabilistic logic languages such as ProbLog, an extension of
Prolog with probabilistic facts, is often based on a reduction to a
propositional formula in DNF. Calculating the probability of such a formula
involves the disjoint-sum-problem, which is computationally hard. In this work
we introduce a new approximation method for ProbLog inference which exploits
the DNF to focus sampling. While this DNF sampling technique has been applied
to a variety of tasks before, to the best of our knowledge it has not been used
for inference in probabilistic logic systems. The paper also presents an
experimental comparison with another sampling based inference method previously
introduced for ProbLog.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3800</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3800</id><created>2010-09-20</created><authors><author><keyname>Pedro</keyname><forenames>Vasco</forenames></author><author><keyname>Abreu</keyname><forenames>Salvador</forenames></author></authors><title>Distributed Work Stealing for Constraint Solving</title><categories>cs.PL</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the dissemination of affordable parallel and distributed hardware,
parallel and distributed constraint solving has lately been the focus of some
attention. To effectually apply the power of distributed computational systems,
there must be an effective sharing of the work involved in the search for a
solution to a Constraint Satisfaction Problem (CSP) between all the
participating agents, and it must happen dynamically, since it is hard to
predict the effort associated with the exploration of some part of the search
space. We describe and provide an initial experimental assessment of an
implementation of a work stealing-based approach to distributed CSP solving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3802</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3802</id><created>2010-09-20</created><updated>2010-10-08</updated><authors><author><keyname>Ni</keyname><forenames>Yuzhao</forenames></author><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaotong</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author><author><keyname>Cheong</keyname><forenames>Loong-Fah</forenames></author></authors><title>Robust Low-Rank Subspace Segmentation with Semidefinite Guarantees</title><categories>cs.CV cs.IT cs.LG math.IT</categories><comments>10 pages, 4 figures. Accepted by ICDM Workshop on Optimization Based
  Methods for Emerging Data Mining Problems (OEDM), 2010. Main proof simplified
  and typos corrected. Experimental data slightly added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there is a line of research work proposing to employ Spectral
Clustering (SC) to segment (group){Throughout the paper, we use segmentation,
clustering, and grouping, and their verb forms, interchangeably.}
high-dimensional structural data such as those (approximately) lying on
subspaces {We follow {liu2010robust} and use the term &quot;subspace&quot; to denote both
linear subspaces and affine subspaces. There is a trivial conversion between
linear subspaces and affine subspaces as mentioned therein.} or low-dimensional
manifolds. By learning the affinity matrix in the form of sparse
reconstruction, techniques proposed in this vein often considerably boost the
performance in subspace settings where traditional SC can fail. Despite the
success, there are fundamental problems that have been left unsolved: the
spectrum property of the learned affinity matrix cannot be gauged in advance,
and there is often one ugly symmetrization step that post-processes the
affinity for SC input. Hence we advocate to enforce the symmetric positive
semidefinite constraint explicitly during learning (Low-Rank Representation
with Positive SemiDefinite constraint, or LRR-PSD), and show that factually it
can be solved in an exquisite scheme efficiently instead of general-purpose SDP
solvers that usually scale up poorly. We provide rigorous mathematical
derivations to show that, in its canonical form, LRR-PSD is equivalent to the
recently proposed Low-Rank Representation (LRR) scheme {liu2010robust}, and
hence offer theoretic and practical insights to both LRR-PSD and LRR, inviting
future research. As per the computational cost, our proposal is at most
comparable to that of LRR, if not less. We validate our theoretic analysis and
optimization scheme by experiments on both synthetic and real data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3806</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3806</id><created>2010-09-20</created><authors><author><keyname>Andr&#xe9;</keyname><forenames>Paulo</forenames></author><author><keyname>Abreu</keyname><forenames>Salvador</forenames></author></authors><title>Casting of the WAM as an EAM</title><categories>cs.PL</categories><comments>Online proceedings of the Joint Workshop on Implementation of
  Constraint Logic Programming Systems and Logic-based Methods in Programming
  Environments (CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programming provides a very high-level view of programming, which comes
at the cost of some execution efficiency. Improving performance of logic
programs is thus one of the holy grails of Prolog system implementations and a
wide range of approaches have historically been taken towards this goal.
Designing computational models that both exploit the available parallelism in a
given application and that try hard to reduce the explored search space has
been an ongoing line of research for many years. These goals in particular have
motivated the design of several computational models, one of which is the
Extended Andorra Model (EAM). In this paper, we present a preliminary
specification and implementation of the EAM with Implicit Control, the WAM2EAM,
which supplies regular WAM instructions with an EAM-centered interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3809</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3809</id><created>2010-09-20</created><updated>2010-11-02</updated><authors><author><keyname>Bagadi</keyname><forenames>Ramesh C.</forenames></author></authors><title>One, Two, Three and N Dimensional String Search Algorithms</title><categories>cs.DS</categories><comments>withdrawn by arXiv admin due to authorship dispute</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research endeavor, some Sequence Alignment Algorithms are detailed
that are useful for finding or comparing 1 dimensional (1-D), 2 dimensional
(2-D), 3 dimensional (3-D) sequences in or against a parent or mother database
which is 1 dimensional (1-D), 2 dimensional (2-D), 3 dimensional (3-D)
sequence. Inner Product [1], [2] based schemes are used to lay down such
algorithms. Also,in this research, a Sequence Alignment Algorithms is detailed
that is useful for finding or comparing an N-Dimensional (N-D) sequence in or
against a parent or mother database which N-Dimensional (N-D) sequence. Inner
Product [1], [2] based schemes are used to lay down such an algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3819</identifier>
 <datestamp>2012-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3819</id><created>2010-09-20</created><authors><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Rahman</keyname><forenames>Muhammad Mahbubur</forenames></author><author><keyname>Begum</keyname><forenames>Zerina</forenames></author><author><keyname>Hafiz</keyname><forenames>Mohd. Zulfiquar</forenames></author></authors><title>Fault Tolerant Variable Block Carry Skip Logic (VBCSL) using Parity
  Preserving Reversible Gates</title><categories>cs.AR</categories><comments>9 pages, 16 figures, 2 tables, Accepted for publication in IJCEE,
  IACSIT, Singapore</comments><journal-ref>International Journal of Computer and Electrical Engineering vol.
  3, no. 1, pp. 1-7, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic design has become one of the promising research directions
in low power dissipating circuit design in the past few years and has found its
application in low power CMOS design, digital signal processing and
nanotechnology. This paper presents the efficient design approaches of fault
tolerant carry skip adders (FTCSAs) and compares those designs with the
existing ones. Variable block carry skip logic (VBCSL) using the fault tolerant
full adders (FTFAs) has also been developed. The designs are minimized in terms
of hardware complexity, gate count, constant inputs and garbage outputs.
Besides of it, technology independent evaluation of the proposed designs
clearly demonstrates its superiority with the existing counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3822</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3822</id><created>2010-09-20</created><authors><author><keyname>Giro</keyname><forenames>Sergio</forenames></author></authors><title>An algorithmic approximation of the infimum reachability probability for
  Probabilistic Finite Automata</title><categories>cs.LO cs.FL</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a Probabilistic Finite Automata (PFA), a set of states S, and an error
threshold e &gt; 0, our algorithm approximates the infimum probability
(quantifying over all infinite words) that the automata reaches S. Our result
contrasts with the known result that the approximation problem is undecidable
if we consider the supremum instead of the infimum. Since we study the
probability of reaching a set of states, instead of the probability of ending
in an accepting state, our work is more related to model checking than to
formal languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3824</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3824</id><created>2010-09-20</created><updated>2012-02-07</updated><authors><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author><author><keyname>Linder</keyname><forenames>Tam&#xe1;s</forenames></author></authors><title>Optimization and Convergence of Observation Channels in Stochastic
  Control</title><categories>math.OC cs.IT math.IT</categories><comments>24 pages, to appear in the SIAM Journal on Control and Optimization</comments><msc-class>15A15, 15A09, 15A23</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the optimization of observation channels (stochastic
kernels) in partially observed stochastic control problems. In particular,
existence and continuity properties are investigated mostly (but not
exclusively) concentrating on the single-stage case. Continuity properties of
the optimal cost in channels are explored under total variation, setwise
convergence, and weak convergence. Sufficient conditions for compactness of a
class of channels under total variation and setwise convergence are presented
and applications to quantization are explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3863</identifier>
 <datestamp>2011-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3863</id><created>2010-09-20</created><updated>2010-11-02</updated><authors><author><keyname>Garcia</keyname><forenames>Virgile</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Lebedev</keyname><forenames>Nikolai</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Outage Probability for Multi-Cell Processing under Rayleigh Fading</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>IEEE Communications Letters 15, 8 (2011) 801 - 803</journal-ref><doi>10.1109/LCOMM.2011.061011.102120</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-cell processing, also called Coordinated Multiple Point (CoMP), is a
very promising distributed multi-antennas technique that uses neighbour cell's
antennas. This is expected to be part of next generation cellular networks
standards such as LTE-A. Small cell networks in dense urban environment are
mainly limited by interferences and CoMP can strongly take advantage of this
fact to improve cell-edge users' throughput. This paper provides an analytical
derivation of the capacity outage probability for CoMP experiencing fast
Rayleigh fading. Only the average received power (slow varying fading) has to
be known, and perfect Channel State Information (CSI) is not required. An
optimisation of the successfully received data-rate is then derived with
respect to the number of cooperating stations and the outage probability,
illustrated by numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3877</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3877</id><created>2010-09-20</created><authors><author><keyname>Przedzinski</keyname><forenames>Tomasz</forenames></author></authors><title>Software for physics of tau lepton decay in LHC experiments</title><categories>hep-ph cs.SE</categories><comments>Thesis submitted to Applied Computer Science Department in partial
  fulfillment of the requirements for the MSc degree. This work is partially
  supported by EU Marie Curie Research Training Network grant under the
  contract No. MRTN-CT-2006-0355505, Polish Government grant N202 06434
  (2008-2011) and EU-RTN Programme: Contract No. MRTN-CT-2006-035482
  'Flavianet'</comments><report-no>TPJU - 2/2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software development in high energy physics experiments offers unique
experience with rapidly changing environment and variety of different standards
and frameworks that software must be adapted to. As such, regular methods of
software development are hard to use as they do not take into account how
greatly some of these changes influence the whole structure. The following
thesis summarizes development of TAUOLA C++ Interface introducing tau decays to
new event record standard. Documentation of the program is already published.
That is why it is not recalled here again. We focus on the development cycle
and methodology used in the project, starting from the definition of the
expectations through planning and designing the abstract model and concluding
with the implementation. In the last part of the paper we present installation
of the software within different experiments surrounding Large Hadron Collider
and the problems that emerged during this process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3888</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3888</id><created>2010-09-20</created><updated>2011-02-09</updated><authors><author><keyname>Chen</keyname><forenames>Chang-Ching</forenames></author><author><keyname>Tseng</keyname><forenames>Chia-Shiang</forenames></author><author><keyname>Lin</keyname><forenames>Che</forenames></author></authors><title>A General Proof of Convergence for Adaptive Distributed Beamforming
  Schemes</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work focuses on the convergence analysis of adaptive distributed
beamforming schemes that can be reformulated as local random search algorithms
via a random search framework. Once reformulated as local random search
algorithms, it is proved that under two sufficient conditions: a) the objective
function of the algorithm is continuous and all its local maxima are global
maxima, and b) the origin is an interior point within the range of the
considered transformation of the random perturbation, the corresponding
adaptive distributed beamforming schemes converge both in probability and in
mean. This proof of convergence is general since it can be applied to analyze
randomized adaptive distributed beamforming schemes with any type of objective
functions and probability measures as long as both the sufficient conditions
are satisfied. Further, this framework can be generalized to analyze an
asynchronous scheme where distributed transmitters can only update their
beamforming coefficients asynchronously. Simulation results are also provided
to validate our analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3891</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3891</id><created>2010-09-20</created><authors><author><keyname>Villard</keyname><forenames>Joffrey</forenames></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author></authors><title>Secure Lossy Source Coding with Side Information at the Decoders</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures, 1 table, to be presented at Allerton 2010</comments><doi>10.1109/ALLERTON.2010.5706980</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of secure lossy source coding in the
presence of an eavesdropper with arbitrary correlated side informations at the
legitimate decoder (referred to as Bob) and the eavesdropper (referred to as
Eve). This scenario consists of an encoder that wishes to compress a source to
satisfy the desired requirements on: (i) the distortion level at Bob and (ii)
the equivocation rate at Eve. It is assumed that the decoders have access to
correlated sources as side information. For instance, this problem can be seen
as a generalization of the well-known Wyner-Ziv problem taking into account the
security requirements. A complete characterization of the
rate-distortion-equivocation region for the case of arbitrary correlated side
informations at the decoders is derived. Several special cases of interest and
an application example to secure lossy source coding of binary sources in the
presence of binary and ternary side informations are also considered. It is
shown that the statistical differences between the side information at the
decoders and the presence of non-zero distortion at the legitimate decoder can
be useful in terms of secrecy. Applications of these results arise in a variety
of distributed sensor network scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3896</identifier>
 <datestamp>2012-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3896</id><created>2010-09-20</created><updated>2012-11-26</updated><authors><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author><author><keyname>Sridharan</keyname><forenames>Karthik</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author></authors><title>Optimistic Rates for Learning with a Smooth Loss</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish an excess risk bound of O(H R_n^2 + R_n \sqrt{H L*}) for
empirical risk minimization with an H-smooth loss function and a hypothesis
class with Rademacher complexity R_n, where L* is the best risk achievable by
the hypothesis class. For typical hypothesis classes where R_n = \sqrt{R/n},
this translates to a learning rate of O(RH/n) in the separable (L*=0) case and
O(RH/n + \sqrt{L^* RH/n}) more generally. We also provide similar guarantees
for online and stochastic convex optimization with a smooth non-negative
objective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3911</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3911</id><created>2010-09-20</created><authors><author><keyname>Mazzara</keyname><forenames>Manuel</forenames></author></authors><title>Deriving Specifications of Dependable Systems: toward a Method</title><categories>cs.SE</categories><comments>Published in &quot;12th European Workshop on Dependable Computing, EWDC
  2009, Toulouse : France (2009)&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for deriving formal specifications of systems.
To accomplish this task we pass through a non trivial number of steps, concepts
and tools where the first one, the most important, is the concept of method
itself, since we realized that computer science has a proliferation of
languages but very few methods. We also propose the idea of Layered Fault
Tolerant Specification (LFTS) to make the method extensible to dependable
systems. The principle is layering the specification, for the sake of clarity,
in (at least) two different levels, the first one for the normal behavior and
the others (if more than one) for the abnormal. The abnormal behavior is
described in terms of an Error Injector (EI) which represents a model of the
erroneous interference coming from the environment. This structure has been
inspired by the notion of idealized fault tolerant component but the
combination of LFTS and EI using rely guarantee thinking to describe
interference can be considered one of the main contributions of this work. The
progress toward this method and the way to layer specifications has been made
experimenting on the Transportation and the Automotive Case Studies of the
DEPLOY project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3916</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3916</id><created>2010-09-20</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Levin</keyname><forenames>Georgy</forenames></author></authors><title>Finite-SNR Diversity-Multiplexing Tradeoff via Asymptotic Analysis of
  Large MIMO Systems</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE IT Trans</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diversity-multiplexing tradeoff (DMT) was characterized asymptotically (SNR-&gt;
infinity) for i.i.d. Rayleigh fading channel by Zheng and Tse [1]. The
SNR-asymptotic DMT overestimates the finite-SNR one [2]. This paper outlines a
number of additional limitations and difficulties of the DMT framework and
discusses their implications. Using the recent results on the size-asymptotic
(in the number of antennas) outage capacity distribution, the finite-SNR,
size-asymptotic DMT is derived for a broad class of fading distributions. The
SNR range over which the finite-SNR DMT is accurately approximated by the
SNR-asymptotic one is characterized. The multiplexing gain definition is shown
to affect critically this range and thus should be carefully selected, so that
the SNR-asymptotic DMT is an accurate approximation at realistic SNR values and
thus has operational significance to be used as a design criteria. The finite
SNR diversity gain is shown to decrease with correlation and power imbalance in
a broad class of fading channels, and such an effect is described in a compact,
closed form. Complete characterization of the outage probability (or outage
capacity) requires not only the finite-SNR DMT, but also the SNR offset, which
is introduced and investigated as well. This offset, which is not accounted for
in the DMT framework, is shown to have a significant impact on the outage
probability for a broad class of fading channels, especially when the
multiplexing gain is small. The analytical results and conclusions are
validated via extensive Monte-Carlo simulations. Overall, the size-asymptotic
DMT represents a valuable alternative to the SNR-asymptotic one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3951</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3951</id><created>2010-09-20</created><authors><author><keyname>Zhu</keyname><forenames>Ji</forenames></author><author><keyname>Srivatsa</keyname><forenames>Mudhakar</forenames></author></authors><title>Quantifying Information Leakage in Finite Order Deterministic Programs</title><categories>cs.CR cs.IT math.IT</categories><comments>14 pages, 1 figure. A shorter version of this paper is submitted to
  ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information flow analysis is a powerful technique for reasoning about the
sensitive information exposed by a program during its execution. While past
work has proposed information theoretic metrics (e.g., Shannon entropy,
min-entropy, guessing entropy, etc.) to quantify such information leakage, we
argue that some of these measures not only result in counter-intuitive measures
of leakage, but also are inherently prone to conflicts when comparing two
programs P1 and P2 -- say Shannon entropy predicts higher leakage for program
P1, while guessing entropy predicts higher leakage for program P2. This paper
presents the first attempt towards addressing such conflicts and derives
solutions for conflict-free comparison of finite order deterministic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3955</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3955</id><created>2010-09-20</created><updated>2011-03-23</updated><authors><author><keyname>Bizhani</keyname><forenames>Golnoosh</forenames></author><author><keyname>Sood</keyname><forenames>Vishal</forenames></author><author><keyname>Paczuski</keyname><forenames>Maya</forenames></author><author><keyname>Grassberger</keyname><forenames>Peter</forenames></author></authors><title>Random Sequential Renormalization of Networks I: Application to Critical
  Trees</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><journal-ref>Phys. Rev. E 83, 036110 (2011)</journal-ref><doi>10.1103/PhysRevE.83.036110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of Random Sequential Renormalization (RSR) for
arbitrary networks. RSR is a graph renormalization procedure that locally
aggregates nodes to produce a coarse grained network. It is analogous to the
(quasi-)parallel renormalization schemes introduced by C. Song {\it et al.}
(Nature {\bf 433}, 392 (2005)) and studied more recently by F. Radicchi {\it et
al.} (Phys. Rev. Lett. {\bf 101}, 148701 (2008)), but much simpler and easier
to implement. In this first paper we apply RSR to critical trees and derive
analytical results consistent with numerical simulations. Critical trees
exhibit three regimes in their evolution under RSR: (i) An initial regime
$N_0^{\nu}\lesssim N&lt;N_0$, where $N$ is the number of nodes at some step in the
renormalization and $N_0$ is the initial size. RSR in this regime is described
by a mean field theory and fluctuations from one realization to another are
small. The exponent $\nu=1/2$ is derived using random walk arguments. The
degree distribution becomes broader under successive renormalization --
reaching a power law, $p_k\sim 1/k^{\gamma}$ with $\gamma=2$ and a variance
that diverges as $N_0^{1/2}$ at the end of this regime. Both of these results
are derived based on a scaling theory. (ii) An intermediate regime for
$N_0^{1/4}\lesssim N \lesssim N_0^{1/2}$, in which hubs develop, and
fluctuations between different realizations of the RSR are large. Crossover
functions exhibiting finite size scaling, in the critical region $N\sim
N_0^{1/2} \to \infty$, connect the behaviors in the first two regimes. (iii)
The last regime, for $1 \ll N\lesssim N_0^{1/4}$, is characterized by the
appearance of star configurations with a central hub surrounded by many leaves.
The distribution of sizes where stars first form is found numerically to be a
power law up to a cutoff that scales as $N_0^{\nu_{star}}$ with
$\nu_{star}\approx 1/4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3958</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3958</id><created>2010-09-20</created><authors><author><keyname>Rawlik</keyname><forenames>Konrad</forenames></author><author><keyname>Toussaint</keyname><forenames>Marc</forenames></author><author><keyname>Vijayakumar</keyname><forenames>Sethu</forenames></author></authors><title>Approximate Inference and Stochastic Optimal Control</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel reformulation of the stochastic optimal control problem as
an approximate inference problem, demonstrating, that such a interpretation
leads to new practical methods for the original problem. In particular we
characterise a novel class of iterative solutions to the stochastic optimal
control problem based on a natural relaxation of the exact dual formulation.
These theoretical insights are applied to the Reinforcement Learning problem
where they lead to new model free, off policy methods for discrete and
continuous problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3959</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3959</id><created>2010-09-20</created><updated>2011-12-06</updated><authors><author><keyname>Ouyang</keyname><forenames>Wenzhuo</forenames></author><author><keyname>Murugesan</keyname><forenames>Sugumar</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Exploiting Channel Memory for Joint Estimation and Scheduling in
  Downlink Networks</title><categories>cs.NI</categories><comments>A shorter version of this report appeared in INFOCOM 2011, Shanghai,
  China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of opportunistic multiuser scheduling in downlink
networks with Markov-modeled outage channels. We consider the scenario in which
the scheduler does not have full knowledge of the channel state information,
but instead estimates the channel state information by exploiting the memory
inherent in the Markov channels along with ARQ-styled feedback from the
scheduled users. Opportunistic scheduling is optimized in two stages: (1)
Channel estimation and rate adaptation to maximize the expected immediate rate
of the scheduled user; (2) User scheduling, based on the optimized immediate
rate, to maximize the overall long term sum-throughput of the downlink. The
scheduling problem is a partially observable Markov decision process with the
classic 'exploitation vs exploration' trade-off that is difficult to quantify.
We therefore study the problem in the framework of Restless Multi-armed Bandit
Processes (RMBP) and perform a Whittle's indexability analysis. Whittle's
indexability is traditionally known to be hard to establish and the index
policy derived based on Whittle's indexability is known to have optimality
properties in various settings. We show that the problem of downlink scheduling
under imperfect channel state information is Whittle indexable and derive the
Whittle's index policy in closed form. Via extensive numerical experiments, we
show that the index policy has near-optimal performance.
  Our work reveals that, under incomplete channel state information, exploiting
channel memory for opportunistic scheduling can result in significant
performance gains and that almost all of these gains can be realized using an
easy-to-implement index policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3961</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3961</id><created>2010-09-20</created><authors><author><keyname>Levorato</keyname><forenames>Marco</forenames></author><author><keyname>O'Neill</keyname><forenames>Daniel</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Optimization of ARQ Protocols in Interference Networks with QoS
  Constraints</title><categories>cs.SY cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study optimal transmission strategies in interfering wireless networks,
under Quality of Service constraints. A buffered, dynamic network with multiple
sources is considered, and sources use a retransmission strategy in order to
improve packet delivery probability. The optimization problem is formulated as
a Markov Decision Process, where constraints and objective functions are ratios
of time-averaged cost functions. The optimal strategy is found as the solution
of a Linear Fractional Program, where the optimization variables are the
steady-state probability of state-action pairs. Numerical results illustrate
the dependence of optimal transmission/interference strategies on the
constraints imposed on the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3982</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3982</id><created>2010-09-20</created><authors><author><keyname>&#xd6;lveczky</keyname><forenames>Peter Csaba</forenames><affiliation>University of Oslo</affiliation></author></authors><title>Proceedings First International Workshop on Rewriting Techniques for
  Real-Time Systems</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010</journal-ref><doi>10.4204/EPTCS.36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the First International Workshop on
Rewriting Techniques for Real-Time Systems (RTRTS 2010), held in Longyearbyen,
Spitsbergen, on April 6-9, 2010.
  The aim of the workshop is to bring together researchers with an interest in
the use of rewriting-based techniques (including rewriting logic) and tools for
the modeling, analysis, and/or implementation of real-time and hybrid systems,
and to give them the opportunity to present their recent works, discuss future
research directions, and exchange ideas. The topics of the workshop comprise,
but are not limited to: methods and tools supporting rewriting-based modeling
and analysis of real-time and hybrid systems, and extensions of such systems;
use of rewriting techniques to provide rigorous support for model-based
software engineering of timed systems; applications and case studies; and
comparison with other formalisms and tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.3984</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.3984</id><created>2010-09-20</created><authors><author><keyname>Dinh</keyname><forenames>Hieu</forenames></author><author><keyname>Rajasekaran</keyname><forenames>Sanguthevar</forenames></author></authors><title>A memory-efficient data structure representing exact-match overlap
  graphs with application for next generation DNA assembly</title><categories>cs.DS cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An exact-match overlap graph of $n$ given strings of length $\ell$ is an
edge-weighted graph in which each vertex is associated with a string and there
is an edge $(x,y)$ of weight $\omega = \ell - |ov_{max}(x,y)|$ if and only if
$\omega \leq \lambda$, where $|ov_{max}(x,y)|$ is the length of $ov_{max}(x,y)$
and $\lambda$ is a given threshold. In this paper, we show that the exact-match
overlap graphs can be represented by a compact data structure that can be
stored using at most $(2\lambda -1 )(2\lceil\log n\rceil +
\lceil\log\lambda\rceil)n$ bits with a guarantee that the basic operation of
accessing an edge takes $O(\log \lambda)$ time.
  Exact-match overlap graphs have been broadly used in the context of DNA
assembly and the \emph{shortest super string problem} where the number of
strings $n$ ranges from a couple of thousands to a couple of billions, the
length $\ell$ of the strings is from 25 to 1000, depending on DNA sequencing
technologies. However, many DNA assemblers using overlap graphs are facing a
major problem of constructing and storing them. Especially, it is impossible
for these DNA assemblers to handle the huge amount of data produced by the next
generation sequencing technologies where the number of strings $n$ is usually
very large ranging from hundred million to a couple of billions. In fact, to
our best knowledge there is no DNA assemblers that can handle such a large
number of strings. Fortunately, with our compact data structure, the major
problem of constructing and storing overlap graphs is practically solved since
it only requires linear time and and linear memory. As a result, it opens the
door of possibilities to build a DNA assembler that can handle large-scale
datasets efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4000</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4000</id><created>2010-09-21</created><authors><author><keyname>Filiol</keyname><forenames>Eric</forenames></author></authors><title>Malicious cryptography techniques for unreversable (malicious or not)
  binaries</title><categories>cs.CR</categories><comments>17 pages, 2 figures, accepted for presentation at H2HC'10</comments><acm-class>D.4.6; E.3; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fighting against computer malware require a mandatory step of reverse
engineering. As soon as the code has been disassemblied/decompiled (including a
dynamic analysis step), there is a hope to understand what the malware actually
does and to implement a detection mean. This also applies to protection of
software whenever one wishes to analyze them. In this paper, we show how to
amour code in such a way that reserse engineering techniques (static and
dymanic) are absolutely impossible by combining malicious cryptography
techniques developped in our laboratory and new types of programming (k-ary
codes). Suitable encryption algorithms combined with new cryptanalytic
approaches to ease the protection of (malicious or not) binaries, enable to
provide both total code armouring and large scale polymorphic features at the
same time. A simple 400 Kb of executable code enables to produce a binary code
and around $2^{140}$ mutated forms natively while going far beyond the old
concept of decryptor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4004</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4004</id><created>2010-09-21</created><updated>2011-12-18</updated><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author></authors><title>A family of statistical symmetric divergences based on Jensen's
  inequality</title><categories>cs.CV cs.IT math.IT</categories><comments>15 pages, 2 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel parametric family of symmetric information-theoretic
distances based on Jensen's inequality for a convex functional generator. In
particular, this family unifies the celebrated Jeffreys divergence with the
Jensen-Shannon divergence when the Shannon entropy generator is chosen. We then
design a generic algorithm to compute the unique centroid defined as the
minimum average divergence. This yields a smooth family of centroids linking
the Jeffreys to the Jensen-Shannon centroid. Finally, we report on our
experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4012</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4012</id><created>2010-09-21</created><authors><author><keyname>Gueguen</keyname><forenames>Geoffroy</forenames></author></authors><title>Van Wijngaarden grammars, metamorphism and K-ary malwares</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grammars are used to describe sentences structure, thanks to some sets of
rules, which depends on the grammar type. A classification of grammars has been
made by Noam Chomsky, which led to four well-known types. Yet, there are other
types of grammars, which do not exactly fit in Chomsky's classification, such
as the two-level grammars. As their name suggests it, the main idea behind
these grammars is that they are composed of two grammars. Van Wijngaarden
grammars, particularly, are such grammars. They are interesting by their power
(expressiveness), which can be the same, under some hypotheses, as the most
powerful grammars of Chomsky's classification, i.e. Type 0 grammars. Another
point of interest is their relative conciseness and readability. Van
Wijngaarden grammars can describe static and dynamic semantic of a language.
So, by using them as a generative engine, it is possible to generate a possibly
infinite set of words, while assuring us that they all have the same semantic.
Moreover, they can describe K-ary codes, by describing the semantic of each
components of a code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4013</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4013</id><created>2010-09-21</created><authors><author><keyname>Inoue</keyname><forenames>Hiroyasu</forenames></author></authors><title>An Analysis of Transaction and Joint-patent Application Networks</title><categories>cs.SI cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many firms these days are opting to specialize rather than generalize as a
way of maintaining their competitiveness. Consequently, they cannot rely solely
on themselves, but must cooperate by combining their advantages. To obtain the
actual condition for this cooperation, a multi-layered network based on two
different types of data was investigated. The first type was transaction data
from Japanese firms. The network created from the data included 961,363 firms
and 7,808,760 links. The second type of data were from joint-patent
applications in Japan. The joint-patent application network included 54,197
nodes and 154,205 links. These two networks were merged into one network.
  The first anaysis was based on input-output tables and three different tables
were compared. The correlation coefficients between tables revealed that
transactions were more strongly tied to joint-patent applications than the
total amount of money. The total amount of money and transactions have few
relationships and these are probably connected to joint-patent applications in
different mechanisms. The second analysis was conducted based on the p* model.
Choice, multiplicity, reciprocity, multi-reciprocity and transitivity
configurations were evaluated. Multiplicity and reciprocity configurations were
significant in all the analyzed industries. The results for multiplicity meant
that transactions and joint-patent application links were closely related.
Multi-reciprocity and transitivity configurations were significant in some of
the analyzed industries. It was difficult to find any common characteristics in
the industries. Bayesian networks were used in the third analysis. The learned
structure revealed that if a transaction link between two firms is known, the
categories of firms' industries do not affect to the existence of a patent
link.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4019</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4019</id><created>2010-09-21</created><authors><author><keyname>Gonzalez-Bailon</keyname><forenames>Sandra</forenames></author><author><keyname>Banchs</keyname><forenames>Rafael E.</forenames></author><author><keyname>Kaltenbrunner</keyname><forenames>Andreas</forenames></author></authors><title>Emotional Reactions and the Pulse of Public Opinion: Measuring the
  Impact of Political Events on the Sentiment of Online Discussions</title><categories>cs.CY</categories><comments>18 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyses changes in public opinion by tracking political
discussions in which people voluntarily engage online. Unlike polls or surveys,
our approach does not elicit opinions but approximates what the public thinks
by analysing the discussions in which they decide to take part. We measure the
emotional content of online discussions in three dimensions (valence, arousal
and dominance), paying special attention to deviation around average values,
which we use as a proxy for disagreement and polarisation. We show that this
measurement of public opinion helps predict presidential approval rates,
suggesting that there is a point of connection between online discussions
(often deemed not representative of the overall population) and offline polls.
We also show that this measurement provides a deeper understanding of the
individual mechanisms that drive aggregated shifts in public opinion. Our data
spans a period that includes two US presidential elections, the attacks of
September 11, and the start of military action in Afghanistan and Iraq.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4020</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4020</id><created>2010-09-21</created><authors><author><keyname>Vidal</keyname><forenames>German</forenames></author><author><keyname>Zhou</keyname><forenames>Neng-Fa</forenames></author></authors><title>Proceedings of CICLOPS-WLPE 2010</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online proceedings of the Joint Workshop on Implementation of Constraint
Logic Programming Systems and Logic-based Methods in Programming Environments
(CICLOPS-WLPE 2010), Edinburgh, Scotland, U.K., July 15, 2010.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4046</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4046</id><created>2010-09-21</created><authors><author><keyname>Lu</keyname><forenames>Lu</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author></authors><title>Channel-coded Collision Resolution by Exploiting Symbol Misalignment</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In random-access networks, such as the IEEE 802.11 network, different users
may transmit their packets simultaneously, resulting in packet collisions.
Traditionally, the collided packets are simply discarded. To improve
performance, advanced signal processing techniques can be applied to extract
the individual packets from the collided signals. Prior work of ours has shown
that the symbol misalignment among the collided packets can be exploited to
improve the likelihood of successfully extracting the individual packets.
However, the failure rate is still unacceptably high. This paper investigates
how channel coding can be used to reduce the failure rate. We propose and
investigate a decoding scheme that incorporates the exploitation of the
aforementioned symbol misalignment into the channel decoding process. This is a
fine-grained integration at the symbol level. In particular, collision
resolution and channel decoding are applied in an integrated manner. Simulation
results indicate that our method outperforms other schemes, including the
straightforward method in which collision resolution and channel coding are
applied separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4048</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4048</id><created>2010-09-21</created><authors><author><keyname>Ahmed</keyname><forenames>Zeeshan</forenames></author></authors><title>A Middleware road towards Web (Grid) Services</title><categories>cs.DC</categories><comments>In the proceedings of Blekinge Institute of Technology Student
  Workshop on Architectures and Research in Middleware (BITSWARM), P 67, 12
  January, Ronneby Sweden 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Middleware technologies is a very big field, containing a strong already done
research as well as the currently running research to confirm already done
research's results and the to have some new solution by theoretical as well as
the experimental (practical) way. This document has been produced by Zeeshan
Ahmed (Student: Connectivity Software Technologies Blekinge Institute of
Technologies). This describes the research already done in the field of
middleware technologies including Web Services, Grid Computing, Grid Services
and Open Grid Service Infrastructure &amp; Architecture. This document concludes
with the overview of Web (Grid) Service, Chain of Web (Grid) Services and the
necessary security issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4091</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4091</id><created>2010-09-21</created><authors><author><keyname>Mahmood</keyname><forenames>Kashif</forenames></author><author><keyname>Rizk</keyname><forenames>Amr</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author></authors><title>On the Flow-Level Delay of a Spatial Multiplexing MIMO Wireless Channel</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MIMO wireless channel offers a rich ground for quality of service
analysis. In this work, we present a stochastic network calculus analysis of a
MIMO system, operating in spatial multiplexing mode, using moment generating
functions (MGF). We quantify the spatial multiplexing gain, achieved through
multiple antennas, for flow level quality of service (QoS) performance.
Specifically we use Gilbert-Elliot model to describe individual spatial paths
between the antenna pairs and model the whole channel by an N-State Markov
Chain, where N depends upon the degrees of freedom available in the MIMO
system. We derive probabilistic delay bounds for the system and show the impact
of increasing the number of antennas on the delay bounds under various
conditions, such as channel burstiness, signal strength and fading speed.
Further we present results for multi-hop scenarios under statistical
independence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4102</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4102</id><created>2010-09-21</created><authors><author><keyname>Andres</keyname><forenames>Bjoern</forenames></author><author><keyname>Kappes</keyname><forenames>Joerg H.</forenames></author><author><keyname>Koethe</keyname><forenames>Ullrich</forenames></author><author><keyname>Hamprecht</keyname><forenames>Fred A.</forenames></author></authors><title>The Lazy Flipper: MAP Inference in Higher-Order Graphical Models by
  Depth-limited Exhaustive Search</title><categories>cs.DS cs.CC</categories><comments>C++ Source Code available from
  http://hci.iwr.uni-heidelberg.de/software.php</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a new search algorithm for the NP-hard problem of
optimizing functions of binary variables that decompose according to a
graphical model. It can be applied to models of any order and structure. The
main novelty is a technique to constrain the search space based on the topology
of the model. When pursued to the full search depth, the algorithm is
guaranteed to converge to a global optimum, passing through a series of
monotonously improving local optima that are guaranteed to be optimal within a
given and increasing Hamming distance. For a search depth of 1, it specializes
to Iterated Conditional Modes. Between these extremes, a useful tradeoff
between approximation quality and runtime is established. Experiments on models
derived from both illustrative and real problems show that approximations found
with limited search depth match or improve those obtained by state-of-the-art
methods based on message passing and linear programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4128</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4128</id><created>2010-09-21</created><authors><author><keyname>Govindasamy</keyname><forenames>Siddhartan</forenames></author><author><keyname>Bliss</keyname><forenames>Daniel W.</forenames></author><author><keyname>Staelin</keyname><forenames>David H.</forenames></author></authors><title>Asymptotic Spectral Efficiency of Multi-antenna Links in Wireless
  Networks with Limited Tx CSI</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An asymptotic technique is presented for finding the spectral efficiency of
multi-antenna links in wireless networks where transmitters have
Channel-State-Information (CSI) corresponding to their target receiver.
Transmitters are assumed to transmit independent data streams on a limited
number of channel modes which limits the rank of transmit covariance matrices.
This technique is applied to spatially distributed networks to derive an
approximation for the asymptotic spectral efficiency in the
interference-limited regime as a function of link-length, interferer density,
number of antennas per receiver and transmitter, number of transmit streams and
path-loss exponent. It is found that targeted-receiver CSI, which can be
acquired with low overhead in duplex systems with reciprocity, can increase
spectral efficiency several fold, particularly when link lengths are large,
node density is high or both. Additionally, the per-link spectral efficiency is
found to be a function of the ratio of node density to the number of receiver
antennas, and that it can often be improved if nodes transmit using fewer
streams. These results are validated for finite-sized systems by Monte-Carlo
simulation and are asymptotic in the regime where the number of users and
antennas per receiver approach infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4136</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4136</id><created>2010-09-21</created><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>Regarding a Representation-Theoretic Conjecture of Wigderson</title><categories>math.GR cs.CC math.RT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there exists a family of irreducible representations R_i (of
finite groups G_i) such that, for any constant t, the average of R_i over t
uniformly random elements g_1, ..., g_t of G_i has operator norm 1 with
probability approaching 1 as i limits to infinity. This settles a conjecture of
Wigderson in the negative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4153</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4153</id><created>2010-09-21</created><authors><author><keyname>Alaei</keyname><forenames>Saeed</forenames></author><author><keyname>Malekian</keyname><forenames>Azarakhsh</forenames></author></authors><title>Maximizing Sequence-Submodular Functions and its Application to Online
  Advertising</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a general class of online maximization problems which
are as follows. We are given a time constraint T. We have to choose a sequence
of actions from a set of possible actions and also the length of time to run
each action subject to the total time being no more than T. Each action has a
marginal profit. We show that if the problem has the following two properties,
then there is a greedy algorithm that can yield O(1-1/e) of the optimal.
  -Performing an action earlier does not decrease the marginal profit of the
action. -Running a sequence of actions &quot;A&quot; followed by a sequence of actions
&quot;B&quot; yields at least as much profit as the maximum profit of &quot;A&quot; or &quot;B&quot;.
  The greedy algorithm also has the advantage that it can still be applied in
many settings where complete knowledge of the problem is not available or in
online settings where the input is revealed gradually. We also give examples of
non-trivial problems, for some of which we are not aware of any better
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4188</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4188</id><created>2010-09-21</created><updated>2012-01-18</updated><authors><author><keyname>Kopp</keyname><forenames>Gene S.</forenames></author><author><keyname>Wiltshire-Gordon</keyname><forenames>John D.</forenames></author></authors><title>Robust Coin Flipping</title><categories>cs.CC cs.CR cs.IT math.IT math.PR</categories><comments>22 pages, 1 figure</comments><doi>10.1007/978-3-642-29011-4_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alice seeks an information-theoretically secure source of private random
data. Unfortunately, she lacks a personal source and must use remote sources
controlled by other parties. Alice wants to simulate a coin flip of specified
bias $\alpha$, as a function of data she receives from $p$ sources; she seeks
privacy from any coalition of $r$ of them. We show: If $p/2 \leq r &lt; p$, the
bias can be any rational number and nothing else; if $0 &lt; r &lt; p/2$, the bias
can be any algebraic number and nothing else. The proof uses projective
varieties, convex geometry, and the probabilistic method. Our results improve
on those laid out by Yao, who asserts one direction of the $r=1$ case in his
seminal paper [Yao82]. We also provide an application to secure multiparty
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4214</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4214</id><created>2010-09-21</created><updated>2010-09-30</updated><authors><author><keyname>Ganapathi</keyname><forenames>Pramod</forenames></author><author><keyname>B</keyname><forenames>Rama</forenames></author></authors><title>A Versatile Algorithm to Generate Various Combinatorial Structures</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms to generate various combinatorial structures find tremendous
importance in computer science. In this paper, we begin by reviewing an
algorithm proposed by Rohl that generates all unique permutations of a list of
elements which possibly contains repetitions, taking some or all of the
elements at a time, in any imposed order. The algorithm uses an auxiliary array
that maintains the number of occurrences of each unique element in the input
list. We provide a proof of correctness of the algorithm. We then show how one
can efficiently generate other combinatorial structures like combinations,
subsets, n-Parenthesizations, derangements and integer partitions &amp;
compositions with minor changes to the same algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4219</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4219</id><created>2010-09-21</created><updated>2011-05-18</updated><authors><author><keyname>Ghaoui</keyname><forenames>Laurent El</forenames></author><author><keyname>Viallon</keyname><forenames>Vivian</forenames></author><author><keyname>Rabbani</keyname><forenames>Tarek</forenames></author></authors><title>Safe Feature Elimination for the LASSO and Sparse Supervised Learning
  Problems</title><categories>cs.LG cs.SY math.OC</categories><comments>Submitted to JMLR in April 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a fast method to eliminate features (variables) in l1 -penalized
least-square regression (or LASSO) problems. The elimination of features leads
to a potentially substantial reduction in running time, specially for large
values of the penalty parameter. Our method is not heuristic: it only
eliminates features that are guaranteed to be absent after solving the LASSO
problem. The feature elimination step is easy to parallelize and can test each
feature for elimination independently. Moreover, the computational effort of
our method is negligible compared to that of solving the LASSO problem -
roughly it is the same as single gradient step. Our method extends the scope of
existing LASSO algorithms to treat larger data sets, previously out of their
reach. We show how our method can be extended to general l1 -penalized convex
problems and present preliminary results for the Sparse Support Vector Machine
and Logistic Regression problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4259</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4259</id><created>2010-09-22</created><authors><author><keyname>Wirsing</keyname><forenames>Martin</forenames><affiliation>LMU M&#xfc;nchen</affiliation></author><author><keyname>Bauer</keyname><forenames>Sebastian S.</forenames><affiliation>LMU M&#xfc;nchen</affiliation></author><author><keyname>Schroeder</keyname><forenames>Andreas</forenames><affiliation>LMU M&#xfc;nchen</affiliation></author></authors><title>Modeling and Analyzing Adaptive User-Centric Systems in Real-Time Maude</title><categories>cs.SE</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 1-25</journal-ref><doi>10.4204/EPTCS.36.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pervasive user-centric applications are systems which are meant to sense the
presence, mood, and intentions of users in order to optimize user comfort and
performance. Building such applications requires not only state-of-the art
techniques from artificial intelligence but also sound software engineering
methods for facilitating modular design, runtime adaptation and verification of
critical system requirements.
  In this paper we focus on high-level design and analysis, and use the
algebraic rewriting language Real-Time Maude for specifying applications in a
real-time setting. We propose a generic component-based approach for modeling
pervasive user-centric systems and we show how to analyze and prove crucial
properties of the system architecture through model checking and simulation.
For proving time-dependent properties we use Metric Temporal Logic (MTL) and
present analysis algorithms for model checking two subclasses of MTL formulas:
time-bounded response and time-bounded safety MTL formulas. The underlying idea
is to extend the Real-Time Maude model with suitable clocks, to transform the
MTL formulas into LTL formulas over the extended specification, and then to use
the LTL model checker of Maude. It is shown that these analyses are sound and
complete for maximal time sampling. The approach is illustrated by a simple
adaptive advertising scenario in which an adaptive advertisement display can
react to actions of the users in front of the display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4260</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4260</id><created>2010-09-22</created><authors><author><keyname>AlTurki</keyname><forenames>Musab</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Meseguer</keyname><forenames>Jos&#xe9;</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Dist-Orc: A Rewriting-based Distributed Implementation of Orc with
  Formal Analysis</title><categories>cs.LO cs.DC cs.PL</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 26-45</journal-ref><doi>10.4204/EPTCS.36.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orc is a theory of orchestration of services that allows structured
programming of distributed and timed computations. Several formal semantics
have been proposed for Orc, including a rewriting logic semantics developed by
the authors. Orc also has a fully fledged implementation in Java with
functional programming features. However, as with descriptions of most
distributed languages, there exists a fairly substantial gap between Orc's
formal semantics and its implementation, in that: (i) programs in Orc are not
easily deployable in a distributed implementation just by using Orc's formal
semantics, and (ii) they are not readily formally analyzable at the level of a
distributed Orc implementation. In this work, we overcome problems (i) and (ii)
for Orc. Specifically, we describe an implementation technique based on
rewriting logic and Maude that narrows this gap considerably. The enabling
feature of this technique is Maude's support for external objects through TCP
sockets. We describe how sockets are used to implement Orc site calls and
returns, and to provide real-time timing information to Orc expressions and
sites. We then show how Orc programs in the resulting distributed
implementation can be formally analyzed at a reasonable level of abstraction by
defining an abstract model of time and the socket communication infrastructure,
and discuss the assumptions under which the analysis can be deemed correct.
Finally, the distributed implementation and the formal analysis methodology are
illustrated with a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4261</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4261</id><created>2010-09-22</created><authors><author><keyname>Bae</keyname><forenames>Kyungmin</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>&#xd6;lveczky</keyname><forenames>Peter Csaba</forenames><affiliation>University of Oslo</affiliation></author></authors><title>Extending the Real-Time Maude Semantics of Ptolemy to Hierarchical DE
  Models</title><categories>cs.LO cs.FL cs.PL cs.SE</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 46-66</journal-ref><doi>10.4204/EPTCS.36.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends our Real-Time Maude formalization of the semantics of flat
Ptolemy II discrete-event (DE) models to hierarchical models, including modal
models. This is a challenging task that requires combining synchronous
fixed-point computations with hierarchical structure. The synthesis of a
Real-Time Maude verification model from a Ptolemy II DE model, and the formal
verification of the synthesized model in Real-Time Maude, have been integrated
into Ptolemy II, enabling a model-engineering process that combines the
convenience of Ptolemy II DE modeling and simulation with formal verification
in Real-Time Maude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4262</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4262</id><created>2010-09-22</created><authors><author><keyname>Bj&#xf8;rk</keyname><forenames>Joakim</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>Johnsen</keyname><forenames>Einar Broch</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>Owe</keyname><forenames>Olaf</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>Schlatte</keyname><forenames>Rudolf</forenames><affiliation>University of Oslo</affiliation></author></authors><title>Lightweight Time Modeling in Timed Creol</title><categories>cs.PL cs.LO cs.SE</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 67-81</journal-ref><doi>10.4204/EPTCS.36.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creol is an object-oriented modeling language in which inherently concurrent
objects exchange asynchronous method calls. The operational semantics of Creol
is written in an actor-based style, formulated in rewriting logic. The
operational semantics yields a language interpreter in the Maude system, which
can be used to analyze models. Recently, Creol has been applied to the modeling
of systems with radio communication, such as sensor systems. With radio
communication, messages expire and, if sent simultaneously, they may collide in
the air. In order to capture these and other properties of distributed systems,
we extended Creol's operational semantics with a notion of time. We exploit the
framework of a language interpreter to use a lightweight notion of time, in
contrast to that needed for a general purpose specification language. This
paper presents a timed extension of Creol, including the semantics and the
implementation strategy, and discusses its properties using an extended
example. The approach can be generalized to other concurrent object or
actor-based systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4263</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4263</id><created>2010-09-22</created><authors><author><keyname>Fadlisyah</keyname><forenames>Muhammad</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>&#xc1;brah&#xe1;m</keyname><forenames>Erika</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>Lepri</keyname><forenames>Daniela</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>&#xd6;lveczky</keyname><forenames>Peter Csaba</forenames><affiliation>University of Oslo</affiliation></author></authors><title>A Rewriting-Logic-Based Technique for Modeling Thermal Systems</title><categories>cs.LO cs.SE physics.comp-ph</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 82-100</journal-ref><doi>10.4204/EPTCS.36.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a rewriting-logic-based modeling and analysis technique
for physical systems, with focus on thermal systems. The contributions of this
paper can be summarized as follows: (i) providing a framework for modeling and
executing physical systems, where both the physical components and their
physical interactions are treated as first-class citizens; (ii) showing how
heat transfer problems in thermal systems can be modeled in Real-Time Maude;
(iii) giving the implementation in Real-Time Maude of a basic numerical
technique for executing continuous behaviors in object-oriented hybrid systems;
and (iv) illustrating these techniques with a set of incremental case studies
using realistic physical parameters, with examples of simulation and model
checking analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4264</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4264</id><created>2010-09-22</created><authors><author><keyname>Lepri</keyname><forenames>Daniela</forenames></author><author><keyname>&#xd6;lveczky</keyname><forenames>Peter Csaba</forenames></author><author><keyname>&#xc1;brah&#xe1;m</keyname><forenames>Erika</forenames></author></authors><title>Model Checking Classes of Metric LTL Properties of Object-Oriented
  Real-Time Maude Specifications</title><categories>cs.LO</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 117-136</journal-ref><doi>10.4204/EPTCS.36.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a transformational approach for model checking two
important classes of metric temporal logic (MTL) properties, namely, bounded
response and minimum separation, for nonhierarchical object-oriented Real-Time
Maude specifications. We prove the correctness of our model checking
algorithms, which terminate under reasonable non-Zeno-ness assumptions when the
reachable state space is finite. These new model checking features have been
integrated into Real-Time Maude, and are used to analyze a network of medical
devices and a 4-way traffic intersection system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4265</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4265</id><created>2010-09-22</created><authors><author><keyname>&#xd6;lveczky</keyname><forenames>Peter Csaba</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>Meseguer</keyname><forenames>Jos&#xe9;</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Specification and Verification of Distributed Embedded Systems: A
  Traffic Intersection Product Family</title><categories>cs.LO</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 137-157</journal-ref><doi>10.4204/EPTCS.36.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed embedded systems (DESs) are no longer the exception; they are the
rule in many application areas such as avionics, the automotive industry,
traffic systems, sensor networks, and medical devices. Formal DES specification
and verification is challenging due to state space explosion and the need to
support real-time features. This paper reports on an extensive industry-based
case study involving a DES product family for a pedestrian and car 4-way
traffic intersection in which autonomous devices communicate by asynchronous
message passing without a centralized controller. All the safety requirements
and a liveness requirement informally specified in the requirements document
have been formally verified using Real-Time Maude and its model checking
features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4266</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4266</id><created>2010-09-22</created><authors><author><keyname>Sun</keyname><forenames>Mu</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Meseguer</keyname><forenames>Jos&#xe9;</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Distributed Real-Time Emulation of Formally-Defined Patterns for Safe
  Medical Device Control</title><categories>cs.LO cs.SE</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><acm-class>Design, Reliability, Verification</acm-class><journal-ref>EPTCS 36, 2010, pp. 158-177</journal-ref><doi>10.4204/EPTCS.36.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Safety of medical devices and of their interoperation is an unresolved issue
causing severe and sometimes deadly accidents for patients with shocking
frequency. Formal methods, particularly in support of highly reusable and
provably safe patterns which can be instantiated to many device instances can
help in this regard. However, this still leaves open the issue of how to pass
from their formal specifications in logical time to executable emulations that
can interoperate in physical time with other devices and with simulations of
patient and/or doctor behaviors. This work presents a specification-based
methodology in which virtual emulation environments can be easily developed
from formal specifications in Real-Time Maude, and can support interactions
with other real devices and with simulation models. This general methodology is
explained in detail and is illustrated with two concrete scenarios which are
both instances of a common safe formal pattern: one scenario involves the
interaction of a provably safe pacemaker with a simulated heart; the other
involves the interaction of a safe controller for patient-induced analgesia
with a real syringe pump.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4268</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4268</id><created>2010-09-22</created><updated>2010-09-25</updated><authors><author><keyname>Yu</keyname><forenames>Hao</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Rank-Constrained Schur-Convex Optimization with Multiple Trace/Log-Det
  Constraints</title><categories>cs.IT math.IT</categories><comments>Some related patents are now applied. To protect our intellectual
  property, we postponed to make our manuscript public</comments><doi>10.1109/TSP.2010.2084997</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rank-constrained optimization problems have received an increasing intensity
of interest recently, because many optimization problems in communications and
signal processing applications can be cast into a rank-constrained optimization
problem. However, due to the non-convex nature of rank constraints, a
systematic solution to general rank-constrained problems has remained open for
a long time. In this paper, we focus on a rank-constrained optimization problem
with a Schur-convex/concave objective function and multiple
trace/logdeterminant constraints. We first derive a structural result on the
optimal solution of the rank-constrained problem using majorization theory.
Based on the solution structure, we transform the rank-constrained problem into
an equivalent problem with a unitary constraint. After that, we derive an
iterative projected steepest descent algorithm which converges to a local
optimal solution. Furthermore, we shall show that under some special cases, we
can derive a closed-form global optimal solution. The numerical results show
the superior performance of our proposed technique over the baseline schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4269</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4269</id><created>2010-09-22</created><authors><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author></authors><title>Distributed Interference Cancellation in Multiple Access Channel with
  Transmitter Cooperation</title><categories>cs.IT math.IT</categories><comments>Extended version of a 5-page conference paper submitted to ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-user Gaussian multiple access channel with two independent
additive white Gaussian interferences. Each interference is known to exactly
one transmitter non-causally. Transmitters are allowed to cooperate through
finite-capacity links. The capacity region is characterized to within 3 and 1.5
bits for the stronger user and the weaker user respectively, regardless of
channel parameters. As a by-product, we characterize the capacity region of the
case without cooperation to within 1 and 0.5 bits for the stronger user and the
weaker user respectively. These results are based on a layered modulo-lattice
transmission architecture which realizes distributed interference cancellation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4287</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4287</id><created>2010-09-22</created><updated>2012-01-04</updated><authors><author><keyname>Olmos</keyname><forenames>Pablo M.</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan Jos&#xe9;</forenames></author><author><keyname>P&#xe9;rez-Cruz</keyname><forenames>Fernando</forenames></author></authors><title>Tree-Structure Expectation Propagation for LDPC Decoding in Erasure
  Channels</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn to be replaced by a corrected version
  under a different title: &quot;Tree-Structure Expectation Propagation for LDPC
  Decoding over the BEC&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new algorithm, denoted as TEP, to decode
low-density parity-check (LDPC) codes over the Binary Erasure Channel (BEC).
The TEP decoder is derived applying the expectation propagation (EP) algorithm
with a tree- structured approximation. Expectation Propagation (EP) is a
generalization to Belief Propagation (BP) in two ways. First, it can be used
with any exponential family distribution over the cliques in the graph. Second,
it can impose additional constraints on the marginal distributions. We use this
second property to impose pair-wise marginal constraints in some check nodes of
the LDPC code's Tanner graph. The algorithm has the same computational
complexity than BP, but it can decode a higher fraction of errors when applied
over the BEC. In this paper, we focus on the asymptotic performance of the TEP
decoder, as the block size tends to infinity. We describe the TEP decoder by a
set of differential equations that represents the residual graph evolution
during the decoding process. The solution of these equations yields the
capacity of this decoder for a given LDPC ensemble over the BEC. We show that
the achieved capacity with the TEP is higher than the BP capacity, at the same
computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4300</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4300</id><created>2010-09-22</created><authors><author><keyname>Chiu</keyname><forenames>Eddy</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Wu</keyname><forenames>Tao</forenames></author><author><keyname>Liu</keyname><forenames>Sheng</forenames></author></authors><title>Robust Transceiver Design for K-Pairs Quasi-Static MIMO Interference
  Channels via Semi-Definite Relaxation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a robust transceiver design for the K-pair
quasi-static MIMO interference channel. Each transmitter is equipped with M
antennas, each receiver is equipped with N antennas, and the k-th transmitter
sends L_k independent data streams to the desired receiver. In the literature,
there exist a variety of theoretically promising transceiver designs for the
interference channel such as interference alignment-based schemes, which have
feasibility and practical limitations. In order to address practical system
issues and requirements, we consider a transceiver design that enforces
robustness against imperfect channel state information (CSI) as well as fair
performance among the users in the interference channel. Specifically, we
formulate the transceiver design as an optimization problem to maximize the
worst-case signal-to-interference-plus-noise ratio among all users. We devise a
low complexity iterative algorithm based on alternative optimization and
semi-definite relaxation techniques. Numerical results verify the advantages of
incorporating into transceiver design for the interference channel important
practical issues such as CSI uncertainty and fairness performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4318</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4318</id><created>2010-09-22</created><authors><author><keyname>Rahman</keyname><forenames>Mst. Farhana</forenames></author><author><keyname>Karim</keyname><forenames>S. M. Masud</forenames></author><author><keyname>Ripon</keyname><forenames>Kazi Shah Nawaz</forenames></author><author><keyname>Suvo</keyname><forenames>Md. Iqbal Hossain</forenames></author></authors><title>Performance Analysis of Estimation of Distribution Algorithm and Genetic
  Algorithm in Zone Routing Protocol</title><categories>cs.NE</categories><comments>5 pages, 5 figures, International Journal of Computer Science and
  Information Security (IJCSIS), ISSN: 1947-5500, Vol. 8, No. 5, pp. 203-207,
  August 2010, Pittsburgh, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Estimation of Distribution Algorithm (EDA) is used for Zone
Routing Protocol (ZRP) in Mobile Ad-hoc Network (MANET) instead of Genetic
Algorithm (GA). It is an evolutionary approach, and used when the network size
grows and the search space increases. When the destination is outside the zone,
EDA is applied to find the route with minimum cost and time. The implementation
of proposed method is compared with Genetic ZRP, i.e., GZRP and the result
demonstrates better performance for the proposed method. Since the method
provides a set of paths to the destination, it results in load balance to the
network. As both EDA and GA use random search method to reach the optimal
point, the searching cost reduced significantly, especially when the number of
data is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4330</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4330</id><created>2010-09-22</created><updated>2011-03-06</updated><authors><author><keyname>Trott</keyname><forenames>Christian R.</forenames></author><author><keyname>Winterfeld</keyname><forenames>Lars</forenames></author><author><keyname>Crozier</keyname><forenames>Paul S.</forenames></author></authors><title>General-purpose molecular dynamics simulations on GPU-based clusters</title><categories>cond-mat.mtrl-sci cs.DC cs.PF physics.comp-ph</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a GPU implementation of LAMMPS, a widely-used parallel molecular
dynamics (MD) software package, and show 5x to 13x single node speedups versus
the CPU-only version of LAMMPS. This new CUDA package for LAMMPS also enables
multi-GPU simulation on hybrid heterogeneous clusters, using MPI for inter-node
communication, CUDA kernels on the GPU for all methods working with particle
data, and standard LAMMPS C++ code for CPU execution. Cell and neighbor list
approaches are compared for best performance on GPUs, with thread-per-atom and
block-per-atom neighbor list variants showing best performance at low and high
neighbor counts, respectively. Computational performance results of GPU-enabled
LAMMPS are presented for a variety of materials classes (e.g. biomolecules,
polymers, metals, semiconductors), along with a speed comparison versus other
available GPU-enabled MD software. Finally, we show strong and weak scaling
performance on a CPU/GPU cluster using up to 128 dual GPU nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4352</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4352</id><created>2010-09-22</created><updated>2011-02-08</updated><authors><author><keyname>Kim</keyname><forenames>Byung-Hak</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>An Iterative Joint Linear-Programming Decoding of LDPC Codes and
  Finite-State Channels</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. IEEE ICC 2011, Kyoto, Japan, June 5-9, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an efficient iterative solver for the joint
linear-programming (LP) decoding of low-density parity-check (LDPC) codes and
finite-state channels (FSCs). In particular, we extend the approach of
iterative approximate LP decoding, proposed by Vontobel and Koetter and
explored by Burshtein, to this problem. By taking advantage of the dual-domain
structure of the joint decoding LP, we obtain a convergent iterative algorithm
for joint LP decoding whose structure is similar to BCJR-based turbo
equalization (TE). The result is a joint iterative decoder whose complexity is
similar to TE but whose performance is similar to joint LP decoding. The main
advantage of this decoder is that it appears to provide the predictability of
joint LP decoding and superior performance with the computational complexity of
TE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4355</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4355</id><created>2010-09-22</created><authors><author><keyname>Chan</keyname><forenames>Ho-Leung</forenames></author><author><keyname>Megow</keyname><forenames>Nicole</forenames></author><author><keyname>van Stee</keyname><forenames>Rob</forenames></author><author><keyname>Sitters</keyname><forenames>Rene</forenames></author></authors><title>The Sorting Buffer Problem is NP-hard</title><categories>cs.DS</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the offline sorting buffer problem. The input is a sequence of
items of different types. All items must be processed one by one by a server.
The server is equipped with a random-access buffer of limited capacity which
can be used to rearrange items. The problem is to design a scheduling strategy
that decides upon the order in which items from the buffer are sent to the
server. Each type change incurs unit cost, and thus, the cost minimizing
objective is to minimize the total number of type changes for serving the
entire sequence. This problem is motivated by various applications in
manufacturing processes and computer science, and it has attracted significant
attention in the last few years. The main focus has been on online competitive
algorithms. Surprisingly little is known on the basic offline problem. In this
paper, we show that the sorting buffer problem with uniform cost is NP-hard
and, thus, close one of the most fundamental questions for the offline problem.
On the positive side, we give an O(1)-approximation algorithm when the
scheduler is given a buffer only slightly larger than double the original size.
We also give a dynamic programming algorithm for the special case of buffer
size two that solves the problem exactly in linear time, improving on the
standard DP which runs in cubic time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4375</identifier>
 <datestamp>2011-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4375</id><created>2010-09-22</created><updated>2011-03-10</updated><authors><author><keyname>Barak</keyname><forenames>Boaz</forenames></author><author><keyname>Dvir</keyname><forenames>Zeev</forenames></author><author><keyname>Wigderson</keyname><forenames>Avi</forenames></author><author><keyname>Yehudayoff</keyname><forenames>Amir</forenames></author></authors><title>Rank Bounds for Design Matrices with Applications to Combinatorial
  Geometry and Locally Correctable Codes</title><categories>math.CO cs.CC cs.CG math.MG</categories><comments>31 pages. Added high dimensional SG theorem. Extended abstract to
  appear in STOC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A (q,k,t)-design matrix is an m x n matrix whose pattern of zeros/non-zeros
satisfies the following design-like condition: each row has at most q
non-zeros, each column has at least k non-zeros and the supports of every two
columns intersect in at most t rows. We prove that the rank of any
(q,k,t)-design matrix over a field of characteristic zero (or sufficiently
large finite characteristic) is at least n - (qtn/2k)^2 . Using this result we
derive the following applications:
  (1) Impossibility results for 2-query LCCs over the complex numbers: A
2-query locally correctable code (LCC) is an error correcting code in which
every codeword coordinate can be recovered, probabilistically, by reading at
most two other code positions. Such codes have numerous applications and
constructions (with exponential encoding length) are known over finite fields
of small characteristic. We show that infinite families of such linear 2-query
LCCs do not exist over the complex numbers.
  (2) Generalization of results in combinatorial geometry: We prove a
quantitative analog of the Sylvester-Gallai theorem: Let $v_1,...,v_m$ be a set
of points in $\C^d$ such that for every $i \in [m]$ there exists at least
$\delta m$ values of $j \in [m]$ such that the line through $v_i,v_j$ contains
a third point in the set. We show that the dimension of $\{v_1,...,v_m \}$ is
at most $O(1/\delta^2)$. Our results generalize to the high dimensional case
(replacing lines with planes, etc.) and to the case where the points are
colored (as in the Motzkin-Rabin Theorem).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4383</identifier>
 <datestamp>2011-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4383</id><created>2010-09-22</created><updated>2011-09-01</updated><authors><author><keyname>Maiya</keyname><forenames>Arun S.</forenames></author><author><keyname>Berger-Wolf</keyname><forenames>Tanya Y.</forenames></author></authors><title>Expansion and Search in Networks</title><categories>cs.SI cs.NI physics.data-an physics.soc-ph</categories><comments>10 pages</comments><acm-class>H.2.8; H.3.3</acm-class><journal-ref>CIKM 2010: 19th ACM International Conference on Information and
  Knowledge Management</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Borrowing from concepts in expander graphs, we study the expansion properties
of real-world, complex networks (e.g. social networks, unstructured
peer-to-peer or P2P networks) and the extent to which these properties can be
exploited to understand and address the problem of decentralized search. We
first produce samples that concisely capture the overall expansion properties
of an entire network, which we collectively refer to as the expansion
signature. Using these signatures, we find a correspondence between the
magnitude of maximum expansion and the extent to which a network can be
efficiently searched. We further find evidence that standard graph-theoretic
measures, such as average path length, fail to fully explain the level of
&quot;searchability&quot; or ease of information diffusion and dissemination in a
network. Finally, we demonstrate that this high expansion can be leveraged to
facilitate decentralized search in networks and show that an expansion-based
search strategy outperforms typical search methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4386</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4386</id><created>2010-09-22</created><updated>2011-03-02</updated><authors><author><keyname>Fang</keyname><forenames>Minyu</forenames></author><author><keyname>Malone</keyname><forenames>David</forenames></author><author><keyname>Duffy</keyname><forenames>Ken R.</forenames></author><author><keyname>Leith</keyname><forenames>Douglas J.</forenames></author></authors><title>Decentralised Learning MACs for Collision-free Access in WLANs</title><categories>cs.NI</categories><journal-ref>Springer Wireless Networks 2013, Volume 19, Issue 1, pp 83-98</journal-ref><doi>10.1007/s11276-012-0452-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By combining the features of CSMA and TDMA, fully decentralised WLAN MAC
schemes have recently been proposed that converge to collision-free schedules.
In this paper we describe a MAC with optimal long-run throughput that is almost
decentralised. We then design two \changed{schemes} that are practically
realisable, decentralised approximations of this optimal scheme and operate
with different amounts of sensing information. We achieve this by (1)
introducing learning algorithms that can substantially speed up convergence to
collision free operation; (2) developing a decentralised schedule length
adaptation scheme that provides long-run fair (uniform) access to the medium
while maintaining collision-free access for arbitrary numbers of stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4400</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4400</id><created>2010-09-22</created><updated>2010-10-20</updated><authors><author><keyname>Laurent</keyname><forenames>Olivier</forenames><affiliation>CNRS - ENS Lyon</affiliation></author></authors><title>Game semantics for first-order logic</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.2, F.4.1, F.3.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (October
  20, 2010) lmcs:1130</journal-ref><doi>10.2168/LMCS-6(4:3)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We refine HO/N game semantics with an additional notion of pointer
(mu-pointers) and extend it to first-order classical logic with completeness
results. We use a Church style extension of Parigot's lambda-mu-calculus to
represent proofs of first-order classical logic. We present some relations with
Krivine's classical realizability and applications to type isomorphisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4409</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4409</id><created>2010-09-22</created><authors><author><keyname>Oreshkin</keyname><forenames>Boris N.</forenames></author><author><keyname>Liu</keyname><forenames>Xuan</forenames></author><author><keyname>Coates</keyname><forenames>Mark J.</forenames></author></authors><title>Efficient delay-tolerant particle filtering</title><categories>stat.AP cs.MA</categories><doi>10.1109/TSP.2011.2140110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel framework for delay-tolerant particle filtering
that is computationally efficient and has limited memory requirements. Within
this framework the informativeness of a delayed (out-of-sequence) measurement
(OOSM) is estimated using a lightweight procedure and uninformative
measurements are immediately discarded. The framework requires the
identification of a threshold that separates informative from uninformative;
this threshold selection task is formulated as a constrained optimization
problem, where the goal is to minimize tracking error whilst controlling the
computational requirements. We develop an algorithm that provides an
approximate solution for the optimization problem. Simulation experiments
provide an example where the proposed framework processes less than 40% of all
OOSMs with only a small reduction in tracking accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4415</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4415</id><created>2010-09-22</created><updated>2012-04-04</updated><authors><author><keyname>Shur</keyname><forenames>Arseny M.</forenames></author></authors><title>Numerical values of the growth rates of power-free languages</title><categories>cs.FL math.CO</categories><comments>5 pages, 4 tables</comments><msc-class>68Q70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present upper and two-sided bounds of the exponential growth rate for a
wide range of power-free languages. All bounds are obtained with the use of
algorithms previously developed by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4447</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4447</id><created>2010-09-22</created><updated>2010-10-05</updated><authors><author><keyname>Becker</keyname><forenames>Florent</forenames></author><author><keyname>Matamala</keyname><forenames>Mart&#xed;n</forenames></author><author><keyname>Nisse</keyname><forenames>Nicolas</forenames></author><author><keyname>Rapaport</keyname><forenames>Ivan</forenames></author><author><keyname>Suchan</keyname><forenames>Karol</forenames></author><author><keyname>Todinca</keyname><forenames>Ioan</forenames></author></authors><title>Adding a referee to an interconnection network: What can(not) be
  computed in one round</title><categories>cs.CC cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we ask which properties of a distributed network can be
computed from a little amount of local information provided by its nodes. The
distributed model we consider is a restriction of the classical CONGEST
(distributed) model and it is close to the simultaneous messages (communication
complexity) model defined by Babai, Kimmel and Lokam. More precisely, each of
these n nodes -which only knows its own ID and the IDs of its neighbors- is
allowed to send a message of O(log n) bits to some central entity, called the
referee. Is it possible for the referee to decide some basic structural
properties of the network topology G? We show that simple questions like, &quot;does
G contain a square?&quot;, &quot;does G contain a triangle?&quot; or &quot;Is the diameter of G at
most 3? cannot be solved in general. On the other hand, the referee can decode
the messages in order to have full knowledge of G when G belongs to many graph
classes such as planar graphs, bounded treewidth graphs and, more generally,
bounded degeneracy graphs. We leave open questions related to the connectivity
of arbitrary graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4455</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4455</id><created>2010-09-22</created><authors><author><keyname>Rumyantsev</keyname><forenames>Andrey</forenames></author><author><keyname>Ushakov</keyname><forenames>Maxim</forenames></author></authors><title>Forbidden substrings, Kolmogorov complexity and almost periodic
  sequences</title><categories>math.CO cs.DM</categories><journal-ref>Andrey Yu. Rumyantsev, Maxim A. Ushakov, Forbidden Substrings,
  Kolmogorov Complexity and Almost Periodic Sequences, Springer, Lecture Notes
  in Computer Science, Volume 3884 / 2006, STACS 2006, pp. 396--407</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assume that for some $\alpha&lt;1$ and for all nutural $n$ a set $F_n$ of at
most $2^{\alpha n}$ &quot;forbidden&quot; binary strings of length $n$ is fixed. Then
there exists an infinite binary sequence $\omega$ that does not have (long)
forbidden substrings. We prove this combinatorial statement by translating it
into a statement about Kolmogorov complexity and compare this proof with a
combinatorial one based on Laslo Lovasz local lemma. Then we construct an
almost periodic sequence with the same property (thus combines the results of
Levin and Muchnik-Semenov-Ushakov). Both the combinatorial proof and Kolmogorov
complexity argument can be generalized to the multidimensional case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4471</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4471</id><created>2010-09-22</created><authors><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Mathew</keyname><forenames>Rogers</forenames></author><author><keyname>Sivadasan</keyname><forenames>Naveen</forenames></author></authors><title>Boxicity of Line Graphs</title><categories>math.CO cs.DM</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boxicity of a graph H, denoted by box(H), is the minimum integer k such that
H is an intersection graph of axis-parallel k-dimensional boxes in R^k. In this
paper, we show that for a line graph G of a multigraph, box(G) &lt;=
2\Delta(\lceil log_2(log_2(\Delta)) \rceil + 3) + 1, where \Delta denotes the
maximum degree of G. Since \Delta &lt;= 2(\chi - 1), for any line graph G with
chromatic number \chi, box(G) = O(\chi log_2(log_2(\chi))). For the
d-dimensional hypercube H_d, we prove that box(H_d) &gt;= (\lceil log_2(log_2(d))
\rceil + 1)/2. The question of finding a non-trivial lower bound for box(H_d)
was left open by Chandran and Sivadasan in [L. Sunil Chandran and Naveen
Sivadasan. The cubicity of Hypercube Graphs. Discrete Mathematics,
308(23):5795-5800, 2008]. The above results are consequences of bounds that we
obtain for the boxicity of fully subdivided graphs (a graph which can be
obtained by subdividing every edge of a graph exactly once).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4489</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4489</id><created>2010-09-22</created><authors><author><keyname>Ruzzenenti</keyname><forenames>Franco</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author><author><keyname>Basosi</keyname><forenames>Riccardo</forenames></author></authors><title>Complex Networks and Symmetry II: Reciprocity and Evolution of World
  Trade</title><categories>q-fin.GN cs.SI nlin.AO physics.soc-ph</categories><comments>Final accepted version</comments><journal-ref>Symmetry 2, no. 3, pp. 1710-1744 (2010)</journal-ref><doi>10.3390/sym2031710</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We exploit the symmetry concepts developed in the companion review of this
article to introduce a stochastic version of link reversal symmetry, which
leads to an improved understanding of the reciprocity of directed networks. We
apply our formalism to the international trade network and show that a strong
embedding in economic space determines particular symmetries of the network,
while the observed evolution of reciprocity is consistent with a symmetry
breaking taking place in production space. Our results show that networks can
be strongly affected by symmetry-breaking phenomena occurring in embedding
spaces, and that stochastic network symmetries can successfully suggest, or
rule out, possible underlying mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4495</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4495</id><created>2010-09-22</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Unary Coding for Neural Network Learning</title><categories>cs.NE</categories><comments>7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents some properties of unary coding of significance for
biological learning and instantaneously trained neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4499</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4499</id><created>2010-09-22</created><authors><author><keyname>Sen</keyname><forenames>Arunabha</forenames></author><author><keyname>Ghosh</keyname><forenames>Pavel</forenames></author><author><keyname>Silva</keyname><forenames>Tiffany</forenames></author><author><keyname>Das</keyname><forenames>Nibedita</forenames></author><author><keyname>Kundu</keyname><forenames>Anjan</forenames></author></authors><title>Architecture and Algorithms for an Airborne Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The U.S. Air Force currently is in the process of developing an Airborne
Network (AN) to provide support to its combat aircrafts on a mission. The
reliability needed for continuous operation of an AN is difficult to achieve
through completely infrastructure-less mobile ad hoc networks. In this paper we
first propose an architecture for an AN where airborne networking platforms
(ANPs - aircrafts, UAVs and satellites) form the backbone of the AN. In this
architecture, the ANPs can be viewed as mobile base stations and the combat
aircrafts on a mission as mobile clients. The combat aircrafts on a mission
move through a space called air corridor. The goal of the AN design is to form
a backbone network with the ANPs with two properties: (i) the backbone network
remains connected at all times, even though the topology of the network changes
with the movement of the ANPs, and (ii) the entire 3D space of the air corridor
is under radio coverage at all times by the continuously moving ANPs.
  In addition to proposing an architecture for an AN, the contributions of the
paper include, development of an algorithm that finds the velocity and
transmission range of the ANPs so that the dynamically changing backbone
network remains connected at all times, development of a routing algorithm that
ensures a connection between the source-destination node pair with the fewest
number of path switching, given the dimensions of the air corridor and the
radius of the coverage sphere associated with an ANP, development of an
algorithm that finds the fewest number of ANPs required to provide complete
coverage of the air corridor at all times, development of an algorithm that
provides connected-coverage to the air corridor at all times, and development
of a visualization tool that depicts the movement patterns of the ANPs and the
resulting dynamic graph and the coverage volume of the backbone network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4503</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4503</id><created>2010-09-22</created><authors><author><keyname>Barbieri</keyname><forenames>Davide</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author></authors><title>On Repetition Protocols and Power Control for Multiple Access
  Block-Fading Channels</title><categories>cs.IT math.IT</categories><comments>submitted to icc2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the long-term throughput performance of repetition
protocols coupled with power control for multiple access block-fading channels.
We propose to use the feedback bits to inform the transmitter about the
decoding status and the instantaneous channel quality. We determine the
throughput of simple and practically inspired protocols; we show remarkable
throughput improvements, especially at low and moderate SNR, when compared to
protocols where the feedback bits are used for acknowledgment only or for power
control only; we show that the throughput is very close to the ultimate ergodic
multi-user water-filling capacity for small number of feedback bits and/or
retransmissions. For symmetric Rayleigh fading channels, numerical results show
that the throughput improvement is mainly due to the ability to perform a power
control, rather than to retransmit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4509</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4509</id><created>2010-09-22</created><authors><author><keyname>Kayama</keyname><forenames>Yoshihiko</forenames></author></authors><title>Complex networks derived from cellular automata</title><categories>nlin.CG cs.SI math-ph math.MP</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for deriving networks from one-dimensional binary
cellular automata. The derived networks are usually directed and have
structural properties corresponding to the dynamical behaviors of their
cellular automata. Network parameters, particularly the efficiency and the
degree distribution, show that the dependence of efficiency on the grid size is
characteristic and can be used to classify cellular automata and that derived
networks exhibit various degree distributions. In particular, a class IV rule
of Wolfram's classification produces a network having a scale-free
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4517</identifier>
 <datestamp>2011-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4517</id><created>2010-09-23</created><updated>2011-12-09</updated><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Jampani</keyname><forenames>Krishnam Raju</forenames></author><author><keyname>Lubiw</keyname><forenames>Anna</forenames></author></authors><title>Testing Simultaneous Planarity when the Common Graph is 2-Connected</title><categories>cs.DS</categories><comments>Appeared in ISAAC 2010, 15 pages, 3 figures</comments><msc-class>68R10</msc-class><acm-class>G.2.2; E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two planar graphs G1 and G2 sharing some vertices and edges are
`simultaneously planar' if they have planar drawings such that a shared vertex
[edge] is represented by the same point [curve] in both drawings. It is an open
problem whether simultaneous planarity can be tested efficiently. We give a
linear-time algorithm to test simultaneous planarity when the two graphs share
a 2-connected subgraph. Our algorithm extends to the case of k planar graphs
where each vertex [edge] is either common to all graphs or belongs to exactly
one of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4520</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4520</id><created>2010-09-23</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>An Energy Efficient Multichannel MAC Protocol for Cognitive Radio Ad Hoc
  Networks</title><categories>cs.NI</categories><comments>8 Pages, International Journal</comments><journal-ref>International Journal of Communication Networks and Information
  Security (IJCNIS), Vol. 2, No. 2, pp. 112-119, Aug. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a TDMA based energy efficient cognitive radio
multichannel medium access control (MAC) protocol called ECR-MAC for wireless
Ad Hoc Networks. ECR-MAC requires only a single half-duplex radio transceiver
on each node that integrates the spectrum sensing at physical (PHY) layer and
the packet scheduling at MAC layer. In addition to explicit frequency
negotiation which is adopted by conventional multichannel MAC protocols,
ECR-MAC introduces lightweight explicit time negotiation. This two-dimensional
negotiation enables ECR-MAC to exploit the advantage of both multiple channels
and TDMA, and achieve aggressive power savings by allowing nodes that are not
involved in communication to go into doze mode. The IEEE 802.11 standard allows
for the use of multiple channels available at the PHY layer, but its MAC
protocol is designed only for a single channel. A single channel MAC protocol
does not work well in a multichannel environment, because of the multichannel
hidden terminal problem. The proposed energy efficient ECR-MAC protocol allows
SUs to identify and use the unused frequency spectrum in a way that constrains
the level of interference to the primary users (PUs). Extensive simulation
results show that our proposed ECR-MAC protocol successfully exploits multiple
channels and significantly improves network performance by using the licensed
spectrum band opportunistically and protects QoS provisioning over cognitive
radio ad hoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4521</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4521</id><created>2010-09-23</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>CR-MAC: A multichannel MAC protocol for cognitive radio ad hoc networks</title><categories>cs.NI</categories><comments>14 Pages, International Journal</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol.2, No.5, pp. 1-14, Sep. 2010</journal-ref><doi>10.5121/ijcnc.2010.2501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a cross-layer based cognitive radio multichannel medium
access control (MAC) protocol with TDMA, which integrate the spectrum sensing
at physical (PHY) layer and the packet scheduling at MAC layer, for the ad hoc
wireless networks. The IEEE 802.11 standard allows for the use of multiple
channels available at the PHY layer, but its MAC protocol is designed only for
a single channel. A single channel MAC protocol does not work well in a
multichannel environment, because of the multichannel hidden terminal problem.
Our proposed protocol enables secondary users (SUs) to utilize multiple
channels by switching channels dynamically, thus increasing network throughput.
In our proposed protocol, each SU is equipped with only one spectrum agile
transceiver, but solves the multichannel hidden terminal problem using temporal
synchronization. The proposed cognitive radio MAC (CR-MAC) protocol allows SUs
to identify and use the unused frequency spectrum in a way that constrains the
level of interference to the primary users (PUs). Our scheme improves network
throughput significantly, especially when the network is highly congested. The
simulation results show that our proposed CR-MAC protocol successfully exploits
multiple channels and significantly improves network performance by using the
licensed spectrum band opportunistically and protects PUs from interference,
even in hidden terminal situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4524</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4524</id><created>2010-09-23</created><authors><author><keyname>Monica</keyname><affiliation>Dr B R Ambedkar National Institute of Technology, India</affiliation></author><author><keyname>Sharma</keyname><forenames>Ajay K</forenames><affiliation>Dr B R Ambedkar National Institute of Technology, India</affiliation></author></authors><title>Comparative Investigation for Energy Consumption of Different Chipsets
  Based on Scheduling for Wireless Sensor Networks</title><categories>cs.NI</categories><comments>17 pages, Based on scheduling for Wireless Sensor Networks</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.2, No.5, September 2010</journal-ref><doi>10.5121/ijcnc.2010.2511</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapid progress in microelectromechanical system (MEMS) and radio frequency
(RF) design has enabled the development of low-power, inexpensive, and
network-enabled microsensors. These sensor nodes are capable of capturing
various physical information, such as temperature, pressure, motion of an
object, etc as well as mapping such physical characteristics of the environment
to quantitative measurements. A typical wireless sensor network (WSN) consists
of hundreds to thousands of such sensor nodes linked by a wireless medium. In
this paper, we present a comparative investigation of energy consumption for
few commercially available chipsets such as TR1001, CC1000 and CC1010 based on
different scheduling methods for two types of deployment strategies. We
conducted our experiment within the OMNeT++ simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4529</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4529</id><created>2010-09-23</created><authors><author><keyname>Schwarz</keyname><forenames>Ulrich M.</forenames></author></authors><title>A PTAS for Scheduling with Tree Assignment Restrictions</title><categories>cs.DS</categories><comments>6 pages</comments><msc-class>68W25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheduling with assignment restrictions is an important special case of
scheduling unrelated machines which has attracted much attention in the recent
past. While a lower bound on approximability of 3/2 is known for its most
general setting, subclasses of the problem admit polynomial-time approximation
schemes. This note provides a PTAS for tree-like hierarchical structures,
improving on a recent 4/3-approximation by Huo and Leung.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4556</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4556</id><created>2010-09-23</created><authors><author><keyname>Gautier</keyname><forenames>Maxime</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Janot</keyname><forenames>Alexandre</forenames><affiliation>LCPC</affiliation></author><author><keyname>Vandanjon</keyname><forenames>Pierre-Olivier</forenames><affiliation>LCPC</affiliation></author></authors><title>A new closed-loop output error method for parameter identification of
  robot dynamics</title><categories>cs.RO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Off-line robot dynamic identification methods are mostly based on the use of
the inverse dynamic model, which is linear with respect to the dynamic
parameters. This model is sampled while the robot is tracking reference
trajectories that excite the system dynamics. This allows using linear
least-squares techniques to estimate the parameters. The efficiency of this
method has been proved through the experimental identification of many
prototypes and industrial robots. However, this method requires the joint
force/torque and position measurements and the estimate of the joint velocity
and acceleration, through the bandpass filtering of the joint position at high
sampling rates. The proposed new method requires only the joint force/torque
measurement. It is a closed-loop output error method where the usual joint
position output is replaced by the joint force/torque. It is based on a
closed-loop simulation of the robot using the direct dynamic model, the same
structure of the control law, and the same reference trajectory for both the
actual and the simulated robot. The optimal parameters minimize the 2-norm of
the error between the actual force/torque and the simulated force/torque. This
is a non-linear least-squares problem which is dramatically simplified using
the inverse dynamic model to obtain an analytical expression of the simulated
force/torque, linear in the parameters. A validation experiment on a 2
degree-of-freedom direct drive robot shows that the new method is efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4563</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4563</id><created>2010-09-23</created><authors><author><keyname>Ayyasamy</keyname><forenames>S.</forenames></author><author><keyname>Sivanandam</keyname><forenames>S. N.</forenames></author></authors><title>A Cluster Based Replication Architecture for Load Balancing in
  Peer-to-Peer Content Distribution</title><categories>cs.NI</categories><comments>15 pages, 8 figures</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.2, No.5, September 2010</journal-ref><doi>10.5121/ijcnc.2010.2510</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In P2P systems, large volumes of data are declustered naturally across a
large number of peers. But it is very difficult to control the initial data
distribution because every user has the freedom to share any data with other
users. The system scalability can be improved by distributing the load across
multiple servers which is proposed by replication. The large scale content
distribution systems were improved broadly using the replication techniques.
The demanded contents can be brought closer to the clients by multiplying the
source of information geographically, which in turn reduce both the access
latency and the network traffic. In addition to this, due to the intrinsic
dynamism of the P2P environment, static data distribution cannot be expected to
guarantee good load balancing. If the hot peers become bottleneck, it leads to
increased user response time and significant performance degradation of the
system. Hence an effective load balancing mechanism is necessary in such cases
and it can be attained efficiently by intelligent data replication. In this
paper, we propose a cluster based replication architecture for load-balancing
in peer-to-peer content distribution systems. In addition to an intelligent
replica placement technique, it also consists of an effective load balancing
technique. In the intelligent replica placement technique, peers are grouped
into strong and weak clusters based on their weight vector which comprises
available capacity, CPU speed, access latency and memory size. In order to
achieve complete load balancing across the system, an intracluster and
inter-cluster load balancing algorithms are proposed. We are able to show that
our proposed architecture attains less latency and better throughput with
reduced bandwidth usage, through the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4564</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4564</id><created>2010-09-23</created><authors><author><keyname>Siddiquee</keyname><forenames>Abu Bakar</forenames></author><author><keyname>Mazumder</keyname><forenames>Md. Ehsanul Hoque</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>A Constructive Algorithm for Feedforward Neural Networks for Medical
  Diagnostic Reasoning</title><categories>cs.NE</categories><comments>4 Pages, International Symposium</comments><journal-ref>Proc. MMU International Symposium on Information and
  Communications Technology (M2USIC 2004), Kuala Lumpur, Malaysia, pp. TS4B2:
  5-8, Oct. 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research is to search for alternatives to the resolution of complex
medical diagnosis where human knowledge should be apprehended in a general
fashion. Successful application examples show that human diagnostic
capabilities are significantly worse than the neural diagnostic system. Our
research describes a constructive neural network algorithm with
backpropagation; offer an approach for the incremental construction of
nearminimal neural network architectures for pattern classification. The
algorithm starts with minimal number of hidden units in the single hidden
layer; additional units are added to the hidden layer one at a time to improve
the accuracy of the network and to get an optimal size of a neural network. Our
algorithm was tested on several benchmarking classification problems including
Cancer1, Heart, and Diabetes with good generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4566</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4566</id><created>2010-09-23</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Islam</keyname><forenames>Md. Monirul</forenames></author></authors><title>An Algorithm to Extract Rules from Artificial Neural Networks for
  Medical Diagnosis Problems</title><categories>cs.NE</categories><comments>19 Pages, Internatiomal Journal</comments><journal-ref>International Journal of Information Technology (IJIT), Vol. 12,
  No. 8, pp. 41-59, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial neural networks (ANNs) have been successfully applied to solve a
variety of classification and function approximation problems. Although ANNs
can generally predict better than decision trees for pattern classification
problems, ANNs are often regarded as black boxes since their predictions cannot
be explained clearly like those of decision trees. This paper presents a new
algorithm, called rule extraction from ANNs (REANN), to extract rules from
trained ANNs for medical diagnosis problems. A standard three-layer feedforward
ANN with four-phase training is the basis of the proposed algorithm. In the
first phase, the number of hidden nodes in ANNs is determined automatically by
a constructive algorithm. In the second phase, irrelevant connections and input
nodes are removed from trained ANNs without sacrificing the predictive accuracy
of ANNs. The continuous activation values of the hidden nodes are discretized
by using an efficient heuristic clustering algorithm in the third phase.
Finally, rules are extracted from compact ANNs by examining the discretized
activation values of the hidden nodes. Extensive experimental studies on three
benchmark classification problems, i.e. breast cancer, diabetes and lenses,
demonstrate that REANN can generate high quality rules from ANNs, which are
comparable with other methods in terms of number of rules, average number of
conditions for a rule, and predictive accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4569</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4569</id><created>2010-09-23</created><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author><author><keyname>Jamalipour</keyname><forenames>Abbas</forenames></author></authors><title>Fastest Distributed Consensus on Star-Mesh Hybrid Sensor Networks</title><categories>cs.IT cs.DM math.IT</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving Fastest Distributed Consensus (FDC) averaging problem over sensor
networks with different topologies has received some attention recently and one
of the well known topologies in this issue is star-mesh hybrid topology. Here
in this work we present analytical solution for the problem of FDC algorithm by
means of stratification and semidefinite programming, for the Star-Mesh Hybrid
network with K-partite core (SMHK) which has rich symmetric properties. Also
the variations of asymptotic and per step convergence rate of SMHK network
versus its topological parameters have been studied numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4570</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4570</id><created>2010-09-23</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Islam</keyname><forenames>Md. Monirul</forenames></author></authors><title>Extraction of Symbolic Rules from Artificial Neural Networks</title><categories>cs.NE</categories><comments>7 Pages, WASET Transactions</comments><journal-ref>WASET Transactions on Science, Engineering and Technology, Vol.
  10, pp. 271-277, Dec. 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although backpropagation ANNs generally predict better than decision trees do
for pattern classification problems, they are often regarded as black boxes,
i.e., their predictions cannot be explained as those of decision trees. In many
applications, it is desirable to extract knowledge from trained ANNs for the
users to gain a better understanding of how the networks solve the problems. A
new rule extraction algorithm, called rule extraction from artificial neural
networks (REANN) is proposed and implemented to extract symbolic rules from
ANNs. A standard three-layer feedforward ANN is the basis of the algorithm. A
four-phase training algorithm is proposed for backpropagation learning.
Explicitness of the extracted rules is supported by comparing them to the
symbolic rules generated by other methods. Extracted rules are comparable with
other methods in terms of number of rules, average number of conditions for a
rule, and predictive accuracy. Extensive experimental studies on several
benchmarks classification problems, such as breast cancer, iris, diabetes, and
season classification problems, demonstrate the effectiveness of the proposed
approach with good generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4572</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4572</id><created>2010-09-23</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Hasan</keyname><forenames>Ahmed Ryadh</forenames></author><author><keyname>Siddiquee</keyname><forenames>Abu Bakar</forenames></author><author><keyname>Mazumder</keyname><forenames>Md. Ehsanul Hoque</forenames></author></authors><title>Medical diagnosis using neural network</title><categories>cs.NE</categories><comments>4 pages, International Conference</comments><journal-ref>Proc. 3rd International Conference on Electrical &amp; Computer
  Engineering (ICECE 2004), Dhaka Bangladesh, pp. 537-540, Dec. 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research is to search for alternatives to the resolution of complex
medical diagnosis where human knowledge should be apprehended in a general
fashion. Successful application examples show that human diagnostic
capabilities are significantly worse than the neural diagnostic system. This
paper describes a modified feedforward neural network constructive algorithm
(MFNNCA), a new algorithm for medical diagnosis. The new constructive algorithm
with backpropagation; offer an approach for the incremental construction of
near-minimal neural network architectures for pattern classification. The
algorithm starts with minimal number of hidden units in the single hidden
layer; additional units are added to the hidden layer one at a time to improve
the accuracy of the network and to get an optimal size of a neural network. The
MFNNCA was tested on several benchmarking classification problems including the
cancer, heart disease and diabetes. Experimental results show that the MFNNCA
can produce optimal neural network architecture with good generalization
ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4574</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4574</id><created>2010-09-23</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Haider</keyname><forenames>Farhana</forenames></author></authors><title>A hybrid learning algorithm for text classification</title><categories>cs.NE cs.IR cs.LG</categories><comments>4 pages, International Conference</comments><journal-ref>Proc. 3rd International Conference on Electrical &amp; Computer
  Engineering (ICECE 2004), Dhaka Bangladesh, pp. 577-580, Dec. 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text classification is the process of classifying documents into predefined
categories based on their content. Existing supervised learning algorithms to
automatically classify text need sufficient documents to learn accurately. This
paper presents a new algorithm for text classification that requires fewer
documents for training. Instead of using words, word relation i.e association
rules from these words is used to derive feature set from preclassified text
documents. The concept of Naive Bayes classifier is then used on derived
features and finally only a single concept of Genetic Algorithm has been added
for final classification. Experimental results show that the classifier build
this way is more accurate than the existing text classification systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4581</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4581</id><created>2010-09-23</created><authors><author><keyname>Hassouni</keyname><forenames>Mohammed EL</forenames></author><author><keyname>Aboutajdine</keyname><forenames>Driss</forenames></author></authors><title>3D-Mesh denoising using an improved vertex based anisotropic diffusion</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with an improvement of vertex based nonlinear diffusion for
mesh denoising. This method directly filters the position of the vertices using
Laplace, reduced centered Gaussian and Rayleigh probability density functions
as diffusivities. The use of these PDFs improves the performance of a
vertex-based diffusion method which are adapted to the underlying mesh
structure. We also compare the proposed method to other mesh denoising methods
such as Laplacian flow, mean, median, min and the adaptive MMSE filtering. To
evaluate these methods of filtering, we use two error metrics. The first is
based on the vertices and the second is based on the normals. Experimental
results demonstrate the effectiveness of our proposed method in comparison with
the existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4582</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4582</id><created>2010-09-23</created><authors><author><keyname>Rahman</keyname><forenames>Chowdhury Mofizur</forenames></author><author><keyname>Sohel</keyname><forenames>Ferdous Ahmed</forenames></author><author><keyname>Naushad</keyname><forenames>Parvez</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Text Classification using the Concept of Association Rule of Data Mining</title><categories>cs.LG cs.DB cs.IR</categories><comments>8 Pages, International Conference</comments><journal-ref>Proc. International Conference on Information Technology,
  Kathmandu, Nepal, pp. 234-241, May. 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the amount of online text increases, the demand for text classification to
aid the analysis and management of text is increasing. Text is cheap, but
information, in the form of knowing what classes a text belongs to, is
expensive. Automatic classification of text can provide this information at low
cost, but the classifiers themselves must be built with expensive human effort,
or trained from texts which have themselves been manually classified. In this
paper we will discuss a procedure of classifying text using the concept of
association rule of data mining. Association rule mining technique has been
used to derive feature set from pre-classified text documents. Naive Bayes
classifier is then used on derived features for final classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4586</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4586</id><created>2010-09-23</created><authors><author><keyname>Alam</keyname><forenames>Md. Hijbul</forenames></author><author><keyname>Masum</keyname><forenames>Abdul Kadar Muhammad</forenames></author><author><keyname>Hassan</keyname><forenames>Mohammad Mahadi</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Optimal Bangla Keyboard Layout using Association Rule of Data Mining</title><categories>cs.AI</categories><comments>3 Pages, International Conference</comments><journal-ref>Proc. 7th International Conference on Computer and Information
  Technology (ICCIT 2004), Dhaka, Bangladesh, pp. 679-681, Dec. 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an optimal Bangla Keyboard Layout, which distributes
the load equally on both hands so that maximizing the ease and minimizing the
effort. Bangla alphabet has a large number of letters, for this it is difficult
to type faster using Bangla keyboard. Our proposed keyboard will maximize the
speed of operator as they can type with both hands parallel. Here we use the
association rule of data mining to distribute the Bangla characters in the
keyboard. First, we analyze the frequencies of data consisting of monograph,
digraph and trigraph, which are derived from data wire-house, and then used
association rule of data mining to distribute the Bangla characters in the
layout. Finally, we propose a Bangla Keyboard Layout. Experimental results on
several keyboard layout shows the effectiveness of the proposed approach with
better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4590</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4590</id><created>2010-09-23</created><authors><author><keyname>Azad</keyname><forenames>Md. Abul Kalam</forenames></author><author><keyname>Sharmeen</keyname><forenames>Rezwana</forenames></author><author><keyname>Ahmad</keyname><forenames>Shabbir</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>A Unique 10 Segment Display for Bengali Numerals</title><categories>cs.AR</categories><comments>3 Pages, International Conference</comments><journal-ref>Proc. 8th International Conference on Computer and Information
  Technology (ICCIT 2005), Dhaka, Bangladesh, pp. 97-99, Dec. 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmented display is widely used for efficient display of alphanumeric
characters. English numerals are displayed by 7 segment and 16 segment display.
The segment size is uniform in this two display architecture. Display
architecture using 8, 10, 11, 18 segments have been proposed for Bengali
numerals 0...9 yet no display architecture is designed using segments of
uniform size and uniform power consumption. In this paper we have proposed a
uniform 10 segment architecture for Bengali numerals. This segment architecture
uses segments of uniform size and no bent segment is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4595</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4595</id><created>2010-09-23</created><authors><author><keyname>Schulze</keyname><forenames>Henrik</forenames></author></authors><title>Diversity Spectra of Spatial Multipath Fading Processes</title><categories>cs.IT math.IT</categories><comments>32 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the spatial diversity of a multipath fading process for a finite
region or curve in the plane. By means of the Karhunen-Lo\`eve (KL) expansion,
this diversity can be characterised by the eigenvalue spectrum of the spatial
autocorrelation kernel. This justifies to use the term diversity spectrum for
it. We show how the diversity spectrum can be calculated for any such
geometrical object and any fading statistics represented by the power azimuth
spectrum (PAS). We give rigorous estimates for the accuracy of the numerically
calculated eigenvalues. The numerically calculated diversity spectra provide
useful hints for the optimisation of the geometry of an antenna array.
Furthermore, for a channel coded system, they allow to evaluate the time
interleaving depth that is necessary to exploit the diversity gain of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4597</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4597</id><created>2010-09-23</created><updated>2013-09-09</updated><authors><author><keyname>Giorgi</keyname><forenames>Pascal</forenames><affiliation>LIRMM</affiliation></author></authors><title>On Polynomial Multiplication in Chebyshev Basis</title><categories>cs.CC cs.PF</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Computers 61, 6 (2012) 780-789</journal-ref><doi>10.1109/TC.2011.110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper Lima, Panario and Wang have provided a new method to
multiply polynomials in Chebyshev basis which aims at reducing the total number
of multiplication when polynomials have small degree. Their idea is to use
Karatsuba's multiplication scheme to improve upon the naive method but without
being able to get rid of its quadratic complexity. In this paper, we extend
their result by providing a reduction scheme which allows to multiply
polynomial in Chebyshev basis by using algorithms from the monomial basis case
and therefore get the same asymptotic complexity estimate. Our reduction allows
to use any of these algorithms without converting polynomials input to monomial
basis which therefore provide a more direct reduction scheme then the one using
conversions. We also demonstrate that our reduction is efficient in practice,
and even outperform the performance of the best known algorithm for Chebyshev
basis when polynomials have large degree. Finally, we demonstrate a linear time
equivalence between the polynomial multiplication problem under monomial basis
and under Chebyshev basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4601</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4601</id><created>2010-09-22</created><authors><author><keyname>Katelman</keyname><forenames>Michael</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Meseguer</keyname><forenames>Jos&#xe9;</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Using the PALS Architecture to Verify a Distributed Topology Control
  Protocol for Wireless Multi-Hop Networks in the Presence of Node Failures</title><categories>cs.LO</categories><comments>In Proceedings RTRTS 2010, arXiv:1009.3982</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 36, 2010, pp. 101-116</journal-ref><doi>10.4204/EPTCS.36.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PALS architecture reduces distributed, real-time asynchronous system
design to the design of a synchronous system under reasonable requirements.
Assuming logical synchrony leads to fewer system behaviors and provides a
conceptually simpler paradigm for engineering purposes. One of the current
limitations of the framework is that from a set of independent &quot;synchronous
machines&quot;, one must compose the entire synchronous system by hand, which is
tedious and error-prone. We use Maude's meta-level to automatically generate a
synchronous composition from user-provided component machines and a description
of how the machines communicate with each other. We then use the new
capabilities to verify the correctness of a distributed topology control
protocol for wireless networks in the presence of nodes that may fail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4602</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4602</id><created>2010-09-23</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>Geoglyphs of Titicaca as an ancient example of graphic design</title><categories>cs.GR</categories><comments>Keywords: Geoglyphs, History of Graphics, Image processing, Satellite
  maps, Archaeology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes an ancient landscape design as an example of graphic
design for an age and place where no written documents existed. It is created
by a network of earthworks, which constitute the remains of an extensive
ancient agricultural system. It can be seen by means of the Google satellite
imagery on the Peruvian region near the Titicaca Lake, as a texture
superimposed to the background landform. In this texture, many drawings
(geoglyphs) can be observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4606</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4606</id><created>2010-09-23</created><updated>2010-10-31</updated><authors><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Constantin</keyname><forenames>Florin</forenames></author></authors><title>Sequential item pricing for unlimited supply</title><categories>cs.GT</categories><comments>18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the extent to which price updates can increase the revenue of
a seller with little prior information on demand. We study prior-free revenue
maximization for a seller with unlimited supply of n item types facing m myopic
buyers present for k &lt; log n days. For the static (k = 1) case, Balcan et al.
[2] show that one random item price (the same on each item) yields revenue
within a \Theta(log m + log n) factor of optimum and this factor is tight. We
define the hereditary maximizers property of buyer valuations (satisfied by any
multi-unit or gross substitutes valuation) that is sufficient for a significant
improvement of the approximation factor in the dynamic (k &gt; 1) setting. Our
main result is a non-increasing, randomized, schedule of k equal item prices
with expected revenue within a O((log m + log n) / k) factor of optimum for
private valuations with hereditary maximizers. This factor is almost tight: we
show that any pricing scheme over k days has a revenue approximation factor of
at least (log m + log n) / (3k). We obtain analogous matching lower and upper
bounds of \Theta((log n) / k) if all valuations have the same maximum. We
expect our upper bound technique to be of broader interest; for example, it can
significantly improve the result of Akhlaghpour et al. [1]. We also initiate
the study of revenue maximization given allocative externalities (i.e.
influences) between buyers with combinatorial valuations. We provide a rather
general model of positive influence of others' ownership of items on a buyer's
valuation. For affine, submodular externalities and valuations with hereditary
maximizers we present an influence-and-exploit (Hartline et al. [13]) marketing
strategy based on our algorithm for private valuations. This strategy preserves
our approximation factor, despite an affine increase (due to externalities) in
the optimum revenue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4610</identifier>
 <datestamp>2011-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4610</id><created>2010-09-23</created><updated>2011-11-30</updated><authors><author><keyname>Rathi</keyname><forenames>Vishwambhar</forenames></author><author><keyname>Andersson</keyname><forenames>Mattias</forenames></author><author><keyname>Thobaben</keyname><forenames>Ragnar</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Performance Analysis and Design of Two Edge Type LDPC Codes for the BEC
  Wiretap Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory. Updated version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider transmission over a wiretap channel where both the main channel
and the wiretapper's channel are Binary Erasure Channels (BEC). We propose a
code construction method using two edge type LDPC codes based on the coset
encoding scheme. Using a standard LDPC ensemble with a given threshold over the
BEC, we give a construction for a two edge type LDPC ensemble with the same
threshold. If the given standard LDPC ensemble has degree two variable nodes,
our construction gives rise to degree one variable nodes in the code used over
the main channel. This results in zero threshold over the main channel. In
order to circumvent this problem, we numerically optimize the degree
distribution of the two edge type LDPC ensemble. We find that the resulting
ensembles are able to perform close to the boundary of the rate-equivocation
region of the wiretap channel.
  There are two performance criteria for a coding scheme used over a wiretap
channel: reliability and secrecy. The reliability measure corresponds to the
probability of decoding error for the intended receiver. This can be easily
measured using density evolution recursion. However, it is more challenging to
characterize secrecy, corresponding to the equivocation of the message for the
wiretapper. M\'easson, Montanari, and Urbanke have shown how the equivocation
can be measured for a broad range of standard LDPC ensembles for transmission
over the BEC under the point-to-point setup. By generalizing the method of
M\'easson, Montanari, and Urbanke to two edge type LDPC ensembles, we show how
the equivocation for the wiretapper can be computed. We find that relatively
simple constructions give very good secrecy performance and are close to the
secrecy capacity. However finding explicit sequences of two edge type LDPC
ensembles which achieve secrecy capacity is a more difficult problem. We pose
it as an interesting open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4625</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4625</id><created>2010-09-07</created><authors><author><keyname>Calvi</keyname><forenames>Alberto</forenames></author><author><keyname>Ranise</keyname><forenames>Silvio</forenames></author><author><keyname>Vigan&#xf2;</keyname><forenames>Luca</forenames></author></authors><title>Automated Validation of Security-sensitive Web Services specified in
  BPEL and RBAC (Extended Version)</title><categories>cs.CR cs.LO cs.SE</categories><comments>12 pages, 3 figures, short version to appear in the Proceedings of
  WOSS'10, 1st Workshop on Software Services: Frameworks and Platforms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formalize automated analysis techniques for the validation of web services
specified in BPEL and a RBAC variant tailored to BPEL. The idea is to use
decidable fragments of first-order logic to describe the state space of a
certain class of web services and then use state-of-the-art SMT solvers to
handle their reachability problems. To assess the practical viability of our
approach, we have developed a prototype tool implementing our techniques and
applied it to a digital contract signing service inspired by an industrial case
study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4638</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4638</id><created>2010-08-16</created><authors><author><keyname>Noshad</keyname><forenames>Mohammad</forenames></author><author><keyname>Jamshidi</keyname><forenames>Kambiz</forenames></author></authors><title>Novel Codes Family for Modified Spectral-Amplitude-Coding OCDMA Systems
  and Performance Analysis</title><categories>cs.IT math.IT</categories><journal-ref>Journal of Optical Communications and Networking, Vol. 2, No. 6,
  June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel family of codes for modified spectral-amplitude-coding
optical code division multiple access (SAC-OCDMA) is introduced. The proposed
codes exist for more number of processing gains comparing to the previously
reported codes. In the network using these codes, the number of users can be
extended without any essential changes in the previous transmitters. In this
study, we propose a construction method for these codes and compare their
performance with previously reported codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4641</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4641</id><created>2010-09-23</created><updated>2010-09-24</updated><authors><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Decomposition of Geometric Set Systems and Graphs</title><categories>math.CO cs.CG</categories><comments>This is my PhD thesis</comments><report-no>EPFL TH\`ESE N{\deg} 4821 (2010)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two decomposition problems in combinatorial geometry. The first part
deals with the decomposition of multiple coverings of the plane. We say that a
planar set is cover-decomposable if there is a constant m such that any m-fold
covering of the plane with its translates is decomposable into two disjoint
coverings of the whole plane. Pach conjectured that every convex set is
cover-decomposable. We verify his conjecture for polygons. Moreover, if m is
large enough, we prove that any m-fold covering can even be decomposed into k
coverings. Then we show that the situation is exactly the opposite in 3
dimensions, for any polyhedron and any $m$ we construct an m-fold covering of
the space that is not decomposable. We also give constructions that show that
concave polygons are usually not cover-decomposable. We start the first part
with a detailed survey of all results on the cover-decomposability of polygons.
  The second part investigates another geometric partition problem, related to
planar representation of graphs. The slope number of a graph G is the smallest
number s with the property that G has a straight-line drawing with edges of at
most s distinct slopes and with no bends. We examine the slope number of
bounded degree graphs. Our main results are that if the maximum degree is at
least 5, then the slope number tends to infinity as the number of vertices
grows but every graph with maximum degree at most 3 can be embedded with only
five slopes. We also prove that such an embedding exists for the related notion
called slope parameter. Finally, we study the planar slope number, defined only
for planar graphs as the smallest number s with the property that the graph has
a straight-line drawing in the plane without any crossings such that the edges
are segments of only s distinct slopes. We show that the planar slope number of
planar graphs with bounded degree is bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4642</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4642</id><created>2010-09-09</created><authors><author><keyname>Mavromoustakis</keyname><forenames>Constandinos X.</forenames></author><author><keyname>Karatza</keyname><forenames>Helen D.</forenames></author></authors><title>A Gossip-based optimistic replication for efficient delay-sensitive
  streaming using an interactive middleware support system</title><categories>cs.DC cs.MM</categories><comments>IEEE Systems Journal 2010</comments><doi>10.1109/JSYST.2010.2047172</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  While sharing resources the efficiency is substantially degraded as a result
of the scarceness of availability of the requested resources in a multiclient
support manner. These resources are often aggravated by many factors like the
temporal constraints for availability or node flooding by the requested
replicated file chunks. Thus replicated file chunks should be efficiently
disseminated in order to enable resource availability on-demand by the mobile
users. This work considers a cross layered middleware support system for
efficient delay-sensitive streaming by using each device's connectivity and
social interactions in a cross layered manner. The collaborative streaming is
achieved through the epidemically replicated file chunk policy which uses a
transition-based approach of a chained model of an infectious disease with
susceptible, infected, recovered and death states. The Gossip-based stateful
model enforces the mobile nodes whether to host a file chunk or not or, when no
longer a chunk is needed, to purge it. The proposed model is thoroughly
evaluated through experimental simulation taking measures for the effective
throughput Eff as a function of the packet loss parameter in contrast with the
effectiveness of the replication Gossip-based policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4647</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4647</id><created>2010-09-23</created><updated>2010-10-28</updated><authors><author><keyname>Adler</keyname><forenames>Stephen L.</forenames></author></authors><title>Parameterized Adaptive Multidimensional Integration Routines (PAMIR):
  Localization by Repeated 2^p Subdivision</title><categories>hep-ph cs.MS cs.NA math.NA</categories><comments>84 pages Latex, figures included; minor changes to program
  descriptions and tildes added to Eqs. (63) and (65)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book draft gives the theory of a new method for p dimensional adaptive
integration by repeated 2^p subdivision of simplexes and hypercubes. A new
method of constructing high order integration routines for these geometries
permits adjustable samplings of the integration region controlled by user
supplied parameters. An outline of the programs and use instructions are also
included in the draft. The fortran programs are not included, but will be
published with this draft as a book.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4672</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4672</id><created>2010-09-23</created><authors><author><keyname>Patra</keyname><forenames>Tapas Kumar</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>Threshold Policy for Route Discovery Initiation in Mobile Ad hoc
  Networks</title><categories>cs.NI</categories><comments>5 pages; 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Achieving optimal transmission throughput in data networks in a multi-hop
wireless networks is fundamental but hard problem. The situation is aggravated
when nodes are mobile. Further, multi-rate system make the analysis of
throughput more complicated. In mobile scenario, link may break or be created
as nodes are moving within communication range. `Route Discovery' which is to
find the optimal route and transmission schedule is an important issue. Route
discovery entails some cost; so one would not like to initiate discovery too
often. On the other hand, not discovering reasonably often entails the risk of
being stuck with a suboptimal route and/or schedule, which hurts end-to-end
throughput. The implementation of the routing decision problem in one
dimensional mobile ad hoc network as Markov decision process problem is already
is discussed in the paper [1]. A heuristic based on threshold policy is
discussed in the same paper without giving a way to find the threshold. In this
paper, we suggested a rule for setting the threshold, given the parameters of
the system. We also point out that our results remain valid in a slightly
different mobility model; this model is a first step towards an `open' network
in which existing relay nodes can leave and/or new relay nodes can join the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4674</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4674</id><created>2010-09-23</created><updated>2012-06-27</updated><authors><author><keyname>Andrei</keyname><forenames>Raluca Mihaela</forenames></author><author><keyname>Callieri</keyname><forenames>Marco</forenames></author><author><keyname>Zini</keyname><forenames>Maria Francesca</forenames></author><author><keyname>Loni</keyname><forenames>Tiziana</forenames></author><author><keyname>Maraziti</keyname><forenames>Giuseppe</forenames></author><author><keyname>Pan</keyname><forenames>Mike Chen</forenames></author><author><keyname>Zopp&#xe8;</keyname><forenames>Monica</forenames></author></authors><title>Intuitive representation of surface properties of biomolecules using
  BioBlender</title><categories>q-bio.BM cs.GR</categories><comments>One of two strictly related papers. The other one is: Zini et al.
  'BioBlender: Fast and Efficient All Atom Morphing of Proteins Using Blender
  Game Engine'. This paper is 12 pages, with 6 Figures</comments><journal-ref>Andrei et al.: Intuitive representation of surface properties of
  biomolecules using BioBlender. BMC Bioinformatics 2012 13 (Suppl 4):S16</journal-ref><doi>10.1186/1471-2105-13-S4-S16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this and the associated article 'BioBlender: Fast and Efficient All Atom
Morphing of Proteins Using Blender Game Engine', by Zini et al., we present
BioBlender, a complete instrument for the elaboration of motion (Zini et al.)
and the visualization (here) of proteins and other macromolecules, using
instruments of computer graphics. The availability of protein structures
enables the study of their surfaces and surface properties such as
electrostatic potential (EP) and hydropathy (MLP), based on atomic
contribution. Recent advances in 3D animation and rendering software have not
yet been exploited for the representation of proteins and other biological
molecules in an intuitive, animated form. Taking advantage of an open-source,
3D animation and rendering software, Blender, we developed BioBlender, a
package dedicated to biological work: elaboration of proteins' motions with the
simultaneous visualization of chemical and physical features. EP and MLP are
calculated using physico-chemical programs and custom programs and scripts,
organized and accessed within BioBlender interface. A new visual code is
introduced for MLP visualization: a range of optical features that permits a
photorealistic rendering of its spatial distribution on the surface of the
protein. EP is represented as animated line particles that flow along field
lines proportional to the total charge of the protein. Our system permits EP
and MLP visualization of molecules and, in the case of moving proteins, the
continuous perception of these features, calculated for each intermediate
conformation. Using real world tactile/sight feelings, the nanoscale world of
proteins becomes more understandable, familiar to our everyday life, making it
easier to introduce &quot;un-seen&quot; phenomena (concepts) such as hydropathy or
charges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4677</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4677</id><created>2010-09-23</created><updated>2011-08-12</updated><authors><author><keyname>Dumitriu</keyname><forenames>Ioana</forenames></author></authors><title>Smallest eigenvalue distributions for two classes of $\beta$-Jacobi
  ensembles</title><categories>math.PR cs.DC cs.NA math-ph math.MP</categories><comments>15 pages, 6 figures</comments><msc-class>60B20, 15B52</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute the exact and limiting smallest eigenvalue distributions for two
classes of $\beta$-Jacobi ensembles not covered by previous studies. In the
general $\beta$ case, these distributions are given by multivariate
hypergeometric ${}_2F_{1}^{2/\beta}$ functions, whose behavior can be analyzed
asymptotically for special values of $\beta$ which include $\beta \in
2\mathbb{N}_{+}$ as well as for $\beta = 1$. Interest in these objects stems
from their connections (in the $\beta = 1,2$ cases) to principal submatrices of
Haar-distributed (orthogonal, unitary) matrices appearing in randomized,
communication-optimal, fast, and stable algorithms for eigenvalue computations
\cite{DDH07}, \cite{BDD10}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4683</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4683</id><created>2010-09-23</created><authors><author><keyname>Boyarshinov</keyname><forenames>Victor</forenames></author><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Efficient Computation of Optimal Trading Strategies</title><categories>cs.CE q-fin.CP</categories><comments>45 pages; working paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the return series for a set of instruments, a \emph{trading strategy}
is a switching function that transfers wealth from one instrument to another at
specified times. We present efficient algorithms for constructing (ex-post)
trading strategies that are optimal with respect to the total return, the
Sterling ratio and the Sharpe ratio. Such ex-post optimal strategies are useful
analysis tools. They can be used to analyze the &quot;profitability of a market&quot; in
terms of optimal trading; to develop benchmarks against which real trading can
be compared; and, within an inductive framework, the optimal trades can be used
to to teach learning systems (predictors) which are then used to identify
future trading opportunities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4693</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4693</id><created>2010-09-23</created><authors><author><keyname>Elser</keyname><forenames>Veit</forenames></author><author><keyname>Eisebitt</keyname><forenames>Stefan</forenames></author></authors><title>Uniqueness transition in noisy phase retrieval</title><categories>physics.data-an cs.IT math.IT physics.optics</categories><comments>19 pages, 8 figures</comments><doi>10.1088/1367-2630/13/2/023001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous criteria for the feasibility of reconstructing phase information
from intensity measurements, both in x-ray crystallography and more recently in
coherent x-ray imaging, have been based on the Maxwell constraint counting
principle. We propose a new criterion, based on Shannon's mutual information,
that is better suited for noisy data or contrast that has strong priors not
well modeled by continuous variables. A natural application is magnetic domain
imaging, where the criterion for uniqueness in the reconstruction takes the
form that the number of photons, per pixel of contrast in the image, exceeds a
certain minimum. Detailed studies of a simple model show that the uniqueness
transition is of the type exhibited by spin glasses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4719</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4719</id><created>2010-09-23</created><authors><author><keyname>Biatov</keyname><forenames>Konstantin</forenames></author></authors><title>A Fast Audio Clustering Using Vector Quantization and Second Order
  Statistics</title><categories>cs.SD cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an effective unsupervised speaker indexing approach. We
suggest a two stage algorithm to speed-up the state-of-the-art algorithm based
on the Bayesian Information Criterion (BIC). In the first stage of the merging
process a computationally cheap method based on the vector quantization (VQ) is
used. Then in the second stage a more computational expensive technique based
on the BIC is applied. In the speaker indexing task a turning parameter or a
threshold is used. We suggest an on-line procedure to define the value of a
turning parameter without using development data. The results are evaluated
using 10 hours of audio data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4733</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4733</id><created>2010-09-23</created><updated>2011-07-25</updated><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>El-Azouzi</keyname><forenames>Rachid</forenames></author><author><keyname>Menasche</keyname><forenames>Daniel Sadoc</forenames></author><author><keyname>Xu</keyname><forenames>Yuedong</forenames></author></authors><title>Forever Young: Aging Control For Smartphones In Hybrid Networks</title><categories>cs.PF</categories><comments>See also http://www-net.cs.umass.edu/~sadoc/agecontrol/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The demand for Internet services that require frequent updates through small
messages, such as microblogging, has tremendously grown in the past few years.
Although the use of such applications by domestic users is usually free, their
access from mobile devices is subject to fees and consumes energy from limited
batteries. If a user activates his mobile device and is in range of a service
provider, a content update is received at the expense of monetary and energy
costs. Thus, users face a tradeoff between such costs and their messages aging.
The goal of this paper is to show how to cope with such a tradeoff, by devising
\emph{aging control policies}. An aging control policy consists of deciding,
based on the current utility of the last message received, whether to activate
the mobile device, and if so, which technology to use (WiFi or 3G). We present
a model that yields the optimal aging control policy. Our model is based on a
Markov Decision Process in which states correspond to message ages. Using our
model, we show the existence of an optimal strategy in the class of threshold
strategies, wherein users activate their mobile devices if the age of their
messages surpasses a given threshold and remain inactive otherwise. We then
consider strategic content providers (publishers) that offer \emph{bonus
packages} to users, so as to incent them to download updates of advertisement
campaigns. We provide simple algorithms for publishers to determine optimal
bonus levels, leveraging the fact that users adopt their optimal aging control
strategies. The accuracy of our model is validated against traces from the
UMass DieselNet bus network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4739</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4739</id><created>2010-09-21</created><authors><author><keyname>Tavenard</keyname><forenames>Romain</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Amsaleg</keyname><forenames>Laurent</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>J&#xe9;gou</keyname><forenames>Herv&#xe9;</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>Balancing clusters to reduce response time variability in large scale
  image search</title><categories>cs.CV</categories><proxy>ccsd</proxy><report-no>RR-7387</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many algorithms for approximate nearest neighbor search in high-dimensional
spaces partition the data into clusters. At query time, in order to avoid
exhaustive search, an index selects the few (or a single) clusters nearest to
the query point. Clusters are often produced by the well-known $k$-means
approach since it has several desirable properties. On the downside, it tends
to produce clusters having quite different cardinalities. Imbalanced clusters
negatively impact both the variance and the expectation of query response
times. This paper proposes to modify $k$-means centroids to produce clusters
with more comparable sizes without sacrificing the desirable properties.
Experiments with a large scale collection of image descriptors show that our
algorithm significantly reduces the variance of response times without
seriously impacting the search quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4741</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4741</id><created>2010-09-23</created><updated>2011-04-25</updated><authors><author><keyname>H&#xe4;nggi</keyname><forenames>Esther</forenames></author><author><keyname>Wullschleger</keyname><forenames>J&#xfc;rg</forenames></author></authors><title>Tight bounds for classical and quantum coin flipping</title><categories>quant-ph cs.CR</categories><comments>18 pages, 2 figures; v2: published version</comments><journal-ref>Proceedings of TCC 2011, p 468-485</journal-ref><doi>10.1007/978-3-642-19571-6_28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coin flipping is a cryptographic primitive for which strictly better
protocols exist if the players are not only allowed to exchange classical, but
also quantum messages. During the past few years, several results have appeared
which give a tight bound on the range of implementable unconditionally secure
coin flips, both in the classical as well as in the quantum setting and for
both weak as well as strong coin flipping. But the picture is still incomplete:
in the quantum setting, all results consider only protocols with perfect
correctness, and in the classical setting tight bounds for strong coin flipping
are still missing. We give a general definition of coin flipping which unifies
the notion of strong and weak coin flipping (it contains both of them as
special cases) and allows the honest players to abort with a certain
probability. We give tight bounds on the achievable range of parameters both in
the classical and in the quantum setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4757</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4757</id><created>2010-09-23</created><updated>2010-11-25</updated><authors><author><keyname>Dhillon</keyname><forenames>Vikram</forenames></author></authors><title>Modeling Instantaneous Changes In Natural Scenes</title><categories>cs.CV</categories><comments>20 pages double spaced</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This project aims to create 3d model of the natural world and model changes
in it instantaneously. A framework for modeling instantaneous changes natural
scenes in real time using Lagrangian Particle Framework and a fluid-particle
grid approach is presented. This project is presented in the form of a
proof-based system where we show that the design is very much possible but
currently we only have selective scripts that accomplish the given job, a
complete software however is still under work. This research can be divided
into 3 distinct sections: the first one discusses a multi-camera rig that can
measure ego-motion accurately up to 88%, how this device becomes the backbone
of our framework, and some improvements devised to optimize a know framework
for depth maps and 3d structure estimation from a single still image called
make3d. The second part discusses the fluid-particle framework to model natural
scenes, presents some algorithms that we are using to accomplish this task and
we show how an application of our framework can extend make3d to model natural
scenes in real time. This part of the research constructs a bridge between
computer vision and computer graphics so that now ideas, answers and intuitions
that arose in the domain of computer graphics can now be applied to computer
vision and natural modeling. The final part of this research improves upon what
might become the first general purpose vision system using deep belief
architectures and provides another framework to improve the lower bound on
training images for boosting by using a variation of Restricted Boltzmann
machines (RBM). We also discuss other applications that might arise from our
work in these areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4766</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4766</id><created>2010-09-24</created><authors><author><keyname>Liu</keyname><forenames>Jun</forenames></author><author><keyname>Ye</keyname><forenames>Jieping</forenames></author></authors><title>Efficient L1/Lq Norm Regularization</title><categories>cs.LG</categories><comments>19 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Sparse learning has recently received increasing attention in many areas
including machine learning, statistics, and applied mathematics. The mixed-norm
regularization based on the L1/Lq norm with q &gt; 1 is attractive in many
applications of regression and classification in that it facilitates group
sparsity in the model. The resulting optimization problem is, however,
challenging to solve due to the structure of the L1/Lq -regularization.
Existing work deals with special cases including q = 2,infinity, and they
cannot be easily extended to the general case. In this paper, we propose an
efficient algorithm based on the accelerated gradient method for solving the
L1/Lq -regularized problem, which is applicable for all values of q larger than
1, thus significantly extending existing work. One key building block of the
proposed algorithm is the L1/Lq -regularized Euclidean projection (EP1q). Our
theoretical analysis reveals the key properties of EP1q and illustrates why
EP1q for the general q is significantly more challenging to solve than the
special cases. Based on our theoretical analysis, we develop an efficient
algorithm for EP1q by solving two zero finding problems. Experimental results
demonstrate the efficiency of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4773</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4773</id><created>2010-09-24</created><authors><author><keyname>Bui</keyname><forenames>Huyen Chi</forenames></author><author><keyname>Lacan</keyname><forenames>Jerome</forenames></author><author><keyname>Boucheret</keyname><forenames>Marie-Laure</forenames></author></authors><title>NCSA: A New Protocol for Random Multiple Access Based on Physical Layer
  Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>submitted to ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a random multiple access method for satellite
communications, named Network Coding-based Slotted Aloha (NCSA). The goal is to
improve diversity of data bursts on a slotted-ALOHA-like channel thanks to
error correcting codes and Physical-layer Network Coding (PNC). This scheme can
be considered as a generalization of the Contention Resolution Diversity
Slotted Aloha (CRDSA) where the different replicas of this system are replaced
by the different parts of a single word of an error correcting code. The
performance of this scheme is first studied through a density evolution
approach. Then, simulations confirm the CRDSA results by showing that, for a
time frame of $400$ slots, the achievable total throughput is greater than
$0.7\times C$, where $C$ is the maximal throughput achieved by a centralized
scheme. This paper is a first analysis of the proposed scheme which open
several perspectives. The most promising approach is to integrate collided
bursts into the decoding process in order to improve the obtained performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4780</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4780</id><created>2010-09-24</created><updated>2011-02-13</updated><authors><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Zhong</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Li</keyname><forenames>Yunzhou</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author><author><keyname>Xu</keyname><forenames>Xibin</forenames></author></authors><title>Spectrum Sharing between Cooperative Relay and Ad-hoc Networks: Dynamic
  Transmissions under Computation and Signaling Limitations</title><categories>cs.IT math.IT math.OC</categories><comments>5 pages, 3 figures, to appear in IEEE International Conference on
  Communications (ICC 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a spectrum sharing scenario between a cooperative relay
network (CRN) and a nearby ad-hoc network. In particular, we consider a dynamic
spectrum access and resource allocation problem of the CRN. Based on sensing
and predicting the ad-hoc transmission behaviors, the ergodic traffic collision
time between the CRN and ad-hoc network is minimized subject to an ergodic
uplink throughput requirement for the CRN. We focus on real-time implementation
of spectrum sharing policy under practical computation and signaling
limitations. In our spectrum sharing policy, most computation tasks are
accomplished off-line. Hence, little real-time calculation is required which
fits the requirement of practical applications. Moreover, the signaling
procedure and computation process are designed carefully to reduce the time
delay between spectrum sensing and data transmission, which is crucial for
enhancing the accuracy of traffic prediction and improving the performance of
interference mitigation. The benefits of spectrum sensing and cooperative relay
techniques are demonstrated by our numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4787</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4787</id><created>2010-09-24</created><authors><author><keyname>Berger</keyname><forenames>Itamar</forenames></author><author><keyname>Eldar</keyname><forenames>Bosmat</forenames></author><author><keyname>Zohar</keyname><forenames>Gal</forenames></author><author><keyname>Raveh</keyname><forenames>Barak</forenames></author><author><keyname>Halperin</keyname><forenames>Dan</forenames></author></authors><title>Improving the Quality of Non-Holonomic Motion by Hybridizing C-PRM Paths</title><categories>cs.RO</categories><comments>2 pages</comments><acm-class>I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling-based motion planners are an effective means for generating
collision-free motion paths. However, the quality of these motion paths, with
respect to different quality measures such as path length, clearance,
smoothness or energy, is often notoriously low. This problem is accentuated in
the case of non-holonomic sampling-based motion planning, in which the space of
feasible motion trajectories is restricted. In this study, we combine the C-PRM
algorithm by Song and Amato with our recently introduced path-hybridization
approach, for creating high quality non-holonomic motion paths, with
combinations of several different quality measures such as path length,
smoothness or clearance, as well as the number of reverse car motions. Our
implementation includes a variety of code optimizations that result in nearly
real-time performance, and which we believe can be extended with further
optimizations to a real-time tool for the planning of high-quality car-like
motion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4791</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4791</id><created>2010-09-24</created><updated>2010-11-01</updated><authors><author><keyname>Karasuyama</keyname><forenames>Masayuki</forenames></author><author><keyname>Harada</keyname><forenames>Naoyuki</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author><author><keyname>Takeuchi</keyname><forenames>Ichiro</forenames></author></authors><title>Multi-parametric Solution-path Algorithm for Instance-weighted Support
  Vector Machines</title><categories>cs.LG</categories><comments>Submitted to Journal of Machine Learning Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An instance-weighted variant of the support vector machine (SVM) has
attracted considerable attention recently since they are useful in various
machine learning tasks such as non-stationary data analysis, heteroscedastic
data modeling, transfer learning, learning to rank, and transduction. An
important challenge in these scenarios is to overcome the computational
bottleneck---instance weights often change dynamically or adaptively, and thus
the weighted SVM solutions must be repeatedly computed. In this paper, we
develop an algorithm that can efficiently and exactly update the weighted SVM
solutions for arbitrary change of instance weights. Technically, this
contribution can be regarded as an extension of the conventional solution-path
algorithm for a single regularization parameter to multiple instance-weight
parameters. However, this extension gives rise to a significant problem that
breakpoints (at which the solution path turns) have to be identified in
high-dimensional space. To facilitate this, we introduce a parametric
representation of instance weights. We also provide a geometric interpretation
in weight space using a notion of critical region: a polyhedron in which the
current affine solution remains to be optimal. Then we find breakpoints at
intersections of the solution path and boundaries of polyhedrons. Through
extensive experiments on various practical applications, we demonstrate the
usefulness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4797</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4797</id><created>2010-09-24</created><updated>2010-12-29</updated><authors><author><keyname>Masucci</keyname><forenames>A. P.</forenames></author><author><keyname>Kalampokis</keyname><forenames>A.</forenames></author><author><keyname>Egu&#xed;luz</keyname><forenames>V. M.</forenames></author><author><keyname>Hern&#xe1;ndez-Garc&#xed;a</keyname><forenames>E.</forenames></author></authors><title>Extracting directed information flow networks: an application to
  genetics and semantics</title><categories>physics.data-an cs.SI physics.soc-ph</categories><journal-ref>Phys. Rev. E 83, 026103 (2011)</journal-ref><doi>10.1103/PhysRevE.83.026103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a general method to infer the directional information flow
between populations whose elements are described by n-dimensional vectors of
symbolic attributes. The method is based on the Jensen-Shannon divergence and
on the Shannon entropy and has a wide range of application. We show here the
results of two applications: first extracting the network of genetic flow
between the meadows of the seagrass Poseidonia Oceanica, where the meadow
elements are specified by sets of microsatellite markers, then we extract the
semantic flow network from a set of Wikipedia pages, showing the semantic
channels between different areas of knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4798</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4798</id><created>2010-09-24</created><updated>2011-04-12</updated><authors><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author></authors><title>Role of feedback and broadcasting in the naming game</title><categories>physics.soc-ph cond-mat.stat-mech cs.GT cs.MA cs.NI q-bio.PE</categories><comments>7 pages, 6 figures</comments><journal-ref>Phys. Rev. E 83, 046103 (2011)</journal-ref><doi>10.1103/PhysRevE.83.046103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The naming game (NG) describes the agreement dynamics of a population of
agents that interact locally in a pairwise fashion, and in recent years
statistical physics tools and techniques have greatly contributed to shed light
on its rich phenomenology. Here we investigate in details the role played by
the way in which the two agents update their states after an interaction. We
show that slightly modifying the NG rules in terms of which agent performs the
update in given circumstances (i.e. after a success) can either alter
dramatically the overall dynamics or leave it qualitatively unchanged. We
understand analytically the first case by casting the model in the broader
framework of a generalized NG. As for the second case, on the other hand, we
note that the modified rule reproducing the main features of the usual NG
corresponds in fact to a simplification of it consisting in the elimination of
feedback between the agents. This allows us to introduce and study a very
natural broadcasting scheme on networks that can be potentially relevant for
different applications, such as the design and implementation of autonomous
sensor networks, as pointed out in the recent literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4820</identifier>
 <datestamp>2011-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4820</id><created>2010-09-24</created><updated>2011-02-22</updated><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author><author><keyname>Kuich</keyname><forenames>Werner</forenames></author></authors><title>Free inductive K-semialgebras</title><categories>cs.FL</categories><msc-class>68Q70</msc-class><acm-class>F.4.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider rational power series over an alphabet $\Sigma$ with coefficients
in a ordered commutative semiring $K$ and characterize them as the free ordered
$K$-semialgebras in various classes of ordered $K$-semialgebras equipped with a
star operation satisfying the least pre-fixed point rule and/or its dual. The
results are generalizations of Kozen's axiomatization of regular languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4823</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4823</id><created>2010-09-24</created><authors><author><keyname>Carreira</keyname><forenames>Joao</forenames></author><author><keyname>Ion</keyname><forenames>Adrian</forenames></author><author><keyname>Sminchisescu</keyname><forenames>Cristian</forenames></author></authors><title>Image Segmentation by Discounted Cumulative Ranking on Maximal Cliques</title><categories>cs.CV</categories><comments>11 pages, 5 figures</comments><report-no>TR-06-2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a mid-level image segmentation framework that combines multiple
figure-ground hypothesis (FG) constrained at different locations and scales,
into interpretations that tile the entire image. The problem is cast as
optimization over sets of maximal cliques sampled from the graph connecting
non-overlapping, putative figure-ground segment hypotheses. Potential functions
over cliques combine unary Gestalt-based figure quality scores and pairwise
compatibilities among spatially neighboring segments, constrained by
T-junctions and the boundary interface statistics resulting from projections of
real 3d scenes. Learning the model parameters is formulated as rank
optimization, alternating between sampling image tilings and optimizing their
potential function parameters. State of the art results are reported on both
the Berkeley and the VOC2009 segmentation dataset, where a 28% improvement was
achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4825</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4825</id><created>2010-09-24</created><authors><author><keyname>BK</keyname><forenames>Pradeepa</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>TCP-controlled Long File Transfer Throughput in Multirate WLANs with
  Nonzero Round Trip Propagation Delays</title><categories>cs.NI</categories><comments>5 pages, 5 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multirate WLAN with a single access point (AP) and several stations
(STAs), we obtain analytical expressions for TCP-controlled long file transfer
throughputs allowing nonzero propagation delays between the file server and
STAs. We extend our earlier work in [3] to obtain AP and STA throughputs in a
multirate WLAN, and use these in a closed BCMP queueing network model to obtain
TCP throughputs. Simulation show that our approach is able to predict observed
throughputs with a high degree of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4828</identifier>
 <datestamp>2013-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4828</id><created>2010-09-24</created><updated>2013-02-07</updated><authors><author><keyname>Shtrakov</keyname><forenames>Sl.</forenames></author><author><keyname>Koppitz</keyname><forenames>J.</forenames></author></authors><title>Finite symmetric functions with non-trivial arity gap</title><categories>cs.DM</categories><comments>12 pages</comments><msc-class>06E35</msc-class><acm-class>G.2.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Given an $n$-ary
  $k-$valued function $f$, $gap(f)$ denotes the essential arity gap of $f$
which is the minimal number of essential variables in $f$ which become fictive
when identifying any two distinct essential variables in $f$. In the present
paper we study the properties of the symmetric function with non-trivial arity
gap ($2\leq gap(f)$). We prove several results concerning decomposition of the
symmetric functions with non-trivial arity gap with its minors or subfunctions.
We show that all non-empty sets of essential variables in symmetric functions
with non-trivial arity gap are separable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4830</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4830</id><created>2010-09-24</created><updated>2011-05-19</updated><authors><author><keyname>Hertli</keyname><forenames>Timon</forenames></author><author><keyname>Moser</keyname><forenames>Robin A.</forenames></author><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author></authors><title>Improving PPSZ for 3-SAT using Critical Variables</title><categories>cs.DS</categories><comments>12 pages, 2 figures, corrected a typo in the title, added appendix
  with bound O(1.32065^n)</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A critical variable of a satisfiable CNF formula is a variable that has the
same value in all satisfying assignments. Using a simple case distinction on
the fraction of critical variables of a CNF formula, we improve the running
time for 3-SAT from O(1.32216^n) by Rolf [2006] to O(1.32153^n). Using a
different approach, Iwama et al. [2010] very recently achieved a running time
of O(1.32113^n). Our method nicely combines with theirs, yielding the currently
fastest known algorithm with running time O(1.32065^n). We also improve the
bound for 4-SAT from O(1.47390^n) [Iwama, Tamaki 2004] to O(1.46928^n), where
O(1.46981^n) can be obtained using the methods of [Iwama, Tamaki 2004] and
[Rolf 2006].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4841</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4841</id><created>2010-09-24</created><authors><author><keyname>Khalid</keyname><forenames>Omer</forenames></author><author><keyname>Maljevic</keyname><forenames>Ivo</forenames></author><author><keyname>Anthony</keyname><forenames>Richard</forenames></author><author><keyname>Petridis</keyname><forenames>Miltos</forenames></author><author><keyname>Parrot</keyname><forenames>Kevin</forenames></author><author><keyname>Schulz</keyname><forenames>Markus</forenames></author></authors><title>Dynamic scheduling of virtual machines running hpc workloads in
  scientific grids</title><categories>cs.DC cs.DS cs.PF</categories><comments>5 pages, 5 figures, NTMS 2009, Cairo, Egypt</comments><journal-ref>In Proceedings of 3rd IEEE International Conference of New
  Technologies, Mobility and Security, 2009</journal-ref><doi>10.1145/1330555.1330556</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The primary motivation for uptake of virtualization has been resource
isolation, capacity management and resource customization allowing resource
providers to consolidate their resources in virtual machines. Various
approaches have been taken to integrate virtualization in to scientific Grids
especially in the arena of High Performance Computing (HPC) to run grid jobs in
virtual machines, thus enabling better provisioning of the underlying resources
and customization of the execution environment on runtime. Despite the gains,
virtualization layer also incur a performance penalty and its not very well
understood that how such an overhead will impact the performance of systems
where jobs are scheduled with tight deadlines. Since this overhead varies the
types of workload whether they are memory intensive, CPU intensive or network
I/O bound, and could lead to unpredictable deadline estimation for the running
jobs in the system. In our study, we have attempted to tackle this problem by
developing an intelligent scheduling technique for virtual machines which
monitors the workload types and deadlines, and calculate the system over head
in real time to maximize number of jobs finishing within their agreed
deadlines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4847</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4847</id><created>2010-09-24</created><authors><author><keyname>Khalid</keyname><forenames>Omer</forenames></author><author><keyname>Maljevic</keyname><forenames>Ivo</forenames></author><author><keyname>Anthony</keyname><forenames>Richard</forenames></author><author><keyname>Petridis</keyname><forenames>Miltos</forenames></author><author><keyname>Parrot</keyname><forenames>Kevin</forenames></author><author><keyname>Schulz</keyname><forenames>Markus</forenames></author></authors><title>Deadline aware virtual machine scheduler for scientific grids and cloud
  computing</title><categories>cs.DC cs.PF cs.SE</categories><comments>6 pages, 4 figures</comments><acm-class>D.4.1; D.4.8</acm-class><journal-ref>In Proceeding of 24th IEEE International Conference of Advance
  Information Networking and Applications, 2010</journal-ref><doi>10.1109/WAINA.2010.107</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Virtualization technology has enabled applications to be decoupled from the
underlying hardware providing the benefits of portability, better control over
execution environment and isolation. It has been widely adopted in scientific
grids and commercial clouds. Since virtualization, despite its benefits incurs
a performance penalty, which could be significant for systems dealing with
uncertainty such as High Performance Computing (HPC) applications where jobs
have tight deadlines and have dependencies on other jobs before they could run.
The major obstacle lies in bridging the gap between performance requirements of
a job and performance offered by the virtualization technology if the jobs were
to be executed in virtual machines. In this paper, we present a novel approach
to optimize job deadlines when run in virtual machines by developing a
deadline-aware algorithm that responds to job execution delays in real time,
and dynamically optimizes jobs to meet their deadline obligations. Our
approaches borrowed concepts both from signal processing and statistical
techniques, and their comparative performance results are presented later in
the paper including the impact on utilization rate of the hardware resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4870</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4870</id><created>2010-09-24</created><authors><author><keyname>Baumgartner</keyname><forenames>Tobias</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Kroeller</keyname><forenames>Alexander</forenames></author><author><keyname>Pagel</keyname><forenames>Max</forenames></author></authors><title>Hallway Monitoring: Distributed Data Processing with Wireless Sensor
  Networks</title><categories>cs.DC</categories><comments>12 pages, 5 figures, to appear in REALWSN'10</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a sensor network testbed that monitors a hallway. It consists of
120 load sensors and 29 passive infrared sensors (PIRs), connected to 30
wireless sensor nodes. There are also 29 LEDs and speakers installed, operating
as actuators, and enabling a direct interaction between the testbed and
passers-by. Beyond that, the network is heterogeneous, consisting of three
different circuit boards---each with its specific responsibility. The design of
the load sensors is of extremely low cost compared to industrial solutions and
easily transferred to other settings. The network is used for in-network data
processing algorithms, offering possibilities to develop, for instance,
distributed target-tracking algorithms. Special features of our installation
are highly correlated sensor data and the availability of miscellaneous sensor
types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4877</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4877</id><created>2010-09-24</created><authors><author><keyname>Steck</keyname><forenames>Andreas</forenames></author><author><keyname>Schlegel</keyname><forenames>Christian</forenames></author></authors><title>Towards Quality of Service and Resource Aware Robotic Systems through
  Model-Driven Software Development</title><categories>cs.RO</categories><comments>6 pages; 1st International Workshop on Domain-Specific Languages and
  models for ROBotic systems (DSLRob'10), October 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Engineering the software development process in robotics is one of the basic
necessities towards industrial-strength service robotic systems. A major
challenge is to make the step from code-driven to model-driven systems. This is
essential to replace hand-crafted single-unit systems by systems composed out
of components with explicitly stated properties. Furthermore, this fosters
reuse by separating robotics knowledge from short-cycled implementational
technologies. Altogether, this is one but important step towards &quot;able&quot; robots.
This paper reports on a model-driven development process for robotic systems.
The process consists of a robotics metamodel with first explications of
non-functional properties. A model-driven toolchain based on Eclipse provides
the model transformation and code generation steps. It also provides design
time analysis of resource parameters (e.g. schedulability analysis of realtime
tasks) as a first step towards overall resource awareness in the development of
integrated robotic systems. The overall approach is underpinned by several real
world scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4880</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4880</id><created>2010-09-24</created><authors><author><keyname>Paul</keyname><forenames>Gerald</forenames></author></authors><title>An Efficient Implementation of the Robust Tabu Search Heuristic for
  Sparse Quadratic Assignment Problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and develop an efficient implementation of the robust tabu search
heuristic for sparse quadratic assignment problems. The traditional
implementation of the heuristic applicable to all quadratic assignment problems
is of O(N^2) complexity per iteration for problems of size N. Using multiple
priority queues to determine the next best move instead of scanning all
possible moves, and using adjacency lists to minimize the operations needed to
determine the cost of moves, we reduce the asymptotic complexity per iteration
to O(N log N ). For practical sized problems, the complexity is O(N).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4898</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4898</id><created>2010-09-24</created><updated>2012-08-01</updated><authors><author><keyname>Sarangi</keyname><forenames>Sanat</forenames></author><author><keyname>Kar</keyname><forenames>Subrat</forenames></author></authors><title>Location Estimation with Reactive Routing in Resource Constrained Sensor
  Networks</title><categories>cs.NI</categories><comments>6 pages, 6 figures</comments><journal-ref>International Conference on Sensors and Related Networks
  (SENNET'09), VIT University, Vellore, India, Dec. 08-10, 2009, pp.563-567</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Routing algorithms for wireless sensor networks can be broadly divided into
two classes - proactive and reactive. Proactive routing is suitable for a
network with a fixed topology. On the other hand, reactive routing is more
suitable for a set of mobile nodes where routes are created on demand and there
is not much time to evaluate the worthiness of a route, the prime concern being
reachability due to constantly changing node positions. Sensor networks route
events of interest from source(s) to destination(s) where appropriate actions
could be taken. However, with mobile sensor nodes, it is not only important to
know the events but the location of the nodes generating the events. Most
sensor nodes are not equipped with expensive GPS or accurate RSSI computation
hardware to aid localization. Keeping these in view, we propose a modified
reactive routing algorithm, with added support for localization, to localize
mobile sensor nodes on the basis of information received from fixed sensor
nodes during mutual exchange of routing control packets. The accuracy of
localization depends on the ratio of the number of fixed nodes to the number of
mobile nodes and the topology of the fixed nodes. A typical application
scenario would be a mix of mobile nodes and fixed nodes, where fixed nodes know
their absolute location and the location of mobile nodes is derived from the
fixed nodes, in step with the reactive routing protocol in action. The modified
algorithm would be suitable for deployments where the approximate position of a
mobile node (i.e. the event location) is required but there is no external
support infrastructure available for localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4954</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4954</id><created>2010-09-24</created><updated>2011-01-25</updated><authors><author><keyname>Xue</keyname><forenames>Dongyue</forenames></author><author><keyname>Ekici</keyname><forenames>Eylem</forenames></author></authors><title>Delay-Guaranteed Cross-Layer Scheduling in Multi-Hop Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a cross-layer scheduling algorithm that achieves a
throughput &quot;epsilon-close&quot; to the optimal throughput in multi-hop wireless
networks with a tradeoff of O(1/epsilon) in delay guarantees. The algorithm
aims to solve a joint congestion control, routing, and scheduling problem in a
multi-hop wireless network while satisfying per-flow average end-to-end delay
guarantees and minimum data rate requirements. This problem has been solved for
both backlogged as well as arbitrary arrival rate systems. Moreover, we discuss
the design of a class of low-complexity suboptimal algorithms, the effects of
delayed feedback on the optimal algorithm, and the extensions of the proposed
algorithm to different interference models with arbitrary link capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4962</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4962</id><created>2010-09-24</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>RGANN: An Efficient Algorithm to Extract Rules from ANNs</title><categories>cs.NE</categories><comments>12 Pages, International Journal</comments><journal-ref>Journal of Electronics and Computer Science, Jahangarnagar
  University, Bangladesh, Vol. 8, pp. 19-30, Jun. 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an efficient rule generation algorithm, called rule
generation from artificial neural networks (RGANN) to generate symbolic rules
from ANNs. Classification rules are sought in many areas from automatic
knowledge acquisition to data mining and ANN rule extraction. This is because
classification rules possess some attractive features. They are explicit,
understandable and verifiable by domain experts, and can be modified, extended
and passed on as modular knowledge. A standard three-layer feedforward ANN is
the basis of the algorithm. A four-phase training algorithm is proposed for
backpropagation learning. Comparing them to the symbolic rules generated by
other methods supports explicitness of the generated rules. Generated rules are
comparable with other methods in terms of number of rules, average number of
conditions for a rule, and predictive accuracy. Extensive experimental studies
on several benchmarks classification problems, including breast cancer, wine,
season, golf-playing, and lenses classification demonstrate the effectiveness
of the proposed approach with good generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4964</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4964</id><created>2010-09-24</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Text Classification using Artificial Intelligence</title><categories>cs.IR</categories><comments>6 Pages, International Journal</comments><journal-ref>Journal of Electrical Engineering, The Institution of Engineers,
  Bangladesh, Vol. EE 33, No. I &amp; II, Dec. 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text classification is the process of classifying documents into predefined
categories based on their content. It is the automated assignment of natural
language texts to predefined categories. Text classification is the primary
requirement of text retrieval systems, which retrieve texts in response to a
user query, and text understanding systems, which transform text in some way
such as producing summaries, answering questions or extracting data. Existing
supervised learning algorithms for classifying text need sufficient documents
to learn accurately. This paper presents a new algorithm for text
classification using artificial intelligence technique that requires fewer
documents for training. Instead of using words, word relation i.e. association
rules from these words is used to derive feature set from pre-classified text
documents. The concept of na\&quot;ive Bayes classifier is then used on derived
features and finally only a single concept of genetic algorithm has been added
for final classification. A system based on the proposed algorithm has been
implemented and tested. The experimental results show that the proposed system
works as a successful text classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4966</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4966</id><created>2010-09-24</created><updated>2011-07-20</updated><authors><author><keyname>Sarmiento</keyname><forenames>Eliseo</forenames></author><author><keyname>Pinto</keyname><forenames>Maria Vaz</forenames></author><author><keyname>Villarreal</keyname><forenames>Rafael H.</forenames></author></authors><title>The minimum distance of parameterized codes on projective tori</title><categories>math.AC cs.IT math.AG math.IT</categories><comments>Appl. Algebra Engrg. Comm. Comput., to appear</comments><msc-class>13P25, 14G50, 94B27</msc-class><journal-ref>Appl. Algebra Engrg. Comm. Comput. 22 (2011), no. 4, 249--264</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let X be a subset of a projective space, over a finite field K, which is
parameterized by the monomials arising from the edges of a clutter. Let I(X) be
the vanishing ideal of X. It is shown that I(X) is a complete intersection if
and only if X is a projective torus. In this case we determine the minimum
distance of any parameterized linear code arising from X.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4969</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4969</id><created>2010-09-25</created><updated>2010-11-18</updated><authors><author><keyname>Hu</keyname><forenames>Yang</forenames></author><author><keyname>Liu</keyname><forenames>Yimin</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Extended Range Profiling in Stepped-Frequency Radar with Sparse Recovery</title><categories>cs.IT math.IT</categories><comments>3 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The newly emerging theory of compressed sensing (CS) enables restoring a
sparse signal from inadequate number of linear projections. Based on compressed
sensing theory, a new algorithm of high-resolution range profiling for
stepped-frequency (SF) radar suffering from missing pulses is proposed. The new
algorithm recovers target range profile over multiple coarse-range-bins,
providing a wide range profiling capability. MATLAB simulation results are
presented to verify the proposed method. Furthermore, we use collected data
from real SF radar to generate extended target high-resolution range (HRR)
profile. Results are compared with `stretch' based least square method to prove
its applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4970</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4970</id><created>2010-09-25</created><updated>2010-12-11</updated><authors><author><keyname>Li</keyname><forenames>Quan-Lin</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author></authors><title>Doubly Exponential Solution for Randomized Load Balancing Models with
  Markovian Arrival Processes and PH Service Times</title><categories>cs.DM cs.DC</categories><comments>Randomized load balancing, supermarket model, matrix-analytic
  approach, doubly exponential solution, density dependent jump Markov process,
  Markovian Arrival Process (MAP), phase type (PH) distribution, fixed point,
  exponential convergence, Lipschitz condition</comments><msc-class>90B15, 90B18</msc-class><acm-class>C.2; C.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we provide a novel matrix-analytic approach for studying
doubly exponential solutions of randomized load balancing models (also known as
supermarket models) with Markovian arrival processes (MAPs) and phase-type (PH)
service times. We describe the supermarket model as a system of differential
vector equations by means of density dependent jump Markov processes, and
obtain a closed-form solution with a doubly exponential structure to the fixed
point of the system of differential vector equations. Based on this, we show
that the fixed point can be decomposed into the product of two factors
inflecting arrival information and service information, and further find that
the doubly exponential solution to the fixed point is not always unique for
more general supermarket models. Furthermore, we analyze the exponential
convergence of the current location of the supermarket model to its fixed
point, and apply the Kurtz Theorem to study density dependent jump Markov
process given in the supermarket model with MAPs and PH service times, which
leads to the Lipschitz condition under which the fraction measure of the
supermarket model weakly converges the system of differential vector equations.
This paper gains a new understanding of how workload probing can help in load
balancing jobs with non-Poisson arrivals and non-exponential service times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4971</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4971</id><created>2010-09-25</created><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author></authors><title>Fastest Distributed Consensus on Petal Networks</title><categories>cs.IT cs.DM math.IT</categories><comments>28 Pages, 6 Figures, 2 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing an analytical solution for the problem of finding Fastest
Distributed Consensus (FDC) is one of the challenging problems in the field of
sensor networks. Here in this work we present analytical solution for the
problem of fastest distributed consensus averaging algorithm by means of
stratification and semi-definite programming, for two particular types of Petal
networks, namely symmetric and Complete Cored Symmetric (CCS) Petal networks.
Our method in this paper is based on convexity of fastest distributed consensus
averaging problem, and inductive comparing of the characteristic polynomials
initiated by slackness conditions in order to find the optimal weights. Also
certain types of leaves are introduced along with their optimal weights which
are not achievable by the method used in this work if these leaves are
considered individually.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4972</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4972</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Karim</keyname><forenames>A. N. M. Rezaul</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Haque</keyname><forenames>Md. Emdadul</forenames></author></authors><title>Speaker Identification using MFCC-Domain Support Vector Machine</title><categories>cs.LG cs.SD</categories><comments>5 Pages, International Journal</comments><journal-ref>International Journal of Electrical and Power Engineering, Vol. 1,
  No. 3, pp. 274-278, 2007</journal-ref><doi>10.3923/ijepe.2007.274.278</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech recognition and speaker identification are important for
authentication and verification in security purpose, but they are difficult to
achieve. Speaker identification methods can be divided into text-independent
and text-dependent. This paper presents a technique of text-dependent speaker
identification using MFCC-domain support vector machine (SVM). In this work,
melfrequency cepstrum coefficients (MFCCs) and their statistical distribution
properties are used as features, which will be inputs to the neural network.
This work firstly used sequential minimum optimization (SMO) learning technique
for SVM that improve performance over traditional techniques Chunking, Osuna.
The cepstrum coefficients representing the speaker characteristics of a speech
segment are computed by nonlinear filter bank analysis and discrete cosine
transform. The speaker identification ability and convergence speed of the SVMs
are investigated for different combinations of features. Extensive experimental
results on several samples show the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4973</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4973</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Rahman</keyname><forenames>Md. Anisur</forenames></author></authors><title>Performance Analysis of Pulse Shaping Technique for OFDM PAPR Reduction</title><categories>cs.IT math.IT</categories><comments>5 Pages, International Conference</comments><journal-ref>Proc. 12th International Conference on Human Computer Interaction,
  Beijing, China, Vol. 18, Jul. 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal Frequency Division Multiplexing (OFDM) is an attractive modulation
and multiple access techniques for channels with a nonflat frequency response,
as it saves the need for complex equalizers. It can offer high quality
performance in terms of bandwidth efficiency, robustness against multipath
fading and cost-effective implementation. However, its main disadvantage is the
high peak-to-average power ratio (PAPR) of the output signal. As a result, a
linear behavior of the system over a large dynamic range is needed and
therefore the efficiency of the output amplifier is reduced. In this paper, we
investigate the effect of some of these sets of time waveforms on the OFDM
system performance in terms of Bit Error Rate (BER). We evaluate the system
performance in AWGN channels. The obtained results indicate that the reduction
in PAPR of the investigated methods is associated with considerable improvement
in BER performance of the system, in multipath channels, as compared to
conventional OFDM. These promising results indicate that pulse shaping with
reduced PAPR is an attractive solution for an OFDM system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4974</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4974</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Siddiqi</keyname><forenames>Firoz Ahmed</forenames></author><author><keyname>Islam</keyname><forenames>Md. Saiful</forenames></author><author><keyname>Haque</keyname><forenames>Md. Emdadul</forenames></author><author><keyname>Alam</keyname><forenames>Mohammad Shamsul</forenames></author></authors><title>Rotation Invariant Face Detection Using Wavelet, PCA and Radial Basis
  Function Networks</title><categories>cs.CV</categories><comments>5 Pages, International Conference</comments><journal-ref>12th International Conference on Human Computer Interaction,
  Beijing, China, Vol. 18, Jul. 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel method for human face detection with its
orientation by using wavelet, principle component analysis (PCA) and redial
basis networks. The input image is analyzed by two-dimensional wavelet and a
two-dimensional stationary wavelet. The common goals concern are the image
clearance and simplification, which are parts of de-noising or compression. We
applied an effective procedure to reduce the dimension of the input vectors
using PCA. Radial Basis Function (RBF) neural network is then used as a
function approximation network to detect where either the input image is
contained a face or not and if there is a face exists then tell about its
orientation. We will show how RBF can perform well then back-propagation
algorithm and give some solution for better regularization of the RBF (GRNN)
network. Compared with traditional RBF networks, the proposed network
demonstrates better capability of approximation to underlying functions, faster
learning speed, better size of network, and high robustness to outliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4975</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4975</id><created>2010-09-25</created><authors><author><keyname>Wang</keyname><forenames>Shun</forenames></author><author><keyname>de Sturler</keyname><forenames>Eric</forenames></author><author><keyname>Paulino</keyname><forenames>Glaucio H.</forenames></author></authors><title>Dynamic Adaptive Mesh Refinement for Topology Optimization</title><categories>math.NA cs.CE</categories><comments>adaptive mesh refinement, topology optimization, iterative solvers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an improved method for topology optimization with both adaptive
mesh refinement and derefinement. Since the total volume fraction in topology
optimization is usually modest, after a few initial iterations the domain of
computation is largely void. Hence, it is inefficient to have many small
elements, in such regions, that contribute significantly to the overall
computational cost but contribute little to the accuracy of computation and
design. At the same time, we want high spatial resolution for accurate
three-dimensional designs to avoid postprocessing or interpretation as much as
possible. Dynamic adaptive mesh refinement (AMR) offers the possibility to
balance these two requirements. We discuss requirements on AMR for topology
optimization and the algorithmic features to implement them. The numerical
design problems demonstrate (1) that our AMR strategy for topology optimization
leads to designs that are equivalent to optimal designs on uniform meshes, (2)
how AMR strategies that do not satisfy the postulated requirements may lead to
suboptimal designs, and (3) that our AMR strategy significantly reduces the
time to compute optimal designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4976</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4976</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Haider</keyname><forenames>Farhana</forenames></author><author><keyname>Hasan</keyname><forenames>Ahmed Ryadh</forenames></author></authors><title>Text Classification using Association Rule with a Hybrid Concept of
  Naive Bayes Classifier and Genetic Algorithm</title><categories>cs.IR cs.DB cs.LG</categories><comments>6 Pages, International Conference</comments><journal-ref>Proc. 7th International Conference on Computer and Information
  Technology (ICCIT-2004), Dhaka, Bangladesh, pp. 682-687, Dec. 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text classification is the automated assignment of natural language texts to
predefined categories based on their content. Text classification is the
primary requirement of text retrieval systems, which retrieve texts in response
to a user query, and text understanding systems, which transform text in some
way such as producing summaries, answering questions or extracting data. Now a
day the demand of text classification is increasing tremendously. Keeping this
demand into consideration, new and updated techniques are being developed for
the purpose of automated text classification. This paper presents a new
algorithm for text classification. Instead of using words, word relation i.e.
association rules is used to derive feature set from pre-classified text
documents. The concept of Naive Bayes Classifier is then used on derived
features and finally a concept of Genetic Algorithm has been added for final
classification. A system based on the proposed algorithm has been implemented
and tested. The experimental results show that the proposed system works as a
successful text classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4977</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4977</id><created>2010-09-25</created><authors><author><keyname>Azad</keyname><forenames>Md. Abul kalam</forenames></author><author><keyname>Sharmeen</keyname><forenames>Rezwana</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Universal Numeric Segmented Display</title><categories>cs.AR</categories><comments>6 Pages, International Conference</comments><journal-ref>Proc. 7th International Conference on Computer and Information
  Technology (ICCIT-2004), Dhaka, Bangladesh, pp. 887-892, Dec. 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation display plays a vital role to display numerals. But in today's
world matrix display is also used in displaying numerals. Because numerals has
lots of curve edges which is better supported by matrix display. But as matrix
display is costly and complex to implement and also needs more memory, segment
display is generally used to display numerals. But as there is yet no proposed
compact display architecture to display multiple language numerals at a time,
this paper proposes uniform display architecture to display multiple language
digits and general mathematical expressions with higher accuracy and simplicity
by using a 18-segment display, which is an improvement over the 16 segment
display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4978</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4978</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Extracting Symbolic Rules for Medical Diagnosis Problem</title><categories>cs.NE</categories><comments>6 Pages, International Conference</comments><journal-ref>Proc. 8th International Conference on Computer and Information
  Technology (ICCIT 2005), Dhaka, Bangladesh, pp. 602-607, Dec. 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural networks (NNs) have been successfully applied to solve a variety of
application problems involving classification and function approximation.
Although backpropagation NNs generally predict better than decision trees do
for pattern classification problems, they are often regarded as black boxes,
i.e., their predictions cannot be explained as those of decision trees. In many
applications, it is desirable to extract knowledge from trained NNs for the
users to gain a better understanding of how the networks solve the problems. An
algorithm is proposed and implemented to extract symbolic rules for medical
diagnosis problem. Empirical study on three benchmarks classification problems,
such as breast cancer, diabetes, and lenses demonstrates that the proposed
algorithm generates high quality rules from NNs comparable with other methods
in terms of number of rules, average number of conditions for a rule, and
predictive accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4979</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4979</id><created>2010-09-25</created><authors><author><keyname>Azad</keyname><forenames>Md. Abul Kalam</forenames></author><author><keyname>Sharmeen</keyname><forenames>Rezwana</forenames></author><author><keyname>Ahmad</keyname><forenames>Shabbir</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Smart Bengali Cell Phone Keypad Layout</title><categories>cs.HC</categories><comments>4 Pages, International Conference</comments><journal-ref>Proc. 8th International Conference on Computer and Information
  Technology (ICCIT 2005), Dhaka, Bangladesh, pp. 1208-1211, Dec. 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays cell phone is the most common communicating used by mass people. SMS
based communication is a cheap and popular communication method. It is human
tendency to have the opportunity to write SMS in their mother language. Text
input in mother language is more flexible when the alphabets of that language
are printed on the keypad. Bangla mobile keypad based on phonetics has been
proposed earlier. But the keypad is not scientific from frequency and
flexibility point of view. Since it is not a feasible solution in this paper we
have proposed an efficient Bengali keypad for cell phone and other cellular
device. The proposed keypad is based on the frequency of the alphabets in
Bengali language and also with the view of structure of human finger movements.
We took the two points in count to provide a flexible and fast cell phone
keypad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4980</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4980</id><created>2010-09-25</created><authors><author><keyname>Sharmeen</keyname><forenames>Rezwana</forenames></author><author><keyname>Azad</keyname><forenames>Md. Abul Kalam</forenames></author><author><keyname>Ahmad</keyname><forenames>Shabbir</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Completely Enhanced Cell Phone Keypad</title><categories>cs.HC</categories><comments>5 Pages, International Conference</comments><journal-ref>Proc. International Conference on Information Management and
  Business (IMB 2005), Shih Chien University, Taiwan, pp. 217-221, Mar. 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The enhanced frequency based keypad is designed to speed up the typing
process. This paper will show that the proposed layout will increase the typing
speed and be flexible for thumb. Traditional cell phone keypad is not a
scientific keypad from the frequency point of view. Approaches have been
explored to speed up the typing process. We found that no manufacturer has
considered the frequency of the alphabet. The current architecture does not
provide flexibility although the users are accustomed to the currently
available multi-tapping keypad. Since the currently available keypad layouts
are not best suited for users, this paper will suggest a keypad for cell phone
and other cellular device based on the frequency of the alphabet in English
language and also with the view of structure of human finger movements to
provide a flexible and fast cell phone keypad. It also takes into consideration
the key jamming problem that was available in typewriter. At first we
identified those keys of cell phone, which are easily reachable and create less
pressure on the thumb. Thus the key frequency order is calculated from
anatomical point of view. In our proposed layout we arranged the alphabet in
the frequent keys based on the frequency of the alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4981</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4981</id><created>2010-09-25</created><authors><author><keyname>Azad</keyname><forenames>Md. Abul Kalam</forenames></author><author><keyname>Sharmeen</keyname><forenames>Rezwana</forenames></author><author><keyname>Ahmad</keyname><forenames>Shabbir</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>An Efficient Technique for Text Compression</title><categories>cs.IT cs.IR math.IT</categories><comments>7 Pages, International Conference</comments><journal-ref>Proc. International Conference on Information Management and
  Business (IMB 2005), Shih Chien University, Taiwan, pp. 467-473, Mar. 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For storing a word or the whole text segment, we need a huge storage space.
Typically a character requires 1 Byte for storing it in memory. Compression of
the memory is very important for data management. In case of memory requirement
compression for text data, lossless memory compression is needed. We are
suggesting a lossless memory requirement compression method for text data
compression. The proposed compression method will compress the text segment or
the text file based on two level approaches firstly reduction and secondly
compression. Reduction will be done using a word lookup table not using
traditional indexing system, then compression will be done using currently
available compression methods. The word lookup table will be a part of the
operating system and the reduction will be done by the operating system.
According to this method each word will be replaced by an address value. This
method can quite effectively reduce the size of persistent memory required for
text data. At the end of the first level compression with the use of word
lookup table, a binary file containing the addresses will be generated. Since
the proposed method does not use any compression algorithm in the first level
so this file can be compressed using the popular compression algorithms and
finally will provide a great deal of data compression on purely English text
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4982</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4982</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Alam</keyname><forenames>Md. Hijbul</forenames></author><author><keyname>Masum</keyname><forenames>Abdul Kadar Muhammad</forenames></author><author><keyname>Hassan</keyname><forenames>Md. Mahadi</forenames></author></authors><title>Optimal Bangla Keyboard Layout using Data Mining Technique</title><categories>cs.AI</categories><comments>9 Pages, International Conference</comments><journal-ref>Proc. International Conference on Information and Communication
  Technology in Management (ICTM 2005), Multimedia University, Malaysia, May
  2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an optimal Bangla Keyboard Layout, which distributes the
load equally on both hands so that maximizing the ease and minimizing the
effort. Bangla alphabet has a large number of letters, for this it is difficult
to type faster using Bangla keyboard. Our proposed keyboard will maximize the
speed of operator as they can type with both hands parallel. Here we use the
association rule of data mining to distribute the Bangla characters in the
keyboard. First, we analyze the frequencies of data consisting of monograph,
digraph and trigraph, which are derived from data wire-house, and then used
association rule of data mining to distribute the Bangla characters in the
layout. Experimental results on several data show the effectiveness of the
proposed approach with better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4983</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4983</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Hasan</keyname><forenames>Ahmed Ryadh</forenames></author></authors><title>Pattern Classification using Simplified Neural Networks</title><categories>cs.NE</categories><comments>7 Pages, International Conference</comments><journal-ref>Proc. International Conference on Information and Communication
  Technology in Management (ICTM 2005), Multimedia University, Malaysia, May
  2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, many neural network models have been proposed for pattern
classification, function approximation and regression problems. This paper
presents an approach for classifying patterns from simplified NNs. Although the
predictive accuracy of ANNs is often higher than that of other methods or human
experts, it is often said that ANNs are practically &quot;black boxes&quot;, due to the
complexity of the networks. In this paper, we have an attempted to open up
these black boxes by reducing the complexity of the network. The factor makes
this possible is the pruning algorithm. By eliminating redundant weights,
redundant input and hidden units are identified and removed from the network.
Using the pruning algorithm, we have been able to prune networks such that only
a few input units, hidden units and connections left yield a simplified
network. Experimental results on several benchmarks problems in neural networks
show the effectiveness of the proposed approach with good generalization
ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4984</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4984</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Hasan</keyname><forenames>Ahmed Ryadh</forenames></author></authors><title>Rule Extraction using Artificial Neural Networks</title><categories>cs.NE</categories><comments>14 Pages, International Conference</comments><journal-ref>Proc. International Conference on Information and Communication
  Technology in Management (ICTM 2005), Multimedia University, Malaysia, May
  2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial neural networks have been successfully applied to a variety of
business application problems involving classification and regression. Although
backpropagation neural networks generally predict better than decision trees do
for pattern classification problems, they are often regarded as black boxes,
i.e., their predictions are not as interpretable as those of decision trees. In
many applications, it is desirable to extract knowledge from trained neural
networks so that the users can gain a better understanding of the solution.
This paper presents an efficient algorithm to extract rules from artificial
neural networks. We use two-phase training algorithm for backpropagation
learning. In the first phase, the number of hidden nodes of the network is
determined automatically in a constructive fashion by adding nodes one after
another based on the performance of the network on training data. In the second
phase, the number of relevant input units of the network is determined using
pruning algorithm. The pruning process attempts to eliminate as many
connections as possible from the network. Relevant and irrelevant attributes of
the data are distinguished during the training process. Those that are relevant
will be kept and others will be automatically discarded. From the simplified
networks having small number of connections and nodes we may easily able to
extract symbolic rules using the proposed algorithm. Extensive experimental
results on several benchmarks problems in neural networks demonstrate the
effectiveness of the proposed approach with good generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4987</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4987</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Haider</keyname><forenames>Farhana</forenames></author><author><keyname>Hasan</keyname><forenames>Ahmed Ryadh</forenames></author></authors><title>Text Classification using Data Mining</title><categories>cs.IR cs.DB</categories><comments>19 Pages, International Conference</comments><journal-ref>Proc. International Conference on Information and Communication
  Technology in Management (ICTM-2005), Multimedia University, Malaysia, May
  2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text classification is the process of classifying documents into predefined
categories based on their content. It is the automated assignment of natural
language texts to predefined categories. Text classification is the primary
requirement of text retrieval systems, which retrieve texts in response to a
user query, and text understanding systems, which transform text in some way
such as producing summaries, answering questions or extracting data. Existing
supervised learning algorithms to automatically classify text need sufficient
documents to learn accurately. This paper presents a new algorithm for text
classification using data mining that requires fewer documents for training.
Instead of using words, word relation i.e. association rules from these words
is used to derive feature set from pre-classified text documents. The concept
of Naive Bayes classifier is then used on derived features and finally only a
single concept of Genetic Algorithm has been added for final classification. A
system based on the proposed algorithm has been implemented and tested. The
experimental results show that the proposed system works as a successful text
classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4988</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4988</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>REx: An Efficient Rule Generator</title><categories>cs.NE</categories><comments>4 Pages, International Conference</comments><journal-ref>Proc. 4th International Conference on Electrical Engineering, The
  Institution of Engineers, Dhaka, Bangladesh, pp. 79-82, Jan. 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an efficient algorithm REx for generating symbolic rules
from artificial neural network (ANN). Classification rules are sought in many
areas from automatic knowledge acquisition to data mining and ANN rule
extraction. This is because classification rules possess some attractive
features. They are explicit, understandable and verifiable by domain experts,
and can be modified, extended and passed on as modular knowledge. REx exploits
the first order information in the data and finds shortest sufficient
conditions for a rule of a class that can differentiate it from patterns of
other classes. It can generate concise and perfect rules in the sense that the
error rate of the rules is not worse than the inconsistency rate found in the
original data. An important feature of rule extraction algorithm, REx, is its
recursive nature. They are concise, comprehensible, order insensitive and do
not involve any weight values. Extensive experimental studies on several
benchmark classification problems, such as breast cancer, iris, season, and
golf-playing, demonstrate the effectiveness of the proposed approach with good
generalization ability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4991</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4991</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>Web Page Categorization Using Artificial Neural Networks</title><categories>cs.NE cs.IR</categories><comments>4 Pages, International Conference</comments><journal-ref>Proc. 4th International Conference on Electrical Engineering, The
  Institution of Engineers, Dhaka, Bangladesh, pp. 96-99, Jan. 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web page categorization is one of the challenging tasks in the world of ever
increasing web technologies. There are many ways of categorization of web pages
based on different approach and features. This paper proposes a new dimension
in the way of categorization of web pages using artificial neural network (ANN)
through extracting the features automatically. Here eight major categories of
web pages have been selected for categorization; these are business &amp; economy,
education, government, entertainment, sports, news &amp; media, job search, and
science. The whole process of the proposed system is done in three successive
stages. In the first stage, the features are automatically extracted through
analyzing the source of the web pages. The second stage includes fixing the
input values of the neural network; all the values remain between 0 and 1. The
variations in those values affect the output. Finally the third stage
determines the class of a certain web page out of eight predefined classes.
This stage is done using back propagation algorithm of artificial neural
network. The proposed concept will facilitate web mining, retrievals of
information from the web and also the search engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4992</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4992</id><created>2010-09-25</created><authors><author><keyname>Haque</keyname><forenames>S. M. Anamul</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Islam</keyname><forenames>Md. Ashraful</forenames></author></authors><title>A System for Smart Home Control of Appliances based on Timer and Speech
  Interaction</title><categories>cs.HC</categories><comments>4 Pages, International Conference</comments><journal-ref>Proc. 4th International Conference on Electrical Engineering, The
  Institution of Engineers, Dhaka, Bangladesh pp. 128-131, Jan. 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of this work is to design and construct a microcomputer
based system: to control electric appliances such as light, fan, heater,
washing machine, motor, TV, etc. The paper discusses two major approaches to
control home appliances. The first involves controlling home appliances using
timer option. The second approach is to control home appliances using voice
command. Moreover, it is also possible to control appliances using Graphical
User Interface. The parallel port is used to transfer data from computer to the
particular device to be controlled. An interface box is designed to connect the
high power loads to the parallel port. This system will play an important role
for the elderly and physically disable people to control their home appliances
in intuitive and flexible way. We have developed a system, which is able to
control eight electric appliances properly in these three modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4994</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4994</id><created>2010-09-25</created><authors><author><keyname>Kamruzzaman</keyname><forenames>S M</forenames></author><author><keyname>Rahman</keyname><forenames>Chowdhury Mofizur</forenames></author></authors><title>Text Categorization using Association Rule and Naive Bayes Classifier</title><categories>cs.IR cs.DB</categories><comments>9 Pages, International Journal</comments><journal-ref>Asian Journal of Information Technology, Vol. 3, No. 9, pp
  657-665, Sep. 2004</journal-ref><doi>10.3923/ajit.2004.657.665</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the amount of online text increases, the demand for text categorization to
aid the analysis and management of text is increasing. Text is cheap, but
information, in the form of knowing what classes a text belongs to, is
expensive. Automatic categorization of text can provide this information at low
cost, but the classifiers themselves must be built with expensive human effort,
or trained from texts which have themselves been manually classified. Text
categorization using Association Rule and Na\&quot;ive Bayes Classifier is proposed
here. Instead of using words word relation i.e association rules from these
words is used to derive feature set from pre-classified text documents. Naive
Bayes Classifier is then used on derived features for final categorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.4995</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.4995</id><created>2010-09-25</created><authors><author><keyname>Rumyantsev</keyname><forenames>Andrey</forenames></author></authors><title>Kolmogorov complexity, Lovasz local lemma and critical exponents</title><categories>math.CO cs.DS</categories><journal-ref>Andrey Yu. Rumyantsev, Kolmogorov Complexity, Lov\'asz Local Lemma
  and Critical Exponents, Springer, Lecture Notes in Computer Science, Volume
  4649 / 2007, CSR 2007, pp. 349--355</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  D. Krieger and J. Shallit have proved that every real number greater than 1
is a critical exponent of some sequence. We show how this result can be derived
from some general statements about sequences whose subsequences have (almost)
maximal Kolmogorov complexity. In this way one can also construct a sequence
that has no &quot;approximate&quot; fractional powers with exponent that exceeds a given
value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5003</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5003</id><created>2010-09-25</created><authors><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author></authors><title>Demonstrating a Service-Enhanced Retrieval System</title><categories>cs.IR cs.DL</categories><comments>2 pages, 1 figure, ASIST 2010 conference, Pittsburgh, PA, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a short description of an information retrieval system enhanced
by three model driven retrieval services: (1) co-word analysis based query
expansion, re-ranking via (2) Bradfordizing and (3) author centrality. The
different services each favor quite other - but still relevant - documents than
pure term-frequency based rankings. Each service can be interactively combined
with each other to allow an iterative retrieval refinement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5004</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5004</id><created>2010-09-25</created><authors><author><keyname>M&#xfc;he</keyname><forenames>Henrik</forenames></author><author><keyname>Angerer</keyname><forenames>Andreas</forenames></author><author><keyname>Hoffmann</keyname><forenames>Alwin</forenames></author><author><keyname>Reif</keyname><forenames>Wolfgang</forenames></author></authors><title>On reverse-engineering the KUKA Robot Language</title><categories>cs.RO</categories><comments>1st International Workshop on Domain-Specific Languages and models
  for ROBotic systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most commercial manufacturers of industrial robots require their robots to be
programmed in a proprietary language tailored to the domain - a typical
domain-specific language (DSL). However, these languages oftentimes suffer from
shortcomings such as controller-specific design, limited expressiveness and a
lack of extensibility. For that reason, we developed the extensible Robotics
API for programming industrial robots on top of a general-purpose language.
Although being a very flexible approach to programming industrial robots, a
fully-fledged language can be too complex for simple tasks. Additionally,
legacy support for code written in the original DSL has to be maintained. For
these reasons, we present a lightweight implementation of a typical robotic
DSL, the KUKA Robot Language (KRL), on top of our Robotics API. This work deals
with the challenges in reverse-engineering the language and mapping its
specifics to the Robotics API. We introduce two different approaches of
interpreting and executing KRL programs: tree-based and bytecode-based
interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5012</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5012</id><created>2010-09-25</created><authors><author><keyname>BK</keyname><forenames>Pradeepa</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>Bulk File Download Throughput in a Single Station WLAN with Nonzero
  Propagation Delay</title><categories>cs.NI</categories><comments>5 pages, 7 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze TCP-controlled bulk file transfers in a single station (STA) WLAN
with nonzero propagation delay between the file server and the WLAN. Our
approach is to model the flow of packets as a closed queueing network (BCMP
network) with 3 service centres, one each for the Access Point (AP) and the
STA, and the third for the propagation delay. The service rates of the first
two are obtained by analyzing the WLAN MAC. Simulations show a very close match
with the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5019</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5019</id><created>2010-09-25</created><authors><author><keyname>Ge</keyname><forenames>Qi</forenames></author><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author></authors><title>The Complexity of Counting Eulerian Tours in 4-Regular Graphs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the complexity of counting Eulerian tours ({\sc #ET}) and its
variations from two perspectives---the complexity of exact counting and the
complexity w.r.t. approximation-preserving reductions (AP-reductions
\cite{MR2044886}). We prove that {\sc #ET} is #P-complete even for planar
4-regular graphs.
  A closely related problem is that of counting A-trails ({\sc #A-trails}) in
graphs with rotational embedding schemes (so called maps). Kotzig
\cite{MR0248043} showed that {\sc #A-trails} can be computed in polynomial time
for 4-regular plane graphs (embedding in the plane is equivalent to giving a
rotational embedding scheme). We show that for 4-regular maps the problem is
#P-hard. Moreover, we show that from the approximation viewpoint {\sc
#A-trails} in 4-regular maps captures the essence of {\sc #ET}, that is, we
give an AP-reduction from {\sc #ET} in general graphs to {\sc #A-trails} in
4-regular maps. The reduction uses a fast mixing result for a card shuffling
problem \cite{MR2023023}.
  In order to understand whether #{\sc A-trails} in 4-regular maps can
AP-reduce to #{\sc ET} in 4-regular graphs, we investigate a problem in which
transitions in vertices are weighted (this generalizes both #{\sc A-trails} and
#{\sc ET}). In the 4-regular case we show that {\sc A-trails} can be used to
simulate any vertex weights and provide evidence that {\sc ET} can simulate
only a limited set of vertex weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5026</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5026</id><created>2010-09-25</created><authors><author><keyname>Perlaza</keyname><forenames>S. M.</forenames></author><author><keyname>Tembine</keyname><forenames>H.</forenames></author><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author><author><keyname>Quintero-Florez</keyname><forenames>V.</forenames></author></authors><title>On the Fictitious Play and Channel Selection Games</title><categories>cs.GT cs.IT math.IT</categories><comments>In proc. of the IEEE Latin-American Conference on Communications
  (LATINCOM), Bogota, Colombia, September, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the interaction through mutual interference of the different
radio devices, the channel selection (CS) problem in decentralized parallel
multiple access channels can be modeled by strategic-form games. Here, we show
that the CS problem is a potential game (PG) and thus the fictitious play (FP)
converges to a Nash equilibrium (NE) either in pure or mixed strategies. Using
a 2-player 2-channel game, it is shown that convergence in mixed strategies
might lead to cycles of action profiles which lead to individual spectral
efficiencies (SE) which are worse than the SE at the worst NE in mixed and pure
strategies. Finally, exploiting the fact that the CS problem is a PG and an
aggregation game, we present a method to implement FP with local information
and minimum feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5028</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5028</id><created>2010-09-25</created><authors><author><keyname>Buliga</keyname><forenames>Marius</forenames></author></authors><title>What is a space? Computations in emergent algebras and the front end
  visual system</title><categories>math.GR cs.LO q-bio.NC</categories><comments>comments welcomed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the help of link diagrams with decorated crossings, I explain
computations in emergent algebras, introduced in arXiv:0907.1520, as the kind
of computations done in the front end visual system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5029</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5029</id><created>2010-09-25</created><authors><author><keyname>Toulouse</keyname><forenames>Sophie</forenames><affiliation>LIPN</affiliation></author><author><keyname>Calvo</keyname><forenames>Roberto Wolfler</forenames><affiliation>LIPN</affiliation></author></authors><title>On the complexity of the multiple stack TSP, kSTSP</title><categories>cs.CC cs.RO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiple Stack Travelling Salesman Problem, STSP, deals with the collect
and the deliverance of n commodities in two distinct cities. The two cities are
represented by means of two edge-valued graphs (G1,d2) and (G2,d2). During the
pick-up tour, the commodities are stored into a container whose rows are
subject to LIFO constraints. As a generalisation of standard TSP, the problem
obviously is NP-hard; nevertheless, one could wonder about what combinatorial
structure of STSP does the most impact its complexity: the arrangement of the
commodities into the container, or the tours themselves? The answer is not
clear. First, given a pair (T1,T2) of pick-up and delivery tours, it is
polynomial to decide whether these tours are or not compatible. Second, for a
given arrangement of the commodities into the k rows of the container, the
optimum pick-up and delivery tours w.r.t. this arrangement can be computed
within a time that is polynomial in n, but exponential in k. Finally, we
provide instances on which a tour that is optimum for one of three distances
d1, d2 or d1+d2 lead to solutions of STSP that are arbitrarily far to the
optimum STSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5030</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5030</id><created>2010-09-25</created><authors><author><keyname>Toulouse</keyname><forenames>Sophie</forenames><affiliation>LIPN</affiliation></author></authors><title>Approximability of the Multiple Stack TSP</title><categories>cs.CC cs.RO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  STSP seeks a pair of pickup and delivery tours in two distinct networks,
where the two tours are related by LIFO contraints. We address here the problem
approximability. We notably establish that asymmetric MaxSTSP and MinSTSP12 are
APX, and propose a heuristic that yields to a 1/2, 3/4 and 3/2 standard
approximation for respectively Max2STSP, Max2STSP12 and Min2STSP12.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5031</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5031</id><created>2010-09-25</created><authors><author><keyname>Dridi</keyname><forenames>Imen Harbaoui</forenames><affiliation>LAGIS</affiliation></author><author><keyname>Kammarti</keyname><forenames>Ryan</forenames><affiliation>ACS</affiliation></author><author><keyname>Ksouri</keyname><forenames>Mekki</forenames><affiliation>ACS</affiliation></author><author><keyname>Borne</keyname><forenames>Pierre</forenames><affiliation>LAGIS</affiliation></author></authors><title>A Genetic Algorithm for the Multi-Pickup and Delivery Problem with time
  windows</title><categories>cs.NE</categories><proxy>ccsd</proxy><journal-ref>Studies in Informatics and Control 18, 2 (2009) pages 173-180</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In This paper we present a genetic algorithm for the multi-pickup and
delivery problem with time windows (m-PDPTW). The m-PDPTW is an optimization
vehicles routing problem which must meet requests for transport between
suppliers and customers satisfying precedence, capacity and time constraints.
This paper purposes a brief literature review of the PDPTW, present our
approach based on genetic algorithms to minimizing the total travel distance
and thereafter the total travel cost, by showing that an encoding represents
the parameters of each individual.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5037</identifier>
 <datestamp>2011-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5037</id><created>2010-09-25</created><updated>2010-09-30</updated><authors><author><keyname>Ashwinkumar</keyname><forenames>B. V.</forenames></author></authors><title>Buyback Problem - Approximate matroid intersection with cancellation
  costs</title><categories>cs.GT cs.DM</categories><journal-ref>ICALP'11 Lecture Notes in Computer Science, 2011, Volume
  6755/2011, 379-390</journal-ref><doi>10.1007/978-3-642-22006-7_32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the buyback problem, an algorithm observes a sequence of bids and must
decide whether to accept each bid at the moment it arrives, subject to some
constraints on the set of accepted bids. Decisions to reject bids are
irrevocable, whereas decisions to accept bids may be canceled at a cost that is
a fixed fraction of the bid value. Previous to our work, deterministic and
randomized algorithms were known when the constraint is a matroid constraint.
We extend this and give a deterministic algorithm for the case when the
constraint is an intersection of $k$ matroid constraints. We further prove a
matching lower bound on the competitive ratio for this problem and extend our
results to arbitrary downward closed set systems. This problem has applications
to banner advertisement, semi-streaming, routing, load balancing and other
problems where preemption or cancellation of previous allocations is allowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5048</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5048</id><created>2010-09-25</created><authors><author><keyname>Masum</keyname><forenames>Abdul Kadar Muhammad</forenames></author><author><keyname>Hassan</keyname><forenames>Mohammad Mahadi</forenames></author><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author></authors><title>The Most Advantageous Bangla Keyboard Layout Using Data Mining Technique</title><categories>cs.AI</categories><comments>10 Pages, International Journal</comments><journal-ref>Journal of Computer Science, IBAIS University, Dkhaka, Bangladesh,
  Vol. 1, No. 2, Dec. 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bangla alphabet has a large number of letters, for this it is complicated to
type faster using Bangla keyboard. The proposed keyboard will maximize the
speed of operator as they can type with both hands parallel. Association rule
of data mining to distribute the Bangla characters in the keyboard is used
here. The frequencies of data consisting of monograph, digraph and trigraph are
analyzed, which are derived from data wire-house, and then used association
rule of data mining to distribute the Bangla characters in the layout.
Experimental results on several data show the effectiveness of the proposed
approach with better performance. This paper presents an optimal Bangla
Keyboard Layout, which distributes the load equally on both hands so that
maximizing the ease and minimizing the effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5055</identifier>
 <datestamp>2013-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5055</id><created>2010-09-25</created><updated>2013-10-18</updated><authors><author><keyname>Lin</keyname><forenames>Zhouchen</forenames></author><author><keyname>Chen</keyname><forenames>Minming</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted
  Low-Rank Matrices</title><categories>math.OC cs.NA cs.SY</categories><comments>Please cite &quot;Zhouchen Lin, Risheng Liu, and Zhixun Su, Linearized
  Alternating Direction Method with Adaptive Penalty for Low Rank
  Representation, NIPS 2011.&quot; (available at arXiv:1109.0367) instead for a more
  general method called Linearized Alternating Direction Method This manuscript
  first appeared as University of Illinois at Urbana-Champaign technical report
  #UILU-ENG-09-2215 in October 2009 Zhouchen Lin, Risheng Liu, and Zhixun Su,
  Linearized Alternating Direction Method with Adaptive Penalty for Low Rank
  Representation, NIPS 2011. (available at http://arxiv.org/abs/1109.0367)</comments><doi>10.1016/j.jsb.2012.10.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes scalable and fast algorithms for solving the Robust PCA
problem, namely recovering a low-rank matrix with an unknown fraction of its
entries being arbitrarily corrupted. This problem arises in many applications,
such as image processing, web data ranking, and bioinformatic data analysis. It
was recently shown that under surprisingly broad conditions, the Robust PCA
problem can be exactly solved via convex optimization that minimizes a
combination of the nuclear norm and the $\ell^1$-norm . In this paper, we apply
the method of augmented Lagrange multipliers (ALM) to solve this convex
program. As the objective function is non-smooth, we show how to extend the
classical analysis of ALM to such new objective functions and prove the
optimality of the proposed algorithms and characterize their convergence rate.
Empirically, the proposed new algorithms can be more than five times faster
than the previous state-of-the-art algorithms for Robust PCA, such as the
accelerated proximal gradient (APG) algorithm. Moreover, the new algorithms
achieve higher precision, yet being less storage/memory demanding. We also show
that the ALM technique can be used to solve the (related but somewhat simpler)
matrix completion problem and obtain rather promising results too. We further
prove the necessary and sufficient condition for the inexact ALM to converge
globally. Matlab code of all algorithms discussed are available at
http://perception.csl.illinois.edu/matrix-rank/home.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5087</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5087</id><created>2010-09-26</created><authors><author><keyname>Talukder</keyname><forenames>Kamrul Hasan</forenames></author></authors><title>Bus Protocols: MSC-Based Specifications and Translation into Program of
  Verification Tool for Formal Verification</title><categories>cs.SE</categories><comments>13 pages, International Journal of the Computer, the Internet and
  Management</comments><journal-ref>International Journal of the Computer, the Internet and
  Management, Vol 15, Number 3, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Message Sequence Charts (MSCs) are an appealing visual formalism mainly used
in the early stages of system design to capture the system requirements.
However, if we move towards an implementation, an executable specifications
related in some fashion to the MSC-based requirements must be obtained. The
MSCs can be used effectively to specify the bus protocol in the way where
high-level transition systems is used to capture the control flow of the system
components of the protocol and MSCs to describe the non-atomic component
interactions. This system of specification is amenable to formal verification.
In this paper, we present the way how we can specify the bus protocols using
MSCs and how these specifications can be translated into program of
verification tool (we have used Symbolic Model Verifier (SMV)) for the use of
formal verification. We have contributed to the following tasks in this
respect. Firstly, the way to specify the protocol using MSC has been presented.
Secondly, a translator that translates the specifications (described in a
textual input file) into SMV programs has been constructed. Finally, we have
presented the verification result of the AMBA bus protocol using the SMV
program found through the translation process. The SMV program found through
the translation process can be used in order to automatically verify various
properties of any bus protocol specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5088</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5088</id><created>2010-09-26</created><authors><author><keyname>Ripon</keyname><forenames>Shamim Hasnat</forenames></author><author><keyname>Talukder</keyname><forenames>Kamrul Hasan</forenames></author><author><keyname>Molla</keyname><forenames>Khademul Islam</forenames></author></authors><title>Modelling Variability for System Families</title><categories>cs.SE</categories><comments>10 pages, Malaysian Journal of Computer Science, Vol. 16 No. 1, June
  2003, pp. 37-46</comments><report-no>KHT9375</report-no><journal-ref>Malaysian Journal of Computer Science, Vol. 16 No. 1, 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an approach to facilitate the treatment with variabilities in
system families is presented by explicitly modelling variants. The proposed
method of managing variability consists of a variant part, which models
variants and a decision table to depict the customisation decision regarding
each variant. We have found that it is easy to implement and has advantage over
other methods. We present this model as an integral part of modelling system
families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5094</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5094</id><created>2010-09-26</created><updated>2011-05-23</updated><authors><author><keyname>Gajardo</keyname><forenames>Pedro</forenames><affiliation>MISTEA, Lbe</affiliation></author><author><keyname>Harmand</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>MISTEA, Lbe</affiliation></author><author><keyname>Cabrera</keyname><forenames>Hector Ramirez</forenames><affiliation>CMM</affiliation></author><author><keyname>Rapaport</keyname><forenames>Alain</forenames><affiliation>MISTEA</affiliation></author></authors><title>Minimal-time bioremediation of natural water resources</title><categories>math.OC cs.SY math.DS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study minimal time strategies for the treatment of pollution of large
volumes, such as lakes or natural reservoirs, with the help of an autonomous
bioreactor. The control consists in feeding the bioreactor from the resource,
the clean output returning to the resource with the same flow rate. We first
characterize the optimal policies among constant and feedback controls, under
the assumption of a uniform concentration in the resource. In a second part, we
study the influence of an inhomogeneity in the resource, considering two
measurements points. With the help of the Maximum Principle, we show that the
optimal control law is non-monotonic and terminates with a constant phase,
contrary to the homogeneous case for which the optimal flow rate is decreasing
with time. This study allows the decision makers to identify situations for
which the benefit of using non-constant flow rates is significant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5098</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5098</id><created>2010-09-26</created><authors><author><keyname>Chakraborty</keyname><forenames>Avik</forenames></author></authors><title>Testing of Bridging Faults in AND-EXOR based Reversible Logic Circuits</title><categories>cs.OH</categories><comments>6 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible circuits find applications in many areas of Computer Science
including Quantum Computation. This paper examines the testability of an
important subclass of reversible logic circuits that are composed of k-wire
controlled NOT (k-CNOT with k &gt;/- 1) gates. A reversible k-CNOT gate can be
implemented using an irreversible k-input AND gate and an EXOR gate. A
reversible k-CNOT circuit where each k-CNOT gate is realized using irreversible
k-input AND and EXOR gate, has been considered. One of the most commonly used
Single Bridging Fault model (both wired-AND and wired-OR) has been assumed to
be type of fault for such circuits. It has been shown that an (n+p)-input
AND-EXOR based reversible logic circuit with p observable outputs, can be
tested for single bridging faults (SBF) using (3n + \lefthalfcap log2p
\righthalfcap + 2) tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5104</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5104</id><created>2010-09-26</created><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author></authors><title>The Equivalence of Sampling and Searching</title><categories>quant-ph cs.CC</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a sampling problem, we are given an input x, and asked to sample
approximately from a probability distribution D_x. In a search problem, we are
given an input x, and asked to find a member of a nonempty set A_x with high
probability. (An example is finding a Nash equilibrium.) In this paper, we use
tools from Kolmogorov complexity and algorithmic information theory to show
that sampling and search problems are essentially equivalent. More precisely,
for any sampling problem S, there exists a search problem R_S such that, if C
is any &quot;reasonable&quot; complexity class, then R_S is in the search version of C if
and only if S is in the sampling version. As one application, we show that
SampP=SampBQP if and only if FBPP=FBQP: in other words, classical computers can
efficiently sample the output distribution of every quantum circuit, if and
only if they can efficiently solve every search problem that quantum computers
can solve. A second application is that, assuming a plausible conjecture, there
exists a search problem R that can be solved using a simple linear-optics
experiment, but that cannot be solved efficiently by a classical computer
unless the polynomial hierarchy collapses. That application will be described
in a forthcoming paper with Alex Arkhipov on the computational complexity of
linear optics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5108</identifier>
 <datestamp>2012-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5108</id><created>2010-09-26</created><updated>2012-03-09</updated><authors><author><keyname>Musatov</keyname><forenames>Daniil</forenames></author></authors><title>Improving the Space-Bounded Version of Muchnik's Conditional Complexity
  Theorem via &quot;Naive&quot; Derandomization</title><categories>cs.CC</categories><comments>14 pages. Presented at CSR'2011, Yandex Best Student Paper Award</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many theorems about Kolmogorov complexity rely on existence of combinatorial
objects with specific properties. Usually the probabilistic method gives such
objects with better parameters than explicit constructions do. But the
probabilistic method does not give &quot;effective&quot; variants of such theorems, i.e.
variants for resource-bounded Kolmogorov complexity. We show that a &quot;naive
derandomization&quot; approach of replacing these objects by the output of
Nisan-Wigderson pseudo-random generator may give polynomial-space variants of
such theorems.
  Specifically, we improve the preceding polynomial-space analogue of Muchnik's
conditional complexity theorem. I.e., for all $a$ and $b$ there exists a
program $p$ of least possible length that transforms $a$ to $b$ and is simple
conditional on $b$. Here all programs work in polynomial space and all
complexities are measured with logarithmic accuracy instead of polylogarithmic
one in the previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5121</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5121</id><created>2010-09-26</created><updated>2012-12-28</updated><authors><author><keyname>Ning</keyname><forenames>Haishi</forenames></author><author><keyname>Maria~Estela</keyname></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author></authors><title>Noncoherent Interference Alignment: Trade Signal Power for Diversity
  Towards Multiplexing</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to an error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the first known universal interference alignment scheme
for general $(1\times{}1)^K$ interference networks, either Gaussian or
deterministic, with only 2 symbol extension. While interference alignment is
theoretically powerful to increase the total network throughput tremendously,
no existing scheme can achieve the degree of freedom upper bound exactly with
finite complexity. This paper starts with detailed analysis of the diagonality
problem of naive symbol extension in small $(1\times1)^3$ networks, a technique
widely regarded as necessary to achieve interference alignment with
insufficient diversity. Then, a joint bandpass noncoherent demodulation and
interference alignment scheme is proposed to solve the diagonality problem by
trading signal power for increased system diversity, which is further traded
for multiplexing improvement. Finally, the proposed noncoherent interference
alignment scheme is extended to general $(1\times{}1)^K$ cases and is proven to
achieve the degree of freedom upper bound exactly. Simulation results verify
the correctness and powerfulness of the proposed scheme and show significant
degree of freedom improvement compared to the conventional orthogonal
transmission scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5143</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5143</id><created>2010-09-26</created><updated>2010-10-01</updated><authors><author><keyname>Cao</keyname><forenames>Yixin</forenames></author><author><keyname>Chen</keyname><forenames>Jianer</forenames></author></authors><title>FAST: Kernelization based on Graph Modular Decomposition</title><categories>cs.DS</categories><comments>further improvement under progress</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernelization algorithms, usually a preprocessing step before other more
traditional algorithms, are very special in the sense that they return
(reduced) instances, instead of final results. This characteristic excludes the
freedom of applying a kernelization algorithm for the weighted version of a
problem to its unweighted instances. Thus with only very few special cases,
kernelization algorithms have to be studied separately for weigthed and
unweighted versions of a single problem. {\sc feedback arc set on tournament}
is currently a very popular problem in recent research of parameterized, as
well as approximation computation, and its wide applications in many areas make
it appear in all top conferences. The theory of graph modular decompositions is
a general approach in the study of graph structures, which only had its
surfaces touched in previous work on kernelization algorithms of {\sc feedback
arc set on tournament}. In this paper, we study further properties of graph
modular decompositions and apply them to obtain the first linear kernel for the
unweighted {\sc feedback arc set on tournament} problem, which only admits
linear kernel in its weighted version, while quadratic kernel for the
unweighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5145</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5145</id><created>2010-09-26</created><authors><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Louie</keyname><forenames>Raymond H. Y.</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Relay Selection with Network Coding in Two-Way Relay Channels</title><categories>cs.IT math.IT</categories><comments>11 pages, 5 figures</comments><journal-ref>IEEE Transactions on Vehicular Technology, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the design of joint network coding (NC)and relay
selection (RS) in two-way relay channels. In the proposed schemes, two users
first sequentially broadcast their respective information to all the relays. We
propose two RS schemes, a single relay selection with NC and a dual relay
selection with NC. For both schemes, the selected relay(s) perform NC on the
received signals sent from the two users and forward them to both users. The
proposed schemes are analyzed and the exact bit error rate (BER) expressions
are derived and verified through Monte Carlo simulations. It is shown that the
dual relay selection with NC outperforms other considered relay selection
schemes in two-way relay channels. The results also reveal that the proposed NC
relay selection schemes provide a selection gain compared to a NC scheme with
no relay selection, and a network coding gain relative to a conventional relay
selection scheme with no NC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5146</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5146</id><created>2010-09-26</created><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Prasad</keyname><forenames>Narayan</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Robust Linear Precoder Design for Multi-cell Downlink Transmission</title><categories>cs.IT math.IT</categories><comments>38 Pages, 7 Figures, To appear in the IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2010.2082537</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coordinated information processing by the base stations of multi-cell
wireless networks enhances the overall quality of communication in the network.
Such coordinations for optimizing any desired network-wide quality of service
(QoS) necessitate the base stations to acquire and share some channel state
information (CSI). With perfect knowledge of channel states, the base stations
can adjust their transmissions for achieving a network-wise QoS optimality. In
practice, however, the CSI can be obtained only imperfectly. As a result, due
to the uncertainties involved, the network is not guaranteed to benefit from a
globally optimal QoS. Nevertheless, if the channel estimation perturbations are
confined within bounded regions, the QoS measure will also lie within a bounded
region. Therefore, by exploiting the notion of robustness in the worst-case
sense some worst-case QoS guarantees for the network can be asserted. We adopt
a popular model for noisy channel estimates that assumes that estimation noise
terms lie within known hyper-spheres. We aim to design linear transceivers that
optimize a worst-case QoS measure in downlink transmissions. In particular, we
focus on maximizing the worst-case weighted sum-rate of the network and the
minimum worst-case rate of the network. For obtaining such transceiver designs,
we offer several centralized (fully cooperative) and distributed (limited
cooperation) algorithms which entail different levels of complexity and
information exchange among the base stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5149</identifier>
 <datestamp>2015-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5149</id><created>2010-09-26</created><authors><author><keyname>Ahmed</keyname><forenames>Eya ben</forenames></author><author><keyname>Gouider</keyname><forenames>Mohamed Salah</forenames></author></authors><title>Towards an incremental maintenance of cyclic association rules</title><categories>cs.DB</categories><report-no>November 2010, Volume 2, Number 4</report-no><journal-ref>International Journal of Database Management Systems (IJDMS),
  November 2010, Volume 2, Number 4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the cyclic association rules have been introduced in order to
discover rules from items characterized by their regular variation over time.
In real life situations, temporal databases are often appended or updated.
Rescanning the whole database every time is highly expensive while existing
incremental mining techniques can efficiently solve such a problem. In this
paper, we propose an incremental algorithm for cyclic association rules
maintenance. The carried out experiments of our proposal stress on its
efficiency and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5158</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5158</id><created>2010-09-27</created><updated>2011-02-20</updated><authors><author><keyname>Rajesh</keyname><forenames>R</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Information Capacity of Energy Harvesting Sensor Nodes</title><categories>cs.IT math.IT</categories><comments>6 Pages, Submitted to ISIT-2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor nodes with energy harvesting sources are gaining popularity due to
their ability to improve the network life time and are becoming a preferred
choice supporting `green communication'. We study such a sensor node with an
energy harvesting source and compare various architectures by which the
harvested energy is used. We find its Shannon capacity when it is transmitting
its observations over an AWGN channel and show that the capacity achieving
energy management policies are related to the throughput optimal policies. We
also obtain the capacity when energy conserving sleep-wake modes are supported
and an achievable rate for the system with inefficiencies in energy storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5161</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5161</id><created>2010-09-27</created><authors><author><keyname>Knuth</keyname><forenames>Kevin H.</forenames></author></authors><title>Information Physics: The New Frontier</title><categories>math-ph cond-mat.stat-mech cs.IT math.IT math.MP</categories><comments>17 pages, 6 figures. Knuth K.H. 2010. Information physics: The new
  frontier. J.-F. Bercher, P. Bessi\`ere, and A. Mohammad-Djafari (eds.)
  Bayesian Inference and Maximum Entropy Methods in Science and Engineering
  (MaxEnt 2010), Chamonix, France, July 2010</comments><doi>10.1063/1.3573644</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At this point in time, two major areas of physics, statistical mechanics and
quantum mechanics, rest on the foundations of probability and entropy. The last
century saw several significant fundamental advances in our understanding of
the process of inference, which make it clear that these are inferential
theories. That is, rather than being a description of the behavior of the
universe, these theories describe how observers can make optimal predictions
about the universe. In such a picture, information plays a critical role. What
is more is that little clues, such as the fact that black holes have entropy,
continue to suggest that information is fundamental to physics in general.
  In the last decade, our fundamental understanding of probability theory has
led to a Bayesian revolution. In addition, we have come to recognize that the
foundations go far deeper and that Cox's approach of generalizing a Boolean
algebra to a probability calculus is the first specific example of the more
fundamental idea of assigning valuations to partially-ordered sets. By
considering this as a natural way to introduce quantification to the more
fundamental notion of ordering, one obtains an entirely new way of deriving
physical laws. I will introduce this new way of thinking by demonstrating how
one can quantify partially-ordered sets and, in the process, derive physical
laws. The implication is that physical law does not reflect the order in the
universe, instead it is derived from the order imposed by our description of
the universe. Information physics, which is based on understanding the ways in
which we both quantify and process information about the world around us, is a
fundamentally new approach to science.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5167</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5167</id><created>2010-09-27</created><updated>2011-03-09</updated><authors><author><keyname>Fernique</keyname><forenames>Thomas</forenames><affiliation>LIF</affiliation></author><author><keyname>Ollinger</keyname><forenames>Nicolas</forenames><affiliation>LIF</affiliation></author></authors><title>Combinatorial substitutions and sofic tilings</title><categories>math.CO cs.DM</categories><comments>17 pages, 16 figures. In proceedings of JAC 2010</comments><proxy>ccsd</proxy><msc-class>52C23, 37B50, 05B45</msc-class><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A combinatorial substitution is a map over tilings which allows to define
sets of tilings with a strong hierarchical structure. In this paper, we show
that such sets of tilings are sofic, that is, can be enforced by finitely many
local constraints. This extends some similar previous results (Mozes'90,
Goodman-Strauss'98) in a much shorter presentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5168</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5168</id><created>2010-09-27</created><updated>2011-05-09</updated><authors><author><keyname>Voevodski</keyname><forenames>Konstantin</forenames></author><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Roglin</keyname><forenames>Heiko</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author><author><keyname>Xia</keyname><forenames>Yu</forenames></author></authors><title>Efficient Clustering with Limited Distance Information</title><categories>cs.DS</categories><comments>Full version of UAI 2010 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a point set S and an unknown metric d on S, we study the problem of
efficiently partitioning S into k clusters while querying few distances between
the points. In our model we assume that we have access to one versus all
queries that given a point s in S return the distances between s and all other
points. We show that given a natural assumption about the structure of the
instance, we can efficiently find an accurate clustering using only O(k)
distance queries. Our algorithm uses an active selection strategy to choose a
small set of points that we call landmarks, and considers only the distances
between landmarks and other points to produce a clustering. We use our
algorithm to cluster proteins by sequence similarity. This setting nicely fits
our model because we can use a fast sequence database search program to query a
sequence against an entire dataset. We conduct an empirical study that shows
that even though we query a small fraction of the distances between the points,
we produce clusterings that are close to a desired clustering given by manual
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5183</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5183</id><created>2010-09-27</created><authors><author><keyname>Reitz</keyname><forenames>Florian</forenames></author></authors><title>A Framework for an Ego-centered and Time-aware Visualization of
  Relations in Arbitrary Data Repositories</title><categories>cs.GR cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding constellations in large data collections has become a common
task. One obstacle a user has to overcome is the internal complexity of these
repositories. For example, extracting connected data from a normalized
relational database requires knowledge of the table structure which might not
be available for the casual user. In this paper we present a visualization
framework which presents the collection as a set of entities and relations (on
the data level). Using rating functions, we divide large relation networks into
small graphs which resemble ego-centered networks. These graphs are connected
so the user can browse from one to another. To further assist the user, we
present two views which embed information on the evolution of the relations
into the graphs. Each view emphasizes another aspect of temporal development.
The framework can be adapted to any repository by a flexible data interface and
a graph configuration file. We present some first web-based applications
including a visualization of the DBLP data set. We use the DBLP visualization
to evaluate our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5206</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5206</id><created>2010-09-27</created><updated>2010-12-21</updated><authors><author><keyname>Demri</keyname><forenames>Stephane</forenames><affiliation>LSV, ENS Cachan, CNRS, INRIA</affiliation></author><author><keyname>Rabinovich</keyname><forenames>Alexander</forenames><affiliation>School of CS, Tel Aviv University</affiliation></author></authors><title>The complexity of linear-time temporal logic over the class of ordinals</title><categories>cs.LO</categories><comments>Accepted for publication in LMCS</comments><proxy>LMCS</proxy><acm-class>F.4.1, F.3.1., F.2.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  21, 2010) lmcs:1230</journal-ref><doi>10.2168/LMCS-6(4:9)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the temporal logic with since and until modalities. This temporal
logic is expressively equivalent over the class of ordinals to first-order
logic by Kamp's theorem. We show that it has a PSPACE-complete satisfiability
problem over the class of ordinals. Among the consequences of our proof, we
show that given the code of some countable ordinal alpha and a formula, we can
decide in PSPACE whether the formula has a model over alpha. In order to show
these results, we introduce a class of simple ordinal automata, as expressive
as B\&quot;uchi ordinal automata. The PSPACE upper bound for the satisfiability
problem of the temporal logic is obtained through a reduction to the
nonemptiness problem for the simple ordinal automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5208</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5208</id><created>2010-09-27</created><updated>2011-04-26</updated><authors><author><keyname>Anta</keyname><forenames>Adolfo</forenames></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>Exploiting isochrony in self-triggered control</title><categories>math.OC cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event-triggered control and self-triggered control have been recently
proposed as new implementation paradigms that reduce resource usage for control
systems. In self-triggered control, the controller is augmented with the
computation of the next time instant at which the feedback control law is to be
recomputed. Since these execution instants are obtained as a function of the
plant state, we effectively close the loop only when it is required to maintain
the desired performance, thereby greatly reducing the resources required for
control. In this paper we present a new technique for the computation of the
execution instants by exploiting the concept of isochronous manifolds, also
introduced in this paper. While our previous results showed how homogeneity can
be used to compute the execution instants along some directions in the state
space, the concept of isochrony allows us to compute the executions instants
along every direction in the state space. Moreover, we also show in this paper
how to homogenize smooth control systems thus making our results applicable to
any smooth control system. The benefits of the proposed approach with respect
to existing techniques are analyzed in two examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5227</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5227</id><created>2010-09-27</created><authors><author><keyname>Argyriou</keyname><forenames>Evmorfia N.</forenames></author><author><keyname>Bekos</keyname><forenames>Michael A.</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>The Straight-Line RAC Drawing Problem is NP-Hard</title><categories>cs.DS</categories><comments>23 pages in total</comments><doi>10.1007/978-3-642-18381-2_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent cognitive experiments have shown that the negative impact of an edge
crossing on the human understanding of a graph drawing, tends to be eliminated
in the case where the crossing angles are greater than 70 degrees. This
motivated the study of RAC drawings, in which every pair of crossing edges
intersects at right angle. In this work, we demonstrate a class of graphs with
unique RAC combinatorial embedding and we employ members of this class in order
to show that it is NP-hard to decide whether a graph admits a straight-line RAC
drawing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5233</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5233</id><created>2010-09-27</created><updated>2010-10-04</updated><authors><author><keyname>Nassar</keyname><forenames>Nassib</forenames></author></authors><title>A Simple Abstraction for Data Modeling</title><categories>cs.DB cs.DL</categories><comments>10 pages, 2 figures, LaTeX; added two definitions in section 2</comments><acm-class>H.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problems that scientists face in creating well designed databases
intersect with the concerns of data curation. Entity-relationship modeling and
its variants have been the basis of most relational data modeling for decades.
However, these abstractions and the relational model itself are intricate and
have proved not to be very accessible among scientists with limited resources
for data management. This paper explores one aspect of relational data models,
the meaning of foreign key relationships. We observe that a foreign key
produces a table relationship that generally references either an entity or
repeating attributes. This paper proposes constructing foreign keys based on
these two cases, and suggests that the method promotes intuitive data modeling
and normalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5249</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5249</id><created>2010-09-27</created><updated>2011-04-07</updated><authors><author><keyname>Liu</keyname><forenames>Xintao</forenames></author><author><keyname>Jiang</keyname><forenames>Bin</forenames></author></authors><title>Defining and Generating Axial Lines from Street Center Lines for better
  Understanding of Urban Morphologies</title><categories>cs.CV physics.data-an</categories><comments>10 pages, 7 figures, and 2 tables, one figure added + minor revision</comments><journal-ref>International Journal of Geographical Information Science, 26(8),
  2012, 1521-1532</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Axial lines are defined as the longest visibility lines for representing
individual linear spaces in urban environments. The least number of axial lines
that cover the free space of an urban environment or the space between
buildings constitute what is often called an axial map. This is a fundamental
tool in space syntax, a theory developed by Bill Hillier and his colleagues for
characterizing the underlying urban morphologies. For a long time, generating
axial lines with help of some graphic software has been a tedious manual
process that is criticized for being time consuming, subjective, or even
arbitrary. In this paper, we redefine axial lines as the least number of
individual straight line segments mutually intersected along natural streets
that are generated from street center lines using the Gestalt principle of good
continuity. Based on this new definition, we develop an automatic solution to
generating the newly defined axial lines from street center lines. We apply
this solution to six typical street networks (three from North America and
three from Europe), and generate a new set of axial lines for analyzing the
urban morphologies. Through a comparison study between the new axial lines and
the conventional or old axial lines, and between the new axial lines and
natural streets, we demonstrate with empirical evidence that the newly defined
axial lines are a better alternative in capturing the underlying urban
structure.
  Keywords: Space syntax, street networks, topological analysis, traffic,
head/tail division rule
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5257</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5257</id><created>2010-09-27</created><authors><author><keyname>Fang</keyname><forenames>Yong</forenames></author></authors><title>Approximation of DAC Codeword Distribution for Equiprobable Binary
  Sources along Proper Decoding Paths</title><categories>cs.IT math.IT</categories><comments>19 pages, 4 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Arithmetic Coding (DAC) is an effective implementation of
Slepian-Wolf coding, especially for short data blocks. To research its
properties, the concept of DAC codeword distribution along proper and wrong
decoding paths has been introduced. For DAC codeword distribution of
equiprobable binary sources along proper decoding paths, the problem was
formatted as solving a system of functional equations. However, up to now, only
one closed form was obtained at rate 0.5, while in general cases, to find the
closed form of DAC codeword distribution still remains a very difficult task.
This paper proposes three kinds of approximation methods for DAC codeword
distribution of equiprobable binary sources along proper decoding paths:
numeric approximation, polynomial approximation, and Gaussian approximation.
Firstly, as a general approach, a numeric method is iterated to find the
approximation to DAC codeword distribution. Secondly, at rates lower than 0.5,
DAC codeword distribution can be well approximated by a polynomial. Thirdly, at
very low rates, a Gaussian function centered at 0.5 is proved to be a good and
simple approximation to DAC codeword distribution. A simple way to estimate the
variance of Gaussian function is also proposed. Plenty of simulation results
are given to verify theoretical analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5268</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5268</id><created>2010-09-27</created><authors><author><keyname>Liu</keyname><forenames>Xin</forenames></author><author><keyname>Ding</keyname><forenames>Ying</forenames></author><author><keyname>Bao</keyname><forenames>Forrest Sheng</forenames></author></authors><title>General Scaled Support Vector Machines</title><categories>cs.AI</categories><comments>5 pages, 4 figures</comments><acm-class>I.5.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Support Vector Machines (SVMs) are popular tools for data mining tasks such
as classification, regression, and density estimation. However, original SVM
(C-SVM) only considers local information of data points on or over the margin.
Therefore, C-SVM loses robustness. To solve this problem, one approach is to
translate (i.e., to move without rotation or change of shape) the hyperplane
according to the distribution of the entire data. But existing work can only be
applied for 1-D case. In this paper, we propose a simple and efficient method
called General Scaled SVM (GS-SVM) to extend the existing approach to
multi-dimensional case. Our method translates the hyperplane according to the
distribution of data projected on the normal vector of the hyperplane. Compared
with C-SVM, GS-SVM has better performance on several data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5282</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5282</id><created>2010-09-27</created><authors><author><keyname>Keyes</keyname><forenames>Roy W.</forenames></author><author><keyname>Romano</keyname><forenames>Christian</forenames></author><author><keyname>Arnold</keyname><forenames>Dorian</forenames></author><author><keyname>Luan</keyname><forenames>Shuang</forenames></author></authors><title>Radiation therapy calculations using an on-demand virtual cluster via
  cloud computing</title><categories>physics.med-ph cs.DC physics.comp-ph</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer hardware costs are the limiting factor in producing highly accurate
radiation dose calculations on convenient time scales. Because of this,
large-scale, full Monte Carlo simulations and other resource intensive
algorithms are often considered infeasible for clinical settings. The emerging
cloud computing paradigm promises to fundamentally alter the economics of such
calculations by providing relatively cheap, on-demand, pay-as-you-go computing
resources over the Internet. We believe that cloud computing will usher in a
new era, in which very large scale calculations will be routinely performed by
clinics and researchers using cloud-based resources. In this research, several
proof-of-concept radiation therapy calculations were successfully performed on
a cloud-based virtual Monte Carlo cluster. Performance evaluations were made of
a distributed processing framework developed specifically for this project. The
expected 1/n performance was observed with some caveats. The economics of
cloud-based virtual computing clusters versus traditional in-house hardware is
also discussed. For most situations, cloud computing can provide a substantial
cost savings for distributed calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5290</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5290</id><created>2010-09-27</created><authors><author><keyname>Nikolic</keyname><forenames>Mladen</forenames></author></authors><title>Measuring Similarity of Graphs and their Nodes by Neighbor Matching</title><categories>cs.AI</categories><msc-class>05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of measuring similarity of graphs and their nodes is important in
a range of practical problems. There is a number of proposed measures, some of
them being based on iterative calculation of similarity between two graphs and
the principle that two nodes are as similar as their neighbors are. In our
work, we propose one novel method of that sort, with a refined concept of
similarity of two nodes that involves matching of their neighbors. We prove
convergence of the proposed method and show that it has some additional
desirable properties that, to our knowledge, the existing methods lack. We
illustrate the method on two specific problems and empirically compare it to
other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5316</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5316</id><created>2010-09-27</created><authors><author><keyname>Piontti</keyname><forenames>Ana L. Pastore y</forenames></author><author><keyname>Braunstein</keyname><forenames>Lidia A.</forenames></author><author><keyname>Macri</keyname><forenames>Pablo A.</forenames></author></authors><title>Jamming in complex networks with degree correlation</title><categories>physics.soc-ph cs.SI physics.comp-ph</categories><journal-ref>Physics Letters A 374 (2010) 4658-4663</journal-ref><doi>10.1016/j.physleta.2010.09.050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the effects of the degree-degree correlations on the pressure
congestion J when we apply a dynamical process on scale free complex networks
using the gradient network approach. We find that the pressure congestion for
disassortative (assortative) networks is lower (bigger) than the one for
uncorrelated networks which allow us to affirm that disassortative networks
enhance transport through them. This result agree with the fact that many real
world transportation networks naturally evolve to this kind of correlation. We
explain our results showing that for the disassortative case the clusters in
the gradient network turn out to be as much elongated as possible, reducing the
pressure congestion J and observing the opposite behavior for the assortative
case. Finally we apply our model to real world networks, and the results agree
with our theoretical model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5321</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5321</id><created>2010-09-27</created><authors><author><keyname>Sunny</keyname><forenames>Albert</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author><author><keyname>Aggarwal</keyname><forenames>Saurabh</forenames></author></authors><title>Application Delay Modelling for Variable Length Packets in Single Cell
  IEEE 802.11 WLANs</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of modelling the average delay
experienced by an application packets of variable length in a single cell IEEE
802.11 DCF wireless local area network. The packet arrival process at each node
i is assumed to be a stationary and independent increment random process with
mean ai and second moment a(2) i . The packet lengths at node i are assumed to
be i.i.d random variables Pi with finite mean and second moment. A closed form
expression has been derived for the same. We assume the input arrival process
across queues to be uncorrelated Poison processes. As the nodes share a single
channel, they have to contend with one another for a successful transmission.
The mean delay for a packet has been approximated by modelling the system as a
1-limited Random Polling system with zero switchover times. Extensive
simulations are conducted to verify the analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5338</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5338</id><created>2010-09-27</created><authors><author><keyname>Fatahi</keyname><forenames>Somayeh</forenames></author><author><keyname>Manashty</keyname><forenames>Ali Reza</forenames></author><author><keyname>Jahromi</keyname><forenames>Zahra Forootan</forenames></author></authors><title>Vast Educational Mobile Content Broadcasting using ARMrayan Multimedia
  Mobile CMS</title><categories>cs.CY</categories><comments>6 Pages, 3 figures, IEEE publication format, Keywords- mobile
  education; m-commerce; mobile CMS; multimedia cms; mobile; content
  broadcasting; mobile catalogue; education; J2ME</comments><msc-class>97U70</msc-class><acm-class>K.3.0; K.4.4</acm-class><journal-ref>International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 8, No. 5, August 2010, ISSN 1947-5500, Pages 101-106</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The huge information flow currently available to young generation makes it
difficult for educational centers to train them as needed. Most of these
information flows occur in transportation time or while on public areas.
Competing with commercial information streams is far out of educational centers
time and budget. For creating enough mobile applications for vast educational
mobile content broadcasting that can match young spirits as well, we designed
and developed the ARMrayan Multimedia Mobile CMS as the software that helps
communities, educational, cultural or marketing centers in a way that ordinary
operators be able to create a variety of fully functional multimedia mobile
applications such as tutorials, catalogues, books, and guides in minutes
without writing even a line of code. In this paper, we present the role of our
developed software in our proposed vast educational content broadcasting system
using kiosks and Bluetooth advertising, which will lead to a great leap in
M-commerce marketing and public education solutions. Related experiences are
described and diagrams are used to illustrate the solution. Upon release of the
software, it achieved two titles and prizes in different festivals and various
cultural and commercial centers became its customers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5341</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5341</id><created>2010-09-27</created><updated>2012-06-26</updated><authors><author><keyname>Oliveira</keyname><forenames>Mateus de Oliveira</forenames></author></authors><title>Canonizable Partial Order Generators and Regular Slice Languages</title><categories>cs.FL cs.DC</categories><comments>38 pages. 9 Figures. This work extends the paper &quot;Canonizable Partial
  Order Generators&quot; by the same author that appeared in the Proc. of the 6-th
  International Conference on Language and Automata Theory and Applications
  (LATA 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous work we introduced slice graphs as a way to specify both
infinite languages of directed acyclic graphs (DAGs) and infinite languages of
partial orders. Therein we focused on the study of Hasse diagram generators,
i.e., slice graphs that generate only transitive reduced DAGs, and showed that
they could be used to solve several problems related to the partial order
behavior of p/t-nets. In the present work we show that both slice graphs and
Hasse diagram generators are worth studying on their own. First, we prove that
any slice graph SG can be effectively transformed into a Hasse diagram
generator HG representing the same set of partial orders. Thus from an
algorithmic standpoint we introduce a method of transitive reducing infinite
families of DAGs specified by slice graphs. Second, we identify the class of
saturated slice graphs. By using our transitive reduction algorithm, we prove
that the class of partial order languages representable by saturated slice
graphs is closed under union, intersection and even under a suitable notion of
complementation (cut-width complementation). Furthermore partial order
languages belonging to this class can be tested for inclusion and admit
canonical representatives in terms of Hasse diagram generators. As an
application of our results, we give stronger forms of some results in our
previous work, and establish some unknown connections between the partial order
behavior of $p/t$-nets and other well known formalisms for the specification of
infinite families of partial orders, such as Mazurkiewicz trace languages and
message sequence chart (MSC) languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5344</identifier>
 <datestamp>2012-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5344</id><created>2010-09-27</created><updated>2012-03-11</updated><authors><author><keyname>Pilaud</keyname><forenames>Vincent</forenames></author><author><keyname>Pocchiola</keyname><forenames>Michel</forenames></author></authors><title>Multitriangulations, pseudotriangulations and primitive sorting networks</title><categories>math.CO cs.CG</categories><comments>60 pages, 40 figures; minor corrections and improvements of
  presentation</comments><msc-class>52C30, 52C20, 05C62, 05A05</msc-class><journal-ref>Discrete Comput. Geom., 48(1):142-191, 2012</journal-ref><doi>10.1007/s00454-012-9408-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the set of all pseudoline arrangements with contact points which
cover a given support. We define a natural notion of flip between these
arrangements and study the graph of these flips. In particular, we provide an
enumeration algorithm for arrangements with a given support, based on the
properties of certain greedy pseudoline arrangements and on their connection
with sorting networks. Both the running time per arrangement and the working
space of our algorithm are polynomial.
  As the motivation for this work, we provide in this paper a new
interpretation of both pseudotriangulations and multitriangulations in terms of
pseudoline arrangements on specific supports. This interpretation explains
their common properties and leads to a natural definition of
multipseudotriangulations, which generalizes both. We study elementary
properties of multipseudotriangulations and compare them to iterations of
pseudotriangulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5346</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5346</id><created>2010-09-27</created><authors><author><keyname>Kuttikrishnan</keyname><forenames>Murugesan</forenames></author></authors><title>A Novel Approach for Cardiac Disease Prediction and Classification Using
  Intelligent Agents</title><categories>cs.MA cs.AI</categories><comments>8 pages 2 figures and 7 tables</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 8, No. 5, August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal is to develop a novel approach for cardiac disease prediction and
diagnosis using intelligent agents. Initially the symptoms are preprocessed
using filter and wrapper based agents. The filter removes the missing or
irrelevant symptoms. Wrapper is used to extract the data in the data set
according to the threshold limits. Dependency of each symptom is identified
using dependency checker agent. The classification is based on the prior and
posterior probability of the symptoms with the evidence value. Finally the
symptoms are classified in to five classes namely absence, starting, mild,
moderate and serious. Using the cooperative approach the cardiac problem is
solved and verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5347</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5347</id><created>2010-09-27</created><authors><author><keyname>Manashty</keyname><forenames>Ali Reza</forenames></author><author><keyname>Raji</keyname><forenames>Mohammad Reza Ahmadzadeh</forenames></author><author><keyname>Jahromi</keyname><forenames>Zahra Forootan</forenames></author><author><keyname>Rajabzadeh</keyname><forenames>Amir</forenames></author></authors><title>ARMrayan Multimedia Mobile CMS: a Simplified Approach towards
  Content-Oriented Mobile Application Designing</title><categories>cs.OH</categories><comments>6 Pages, 4 figures, Keywords- Mobile CMS, MCMS, Mobile Content
  Builder, J2ME Application, Multimedia Mobile Application, Multimedia CMS,
  Multimedia Mobile CMS, Content Management System; ISSN. 2070-3724</comments><msc-class>97R10</msc-class><acm-class>K.4.4</acm-class><journal-ref>International Conference on Wireless Communication and Mobile
  Computing (ICWCMC 2010), Proceedings of WASET, vol. 62, pp. 62-67, February
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ARMrayan Multimedia Mobile CMS (Content Management System) is the first
mobile CMS that gives the opportunity to users for creating multimedia J2ME
mobile applications with their desired content, design and logo; simply,
without any need for writing even a line of code. The low-level programming and
compatibility problems of the J2ME, along with UI designing difficulties, makes
it hard for most people -even programmers- to broadcast their content to the
widespread mobile phones used by nearly all people. This system provides
user-friendly, PC-based tools for creating a tree index of pages and inserting
multiple multimedia contents (e.g. sound, video and picture) in each page for
creating a J2ME mobile application. The output is a stand-alone Java mobile
application that has a user interface, shows texts and pictures and plays music
and videos regardless of the type of devices used as long as the devices
support the J2ME platform. Bitmap fonts have also been used thus Middle Eastern
languages can be easily supported on all mobile phone devices. We omitted
programming concepts for users in order to simplify multimedia content-oriented
mobile application designing for use in educational, cultural or marketing
centers. Ordinary operators can now create a variety of multimedia mobile
applications such as tutorials, catalogues, books, and guides in minutes rather
than months. Simplicity and power has been the goal of this CMS. In this paper,
we present the software engineered-designed concepts of the ARMrayan MCMS along
with the implementation challenges faces and solutions adapted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5352</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5352</id><created>2010-09-27</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Zapilko</keyname><forenames>Benjamin</forenames></author><author><keyname>Sure</keyname><forenames>York</forenames></author></authors><title>Establishing a Multi-Thesauri-Scenario based on SKOS and
  Cross-Concordances</title><categories>cs.DL cs.IR</categories><comments>3 pages, Dublin Core conference 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This case study proposes a scenario with three topic-related thesauri, which
have been connected with bilateral cross-concordances as part of a major
terminology mapping initiative in the project KoMoHe (Mayr &amp; Petras, 2008). The
thesauri have already been or will be converted to SKOS and in order to not
omit the relevant crosswalks, the mapping properties of SKOS will be used for
modeling them adequately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5397</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5397</id><created>2010-09-27</created><updated>2010-11-04</updated><authors><author><keyname>Batu</keyname><forenames>Tugkan</forenames></author><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Rubinfeld</keyname><forenames>Ronitt</forenames></author><author><keyname>Smith</keyname><forenames>Warren D.</forenames></author><author><keyname>White</keyname><forenames>Patrick</forenames></author></authors><title>Testing Closeness of Discrete Distributions</title><categories>cs.DS math.PR math.ST stat.TH</categories><comments>26 pages, A preliminary version of this paper appeared in the 41st
  Symposium on Foundations of Computer Science, 2000, Redondo Beach, CA, A
  comment from W.D. Smith has been added on the title page</comments><acm-class>F.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given samples from two distributions over an $n$-element set, we wish to test
whether these distributions are statistically close. We present an algorithm
which uses sublinear in $n$, specifically, $O(n^{2/3}\epsilon^{-8/3}\log n)$,
independent samples from each distribution, runs in time linear in the sample
size, makes no assumptions about the structure of the distributions, and
distinguishes the cases when the distance between the distributions is small
(less than $\max\{\epsilon^{4/3}n^{-1/3}/32, \epsilon n^{-1/2}/4\}$) or large
(more than $\epsilon$) in $\ell_1$ distance. This result can be compared to the
lower bound of $\Omega(n^{2/3}\epsilon^{-2/3})$ for this problem given by
Valiant.
  Our algorithm has applications to the problem of testing whether a given
Markov process is rapidly mixing. We present sublinear for several variants of
this problem as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5398</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5398</id><created>2010-09-27</created><authors><author><keyname>Manashty</keyname><forenames>Ali Reza</forenames></author><author><keyname>Rajabzadeh</keyname><forenames>Amir</forenames></author><author><keyname>Jahromi</keyname><forenames>Zahra Forootan</forenames></author></authors><title>A Scenario-Based Mobile Application for Robot-Assisted Smart Digital
  Homes</title><categories>cs.RO</categories><comments>8 pages, 8 figures, IEEE Publication format, Keywords- smart homes;
  mobile applications; remote home controls; automated digital homes; robot
  assisted at home; general packet radio service (GPRS); short message system
  (SMS); robot assisted at home; scenario based smart home</comments><msc-class>93C95</msc-class><acm-class>J.7</acm-class><journal-ref>International Journal of Computer Science and Information Security
  (IJCSIS), Vol. 8, No. 5, August 2010, ISSN 1947-5500, Pages 89-96</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart homes are becoming more popular, as every day a new home appliance can
be digitally controlled. Smart Digital Homes are using a server to make
interaction with all the possible devices in one place, on a computer or
webpage. In this paper we designed and implemented a mobile application using
Windows Mobile platform that can connect to the controlling server of a Smart
Home and grants the access to the Smart Home devices and robots everywhere
possible. UML diagrams are presented to illustrate the application design
process. Robots are also considered as devices that are able to interact to
other object and devices. Scenarios are defined as a set of sequential actions
to help manage different tasks all in one place. The mobile application can
connect to the server using GPRS mobile internet and Short Message System
(SMS). Interactive home map is also designed for easier status-checking and
interacting with the devices using the mobile phones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5403</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5403</id><created>2010-09-27</created><authors><author><keyname>Aperjis</keyname><forenames>Christina</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Social Attention and the Provider's Dilemma</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While attracting attention is one of the prime goals of content providers,
the conversion of that attention into revenue is by no means obvious. Given
that most users expect to consume web content for free, a provider with an
established audience faces a dilemma. Since the introduction of advertisements
or subscription fees will be construed by users as an inconvenience which may
lead them to stop using the site, what should the provider do in order to
maximize revenues? We address this question through the lens of adaptation
theory, which states that even though a change affects a person's utility
initially, as time goes on people tend to adapt and become less aware of past
changes. We establish that if the likelihood of continuing to attend to the
provider after an increase in inconvenience is log-concave in the magnitude of
the increase, then the provider faces a tradeoff between achieving a higher
revenue per user sooner and maximizing the number of users in the long term. On
the other hand, if the likelihood of continuing to attend to the provider after
an increase in inconvenience is log-convex, then it is always optimal for the
provider to perform the increase in one step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5419</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5419</id><created>2010-09-27</created><updated>2011-03-07</updated><authors><author><keyname>Brochu</keyname><forenames>Eric</forenames></author><author><keyname>Hoffman</keyname><forenames>Matthew W.</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Portfolio Allocation for Bayesian Optimization</title><categories>cs.LG</categories><comments>This revision contains an updated the performance bound and other
  minor text changes</comments><acm-class>G.1.6; G.3; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian optimization with Gaussian processes has become an increasingly
popular tool in the machine learning community. It is efficient and can be used
when very little is known about the objective function, making it popular in
expensive black-box optimization scenarios. It uses Bayesian methods to sample
the objective efficiently using an acquisition function which incorporates the
model's estimate of the objective and the uncertainty at any given point.
However, there are several different parameterized acquisition functions in the
literature, and it is often unclear which one to use. Instead of using a single
acquisition function, we adopt a portfolio of acquisition functions governed by
an online multi-armed bandit strategy. We propose several portfolio strategies,
the best of which we call GP-Hedge, and show that this method outperforms the
best individual acquisition function. We also provide a theoretical bound on
the algorithm's performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5423</identifier>
 <datestamp>2013-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5423</id><created>2010-09-27</created><updated>2011-05-30</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author><author><keyname>Debbabi</keyname><forenames>Mourad</forenames></author></authors><title>The Need to Support of Data Flow Graph Visualization of Forensic Lucid
  Programs, Forensic Evidence, and their Evaluation by GIPSY</title><categories>cs.PL cs.CR cs.GR</categories><comments>11 pages, 7 figures, index; extended abstract presented at VizSec'10
  at http://www.vizsec2010.org/posters ; short paper accepted at PST'11</comments><acm-class>D.1.7; D.2.11; D.3.2; D.3.4</acm-class><doi>10.1109/PST.2011.5971973</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lucid programs are data-flow programs and can be visually represented as data
flow graphs (DFGs) and composed visually. Forensic Lucid, a Lucid dialect, is a
language to specify and reason about cyberforensic cases. It includes the
encoding of the evidence (representing the context of evaluation) and the crime
scene modeling in order to validate claims against the model and perform event
reconstruction, potentially within large swaths of digital evidence. To aid
investigators to model the scene and evaluate it, instead of typing a Forensic
Lucid program, we propose to expand the design and implementation of the Lucid
DFG programming onto Forensic Lucid case modeling and specification to enhance
the usability of the language and the system and its behavior. We briefly
discuss the related work on visual programming an DFG modeling in an attempt to
define and select one approach or a composition of approaches for Forensic
Lucid based on various criteria such as previous implementation, wide use,
formal backing in terms of semantics and translation. In the end, we solicit
the readers' constructive, opinions, feedback, comments, and recommendations
within the context of this short discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5432</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5432</id><created>2010-09-27</created><authors><author><keyname>Hayashi</keyname><forenames>Yukio</forenames></author></authors><title>An approximative calculation of the fractal structure in self-similar
  tilings</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>5 pages, 6 figures</comments><journal-ref>IEICE Trans. on Fundamantals, Vol.E94-A, No.2, pp,846-849, 2011</journal-ref><doi>10.1587/transfun.E94.A.846</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractal structures emerge from statistical and hierarchical processes in
urban development or network evolution. In a class of efficient and robust
geographical networks, we derive the size distribution of layered areas, and
estimate the fractal dimension by using the distribution without huge
computations. This method can be applied to self-similar tilings based on a
stochastic process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5435</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5435</id><created>2010-09-27</created><authors><author><keyname>Zhu</keyname><forenames>Guohun</forenames></author></authors><title>Determining All Maximum Uniquely Restricted Matching in Bipartite Graphs</title><categories>cs.CC cs.DS</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The approach mapping from a matching of bipartite graphs to digraphs has been
successfully used for forcing set problem, in this paper, it is extended to
uniquely restricted matching problem. We show to determine a uniquely
restricted matching in a bipartite graph is equivalent to recognition a acyclic
digraph. Based on these results, it proves that determine the bipartite graphs
with all maximum matching are uniquely restricted is polynomial time. This
answers an open question of Levit and Mandrescu(Discrete Applied Mathematics
132(2004) 163-164).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5473</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5473</id><created>2010-09-28</created><authors><author><keyname>Merolla</keyname><forenames>Paul</forenames></author><author><keyname>Ursell</keyname><forenames>Tristan</forenames></author><author><keyname>Arthur</keyname><forenames>John</forenames></author></authors><title>The thermodynamic temperature of a rhythmic spiking network</title><categories>cs.NE cs.AI q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial neural networks built from two-state neurons are powerful
computational substrates, whose computational ability is well understood by
analogy with statistical mechanics. In this work, we introduce similar
analogies in the context of spiking neurons in a fixed time window, where
excitatory and inhibitory inputs drawn from a Poisson distribution play the
role of temperature. For single neurons with a &quot;bandgap&quot; between their inputs
and the spike threshold, this temperature allows for stochastic spiking. By
imposing a global inhibitory rhythm over the fixed time windows, we connect
neurons into a network that exhibits synchronous, clock-like updating akin to
neural networks. We implement a single-layer Boltzmann machine without learning
to demonstrate our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5489</identifier>
 <datestamp>2015-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5489</id><created>2010-09-28</created><authors><author><keyname>Gao</keyname><forenames>Pu</forenames></author><author><keyname>Wormald</keyname><forenames>Nicholas</forenames></author></authors><title>Orientability thresholds for random hypergraphs</title><categories>math.CO cs.DM</categories><comments>47 pages, 1 figures, the journal version of [16]</comments><journal-ref>Combinator. Probab. Comp. 24 (2015) 774-824</journal-ref><doi>10.1017/S096354831400073X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $h&gt;w&gt;0$ be two fixed integers. Let $\orH$ be a random hypergraph whose
hyperedges are all of cardinality $h$. To {\em $w$-orient} a hyperedge, we
assign exactly $w$ of its vertices positive signs with respect to the
hyperedge, and the rest negative. A $(w,k)$-orientation of $\orH$ consists of a
$w$-orientation of all hyperedges of $\orH$, such that each vertex receives at
most $k$ positive signs from its incident hyperedges. When $k$ is large enough,
we determine the threshold of the existence of a $(w,k)$-orientation of a
random hypergraph. The $(w,k)$-orientation of hypergraphs is strongly related
to a general version of the off-line load balancing problem. The graph case,
when $h=2$ and $w=1$, was solved recently by Cain, Sanders and Wormald and
independently by Fernholz and Ramachandran, which settled a conjecture of Karp
and Saks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5520</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5520</id><created>2010-09-28</created><authors><author><keyname>Soos</keyname><forenames>Sandor</forenames><affiliation>Institute for Research Policy Studies, Hungarian Academy of Sciences, Hungary</affiliation></author><author><keyname>Kampis</keyname><forenames>George</forenames><affiliation>History and Philosophy of Science, Lorand Eotvos University, Hungary</affiliation></author></authors><title>Diversity and Polarization of Research Performance: Evidence from
  Hungary</title><categories>cs.SI stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measuring the intellectual diversity encoded in publication records as a
proxy to the degree of interdisciplinarity has recently received considerable
attention in the science mapping community. The present paper draws upon the
use of the Stirling index as a diversity measure applied to a network model
(customized science map) of research profiles, proposed by several authors. A
modified version of the index is used and compared with the previous versions
on a sample data set in order to rank top Hungarian research organizations
(HROs) according to their research performance diversity. Results, unexpected
in several respects, show that the modified index is a candidate for measuring
the degree of polarization of a research profile. The study also points towards
a possible typology of publication portfolios that instantiate different types
of diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5538</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5538</id><created>2010-09-28</created><authors><author><keyname>Elmasry</keyname><forenames>Amr</forenames></author><author><keyname>Farzan</keyname><forenames>Arash</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author></authors><title>Priority Queues with Multiple Time Fingers</title><categories>cs.DS</categories><comments>14 pages, 4 figures</comments><acm-class>E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A priority queue is presented that supports the operations insert and
find-min in worst-case constant time, and delete and delete-min on element x in
worst-case O(lg(min{w_x, q_x}+2)) time, where w_x (respectively q_x) is the
number of elements inserted after x (respectively before x) and are still
present at the time of the deletion of x. Our priority queue then has both the
working-set and the queueish properties, and more strongly it satisfies these
properties in the worst-case sense. We also define a new distribution-sensitive
property---the time-finger property, which encapsulates and generalizes both
the working-set and queueish properties, and present a priority queue that
satisfies this property.
  In addition, we prove a strong implication that the working-set property is
equivalent to the unified bound (which is the minimum per operation among the
static finger, static optimality, and the working-set bounds). This latter
result is of tremendous interest by itself as it had gone unnoticed since the
introduction of such bounds by Sleater and Tarjan [JACM 1985]. Accordingly, our
priority queue satisfies other distribution-sensitive properties as the static
finger, static optimality, and the unified bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5557</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5557</id><created>2010-09-27</created><authors><author><keyname>Rajabzadeh</keyname><forenames>Amir</forenames></author><author><keyname>Manashty</keyname><forenames>Ali Reza</forenames></author><author><keyname>Jahromi</keyname><forenames>Zahra Forootan</forenames></author></authors><title>A Mobile Application for Smart House Remote Control System</title><categories>cs.OH</categories><comments>7 pages, 8 figures, Keywords-Smart House, Mobile Application, Remote
  Control, Automated Home, Windows Mobile</comments><msc-class>93C95</msc-class><acm-class>J.7</acm-class><journal-ref>International Conference on Wireless Communication and Mobile
  Computing (ICWCMC 2010), Proceedings of WASET, vol. 62, ISSN. 2070-3724, pp.
  80-86, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the start of the second decade of 21th century, the time has come to make
the Smart Houses a reality for regular use. The different parts of a Smart
House are researched but there are still distances from an applicable system,
using the modern technology. In this paper we present an overview of the Smart
House subsystems necessary for controlling the house using a mobile application
efficiently and securely. The sequence diagram of the mobile application
connecting to the server application and also the use-cases possible are
presented. The challenges faced in designing the mobile application and
illustrating the updated house top plane view in that application, are
discussed and solutions are adapted for it. Finally the designed mobile
application was implemented and the important sections of it were described,
such as the interactive house top view map which indicates the status of the
devices using predefined icons. The facilities to manage the scheduled tasks
and defined rules are also implemented in this mobile application that was
developed for use in Windows Mobile platform. This application has the
capability of connecting to the main server using GPRS mobile internet and SMS.
This system is expected to be an important step towards a unified system
structure that can be used efficiently in near future regular houses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5588</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5588</id><created>2010-09-28</created><authors><author><keyname>Hugel</keyname><forenames>Thomas</forenames></author><author><keyname>Boufkhad</keyname><forenames>Yacine</forenames></author></authors><title>Second Moment Method on k-SAT: a General Framework</title><categories>cs.DM</categories><comments>35 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a general framework implementing the Second Moment Method on k-SAT
and discuss the conditions making the Second Moment Method work in this
framework. As applications, we make the Second Moment Method work on boolean
solutions and implicants. We extend this to the distributional model of k-SAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5614</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5614</id><created>2010-09-28</created><authors><author><keyname>Manchester</keyname><forenames>Ian R.</forenames></author></authors><title>Input Design for System Identification via Convex Relaxation</title><categories>math.OC cs.SY math.ST stat.TH</categories><comments>Preprint submitted for journal publication, extended version of a
  paper at 2010 IEEE Conference on Decision and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new framework for the optimization of excitation inputs
for system identification. The optimization problem considered is to maximize a
reduced Fisher information matrix in any of the classical D-, E-, or A-optimal
senses. In contrast to the majority of published work on this topic, we
consider the problem in the time domain and subject to constraints on the
amplitude of the input signal. This optimization problem is nonconvex. The main
result of the paper is a convex relaxation that gives an upper bound accurate
to within $2/\pi$ of the true maximum. A randomized algorithm is presented for
finding a feasible solution which, in a certain sense is expected to be at
least $2/\pi$ as informative as the globally optimal input signal. In the case
of a single constraint on input power, the proposed approach recovers the true
global optimum exactly. Extensions to situations with both power and amplitude
constraints on both inputs and outputs are given. A simple simulation example
illustrates the technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5621</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5621</id><created>2010-09-28</created><updated>2010-11-13</updated><authors><author><keyname>Guillon</keyname><forenames>Pierre</forenames><affiliation>LAMA</affiliation></author><author><keyname>Meunier</keyname><forenames>Pierre-Etienne</forenames><affiliation>LAMA</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>Clandestine Simulations in Cellular Automata</title><categories>cs.DM</categories><comments>18 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies two kinds of simulation between cellular automata:
simulations based on factor and simulations based on sub-automaton. We show
that these two kinds of simulation behave in two opposite ways with respect to
the complexity of attractors and factor subshifts. On the one hand, the factor
simulation preserves the complexity of limits sets or column factors (the
simulator CA must have a higher complexity than the simulated CA). On the other
hand, we show that any CA is the sub-automaton of some CA with a simple limit
set (NL-recognizable) and the sub-automaton of some CA with a simple column
factor (finite type). As a corollary, we get intrinsically universal CA with
simple limit sets or simple column factors. Hence we are able to 'hide' the
simulation power of any CA under simple dynamical indicators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5625</identifier>
 <datestamp>2013-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5625</id><created>2010-09-28</created><updated>2013-02-22</updated><authors><author><keyname>Daskin</keyname><forenames>Anmer</forenames></author><author><keyname>Kais</keyname><forenames>Sabre</forenames></author></authors><title>Decomposition of Unitary Matrices for Finding Quantum Circuits:
  Application to Molecular Hamiltonians</title><categories>quant-ph cs.IT math.IT</categories><journal-ref>J. Chem. Phys. 134, 144112 (2011)</journal-ref><doi>10.1063/1.3575402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constructing appropriate unitary matrix operators for new quantum algorithms
and finding the minimum cost gate sequences for the implementation of these
unitary operators is of fundamental importance in the field of quantum
information and quantum computation. Evolution of quantum circuits faces two
major challenges: complex and huge search space and the high costs of
simulating quantum circuits on classical computers. Here, we use the group
leaders optimization algorithm to decompose a given unitary matrix into a
proper-minimum cost quantum gate sequence. We test the method on the known
decompositions of Toffoli gate, the amplification step of the Grover search
algorithm, the quantum Fourier transform, and the sender part of the quantum
teleportation. Using this procedure, we present the circuit designs for the
simulation of the unitary propagators of the Hamiltonians for the hydrogen and
the water molecules. The approach is general and can be applied to generate the
sequence of quantum gates for larger molecular systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5626</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5626</id><created>2010-09-28</created><authors><author><keyname>McLaughlin</keyname><forenames>Jonathan</forenames></author></authors><title>The Realizable Extension Problem and the Weighted Graph $(K_{3,3},l)$</title><categories>math.AG cs.DM</categories><comments>15 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note outlines the realizable extension problem for weighted graphs and
provides results of a detailed analysis of this problem for the weighted graph
$(K_{3,3},l)$. This analysis is then utilized to provide a result relating to
the connectedness of the moduli space of planar realizations of $(K_{3,3},l)$.
The note culminates with two examples which show that in general, realizability
and connectedness results relating to the moduli spaces of weighted cycles
which are contained in a larger weighted graph cannot be extended to similar
results regarding the moduli space of the larger weighted graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5628</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5628</id><created>2010-09-28</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Rote</keyname><forenames>Guenter</forenames></author><author><keyname>Schweer</keyname><forenames>Nils</forenames></author><author><keyname>Schymura</keyname><forenames>Daria</forenames></author><author><keyname>Zelke</keyname><forenames>Mariano</forenames></author></authors><title>Integer Point Sets Minimizing Average Pairwise L1-Distance: What is the
  Optimal Shape of a Town?</title><categories>cs.CG cs.DS</categories><comments>26 pages, 6 figures, to appear in Computational Geometry: Theory and
  Applications</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An n-town, for a natural number n, is a group of n buildings, each occupying
a distinct position on a 2-dimensional integer grid. If we measure the distance
between two buildings along the axis-parallel street grid, then an n-town has
optimal shape if the sum of all pairwise Manhattan distances is minimized. This
problem has been studied for cities, i.e., the limiting case of very large n.
For cities, it is known that the optimal shape can be described by a
differential equation, for which no closed-form is known. We show that optimal
n-towns can be computed in O(n^7.5) time. This is also practically useful, as
it allows us to compute optimal solutions up to n=80.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5636</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5636</id><created>2010-09-28</created><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Bro&#x17e;ek</keyname><forenames>V&#xe1;clav</forenames></author><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author></authors><title>One-Counter Stochastic Games</title><categories>cs.GT</categories><comments>20 pages, 1 figure. This is a full version of a paper accepted for
  publication in proceedings of FSTTCS 2010</comments><acm-class>G.3; F.1.1; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational complexity of basic decision problems for
one-counter simple stochastic games (OC-SSGs), under various objectives.
OC-SSGs are 2-player turn-based stochastic games played on the transition graph
of classic one-counter automata. We study primarily the termination objective,
where the goal of one player is to maximize the probability of reaching counter
value 0, while the other player wishes to avoid this. Partly motivated by the
goal of understanding termination objectives, we also study certain &quot;limit&quot; and
&quot;long run average&quot; reward objectives that are closely related to some
well-studied objectives for stochastic games with rewards. Examples of problems
we address include: does player 1 have a strategy to ensure that the counter
eventually hits 0, i.e., terminates, almost surely, regardless of what player 2
does? Or that the liminf (or limsup) counter value equals infinity with a
desired probability? Or that the long run average reward is &gt;0 with desired
probability? We show that the qualitative termination problem for OC-SSGs is in
NP intersection coNP, and is in P-time for 1-player OC-SSGs, or equivalently
for one-counter Markov Decision Processes (OC-MDPs). Moreover, we show that
quantitative limit problems for OC-SSGs are in NP intersection coNP, and are in
P-time for 1-player OC-MDPs. Both qualitative limit problems and qualitative
termination problems for OC-SSGs are already at least as hard as Condon's
quantitative decision problem for finite-state SSGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5696</identifier>
 <datestamp>2012-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5696</id><created>2010-09-28</created><authors><author><keyname>Blaszczyszyn</keyname><forenames>Bartlomiej</forenames></author><author><keyname>Yogeshwaran</keyname><forenames>D.</forenames></author></authors><title>Connectivity in Sub-Poisson Networks</title><categories>math.PR cs.NI</categories><comments>8 pages, 10 figures, to appear in Proc. of Allerton 2010. For an
  extended version see http://hal.inria.fr/inria-00497707 version 1</comments><journal-ref>Proc. of 48th Annual Allerton Conference 2010</journal-ref><doi>10.1109/ALLERTON.2010.5707086</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of point processes (pp), which we call {\em sub-Poisson};
these are pp that can be directionally-convexly ($dcx$) dominated by some
Poisson pp. The $dcx$ order has already been shown useful in comparing various
point process characteristics, including Ripley's and correlation functions as
well as shot-noise fields generated by pp, indicating in particular that
smaller in the $dcx$ order processes exhibit more regularity (less clustering,
less voids) in the repartition of their points. Using these results, in this
paper we study the impact of the $dcx$ ordering of pp on the properties of two
continuum percolation models, which have been proposed in the literature to
address macroscopic connectivity properties of large wireless networks. As the
first main result of this paper, we extend the classical result on the
existence of phase transition in the percolation of the Gilbert's graph (called
also the Boolean model), generated by a homogeneous Poisson pp, to the class of
homogeneous sub-Poisson pp. We also extend a recent result of the same nature
for the SINR graph, to sub-Poisson pp. Finally, as examples we show that the
so-called perturbed lattices are sub-Poisson. More generally, perturbed
lattices provide some spectrum of models that ranges from periodic grids,
usually considered in cellular network context, to Poisson ad-hoc networks, and
to various more clustered pp including some doubly stochastic Poisson ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5698</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5698</id><created>2010-09-28</created><authors><author><keyname>Thorne</keyname><forenames>Simon</forenames></author></authors><title>Defending the future: An MSc module in End User Computing Risk
  Management</title><categories>cs.SE</categories><comments>9 Pages, 1 Table</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 123-132
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the rationale, curriculum and subject matter of a new
MSc module being taught on an MSc Finance and Information Management course at
the University of Wales Institute in Cardiff. Academic research on spreadsheet
risks now has some penetration in academic literature and there is a growing
body of knowledge on the subjects of spreadsheet error, human factors,
spreadsheet engineering, &quot;best practice&quot;, spreadsheet risk management and
various techniques used to mitigate spreadsheet errors. This new MSc module in
End User Computing Risk Management is an attempt to pull all of this research
and practitioner experience together to arm the next generation of finance
spreadsheet champions with the relevant knowledge, techniques and critical
perspective on an emerging discipline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5701</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5701</id><created>2010-09-28</created><authors><author><keyname>Balson</keyname><forenames>Dermot</forenames></author></authors><title>Changing User Attitudes to Reduce Spreadsheet Risk</title><categories>cs.HC</categories><comments>5 Pages; ISBN 978-1-905404-50-6</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 133-137</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A business case study on how three simple guidelines:
  1. Make it easy to check (and maintain) 2. Make it safe to use 3. Keep
business logic out of code changed user attitudes and improved spreadsheet
quality in a financial services organisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5705</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5705</id><created>2010-09-28</created><authors><author><keyname>Dunn</keyname><forenames>Angus</forenames></author></authors><title>Spreadsheets - the Good, the Bad and the Downright Ugly</title><categories>cs.SE</categories><comments>8 Pages</comments><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2010 157-164
  ISBN 978-1-905404-50-6</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spreadsheets are ubiquitous, heavily relied on throughout vast swathes of
finance, commerce, industry, academia and Government. They are also
acknowledged to be extraordinarily and unacceptably prone to error. If these
two points are accepted, it has to follow that their uncontrolled use has the
potential to inflict considerable damage. One approach to controlling such
error should be to define as &quot;good practice&quot; a set of characteristics that a
spreadsheet must possess and as &quot;bad practice&quot; another set that it must avoid.
Defining such characteristics should, in principle, perfectly do-able. However,
being able to say with authority at a definite moment that any particular
spreadsheet complies with these characteristics is very much more difficult.
The author asserts that the use of automated spreadsheet development could
markedly help in ensuring and demonstrating such compliance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5718</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5718</id><created>2010-09-28</created><authors><author><keyname>Kays</keyname><forenames>Roland</forenames></author><author><keyname>Tilak</keyname><forenames>Sameer</forenames></author><author><keyname>Kranstauber</keyname><forenames>Bart</forenames></author><author><keyname>Jansen</keyname><forenames>Patrick A.</forenames></author><author><keyname>Carbone</keyname><forenames>Chris</forenames></author><author><keyname>Rowcliffe</keyname><forenames>Marcus J.</forenames></author><author><keyname>Fountain</keyname><forenames>Tony</forenames></author><author><keyname>Eggert</keyname><forenames>Jay</forenames></author><author><keyname>He</keyname><forenames>Zhihai</forenames></author></authors><title>Monitoring wild animal communities with arrays of motion sensitive
  camera traps</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studying animal movement and distribution is of critical importance to
addressing environmental challenges including invasive species, infectious
diseases, climate and land-use change. Motion sensitive camera traps offer a
visual sensor to record the presence of a broad range of species providing
location -specific information on movement and behavior. Modern digital camera
traps that record video present new analytical opportunities, but also new data
management challenges. This paper describes our experience with a terrestrial
animal monitoring system at Barro Colorado Island, Panama. Our camera network
captured the spatio-temporal dynamics of terrestrial bird and mammal activity
at the site - data relevant to immediate science questions, and long-term
conservation issues. We believe that the experience gained and lessons learned
during our year long deployment and testing of the camera traps as well as the
developed solutions are applicable to broader sensor network applications and
are valuable for the advancement of the sensor network research. We suggest
that the continued development of these hardware, software, and analytical
tools, in concert, offer an exciting sensor-network solution to monitoring of
animal populations which could realistically scale over larger areas and time
spans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5729</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5729</id><created>2010-09-28</created><updated>2011-03-21</updated><authors><author><keyname>Tanti</keyname><forenames>Bhavin</forenames></author><author><keyname>Doshi</keyname><forenames>Nishant</forenames></author></authors><title>A secure email login system using virtual password</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's world password compromise by some adversaries is common for
different purpose. In ICC 2008 Lei et al. proposed a new user authentication
system based on the virtual password system. In virtual password system they
have used linear randomized function to be secure against identity theft
attacks, phishing attacks, keylogging attack and shoulder surfing system. In
ICC 2010 Li's given a security attack on the Lei's work. This paper gives
modification on Lei's work to prevent the Li's attack with reducing the server
overhead. This paper also discussed the problems with current password recovery
system and gives the better approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5734</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5734</id><created>2010-09-28</created><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author><author><keyname>Korula</keyname><forenames>Nitish</forenames></author></authors><title>Approximability of Capacitated Network Design</title><categories>cs.DS cs.DM</categories><comments>19 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the {\em capacitated} survivable network design problem (Cap-SNDP), we are
given an undirected multi-graph where each edge has a capacity and a cost. The
goal is to find a minimum cost subset of edges that satisfies a given set of
pairwise minimum-cut requirements. Unlike its classical special case of SNDP
when all capacities are unit, the approximability of Cap-SNDP is not well
understood; even in very restricted settings no known algorithm achieves a
$o(m)$ approximation, where $m$ is the number of edges in the graph. In this
paper, we obtain several new results and insights into the approximability of
Cap-SNDP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5750</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5750</id><created>2010-09-28</created><authors><author><keyname>Martinez</keyname><forenames>Josue G.</forenames></author><author><keyname>Huang</keyname><forenames>Jianhua Z.</forenames></author><author><keyname>Burghardt</keyname><forenames>Robert C.</forenames></author><author><keyname>Barhoumi</keyname><forenames>Rola</forenames></author><author><keyname>Carroll</keyname><forenames>Raymond J.</forenames></author></authors><title>Use of multiple singular value decompositions to analyze complex
  intracellular calcium ion signals</title><categories>stat.AP cs.CV physics.bio-ph q-bio.QM</categories><comments>Published in at http://dx.doi.org/10.1214/09-AOAS253 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS253</report-no><journal-ref>Annals of Applied Statistics 2009, Vol. 3, No. 4, 1467-1492</journal-ref><doi>10.1214/09-AOAS253</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare calcium ion signaling ($\mathrm {Ca}^{2+}$) between two exposures;
the data are present as movies, or, more prosaically, time series of images.
This paper describes novel uses of singular value decompositions (SVD) and
weighted versions of them (WSVD) to extract the signals from such movies, in a
way that is semi-automatic and tuned closely to the actual data and their many
complexities. These complexities include the following. First, the images
themselves are of no interest: all interest focuses on the behavior of
individual cells across time, and thus, the cells need to be segmented in an
automated manner. Second, the cells themselves have 100$+$ pixels, so that they
form 100$+$ curves measured over time, so that data compression is required to
extract the features of these curves. Third, some of the pixels in some of the
cells are subject to image saturation due to bit depth limits, and this
saturation needs to be accounted for if one is to normalize the images in a
reasonably unbiased manner. Finally, the $\mathrm {Ca}^{2+}$ signals have
oscillations or waves that vary with time and these signals need to be
extracted. Thus, our aim is to show how to use multiple weighted and standard
singular value decompositions to detect, extract and clarify the $\mathrm
{Ca}^{2+}$ signals. Our signal extraction methods then lead to simple although
finely focused statistical methods to compare $\mathrm {Ca}^{2+}$ signals
across experimental conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5758</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5758</id><created>2010-09-28</created><authors><author><keyname>Paisitkriangkrai</keyname><forenames>Sakrapee</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Zhang</keyname><forenames>Jian</forenames></author></authors><title>Face Detection with Effective Feature Extraction</title><categories>cs.CV</categories><comments>7 pages. Conference version published in Asian Conf. Comp. Vision
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an abundant literature on face detection due to its important role
in many vision applications. Since Viola and Jones proposed the first real-time
AdaBoost based face detector, Haar-like features have been adopted as the
method of choice for frontal face detection. In this work, we show that simple
features other than Haar-like features can also be applied for training an
effective face detector. Since, single feature is not discriminative enough to
separate faces from difficult non-faces, we further improve the generalization
performance of our simple features by introducing feature co-occurrences. We
demonstrate that our proposed features yield a performance improvement compared
to Haar-like features. In addition, our findings indicate that features play a
crucial role in the ability of the system to generalize.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5759</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5759</id><created>2010-09-28</created><authors><author><keyname>Shur</keyname><forenames>Arseny M.</forenames></author></authors><title>On ternary square-free circular words</title><categories>cs.FL cs.DM math.CO</categories><comments>11 pages, 1 figure, 1 table. Presented at NORCOM'2010, submitted to
  EJC</comments><journal-ref>Electronic Journal of Combinatorics 2010 Vol. 17(1) #R140</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circular words are cyclically ordered finite sequences of letters. We give a
computer-free proof of the following result by Currie: square-free circular
words over the ternary alphabet exist for all lengths $l$ except for 5, 7, 9,
10, 14, and 17. Our proof reveals an interesting connection between ternary
square-free circular words and closed walks in the $K_{3{,}3}$ graph. In
addition, our proof implies an exponential lower bound on the number of such
circular words of length $l$ and allows one to list all lengths $l$ for which
such a circular word is unique up to isomorphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5760</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5760</id><created>2010-09-28</created><updated>2010-10-12</updated><authors><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author></authors><title>Secret Key Agreement from Vector Gaussian Sources by Rate Limited Public
  Communication</title><categories>cs.IT math.IT</categories><comments>10 pages, 4 figures, A part of this paper was presented at 2010 IEEE
  International Symposium on Information Theory in Austin U.S.A, version 2
  corrected Remark 6 and added some references</comments><journal-ref>IEEE Transactions on Information Forensics and Security, Vol. 6,
  No. 3, pp. 541-550, 2011</journal-ref><doi>10.1109/TIFS.2011.2132130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the secret key agreement from correlated vector Gaussian
sources in which the legitimate parties can use the public communication with
limited rate. For the class of protocols with the one-way public communication,
we show that the optimal trade-off between the rate of key generation and the
rate of the public communication is characterized as an optimization problem of
a Gaussian random variable. The characterization is derived by using the
enhancement technique introduced by Weingarten et.al. for MIMO Gaussian
broadcast channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5761</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5761</id><created>2010-09-28</created><authors><author><keyname>Hoffman</keyname><forenames>Matthew D.</forenames></author></authors><title>Approximate Maximum A Posteriori Inference with Entropic Priors</title><categories>cs.SD cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In certain applications it is useful to fit multinomial distributions to
observed data with a penalty term that encourages sparsity. For example, in
probabilistic latent audio source decomposition one may wish to encode the
assumption that only a few latent sources are active at any given time. The
standard heuristic of applying an L1 penalty is not an option when fitting the
parameters to a multinomial distribution, which are constrained to sum to 1. An
alternative is to use a penalty term that encourages low-entropy solutions,
which corresponds to maximum a posteriori (MAP) parameter estimation with an
entropic prior. The lack of conjugacy between the entropic prior and the
multinomial distribution complicates this approach. In this report I propose a
simple iterative algorithm for MAP estimation of multinomial distributions with
sparsity-inducing entropic priors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5762</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5762</id><created>2010-09-28</created><authors><author><keyname>Wu</keyname><forenames>Jiaji</forenames></author><author><keyname>Xing</keyname><forenames>Yan</forenames></author><author><keyname>Paul</keyname><forenames>Anand</forenames></author><author><keyname>Fang</keyname><forenames>Yong</forenames></author><author><keyname>Jeong</keyname><forenames>Jechang</forenames></author><author><keyname>Jiao</keyname><forenames>Licheng</forenames></author><author><keyname>Shi</keyname><forenames>Guangming</forenames></author></authors><title>Morphological dilation image coding with context weights prediction</title><categories>cs.IT cs.MM math.IT</categories><comments>33 pages, 7 figures, submitted to Signal Processing: Image
  Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an adaptive morphological dilation image coding with
context weights prediction. The new dilation method is not to use fixed models,
but to decide whether a coefficient needs to be dilated or not according to the
coefficient's predicted significance degree. It includes two key dilation
technologies: 1) controlling dilation process with context weights to reduce
the output of insignificant coefficients, and 2) using variable-length group
test coding with context weights to adjust the coding order and cost as few
bits as possible to present the events with large probability. Moreover, we
also propose a novel context weight strategy to predict coefficient's
significance degree more accurately, which serves for two dilation
technologies. Experimental results show that our proposed method outperforms
the state of the art image coding algorithms available today.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5764</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5764</id><created>2010-09-28</created><updated>2011-02-15</updated><authors><author><keyname>Kurkoski</keyname><forenames>Brian M.</forenames></author></authors><title>The E8 Lattice and Error Correction in Multi-Level Flash Memory</title><categories>cs.IT math.IT</categories><comments>To appear in Proceedings of ICC 2011; 5 pages. See also
  http://arxiv.org/abs/1007.1819</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A construction using the E8 lattice and Reed-Solomon codes for
error-correction in flash memory is given. Since E8 lattice decoding errors are
bursty, a Reed-Solomon code over GF($2^8$) is well suited. This is a type of
coded modulation, where the Euclidean distance of the lattice, which is an
eight-dimensional signal constellation, is combined with the Hamming distance
of the code. This system is compared with the conventional technique for flash
memories, BCH codes using Gray-coded PAM. The described construction has a
performance advantage of 1.6 to 1.8 dB at a probability of word error of
$10^{-6}$. Evaluation is at high data rates of 2.9 bits/cell for flash memory
cells that have an uncoded data density of 3 bits/cell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5773</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5773</id><created>2010-09-29</created><updated>2013-06-04</updated><authors><author><keyname>Mastronarde</keyname><forenames>Nicholas</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Fast Reinforcement Learning for Energy-Efficient Wireless Communications</title><categories>cs.LG</categories><journal-ref>N. Mastronarde and M. van der Schaar, &quot;Joint physical-layer and
  system-level power management for delay-sensitive wireless communication,&quot;
  IEEE Trans. on Mobile Computing, vol. 12, no. 4, pp. 694-709, April 2013</journal-ref><doi>10.1109/TMC.2012.36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of energy-efficient point-to-point transmission of
delay-sensitive data (e.g. multimedia data) over a fading channel. Existing
research on this topic utilizes either physical-layer centric solutions, namely
power-control and adaptive modulation and coding (AMC), or system-level
solutions based on dynamic power management (DPM); however, there is currently
no rigorous and unified framework for simultaneously utilizing both
physical-layer centric and system-level techniques to achieve the minimum
possible energy consumption, under delay constraints, in the presence of
stochastic and a priori unknown traffic and channel conditions. In this report,
we propose such a framework. We formulate the stochastic optimization problem
as a Markov decision process (MDP) and solve it online using reinforcement
learning. The advantages of the proposed online method are that (i) it does not
require a priori knowledge of the traffic arrival and channel statistics to
determine the jointly optimal power-control, AMC, and DPM policies; (ii) it
exploits partial information about the system so that less information needs to
be learned than when using conventional reinforcement learning algorithms; and
(iii) it obviates the need for action exploration, which severely limits the
adaptation speed and run-time performance of conventional reinforcement
learning algorithms. Our results show that the proposed learning algorithms can
converge up to two orders of magnitude faster than a state-of-the-art learning
algorithm for physical layer power-control and up to three orders of magnitude
faster than conventional reinforcement learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5787</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5787</id><created>2010-09-29</created><authors><author><keyname>Ehmsen</keyname><forenames>Martin R.</forenames></author><author><keyname>Kohrt</keyname><forenames>Jens S.</forenames></author><author><keyname>Larsen</keyname><forenames>Kim S.</forenames></author></authors><title>List Factoring and Relative Worst Order Analysis</title><categories>cs.DS</categories><report-no>CP3-Origins-2010-41</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relative worst order analysis is a supplement or alternative to competitive
analysis which has been shown to give results more in accordance with observed
behavior of online algorithms for a range of different online problems. The
contribution of this paper is twofold. First, it adds the static list accessing
problem to the collection of online problems where relative worst order
analysis gives better results. Second, and maybe more interesting, it adds the
non-trivial supplementary proof technique of list factoring to the theoretical
toolbox for relative worst order analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5791</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5791</id><created>2010-09-29</created><authors><author><keyname>Bachrach</keyname><forenames>Yoram</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author></authors><title>Fast Pseudo-Random Fingerprints</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method to exponentially speed up computation of various
fingerprints, such as the ones used to compute similarity and rarity in massive
data sets. Rather then maintaining the full stream of $b$ items of a universe
$[u]$, such methods only maintain a concise fingerprint of the stream, and
perform computations using the fingerprints. The computations are done
approximately, and the required fingerprint size $k$ depends on the desired
accuracy $\epsilon$ and confidence $\delta$. Our technique maintains a single
bit per hash function, rather than a single integer, thus requiring a
fingerprint of length $k = O(\frac{\ln \frac{1}{\delta}}{\epsilon^2})$ bits,
rather than $O(\log u \cdot \frac{\ln \frac{1}{\delta}}{\epsilon^2})$ bits
required by previous approaches. The main advantage of the fingerprints we
propose is that rather than computing the fingerprint of a stream of $b$ items
in time of $O(b \cdot k)$, we can compute it in time $O(b \log k)$. Thus this
allows an exponential speedup for the fingerprint construction, or
alternatively allows achieving a much higher accuracy while preserving
computation time. Our methods rely on a specific family of pseudo-random hashes
for which we can quickly locate hashes resulting in small values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5802</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5802</id><created>2010-09-29</created><authors><author><keyname>Dubrova</keyname><forenames>Elena</forenames></author></authors><title>Synthesis of Binary k-Stage Machines</title><categories>cs.CR</categories><comments>3 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm for constructing a shortest binary k-stage machine generating a
given binary sequence is presented. This algorithm can be considered as an
extension of Berlekamp-Massey algorithm to the non-linear case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5804</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5804</id><created>2010-09-29</created><authors><author><keyname>Tregub</keyname><forenames>Vladimir Vasilich</forenames></author></authors><title>Productivity tools to study constrained motion: electrician's approach
  to mechanician's problem</title><categories>physics.ed-ph cs.SE physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An application design is offered, which students of physics can use when
authoring a solver for mechanical systems with constraints. A 'chainlist'
concept is introduced to capture a constrained mechanical system configuration
and to pass the simulation scenario to the solver application. Code samples are
given to start off the solver application (simulator) project. A short review
of linear algebra for constrained motion computations (pseudoinverse) is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5829</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5829</id><created>2010-09-29</created><updated>2010-09-29</updated><authors><author><keyname>Oohama</keyname><forenames>Yasutada</forenames></author><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author></authors><title>Capacity Results for Relay Channels with Confidential Messages</title><categories>cs.IT math.IT</categories><comments>31 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a communication system where a relay helps transmission of
messages from {a} sender to {a} receiver. The relay is considered not only as a
helper but as a wire-tapper who can obtain some knowledge about transmitted
messages. In this paper we study a relay channel with confidential
messages(RCC), where a sender attempts to transmit common information to both a
receiver and a relay and also has private information intended for the receiver
and confidential to the relay. The level of secrecy of private information
confidential to the relay is measured by the equivocation rate, i.e., the
entropy rate of private information conditioned on channel outputs at the
relay. The performance measure of interest for the RCC is the rate triple that
includes the common rate, the private rate, and the equivocation rate as
components. The rate-equivocation region is defined by the set that consists of
all these achievable rate triples. In this paper we give two definitions of the
rate-equivocation region. We first define the rate-equivocation region in the
case of deterministic encoder and call it the deterministic rate-equivocation
region. Next, we define the rate-equivocation region in the case of stochastic
encoder and call it the stochastic rate-equivocation region. We derive explicit
inner and outer bounds for the above two regions. On the
deterministic/stochastic rate-equivocation region we present two classes of
relay channels where inner and outer bounds match. We also evaluate the
deterministic and stochastic rate-equivocation regions of the Gaussian RCC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5853</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5853</id><created>2010-09-29</created><authors><author><keyname>Baumgartner</keyname><forenames>Tobias</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Hellmann</keyname><forenames>Winfried</forenames></author><author><keyname>Kroeller</keyname><forenames>Alexander</forenames></author></authors><title>Simultaneous Event Execution in Heterogeneous Wireless Sensor Networks</title><categories>cs.DC cs.DS</categories><comments>6 pages, 5 figures, 3 tables, to appear in Journal of Networks</comments><acm-class>C.2.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a synchronization algorithm to let nodes in a sensor network
simultaneously execute a task at a given point in time. In contrast to other
time synchronization algorithms we do not provide a global time basis that is
shared on all nodes. Instead, any node in the network can spontaneously
initiate a process that allows the simultaneous execution of arbitrary tasks.
We show that our approach is beneficial in scenarios where a global time is not
needed, as it requires little communication compared with other time
synchronization algorithms. We also show that our algorithm works in
heterogeneous systems where the hardware provides highly varying clock
accuracy. Moreover, heterogeneity does not only affect the hardware, but also
the communication channels. We deal with different connection types---from
highly unreliable and fluctuating wireless channels to reliable and fast wired
connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5863</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5863</id><created>2010-09-29</created><authors><author><keyname>Barbay</keyname><forenames>J&#xe9;r&#xe9;my</forenames></author><author><keyname>Fischer</keyname><forenames>Johannes</forenames></author></authors><title>LRM-Trees: Compressed Indices, Adaptive Sorting, and Compressed
  Permutations</title><categories>cs.DS</categories><comments>13 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LRM-Trees are an elegant way to partition a sequence of values into sorted
consecutive blocks, and to express the relative position of the first element
of each block within a previous block. They were used to encode ordinal trees
and to index integer arrays in order to support range minimum queries on them.
We describe how they yield many other convenient results in a variety of areas,
from data structures to algorithms: some compressed succinct indices for range
minimum queries; a new adaptive sorting algorithm; and a compressed succinct
data structure for permutations supporting direct and indirect application in
time all the shortest as the permutation is compressible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5878</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5878</id><created>2010-09-29</created><authors><author><keyname>Heissler</keyname><forenames>Adrian</forenames></author></authors><title>Performance analysis of Xen virtual machines in real-world scenarios</title><categories>cs.PF</categories><acm-class>D.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents results of the performance benchmarks of the Open Source
hypervisor Xen. The study focuses on the network related performance as well as
on the application related performance of multiple virtual machines that were
running on the same Xen hypervisor. The comparison was carried out using a
self-developed benchmark suite that consists of easily available Open Source
tools. The goal is to measure the performance of the hypervisor in typical
real-world application scenarios when used for &quot;mass virtual hosting&quot;, such as
hosting solutions of so called virtual private servers for small-to-medium
sized businesses environments. The results of the benchmarks show, that the
tested Xen setup offers good performance with respect to network traffic stress
tests, but only 75% of the performance of the non-virtualized reference
environment. This application performance score decreases as more virtual
machines are running simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5894</identifier>
 <datestamp>2012-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5894</id><created>2010-09-29</created><authors><author><keyname>Levin</keyname><forenames>Leonid A.</forenames></author></authors><title>Some Theorems on the Algorithmic Approach to Probability Theory and
  Information Theory</title><categories>cs.IT math.IT</categories><comments>14 pages, 1 figure</comments><journal-ref>Annals of Pure and Applied Logic 162/3:224-235, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a 1971 dissertation. Only its extended abstract was published at the
time. While some results appeared in other publications, a number of details
remained unpublished and may still have relevance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5900</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5900</id><created>2010-09-29</created><authors><author><keyname>Xu</keyname><forenames>Jiaming</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffery G.</forenames></author></authors><title>On the Accuracy of the Wyner Model in Cellular Networks</title><categories>cs.IT math.IT</categories><comments>24 pages, 9 figures, conference version accepted in IEEE GLOBECOM
  2010 and submmited to IEEE ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Wyner model has been widely used to model and analyze cellular networks
due to its simplicity and analytical tractability. Its key aspects include
fixed user locations and the deterministic and homogeneous interference
intensity. While clearly a significant simplification of a real cellular
system, which has random user locations and interference levels that vary by
several orders of magnitude over a cell, a common presumption by theorists is
that the Wyner model nevertheless captures the essential aspects of cellular
interactions. But is this true? To answer this question, we consider both
uplink and downlink transmissions, and both outage-based and average-based
metrics. For the uplink, for both metrics, we conclude that the Wyner model is
in fact quite accurate for systems with a sufficient number of simultaneous
users, e.g. CDMA. Conversely, it is broadly inaccurate otherwise. With
multicell processing, intracell TDMA is shown to be suboptimal in terms of
average throughput, in sharp contrast to predictions using the Wyner model.
Turning to the downlink, the Wyner model is highly inaccurate for outage since
it depends largely on the user locations. However, for average or sum
throughput, the Wyner model serves as an acceptable simplification in certain
special cases if the interference parameter is set appropriately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5918</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5918</id><created>2010-09-29</created><authors><author><keyname>Bastien</keyname><forenames>J. M. Christian</forenames><affiliation>InterPsy-ETIC</affiliation></author></authors><title>Usability testing: a review of some methodological and technical aspects
  of the method</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>International Journal of Medical Informatics 79 (2010) e18-e23</journal-ref><doi>10.1016/j.ijmedinf.2008.12.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to review some work conducted in the field of user
testing that aims at specifying or clarifying the test procedures and at
defining and developing tools to help conduct user tests. The topics that have
been selected were considered relevant for evaluating applications in the field
of medical and health care informatics. These topics are: the number of
participants that should take part in a user test, the test procedure, remote
usability evaluation, usability testing tools, and evaluating mobile
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5944</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5944</id><created>2010-09-29</created><authors><author><keyname>Lotfinezhad</keyname><forenames>Mahdi</forenames></author><author><keyname>Marbach</keyname><forenames>Peter</forenames></author></authors><title>Throughput-Optimal Random Access with Order-Optimal Delay</title><categories>cs.IT math.IT</categories><comments>44 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider CSMA policies for scheduling of multihop wireless
networks with one-hop traffic. The main contribution of this paper is to
propose Unlocking CSMA (U-CSMA) policy that enables to obtain high throughput
with low (average) packet delay for large wireless networks. In particular, the
delay under U-CSMA policy becomes order-optimal. For one-hop traffic, delay is
defined to be order-optimal if it is O(1), i.e., it stays bounded, as the
network-size increases to infinity. Using mean field theory techniques, we
analytically show that for torus (grid-like) interference topologies with
one-hop traffic, to achieve a network load of $\rho$, the delay under U-CSMA
policy becomes $O(1/(1-\rho)^{3})$ as the network-size increases, and hence,
delay becomes order optimal. We conduct simulations for general random
geometric interference topologies under U-CSMA policy combined with congestion
control to maximize a network-wide utility. These simulations confirm that
order optimality holds, and that we can use U-CSMA policy jointly with
congestion control to operate close to the optimal utility with a low packet
delay in arbitrarily large random geometric topologies. To the best of our
knowledge, it is for the first time that a simple distributed scheduling policy
is proposed that in addition to throughput/utility-optimality exhibits delay
order-optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5949</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5949</id><created>2010-09-29</created><authors><author><keyname>Nguyen</keyname><forenames>Gam D.</forenames></author></authors><title>Fast CRCs (Extended Version)</title><categories>cs.IT math.IT</categories><comments>64 pages, 43 figures, an extended version of a published journal
  paper</comments><journal-ref>G.D. Nguyen, &quot;Fast CRCs,&quot; IEEE Transactions on Computers, vol. 58,
  no. 10, pp. 1321-1331, Oct. 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CRCs have desirable properties for effective error detection. But their
software implementation, which relies on many steps of the polynomial division,
is typically slower than other codes such as weaker checksums. A relevant
question is whether there are some particular CRCs that have fast
implementation. In this paper, we introduce such fast CRCs as well as an
effective technique to implement them. For these fast CRCs, even without using
table lookup, it is possible either to eliminate or to greatly reduce many
steps of the polynomial division during their computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5959</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5959</id><created>2010-09-29</created><updated>2011-02-20</updated><authors><author><keyname>Wu</keyname><forenames>Xiugang</forenames></author><author><keyname>Xie</keyname><forenames>Liang-Liang</forenames></author></authors><title>On the Optimal Compressions in the Compress-and-Forward Relay Schemes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ..... joint decoding provides more freedom in choosing the compression at the
relay.
  However, the question remains whether this freedom of selecting the
compression necessarily improves the achievable rate of the original message.
It has been shown in (El Gamal and Kim, 2010) that the answer is negative in
the single-relay case. In this paper, it is further demonstrated that in the
case of multiple relays, there is no improvement on the achievable rate by
joint decoding either. More interestingly, it is discovered that any
compressions not supporting successive decoding will actually lead to strictly
lower achievable rates for the original message. Therefore, to maximize the
achievable rate for the original message, the compressions should always be
chosen to support successive decoding. Furthermore, it is shown that any
compressions not completely decodable even with joint decoding will not provide
any contribution to the decoding of the original message.
  The above phenomenon is also shown to exist under the repetitive encoding
framework recently proposed by (Lim, Kim, El Gamal, and Chung, 2010), which
improved the achievable rate in the case of multiple relays. Here, another
interesting discovery is that the improvement is not a result of repetitive
encoding, but the benefit of delayed decoding after all the blocks have been
finished. The same rate is shown to be achievable with the simpler classical
encoding process of (Cover and El Gamal, 1979) with a block-by-block backward
decoding process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5972</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5972</id><created>2010-09-29</created><authors><author><keyname>Pelossof</keyname><forenames>Raphael</forenames></author><author><keyname>Ying</keyname><forenames>Zhiliang</forenames></author></authors><title>The Attentive Perceptron</title><categories>cs.LG</categories><comments>Submitted to New York Academy of Sciences Machine Learning symposium
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a focus of attention mechanism to speed up the Perceptron
algorithm. Focus of attention speeds up the Perceptron algorithm by lowering
the number of features evaluated throughout training and prediction. Whereas
the traditional Perceptron evaluates all the features of each example, the
Attentive Perceptron evaluates less features for easy to classify examples,
thereby achieving significant speedups and small losses in prediction accuracy.
Focus of attention allows the Attentive Perceptron to stop the evaluation of
features at any interim point and filter the example. This creates an attentive
filter which concentrates computation at examples that are hard to classify,
and quickly filters examples that are easy to classify.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5975</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5975</id><created>2010-09-29</created><authors><author><keyname>Ozel</keyname><forenames>Omur</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Information-Theoretic Analysis of an Energy Harvesting Communication
  System</title><categories>cs.IT math.IT</categories><comments>Published in IEEE PIMRC, September 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In energy harvesting communication systems, an exogenous recharge process
supplies energy for the data transmission and arriving energy can be buffered
in a battery before consumption. Transmission is interrupted if there is not
sufficient energy. We address communication with such random energy arrivals in
an information-theoretic setting. Based on the classical additive white
Gaussian noise (AWGN) channel model, we study the coding problem with random
energy arrivals at the transmitter. We show that the capacity of the AWGN
channel with stochastic energy arrivals is equal to the capacity with an
average power constraint equal to the average recharge rate. We provide two
different capacity achieving schemes: {\it save-and-transmit} and {\it
best-effort-transmit}. Next, we consider the case where energy arrivals have
time-varying average in a larger time scale. We derive the optimal offline
power allocation for maximum average throughput and provide an algorithm that
finds the optimal power allocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5979</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5979</id><created>2010-09-29</created><updated>2011-06-04</updated><authors><author><keyname>Chen</keyname><forenames>Jianshu</forenames></author><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Shan</keyname><forenames>Xiu-Ming</forenames></author><author><keyname>Ge</keyname><forenames>Ning</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>Performance Analysis of the Matrix Pair Beamformer with Matrix Mismatch</title><categories>cs.IT math.IT</categories><comments>31 pages, 15 figures. Submitted to IEEE Transactions on Signal
  Processing. There is another 5-page supplementary material entitled &quot;Some
  Fundamental Results of Matrix for the Paper: Performance Analysis of the
  Matrix Pair Beamformer with Matrix Mismatch&quot;</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Matrix pair beamformer (MPB) is a blind beamformer. It exploits the temporal
structure of the signal of interest (SOI) and applies generalized
eigen-decomposition to a covariance matrix pair. Unlike other blind algorithms,
it only uses the second order statistics. A key assumption in the previous work
is that the two matrices have the same interference statistics. However, this
assumption may be invalid in the presence of multipath propagations or certain
&quot;smart&quot; jammers, and we call it as matrix mismatch. This paper analyzes the
performance of MPB with matrix mismatch. First, we propose a general framework
that covers the existing schemes. Then, we derive its normalized output SINR.
It reveals that the matrix mismatch leads to a threshold effect caused by
&quot;steering vector competition&quot;. Second, using matrix perturbation theory, we
find that, if there are generalized eigenvalues that are infinite, the
threshold will increase unboundedly with the interference power. This is highly
probable when there are multiple periodical interferers. Finally, we present
simulation results to verify our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.5981</identifier>
 <datestamp>2013-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.5981</id><created>2010-09-29</created><updated>2012-02-23</updated><authors><author><keyname>Padilla</keyname><forenames>Marta</forenames></author><author><keyname>Bickel</keyname><forenames>David R.</forenames></author></authors><title>Empirical Bayes methods corrected for small numbers of tests</title><categories>stat.ME cs.IT math.IT math.ST q-bio.QM stat.TH</categories><comments>This version adds new methods and a simulation study</comments><msc-class>62Fxx</msc-class><journal-ref>Statistical Applications in Genetics and Molecular Biology 11 (5),
  art. 4 (2012)</journal-ref><doi>10.1515/1544-6115.1807</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histogram-based empirical Bayes methods developed for analyzing data for
large numbers of genes, SNPs, or other biological features tend to have large
biases when applied to data with a smaller number of features such as genes
with expression measured conventionally, proteins, and metabolites. To analyze
such small-scale and medium-scale data in an empirical Bayes framework, we
introduce corrections of maximum likelihood estimators (MLE) of the local false
discovery rate (LFDR). In this context, the MLE estimates the LFDR, which is a
posterior probability of null hypothesis truth, by estimating the prior
distribution. The corrections lie in excluding each feature when estimating one
or more parameters on which the prior depends. An application of the new
estimators and previous estimators to protein abundance data illustrates how
different estimators lead to very different conclusions about which proteins
are affected by cancer.
  The estimators are compared using simulated data of two different numbers of
features, two different detectability levels, and all possible numbers of
affected features. The simulations show that some of the corrected MLEs
substantially reduce a negative bias of the MLE. (The best-performing corrected
MLE was derived from the minimum description length principle.) However, even
the corrected MLEs have strong negative biases when the proportion of features
that are unaffected is greater than 90%. Therefore, since the number of
affected features is unknown in the case of real data, we recommend an
optimally weighted combination of the best of the corrected MLEs with a
conservative estimator that has weaker parametric assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6008</identifier>
 <datestamp>2013-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6008</id><created>2010-09-29</created><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Multiple Access Channels with Cooperative Encoders and Channel State
  Information</title><categories>cs.IT math.IT</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-user Multiple Access Channel (MAC) with cooperative encoders and
Channel State Information (CSI) is considered where two different scenarios are
investigated: A two-user MAC with common message (MACCM) and a two-user MAC
with conferencing encoders (MACCE). For both situations, the two cases where
the CSI is known to the encoders either non-causally or causally are studied.
Achievable rate regions are established for both discrete memoryless channels
and Gaussian channels with additive interference. The achievable rate regions
derived for the Gaussian models with additive interference known non-causally
to the encoders are shown to coincide with the capacity region of the same
channel with no interference. Therefore, the capacity region for such channels
is established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6045</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6045</id><created>2010-09-30</created><authors><author><keyname>Kayri</keyname><forenames>Murat</forenames></author><author><keyname>Kayri</keyname><forenames>&#x130;smail</forenames></author></authors><title>A proposed &quot;osi based&quot; network troubles identification model</title><categories>cs.NI</categories><comments>7 pages</comments><journal-ref>International Journal of Next-Generation Networks (IJNGN) Vol.2,
  No.3, September 2010</journal-ref><doi>10.5121/ijngn.2010.2302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The OSI model, developed by ISO in 1984, attempts to summarize complicated
network cases on layers. Moreover, network troubles are expressed by taking the
model into account. However, there has been no standardization for network
troubles up to now. Network troubles have only been expressed by the name of
the related layer. In this paper, it is pointed out that possible troubles on
the related layer vary and possible troubles on each layer are categorized for
functional network administration and they are standardized in an eligible way.
The proposed model for network trouble shooting was developed considering the
OSI model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6046</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6046</id><created>2010-09-30</created><authors><author><keyname>Desai</keyname><forenames>Madhav P.</forenames></author></authors><title>On Cycles in Random Graphs</title><categories>math.CO cs.DM</categories><comments>17 pages, 4 figures</comments><msc-class>05C80 (primary) 60B20 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the geometric random (GR) graph on the $d-$dimensional torus with
the $L_\sigma$ distance measure ($1 \leq \sigma \leq \infty$). Our main result
is an exact characterization of the probability that a particular labeled cycle
exists in this random graph. For $\sigma = 2$ and $\sigma = \infty$, we use
this characterization to derive a series which evaluates to the cycle
probability. We thus obtain an exact formula for the expected number of
Hamilton cycles in the random graph (when $\sigma = \infty$ and $\sigma = 2$).
We also consider the adjacency matrix of the random graph and derive a
recurrence relation for the expected values of the elementary symmetric
functions evaluated on the eigenvalues (and thus the determinant) of the
adjacency matrix, and a recurrence relation for the expected value of the
permanent of the adjacency matrix. The cycle probability features prominently
in these recurrence relations. We calculate these quantities for geometric
random graphs (in the $\sigma = 2$ and $\sigma = \infty$ case) with up to $20$
vertices, and compare them with the corresponding quantities for the
Erd\&quot;{o}s-R\'{e}nyi (ER) random graph with the same edge probabilities. The
calculations indicate that the threshold for rapid growth in the number of
Hamilton cycles (as well as that for rapid growth in the permanent of the
adjacency matrix) in the GR graph is lower than in the ER graph. However, as
the number of vertices $n$ increases, the difference between the GR and ER
thresholds reduces, and in both cases, the threshold $\sim \log(n)/n$. Also, we
observe that the expected determinant can take very large values. This throws
some light on the question of the maximal determinant of symmetric $0/1$
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6050</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6050</id><created>2010-09-30</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>Comments on &quot;Consensus and Cooperation in Networked Multi-Agent Systems&quot;</title><categories>cs.MA cs.NI math.OC</categories><comments>3 pages, 11 references</comments><msc-class>93A14, 05C50</msc-class><journal-ref>Proceedings of the IEEE, Vol. 98, No. 7 (July 2010) 1353-1354</journal-ref><doi>10.1109/JPROC.2010.2049911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note corrects a pretty serious mistake and some inaccuracies in
&quot;Consensus and cooperation in networked multi-agent systems&quot; by R.
Olfati-Saber, J.A. Fax, and R.M. Murray, published in Vol. 95 of the
Proceedings of the IEEE (2007, No. 1, P. 215-233). It also mentions several
stronger results applicable to the class of problems under consideration and
addresses the issue of priority whose interpretation in the above-mentioned
paper is not exact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6052</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6052</id><created>2010-09-30</created><authors><author><keyname>Sankar</keyname><forenames>Sharmila</forenames></author><author><keyname>Sankaranarayanan</keyname><forenames>Dr. V.</forenames></author></authors><title>A Low Overhead Reachability Guaranteed Dynamic Route Discovery Mechanism
  for Dense MANETs</title><categories>cs.NI</categories><comments>Probabilistic Route Discover Algorithm for DENSE MANETs</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing,
  Vol 1, No.3,Sep 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A crucial issue for a mobile ad hoc network is the handling of a large number
of nodes. As more nodes join the mobile ad hoc network, contention and
congestion are more likely. The on demand routing protocols which broadcasts
control packets to discover routes to the destination nodes, generate a high
number of broadcast packets in a larger networks causing contention and
collision. We propose an efficient route discovery protocol, which reduces the
number of broadcast packet, using controlled flooding technique. The simulation
results show that the proposed probabilistic flooding decreases the number of
control packets floating in the network during route discovery phase, without
lowering the success ratio of path discoveries. Furthermore, the proposed
method adapts to the normal network conditions. The results show that up to 70%
of control packet traffic is saved in route discovery phase when the network is
denser.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6053</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6053</id><created>2010-09-30</created><updated>2011-09-20</updated><authors><author><keyname>Selva</keyname><forenames>J.</forenames></author></authors><title>Efficient Sampling of Band-limited Signals from Sine Wave Crossings</title><categories>cs.IT math.CV math.IT math.NA</categories><comments>To appear in the IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This correspondence presents an efficient method for reconstructing a
band-limited signal in the discrete domain from its crossings with a sine wave.
The method makes it possible to design A/D converters that only deliver the
crossing timings, which are then used to interpolate the input signal at
arbitrary instants. Potentially, it may allow for reductions in power
consumption and complexity in these converters. The reconstruction in the
discrete domain is based on a recently-proposed modification of the Lagrange
interpolator, which is readily implementable with linear complexity and
efficiently, given that it re-uses known schemes for variable fractional-delay
(VFD) filters. As a spin-off, the method allows one to perform spectral
analysis from sine wave crossings with the complexity of the FFT. Finally, the
results in the correspondence are validated in several numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6057</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6057</id><created>2010-09-30</created><authors><author><keyname>Shah</keyname><forenames>Virag</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author><author><keyname>Manjunath</keyname><forenames>D.</forenames></author></authors><title>Network Flows for Functions</title><categories>cs.NI cs.DC cs.IT math.IT</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in-network computation of an arbitrary function over an arbitrary
communication network. A network with capacity constraints on the links is
given. Some nodes in the network generate data, e.g., like sensor nodes in a
sensor network. An arbitrary function of this distributed data is to be
obtained at a terminal node. The structure of the function is described by a
given computation schema, which in turn is represented by a directed tree. We
design computing and communicating schemes to obtain the function at the
terminal at the maximum rate. For this, we formulate linear programs to
determine network flows that maximize the computation rate. We then develop
fast combinatorial primal-dual algorithm to obtain $\epsilon$-approximate
solutions to these linear programs. We then briefly describe extensions of our
techniques to the cases of multiple terminals wanting different functions,
multiple computation schemas for a function, computation with a given desired
precision, and to networks with energy constraints at nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6079</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6079</id><created>2010-09-30</created><updated>2010-10-01</updated><authors><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Chen</keyname><forenames>Jianshu</forenames></author><author><keyname>Yuan</keyname><forenames>Jian</forenames></author><author><keyname>Ge</keyname><forenames>Ning</forenames></author><author><keyname>Wei</keyname><forenames>Shuangqing</forenames></author></authors><title>A Multi-Interference-Channel Matrix Pair Beamformer for CDMA Systems</title><categories>cs.CE cs.IT math.IT</categories><comments>25 pages, 12 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Matrix pair beamformer (MPB) is a promising blind beamformer which exploits
the temporal signature of the signal of interest (SOI) to acquire its spatial
statistical information. It does not need any knowledge of directional
information or training sequences. However, the major problem of the existing
MPBs is that they have serious threshold effects and the thresholds will grow
as the interference power increases or even approach infinity. In particular,
this issue prevails in scenarios with structured interference, such as,
periodically repeated white noise, tones, or MAIs in multipath channels. In
this paper, we will first present the principles for designing the projection
space of the MPB which are closely correlated with the ability of suppressing
structured interference and system finite sample performance. Then a
multiple-interference-channel based matrix pair beamformer (MIC-MPB) for CDMA
systems is developed according to the principles. In order to adapt to dynamic
channels, an adaptive algorithm for the beamformer is also proposed.
Theoretical analysis and simulation results show that the proposed beamformer
has a small and bounded threshold when the interference power increases.
Performance comparisons of the MIC-MPB and the existing MPBs in various
scenarios via a number of numerical examples are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6091</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6091</id><created>2010-09-30</created><authors><author><keyname>Chowdhury</keyname><forenames>Prasun</forenames></author><author><keyname>Misra</keyname><forenames>Iti Saha</forenames></author></authors><title>A Fair and Efficient Packet Scheduling Scheme for IEEE 802.16 Broadband
  Wireless Access Systems</title><categories>cs.NI</categories><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing (
  IJASUC ),2010</journal-ref><doi>10.5121/ijasuc.2010.1308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a fair and efficient QoS scheduling scheme for IEEE
802.16 BWA systems that satisfies both throughput and delay guarantee to
various real and non-real time applications. The proposed QoS scheduling scheme
is compared with an existing QoS scheduling scheme proposed in literature in
recent past. Simulation results show that the proposed scheduling scheme can
provide a tight QoS guarantee in terms of delay, delay violation rate and
throughput for all types of traffic as defined in the WiMAX standard, thereby
maintaining the fairness and helps to eliminate starvation of lower priority
class services. Bandwidth utilization of the system and fairness index of the
resources are also encountered to validate the QoS provided by our proposed
scheduling scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6098</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6098</id><created>2010-09-30</created><updated>2011-03-04</updated><authors><author><keyname>Bartolini</keyname><forenames>Novella</forenames></author><author><keyname>Calamoneri</keyname><forenames>Tiziana</forenames></author><author><keyname>la Porta</keyname><forenames>Thomas</forenames></author><author><keyname>Petrioli</keyname><forenames>Chiara</forenames></author><author><keyname>Silvestri</keyname><forenames>Simone</forenames></author></authors><title>Sensor Activation and Radius Adaptation (SARA) in Heterogeneous Sensor
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of prolonging the lifetime of wireless
sensor networks (WSNs) deployed to monitor an area of interest. In this
scenario, a helpful approach is to reduce coverage redundancy and therefore the
energy expenditure due to coverage. We introduce the first algorithm which
reduces coverage redundancy by means of Sensor Activation and sensing Radius
Adaptation (SARA)in a general applicative scenario with two classes of devices:
sensors that can adapt their sensing range (adjustable sensors) and sensors
that cannot (fixed sensors). In particular, SARA activates only a subset of all
the available sensors and reduces the sensing range of the adjustable sensors
that have been activated. In doing so, SARA also takes possible heterogeneous
coverage capabilities of sensors belonging to the same class into account. It
specifically addresses device heterogeneity by modeling the coverage problem in
the Laguerre geometry through Voronoi-Laguerre diagrams.
  SARA executes quickly and is guaranteed to terminate. It provides a
configuration of the active set of sensors that lifetime and coverage
requirements of demanding WSN applications, not met by current solutions.
  By means of extensive simulations we show that SARA achieves a network
lifetime that is significantly superior to that obtained by previous algorithms
in all the considered scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6105</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6105</id><created>2010-09-30</created><authors><author><keyname>Cerd&#xe0;-Uguet</keyname><forenames>M. A.</forenames></author><author><keyname>Schellekens</keyname><forenames>M. P.</forenames></author><author><keyname>Valero</keyname><forenames>O.</forenames></author></authors><title>The Baire partial quasi-metric space: A mathematical tool for asymptotic
  complexity analysis in Computer Science</title><categories>cs.CC</categories><comments>25 pages</comments><msc-class>47H10, 54E50, 54F05, 68Q25, 68W40</msc-class><acm-class>F.1.3; F.2.0; D.2.8; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1994, S.G. Matthews introduced the notion of partial metric space in order
to obtain a suitable mathematical tool for program verification [Ann. New York
Acad. Sci. 728 (1994), 183-197]. He gave an application of this new structure
to parallel computing by means of a partial metric version of the celebrated
Banach fixed point theorem [Theoret. Comput. Sci. 151 (1995), 195-205]. Later
on, M.P. Schellekens introduced the theory of complexity (quasi-metric) spaces
as a part of the development of a topological foundation for the asymptotic
complexity analysis of programs and algorithms [Elec- tronic Notes in Theoret.
Comput. Sci. 1 (1995), 211-232]. The applicability of this theory to the
asymptotic complexity analysis of Divide and Conquer algorithms was also
illustrated by Schellekens. In particular, he gave a new proof, based on the
use of the aforenamed Banach fixed point theorem, of the well-known fact that
Mergesort al- gorithm has optimal asymptotic average running time of computing.
In this paper, motivated by the utility of partial metrics in Computer Science,
we discuss whether the Matthews fixed point theorem is a suitable tool to
analyze the asymptotic complexity of algorithms in the spirit of Schellekens.
Specifically, we show that a slight modification of the well-known Baire
partial metric on the set of all words over an alphabet constitutes an
appropriate tool to carry out the asymptotic complexity analysis of algorithms
via fixed point methods without the need for assuming the convergence condition
inherent to the defini- tion of the complexity space in the Shellekens
framework. Finally, in order to illustrate and to validate the developed theory
we apply our results to analyze the asymptotic complexity of Quicksort,
Mergesort and Largesort algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6114</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6114</id><created>2010-09-30</created><authors><author><keyname>Marschall</keyname><forenames>Tobias</forenames></author><author><keyname>Rahmann</keyname><forenames>Sven</forenames></author></authors><title>Exact Analysis of Pattern Matching Algorithms with Probabilistic
  Arithmetic Automata</title><categories>cs.DS cs.FL</categories><msc-class>68W32, 68W40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for the exact probabilistic analysis of window-based
pattern matching algorithms, such as Boyer-Moore, Horspool, Backward DAWG
Matching, Backward Oracle Matching, and more. In particular, we show how to
efficiently obtain the distribution of such an algorithm's running time cost
for any given pattern in a random text model, which can be quite general, from
simple uniform models to higher-order Markov models or hidden Markov models
(HMMs). Furthermore, we provide a technique to compute the exact distribution
of \emph{differences} in running time cost of two algorithms. In contrast to
previous work, our approach is neither limited to simple text models, nor to
asymptotic statements, nor to moment computations such as expectation and
variance. Methodically, we use extensions of finite automata which we call
deterministic arithmetic automata (DAAs) and probabilistic arithmetic automata
(PAAs) [13]. To our knowledge, this is the first time that substring- or
suffix-based pattern matching algorithms are analyzed exactly. Experimentally,
we compare Horspool's algorithm, Backward DAWG Matching, and Backward Oracle
Matching on prototypical patterns of short length and provide statistics on the
size of minimal DAAs for these computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6119</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6119</id><created>2010-09-30</created><authors><author><keyname>Phua</keyname><forenames>Clifton</forenames></author><author><keyname>Lee</keyname><forenames>Vincent</forenames></author><author><keyname>Smith</keyname><forenames>Kate</forenames></author><author><keyname>Gayler</keyname><forenames>Ross</forenames></author></authors><title>A Comprehensive Survey of Data Mining-based Fraud Detection Research</title><categories>cs.AI cs.CE</categories><comments>14 pages</comments><doi>10.1016/j.chb.2012.01.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This survey paper categorises, compares, and summarises from almost all
published technical and review articles in automated fraud detection within the
last 10 years. It defines the professional fraudster, formalises the main types
and subtypes of known fraud, and presents the nature of data evidence collected
within affected industries. Within the business context of mining the data to
achieve higher cost savings, this research presents methods and techniques
together with their problems. Compared to all related reviews on fraud
detection, this survey covers much more technical articles and is the only one,
to the best of our knowledge, which proposes alternative data and solutions
from related domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6127</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6127</id><created>2010-09-30</created><authors><author><keyname>Jiang</keyname><forenames>Hong</forenames></author></authors><title>Efficient Knowledge Base Management in DCSP</title><categories>cs.AI cs.DC</categories><comments>11 pages</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.1, No.3, September 2010, 21-31</journal-ref><doi>10.5121/ijasuc.2010.1302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DCSP (Distributed Constraint Satisfaction Problem) has been a very important
research area in AI (Artificial Intelligence). There are many application
problems in distributed AI that can be formalized as DSCPs. With the increasing
complexity and problem size of the application problems in AI, the required
storage place in searching and the average searching time are increasing too.
Thus, to use a limited storage place efficiently in solving DCSP becomes a very
important problem, and it can help to reduce searching time as well. This paper
provides an efficient knowledge base management approach based on general usage
of hyper-resolution-rule in consistence algorithm. The approach minimizes the
increasing of the knowledge base by eliminate sufficient constraint and false
nogood. These eliminations do not change the completeness of the original
knowledge base increased. The proofs are given as well. The example shows that
this approach decrease both the new nogoods generated and the knowledge base
greatly. Thus it decreases the required storage place and simplify the
searching process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6132</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6132</id><created>2010-09-09</created><authors><author><keyname>Hatai</keyname><forenames>Indranil</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Indrajit</forenames></author></authors><title>Multi-standard programmable baseband modulator for next generation
  wireless communication</title><categories>cs.AR</categories><journal-ref>International Journal of Computer Networks and Communications
  (IJCNC). Vol.2, No. 4, pp. 58-71, July 2010</journal-ref><doi>10.5121/ijcnc.2010.2406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considerable research has taken place in recent times in the area of
parameterization of software defined radio (SDR) architecture. Parameterization
decreases the size of the software to be downloaded and also limits the
hardware reconfiguration time. The present paper is based on the design and
development of a programmable baseband modulator that perform the QPSK
modulation schemes and as well as its other three commonly used variants to
satisfy the requirement of several established 2G and 3G wireless communication
standards. The proposed design has been shown to be capable of operating at a
maximum data rate of 77 Mbps on Xilinx Virtex 2-Pro University field
programmable gate array (FPGA) board. The pulse shaping root raised cosine
(RRC) filter has been implemented using distributed arithmetic (DA) technique
in the present work in order to reduce the computational complexity, and to
achieve appropriate power reduction and enhanced throughput. The designed
multiplier-less programmable 32-tap FIR-based RRC filter has been found to
withstand a peak inter-symbol interference (ISI) distortion of -41 dBs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6134</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6134</id><created>2010-09-30</created><updated>2011-08-16</updated><authors><author><keyname>Saleem</keyname><forenames>Muhammad Shoaib</forenames></author><author><keyname>Renault</keyname><forenames>&#xc9;ric</forenames></author><author><keyname>Zeghlache</keyname><forenames>Djamal</forenames></author></authors><title>NetInf Mobile Node Architecture and Mobility Management based on LISP
  Mobile Node</title><categories>cs.NI</categories><comments>Accepted in IEEE Consumer Communications and Networking Conference
  2011. Las Vegas, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an architecture for Network of Information mobile
node (NetInf MN). It bears characteristics and features of basic NetInf node
architecture with features introduced in the LISP MN architecture. We also
introduce a virtual node layer for mobility management in the Network of
Information. Therefore, by adopting this architecture no major changes in the
contemporary network topologies is required. Thus, making our approach more
practical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6144</identifier>
 <datestamp>2012-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6144</id><created>2010-09-30</created><updated>2012-05-29</updated><authors><author><keyname>Bollob&#xe1;s</keyname><forenames>B&#xe9;la</forenames></author><author><keyname>Pritchard</keyname><forenames>David</forenames></author><author><keyname>Rothvo&#xdf;</keyname><forenames>Thomas</forenames></author><author><keyname>Scott</keyname><forenames>Alex</forenames></author></authors><title>Cover-Decomposition and Polychromatic Numbers</title><categories>math.CO cs.DM</categories><comments>Supercedes arXiv:1009.5893</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A colouring of a hypergraph's vertices is polychromatic if every hyperedge
contains at least one vertex of each colour; the polychromatic number is the
maximum number of colours in such a colouring. Its dual, the
cover-decomposition number, is the maximum number of disjoint hyperedge-covers.
In geometric hypergraphs, there is extensive work on lower-bounding these
numbers in terms of their trivial upper bounds (minimum hyperedge size and
degree); our goal here is to broaden the study beyond geometric settings. We
obtain algorithms yielding near-tight bounds for three families of hypergraphs:
bounded hyperedge size, paths in trees, and bounded VC-dimension. This reveals
that discrepancy theory and iterated linear program relaxation are useful for
cover-decomposition. Finally, we discuss the generalization of
cover-decomposition to sensor cover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6171</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6171</id><created>2010-09-30</created><authors><author><keyname>Tiu</keyname><forenames>Alwen</forenames></author><author><keyname>Momigliano</keyname><forenames>Alberto</forenames></author></authors><title>Cut Elimination for a Logic with Induction and Co-induction</title><categories>cs.LO</categories><comments>42 pages, submitted to the Journal of Applied Logic</comments><acm-class>F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proof search has been used to specify a wide range of computation systems. In
order to build a framework for reasoning about such specifications, we make use
of a sequent calculus involving induction and co-induction. These proof
principles are based on a proof theoretic (rather than set-theoretic) notion of
definition. Definitions are akin to logic programs, where the left and right
rules for defined atoms allow one to view theories as &quot;closed&quot; or defining
fixed points. The use of definitions and free equality makes it possible to
reason intentionally about syntax. We add in a consistent way rules for pre and
post fixed points, thus allowing the user to reason inductively and
co-inductively about properties of computational system making full use of
higher-order abstract syntax. Consistency is guaranteed via cut-elimination,
where we give the first, to our knowledge, cut-elimination procedure in the
presence of general inductive and co-inductive definitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6182</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6182</id><created>2010-09-30</created><updated>2011-01-14</updated><authors><author><keyname>Chen</keyname><forenames>Qing</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Goodput Maximization in Cooperative Networks with ARQ</title><categories>cs.IT math.IT</categories><comments>7 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the average successful throughput, i.e., goodput, of a coded
3-node cooperative network is studied in a Rayleigh fading environment. It is
assumed that a simple automatic repeat request (ARQ) technique is employed in
the network so that erroneously received codeword is retransmitted until
successful delivery. The relay is assumed to operate in either
amplify-and-forward (AF) or decode-and-forward (DF) mode. Under these
assumptions, retransmission mechanisms and protocols are described, and the
average time required to send information successfully is determined.
Subsequently, the goodput for both AF and DF relaying is formulated. The
tradeoffs and interactions between the goodput, transmission rates, and relay
location are investigated and optimal strategies are identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6186</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6186</id><created>2010-09-30</created><authors><author><keyname>Thamarai</keyname><forenames>SM.</forenames></author><author><keyname>Kuppusamy</keyname><forenames>K.</forenames></author><author><keyname>Meyyappan</keyname><forenames>T.</forenames></author></authors><title>Heuristic approach to optimize the number of test cases for simple
  circuits</title><categories>cs.OH</categories><comments>PDF 9 pages, 2 figures, 2 tables</comments><report-no>0910vlsics02</report-no><journal-ref>International journal of VLSI design &amp; Communication Systems
  (VLSICS) Vol.1, No.3, September 2010</journal-ref><doi>10.5121/vlsic.2010.1302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new solution is proposed for testing simple stwo stage
electronic circuits. It minimizes the number of tests to be performed to
determine the genuinity of the circuit. The main idea behind the present
research work is to identify the maximum number of indistinguishable faults
present in the given circuit and minimize the number of test cases based on the
number of faults that has been detected. Heuristic approach is used for test
minimization part, which identifies the essential tests from overall test
cases. From the results it is observed that, test minimization varies from 50%
to 99% with the lowest one corresponding to a circuit with four gates .Test
minimization is low in case of circuits with lesser input leads in gates
compared to greater input leads in gates for the boolean expression with same
number of symbols. Achievement of 99% reduction is due to the fact that the
large number of tests find the same faults. The new approach is implemented for
simple circuits. The results show potential for both smaller test sets and
lower cpu times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6197</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6197</id><created>2010-09-30</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Secure Relay Beamforming over Cognitive Radio Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a cognitive relay channel is considered, and
amplify-and-forward (AF) relay beamforming designs in the presence of an
eavesdropper and a primary user are studied. Our objective is to optimize the
performance of the cognitive relay beamforming system while limiting the
interference in the direction of the primary receiver and keeping the
transmitted signal secret from the eavesdropper. We show that under both total
and individual power constraints, the problem becomes a quasiconvex
optimization problem which can be solved by interior point methods. We also
propose two sub-optimal null space beamforming schemes which are obtained in a
more computationally efficient way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6200</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6200</id><created>2010-09-30</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Optimal Power Allocation for Secrecy Fading Channels Under
  Spectrum-Sharing Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the spectrum-sharing technology, a secondary user may utilize the primary
user's licensed band as long as its interference to the primary user is below a
tolerable value. In this paper, we consider a scenario in which a secondary
user is operating in the presence of both a primary user and an eavesdropper.
Hence, the secondary user has both interference limitations and security
considerations. In such a scenario, we study the secrecy capacity limits of
opportunistic spectrum-sharing channels in fading environments and investigate
the optimal power allocation for the secondary user under average and peak
received power constraints at the primary user with global channel side
information (CSI). Also, in the absence of the eavesdropper's CSI, we study
optimal power allocation under an average power constraint and propose a
suboptimal on/off power control method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6205</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6205</id><created>2010-09-30</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Channel Coding over Multiple Coherence Blocks with Queueing Constraints</title><categories>cs.IT math.IT</categories><comments>submitted to ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the performance of wireless systems that employ
finite-blocklength channel codes for transmission and operate under queueing
constraints in the form of limitations on buffer overflow probabilities. A
block fading model, in which fading stays constant in each coherence block and
change independently between blocks, is considered. It is assumed that channel
coding is performed over multiple coherence blocks. An approximate lower bound
on the transmission rate is obtained from Feintein's Lemma. This lower bound is
considered as the service rate and is incorporated into the effective capacity
formulation, which characterizes the maximum constant arrival rate that can be
supported under statistical queuing constraints. Performances of variable-rate
and fixed-rate transmissions are studied. The optimum error probability for
variable rate transmission and the optimum coding rate for fixed rate
transmission are shown to be unique. Moreover, the tradeoff between the
throughput and the number of blocks over which channel coding is performed is
identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6206</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6206</id><created>2010-09-30</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>On the Effective Capacity of Two-Hop Communication Systems</title><categories>cs.IT math.IT</categories><comments>submitted to ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, two-hop communication between a source and a destination with
the aid of an intermediate relay node is considered. Both the source and
intermediate relay node are assumed to operate under statistical quality of
service (QoS) constraints imposed as limitations on the buffer overflow
probabilities. It is further assumed that the nodes send the information at
fixed power levels and have perfect channel side information. In this scenario,
the maximum constant arrival rates that can be supported by this two-hop link
are characterized by finding the effective capacity. Through this analysis, the
impact upon the throughput of having buffer constraints at the source and
intermediate-hop nodes is identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6215</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6215</id><created>2010-09-30</created><authors><author><keyname>Andres</keyname><forenames>Bjoern</forenames></author><author><keyname>Koethe</keyname><forenames>Ullrich</forenames></author><author><keyname>Kroeger</keyname><forenames>Thorben</forenames></author><author><keyname>Hamprecht</keyname><forenames>Fred A.</forenames></author></authors><title>How to Extract the Geometry and Topology from Very Large 3D
  Segmentations</title><categories>cs.CG cs.CV cs.DS</categories><comments>C++ source code, free command line tools and MATLAB mex files are
  avilable from http://hci.iwr.uni-heidelberg.de/software.php</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation is often an essential intermediate step in image analysis. A
volume segmentation characterizes the underlying volume image in terms of
geometric information--segments, faces between segments, curves in which
several faces meet--as well as a topology on these objects. Existing algorithms
encode this information in designated data structures, but require that these
data structures fit entirely in Random Access Memory (RAM). Today, 3D images
with several billion voxels are acquired, e.g. in structural neurobiology.
Since these large volumes can no longer be processed with existing methods, we
present a new algorithm which performs geometry and topology extraction with a
runtime linear in the number of voxels and log-linear in the number of faces
and curves. The parallelizable algorithm proceeds in a block-wise fashion and
constructs a consistent representation of the entire volume image on the hard
drive, making the structure of very large volume segmentations accessible to
image analysis. The parallelized C++ source code, free command line tools and
MATLAB mex files are avilable from
http://hci.iwr.uni-heidelberg.de/software.php
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6218</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6218</id><created>2010-09-30</created><authors><author><keyname>Rangaraju</keyname><forenames>H G</forenames></author><author><keyname>Venugopal</keyname><forenames>U.</forenames></author><author><keyname>Muralidhara</keyname><forenames>K N</forenames></author><author><keyname>Raja</keyname><forenames>K B</forenames></author></authors><title>Low Power Reversible Parallel Binary Adder/Subtractor</title><categories>cs.PF</categories><comments>12 pages,VLSICS Journal</comments><journal-ref>International Journal of VLSI Design &amp; Communication Systems,
  1.3(2010),pp-23-34</journal-ref><doi>10.5121/vlsic.2010.1303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, Reversible Logic is becoming more and more prominent
technology having its applications in Low Power CMOS, Quantum Computing,
Nanotechnology, and Optical Computing. Reversibility plays an important role
when energy efficient computations are considered. In this paper, Reversible
eight-bit Parallel Binary Adder/Subtractor with Design I, Design II and Design
III are proposed. In all the three design approaches, the full Adder and
Subtractors are realized in a single unit as compared to only full Subtractor
in the existing design. The performance analysis is verified using number
reversible gates, Garbage input/outputs and Quantum Cost. It is observed that
Reversible eight-bit Parallel Binary Adder/Subtractor with Design III is
efficient compared to Design I, Design II and existing design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1009.6230</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1009.6230</id><created>2010-09-30</created><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>Approximate Representations and Approximate Homomorphisms</title><categories>math.RT cs.DM math.GR quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate algebraic structures play a defining role in arithmetic
combinatorics and have found remarkable applications to basic questions in
number theory and pseudorandomness. Here we study approximate representations
of finite groups: functions f:G -&gt; U_d such that Pr[f(xy) = f(x) f(y)] is
large, or more generally Exp_{x,y} ||f(xy) - f(x)f(y)||^2$ is small, where x
and y are uniformly random elements of the group G and U_d denotes the unitary
group of degree d. We bound these quantities in terms of the ratio d / d_min
where d_min is the dimension of the smallest nontrivial representation of G. As
an application, we bound the extent to which a function f : G -&gt; H can be an
approximate homomorphism where H is another finite group. We show that if H's
representations are significantly smaller than G's, no such f can be much more
homomorphic than a random function.
  We interpret these results as showing that if G is quasirandom, that is, if
d_min is large, then G cannot be embedded in a small number of dimensions, or
in a less-quasirandom group, without significant distortion of G's
multiplicative structure. We also prove that our bounds are tight by showing
that minors of genuine representations and their polar decompositions are
essentially optimal approximate representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0011</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0011</id><created>2010-09-30</created><authors><author><keyname>Yu</keyname><forenames>Nam Yul</forenames></author></authors><title>Deterministic Compressed Sensing Matrices from Additive Character
  Sequences</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a novel technique where one can recover sparse signals
from the undersampled measurements. In this correspondence, a $K \times N$
measurement matrix for compressed sensing is deterministically constructed via
additive character sequences. The Weil bound is then used to show that the
matrix has asymptotically optimal coherence for $N=K^2$, and to present a
sufficient condition on the sparsity level for unique sparse recovery. Also,
the restricted isometry property (RIP) is statistically studied for the
deterministic matrix. Using additive character sequences with small alphabets,
the compressed sensing matrix can be efficiently implemented by linear feedback
shift registers. Numerical results show that the deterministic compressed
sensing matrix guarantees reliable matching pursuit recovery performance for
both noiseless and noisy measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0012</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0012</id><created>2010-09-30</created><authors><author><keyname>Coughlan</keyname><forenames>James M.</forenames></author><author><keyname>Shen</keyname><forenames>Huiying</forenames></author></authors><title>An Embarrassingly Simple Speed-Up of Belief Propagation with Robust
  Potentials</title><categories>cs.CV cs.AI</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an exact method of greatly speeding up belief propagation (BP) for
a wide variety of potential functions in pairwise MRFs and other graphical
models. Specifically, our technique applies whenever the pairwise potentials
have been {\em truncated} to a constant value for most pairs of states, as is
commonly done in MRF models with robust potentials (such as stereo) that impose
an upper bound on the penalty assigned to discontinuities; for each of the $M$
possible states in one node, only a smaller number $m$ of compatible states in
a neighboring node are assigned milder penalties. The computational complexity
of our method is $O(mM)$, compared with $O(M^2)$ for standard BP, and we
emphasize that the method is {\em exact}, in contrast with related techniques
such as pruning; moreover, the method is very simple and easy to implement.
Unlike some previous work on speeding up BP, our method applies both to
sum-product and max-product BP, which makes it useful in any applications where
marginal probabilities are required, such as maximum likelihood estimation. We
demonstrate the technique on a stereo MRF example, confirming that the
technique speeds up BP without altering the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0014</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0014</id><created>2010-09-30</created><authors><author><keyname>Iwen</keyname><forenames>M. A.</forenames></author></authors><title>Improved Approximation Guarantees for Sublinear-Time Fourier Algorithms</title><categories>math.NA cs.NA</categories><acm-class>G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper modified variants of the sparse Fourier transform algorithms
from [14] are presented which improve on the approximation error bounds of the
original algorithms. In addition, simple methods for extending the improved
sparse Fourier transforms to higher dimensional settings are developed. As a
consequence, approximate Fourier transforms are obtained which will identify a
near-optimal k-term Fourier series for any given input function, $f : [0, 2 pi]
-&gt; C, in O(k^2 \cdot D^4)$ time (neglecting logarithmic factors). Faster
randomized Fourier algorithm variants with runtime complexities that scale
linearly in the sparsity parameter k are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0019</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0019</id><created>2010-09-30</created><authors><author><keyname>Chun</keyname><forenames>Byung-Gon</forenames></author><author><keyname>Huang</keyname><forenames>Ling</forenames></author><author><keyname>Lee</keyname><forenames>Sangmin</forenames></author><author><keyname>Maniatis</keyname><forenames>Petros</forenames></author><author><keyname>Naik</keyname><forenames>Mayur</forenames></author></authors><title>Mantis: Predicting System Performance through Program Analysis and
  Modeling</title><categories>cs.PF cs.AI cs.PL</categories><acm-class>D.4.8; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Mantis, a new framework that automatically predicts program
performance with high accuracy. Mantis integrates techniques from programming
language and machine learning for performance modeling, and is a radical
departure from traditional approaches. Mantis extracts program features, which
are information about program execution runs, through program instrumentation.
It uses machine learning techniques to select features relevant to performance
and creates prediction models as a function of the selected features. Through
program analysis, it then generates compact code slices that compute these
feature values for prediction. Our evaluation shows that Mantis can achieve
more than 93% accuracy with less than 10% training data set, which is a
significant improvement over models that are oblivious to program features. The
system generates code slices that are cheap to compute feature values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0032</identifier>
 <datestamp>2014-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0032</id><created>2010-09-30</created><updated>2014-10-09</updated><authors><author><keyname>King</keyname><forenames>Andrew D.</forenames></author></authors><title>A stronger result on fractional strong colourings</title><categories>cs.DM math.CO</categories><comments>Withdrawn -- critical error in the proof of the main lemma</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aharoni, Berger and Ziv recently proved the fractional relaxation of the
strong colouring conjecture. In this note we generalize their result as
follows. Let $k\geq 1$ and partition the vertices of a graph $G$ into sets
$V_1,..., V_r$, such that for $1\leq i \leq r$ every vertex in $V_i$ has at
most $\max\{k, |V_i|-k \}$ neighbours outside $V_i$. Then there is a
probability distribution on the stable sets of $G$ such that a stable set drawn
from this distribution hits each vertex in $V_i$ with probability $1/|V_i|$,
for $1\leq i\leq r$. We believe that this result will be useful as a tool in
probabilistic approaches to bounding the chromatic number and fractional
chromatic number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0034</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0034</id><created>2010-09-30</created><authors><author><keyname>Zavlanos</keyname><forenames>Michael M.</forenames></author><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Spectral Control of Mobile Robot Networks</title><categories>cs.MA cs.SY math.OC</categories><comments>http://alum.mit.edu/www/vmp</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The eigenvalue spectrum of the adjacency matrix of a network is closely
related to the behavior of many dynamical processes run over the network. In
the field of robotics, this spectrum has important implications in many
problems that require some form of distributed coordination within a team of
robots. In this paper, we propose a continuous-time control scheme that
modifies the structure of a position-dependent network of mobile robots so that
it achieves a desired set of adjacency eigenvalues. For this, we employ a novel
abstraction of the eigenvalue spectrum by means of the adjacency matrix
spectral moments. Since the eigenvalue spectrum is uniquely determined by its
spectral moments, this abstraction provides a way to indirectly control the
eigenvalues of the network. Our construction is based on artificial potentials
that capture the distance of the network's spectral moments to their desired
values. Minimization of these potentials is via a gradient descent closed-loop
system that, under certain convexity assumptions, ensures convergence of the
network topology to one with the desired set of moments and, therefore,
eigenvalues. We illustrate our approach in nontrivial computer simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0041</identifier>
 <datestamp>2012-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0041</id><created>2010-09-30</created><updated>2012-08-29</updated><authors><author><keyname>Gabran</keyname><forenames>Wesam</forenames></author><author><keyname>Pawe&#x142;czak</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>&#x10c;abri&#x107;</keyname><forenames>Danijela</forenames></author></authors><title>Throughput and Collision Analysis of Multi-Channel Multi-Stage Spectrum
  Sensing Algorithms</title><categories>cs.PF cs.IT cs.NI math.IT</categories><journal-ref>IEEE Transations on Vehicular Technology, vol. 60, no. 7, pp.
  3309-3323, 2011</journal-ref><doi>10.1109/TVT.2011.2160210</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-stage sensing is a novel concept that refers to a general class of
spectrum sensing algorithms that divide the sensing process into a number of
sequential stages. The number of sensing stages and the sensing technique per
stage can be used to optimize performance with respect to secondary user
throughput and the collision probability between primary and secondary users.
So far, the impact of multi-stage sensing on network throughput and collision
probability for a realistic network model is relatively unexplored. Therefore,
we present the first analytical framework which enables performance evaluation
of different multi-channel multi-stage spectrum sensing algorithms for
Opportunistic Spectrum Access networks. The contribution of our work lies in
studying the effect of the following parameters on performance: number of
sensing stages, physical layer sensing techniques and durations per each stage,
single and parallel channel sensing and access, number of available channels,
primary and secondary user traffic, buffering of incoming secondary user
traffic, as well as MAC layer sensing algorithms. Analyzed performance metrics
include the average secondary user throughput and the average collision
probability between primary and secondary users. Our results show that when the
probability of primary user mis-detection is constrained, the performance of
multi-stage sensing is, in most cases, superior to the single stage sensing
counterpart. Besides, prolonged channel observation at the first stage of
sensing decreases the collision probability considerably, while keeping the
throughput at an acceptable level. Finally, in realistic primary user traffic
scenarios, using two stages of sensing provides a good balance between
secondary users throughput and collision probability while meeting successful
detection constraints subjected by Opportunistic Spectrum Access communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0047</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0047</id><created>2010-09-30</created><updated>2011-11-24</updated><authors><author><keyname>Wu</keyname><forenames>Haoyang</forenames></author></authors><title>A non-cooperative Pareto-efficient solution to a one-shot Prisoner's
  Dilemma</title><categories>cs.GT</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Prisoner's Dilemma is a simple model that captures the essential
contradiction between individual rationality and global rationality. Although
the one-shot Prisoner's Dilemma is usually viewed simple, in this paper we will
categorize it into five different types. For the type-4 Prisoner's Dilemma
game, we will propose a self-enforcing algorithmic model to help
non-cooperative agents obtain Pareto-efficient payoffs. The algorithmic model
is based on an algorithm using complex numbers and can work in macro
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0056</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0056</id><created>2010-09-30</created><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Online Learning in Opportunistic Spectrum Access: A Restless Bandit
  Approach</title><categories>math.OC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an opportunistic spectrum access (OSA) problem where the
time-varying condition of each channel (e.g., as a result of random fading or
certain primary users' activities) is modeled as an arbitrary finite-state
Markov chain. At each instance of time, a (secondary) user probes a channel and
collects a certain reward as a function of the state of the channel (e.g., good
channel condition results in higher data rate for the user). Each channel has
potentially different state space and statistics, both unknown to the user, who
tries to learn which one is the best as it goes and maximizes its usage of the
best channel. The objective is to construct a good online learning algorithm so
as to minimize the difference between the user's performance in total rewards
and that of using the best channel (on average) had it known which one is the
best from a priori knowledge of the channel statistics (also known as the
regret). This is a classic exploration and exploitation problem and results
abound when the reward processes are assumed to be iid. Compared to prior work,
the biggest difference is that in our case the reward process is assumed to be
Markovian, of which iid is a special case. In addition, the reward processes
are restless in that the channel conditions will continue to evolve independent
of the user's actions. This leads to a restless bandit problem, for which there
exists little result on either algorithms or performance bounds in this
learning context to the best of our knowledge. In this paper we introduce an
algorithm that utilizes regenerative cycles of a Markov chain and computes a
sample-mean based index policy, and show that under mild conditions on the
state transition probabilities of the Markov chains this algorithm achieves
logarithmic regret uniformly over time, and that this regret bound is also
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0060</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0060</id><created>2010-10-01</created><updated>2011-06-19</updated><authors><author><keyname>Uchikawa</keyname><forenames>Hironori</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Design and Performance of Rate-compatible Non-Binary LDPC Convolutional
  Codes</title><categories>cs.IT math.IT</categories><comments>8 pages, submitted to IEICE transaction</comments><doi>10.1587/transfun.E94.A.2135</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a construction method of non-binary low-density
parity-check (LDPC) convolutional codes. Our construction method is an
extension of Felstroem and Zigangirov construction for non-binary LDPC
convolutional codes. The rate-compatibility of the non-binary convolutional
code is also discussed. The proposed rate-compatible code is designed from one
single mother (2,4)-regular non-binary LDPC convolutional code of rate 1/2.
Higher-rate codes are produced by puncturing the mother code and lower-rate
codes are produced by multiplicatively repeating the mother code. Simulation
results show that non-binary LDPC convolutional codes of rate 1/2 outperform
state-of-the-art binary LDPC convolutional codes with comparable constraint bit
length. Also the derived low-rate and high-rate non-binary LDPC convolutional
codes exhibit good decoding performance without loss of large gap to the
Shannon limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0066</identifier>
 <datestamp>2011-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0066</id><created>2010-10-01</created><updated>2011-11-17</updated><authors><author><keyname>Ceragioli</keyname><forenames>Francesca</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author></authors><title>Continuous-time Discontinuous Equations in Bounded Confidence Opinion
  Dynamics</title><categories>math.OC cs.SI cs.SY math.DS</categories><comments>16 pages, no figures - v4: revised proof of Theorem 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report studies a continuous-time version of the well-known
Hegselmann-Krause model of opinion dynamics with bounded confidence. As the
equations of this model have discontinuous right-hand side, we study their
Krasovskii solutions. We present results about existence and completeness of
solutions, and asymptotical convergence to equilibria featuring a
&quot;clusterization&quot; of opinions. The robustness of such equilibria to small
perturbations is also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0122</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0122</id><created>2010-10-01</created><authors><author><keyname>Hartung</keyname><forenames>Michael</forenames></author><author><keyname>Gro&#xdf;</keyname><forenames>Anika</forenames></author><author><keyname>Rahm</keyname><forenames>Erhard</forenames></author></authors><title>Rule-based Generation of Diff Evolution Mappings between Ontology
  Versions</title><categories>cs.DB</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontologies such as taxonomies, product catalogs or web directories are
heavily used and hence evolve frequently to meet new requirements or to better
reflect the current instance data of a domain. To effectively manage the
evolution of ontologies it is essential to identify the difference (Diff)
between two ontology versions. We propose a novel approach to determine an
expressive and invertible diff evolution mapping between given versions of an
ontology. Our approach utilizes the result of a match operation to determine an
evolution mapping consisting of a set of basic change operations
(insert/update/delete). To semantically enrich the evolution mapping we adopt a
rule-based approach to transform the basic change operations into a smaller set
of more complex change operations, such as merge, split, or changes of entire
subgraphs. The proposed algorithm is customizable in different ways to meet the
requirements of diverse ontologies and application scenarios. We evaluate the
proposed approach by determining and analyzing evolution mappings for
real-world life science ontologies and web directories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0141</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0141</id><created>2010-09-30</created><authors><author><keyname>Gupta</keyname><forenames>Mithun Das</forenames></author><author><keyname>Kumar</keyname><forenames>Sanjeev</forenames></author><author><keyname>Xiao</keyname><forenames>Jing</forenames></author></authors><title>L1 Projections with Box Constraints</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the L1 minimization problem with additional box constraints. We
motivate the problem with two different views of optimality considerations. We
look into imposing such constraints in projected gradient techniques and
propose a worst case linear time algorithm to perform such projections. We
demonstrate the merits and effectiveness of our algorithms on synthetic as well
as real experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0145</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0145</id><created>2010-10-01</created><authors><author><keyname>Villadsen</keyname><forenames>J&#xf8;rgen</forenames></author><author><keyname>Boss</keyname><forenames>Niklas Skamriis</forenames></author><author><keyname>Jensen</keyname><forenames>Andreas Schmidt</forenames></author><author><keyname>Vester</keyname><forenames>Steen</forenames></author></authors><title>Multi-Agent Programming Contest 2010 - The Jason-DTU Team</title><categories>cs.MA</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a brief description of the Jason-DTU system, including the
methodology, the tools and the team strategy that we plan to use in the agent
contest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0150</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0150</id><created>2010-10-01</created><authors><author><keyname>Jensen</keyname><forenames>Andreas Schmidt</forenames></author></authors><title>Implementing Lego Agents Using Jason</title><categories>cs.MA</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since many of the currently available multi-agent frameworks are generally
mostly intended for research, it can be difficult to built multi-agent systems
using physical robots. In this report I describe a way to combine the
multi-agent framework Jason, an extended version of the agent-oriented
programming language AgentSpeak, with Lego robots to address this problem. By
extending parts of the Jason reasoning cycle I show how Lego robots are able to
complete tasks such as following lines on a floor and communicating to be able
to avoid obstacles with minimal amount of coding. The final implementation is a
functional extension that is able to built multi-agent systems using Lego
agents, however there are some issues that have not been addressed. If the
agents are highly dependent on percepts from their sensors, they are required
to move quite slowly, because there currently is a high delay in the reasoning
cycle, when it is combined with a robot. Overall the system is quite robust and
can be used to make simple Lego robots perform tasks of an advanced agent in a
multi-agent environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0155</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0155</id><created>2010-10-01</created><authors><author><keyname>Jensen</keyname><forenames>Andreas Schmidt</forenames></author></authors><title>An Investigation of the Advantages of Organization-Centered Multi-Agent
  Systems</title><categories>cs.MA</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whereas classical multi-agent systems have the agent in center, there have
recently been a development towards focusing more on the organization of the
system. This allows the designer to focus on what the system goals are, without
considering how the goals should be fulfilled. This paper investigates whether
taking this approach has any clear advantages to the classical way of
implementing multi-agent systems. The investigation is done by implementing
each type of system in the same environment in order to realize what advantages
and disadvantages each approach has.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0157</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0157</id><created>2010-10-01</created><authors><author><keyname>Paul</keyname><forenames>Gerald</forenames></author></authors><title>Comparative Performance of Tabu Search and Simulated Annealing
  Heuristics for the Quadratic Assignment Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For almost two decades the question of whether tabu search (TS) or simulated
annealing (SA) performs better for the quadratic assignment problem has been
unresolved. To answer this question satisfactorily, we compare performance at
various values of targeted solution quality, running each heuristic at its
optimal number of iterations for each target. We find that for a number of
varied problem instances, SA performs better for higher quality targets while
TS performs better for lower quality targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0168</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0168</id><created>2010-10-01</created><authors><author><keyname>Momani</keyname><forenames>Mohammad</forenames></author><author><keyname>Challa</keyname><forenames>Subhash</forenames></author></authors><title>Survey of trust models in different network domains</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the security and trust concepts in wireless sensor
networks and explains the difference between them, stating that even though
both terms are used interchangeably when defining a secure system, they are not
the same. The difference between reputation and trust is also explained,
highlighting that reputation partially affects trust. A survey of trust and
reputation systems in various domains is conducted, with more details given to
models in ad-hoc and sensor networks as they are closely related to each other
and to our research interests. The methodologies used to model trust and their
references are presented. The factors affecting trust updating are summarised
and some examples of the systems in which these factors have been implemented
are given. The survey states that, even though researchers have started to
explore the issue of trust in wireless sensor networks, they are still
examining the trust associated with routing messages between nodes (binary
events). However, wireless sensor networks are mainly deployed to monitor
events and report data, both continuous and discrete. This leads to the
development of new trust models addressing the continuous data issue and also
to combine the data trust and the communication trust to infer the total trust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0169</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0169</id><created>2010-10-01</created><authors><author><keyname>Masoumi</keyname><forenames>Massoud</forenames></author></authors><title>A Novel and Highly Efficient AES Implementation Robust against
  Differential Power Analysis</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Developed by Paul Kocher, Joshua Jaffe, and Benjamin Jun in 1999,
Differential Power Analysis (DPA) represents a unique and powerful
cryptanalysis technique. Insight into the encryption and decryption behavior of
a cryptographic device can be determined by examining its electrical power
signature. This paper describes a novel approach for implementation of the AES
algorithm which provides a significantly improved strength against differential
power analysis with a minimal additional hardware overhead. Our method is based
on randomization in composite field arithmetic which entails an area penalty of
only 7% while does not decrease the working frequency, does not alter the
algorithm and keeps perfect compatibility with the published standard. The
efficiency of the proposed technique was verified by practical results obtained
from real implementation on a Xilinx Spartan-II FPGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0177</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0177</id><created>2010-10-01</created><updated>2012-04-10</updated><authors><author><keyname>Pierrot</keyname><forenames>Alexandre J.</forenames></author><author><keyname>Bloch</keyname><forenames>Matthieu R.</forenames></author></authors><title>Strongly Secure Communications Over the Two-Way Wiretap Channel</title><categories>cs.IT math.IT</categories><comments>11 pages, 7 figures, submitted to IEEE Transactions on Information
  Forensics and Security, Special Issue: &quot;Using the Physical Layer for Securing
  the Next Generation of Communication Systems&quot;</comments><journal-ref>IEEE Transactions on Information Forensics and Security, Sept.
  2011</journal-ref><doi>10.1109/TIFS.2011.2158422</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of secure communications over the two-way wiretap
channel under a strong secrecy criterion. We improve existing results by
developing an achievable region based on strategies that exploit both the
interference at the eavesdropper's terminal and cooperation between legitimate
users. We leverage the notion of channel resolvability for the multiple-access
channel to analyze cooperative jamming and we show that the artificial noise
created by cooperative jamming induces a source of common randomness that can
be used for secret-key agreement. We illustrate the gain provided by this
coding technique in the case of the Gaussian two-way wiretap channel, and we
show significant improvements for some channel configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0182</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0182</id><created>2010-10-01</created><authors><author><keyname>Song</keyname><forenames>Yiwei</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>List decoding for nested lattices and applications to relay channels</title><categories>cs.IT math.IT</categories><comments>8 pages; presented at Allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate a decoding scheme for nested lattice codes which is able to
decode a list of a particular size which contains the transmitted codeword with
high probability. This list decoder is analogous to that used in random coding
arguments in achievability schemes of relay channels, and allows for the
effective combination of information from the relay and source node. Using this
list decoding result, we demonstrate 1) that lattice codes may achieve the
capacity of the physically degraded AWGN relay channel, 2) an achievable rate
region for the two-way relay channel with direct links using lattice codes, and
3) that we may improve the constant gap to capacity for specific cases of the
two-way relay channel with direct links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0186</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0186</id><created>2010-10-01</created><authors><author><keyname>Anam</keyname><forenames>Beenish</forenames></author><author><keyname>Sakib</keyname><forenames>Kazi</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Alamgir</forenames></author><author><keyname>Dahal</keyname><forenames>Keshav</forenames></author></authors><title>Review on the Advancements of DNA Cryptography</title><categories>cs.CR</categories><journal-ref>SKIMA 2010, August 25-27, 2010, Paro, Bhutan</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since security is one of the most important issues, the evolve of
cryptography and cryptographic analysis are considered as the fields of
on-going research. The latest development on this field is DNA cryptography. It
has emerged after the disclosure of computational ability of Deoxyribo Nucleic
Acid (DNA). DNA cryptography uses DNA as the computational tool along with
several molecular techniques to manipulate it. Due to very high storage
capacity of DNA, this field is becoming very promising. Currently it is in the
development phase and it requires a lot of work and research to reach a mature
stage. By reviewing all the potential and cutting edge technology of current
research, this paper shows the directions that need to be addressed further in
the field of DNA cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0189</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0189</id><created>2010-10-01</created><authors><author><keyname>Yu</keyname><forenames>Nam Yul</forenames></author></authors><title>Reed-Muller Codes for Peak Power Control in Multicarrier CDMA</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reed-Muller codes are studied for peak power control in multicarrier
code-division multiple access (MC-CDMA) communication systems. In a coded
MC-CDMA system, the information data multiplexed from users is encoded by a
Reed-Muller subcode and the codeword is fully-loaded to Walsh-Hadamard
spreading sequences. The polynomial representation of a coded MC-CDMA signal is
established for theoretical analysis of the peak-to-average power ratio (PAPR).
The Reed-Muller subcodes are defined in a recursive way by the Boolean
functions providing the transmitted MC-CDMA signals with the bounded PAPR as
well as the error correction capability. A connection between the code rates
and the maximum PAPR is theoretically investigated in the coded MC-CDMA.
Simulation results present the statistical evidence that the PAPR of the coded
MC-CDMA signal is not only theoretically bounded, but also statistically
reduced. In particular, the coded MC-CDMA solves the major PAPR problem of
uncoded MC-CDMA by dramatically reducing its PAPR for the small number of
users. Finally, the theoretical and statistical studies show that the
Reed-Muller subcodes are effective coding schemes for peak power control in
MC-CDMA with small and moderate numbers of users, subcarriers, and spreading
factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0200</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0200</id><created>2010-10-01</created><updated>2010-10-15</updated><authors><author><keyname>Wang</keyname><forenames>Yue</forenames></author><author><keyname>Coon</keyname><forenames>Justin P.</forenames></author></authors><title>Difference Antenna Selection and Power Allocation for Wireless Cognitive
  Systems</title><categories>cs.IT math.IT</categories><comments>29 pages, 9 figures, to be submitted to IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an antenna selection method in a wireless cognitive
radio (CR) system, namely difference selection, whereby a single transmit
antenna is selected at the secondary transmitter out of $M$ possible antennas
such that the weighted difference between the channel gains of the data link
and the interference link is maximized. We analyze mutual information and
outage probability of the secondary transmission in a CR system with difference
antenna selection, and propose a method of optimizing these performance metrics
of the secondary data link subject to practical constraints on the peak
secondary transmit power and the average interference power as seen by the
primary receiver. The optimization is performed over two parameters: the peak
secondary transmit power and the difference selection weight $\delta\in [0,
1]$. We show that, difference selection using the optimized parameters
determined by the proposed method can be, in many cases of interest, superior
to a so called ratio selection method disclosed in the literature, although
ratio selection has been shown to be optimal, when impractically, the secondary
transmission power constraint is not applied. We address the effects that the
constraints have on mutual information and outage probability, and discuss the
practical implications of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0201</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0201</id><created>2010-10-01</created><updated>2010-10-27</updated><authors><author><keyname>Bulatov</keyname><forenames>Andrei A.</forenames><affiliation>Simon Fraser University</affiliation></author><author><keyname>Marx</keyname><forenames>Daniel</forenames><affiliation>Tel Aviv University</affiliation></author></authors><title>The complexity of global cardinality constraints</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.2.2, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (October
  27, 2010) lmcs:1025</journal-ref><doi>10.2168/LMCS-6(4:4)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a constraint satisfaction problem (CSP) the goal is to find an assignment
of a given set of variables subject to specified constraints. A global
cardinality constraint is an additional requirement that prescribes how many
variables must be assigned a certain value. We study the complexity of the
problem CCSP(G), the constraint satisfaction problem with global cardinality
constraints that allows only relations from the set G. The main result of this
paper characterizes sets G that give rise to problems solvable in polynomial
time, and states that the remaining such problems are NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0219</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0219</id><created>2010-10-01</created><authors><author><keyname>Labarre</keyname><forenames>Anthony</forenames></author><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author></authors><title>Polynomial-time sortable stacks of burnt pancakes</title><categories>cs.DS math.CO</categories><comments>Accepted pending minor revision</comments><journal-ref>Theor. Comput. Sci. 412(8-10): 695-702 (2011)</journal-ref><doi>10.1016/j.tcs.2010.11.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pancake flipping, a famous open problem in computer science, can be
formalised as the problem of sorting a permutation of positive integers using
as few prefix reversals as possible. In that context, a prefix reversal of
length k reverses the order of the first k elements of the permutation. The
burnt variant of pancake flipping involves permutations of signed integers, and
reversals in that case not only reverse the order of elements but also invert
their signs. Although three decades have now passed since the first works on
these problems, neither their computational complexity nor the maximal number
of prefix reversals needed to sort a permutation is yet known. In this work, we
prove a new lower bound for sorting burnt pancakes, and show that an important
class of permutations, known as &quot;simple permutations&quot;, can be optimally sorted
in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0225</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0225</id><created>2010-10-01</created><updated>2011-03-14</updated><authors><author><keyname>Witzel</keyname><forenames>Andreas</forenames></author></authors><title>Characterizing perfect recall using next-step temporal operators in S5
  and sub-S5 Epistemic Temporal Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the notion of perfect recall in the literature on interpreted
systems, game theory, and epistemic logic. In the context of Epistemic Temporal
Logic (ETL), we give a (to our knowledge) novel frame condition for perfect
recall, which is local and can straightforwardly be translated to a defining
formula in a language that only has next-step temporal operators. This frame
condition also gives rise to a complete axiomatization for S5 ETL frames with
perfect recall. We then consider how to extend and consolidate the notion of
perfect recall in sub-S5 settings, where the various notions discussed are no
longer equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0226</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0226</id><created>2010-10-01</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Rajagopalan</keyname><forenames>S. Raj</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>An Information-theoretic Approach to Privacy</title><categories>cs.IT math.IT</categories><comments>in Proc. 48th Annual Allerton Conf. on Commun., Control, and
  Computing, Monticello, IL, Sep 29-Oct 1, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring the usefulness of electronic data sources while providing necessary
privacy guarantees is an important unsolved problem. This problem drives the
need for an overarching analytical framework that can quantify the safety of
personally identifiable information (privacy) while still providing a
quantifable benefit (utility) to multiple legitimate information consumers.
State of the art approaches have predominantly focused on privacy. This paper
presents the first information-theoretic approach that promises an analytical
model guaranteeing tight bounds of how much utility is possible for a given
level of privacy and vice-versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0237</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0237</id><created>2010-10-01</created><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Hogg</keyname><forenames>Tad</forenames></author></authors><title>Using Stochastic Models to Describe and Predict Social Dynamics of Web
  Users</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>Submitted to ACM TIST Special Issue on Computational Models of
  Collective Intelligence in the Social Web</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popularity of content in social media is unequally distributed, with some
items receiving a disproportionate share of attention from users. Predicting
which newly-submitted items will become popular is critically important for
both hosts of social media content and its consumers. Accurate and timely
prediction would enable hosts to maximize revenue through differential pricing
for access to content or ad placement. Prediction would also give consumers an
important tool for filtering the ever-growing amount of content. Predicting
popularity of content in social media, however, is challenging due to the
complex interactions between content quality and how the social media site
chooses to highlight content. Moreover, most social media sites also
selectively present content that has been highly rated by similar users, whose
similarity is indicated implicitly by their behavior or explicitly by links in
a social network. While these factors make it difficult to predict popularity
\emph{a priori}, we show that stochastic models of user behavior on these sites
allows predicting popularity based on early user reactions to new content. By
incorporating the various mechanisms through which web sites display content,
such models improve on predictions based on simply extrapolating from the early
votes. Using data from one such site, the news aggregator Digg, we show how a
stochastic model of user behavior distinguishes the effect of the increased
visibility due to the network from how interested users are in the content. We
find a wide range of interest, identifying stories primarily of interest to
users in the network (``niche interests'') from those of more general interest
to the user community. This distinction is useful for predicting a story's
eventual popularity from users' early reactions to the story.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0278</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0278</id><created>2010-10-01</created><updated>2010-11-17</updated><authors><author><keyname>Arnold</keyname><forenames>Douglas N.</forenames></author><author><keyname>Fowler</keyname><forenames>Kristine K.</forenames></author></authors><title>Nefarious Numbers</title><categories>math.HO cs.DL</categories><comments>5 pages, 1 figure</comments><journal-ref>Notices Amer. Math. Soc., 58(3):434-437, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the journal impact factor, focusing on the applied mathematics
category. We discuss impact factor manipulation and demonstrate that the impact
factor gives an inaccurate view of journal quality, which is poorly correlated
with expert opinion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0280</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0280</id><created>2010-10-01</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiande</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author></authors><title>Infinite Families of Optimal Splitting Authentication Codes Secure
  Against Spoofing Attacks of Higher Order</title><categories>cs.CR cs.DM cs.IT math.CO math.IT</categories><comments>to appear in Advances in Mathematics of Communications (accepted
  September 2010)</comments><msc-class>05B30, 94A60, 94C30, 11T22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of constructing optimal authentication codes with
splitting. New infinite families of such codes are obtained. In particular, we
establish the first known infinite family of optimal authentication codes with
splitting that are secure against spoofing attacks of order two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0287</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0287</id><created>2010-10-01</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Cui</keyname><forenames>Ying</forenames></author></authors><title>Queue-Aware Distributive Resource Control for Delay-Sensitive Two-Hop
  MIMO Cooperative Systems</title><categories>cs.LG</categories><comments>30 pages, 7 figures</comments><msc-class>MIMO, relay, queue-aware, distributive resource control</msc-class><doi>10.1109/TSP.2010.2086449</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a queue-aware distributive resource control
algorithm for two-hop MIMO cooperative systems. We shall illustrate that relay
buffering is an effective way to reduce the intrinsic half-duplex penalty in
cooperative systems. The complex interactions of the queues at the source node
and the relays are modeled as an average-cost infinite horizon Markov Decision
Process (MDP). The traditional approach solving this MDP problem involves
centralized control with huge complexity. To obtain a distributive and low
complexity solution, we introduce a linear structure which approximates the
value function of the associated Bellman equation by the sum of per-node value
functions. We derive a distributive two-stage two-winner auction-based control
policy which is a function of the local CSI and local QSI only. Furthermore, to
estimate the best fit approximation parameter, we propose a distributive online
stochastic learning algorithm using stochastic approximation theory. Finally,
we establish technical conditions for almost-sure convergence and show that
under heavy traffic, the proposed low complexity distributive control is global
optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0298</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0298</id><created>2010-10-02</created><authors><author><keyname>Abraham</keyname><forenames>Siby</forenames></author><author><keyname>Kiss</keyname><forenames>Imre</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author><author><keyname>Sanglikar</keyname><forenames>Mukund</forenames></author></authors><title>Steepest Ascent Hill Climbing For A Mathematical Problem</title><categories>cs.AI</categories><comments>8 Pages, 3 Figures, 2 Tables, International Symposium on Advanced
  Engineering and Applied Management 40th Anniversary in Higher Education -
  Informatics &amp; Computer Science, University Politehnica, Timisoara, 4-5
  November, 2010, Hunedoara, ROMANIA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes artificial intelligence technique called hill climbing to
find numerical solutions of Diophantine Equations. Such equations are important
as they have many applications in fields like public key cryptography, integer
factorization, algebraic curves, projective curves and data dependency in super
computers. Importantly, it has been proved that there is no general method to
find solutions of such equations. This paper is an attempt to find numerical
solutions of Diophantine equations using steepest ascent version of Hill
Climbing. The method, which uses tree representation to depict possible
solutions of Diophantine equations, adopts a novel methodology to generate
successors. The heuristic function used help to make the process of finding
solution as a minimization process. The work illustrates the effectiveness of
the proposed methodology using a class of Diophantine equations given by a1. x1
p1 + a2. x2 p2 + ...... + an . xn pn = N where ai and N are integers. The
experimental results validate that the procedure proposed is successful in
finding solutions of Diophantine Equations with sufficiently large powers and
large number of variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0301</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0301</id><created>2010-10-02</created><authors><author><keyname>Kundu</keyname><forenames>Anjan Kumar</forenames></author><author><keyname>Bandopadhyay</keyname><forenames>Bijoy</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>A Microwave Imaging and Enhancement Technique from Noisy Synthetic Data</title><categories>cs.CV cs.NA</categories><comments>8 Pages, 10 Figures, International Symposium on Advanced Engineering
  and Applied Management-40th Anniversary in Higher Education-Image
  Processing-University Politegnica, Timisoara, 4-5 November, 2010, Hunedoara,
  ROMANIA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An inverse iterative algorithm for microwave imaging based on moment method
solution is presented here. The iterative scheme has been developed on
constrained optimization technique and is certain to converge. Different mesh
size for the model has been used here to overcome the Inverse Crime. The
synthetic data at the receivers is contaminated with different percentage of
noise. The ill-posedness of the problem is solved by Levenberg-Marquardt
method. The algorithm is applied to synthetic data and the reconstructed image
is then further enhanced through the Image enhancement technique
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0302</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0302</id><created>2010-10-02</created><updated>2010-11-04</updated><authors><author><keyname>Barthelemy</keyname><forenames>Marc</forenames></author></authors><title>Spatial Networks</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.SI physics.soc-ph q-bio.NC</categories><comments>Review article, revised and augmented version, 86 pages, 86 figures,
  338 references</comments><journal-ref>Physics Reports 499:1-101 (2011)</journal-ref><doi>10.1016/j.physrep.2010.11.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex systems are very often organized under the form of networks where
nodes and edges are embedded in space. Transportation and mobility networks,
Internet, mobile phone networks, power grids, social and contact networks,
neural networks, are all examples where space is relevant and where topology
alone does not contain all the information. Characterizing and understanding
the structure and the evolution of spatial networks is thus crucial for many
different fields ranging from urbanism to epidemiology. An important
consequence of space on networks is that there is a cost associated to the
length of edges which in turn has dramatic effects on the topological structure
of these networks. We will expose thoroughly the current state of our
understanding of how the spatial constraints affect the structure and
properties of these networks. We will review the most recent empirical
observations and the most important models of spatial networks. We will also
discuss various processes which take place on these spatial networks, such as
phase transitions, random walks, synchronization, navigation, resilience, and
disease spread.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0316</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0316</id><created>2010-10-02</created><updated>2010-10-06</updated><authors><author><keyname>Abhinav</keyname><forenames>G.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Two-User Gaussian Interference Channel with Finite Constellation Input
  and FDMA</title><categories>cs.IT math.IT</categories><comments>12 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the two-user Gaussian Strong Interference Channel (GSIC) with finite
constellation inputs, it is known that relative rotation between the
constellations of the two users enlarges the Constellation Constrained (CC)
capacity region. In this paper, a metric for finding the approximate angle of
rotation (with negligibly small error) to maximally enlarge the CC capacity for
the two-user GSIC is presented. In the case of Gaussian input alphabets with
equal powers for both the users and the modulus of both the cross-channel gains
being equal to unity, it is known that the FDMA rate curve touches the capacity
curve of the GSIC. It is shown that, with unequal powers for both the users
also, when the modulus of one of the cross-channel gains being equal to one and
the modulus of the other cross-channel gain being greater than or equal to one,
the FDMA rate curve touches the capacity curve of the GSIC. On the contrary, it
is shown that, under finite constellation inputs, with both the users using the
same constellation, the FDMA rate curve strictly lies within (never touches)
the enlarged CC capacity region throughout the strong-interference regime. This
means that using FDMA it is impossible to go close to the CC capacity. It is
well known that for the Gaussian input alphabets, the FDMA inner-bound, at the
optimum sum-rate point, is always better than the simultaneous-decoding
inner-bound throughout the weak-interference regime. For a portion of the weak
interference regime, it is shown that with identical finite constellation
inputs for both the users, the simultaneous-decoding inner-bound, enlarged by
relative rotation between the constellations, is strictly better than the FDMA
inner-bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0325</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0325</id><created>2010-10-02</created><updated>2010-10-21</updated><authors><author><keyname>Kamruzzaman</keyname><forenames>S. M.</forenames></author><author><keyname>Jeong</keyname><forenames>Dong Geun</forenames></author></authors><title>Routing Protocols for Cognitive Radio Networks: A Survey</title><categories>cs.NI</categories><comments>This article has been withdrawn by arXiv administrators because it
  plagiarises http://www2.ece.ohio-state.edu/~ekici/papers/crnroutingsurvey.pdf</comments><journal-ref>Journal of Information Industrial Engineering, Vol. 16, pp.
  153-169, Aug. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article has been withdrawn by arXiv administrators because it
plagiarises http://www2.ece.ohio-state.edu/~ekici/papers/crnroutingsurvey.pdf
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0333</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0333</id><created>2010-10-02</created><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Effects of Single-Cycle Structure on Iterative Decoding for Low-Density
  Parity-Check Codes</title><categories>cs.IT math.IT</categories><comments>16 pages, 7 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider communication over the binary erasure channel (BEC) using
low-density parity-check (LDPC) codes and belief propagation (BP) decoding. For
fixed numbers of BP iterations, the bit error probability approaches a limit as
blocklength tends to infinity, and the limit is obtained via density evolution.
On the other hand, the difference between the bit error probability of codes
with blocklength $n$ and that in the large blocklength limit is asymptotically
$\alpha(\epsilon,t)/n + \Theta(n^{-2})$ where $\alpha(\epsilon,t)$ denotes a
specific constant determined by the code ensemble considered, the number $t$ of
iterations, and the erasure probability $\epsilon$ of the BEC. In this paper,
we derive a set of recursive formulas which allows evaluation of the constant
$\alpha(\epsilon,t)$ for standard irregular ensembles. The dominant difference
$\alpha(\epsilon,t)/n$ can be considered as effects of cycle-free and
single-cycle structures of local graphs. Furthermore, it is confirmed via
numerical simulations that estimation of the bit error probability using
$\alpha(\epsilon,t)$ is accurate even for small blocklengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0344</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0344</id><created>2010-10-02</created><authors><author><keyname>Liu</keyname><forenames>Xi</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>Alternating-Offer Bargaining Games over the Gaussian Interference
  Channel</title><categories>cs.IT cs.GT math.IT</categories><comments>8 pages, 6 figures, to appear in Proceedings of Forty-Eighth Annual
  Allerton Conference on Communication, Control, and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper tackles the problem of how two selfish users jointly determine the
operating point in the achievable rate region of a two-user Gaussian
interference channel through bargaining. In previous work, incentive conditions
for two users to cooperate using a simple version of Han-Kobayashi scheme was
studied and the Nash bargaining solution (NBS) was used to obtain a fair
operating point. Here a noncooperative bargaining game of alternating offers is
adopted to model the bargaining process and rates resulting from the
equilibrium outcome are analyzed. In particular, it is shown that the operating
point resulting from the formulated bargaining game depends on the cost of
delay in bargaining and how bargaining proceeds. If the associated bargaining
problem is regular, a unique perfect equilibrium exists and lies on the
individual rational efficient frontier of the achievable rate region. Besides,
the equilibrium outcome approaches the NBS if the bargaining costs of both
users are negligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0371</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0371</id><created>2010-10-02</created><updated>2010-10-05</updated><authors><author><keyname>Milan&#xe9;s</keyname><forenames>Anolan</forenames></author><author><keyname>Rodriguez</keyname><forenames>Noemi</forenames></author><author><keyname>Ierusalimschy</keyname><forenames>Roberto</forenames></author></authors><title>Reflection-based language support for the heterogeneous capture and
  restoration of running computations</title><categories>cs.PL cs.DC</categories><comments>26 pages, 3 figures. Submitted to Computer Languages, Systems &amp;
  Structures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is devoted to the study of the problem of user-level capture and
restoration of running computations in heterogeneous environments. Support for
those operations has traditionally been offered through ready-made solutions
for specific applications, which are difficult to tailor or adapt to different
needs. We believe that a more promising approach would be to build specific
solutions as needed, over a more general framework for capture and restoration.
In this work, in order to explore the basic mechanisms a language should
provide to support the implementation of different policies, we extend the Lua
programming language with an API that allows the programmer to reify the
internal structures of execution into fine-grained language values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0376</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0376</id><created>2010-10-02</created><authors><author><keyname>Shen</keyname><forenames>Charles</forenames></author><author><keyname>Schulzrinne</keyname><forenames>Henning</forenames></author></authors><title>On TCP-based Session Initiation Protocol (SIP) Server Overload Control</title><categories>cs.NI</categories><comments>IPTComm 2010</comments><acm-class>C.2.2; C.2.3; C.2.1; D.4.8; K.6.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Session Initiation Protocol (SIP) server overload management has
attracted interest since SIP is being widely deployed in the Next Generation
Networks (NGN) as a core signaling protocol. Yet all existing SIP overload
control work is focused on SIP-over-UDP, despite the fact that TCP is
increasingly seen as the more viable choice of SIP transport. This paper
answers the following questions: is the existing TCP flow control capable of
handling the SIP overload problem? If not, why and how can we make it work? We
provide a comprehensive explanation of the default SIP-over-TCP overload
behavior through server instrumentation. We also propose and implement novel
but simple overload control algorithms without any kernel or protocol level
modification. Experimental evaluation shows that with our mechanism the
overload performance improves from its original zero throughput to nearly full
capacity. Our work leads to the important general insight that the traditional
notion of TCP flow control alone is incapable of managing overload for
time-critical session-based applications, which would be applicable not only to
SIP, but also to a wide range of other common applications such as database
servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0401</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0401</id><created>2010-10-03</created><authors><author><keyname>Srinivasagopalan</keyname><forenames>Srivathsan</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author><author><keyname>Iyengar</keyname><forenames>S. S.</forenames></author></authors><title>Oblivious Buy-at-Bulk in Planar Graphs</title><categories>cs.DS</categories><comments>13 Pages (includes 1 page of appendix). Submitted to WALCOM-2011 -
  Workshop on Algorithms and Computation</comments><acm-class>F.2; E.1; G.1.2; C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the oblivious buy-at-bulk network design problem in a graph, the task is
to compute a fixed set of paths for every pair of source-destinations in the
graph, such that any set of demands can be routed along these paths. The
demands could be aggregated at intermediate edges where the fusion-cost is
specified by a canonical (non-negative concave) function $f$. We give a novel
algorithm for planar graphs which is oblivious with respect to the demands, and
is also oblivious with respect to the fusion function $f$. The algorithm is
deterministic and computes the fixed set of paths in polynomial time, and
guarantees a $O(\log n)$ approximation ratio for any set of demands and any
canonical fusion function $f$, where $n$ is the number of nodes. The algorithm
is asymptotically optimal, since it is known that this problem cannot be
approximated with better than $\Omega(\log n)$ ratio. To our knowledge, this is
the first tight analysis for planar graphs, and improves the approximation
ratio by a factor of $\log n$ with respect to previously known results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0406</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0406</id><created>2010-10-03</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Jozeph</keyname><forenames>Shlomo</forenames></author></authors><title>Oblivious Algorithms for the Maximum Directed Cut Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a special family of randomized algorithms for Max DICUT
that we call oblivious algorithms. Let the bias of a vertex be the ratio
between the total weight of its outgoing edges and the total weight of all its
edges. An oblivious algorithm selects at random in which side of the cut to
place a vertex v, with probability that only depends on the bias of v,
independently of other vertices. The reader may observe that the algorithm that
ignores the bias and chooses each side with probability 1/2 has an
approximation ratio of 1/4, whereas no oblivious algorithm can have an
approximation ratio better than 1/2 (with an even directed cycle serving as a
negative example). We attempt to characterize the best approximation ratio
achievable by oblivious algorithms, and present results that are nearly tight.
The paper also discusses natural extensions of the notion of oblivious
algorithms, and extensions to the more general problem of Max 2-AND.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0410</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0410</id><created>2010-10-03</created><authors><author><keyname>He</keyname><forenames>Jiankui</forenames></author><author><keyname>Deem</keyname><forenames>Michael W.</forenames></author></authors><title>Structure and Response in the World Trade Network</title><categories>q-fin.GN cs.SI physics.soc-ph</categories><comments>4 pages, 4 figures, to appear in Phys. Rev. Lett</comments><doi>10.1103/PhysRevLett.105.198701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine how the structure of the world trade network has been shaped by
globalization and recessions over the last 40 years. We show that by treating
the world trade network as an evolving system, theory predicts the trade
network is more sensitive to evolutionary shocks and recovers more slowly from
them now than it did 40 years ago, due to structural changes in the world trade
network induced by globalization. We also show that recession-induced change to
the world trade network leads to an \emph{increased} hierarchical structure of
the global trade network for a few years after the recession.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0412</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0412</id><created>2010-10-03</created><updated>2011-09-26</updated><authors><author><keyname>Taneja</keyname><forenames>Inder Jeet</forenames></author></authors><title>Sequences of Inequalities Among New Divergence Measures</title><categories>cs.IT math.IT</categories><msc-class>94A17, 62B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are three classical divergence measures exist in the literature on
information theory and statistics. These are namely, Jeffryes-Kullback-Leiber
J-divergence. Sibson-Burbea-Rao Jensen-Shannon divegernce and Taneja
arithemtic-geometric mean divergence. These three measures bear an interesting
relationship among each other and are based on logarithmic expressions. The
divergence measures like Hellinger discrimination, symmetric chi-square
divergence, and triangular discrimination are also known in the literature and
are not based on logarithmic expressions. Past years Dragomir et al., Kumar and
Johnson and Jain and Srivastava studied different kind of divergence measures.
In this paper, we have presented some more new divergence measures and obtained
inequalities relating these new measures and also made connections with
previous ones. The idea of exponential divergence is also introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0417</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0417</id><created>2010-10-03</created><authors><author><keyname>Su</keyname><forenames>Yu</forenames></author><author><keyname>Dunham</keyname><forenames>Margaret H.</forenames></author></authors><title>Visual-hint Boundary to Segment Algorithm for Image Segmentation</title><categories>cs.CV</categories><comments>45 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Image segmentation has been a very active research topic in image analysis
area. Currently, most of the image segmentation algorithms are designed based
on the idea that images are partitioned into a set of regions preserving
homogeneous intra-regions and inhomogeneous inter-regions. However, human
visual intuition does not always follow this pattern. A new image segmentation
method named Visual-Hint Boundary to Segment (VHBS) is introduced, which is
more consistent with human perceptions. VHBS abides by two visual hint rules
based on human perceptions: (i) the global scale boundaries tend to be the real
boundaries of the objects; (ii) two adjacent regions with quite different
colors or textures tend to result in the real boundaries between them. It has
been demonstrated by experiments that, compared with traditional image
segmentation method, VHBS has better performance and also preserves higher
computational efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0418</identifier>
 <datestamp>2012-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0418</id><created>2010-10-03</created><updated>2012-12-10</updated><authors><author><keyname>Ahlswede</keyname><forenames>Rudolf</forenames></author><author><keyname>Bjelakovic</keyname><forenames>Igor</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author><author><keyname>Noetzel</keyname><forenames>Janis</forenames></author></authors><title>Quantum capacity under adversarial quantum noise: arbitrarily varying
  quantum channels</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>49 pages, no figures, final version of our papers arXiv:1010.0418v2
  and arXiv:1010.0418. Published &quot;Online First&quot; in Communications in
  Mathematical Physics, 2012</comments><report-no>Mittag-Leffler-2010fall</report-no><doi>10.1007/s00220-012-1613-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate entanglement transmission over an unknown channel in the
presence of a third party (called the adversary), which is enabled to choose
the channel from a given set of memoryless but non-stationary channels without
informing the legitimate sender and receiver about the particular choice that
he made. This channel model is called arbitrarily varying quantum channel
(AVQC). We derive a quantum version of Ahlswede's dichotomy for classical
arbitrarily varying channels. This includes a regularized formula for the
common randomness-assisted capacity for entanglement transmission of an AVQC.
Quite surprisingly and in contrast to the classical analog of the problem
involving the maximal and average error probability, we find that the capacity
for entanglement transmission of an AVQC always equals its strong subspace
transmission capacity. These results are accompanied by different notions of
symmetrizability (zero-capacity conditions) as well as by conditions for an
AVQC to have a capacity described by a single-letter formula. In he final part
of the paper the capacity of the erasure-AVQC is computed and some light shed
on the connection between AVQCs and zero-error capacities. Additionally, we
show by entirely elementary and operational arguments motivated by the theory
of AVQCs that the quantum, classical, and entanglement-assisted zero-error
capacities of quantum channels are generically zero and are discontinuous at
every positivity point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0422</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0422</id><created>2010-10-03</created><authors><author><keyname>Szlam</keyname><forenames>Arthur</forenames></author><author><keyname>Kavukcuoglu</keyname><forenames>Koray</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Convolutional Matching Pursuit and Dictionary Training</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Matching pursuit and K-SVD is demonstrated in the translation invariant
setting
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0424</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0424</id><created>2010-10-03</created><authors><author><keyname>Fisher</keyname><forenames>Edgar</forenames></author><author><keyname>Sieben</keyname><forenames>Nandor</forenames></author></authors><title>Rectangular Polyomino Set Weak (1,2)-achievement Games</title><categories>math.CO cs.DM cs.GT</categories><msc-class>05B50, 91A46</msc-class><journal-ref>Theoretical Computer Science 409 (2008), no.3, 333--340</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a polyomino set (1,2)-achievement game the maker and the breaker
alternately mark one and two previously unmarked cells respectively. The
maker's goal is to mark a set of cells congruent to one of a given set of
polyominoes. The breaker tries to prevent the maker from achieving his goal.
The teams of polyominoes for which the maker has a winning strategy is
determined up to size 4. In set achievement games, it is natural to study
infinitely large polyominoes. This enables the construction of super winners
that characterize all winning teams up to a certain size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0430</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0430</id><created>2010-10-03</created><authors><author><keyname>Javad</keyname><forenames>Sayadi Mohammad</forenames></author><author><keyname>Mahmood</keyname><forenames>Fathy</forenames></author></authors><title>A New Approach in Packet Scheduling in the Vanet</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Vehicular Ad hoc Networks (VANET) are expected to have great potential to
improve both traffic safety and comfort in the future. When many vehicles want
to access data through roadside unit, data scheduling become an important
issue. In this paper, we identify some challenges in roadside based data
access. To address these challenges we first review some existing scheduling
schemes. We then propose a priority scheduling and finally show that using this
idea can increase QOS compare to previous algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0431</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0431</id><created>2010-10-03</created><updated>2011-04-10</updated><authors><author><keyname>Rosvall</keyname><forenames>M.</forenames></author><author><keyname>Bergstrom</keyname><forenames>C. T.</forenames></author></authors><title>Multilevel compression of random walks on networks reveals hierarchical
  organization in large integrated systems</title><categories>physics.soc-ph cs.SI physics.comp-ph</categories><comments>11 pages, 5 figures. For associated code, see
  http://www.tp.umu.se/~rosvall/code.html</comments><journal-ref>PLoS ONE 6(4): e18209 (2011)</journal-ref><doi>10.1371/journal.pone.0018209</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To comprehend the hierarchical organization of large integrated systems, we
introduce the hierarchical map equation, which reveals multilevel structures in
networks. In this information-theoretic approach, we exploit the duality
between compression and pattern detection; by compressing a description of a
random walker as a proxy for real flow on a network, we find regularities in
the network that induce this system-wide flow. Finding the shortest multilevel
description of the random walker therefore gives us the best hierarchical
clustering of the network, the optimal number of levels and modular partition
at each level, with respect to the dynamics on the network. With a novel search
algorithm, we extract and illustrate the rich multilevel organization of
several large social and biological networks. For example, from the global air
traffic network we uncover countries and continents, and from the pattern of
scientific communication we reveal more than 100 scientific fields organized in
four major disciplines: life sciences, physical sciences, ecology and earth
sciences, and social sciences. In general, we find shallow hierarchical
structures in globally interconnected systems, such as neural networks, and
rich multilevel organizations in systems with highly separated regions, such as
road networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0433</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0433</id><created>2010-10-03</created><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author></authors><title>Derandomization and Group Testing</title><categories>cs.IT math.IT</categories><comments>Invited Paper in Proceedings of 48th Annual Allerton Conference on
  Communication, Control, and Computing, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of derandomization theory, which is a fundamental area
in theoretical computer science, has recently led to many surprising
applications outside its initial intention. We will review some recent such
developments related to combinatorial group testing. In its most basic setting,
the aim of group testing is to identify a set of &quot;positive&quot; individuals in a
population of items by taking groups of items and asking whether there is a
positive in each group.
  In particular, we will discuss explicit constructions of optimal or
nearly-optimal group testing schemes using &quot;randomness-conducting&quot; functions.
Among such developments are constructions of error-correcting group testing
schemes using randomness extractors and condensers, as well as threshold group
testing schemes from lossless condensers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0454</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0454</id><created>2010-10-03</created><updated>2013-05-28</updated><authors><author><keyname>Dhillon</keyname><forenames>Vikram</forenames></author></authors><title>Nations At War I: Why do we keep building weapons?</title><categories>cs.OH</categories><comments>This paper has been withdrawn by the authors because of improper
  submission and some critical errors in the manuscript</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper is the first in series of four papers that present an analytical
approach to war using game theory. We try to explore why is it that &quot;true
peace&quot; can't be achieved and all or any efforts we make towards that goal will
have huge road-blocks. A fairly simplistic and non technical overview of our
approach is given in this paper using prisoner's dilemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0471</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0471</id><created>2010-10-04</created><authors><author><keyname>Lakshmi</keyname><forenames>B.</forenames></author><author><keyname>Srinivasan</keyname><forenames>R.</forenames></author></authors><title>Statistical Modelling of ft to Process Parameters in 30 nm Gate Length
  Finfets</title><categories>cs.OH</categories><comments>12 pages</comments><journal-ref>International Journal of VLSI Design &amp; Communication
  Systems(VLSICS) Vol.1, No.3, September 2010</journal-ref><doi>10.5121/vlsi.2010.1304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the effect of process variations on unity gain
frequency (ft) in 30 nm gate length FinFET by performing extensive TCAD
simulations. Six different geometrical parameters, channel doping, source/drain
doping and gate electrode work function are studied for their sensitivity on
ft. It is found that ft is more sensitive to gate length, underlap, gate-oxide
thickness, channel and Source/Drain doping and less sensitive to source/drain
width and length, and work function variations. Statistical modelling has been
performed for ft through design of experiment with respect to sensitive
parameters. The model has been validated through a comparison between random
set of experimental data simulations and predicted values obtained from the
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0476</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0476</id><created>2010-10-04</created><updated>2011-03-16</updated><authors><author><keyname>Papailiopoulos</keyname><forenames>Dimitris S.</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author></authors><title>Interference Alignment as a Rank Constrained Rank Minimization</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>27 pages, single column, 7 figures, TSP submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the maximization of the sum degrees-of-freedom for the static
flat-fading multiple-input multiple-output (MIMO) interference channel is
equivalent to a rank constrained rank minimization problem (RCRM), when the
signal spaces span all available dimensions. The rank minimization corresponds
to maximizing interference alignment (IA) so that interference spans the lowest
dimensional subspace possible. The rank constraints account for the useful
signal spaces spanning all available spatial dimensions. That way, we
reformulate all IA requirements to requirements involving ranks. Then, we
present a convex relaxation of the RCRM problem inspired by recent results in
compressed sensing and low-rank matrix completion theory that rely on
approximating rank with the nuclear norm. We show that the convex envelope of
the sum of ranks of the interference matrices is the normalized sum of their
corresponding nuclear norms and introduce tractable constraints that are
asymptotically equivalent to the rank constraints for the initial problem. We
also show that our heuristic relaxation can be tuned for the multi-cell
interference channel. Furthermore, we experimentally show that in many cases
the proposed algorithm attains perfect interference alignment and in some cases
outperforms previous approaches for finding precoding and zero-forcing matrices
for interference alignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0485</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0485</id><created>2010-10-04</created><authors><author><keyname>Papailiopoulos</keyname><forenames>Dimitris S.</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author></authors><title>Distributed Storage Codes Meet Multiple-Access Wiretap Channels</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>10 pages, allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider {\it i)} the overhead minimization of maximum-distance separable
(MDS) storage codes for the repair of a single failed node and {\it ii)} the
total secure degrees-of-freedom (S-DoF) maximization in a multiple-access
compound wiretap channel. We show that the two problems are connected.
Specifically, the overhead minimization for a single node failure of an {\it
optimal} MDS code, i.e. one that can achieve the information theoretic overhead
minimum, is equivalent to maximizing the S-DoF in a multiple-access compound
wiretap channel. Additionally, we show that maximizing the S-DoF in a
multiple-access compound wiretap channel is equivalent to minimizing the
overhead of an MDS code for the repair of a departed node. An optimal MDS code
maps to a full S-DoF channel and a full S-DoF channel maps to an MDS code with
minimum repair overhead for one failed node. We also state a general framework
for code-to-channel and channel-to-code mappings and performance bounds between
the two settings. The underlying theme for all connections presented is
interference alignment (IA). The connections between the two problems become
apparent when we restate IA as an optimization problem. Specifically, we
formulate the overhead minimization and the S-DoF maximization as rank
constrained, sum-rank and max-rank minimization problems respectively. The
derived connections allow us to map repair strategies of recently discovered
repair codes to beamforming matrices and characterize the maximum S-DoF for the
single antenna multiple-access compound wiretap channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0506</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0506</id><created>2010-10-04</created><authors><author><keyname>Dallmeier-Tiessen</keyname><forenames>Suenje</forenames></author><author><keyname>Darby</keyname><forenames>Robert</forenames></author><author><keyname>Goerner</keyname><forenames>Bettina</forenames></author><author><keyname>Hyppoelae</keyname><forenames>Jenni</forenames></author><author><keyname>Igo-Kemenes</keyname><forenames>Peter</forenames></author><author><keyname>Kahn</keyname><forenames>Deborah</forenames></author><author><keyname>Lambert</keyname><forenames>Simon</forenames></author><author><keyname>Lengenfelder</keyname><forenames>Anja</forenames></author><author><keyname>Leonard</keyname><forenames>Chris</forenames></author><author><keyname>Mele</keyname><forenames>Salvatore</forenames></author><author><keyname>Polydoratou</keyname><forenames>Panayiota</forenames></author><author><keyname>Ross</keyname><forenames>David</forenames></author><author><keyname>Ruiz-Perez</keyname><forenames>Sergio</forenames></author><author><keyname>Schimmer</keyname><forenames>Ralf</forenames></author><author><keyname>Swaisland</keyname><forenames>Mark</forenames></author><author><keyname>van der Stelt</keyname><forenames>Wim</forenames></author></authors><title>First results of the SOAP project. Open access publishing in 2010</title><categories>cs.DL</categories><comments>Submitted to PLoS ONE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The SOAP (Study of Open Access Publishing) project has compiled data on the
present offer for open access publishing in online peer-reviewed journals.
Starting from the Directory of Open Access Journals, several sources of data
are considered, including inspection of journal web site and direct inquiries
within the publishing industry. Several results are derived and discussed,
together with their correlations: the number of open access journals and
articles; their subject area; the starting date of open access journals; the
size and business models of open access publishers; the licensing models; the
presence of an impact factor; the uptake of hybrid open access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0522</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0522</id><created>2010-10-04</created><updated>2010-10-14</updated><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author></authors><title>Strong direct product conjecture holds for all relations in public coin
  randomized one-way communication complexity</title><categories>cs.CC cs.IT math.IT</categories><comments>ver 2. 11 pages, proofs simplified</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let f subset of X x Y x Z be a relation. Let the public coin one-way
communication complexity of f, with worst case error 1/3, be denoted
R^{1,pub}_{1/3}(f). We show that if for computing f^k (k independent copies of
f), o(k R^{1,pub}_{1/3}(f)) communication is provided, then the success is
exponentially small in k. This settles the strong direct product conjecture for
all relations in public coin one-way communication complexity.
  We show a new tight characterization of public coin one-way communication
complexity which strengthens on the tight characterization shown in [J.,
Klauck, Nayak 08]. We use the new characterization to show our direct product
result and this may also be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0552</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0552</id><created>2010-10-04</created><updated>2011-07-16</updated><authors><author><keyname>Sinha</keyname><forenames>Shriprakash</forenames></author><author><keyname>Nanetti</keyname><forenames>Luca</forenames></author></authors><title>Inaccessibility-Inside Theorem for Point in Polygon</title><categories>cs.CG cs.GR</categories><comments>23 pages, 22 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The manuscript presents a theoretical proof in conglomeration with new
definitions on Inaccessibility and Inside for a point S related to a simple or
self intersecting polygon P. The proposed analytical solution depicts a novel
way of solving the point in polygon problem by employing the properties of
epigraphs and hypographs, explicitly. Contrary to the ambiguous solutions given
by the cross over for the simple and self intersecting polygons and the
solution of a point being multiply inside a self intersecting polygon given by
the winding number rule, the current solution gives unambiguous and singular
result for both kinds of polygons. Finally, the current theoretical solution
proves to be mathematically correct for simple and self intersecting polygons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0558</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0558</id><created>2010-10-04</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author></authors><title>Analyzing Network Coding Gossip Made Easy</title><categories>cs.DC cs.DS cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new technique to analyze the stopping time of gossip protocols that
are based on random linear network coding (RLNC). Our analysis drastically
simplifies, extends and strengthens previous results. We analyze RLNC gossip in
a general framework for network and communication models that encompasses and
unifies the models used previously in this context. We show, in most settings
for the first time, that it converges with high probability in the
information-theoretically optimal time. Most stopping times are of the form O(k
+ T) where k is the number of messages to be distributed and T is the time it
takes to disseminate one message. This means RLNC gossip achieves &quot;perfect
pipelining&quot;. Our analysis directly extends to highly dynamic networks in which
the topology can change completely at any time. This remains true even if the
network dynamics are controlled by a fully adaptive adversary that knows the
complete network state. Virtually nothing besides simple O(kT) sequential
flooding protocols was previously known for such a setting. While RLNC gossip
works in this wide variety of networks its analysis remains the same and
extremely simple. This contrasts with more complex proofs that were put forward
to give less strong results for various special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0562</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0562</id><created>2010-10-04</created><authors><author><keyname>Abdi</keyname><forenames>Somayeh</forenames></author><author><keyname>Pedram</keyname><forenames>Hossein</forenames></author><author><keyname>Mohamadi</keyname><forenames>Somayeh</forenames></author></authors><title>The Impact of Data Replicatino on Job Scheduling Performance in
  Hierarchical data Grid</title><categories>cs.DC</categories><comments>11 pages, 7 figures</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks (GRAPH-HOC) Vol.2, No.3, September 2010</journal-ref><doi>10.5121/jgraphoc.2010.2302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In data-intensive applications data transfer is a primary cause of job
execution delay. Data access time depends on bandwidth. The major bottleneck to
supporting fast data access in Grids is the high latencies of Wide Area
Networks and Internet. Effective scheduling can reduce the amount of data
transferred across the internet by dispatching a job to where the needed data
are present. Another solution is to use a data replication mechanism. Objective
of dynamic replica strategies is reducing file access time which leads to
reducing job runtime. In this paper we develop a job scheduling policy and a
dynamic data replication strategy, called HRS (Hierarchical Replication
Strategy), to improve the data access efficiencies. We study our approach and
evaluate it through simulation. The results show that our algorithm has
improved 12% over the current strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0601</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0601</id><created>2010-10-04</created><authors><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author><author><keyname>Tucci</keyname><forenames>Gabriel H.</forenames></author><author><keyname>Simon</keyname><forenames>Steven H.</forenames></author></authors><title>A Random Matrix--Theoretic Approach to Handling Singular Covariance
  Estimates</title><categories>math.PR cs.IT math.IT math.ST physics.data-an stat.TH</categories><comments>Submitted to Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many practical situations we would like to estimate the covariance matrix
of a set of variables from an insufficient amount of data. More specifically,
if we have a set of $N$ independent, identically distributed measurements of an
$M$ dimensional random vector the maximum likelihood estimate is the sample
covariance matrix. Here we consider the case where $N&lt;M$ such that this
estimate is singular and therefore fundamentally bad. We present a radically
new approach to deal with this situation. Let $X$ be the $M\times N$ data
matrix, where the columns are the $N$ independent realizations of the random
vector with covariance matrix $\Sigma$. Without loss of generality, we can
assume that the random variables have zero mean. We would like to estimate
$\Sigma$ from $X$. Let $K$ be the classical sample covariance matrix. Fix a
parameter $1\leq L\leq N$ and consider an ensemble of $L\times M$ random
unitary matrices, $\{\Phi\}$, having Haar probability measure. Pre and post
multiply $K$ by $\Phi$, and by the conjugate transpose of $\Phi$ respectively,
to produce a non--singular $L\times L$ reduced dimension covariance estimate. A
new estimate for $\Sigma$, denoted by $\mathrm{cov}_L(K)$, is obtained by a)
projecting the reduced covariance estimate out (to $M\times M$) through pre and
post multiplication by the conjugate transpose of $\Phi$, and by $\Phi$
respectively, and b) taking the expectation over the unitary ensemble. Another
new estimate (this time for $\Sigma^{-1}$), $\mathrm{invcov}_L(K)$, is obtained
by a) inverting the reduced covariance estimate, b) projecting the inverse out
(to $M\times M$) through pre and post multiplication by the conjugate transpose
of $\Phi$, and by $\Phi$ respectively, and c) taking the expectation over the
unitary ensemble. We have a closed analytical expression for
$\mathrm{invcov}_L(K)$ and $\mathrm{cov}_L(K)$ in terms of its eigenvalue
decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0608</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0608</id><created>2010-10-04</created><updated>2011-02-12</updated><authors><author><keyname>Qiu</keyname><forenames>Chenlu</forenames></author><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Real-time Robust Principal Components' Pursuit</title><categories>cs.CV cs.IT math.IT</categories><comments>8 pages, 4 figures, Allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent work of Candes et al, the problem of recovering low rank matrix
corrupted by i.i.d. sparse outliers is studied and a very elegant solution,
principal component pursuit, is proposed. It is motivated as a tool for video
surveillance applications with the background image sequence forming the low
rank part and the moving objects/persons/abnormalities forming the sparse part.
Each image frame is treated as a column vector of the data matrix made up of a
low rank matrix and a sparse corruption matrix. Principal component pursuit
solves the problem under the assumptions that the singular vectors of the low
rank matrix are spread out and the sparsity pattern of the sparse matrix is
uniformly random. However, in practice, usually the sparsity pattern and the
signal values of the sparse part (moving persons/objects) change in a
correlated fashion over time, for e.g., the object moves slowly and/or with
roughly constant velocity. This will often result in a low rank sparse matrix.
  For video surveillance applications, it would be much more useful to have a
real-time solution. In this work, we study the online version of the above
problem and propose a solution that automatically handles correlated sparse
outliers. The key idea of this work is as follows. Given an initial estimate of
the principal directions of the low rank part, we causally keep estimating the
sparse part at each time by solving a noisy compressive sensing type problem.
The principal directions of the low rank part are updated every-so-often. In
between two update times, if new Principal Components' directions appear, the
&quot;noise&quot; seen by the Compressive Sensing step may increase. This problem is
solved, in part, by utilizing the time correlation model of the low rank part.
We call the proposed solution &quot;Real-time Robust Principal Components' Pursuit&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0609</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0609</id><created>2010-10-04</created><authors><author><keyname>Theodorakopoulos</keyname><forenames>George</forenames></author><author><keyname>Boudec</keyname><forenames>Jean-Yves Le</forenames></author><author><keyname>Baras</keyname><forenames>John S.</forenames></author></authors><title>Selfish Response to Epidemic Propagation</title><categories>cs.SY cs.MA nlin.AO</categories><comments>19 pages, 5 figures, submitted to the IEEE Transactions on Automatic
  Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An epidemic spreading in a network calls for a decision on the part of the
network members: They should decide whether to protect themselves or not. Their
decision depends on the trade-off between their perceived risk of being
infected and the cost of being protected. The network members can make
decisions repeatedly, based on information that they receive about the changing
infection level in the network.
  We study the equilibrium states reached by a network whose members increase
(resp. decrease) their security deployment when learning that the network
infection is widespread (resp. limited). Our main finding is that the
equilibrium level of infection increases as the learning rate of the members
increases. We confirm this result in three scenarios for the behavior of the
members: strictly rational cost minimizers, not strictly rational, and strictly
rational but split into two response classes. In the first two cases, we
completely characterize the stability and the domains of attraction of the
equilibrium points, even though the first case leads to a differential
inclusion. We validate our conclusions with simulations on human mobility
traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0621</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0621</id><created>2010-10-04</created><updated>2011-02-25</updated><authors><author><keyname>Yang</keyname><forenames>Shuang Hong</forenames></author></authors><title>Local Optimality of User Choices and Collaborative Competitive Filtering</title><categories>stat.ML cs.IR cs.SI stat.AP</categories><comments>27 pages, 4 figure</comments><acm-class>I.2.6; H.1.1; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While a user's preference is directly reflected in the interactive choice
process between her and the recommender, this wealth of information was not
fully exploited for learning recommender models. In particular, existing
collaborative filtering (CF) approaches take into account only the binary
events of user actions but totally disregard the contexts in which users'
decisions are made. In this paper, we propose Collaborative Competitive
Filtering (CCF), a framework for learning user preferences by modeling the
choice process in recommender systems. CCF employs a multiplicative latent
factor model to characterize the dyadic utility function. But unlike CF, CCF
models the user behavior of choices by encoding a local competition effect. In
this way, CCF allows us to leverage dyadic data that was previously lumped
together with missing data in existing CF models. We present two formulations
and an efficient large scale optimization algorithm. Experiments on three
real-world recommendation data sets demonstrate that CCF significantly
outperforms standard CF approaches in both offline and online evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0624</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0624</id><created>2010-10-04</created><authors><author><keyname>Tucci</keyname><forenames>Gabriel H.</forenames></author><author><keyname>Whiting</keyname><forenames>Philip A.</forenames></author></authors><title>Eigenvalue Results for Large Scale Random Vandermonde Matrices with Unit
  Complex Entries</title><categories>math.PR cs.IT math.IT physics.data-an</categories><comments>Submitted to Transactions of Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper centers on the limit eigenvalue distribution for random
Vandermonde matrices with unit magnitude complex entries. The phases of the
entries are chosen independently and identically distributed from the interval
$[-\pi,\pi]$. Various types of distribution for the phase are considered and we
establish the existence of the empirical eigenvalue distribution in the large
matrix limit on a wide range of cases. The rate of growth of the maximum
eigenvalue is examined and shown to be no greater than $O(\log N)$ and no
slower than $O(\log N/\log\log N)$ where $N$ is the dimension of the matrix.
Additional results include the existence of the capacity of the Vandermonde
channel (limit integral for the expected log determinant).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0626</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0626</id><created>2010-10-04</created><authors><author><keyname>Dell'Amico</keyname><forenames>Matteo</forenames></author><author><keyname>Michiardi</keyname><forenames>Pietro</forenames></author><author><keyname>Roudier</keyname><forenames>Yves</forenames></author></authors><title>Back To The Future: On Predicting User Uptime</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correlation in user connectivity patterns is generally considered a problem
for system designers, since it results in peaks of demand and also in the
scarcity of resources for peer-to-peer applications. The other side of the coin
is that these connectivity patterns are often predictable and that, to some
extent, they can be dealt with proactively.
  In this work, we build predictors aiming to determine the probability that
any given user will be online at any given time in the future. We evaluate the
quality of these predictors on various large traces from instant messaging and
file sharing applications.
  We also illustrate how availability prediction can be applied to enhance the
behavior of peer-to-peer applications: we show through simulation how data
availability is substantially increased in a distributed hash table simply by
adjusting data placement policies according to peer availability prediction and
without requiring any additional storage from any peer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0630</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0630</id><created>2010-10-04</created><authors><author><keyname>Mannersalo</keyname><forenames>Petteri</forenames></author><author><keyname>Paschos</keyname><forenames>Georgios S.</forenames></author><author><keyname>Gkatzikis</keyname><forenames>Lazaros</forenames></author></authors><title>Performance of wireless network coding: motivating small encoding
  numbers</title><categories>cs.NI cs.PF</categories><comments>8 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on a particular transmission scheme called local network
coding, which has been reported to provide significant performance gains in
practical wireless networks. The performance of this scheme strongly depends on
the network topology and thus on the locations of the wireless nodes. Also, it
has been shown previously that finding the encoding strategy, which achieves
maximum performance, requires complex calculations to be undertaken by the
wireless node in real-time.
  Both deterministic and random point pattern are explored and using the
Boolean connectivity model we provide upper bounds for the maximum coding
number, i.e., the number of packets that can be combined such that the
corresponding receivers are able to decode. For the models studied, this upper
bound is of order of $\sqrt{N}$, where $N$ denotes the (mean) number of
neighbors. Moreover, achievable coding numbers are provided for grid-like
networks. We also calculate the multiplicative constants that determine the
gain in case of a small network. Building on the above results, we provide an
analytic expression for the upper bound of the efficiency of local network
coding. The conveyed message is that it is favorable to reduce computational
complexity by relying only on small encoding numbers since the resulting
expected throughput loss is negligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0642</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0642</id><created>2010-10-04</created><authors><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>Luo</keyname><forenames>Jie</forenames></author></authors><title>Error Performance of Channel Coding in Random Access Communication</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new channel coding approach was proposed in [1] for random multiple access
communication over the discrete-time memoryless channel. The coding approach
allows users to choose their communication rates independently without sharing
the rate information among each other or with the receiver. The receiver will
either decode the message or report a collision depending on whether reliable
message recovery is possible. It was shown that, asymptotically as the codeword
length goes to infinity, the set of communication rates supporting reliable
message recovery can be characterized by an achievable region which equals
Shannon's information rate region possibly without a convex hull operation. In
this paper, we derive achievable bounds on error probabilities, including the
decoding error probability and the collision miss detection probability, of
random multiple access systems with a finite codeword length. Achievable error
exponents are obtained by taking the codeword length to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0654</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0654</id><created>2010-10-04</created><authors><author><keyname>Effros</keyname><forenames>Michelle</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author></authors><title>On Equivalence Between Network Topologies</title><categories>cs.IT math.IT</categories><comments>8 pages, 12 figures, 48th Annual Allerton Conference on
  Communication, Control, and Computing, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One major open problem in network coding is to characterize the capacity
region of a general multi-source multi-demand network. There are some existing
computational tools for bounding the capacity of general networks, but their
computational complexity grows very quickly with the size of the network. This
motivates us to propose a new hierarchical approach which finds upper and lower
bounding networks of smaller size for a given network. This approach
sequentially replaces components of the network with simpler structures, i.e.,
with fewer links or nodes, so that the resulting network is more amenable to
computational analysis and its capacity provides an upper or lower bound on the
capacity of the original network. The accuracy of the resulting bounds can be
bounded as a function of the link capacities. Surprisingly, we are able to
simplify some families of network structures without any loss in accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0670</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0670</id><created>2010-10-04</created><updated>2014-02-18</updated><authors><author><keyname>Wang</keyname><forenames>Ye</forenames></author><author><keyname>Rane</keyname><forenames>Shantanu</forenames></author><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author><author><keyname>Sun</keyname><forenames>Wei</forenames></author></authors><title>Unconditionally Secure Computation on Large Distributed Databases with
  Vanishing Cost</title><categories>cs.CR cs.IT math.IT</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a network of k parties, each holding a long sequence of n entries (a
database), with minimum vertex-cut greater than t. We show that any empirical
statistic across the network of databases can be computed by each party with
perfect privacy, against any set of t &lt; k/2 passively colluding parties, such
that the worst-case distortion and communication cost (in bits per database
entry) both go to zero as n, the number of entries in the databases, goes to
infinity. This is based on combining a striking dimensionality reduction result
for random sampling with unconditionally secure multi-party computation
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0694</identifier>
 <datestamp>2012-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0694</id><created>2010-10-04</created><updated>2010-11-02</updated><authors><author><keyname>Bickel</keyname><forenames>David R.</forenames></author></authors><title>Statistical inference optimized with respect to the observed sample for
  single or multiple comparisons</title><categories>math.ST cs.IT math.IT q-bio.BM stat.ME stat.TH</categories><comments>Typo in equation (7) of v2 corrected in equation (6) of v3; clarity
  improved</comments><msc-class>62Fxx</msc-class><journal-ref>Bickel, D. R. (2011). A predictive approach to measuring the
  strength of statistical evidence for single and multiple comparisons.
  Canadian Journal of Statistics, 39, 610-631</journal-ref><doi>10.1002/cjs.10109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The normalized maximum likelihood (NML) is a recent penalized likelihood that
has properties that justify defining the amount of discrimination information
(DI) in the data supporting an alternative hypothesis over a null hypothesis as
the logarithm of an NML ratio, namely, the alternative hypothesis NML divided
by the null hypothesis NML. The resulting DI, like the Bayes factor but unlike
the p-value, measures the strength of evidence for an alternative hypothesis
over a null hypothesis such that the probability of misleading evidence
vanishes asymptotically under weak regularity conditions and such that evidence
can support a simple null hypothesis. Unlike the Bayes factor, the DI does not
require a prior distribution and is minimax optimal in a sense that does not
involve averaging over outcomes that did not occur. Replacing a (possibly
pseudo-) likelihood function with its weighted counterpart extends the scope of
the DI to models for which the unweighted NML is undefined. The likelihood
weights leverage side information, either in data associated with comparisons
other than the comparison at hand or in the parameter value of a simple null
hypothesis. Two case studies, one involving multiple populations and the other
involving multiple biological features, indicate that the DI is robust to the
type of side information used when that information is assigned the weight of a
single observation. Such robustness suggests that very little adjustment for
multiple comparisons is warranted if the sample size is at least moderate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0696</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0696</id><created>2010-10-04</created><authors><author><keyname>Abbaszadeh</keyname><forenames>Masoud</forenames></author><author><keyname>Marquez</keyname><forenames>Horacio J.</forenames></author></authors><title>Robust H_infinity Filter Design for Lipschitz Nonlinear Systems via
  Multiobjective Optimization</title><categories>cs.SY math.OC</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new method of H_infinity observer design for Lipschitz
nonlinear systems is proposed in the form of an LMI optimization problem. The
proposed observer has guaranteed decay rate (exponential convergence) and is
robust against unknown exogenous disturbance. In addition, thanks to the
linearity of the proposed LMIs in the admissible Lipschitz constant, it can be
maximized via LMI optimization. This adds an extra important feature to the
observer, robustness against nonlinear uncertainty. Explicit bound on the
tolerable nonlinear uncertainty is derived. The new LMI formulation also allows
optimizations over the disturbance attenuation level (H_infinity cost). Then,
the admissible Lipschitz constant and the disturbance attenuation level of the
H_infinity filter are simultaneously optimized through LMI multiobjective
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0703</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0703</id><created>2010-10-04</created><updated>2011-04-26</updated><authors><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author><author><keyname>Orecchia</keyname><forenames>Lorenzo</forenames></author></authors><title>Implementing regularization implicitly via approximate eigenvector
  computation</title><categories>cs.DS stat.CO stat.ML</categories><comments>11 pages; a few clarifications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularization is a powerful technique for extracting useful information from
noisy data. Typically, it is implemented by adding some sort of norm constraint
to an objective function and then exactly optimizing the modified objective
function. This procedure often leads to optimization problems that are
computationally more expensive than the original problem, a fact that is
clearly problematic if one is interested in large-scale applications. On the
other hand, a large body of empirical work has demonstrated that heuristics,
and in some cases approximation algorithms, developed to speed up computations
sometimes have the side-effect of performing regularization implicitly. Thus,
we consider the question: What is the regularized optimization objective that
an approximation algorithm is exactly optimizing?
  We address this question in the context of computing approximations to the
smallest nontrivial eigenvector of a graph Laplacian; and we consider three
random-walk-based procedures: one based on the heat kernel of the graph, one
based on computing the the PageRank vector associated with the graph, and one
based on a truncated lazy random walk. In each case, we provide a precise
characterization of the manner in which the approximation method can be viewed
as implicitly computing the exact solution to a regularized problem.
Interestingly, the regularization is not on the usual vector form of the
optimization problem, but instead it is on a related semidefinite program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0707</identifier>
 <datestamp>2011-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0707</id><created>2010-10-04</created><updated>2011-01-10</updated><authors><author><keyname>Ragnarsson</keyname><forenames>Stefan</forenames></author><author><keyname>Van Loan</keyname><forenames>Charles F.</forenames></author></authors><title>Block tensors and symmetric embeddings</title><categories>math.NA cs.NA</categories><msc-class>15A18, 15A69, 65F15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Well known connections exist between the singular value decomposition of a
matrix A and the Schur decomposition of its symmetric embedding sym(A) = [ 0 A;
A' 0]. In particular, if s is a singular value of A then +s and -s are
eigenvalues of the symmetric embedding. The top and bottom halves of sym(A)'s
eigenvectors are singular vectors for A. Power methods applied to A can be
related to power methods applied to sym(A). The rank of sym(A) is twice the
rank of A. In this paper we show how to embed a general order-d tensor A into
an order-d symmetric tensor sym(A). Through the embedding we relate (a) power
methods for A's singular values to power methods for sym(A)'s eigenvalues and
(b) the rank of A to the rank of sym(A).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0711</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0711</id><created>2010-10-04</created><updated>2010-11-09</updated><authors><author><keyname>Meloni</keyname><forenames>Sandro</forenames></author><author><keyname>G&#xf3;mez-Garde&#xf1;es</keyname><forenames>Jes&#xfa;s</forenames></author></authors><title>Local Empathy provides Global Minimization of Congestion in
  Communication Networks</title><categories>physics.soc-ph cs.NI</categories><comments>8 pages, 6 figures</comments><journal-ref>Phys. Rev. E 82, 056105 (2010)</journal-ref><doi>10.1103/PhysRevE.82.056105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel mechanism to avoid congestion in complex networks based on
local knowledge of traffic conditions and the ability of routers to
self-coordinate their dynamical behavior. In particular, routers make use of
local information about traffic conditions to either reject or accept
information packets from their neighbors. We show that when nodes are only
aware of their own congestion state they self-organize into a hierarchical
configuration that delays remarkably the onset of congestion although, leading
to a sharp first-order like congestion transition. We also consider the case
when nodes are aware of the congestion state of their neighbors. In this case,
we show that empathy between nodes is strongly beneficial to the overall
performance of the system and it is possible to achieve larger values for the
critical load together with a smooth, second-order like, transition. Finally,
we show how local empathy minimize the impact of congestion as much as global
minimization. Therefore, here we present an outstanding example of how local
dynamical rules can optimize the system's functioning up to the levels reached
using global knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0725</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0725</id><created>2010-10-04</created><authors><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Link Prediction in Complex Networks: A Survey</title><categories>physics.soc-ph cs.SI physics.comp-ph</categories><comments>44 pages, 5 figures</comments><journal-ref>Physica A 390 (2011) 1150-1170</journal-ref><doi>10.1016/j.physa.2010.11.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link prediction in complex networks has attracted increasing attention from
both physical and computer science communities. The algorithms can be used to
extract missing information, identify spurious interactions, evaluate network
evolving mechanisms, and so on. This article summaries recent progress about
link prediction algorithms, emphasizing on the contributions from physical
perspectives and approaches, such as the random-walk-based methods and the
maximum likelihood methods. We also introduce three typical applications:
reconstruction of networks, evaluation of network evolving mechanism and
classification of partially labelled networks. Finally, we introduce some
applications and outline future challenges of link prediction algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0743</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0743</id><created>2010-10-04</created><updated>2011-05-24</updated><authors><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Strong security and separated code constructions for the broadcast
  channels with confidential messages</title><categories>cs.IT cs.CR math.IT</categories><comments>LaTeX2e, two column, 9 pages, no figure, improved version registered
  as arXiv:1101.4036</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the capacity region of the broadcast channel with confidential
messages does not change when the strong security criterion is adopted instead
of the weak security criterion traditionally used. We also show a construction
method of coding for the broadcast channel with confidential messages by using
an arbitrary given coding for the broadcast channel with degraded message sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0750</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0750</id><created>2010-10-04</created><authors><author><keyname>Wu</keyname><forenames>Shang-Guan H.</forenames></author></authors><title>A note on hierarchies and bureaucracies</title><categories>cs.GT</categories><comments>2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we argue that there is a bug in [Tirole, J., &quot;Hierarchies and
bureaucracies: On the role of collusion in organizations,&quot; {\em Journal of Law,
Economics and Organization}, vol.2, 181-214, 1986].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0756</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0756</id><created>2010-10-04</created><authors><author><keyname>Carrijo</keyname><forenames>Jose</forenames></author><author><keyname>Tonicelli</keyname><forenames>Rafael</forenames></author><author><keyname>Nascimento</keyname><forenames>Anderson C. A.</forenames></author></authors><title>A Fault Analytic Method against HB+</title><categories>cs.CR</categories><doi>10.1587/transfun.E94.A.855</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search for lightweight authentication protocols suitable for low-cost
RFID tags constitutes an active and challenging research area. In this context,
a family of protocols based on the LPN problem has been proposed: the so-called
HB-family. Despite the rich literature regarding the cryptanalysis of these
protocols, there are no published results about the impact of fault analysis
over them. The purpose of this paper is to fill this gap by presenting a fault
analytic method against a prominent member of the HB-family: HB+ protocol. We
demonstrate that the fault analysis model can lead to a flexible and effective
attack against HB-like protocols, posing a serious threat over them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0765</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0765</id><created>2010-10-05</created><updated>2011-08-08</updated><authors><author><keyname>Fong</keyname><forenames>Chamberlain</forenames></author><author><keyname>Walters</keyname><forenames>Michael K.</forenames></author></authors><title>Methods for Accelerating Conway's Doomsday Algorithm (part 2)</title><categories>cs.DS cs.DM</categories><comments>7th International Congress of Industrial and Applied Mathematics
  (2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a modification of a key component in the Doomsday Algorithm for
calculating the day of the week of any calendar date. In particular, we propose
to replace the calculation of the required term: \lfloor \frac{x}{12} \rfloor +
x \bmod 12 + \lfloor \frac{x \bmod 12}{4} \rfloor with -[ \frac{x+11(x \bmod
2)}{2} + 11 (\frac{x+11(x \bmod 2)}{2}\bmod 2)] \bmod 7 for a 2-digit input
year x; Although our expression looks daunting and complicated, we will explain
why it is actually easy to calculate mentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0771</identifier>
 <datestamp>2013-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0771</id><created>2010-10-05</created><updated>2013-02-01</updated><authors><author><keyname>Dridi</keyname><forenames>Imen Harbaoui</forenames><affiliation>ACS</affiliation></author><author><keyname>Kammarti</keyname><forenames>Ryan</forenames><affiliation>ACS</affiliation></author><author><keyname>Ksouri</keyname><forenames>Mekki</forenames><affiliation>ACS</affiliation></author><author><keyname>Borne</keyname><forenames>Pierre</forenames><affiliation>LAGIS</affiliation></author></authors><title>Genetic Algorithm for Mulicriteria Optimization of a Multi-Pickup and
  Delivery Problem with Time Windows</title><categories>cs.NE</categories><proxy>ccsd</proxy><journal-ref>INCOM'09 IFAC, Russie, F\'ed\'eration De (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In This paper we present a genetic algorithm for mulicriteria optimization of
a multipickup and delivery problem with time windows (m-PDPTW). The m-PDPTW is
an optimization vehicles routing problem which must meet requests for transport
between suppliers and customers satisfying precedence, capacity and time
constraints. This paper purposes a brief literature review of the PDPTW,
present an approach based on genetic algorithms and Pareto dominance method to
give a set of satisfying solutions to the m-PDPTW minimizing total travel cost,
total tardiness time and the vehicles number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0781</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0781</id><created>2010-10-05</created><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>Transmission Capacity of Spectrum Sharing Ad-hoc Networks with Multiple
  Antennas</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two coexisting ad-hoc networks, primary and secondary, are considered, where
each node of the primary network has a single antenna, while each node of the
secondary network is equipped with multiple antennas. Using multiple antennas,
each secondary transmitter uses some of its spatial transmit degrees of freedom
(STDOF) to null its interference towards the primary receivers, while each
secondary receiver employs interference cancelation using some of its spatial
receive degrees of freedom (SRDOF). This paper derives the optimal STDOF for
nulling and SRDOF for interference cancelation that maximize the scaling of the
transmission capacity of the secondary network with respect to the number of
antennas, when the secondary network operates under an outage constraint at the
primary receivers. With a single receive antenna, using a fraction of the total
STDOF for nulling at each secondary transmitter maximizes the transmission
capacity. With multiple transmit and receive antennas and fixing all but one
STDOF for nulling, using a fraction of the total SRDOF to cancel the nearest
interferers maximizes the transmission capacity of the secondary network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0803</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0803</id><created>2010-10-05</created><updated>2015-01-07</updated><authors><author><keyname>Scholz</keyname><forenames>Matthias</forenames></author></authors><title>Node similarity as a basic principle behind connectivity in complex
  networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>6 pages in Journal of Data Mining &amp; Digital Humanities (2015)
  jdmdh:33</comments><journal-ref>Journal of Data Mining &amp; Digital Humanities, 2015 (January 13,
  2015) jdmdh:77</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How are people linked in a highly connected society? Since in many networks a
power-law (scale-free) node-degree distribution can be observed, power-law
might be seen as a universal characteristics of networks. But this study of
communication in the Flickr social online network reveals that power-law
node-degree distributions are restricted to only sparsely connected networks.
More densely connected networks, by contrast, show an increasing divergence
from power-law. This work shows that this observation is consistent with the
classic idea from social sciences that similarity is the driving factor behind
communication in social networks. The strong relation between communication
strength and node similarity could be confirmed by analyzing the Flickr
network. It also is shown that node similarity as a network formation model can
reproduce the characteristics of different network densities and hence can be
used as a model for describing the topological transition from weakly to
strongly connected societies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0809</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0809</id><created>2010-10-05</created><authors><author><keyname>Geisberger</keyname><forenames>Robert</forenames></author></authors><title>Engineering Time-dependent One-To-All Computation</title><categories>cs.DS</categories><comments>7 pages, technical report</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very recently a new algorithm to the nonnegative single-source shortest path
problem on road networks has been discovered. It is very cache-efficient, but
only on static road networks. We show how to augment it to the time-dependent
scenario. The advantage if the new approach is that it settles nodes, even for
a profile query, by scanning all downward edges. We improve the scanning of the
downward edges with techniques developed for time-dependent many-to-many
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0846</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0846</id><created>2010-10-05</created><updated>2010-11-26</updated><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author></authors><title>A strong direct product theorem for two-way public coin communication
  complexity</title><categories>cs.CC cs.IT math.IT</categories><comments>ver 2, 12 pages, application to set disjointness added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a direct product result for two-way public coin communication
complexity of all relations in terms of a new complexity measure that we
define. Our new measure is a generalization to non-product distributions of the
two-way product subdistribution bound of [J, Klauck and Nayak 08], thereby our
result implying their direct product result in terms of the two-way product
subdistribution bound.
  We show that our new complexity measure gives tight lower bound for the
set-disjointness problem, as a result we reproduce strong direct product result
for this problem, which was previously shown by [Klauck 00].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0852</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0852</id><created>2010-10-05</created><updated>2012-03-27</updated><authors><author><keyname>Chepoi</keyname><forenames>Victor</forenames></author><author><keyname>Maftuleac</keyname><forenames>Daniela</forenames></author></authors><title>Shortest path problem in rectangular complexes of global nonpositive
  curvature</title><categories>cs.CG</categories><doi>10.1016/j.comgeo.2012.04.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CAT(0) metric spaces constitute a far-reaching common generalization of
Euclidean and hyperbolic spaces and simple polygons: any two points x and y of
a CAT(0) metric space are connected by a unique shortest path {\gamma}(x,y). In
this paper, we present an efficient algorithm for answering two-point distance
queries in CAT(0) rectangular complexes and two of theirs subclasses, ramified
rectilinear polygons (CAT(0) rectangular complexes in which the links of all
vertices are bipartite graphs) and squaregraphs (CAT(0) rectangular complexes
arising from plane quadrangulations in which all inner vertices have degrees
\geq4). Namely, we show that for a CAT(0) rectangular complex K with n
vertices, one can construct a data structure D of size $O(n^2)$ so that, given
any two points x,y in K, the shortest path {\gamma}(x,y) between x and y can be
computed in O(d(p,q)) time, where p and q are vertices of two faces of K
containing the points x and y, respectively, such that {\gamma}(x,y) is
contained in K(I(p,q)) and d(p,q) is the distance between p and q in the
underlying graph of K. If K is a ramified rectilinear polygon, then one can
construct a data structure D of optimal size O(n) and answer two-point shortest
path queries in O(d(p,q)log{\Delta}) time, where {\Delta} is the maximal degree
of a vertex of G(K). Finally, if K is a squaregraph, then one can construct a
data structure D of size O(nlogn) and answer two-point shortest path queries in
O(d(p,q)) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0863</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0863</id><created>2010-10-05</created><authors><author><keyname>Hajra</keyname><forenames>Kamalika Basu</forenames></author><author><keyname>Chandra</keyname><forenames>Anjan Kumar</forenames></author></authors><title>Coevolution of Glauber-like Ising dynamics on typical networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>8 pages, 10 figures</comments><journal-ref>Eur. Phys. J. B (2012) 85: 27</journal-ref><doi>10.1140/epjb/e2011-20428-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider coevolution of site status and link structures from two different
initial networks: a one dimensional Ising chain and a scale free network. The
dynamics is governed by a preassigned stability parameter $S$, and a rewiring
factor $\phi$, that determines whether the Ising spin at the chosen site flips
or whether the node gets rewired to another node in the system. This dynamics
has also been studied with Ising spins distributed randomly among nodes which
lie on a network with preferential attachment. We have observed the steady
state average stability and magnetisation for both kinds of systems to have an
idea about the effect of initial network topology. Although the average
stability shows almost similar behaviour, the magnetisation depends on the
initial condition we start from. Apart from the local dynamics, the global
effect on the dynamics has also been studied. These parameters show interesting
variations for different values of $S$ and $\phi$, which helps in determining
the steady-state condition for a given substrate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0886</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0886</id><created>2010-10-05</created><authors><author><keyname>Reckhaus</keyname><forenames>Michael</forenames></author><author><keyname>Hochgeschwender</keyname><forenames>Nico</forenames></author><author><keyname>Ploeger</keyname><forenames>Paul G.</forenames></author><author><keyname>Kraetzschmar</keyname><forenames>Gerhard K.</forenames></author></authors><title>A Platform-independent Programming Environment for Robot Control</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of robot control programs is a complex task. Many robots are
different in their electrical and mechanical structure which is also reflected
in the software. Specific robot software environments support the program
development, but are mainly text-based and usually applied by experts in the
field with profound knowledge of the target robot. This paper presents a
graphical programming environment which aims to ease the development of robot
control programs. In contrast to existing graphical robot programming
environments, our approach focuses on the composition of parallel action
sequences. The developed environment allows to schedule independent robot
actions on parallel execution lines and provides mechanism to avoid
side-effects of parallel actions. The developed environment is
platform-independent and based on the model-driven paradigm. The feasibility of
our approach is shown by the application of the sequencer to a simulated
service robot and a robot for educational purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0905</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0905</id><created>2010-10-05</created><authors><author><keyname>Jansens</keyname><forenames>Dana</forenames></author><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Smid</keyname><forenames>Michiel</forenames></author></authors><title>Improved Methods For Generating Quasi-Gray Codes</title><categories>cs.DM</categories><comments>Masters Thesis. A conference version appeared in the proceedings of
  SWAT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a sequence of bit strings of length d, such that each string differs
from the next in a constant number of bits. We call this sequence a quasi-Gray
code. We examine the problem of efficiently generating such codes, by
considering the number of bits read and written at each generating step, the
average number of bits read while generating the entire code, and the number of
strings generated in the code. Our results give a trade-off between these
constraints, and present algorithms that do less work on average than previous
results, and that increase the number of bit strings generated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0924</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0924</id><created>2010-10-05</created><authors><author><keyname>Riboni</keyname><forenames>Daniele</forenames></author><author><keyname>Pareschi</keyname><forenames>Linda</forenames></author><author><keyname>Bettini</keyname><forenames>Claudio</forenames></author></authors><title>Preserving Privacy in Sequential Data Release against Background
  Knowledge Attacks</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large amount of transaction data containing associations between
individuals and sensitive information flows everyday into data stores. Examples
include web queries, credit card transactions, medical exam records, transit
database records. The serial release of these data to partner institutions or
data analysis centers is a common situation. In this paper we show that, in
most domains, correlations among sensitive values associated to the same
individuals in different releases can be easily mined, and used to violate
users' privacy by adversaries observing multiple data releases. We provide a
formal model for privacy attacks based on this sequential background knowledge,
as well as on background knowledge on the probability distribution of sensitive
values over different individuals. We show how sequential background knowledge
can be actually obtained by an adversary, and used to identify with high
confidence the sensitive values associated with an individual. A defense
algorithm based on Jensen-Shannon divergence is proposed, and extensive
experiments show the superiority of the proposed technique with respect to
other applicable solutions. To the best of our knowledge, this is the first
work that systematically investigates the role of sequential background
knowledge in serial release of transaction data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0933</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0933</id><created>2010-10-05</created><authors><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Shin</keyname><forenames>Wonjae</forenames></author><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author></authors><title>Interference Alignment with Limited Feedback on Two-cell Interfering
  Two-User MIMO-MAC</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, Submitted ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a two-cell interfering two-user multiple-input
multiple-output multiple access channel (MIMO-MAC) with limited feedback. We
first investigate the multiplexing gain of such channel when users have perfect
channel state information at transmitter (CSIT) by exploiting an interference
alignment scheme. In addition, we propose a feedback framework for the
interference alignment in the limited feedback system. On the basis of the
proposed feedback framework, we analyze the rate gap loss and it is shown that
in order to keep the same multiplexing gain with the case of perfect CSIT, the
number of feedback bits per receiver scales as $B \geq
(M\!-1\!)\!\log_{2}(\textsf{SNR})+C$, where $M$ and $C$ denote the number of
transmit antennas and a constant, respectively. Throughout the simulation
results, it is shown that the sum-rate performance coincides with the derived
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0937</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0937</id><created>2010-10-05</created><authors><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Chun</keyname><forenames>Joohwan</forenames></author></authors><title>Signal Space Alignment for an Encryption Message and Successive Network
  Code Decoding on the MIMO K-way Relay Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, and submitted ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a network information flow problem for a
multiple-input multiple-output (MIMO) Gaussian wireless network with $K$-users
and a single intermediate relay having $M$ antennas. In this network, each user
intends to convey a multicast message to all other users while receiving $K-1$
independent messages from the other users via an intermediate relay. This
network information flow is termed a MIMO Gaussian $K$-way relay channel. For
this channel, we show that $\frac{K}{2}$ degrees of freedom is achievable if
$M=K-1$. To demonstrate this, we come up with an encoding and decoding strategy
inspired from cryptography theory. The proposed encoding and decoding strategy
involves a \textit{signal space alignment for an encryption message} for the
multiple access phase (MAC) and \textit{zero forcing with successive network
code decoding} for the broadcast (BC) phase. The idea of the \emph{signal space
alignment for an encryption message} is that all users cooperatively choose the
precoding vectors to transmit the message so that the relay can receive a
proper encryption message with a special structure, \textit{network code chain
structure}. During the BC phase, \emph{zero forcing combined with successive
network code decoding} enables all users to decipher the encryption message
from the relay despite the fact that they all have different self-information
which they use as a key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0958</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0958</id><created>2010-10-05</created><authors><author><keyname>Sharma</keyname><forenames>Punit</forenames></author><author><keyname>Mandal</keyname><forenames>Partha Sarathi</forenames></author></authors><title>Reconstruction of Aggregation Tree in spite of Faulty Nodes in Wireless
  Sensor Networks</title><categories>cs.DC</categories><comments>this is a 5 page paper. this paper has been submitted to WCSN 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in wireless sensor networks (WSNs) have led to many new
promissing applications. However data communication between nodes consumes a
large portion of the total energy of WSNs. Consequently efficient data
aggregation technique can help greatly to reduce power consumption. Data
aggregation has emerged as a basic approach in WSNs in order to reduce the
number of transmissions of sensor nodes over {\it aggregation tree} and hence
minimizing the overall power consumption in the network. If a sensor node fails
during data aggregation then the aggregation tree is disconnected. Hence the
WSNs rely on in-network aggregation for efficiency but a single faulty node can
severely influence the outcome by contributing an arbitrary partial aggregate
value.
  In this paper we have presented a distributed algorithm that reconstruct the
aggregation tree from the initial aggregation tree excluding the faulty sensor
node. This is a synchronous model that is completed in several rounds. Our
proposed scheme can handle multiple number of faulty nodes as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0979</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0979</id><created>2010-10-05</created><authors><author><keyname>Dridi</keyname><forenames>Imen Harbaoui</forenames><affiliation>LAGIS, ACS</affiliation></author><author><keyname>Kammarti</keyname><forenames>Ryan</forenames><affiliation>ACS</affiliation></author><author><keyname>Borne</keyname><forenames>Pierre</forenames><affiliation>LAGIS</affiliation></author><author><keyname>Ksouri</keyname><forenames>Mekki</forenames><affiliation>ACS</affiliation></author></authors><title>Un Algorithme g\'en\'etique pour le probl\`eme de ramassage et de
  livraison avec fen\^etres de temps \`a plusieurs v\'ehicules</title><categories>cs.NE</categories><proxy>ccsd</proxy><journal-ref>CIFA, Roumanie (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PDPTW is an optimization vehicles routing problem which must meet
requests for transport between suppliers and customers satisfying precedence,
capacity and time constraints. We present, in this paper, a genetic algorithm
for optimization of a multi pickup and delivery problem with time windows
(m-PDPTW). We purposes a brief literature review of the PDPTW, present an
approach based on genetic algorithms to give a satisfying solution to the
m-PDPTW minimizing the total travel cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.0980</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.0980</id><created>2010-10-05</created><authors><author><keyname>Dridi</keyname><forenames>Imen Harbaoui</forenames><affiliation>LAGIS, ACS</affiliation></author><author><keyname>Kammarti</keyname><forenames>Ryan</forenames><affiliation>ACS</affiliation></author><author><keyname>Ksouri</keyname><forenames>Mekki</forenames><affiliation>ACS</affiliation></author><author><keyname>Borne</keyname><forenames>Pierre</forenames><affiliation>LAGIS</affiliation></author></authors><title>Approche Multicrit\`ere pour le Probl\`eme de Ramassage et de Livraison
  avec Fen\^etres de Temps \`a Plusieurs V\'ehicules</title><categories>cs.NE</categories><proxy>ccsd</proxy><journal-ref>LT IEEE 2009, Tunisie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the transport goods problem occupies an important place in the
economic life of modern societies. The pickup and delivery problem with time
windows (PDPTW) is one of the problems which a large part of the research was
interested. In this paper, we present a a brief literature review of the VRP
and the PDPTW, propose our multicriteria approach based on genetic algorithms
which allows minimize the compromise between the vehicles number, the total
tardiness time and the total travel cost. And this, by treating the case where
a customer can have multiple suppliers and one supplier can have multiple
customers
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1015</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1015</id><created>2010-10-05</created><authors><author><keyname>Wiley</keyname><forenames>Keith</forenames></author><author><keyname>Connolly</keyname><forenames>Andrew</forenames></author><author><keyname>Gardner</keyname><forenames>Jeff</forenames></author><author><keyname>Krughof</keyname><forenames>Simon</forenames></author><author><keyname>Balazinska</keyname><forenames>Magdalena</forenames></author><author><keyname>Howe</keyname><forenames>Bill</forenames></author><author><keyname>Kwon</keyname><forenames>YongChul</forenames></author><author><keyname>Bu</keyname><forenames>YingYi</forenames></author></authors><title>Astronomy in the Cloud: Using MapReduce for Image Coaddition</title><categories>cs.DC</categories><comments>31 pages, 11 figures, 2 tables</comments><doi>10.1086/658877</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the coming decade, astronomical surveys of the sky will generate tens of
terabytes of images and detect hundreds of millions of sources every night. The
study of these sources will involve computation challenges such as anomaly
detection and classification, and moving object tracking. Since such studies
benefit from the highest quality data, methods such as image coaddition
(stacking) will be a critical preprocessing step prior to scientific
investigation. With a requirement that these images be analyzed on a nightly
basis to identify moving sources or transient objects, these data streams
present many computational challenges. Given the quantity of data involved, the
computational load of these problems can only be addressed by distributing the
workload over a large number of nodes. However, the high data throughput
demanded by these applications may present scalability challenges for certain
storage architectures. One scalable data-processing method that has emerged in
recent years is MapReduce, and in this paper we focus on its popular
open-source implementation called Hadoop. In the Hadoop framework, the data is
partitioned among storage attached directly to worker nodes, and the processing
workload is scheduled in parallel on the nodes that contain the required input
data. A further motivation for using Hadoop is that it allows us to exploit
cloud computing resources, e.g., Amazon's EC2. We report on our experience
implementing a scalable image-processing pipeline for the SDSS imaging database
using Hadoop. This multi-terabyte imaging dataset provides a good testbed for
algorithm development since its scope and structure approximate future surveys.
First, we describe MapReduce and how we adapted image coaddition to the
MapReduce framework. Then we describe a number of optimizations to our basic
approach and report experimental results comparing their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1016</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1016</id><created>2010-10-05</created><updated>2011-07-27</updated><authors><author><keyname>Hern</keyname><forenames>Brett</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna</forenames></author></authors><title>Multilevel Coding Schemes for Compute-and-Forward</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate techniques for designing modulation/coding schemes for the
wireless two-way relaying channel. The relay is assumed to have perfect channel
state information, but the transmitters are assumed to have no channel state
information. We consider physical layer network coding based on multilevel
coding techniques. Our multilevel coding framework is inspired by the
compute-and-forward relaying protocol. Indeed, we show that the framework
developed here naturally facilitates decoding of linear combinations of
codewords for forwarding by the relay node. We develop our framework with
general modulation formats in mind, but numerical results are presented for the
case where each node transmits using the QPSK constellation with gray labeling.
We focus our discussion on the rates at which the relay may reliably decode
linear combinations of codewords transmitted from the end nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1024</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1024</id><created>2010-10-05</created><authors><author><keyname>Cicalese</keyname><forenames>Ferdinando</forenames></author><author><keyname>Vaccaro</keyname><forenames>Ugo</forenames></author></authors><title>Superselectors: Efficient Constructions and Applications</title><categories>cs.DS cs.DM cs.IT math.IT</categories><msc-class>68R05, 68W40, 68P30, 68P05, 68P10</msc-class><acm-class>G.2.1; F.2.2; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new combinatorial structure: the superselector. We show that
superselectors subsume several important combinatorial structures used in the
past few years to solve problems in group testing, compressed sensing,
multi-channel conflict resolution and data security. We prove close upper and
lower bounds on the size of superselectors and we provide efficient algorithms
for their constructions. Albeit our bounds are very general, when they are
instantiated on the combinatorial structures that are particular cases of
superselectors (e.g., (p,k,n)-selectors, (d,\ell)-list-disjunct matrices,
MUT_k(r)-families, FUT(k, a)-families, etc.) they match the best known bounds
in terms of size of the structures (the relevant parameter in the
applications). For appropriate values of parameters, our results also provide
the first efficient deterministic algorithms for the construction of such
structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1028</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1028</id><created>2010-10-05</created><authors><author><keyname>Altshuler</keyname><forenames>Yaniv</forenames></author><author><keyname>Aharony</keyname><forenames>Nadav</forenames></author><author><keyname>Elovici</keyname><forenames>Yuval</forenames></author><author><keyname>Pentland</keyname><forenames>Alex</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author></authors><title>Stealing Reality</title><categories>cs.SI physics.soc-ph</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we discuss the threat of malware targeted at extracting
information about the relationships in a real-world social network as well as
characteristic information about the individuals in the network, which we dub
Stealing Reality. We present Stealing Reality, explain why it differs from
traditional types of network attacks, and discuss why its impact is
significantly more dangerous than that of other attacks. We also present our
initial analysis and results regarding the form that an SR attack might take,
with the goal of promoting the discussion of defending against such an attack,
or even just detecting the fact that one has already occurred.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1037</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1037</id><created>2010-10-05</created><authors><author><keyname>Herrera</keyname><forenames>J. L.</forenames></author><author><keyname>Cosenza</keyname><forenames>M. G.</forenames></author><author><keyname>Tucci</keyname><forenames>K.</forenames></author></authors><title>Stratified economic exchange on networks</title><categories>physics.soc-ph cs.SI nlin.CG</categories><journal-ref>Physica A 390 (2011) 1453-1457</journal-ref><doi>10.1016/j.physa.2010.12.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a model of stratified economic interactions between agents
when the notion of spatial location is introduced. The agents are placed on a
network with near-neighbor connections. Interactions between neighbors can
occur only if the difference in their wealth is less than a threshold value
that defines the width of the economic classes. By employing concepts from
spatiotemporal dynamical systems, three types of patterns can be identified in
the system as parameters are varied: laminar, intermittent and turbulent
states. The transition from the laminar state to the turbulent state is
characterized by the activity of the system, a quantity that measures the
average exchange of wealth over long times. The degree of inequality in the
wealth distribution for different parameter values is characterized by the Gini
Coefficient. High levels of activity are associated to low values of the Gini
coefficient. It is found that the topological properties of the network have
little effect on the activity of the system, but the Gini coefficient increases
when the clustering coefficient of the network is increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1042</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1042</id><created>2010-10-05</created><updated>2011-05-05</updated><authors><author><keyname>Zhao</keyname><forenames>James Y.</forenames></author></authors><title>Hidden Markov Models with Multiple Observation Processes</title><categories>math.PR cs.IT cs.LG math.IT</categories><comments>Masters Thesis, 79 pages</comments><msc-class>90C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a hidden Markov model with multiple observation processes, one of
which is chosen at each point in time by a policy---a deterministic function of
the information state---and attempt to determine which policy minimises the
limiting expected entropy of the information state. Focusing on a special case,
we prove analytically that the information state always converges in
distribution, and derive a formula for the limiting entropy which can be used
for calculations with high precision. Using this fomula, we find
computationally that the optimal policy is always a threshold policy, allowing
it to be easily found. We also find that the greedy policy is almost optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1044</identifier>
 <datestamp>2012-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1044</id><created>2010-10-05</created><updated>2012-08-31</updated><authors><author><keyname>Zhou</keyname><forenames>Lei</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>On the Capacity of the $K$-User Cyclic Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>To appear at IEEE Transactions on Information Theory. arXiv admin
  note: substantial text overlap with arXiv:1103.5789</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper studies the capacity region of a $K$-user cyclic Gaussian
interference channel, where the $k$th user interferes with only the $(k-1)$th
user (mod $K$) in the network. Inspired by the work of Etkin, Tse and Wang, who
derived a capacity region outer bound for the two-user Gaussian interference
channel and proved that a simple Han-Kobayashi power splitting scheme can
achieve to within one bit of the capacity region for all values of channel
parameters, this paper shows that a similar strategy also achieves the capacity
region of the $K$-user cyclic interference channel to within a constant gap in
the weak interference regime. Specifically, for the $K$-user cyclic Gaussian
interference channel, a compact representation of the Han-Kobayashi achievable
rate region using Fourier-Motzkin elimination is first derived, a capacity
region outer bound is then established. It is shown that the Etkin-Tse-Wang
power splitting strategy gives a constant gap of at most 2 bits in the weak
interference regime. For the special 3-user case, this gap can be sharpened to
1 1/2 bits by time-sharing of several different strategies. The capacity result
of the $K$-user cyclic Gaussian interference channel in the strong interference
regime is also given. Further, based on the capacity results, this paper
studies the generalized degrees of freedom (GDoF) of the symmetric cyclic
interference channel. It is shown that the GDoF of the symmetric capacity is
the same as that of the classic two-user interference channel, no matter how
many users are in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1047</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1047</id><created>2010-10-05</created><authors><author><keyname>Louis</keyname><forenames>Anand</forenames></author></authors><title>Cut-Matching Games on Directed Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give O(log^2 n)-approximation algorithm based on the cut-matching
framework of [10, 13, 14] for computing the sparsest cut on directed graphs.
Our algorithm uses only O(log^2 n) single commodity max-flow computations and
thus breaks the multicommodity-flow barrier for computing the sparsest cut on
directed graphs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1052</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1052</id><created>2010-10-05</created><authors><author><keyname>Xu</keyname><forenames>Peiliang</forenames></author><author><keyname>Cannon</keyname><forenames>Elizabeth</forenames></author><author><keyname>Lachapelle</keyname><forenames>Gerard</forenames></author></authors><title>Mixed integer programming for the resolution of GPS carrier phase
  ambiguities</title><categories>cs.IT cs.DM math.IT</categories><comments>this is the unaltered version of our paper presented at the General
  Assembly of the International Union of Geodesy and Geophysics, Boulder, 1995</comments><report-no>Technical Report Nr.2000.2, Department of Geodesy and
  Geoinformatics, Stuttgart University</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This arXiv upload is to clarify that the now well-known sorted QR MIMO
decoder was first presented in the 1995 IUGG General Assembly. We clearly go
much further in the sense that we directly incorporated reduction into this one
step, non-exact suboptimal integer solution. Except for these first few lines
up to this point, this paper is an unaltered version of the paper presented at
the IUGG1995 Assembly in Boulder.
  Ambiguity resolution of GPS carrier phase observables is crucial in high
precision geodetic positioning and navigation applications. It consists of two
aspects: estimating the integer ambiguities in the mixed integer observation
model and examining whether they are sufficiently accurate to be fixed as known
nonrandom integers. We shall discuss the first point in this paper from the
point of view of integer programming. A one-step nonexact approach is proposed
by employing minimum diagonal pivoting Gaussian decompositions, which may be
thought of as an improvement of the simple rounding-off method, since the
weights and correlations of the floating-estimated ambiguities are fully taken
into account. The second approach is to reformulate the mixed integer least
squares problem into the standard 0-1 linear integer programming model, which
can then be solved by using, for instance, the practically robust and efficient
simplex algorithm for linear integer programming. It is exact, if proper bounds
for the ambiguities are given. Theoretical results on decorrelation by
unimodular transformation are given in the form of a theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1060</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1060</id><created>2010-10-06</created><updated>2010-10-07</updated><authors><author><keyname>Vahid</keyname><forenames>Alireza</forenames></author><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Avestimehr</keyname><forenames>Amir Salman</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>On the Capacity of Multi-Hop Wireless Networks with Partial Network
  Knowledge</title><categories>cs.IT math.IT</categories><comments>proceedings of Allerton conference 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In large wireless networks, acquiring full network state information is
typically infeasible. Hence, nodes need to flow the information and manage the
interference based on partial information about the network. In this paper, we
consider multi-hop wireless networks and assume that each source only knows the
channel gains that are on the routes from itself to other destinations in the
network. We develop several distributed strategies to manage the interference
among the users and prove their optimality in maximizing the achievable
normalized sum-rate for some classes of networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1066</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1066</id><created>2010-10-06</created><updated>2010-12-13</updated><authors><author><keyname>de Falco</keyname><forenames>Marc</forenames><affiliation>CNRS</affiliation></author></authors><title>An Explicit Framework for Interaction Nets</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  12, 2010) lmcs:1108</journal-ref><doi>10.2168/LMCS-6(4:6)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interaction nets are a graphical formalism inspired by Linear Logic
proof-nets often used for studying higher order rewriting e.g. \Beta-reduction.
Traditional presentations of interaction nets are based on graph theory and
rely on elementary properties of graph theory. We give here a more explicit
presentation based on notions borrowed from Girard's Geometry of Interaction:
interaction nets are presented as partial permutations and a composition of
nets, the gluing, is derived from the execution formula. We then define
contexts and reduction as the context closure of rules. We prove strong
confluence of the reduction within our framework and show how interaction nets
can be viewed as the quotient of some generalized proof-nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1069</identifier>
 <datestamp>2012-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1069</id><created>2010-10-06</created><updated>2012-11-23</updated><authors><author><keyname>S</keyname><forenames>Jithin K</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Gopalarathnam</keyname><forenames>Raghav</forenames></author></authors><title>Cooperative Distributed Sequential Spectrum Sensing</title><categories>cs.IT math.IT stat.AP</categories><comments>This paper has been withdrawn by the author due to the submission of
  detailed journal version of the same paper, to arXiv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider cooperative spectrum sensing for cognitive radios. We develop an
energy efficient detector with low detection delay using sequential hypothesis
testing. Sequential Probability Ratio Test (SPRT) is used at both the local
nodes and the fusion center. We also analyse the performance of this algorithm
and compare with the simulations. Modelling uncertainties in the distribution
parameters are considered. Slow fading with and without perfect channel state
information at the cognitive radios is taken into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1071</identifier>
 <datestamp>2012-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1071</id><created>2010-10-06</created><updated>2012-11-23</updated><authors><author><keyname>S</keyname><forenames>Jithin K</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author></authors><title>A Novel Algorithm for Cooperative Distributed Sequential Spectrum
  Sensing in Cognitive Radio</title><categories>cs.IT math.IT stat.AP</categories><comments>This paper has been withdrawn by the author due to the submission of
  detailed journal version of the same paper, to arXiv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers cooperative spectrum sensing in Cognitive Radios. In our
previous work we have developed DualSPRT, a distributed algorithm for
cooperative spectrum sensing using Sequential Probability Ratio Test (SPRT) at
the Cognitive Radios as well as at the fusion center. This algorithm works
well, but is not optimal. In this paper we propose an improved algorithm-
SPRT-CSPRT, which is motivated from Cumulative Sum Procedures (CUSUM). We
analyse it theoretically. We also modify this algorithm to handle uncertainties
in SNR's and fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1086</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1086</id><created>2010-10-06</created><authors><author><keyname>Bodini</keyname><forenames>Olivier</forenames></author><author><keyname>Fernique</keyname><forenames>Thomas</forenames></author><author><keyname>Regnault</keyname><forenames>Damien</forenames></author></authors><title>Stochastic Flips on Two-letter Words</title><categories>math.PR cond-mat.stat-mech cs.DM</categories><comments>ANALCO'10</comments><msc-class>60J10, 60C05, 52C23, 37A25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a simple Markov process inspired by the problem of
quasicrystal growth. It acts over two-letter words by randomly performing
\emph{flips}, a local transformation which exchanges two consecutive different
letters. More precisely, only the flips which do not increase the number of
pairs of consecutive identical letters are allowed. Fixed-points of such a
process thus perfectly alternate different letters. We show that the expected
number of flips to converge towards a fixed-point is bounded by $O(n^3)$ in the
worst-case and by $O(n^{5/2}\ln{n})$ in the average-case, where $n$ denotes the
length of the initial word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1101</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1101</id><created>2010-10-06</created><authors><author><keyname>Pospelov</keyname><forenames>Alexey</forenames></author></authors><title>Faster Polynomial Multiplication via Discrete Fourier Transforms</title><categories>cs.CC cs.DS</categories><comments>26 pages, submitted to a conference</comments><msc-class>65Y20, 68Q25, 11Y16</msc-class><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of polynomial multiplication over arbitrary fields.
We present a unified approach that generalizes all known asymptotically fastest
algorithms for this problem. In particular, the well-known algorithm for
multiplication of polynomials over fields supporting DFTs of large smooth
orders, Sch\&quot;onhage-Strassen's algorithm over arbitrary fields of
characteristic different from 2, Sch\&quot;onhage's algorithm over fields of
characteristic 2, and Cantor-Kaltofen's algorithm over arbitrary algebras---all
appear to be instances of this approach. We also obtain faster algorithms for
polynomial multiplication over certain fields which do not support DFTs of
large smooth orders.
  We prove that the Sch\&quot;onhage-Strassen's upper bound cannot be improved
further over the field of rational numbers if we consider only algorithms based
on consecutive applications of DFT, as all known fastest algorithms are. We
also explore the ways to transfer the recent F\&quot;urer's algorithm for integer
multiplication to the problem of polynomial multiplication over arbitrary
fields of positive characteristic.
  This work is inspired by the recent improvement for the closely related
problem of complexity of integer multiplication by F\&quot;urer and its consequent
modular arithmetic treatment due to De, Kurur, Saha, and Saptharishi. We
explore the barriers in transferring the techniques for solutions of one
problem to a solution of the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1108</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1108</id><created>2010-10-06</created><authors><author><keyname>Park</keyname><forenames>Cheolwoo</forenames></author><author><keyname>Hern&#xe1;ndez-Campos</keyname><forenames>Felix</forenames></author><author><keyname>Marron</keyname><forenames>J. S.</forenames></author><author><keyname>Jeffay</keyname><forenames>Kevin</forenames></author><author><keyname>Smith</keyname><forenames>F. Donelson</forenames></author></authors><title>Analysis of dependence among size, rate and duration in internet flows</title><categories>stat.AP cs.NI</categories><comments>Published in at http://dx.doi.org/10.1214/09-AOAS268 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS268</report-no><journal-ref>Annals of Applied Statistics 2010, Vol. 4, No. 1, 26-52</journal-ref><doi>10.1214/09-AOAS268</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we examine rigorously the evidence for dependence among data
size, transfer rate and duration in Internet flows. We emphasize two
statistical approaches for studying dependence, including Pearson's correlation
coefficient and the extremal dependence analysis method. We apply these methods
to large data sets of packet traces from three networks. Our major results show
that Pearson's correlation coefficients between size and duration are much
smaller than one might expect. We also find that correlation coefficients
between size and rate are generally small and can be strongly affected by
applying thresholds to size or duration. Based on Transmission Control Protocol
connection startup mechanisms, we argue that thresholds on size should be more
useful than thresholds on duration in the analysis of correlations. Using
extremal dependence analysis, we draw a similar conclusion, finding remarkable
independence for extremal values of size and rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1112</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1112</id><created>2010-10-06</created><authors><author><keyname>Barenboim</keyname><forenames>Leonid</forenames></author><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>Deterministic and Energy-Optimal Wireless Synchronization</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of clock synchronization in a wireless setting where
processors must power-down their radios in order to save energy. Energy
efficiency is a central goal in wireless networks, especially if energy
resources are severely limited. In the current setting, the problem is to
synchronize clocks of $m$ processors that wake up in arbitrary time points,
such that the maximum difference between wake up times is bounded by a positive
integer $n$, where time intervals are appropriately discretized. Currently, the
best-known results for synchronization for single-hop networks of $m$
processors is a randomized algorithm due to \cite{BKO09} of O(\sqrt {n /m}
\cdot poly-log(n)) awake times per processor and a lower bound of
Omega(\sqrt{n/m}) of the number of awake times needed per processor
\cite{BKO09}. The main open question left in their work is to close the
poly-log gap between the upper and the lower bound and to de-randomize their
probabilistic construction and eliminate error probability. This is exactly
what we do in this paper.
  That is, we show a {deterministic} algorithm with radio use of Theta(\sqrt {n
/m}) that never fails. We stress that our upper bound exactly matches the lower
bound proven in \cite{BKO09}, up to a small multiplicative constant. Therefore,
our algorithm is {optimal} in terms of energy efficiency and completely
resolves a long sequence of works in this area. In order to achieve these
results we devise a novel {adaptive} technique that determines the times when
devices power their radios on and off. In addition, we prove several lower
bounds on the energy efficiency of algorithms for {multi-hop networks}.
Specifically, we show that any algorithm for multi-hop networks must have radio
use of Omega(\sqrt n) per processor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1128</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1128</id><created>2010-10-06</created><updated>2011-06-09</updated><authors><author><keyname>Avanzini</keyname><forenames>Martin</forenames></author><author><keyname>Eguchi</keyname><forenames>Naohi</forenames></author><author><keyname>Moser</keyname><forenames>Georg</forenames></author></authors><title>A Path Order for Rewrite Systems that Compute Exponential Time Functions
  (Technical Report)</title><categories>cs.CC</categories><comments>Technical Report</comments><msc-class>03D15</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we present a new path order for rewrite systems, the
exponential path order EPOSTAR. Suppose a term rewrite system is compatible
with EPOSTAR, then the runtime complexity of this rewrite system is bounded
from above by an exponential function. Furthermore, the class of function
computed by a rewrite system compatible with EPOSTAR equals the class of
functions computable in exponential time on a Turing maschine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1139</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1139</id><created>2010-10-06</created><authors><author><keyname>Kara</keyname><forenames>Ahmet</forenames></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames></author><author><keyname>Zeume</keyname><forenames>Thomas</forenames></author></authors><title>Temporal Logics on Words with Multiple Data Values</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes and studies temporal logics for attributed words, that is,
data words with a (finite) set of (attribute,value)-pairs at each position. It
considers a basic logic which is a semantical fragment of the logic
$LTL^\downarrow_1$ of Demri and Lazic with operators for navigation into the
future and the past. By reduction to the emptiness problem for data automata it
is shown that this basic logic is decidable. Whereas the basic logic only
allows navigation to positions where a fixed data value occurs, extensions are
studied that also allow navigation to positions with different data values.
Besides some undecidable results it is shown that the extension by a certain
UNTIL-operator with an inequality target condition remains decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1147</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1147</id><created>2010-10-06</created><authors><author><keyname>Simalango</keyname><forenames>Mikael Fernandus</forenames></author></authors><title>XML Query Processing and Query Languges: A Survey</title><categories>cs.DB cs.DS</categories><comments>6 pages, 3 figures, 2 tables, written in 2008</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Today's database is associated with interoperability between different
domains and applications. This consequently results in the importance of data
portability in database. XML format fits the requirements and it has been
increasingly used for serving applications across different domains and
purposes. However, querying XML document effectively and efficiently is still a
challenging issue. This paper discusses query processing issues on XML and
reviews proposed solutions for querying XML databases by various authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1149</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1149</id><created>2010-10-06</created><updated>2011-03-04</updated><authors><author><keyname>Poggiolini</keyname><forenames>Laura</forenames></author><author><keyname>Spadini</keyname><forenames>Marco</forenames></author></authors><title>Bang--bang trajectories with a double switching time: sufficient strong
  local optimality conditions</title><categories>math.OC cs.SY</categories><comments>43 pages</comments><msc-class>49K15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives sufficient conditions for a class of bang-bang extremals
with multiple switches to be locally optimal in the strong topology. The
conditions are the natural generalizations of the ones considered in previous
papers for more specific cases. We require both the strict bang-bang Legendre
condition, and the second order conditions for the finite dimensional problem
obtained by moving the switching times of the reference trajectory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1163</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1163</id><created>2010-10-06</created><authors><author><keyname>Raghava</keyname><forenames>G. D.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Secrecy Capacity of the Gaussian Wire-Tap Channel with Finite Complex
  Constellation Input</title><categories>cs.IT math.IT</categories><comments>7 pages and 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secrecy capacity of a discrete memoryless Gaussian Wire-Tap Channel when
the input is from a finite complex constellation is studied. It is shown that
the secrecy capacity curves of a finite constellation plotted against the SNR,
for a fixed noise variance of the eavesdropper's channel has a global maximum
at an internal point. This is in contrast to what is known in the case of
Gaussian codebook input where the secrecy capacity curve is a bounded,
monotonically increasing function of SNR. Secrecy capacity curves for some well
known constellations like BPSK, 4-QAM, 16-QAM and 8-PSK are plotted and the SNR
at which the maximum occurs is found through simulation. It is conjectured that
the secrecy capacity curves for finite constellations have a single maximum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1221</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1221</id><created>2010-10-06</created><updated>2011-05-31</updated><authors><author><keyname>Choi</keyname><forenames>Vicky</forenames></author></authors><title>Different Adiabatic Quantum Optimization Algorithms for the NP-Complete
  Exact Cover and 3SAT Problems</title><categories>quant-ph cs.CC</categories><comments>This is the second part of article arXiv:quant-ph/1004.2226.
  References added</comments><journal-ref>Quantum Information and Computation, Vol. 11, No. 7&amp;8 (2011)
  0638-0648</journal-ref><doi>10.1073/pnas.1018310108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important questions in studying quantum computation is:
whether a quantum computer can solve NP-complete problems more efficiently than
a classical computer? In 2000, Farhi, et al. (Science, 292(5516):472--476,
2001) proposed the adiabatic quantum optimization (AQO), a paradigm that
directly attacks NP-hard optimization problems. How powerful is AQO? Early on,
van Dam and Vazirani claimed that AQO failed (i.e. would take exponential time)
for a family of 3SAT instances they constructed. More recently, Altshuler, et
al. (Proc Natl Acad Sci USA, 107(28): 12446--12450, 2010) claimed that AQO
failed also for random instances of the NP-complete Exact Cover problem. In
this paper, we make clear that all these negative results are only for a
specific AQO algorithm. We do so by demonstrating different AQO algorithms for
the same problem for which their arguments no longer hold. Whether AQO fails or
succeeds for solving the NP-complete problems (either the worst case or the
average case) requires further investigation. Our AQO algorithms for Exact
Cover and 3SAT are based on the polynomial reductions to the NP-complete
Maximum-weight Independent Set (MIS) problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1234</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1234</id><created>2010-10-06</created><updated>2012-05-31</updated><authors><author><keyname>Sorkin</keyname><forenames>Arthur</forenames></author><author><keyname>Donovan</keyname><forenames>Peter</forenames></author></authors><title>LR(1) Parser Generation System: LR(1) Error Recovery, Oracles, and
  Generic Tokens</title><categories>cs.PL cs.FL</categories><comments>6 pages</comments><msc-class>68N20</msc-class><acm-class>D.3.4; F.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The LR(1) Parser Generation System generates full LR(1) parsers that are
comparable in speed and size to those generated by LALR(1) parser generators,
such as yacc [5]. LR contains a number of novel feature. This paper discusses
three of them in detail: an LR(1) grammar specified automatic error recovery
algorithm, oracles, and generic tokens.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1256</identifier>
 <datestamp>2014-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1256</id><created>2010-10-06</created><updated>2013-05-15</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Hsieh</keyname><forenames>Min-Hsiu</forenames></author><author><keyname>Babar</keyname><forenames>Zunaira</forenames></author></authors><title>Entanglement-assisted quantum turbo codes</title><categories>quant-ph cs.IT math.IT</categories><comments>31 pages, software for simulating EA turbo codes is available at
  http://code.google.com/p/ea-turbo/ and a presentation is available at
  http://markwilde.com/publications/10-10-EA-Turbo.ppt ; v2, revisions based on
  feedback from journal; v3, modification of the quantum turbo decoding
  algorithm that leads to improved performance over results in v2 and the
  results of Poulin et al. in arXiv:0712.2888</comments><journal-ref>IEEE Transactions on Information Theory vol. 60, no. 2, pages
  1203-1222 (February 2014)</journal-ref><doi>10.1109/TIT.2013.2292052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An unexpected breakdown in the existing theory of quantum serial turbo coding
is that a quantum convolutional encoder cannot simultaneously be recursive and
non-catastrophic. These properties are essential for quantum turbo code
families to have a minimum distance growing with blocklength and for their
iterative decoding algorithm to converge, respectively. Here, we show that the
entanglement-assisted paradigm simplifies the theory of quantum turbo codes, in
the sense that an entanglement-assisted quantum (EAQ) convolutional encoder can
possess both of the aforementioned desirable properties. We give several
examples of EAQ convolutional encoders that are both recursive and
non-catastrophic and detail their relevant parameters. We then modify the
quantum turbo decoding algorithm of Poulin et al., in order to have the
constituent decoders pass along only &quot;extrinsic information&quot; to each other
rather than a posteriori probabilities as in the decoder of Poulin et al., and
this leads to a significant improvement in the performance of unassisted
quantum turbo codes. Other simulation results indicate that
entanglement-assisted turbo codes can operate reliably in a noise regime 4.73
dB beyond that of standard quantum turbo codes, when used on a memoryless
depolarizing channel. Furthermore, several of our quantum turbo codes are
within 1 dB or less of their hashing limits, so that the performance of quantum
turbo codes is now on par with that of classical turbo codes. Finally, we prove
that entanglement is the resource that enables a convolutional encoder to be
both non-catastrophic and recursive because an encoder acting on only
information qubits, classical bits, gauge qubits, and ancilla qubits cannot
simultaneously satisfy them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1260</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1260</id><created>2010-10-06</created><authors><author><keyname>Hupca</keyname><forenames>Ioan O.</forenames></author><author><keyname>Falcou</keyname><forenames>Joel</forenames></author><author><keyname>Grigori</keyname><forenames>Laura</forenames></author><author><keyname>Stompor</keyname><forenames>Radek</forenames></author></authors><title>Spherical harmonic transform with GPUs</title><categories>cs.DC astro-ph.CO</categories><report-no>INRIA technical report 7409</report-no><journal-ref>Proceedings of Euro-Par 2011, Lecture Notes in Computer Science,
  2012, Vol. 7155/2012, p. 355</journal-ref><doi>10.1007/978-3-642-29737-3_40</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm for computing an inverse spherical harmonic
transform suitable for graphic processing units (GPU). We use CUDA and base our
implementation on a Fortran90 routine included in a publicly available parallel
package, S2HAT. We focus our attention on the two major sequential steps
involved in the transforms computation, retaining the efficient parallel
framework of the original code. We detail optimization techniques used to
enhance the performance of the CUDA-based code and contrast them with those
implemented in the Fortran90 version. We also present performance comparisons
of a single CPU plus GPU unit with the S2HAT code running on either a single or
4 processors. In particular we find that use of the latest generation of GPUs,
such as NVIDIA GF100 (Fermi), can accelerate the spherical harmonic transforms
by as much as 18 times with respect to S2HAT executed on one core, and by as
much as 5.5 with respect to S2HAT on 4 cores, with the overall performance
being limited by the Fast Fourier transforms. The work presented here has been
performed in the context of the Cosmic Microwave Background simulations and
analysis. However, we expect that the developed software will be of more
general interest and applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1286</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1286</id><created>2010-10-06</created><authors><author><keyname>Kieffer</keyname><forenames>John</forenames></author><author><keyname>Liao</keyname><forenames>Yu</forenames></author></authors><title>Exact Hamming Distortion Analysis of Viterbi Encoded Trellis Coded
  Quantizers</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a finite strongly connected aperiodic directed graph in which each
edge carries a label from a finite alphabet A. Then G induces a trellis coded
quantizer for encoding an alphabet A memoryless source. A source sequence of
long finite length is encoded by finding a path in G of that length whose
sequence of labels is closest in Hamming distance to the source sequence;
finding the minimum distance path is a dynamic programming problem that is
solved using the Viterbi algorithm. We show how a Markov chain can be used to
obtain a closed form expression for the asymptotic expected Hamming distortion
per sample that results as the number of encoded source samples increases
without bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1295</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1295</id><created>2010-10-06</created><authors><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Optimal Packet Scheduling in an Energy Harvesting Communication System</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted to IEEE Transactions on Communications, June 2010.
  Conference version appeared in CISS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the optimal packet scheduling problem in a single-user energy
harvesting wireless communication system. In this system, both the data packets
and the harvested energy are modeled to arrive at the source node randomly. Our
goal is to adaptively change the transmission rate according to the traffic
load and available energy, such that the time by which all packets are
delivered is minimized. Under a deterministic system setting, we assume that
the energy harvesting times and harvested energy amounts are known before the
transmission starts. For the data traffic arrivals, we consider two different
scenarios. In the first scenario, we assume that all bits have arrived and are
ready at the transmitter before the transmission starts. In the second
scenario, we consider the case where packets arrive during the transmissions,
with known arrival times and sizes. We develop optimal off-line scheduling
policies which minimize the time by which all packets are delivered to the
destination, under causality constraints on both data and energy arrivals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1303</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1303</id><created>2010-10-06</created><authors><author><keyname>Nazari</keyname><forenames>Ali</forenames></author><author><keyname>Anastasopoulos</keyname><forenames>Achilleas</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>Error Exponent for Multiple-Access Channels:Lower Bounds</title><categories>cs.IT math.IT</categories><comments>46 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A unified framework to obtain all known lower bounds (random coding, typical
random coding and expurgated bound) on the reliability function of a
point-to-point discrete memoryless channel (DMC) is presented. By using a
similar idea for a two-user discrete memoryless (DM) multiple-access channel
(MAC), three lower bounds on the reliability function are derived. The first
one (random coding) is identical to the best known lower bound on the
reliability function of DM-MAC. It is shown that the random coding bound is the
performance of the average code in the constant composition code ensemble. The
second bound (Typical random coding) is the typical performance of the constant
composition code ensemble. To derive the third bound (expurgated), we eliminate
some of the codewords from the codebook with larger rate. This is the first
bound of this type that explicitly uses the method of expurgation for MACs. It
is shown that the exponent of the typical random coding and the expurgated
bounds are greater than or equal to the exponent of the known random coding
bounds for all rate pairs. Moreover, an example is given where the exponent of
the expurgated bound is strictly larger. All these bounds can be universally
obtained for all discrete memoryless MACs with given input and output
alphabets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1309</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1309</id><created>2010-10-06</created><authors><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Probing Capacity</title><categories>cs.IT math.IT</categories><comments>20 pages, Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of optimal probing of states of a channel by
transmitter and receiver for maximizing rate of reliable communication. The
channel is discrete memoryless (DMC) with i.i.d. states. The encoder takes
probing actions dependent on the message. It then uses the state information
obtained from probing causally or non-causally to generate channel input
symbols. The decoder may also take channel probing actions as a function of the
observed channel output and use the channel state information thus acquired,
along with the channel output, to estimate the message. We refer to the maximum
achievable rate for reliable communication for such systems as the 'Probing
Capacity'. We characterize this capacity when the encoder and decoder actions
are cost constrained. To motivate the problem, we begin by characterizing the
trade-off between the capacity and fraction of channel states the encoder is
allowed to observe, while the decoder is aware of channel states. In this
setting of 'to observe or not to observe' state at the encoder, we compute
certain numerical examples and note a pleasing phenomenon, where encoder can
observe a relatively small fraction of states and yet communicate at maximum
rate, i.e. rate when observing states at encoder is not cost constrained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1316</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1316</id><created>2010-10-06</created><updated>2011-05-02</updated><authors><author><keyname>Heeringa</keyname><forenames>Brent</forenames></author><author><keyname>Iordan</keyname><forenames>Marius Catalin</forenames></author><author><keyname>Theran</keyname><forenames>Louis</forenames></author></authors><title>Searching in Dynamic Tree-Like Partial Orders</title><categories>cs.DS cs.DM</categories><comments>51 pages, 30 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first data structure for the problem of maintaining a dynamic set
of n elements drawn from a partially ordered universe described by a tree. We
define the Line-Leaf Tree, a linear-sized data structure that supports the
operations: insert; delete; test membership; and predecessor. The performance
of our data structure is within an O(log w)-factor of optimal. Here w &lt;= n is
the width of the partial-order---a natural obstacle in searching a partial
order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1317</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1317</id><created>2010-10-06</created><updated>2010-10-08</updated><authors><author><keyname>Nazari</keyname><forenames>Ali</forenames></author><author><keyname>Venkataramanan</keyname><forenames>Ramji</forenames></author><author><keyname>Krithivasan</keyname><forenames>Dinesh</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author><author><keyname>Anastasopoulos</keyname><forenames>Achilleas</forenames></author></authors><title>Typicality Graphs:Large Deviation Analysis</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{X}$ and $\mathcal{Y}$ be finite alphabets and $P_{XY}$ a joint
distribution over them, with $P_X$ and $P_Y$ representing the marginals. For
any $\epsilon &gt; 0$, the set of $n$-length sequences $x^n$ and $y^n$ that are
jointly typical \cite{ckbook} according to $P_{XY}$ can be represented on a
bipartite graph. We present a formal definition of such a graph, known as a
\emph{typicality} graph, and study some of its properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1322</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1322</id><created>2010-10-07</created><authors><author><keyname>Nazari</keyname><forenames>Ali</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author><author><keyname>Anastasopoulos</keyname><forenames>Achilleas</forenames></author></authors><title>A New Upper Bound on the Average Error Exponent for Multiple-Access
  Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new lower bound for the average probability or error for a two-user
discrete memoryless (DM) multiple-access channel (MAC) is derived. This bound
has a structure very similar to the well-known sphere packing packing bound
derived by Haroutunian. However, since explicitly imposes independence of the
users' input distributions (conditioned on the time-sharing auxiliary variable)
results in a tighter sphere-packing exponent in comparison to Haroutunian's.
Also, the relationship between average and maximal error probabilities is
studied. Finally, by using a known sphere packing bound on the maximal
probability of error, a lower bound on the average error probability is
derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1328</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1328</id><created>2010-10-07</created><updated>2011-04-15</updated><authors><author><keyname>Joosten</keyname><forenames>Joost J.</forenames></author><author><keyname>Soler-Toscano</keyname><forenames>Fernando</forenames></author><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Complejidad descriptiva y computacional en maquinas de Turing pequenas</title><categories>cs.CC cs.IT math.IT</categories><comments>Art\'iculo en espa\~nol. Actas de las V Jornadas Ib\'ericas, L\'ogica
  Universal e Unidade da Ciencia, CFCUL, 2010. 20 pages, 22 figures, 3 tables;
  Keywords: small Turing machines, Program-size complexity, Kolmogorov-Chaitin
  complexity, space-time complexity, computational complexity, algorithmic
  complexity, geometric complexity</comments><acm-class>D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We start by an introduction to the basic concepts of computability theory and
the introduction of the concept of Turing machine and computation universality.
Then se turn to the exploration of trade-offs between different measures of
complexity, particularly algorithmic (program-size) and computational (time)
complexity as a mean to explain these measure in a novel manner. The
investigation proceeds by an exhaustive exploration and systematic study of the
functions computed by a large set of small Turing machines with 2 and 3 states
with particular attention to runtimes, space-usages and patterns corresponding
to the computed functions when the machines have access to larger resources
(more states).
  We report that the average runtime of Turing machines computing a function
increases as a function of the number of states, indicating that non-trivial
machines tend to occupy all the resources at hand. General slow-down was
witnessed and some incidental cases of (linear) speed-up were found. Throughout
our study various interesting structures were encountered. We unveil a study of
structures in the micro-cosmos of small Turing machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1331</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1331</id><created>2010-10-07</created><authors><author><keyname>Shi</keyname><forenames>Cuizhu</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author></authors><title>Improved Combinatorial Algorithms for Wireless Information Flow</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, presented at Allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work of Avestimehr et al. '07 has recently proposed a deterministic model
for wireless networks and characterized the unicast capacity C of such networks
as the minimum rank of the adjacency matrices describing all possible
source-destination cuts. Amaudruz &amp; Fragouli first proposed a polynomial-time
algorithm for finding the unicast capacity of a linear deterministic wireless
network in their 2009 paper. In this work, we improve upon Amaudruz &amp;
Fragouli's work and further reduce the computational complexity of the
algorithm by fully exploring the useful combinatorial features intrinsic in the
problem. Our improvement applies generally with any size of finite fields
associated with the channel model. Comparing with other algorithms on solving
the same problem, our improved algorithm is very competitive in terms of
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1358</identifier>
 <datestamp>2013-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1358</id><created>2010-10-07</created><updated>2013-08-10</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Tight exponential analysis of universally composable privacy
  amplification and its applications</title><categories>cs.IT cs.CR math.IT</categories><comments>Several errors are fixed. The title is slightly changed. The topic
  and protocol are similar to those in arXiv:0904.0308. However, the security
  criterion of this paper is different from arXiv:0904.0308. This paper adopts
  the universal composability while arXiv:0904.0308 adopts the mutual
  information criterion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the desirability of universal composability, we analyze in terms
of L_1 distinguishability the task of secret key generation from a joint random
variable. Under this secrecy criterion, using the Renyi entropy of order 1+s
for s in [0,1, we derive a new upper bound of Eve's distinguishability under
the application of the universal2 hash functions. It is also shown that this
bound gives the tight exponential rate of decrease in the case of independent
and identical distributions. The result is applied to the wire-tap channel
model and to secret key generation (distillation) by public discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1365</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1365</id><created>2010-10-07</created><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Misra</keyname><forenames>Neeldhara</forenames></author><author><keyname>Philip</keyname><forenames>Geevarghese</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Hitting forbidden minors: Approximation and Kernelization</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a general class of problems called F-deletion problems. In an
F-deletion problem, we are asked whether a subset of at most $k$ vertices can
be deleted from a graph $G$ such that the resulting graph does not contain as a
minor any graph from the family F of forbidden minors.
  We obtain a number of algorithmic results on the F-deletion problem when F
contains a planar graph. We give (1) a linear vertex kernel on graphs excluding
$t$-claw $K_{1,t}$, the star with $t$ leves, as an induced subgraph, where $t$
is a fixed integer. (2) an approximation algorithm achieving an approximation
ratio of $O(\log^{3/2} OPT)$, where $OPT$ is the size of an optimal solution on
general undirected graphs. Finally, we obtain polynomial kernels for the case
when F contains graph $\theta_c$ as a minor for a fixed integer $c$. The graph
$\theta_c$ consists of two vertices connected by $c$ parallel edges. Even
though this may appear to be a very restricted class of problems it already
encompasses well-studied problems such as {\sc Vertex Cover}, {\sc Feedback
Vertex Set} and Diamond Hitting Set. The generic kernelization algorithm is
based on a non-trivial application of protrusion techniques, previously used
only for problems on topological graph classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1386</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1386</id><created>2010-10-07</created><authors><author><keyname>Berberich</keyname><forenames>Eric</forenames></author><author><keyname>Emeliyanenko</keyname><forenames>Pavel</forenames></author><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>An Elimination Method for Solving Bivariate Polynomial Systems:
  Eliminating the Usual Drawbacks</title><categories>cs.MS cs.SC math.AC math.AG</categories><comments>16 pages with appendix, 1 figure, submitted to ALENEX 2010</comments><msc-class>68W30 (Primary), 13P15 (Secondary)</msc-class><acm-class>G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an exact and complete algorithm to isolate the real solutions of a
zero-dimensional bivariate polynomial system. The proposed algorithm
constitutes an elimination method which improves upon existing approaches in a
number of points. First, the amount of purely symbolic operations is
significantly reduced, that is, only resultant computation and square-free
factorization is still needed. Second, our algorithm neither assumes generic
position of the input system nor demands for any change of the coordinate
system. The latter is due to a novel inclusion predicate to certify that a
certain region is isolating for a solution. Our implementation exploits
graphics hardware to expedite the resultant computation. Furthermore, we
integrate a number of filtering techniques to improve the overall performance.
Efficiency of the proposed method is proven by a comparison of our
implementation with two state-of-the-art implementations, that is, LPG and
Maple's isolate. For a series of challenging benchmark instances, experiments
show that our implementation outperforms both contestants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1391</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1391</id><created>2010-10-07</created><authors><author><keyname>Muralidhar</keyname><forenames>Kathik</forenames></author><author><keyname>Li</keyname><forenames>Kwok Hung</forenames></author></authors><title>On the Full Column-Rank Condition of the Channel Estimation Matrix in
  Doubly-Selective MIMO-OFDM Systems</title><categories>cs.IT math.IT</categories><comments>19 Pages, 4 figures, currently under review in IEEE Transactions
  Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, this journal has published a paper which dealt with basis expansion
model (BEM) based least-squares (LS) channel estimation in doubly-selective
orthogonal frequency-division multiplexing (DS-OFDM) systems. The least-squares
channel estimator computes the pseudo-inverse of a channel estimation matrix.
For the existence of the pseudo-inverse, it is necessary that the channel
estimation matrix be of full column rank. In this paper, we investigate the
conditions that need to be satisfied that ensures the full column-rank
condition of the channel estimation matrix. In particular, we derive conditions
that the BEM and pilot pattern designs should satisfy to ensure that the
channel estimation matrix is of full column rank. We explore the polynomial BEM
(P-BEM), complex exponential BEM (CE-BEM), Slepian BEM (S-BEM) and generalized
complex exponential BEM (GCE-BEM). We present one possible way to design the
pilot patterns which satisfy the full column-rank conditions. Furthermore, the
proposed method is extended to the case of multiple-input multiple-output
(MIMO) DS-OFDM systems as well. Examples of pilot pattern designs are
presented, that ensure the channel estimation matrix is of full column rank for
a large DS-MIMO-OFDM system with as many as six transmitters, six receivers and
1024 subcarriers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1416</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1416</id><created>2010-10-07</created><authors><author><keyname>Chacc</keyname><forenames>Eric Goles</forenames></author><author><keyname>Martin</keyname><forenames>Bruno</forenames></author></authors><title>Computational Complexity of Avalanches in the Kadanoff two-dimensional
  Sandpile Model</title><categories>cs.DM math.DS</categories><comments>15 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove that the avalanche problem for Kadanoff sandpile model
(KSPM) is P-complete for two-dimensions. Our proof is based on a reduction from
the monotone circuit value problem by building logic gates and wires which work
with configurations in KSPM. The proof is also related to the known prediction
problem for sandpile which is in NC for one-dimensional sandpiles and is
P-complete for dimension 3 or greater. The computational complexity of the
prediction problem remains open for two-dimensional sandpiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1429</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1429</id><created>2010-10-07</created><updated>2010-10-14</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Jansen</keyname><forenames>Thomas</forenames></author><author><keyname>Sudholt</keyname><forenames>Dirk</forenames></author><author><keyname>Winzen</keyname><forenames>Carola</forenames></author><author><keyname>Zarges</keyname><forenames>Christine</forenames></author></authors><title>Optimizing Monotone Functions Can Be Difficult</title><categories>cs.NE</categories><comments>Preliminary version appeared at PPSN XI. Compared to version 1, a
  small bug in the constants was fixed ($\gamma$ is slightly larger now, thus
  ensuring that $\gamma$ is now strictly larger than $\rho$ in Lemma 5)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extending previous analyses on function classes like linear functions, we
analyze how the simple (1+1) evolutionary algorithm optimizes pseudo-Boolean
functions that are strictly monotone. Contrary to what one would expect, not
all of these functions are easy to optimize. The choice of the constant $c$ in
the mutation probability $p(n) = c/n$ can make a decisive difference.
  We show that if $c &lt; 1$, then the (1+1) evolutionary algorithm finds the
optimum of every such function in $\Theta(n \log n)$ iterations. For $c=1$, we
can still prove an upper bound of $O(n^{3/2})$. However, for $c &gt; 33$, we
present a strictly monotone function such that the (1+1) evolutionary algorithm
with overwhelming probability does not find the optimum within $2^{\Omega(n)}$
iterations. This is the first time that we observe that a constant factor
change of the mutation probability changes the run-time by more than constant
factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1437</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1437</id><created>2010-10-07</created><authors><author><keyname>Shafiei</keyname><forenames>Mahdi</forenames></author><author><keyname>Chipman</keyname><forenames>Hugh</forenames></author></authors><title>Mixed-Membership Stochastic Block-Models for Transactional Networks</title><categories>stat.ML cs.AI cs.SI stat.AP stat.ME</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transactional network data can be thought of as a list of one-to-many
communications(e.g., email) between nodes in a social network. Most social
network models convert this type of data into binary relations between pairs of
nodes. We develop a latent mixed membership model capable of modeling richer
forms of transactional network data, including relations between more than two
nodes. The model can cluster nodes and predict transactions. The block-model
nature of the model implies that groups can be characterized in very general
ways. This flexible notion of group structure enables discovery of rich
structure in transactional networks. Estimation and inference are accomplished
via a variational EM algorithm. Simulations indicate that the learning
algorithm can recover the correct generative model. Interesting structure is
discovered in the Enron email dataset and another dataset extracted from the
Reddit website. Analysis of the Reddit data is facilitated by a novel
performance measure for comparing two soft clusterings. The new model is
superior at discovering mixed membership in groups and in predicting
transactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1438</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1438</id><created>2010-10-07</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author></authors><title>Coalition Formation Games for Distributed Cooperation Among Roadside
  Units in Vehicular Networks</title><categories>cs.IT cs.GT cs.SY math.IT</categories><comments>accepted and to appear in IEEE Journal on Selected Areas in
  Communications (JSAC), Special issue on Vehicular Communications and Networks</comments><journal-ref>IEEE Journal on Selected Areas in Communications (JSAC), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicle-to-roadside (V2R) communications enable vehicular networks to support
a wide range of applications for enhancing the efficiency of road
transportation. While existing work focused on non-cooperative techniques for
V2R communications between vehicles and roadside units (RSUs), this paper
investigates novel cooperative strategies among the RSUs in a vehicular
network. We propose a scheme whereby, through cooperation, the RSUs in a
vehicular network can coordinate the classes of data being transmitted through
V2R communications links to the vehicles. This scheme improves the diversity of
the information circulating in the network while exploiting the underlying
content-sharing vehicle-to-vehicle communication network. We model the problem
as a coalition formation game with transferable utility and we propose an
algorithm for forming coalitions among the RSUs. For coalition formation, each
RSU can take an individual decision to join or leave a coalition, depending on
its utility which accounts for the generated revenues and the costs for
coalition coordination. We show that the RSUs can self-organize into a
Nash-stable partition and adapt this partition to environmental changes.
Simulation results show that, depending on different scenarios, coalition
formation presents a performance improvement, in terms of the average payoff
per RSU, ranging between 20.5% and 33.2%, relative to the non-cooperative case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1456</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1456</id><created>2010-10-07</created><authors><author><keyname>Wei</keyname><forenames>Fangzhou</forenames></author><author><keyname>Y&#x131;lmaz</keyname><forenames>Ali E.</forenames></author></authors><title>A Hybrid Parallelization of AIM for Multi-Core Clusters: Implementation
  Details and Benchmark Results on Ranger</title><categories>cs.CE cs.MS</categories><comments>24 pages, 3 tables, 9 figures. Due to space constraints, some
  implementation details and empirical data are omitted in authors' another
  paper (reference [1]), which has been submitted to Parallel Computing. This
  paper here serves as a major reference with the implementation details and
  comprehensive empirical data</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents implementation details and empirical results for a hybrid
message passing and shared memory paralleliziation of the adaptive integral
method (AIM). AIM is implemented on a (near) petaflop supercomputing cluster of
quad-core processors and its accuracy, complexity, and scalability are
investigated by solving benchmark scattering problems. The timing and speedup
results on up to 1024 processors show that the hybrid MPI/OpenMP
parallelization of AIM exhibits better strong scalability (fixed problem size
speedup) than pure MPI parallelization of it when multiple cores are used on
each processor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1481</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1481</id><created>2010-10-07</created><authors><author><keyname>Austrin</keyname><forenames>Per</forenames></author><author><keyname>Khot</keyname><forenames>Subhash</forenames></author></authors><title>A Simple Deterministic Reduction for the Gap Minimum Distance of Code
  Problem</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple deterministic gap-preserving reduction from SAT to the
Minimum Distance of Code Problem over $\F_2$. We also show how to extend the
reduction to work over any finite field. Previously a randomized reduction was
known due to Dumer, Micciancio, and Sudan, which was recently derandomized by
Cheng and Wan. These reductions rely on highly non-trivial coding theoretic
constructions whereas our reduction is elementary.
  As an additional feature, our reduction gives a constant factor hardness even
for asymptotically good codes, i.e., having constant rate and relative
distance. Previously it was not known how to achieve deterministic reductions
for such codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1496</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1496</id><created>2010-10-07</created><authors><author><keyname>Singh</keyname><forenames>Vishwakarma</forenames></author><author><keyname>Singh</keyname><forenames>Ambuj K.</forenames></author></authors><title>Profile Based Sub-Image Search in Image Databases</title><categories>cs.CV cs.IR cs.MM</categories><comments>Sub-Image Retrieval, New Feature Vector, Similarity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sub-image search with high accuracy in natural images still remains a
challenging problem. This paper proposes a new feature vector called profile
for a keypoint in a bag of visual words model of an image. The profile of a
keypoint captures the spatial geometry of all the other keypoints in an image
with respect to itself, and is very effective in discriminating true matches
from false matches. Sub-image search using profiles is a single-phase process
requiring no geometric validation, yields high precision on natural images, and
works well on small visual codebook. The proposed search technique differs from
traditional methods that first generate a set of candidates disregarding
spatial information and then verify them geometrically. Conventional methods
also use large codebooks. We achieve a precision of 81% on a combined data set
of synthetic and real natural images using a codebook size of 500 for top-10
queries; that is 31% higher than the conventional candidate generation
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1499</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1499</id><created>2010-10-07</created><updated>2012-06-29</updated><authors><author><keyname>Maddah-Ali</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Completely Stale Transmitter Channel State Information is Still Very
  Useful</title><categories>cs.IT math.IT</categories><comments>Initially reported as Technical Report No. UCB/EECS-2010-122 at the
  University of California--Berkeley, Sept. 6, 2010. Presented at the
  Forty-Eighth Annual Allerton Conference, Sept. 2010. Accepted for IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmitter channel state information (CSIT) is crucial for the multiplexing
gains offered by advanced interference management techniques such as multiuser
MIMO and interference alignment. Such CSIT is usually obtained by feedback from
the receivers, but the feedback is subject to delays. The usual approach is to
use the fed back information to predict the current channel state and then
apply a scheme designed assuming perfect CSIT. When the feedback delay is large
compared to the channel coherence time, such a prediction approach completely
fails to achieve any multiplexing gain. In this paper, we show that even in
this case, the completely stale CSI is still very useful. More concretely, we
show that in a MIMO broadcast channel with $K$ transmit antennas and $K$
receivers each with 1 receive antenna, $\frac{K}{1+1/2+ ...+ \frac{1}{K}} (&gt; 1)
$ degrees of freedom is achievable even when the fed back channel state is
completely independent of the current channel state. Moreover, we establish
that if all receivers have independent and identically distributed channels,
then this is the optimal number of degrees of freedom achievable. In the
optimal scheme, the transmitter uses the fed back CSI to learn the side
information that the receivers receive from previous transmissions rather than
to predict the current channel state. Our result can be viewed as the first
example of feedback providing a degree-of-freedom gain in memoryless channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1508</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1508</id><created>2010-10-07</created><authors><author><keyname>Prasad</keyname><forenames>Sudhakar</forenames></author></authors><title>Certain Relations between Mutual Information and Fidelity of Statistical
  Estimation</title><categories>stat.AP cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I present several new relations between mutual information (MI) and
statistical estimation error for a system that can be regarded simultaneously
as a communication channel and as an estimator of an input parameter. I first
derive a second-order result between MI and Fisher information (FI) that is
valid for sufficiently narrow priors, but arbitrary channels. A second relation
furnishes a lower bound on the MI in terms of the minimum mean-squared error
(MMSE) on the Bayesian estimation of the input parameter from the channel
output, one that is valid for arbitrary channels and priors. The existence of
such a lower bound, while extending previous work relating the MI to the FI
that is valid only in the asymptotic and high-SNR limits, elucidates further
the fundamental connection between information and estimation theoretic
measures of fidelity. The remaining relations I present are inequalities and
correspondences among MI, FI, and MMSE in the presence of nuisance parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1514</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1514</id><created>2010-10-07</created><updated>2010-10-26</updated><authors><author><keyname>Lagorio</keyname><forenames>C.</forenames></author><author><keyname>Dickison</keyname><forenames>M.</forenames></author><author><keyname>Vazquez</keyname><forenames>F.</forenames></author><author><keyname>Braunstein</keyname><forenames>L. A.</forenames></author><author><keyname>Macri</keyname><forenames>P. A.</forenames></author><author><keyname>Migueles</keyname><forenames>M. V.</forenames></author><author><keyname>Havlin</keyname><forenames>S.</forenames></author><author><keyname>Stanley</keyname><forenames>H. E.</forenames></author></authors><title>Quarantine generated phase transition in epidemic spreading</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.bio-ph</categories><comments>13 pages, 6 figures</comments><doi>10.1103/PhysRevE.83.026102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the critical effect of quarantine on the propagation of epidemics on
an adaptive network of social contacts. For this purpose, we analyze the
susceptible-infected-recovered (SIR) model in the presence of quarantine, where
susceptible individuals protect themselves by disconnecting their links to
infected neighbors with probability w, and reconnecting them to other
susceptible individuals chosen at random. Starting from a single infected
individual, we show by an analytical approach and simulations that there is a
phase transition at a critical rewiring (quarantine) threshold w_c separating a
phase (w&lt;w_c) where the disease reaches a large fraction of the population,
from a phase (w &gt;= w_c) where the disease does not spread out. We find that in
our model the topology of the network strongly affects the size of the
propagation, and that w_c increases with the mean degree and heterogeneity of
the network. We also find that w_c is reduced if we perform a preferential
rewiring, in which the rewiring probability is proportional to the degree of
infected nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1523</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1523</id><created>2010-10-07</created><updated>2011-02-10</updated><authors><author><keyname>Gregory</keyname><forenames>Steve</forenames></author></authors><title>Fuzzy overlapping communities in networks</title><categories>physics.soc-ph cs.SI</categories><journal-ref>J. Stat. Mech. P02017 (2011)</journal-ref><doi>10.1088/1742-5468/2011/02/P02017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks commonly exhibit a community structure, whereby groups of vertices
are more densely connected to each other than to other vertices. Often these
communities overlap, such that each vertex may occur in more than one
community. However, two distinct types of overlapping are possible: crisp
(where each vertex belongs fully to each community of which it is a member) and
fuzzy (where each vertex belongs to each community to a different extent). We
investigate the effects of the fuzziness of community overlap. We find that it
has a strong effect on the performance of community detection methods: some
algorithms perform better with fuzzy overlapping while others favour crisp
overlapping. We also evaluate the performance of some algorithms that recover
the belonging coefficients when the overlap is fuzzy. Finally, we investigate
whether real networks contain fuzzy or crisp overlapping.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1524</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1524</id><created>2010-10-07</created><authors><author><keyname>Thouin</keyname><forenames>Frederic</forenames></author><author><keyname>Coates</keyname><forenames>Mark</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author></authors><title>Real-Time Multi-path Tracking of Probabilistic Available Bandwidth</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications such as traffic engineering and network provisioning can greatly
benefit from knowing, in real time, what is the largest input rate at which it
is possible to transmit on a given path without causing congestion. We consider
a probabilistic formulation for available bandwidth where the user specifies
the probability of achieving an output rate almost as large as the input rate.
We are interested in estimating and tracking the network-wide probabilistic
available bandwidth (PAB) on multiple paths simultaneously with minimal
overhead on the network. We propose a novel framework based on chirps, Bayesian
inference, belief propagation and active sampling to estimate the PAB. We also
consider the time evolution of the PAB by forming a dynamic model and designing
a tracking algorithm based on particle filters. We implement our method in a
lightweight and practical tool that has been deployed on the PlanetLab network
to do online experiments. We show through these experiments and simulations
that our approach outperforms block-based algorithms in terms of input rate
cost and probability of successful transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1526</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1526</id><created>2010-10-07</created><updated>2012-07-02</updated><authors><author><keyname>Prekopcs&#xe1;k</keyname><forenames>Zolt&#xe1;n</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Time Series Classification by Class-Specific Mahalanobis Distance
  Measures</title><categories>cs.LG</categories><journal-ref>Advances in Data Analysis and Classification 6 (3), 2012</journal-ref><doi>10.1007/s11634-012-0110-6</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  To classify time series by nearest neighbors, we need to specify or learn one
or several distance measures. We consider variations of the Mahalanobis
distance measures which rely on the inverse covariance matrix of the data.
Unfortunately --- for time series data --- the covariance matrix has often low
rank. To alleviate this problem we can either use a pseudoinverse, covariance
shrinking or limit the matrix to its diagonal. We review these alternatives and
benchmark them against competitive methods such as the related Large Margin
Nearest Neighbor Classification (LMNN) and the Dynamic Time Warping (DTW)
distance. As we expected, we find that the DTW is superior, but the Mahalanobis
distance measures are one to two orders of magnitude faster. To get best
results with Mahalanobis distance measures, we recommend learning one distance
measure per class using either covariance shrinking or the diagonal approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1561</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1561</id><created>2010-10-07</created><updated>2011-07-02</updated><authors><author><keyname>Brautbar</keyname><forenames>Mickey</forenames></author><author><keyname>Kearns</keyname><forenames>Michael</forenames></author></authors><title>A Clustering Coefficient Network Formation Game</title><categories>cs.SI cs.DS cs.GT physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the most up-to-date version please visit
http://www.cis.upenn.edu/~brautbar/ccgame.pdf
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1583</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1583</id><created>2010-10-07</created><authors><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author><author><keyname>Dhinakaran</keyname><forenames>Cynthia</forenames></author><author><keyname>Lee</keyname><forenames>Jae Kwang</forenames></author></authors><title>Multi Layer Approach to Defend DDoS Attacks Caused by Spam</title><categories>cs.CR cs.NI</categories><comments>6 pages,5 figures,MUE 2007, IEEE CS</comments><journal-ref>MUE 2007, IEEE CS</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Corporate mail services are designed to perform better than public mail
services. Fast mail delivery, large size file transfer as an attachments, high
level spam and virus protection, commercial advertisement free environment are
some of the advantages worth to mention. But these mail services are frequent
target of hackers and spammers. Distributed Denial of service attacks are
becoming more common and sophisticated. The researchers have proposed various
solutions to the DDOS attacks. Can we stop these kinds of attacks with
available technology? These days the DDoS attack through spam has increased and
disturbed the mail services of various organizations. Spam penetrates through
all the filters to establish DDoS attacks, which causes serious problems to
users and the data. In this paper we propose a multilayer approach to defend
DDoS attack caused by spam mails. This approach is a combination of fine tuning
of source filters, content filters, strictly implementing mail policies,
educating user, network monitoring and logical solutions to the ongoing attack.
We have conducted several experiments in corporate mail services; the results
show that this approach is highly effective to prevent DDoS attack caused by
spam. The defense mechanism reduced 60% of the incoming spam traffic and
repelled many DDoS attacks caused by spam
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1584</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1584</id><created>2010-10-07</created><authors><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>High-SIR Transmission Capacity of Wireless Networks with General Fading
  and Node Distribution</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Info Theory special issue</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many wireless systems, interference is the main performance-limiting
factor, and is primarily dictated by the locations of concurrent transmitters.
In many earlier works, the locations of the transmitters is often modeled as a
Poisson point process for analytical tractability. While analytically
convenient, the PPP only accurately models networks whose nodes are placed
independently and use ALOHA as the channel access protocol, which preserves the
independence. Correlations between transmitter locations in non-Poisson
networks, which model intelligent access protocols, makes the outage analysis
extremely difficult. In this paper, we take an alternative approach and focus
on an asymptotic regime where the density of interferers $\eta$ goes to 0. We
prove for general node distributions and fading statistics that the success
probability $\p \sim 1-\gamma \eta^{\kappa}$ for $\eta \rightarrow 0$, and
provide values of $\gamma$ and $\kappa$ for a number of important special
cases. We show that $\kappa$ is lower bounded by 1 and upper bounded by a value
that depends on the path loss exponent and the fading. This new analytical
framework is then used to characterize the transmission capacity of a very
general class of networks, defined as the maximum spatial density of active
links given an outage constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1595</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1595</id><created>2010-10-08</created><updated>2011-03-24</updated><authors><author><keyname>Jacob</keyname><forenames>Pierre</forenames><affiliation>Universite Paris-Dauphine and CREST, France</affiliation></author><author><keyname>Robert</keyname><forenames>Christian P.</forenames><affiliation>Universite Paris-Dauphine, IuF, and CREST, France</affiliation></author><author><keyname>Smith</keyname><forenames>Murray H.</forenames><affiliation>NIWA, Wellington, New Zealand</affiliation></author></authors><title>Using parallel computation to improve Independent Metropolis--Hastings
  based estimation</title><categories>stat.CO cs.DC cs.DS</categories><comments>19 pages, 8 figures, to appear in Journal of Computational and
  Graphical Statistics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the implications of the fact that parallel
raw-power can be exploited by a generic Metropolis--Hastings algorithm if the
proposed values are independent. In particular, we present improvements to the
independent Metropolis--Hastings algorithm that significantly decrease the
variance of any estimator derived from the MCMC output, for a null computing
cost since those improvements are based on a fixed number of target density
evaluations. Furthermore, the techniques developed in this paper do not
jeopardize the Markovian convergence properties of the algorithm, since they
are based on the Rao--Blackwell principles of Gelfand and Smith (1990), already
exploited in Casella and Robert (1996), Atchade and Perron (2005) and Douc and
Robert (2010). We illustrate those improvements both on a toy normal example
and on a classical probit regression model, but stress the fact that they are
applicable in any case where the independent Metropolis-Hastings is applicable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1602</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1602</id><created>2010-10-08</created><authors><author><keyname>Faber</keyname><forenames>Johannes</forenames><affiliation>MPII</affiliation></author><author><keyname>Ihlemann</keyname><forenames>Carsten</forenames><affiliation>MPII</affiliation></author><author><keyname>Jacobs</keyname><forenames>Swen</forenames><affiliation>EPFL</affiliation></author><author><keyname>Sofronie-Stokkermans</keyname><forenames>Viorica</forenames><affiliation>MPII</affiliation></author></authors><title>Automatic Verification of Parametric Specifications with Complex
  Topologies</title><categories>cs.SE cs.LO</categories><comments>The original publication is available at http://www.springerlink.com</comments><proxy>ccsd</proxy><journal-ref>Integrated Formal Methods - IFM 2010, Nancy : France (2010)</journal-ref><doi>10.1007/978-3-642-16265-7_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of this paper is on reducing the complexity in verification by
exploiting modularity at various levels: in specification, in verification, and
structurally. For specifications, we use the modular language CSP-OZ-DC, which
allows us to decouple verification tasks concerning data from those concerning
durations. At the verification level, we exploit modularity in theorem proving
for rich data structures and use this for invariant checking. At the structural
level, we analyze possibilities for modular verification of systems consisting
of various components which interact.We illustrate these ideas by automatically
verifying safety properties of a case study from the European Train Control
System standard, which extends previous examples by comprising a complex track
topology with lists of track segments and trains with different routes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1605</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1605</id><created>2010-10-08</created><authors><author><keyname>Warsi</keyname><forenames>Naqueeb</forenames></author><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Shah</keyname><forenames>Tapan</forenames></author></authors><title>Communicating Under Channel Uncertainty</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a single transmit and receive antenna system, a new constellation design
is proposed to combat errors in the phase estimate of the channel coefficient.
The proposed constellation is a combination of PSK and PAM constellations,
where PSK is used to provide protection against phase errors, while PAM is used
to increase the transmission rate using the knowledge of the magnitude of the
channel coefficient. The performance of the proposed constellation is shown to
be significantly better than the widely used QAM in terms of probability of
error. The proposed strategy can also be extended to systems using multiple
transmit and receive antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1609</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1609</id><created>2010-10-08</created><authors><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>Algorithmic and Statistical Perspectives on Large-Scale Data Analysis</title><categories>cs.DS stat.CO stat.ML</categories><comments>33 pages. To appear in Uwe Naumann and Olaf Schenk, editors,
  &quot;Combinatorial Scientific Computing,&quot; Chapman and Hall/CRC Press, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, ideas from statistics and scientific computing have begun to
interact in increasingly sophisticated and fruitful ways with ideas from
computer science and the theory of algorithms to aid in the development of
improved worst-case algorithms that are useful for large-scale scientific and
Internet data analysis problems. In this chapter, I will describe two recent
examples---one having to do with selecting good columns or features from a (DNA
Single Nucleotide Polymorphism) data matrix, and the other having to do with
selecting good clusters or communities from a data graph (representing a social
or information network)---that drew on ideas from both areas and that may serve
as a model for exploiting complementary algorithmic and statistical
perspectives in order to solve applied large-scale data analysis problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1622</identifier>
 <datestamp>2011-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1622</id><created>2010-10-08</created><updated>2011-06-16</updated><authors><author><keyname>Zhang</keyname><forenames>Ming</forenames></author><author><keyname>Xi</keyname><forenames>Zairong</forenames></author><author><keyname>Wei</keyname><forenames>Jia-Hua</forenames></author></authors><title>Manipulating quantum information on the controllable systems or
  subspaces</title><categories>quant-ph cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore how to constructively manipulate qubits by rotating
Bloch spheres. It is revealed that three-rotation and one-rotation Hamiltonian
controls can be constructed to steer qubits when two tunable Hamiltonian
controls are available. It is demonstrated in this research that local-wave
function controls such as Bang-Bang, triangle-function and quadratic function
controls can be utilized to manipulate quantum states on the Bloch sphere. A
new kind of time-energy performance index is proposed to trade-off time and
energy resource cost, in which control magnitudes are optimized in terms of
this kind of performance. It is further exemplified that this idea can be
generalized to manipulate encoded qubits on the controllable subspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1646</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1646</id><created>2010-10-08</created><updated>2010-12-09</updated><authors><author><keyname>Castellano</keyname><forenames>Claudio</forenames></author><author><keyname>Pastor-Satorras</keyname><forenames>Romualdo</forenames></author></authors><title>Thresholds for epidemic spreading in networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>5 pages, 4 figures</comments><journal-ref>Phys. Rev. Lett. 105, 218701 (2010)</journal-ref><doi>10.1103/PhysRevLett.105.218701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the threshold of epidemic models in quenched networks with degree
distribution given by a power-law. For the susceptible-infected-susceptible
(SIS) model the activity threshold lambda_c vanishes in the large size limit on
any network whose maximum degree k_max diverges with the system size, at odds
with heterogeneous mean-field (HMF) theory. The vanishing of the threshold has
not to do with the scale-free nature of the connectivity pattern and is instead
originated by the largest hub in the system being active for any spreading rate
lambda&gt;1/sqrt{k_max} and playing the role of a self-sustained source that
spreads the infection to the rest of the system. The
susceptible-infected-removed (SIR) model displays instead agreement with HMF
theory and a finite threshold for scale-rich networks. We conjecture that on
quenched scale-rich networks the threshold of generic epidemic models is
vanishing or finite depending on the presence or absence of a steady state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1648</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1648</id><created>2010-10-08</created><authors><author><keyname>Campo</keyname><forenames>Adri&#xe0; Tauste</forenames></author><author><keyname>F&#xe0;bregas</keyname><forenames>Albert Guill&#xe9;n i</forenames></author><author><keyname>Biglieri</keyname><forenames>Ezio</forenames></author></authors><title>Large-System Analysis of Multiuser Detection with an Unknown Number of
  Users: A High-SNR Approach</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze multiuser detection under the assumption that the number of users
accessing the channel is unknown by the receiver. In this environment, users'
activity must be estimated along with any other parameters such as data, power,
and location. Our main goal is to determine the performance loss caused by the
need for estimating the identities of active users, which are not known a
priori. To prevent a loss of optimality, we assume that identities and data are
estimated jointly, rather than in two separate steps. We examine the
performance of multiuser detectors when the number of potential users is large.
Statistical-physics methodologies are used to determine the macroscopic
performance of the detector in terms of its multiuser efficiency. Special
attention is paid to the fixed-point equation whose solution yields the
multiuser efficiency of the optimal (maximum a posteriori) detector in the
large signal-to-noise ratio regime. Our analysis yields closed-form approximate
bounds to the minimum mean-squared error in this regime. These illustrate the
set of solutions of the fixed-point equation, and their relationship with the
maximum system load. Next, we study the maximum load that the detector can
support for a given quality of service (specified by error probability).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1669</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1669</id><created>2010-10-08</created><updated>2011-07-18</updated><authors><author><keyname>Rathi</keyname><forenames>Vishwambhar</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author><author><keyname>Andersson</keyname><forenames>Mattias</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Rate-Equivocation Optimal Spatially Coupled LDPC Codes for the BEC
  Wiretap Channel</title><categories>cs.IT math.IT</categories><comments>Working paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider transmission over a wiretap channel where both the main channel
and the wiretapper's channel are Binary Erasure Channels (BEC). We use
convolutional LDPC ensembles based on the coset encoding scheme. More
precisely, we consider regular two edge type convolutional LDPC ensembles. We
show that such a construction achieves the whole rate-equivocation region of
the BEC wiretap channel.
  Convolutional LDPC ensemble were introduced by Felstr\&quot;om and Zigangirov and
are known to have excellent thresholds. Recently, Kudekar, Richardson, and
Urbanke proved that the phenomenon of &quot;Spatial Coupling&quot; converts MAP threshold
into BP threshold for transmission over the BEC.
  The phenomenon of spatial coupling has been observed to hold for general
binary memoryless symmetric channels. Hence, we conjecture that our
construction is a universal rate-equivocation achieving construction when the
main channel and wiretapper's channel are binary memoryless symmetric channels,
and the wiretapper's channel is degraded with respect to the main channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1697</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1697</id><created>2010-10-08</created><authors><author><keyname>Amadio</keyname><forenames>Roberto M.</forenames><affiliation>PPS</affiliation></author><author><keyname>Ayache</keyname><forenames>Nicolas</forenames><affiliation>PPS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>R&#xe9;gis-Gianas</keyname><forenames>Yann</forenames><affiliation>PPS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Saillard</keyname><forenames>Ronan</forenames><affiliation>PPS, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Certifying cost annotations in compilers</title><categories>cs.PL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the problem of building a compiler which can lift in a provably
correct way pieces of information on the execution cost of the object code to
cost annotations on the source code. To this end, we need a clear and flexible
picture of: (i) the meaning of cost annotations, (ii) the method to prove them
sound and precise, and (iii) the way such proofs can be composed. We propose a
so-called labelling approach to these three questions. As a first step, we
examine its application to a toy compiler. This formal study suggests that the
labelling approach has good compositionality and scalability properties. In
order to provide further evidence for this claim, we report our successful
experience in implementing and testing the labelling approach on top of a
prototype compiler written in OCAML for (a large fragment of) the C language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1705</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1705</id><created>2010-10-08</created><authors><author><keyname>Xu</keyname><forenames>Xiao-Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Jie</forenames></author><author><keyname>Small</keyname><forenames>Michael</forenames></author></authors><title>Rich-club connectivity dominates assortativity and transitivity of
  complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 2 figures, accepted by Phys. Rev. E</comments><doi>10.1103/PhysRevE.82.046117</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Rich-club, assortativity and clustering coefficients are frequently-used
measures to estimate topological properties of complex networks. Here we find
that the connectivity among a very small portion of the richest nodes can
dominate the assortativity and clustering coefficients of a large network,
which reveals that the rich-club connectivity is leveraged throughout the
network. Our study suggests that more attention should be payed to the
organization pattern of rich nodes, for the structure of a complex system as a
whole is determined by the associations between the most influential
individuals. Moreover, by manipulating the connectivity pattern in a very small
rich-club, it is sufficient to produce a network with desired assortativity or
transitivity. Conversely, our findings offer a simple explanation for the
observed assortativity and transitivity in many real world networks --- such
biases can be explained by the connectivities among the richest nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1746</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1746</id><created>2010-10-08</created><authors><author><keyname>Atay</keyname><forenames>Mustafa</forenames></author><author><keyname>Sun</keyname><forenames>Yezhou</forenames></author><author><keyname>Liu</keyname><forenames>Dapeng</forenames></author><author><keyname>Lu</keyname><forenames>Shiyong</forenames></author><author><keyname>Fotouhi</keyname><forenames>Farshad</forenames></author></authors><title>Mapping XML Data to Relational Data: A DOM-Based Approach</title><categories>cs.DB cs.DS</categories><comments>In Proc. of the 8th IASTED International Conference on Internet and
  Multimedia Systems and Applications (IMSA'04), pp. 59-64, Kauai , Hawaii ,
  USA. August 2004</comments><journal-ref>In Proc. of the 8th IASTED International Conference on Internet
  and Multimedia Systems and Applications (IMSA'04), pp. 59-64, Kauai , Hawaii
  , USA. August 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML has emerged as the standard for representing and exchanging data on the
World Wide Web. It is critical to have efficient mechanisms to store and query
XML data to exploit the full power of this new technology. Several researchers
have proposed to use relational databases to store and query XML data. While
several algorithms of schema mapping and query mapping have been proposed, the
problem of mapping XML data to relational data, i.e., mapping an XML INSERT
statement to a sequence of SQL INSERT statements, has not been addressed
thoroughly in the literature. In this paper, we propose an efficient linear
algorithm for mapping XML data to relational data. This algorithm is based on
our previous proposed inlining algorithm for mapping DTDs to relational schemas
and can be easily adapted to other inlining algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1763</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1763</id><created>2010-10-08</created><updated>2011-03-08</updated><authors><author><keyname>F&#xe9;votte</keyname><forenames>C&#xe9;dric</forenames><affiliation>LTCI</affiliation></author><author><keyname>Idier</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Algorithms for nonnegative matrix factorization with the beta-divergence</title><categories>cs.LG</categories><comments>\`a para\^itre dans Neural Computation</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes algorithms for nonnegative matrix factorization (NMF)
with the beta-divergence (beta-NMF). The beta-divergence is a family of cost
functions parametrized by a single shape parameter beta that takes the
Euclidean distance, the Kullback-Leibler divergence and the Itakura-Saito
divergence as special cases (beta = 2,1,0, respectively). The proposed
algorithms are based on a surrogate auxiliary function (a local majorization of
the criterion function). We first describe a majorization-minimization (MM)
algorithm that leads to multiplicative updates, which differ from standard
heuristic multiplicative updates by a beta-dependent power exponent. The
monotonicity of the heuristic algorithm can however be proven for beta in (0,1)
using the proposed auxiliary function. Then we introduce the concept of
majorization-equalization (ME) algorithm which produces updates that move along
constant level sets of the auxiliary function and lead to larger steps than MM.
Simulations on synthetic and real data illustrate the faster convergence of the
ME approach. The paper also describes how the proposed algorithms can be
adapted to two common variants of NMF : penalized NMF (i.e., when a penalty
function of the factors is added to the criterion function) and convex-NMF
(when the dictionary is assumed to belong to a known subspace).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1764</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1764</id><created>2010-10-08</created><updated>2011-04-26</updated><authors><author><keyname>Tsigaridas</keyname><forenames>Elias</forenames></author></authors><title>Improved complexity bounds for real root isolation using Continued
  Fractions</title><categories>cs.SC</categories><comments>This paper has been withdrawn by the author due to a new version
  available at arXiv:1010.2006</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of isolating the real roots of a square-free
polynomial with integer coefficients using (variants of) the continued fraction
algorithm (CF). We introduce a novel way to compute a lower bound on the
positive real roots of univariate polynomials. This allows us to derive a worst
case bound of $\sOB(d^6 + d^4\tau^2 + d^3\tau^2)$ for isolating the real roots
of a polynomial with integer coefficients using the classic variant of CF,
where $d$ is the degree of the polynomial and $\tau$ the maximum bitsize of its
coefficients. This improves the previous bound by Sharma \cite{sharma-tcs-2008}
by a factor of $d^3$ and matches the bound derived by Mehlhorn and Ray
\cite{mr-jsc-2009} for another variant of CF; it also matches the worst case
bound of the subdivision-based solvers. We present a new variant of CF, we call
it iCF, that isolates the real roots of a polynomial with integer coefficients
in $\sOB(d^5+d^4\tau)$, thus improving the current known bound for the problem
by a factor of $d$. If the polynomial has only real roots, then our bound
becomes $\sOB(d^4+d^3\tau+ d^2\tau^2)$, thus matching the bound of the
numerical algorithms by Reif \cite{r-focs-1993} and by Ben-Or and Tiwari
\cite{bt-joc-1990}. Actually the latter bound holds in a more general setting,
that is under the rather mild assumption that $\Omega(d/\lg^c{d})$, where
$c\geq 0$ is a constant, roots contribute to the sign variations of the
coefficient list of the polynomial. This is the only bound on exact algorithms
that matches the one of the numerical algorithms by Pan \cite{Pan02jsc} and
Sch\&quot;onhage \cite{Sch82}. To our knowledge the presented bounds are the best
known for the problem of real root isolation for algorithms based on exact
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1800</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1800</id><created>2010-10-08</created><authors><author><keyname>El-Gamal</keyname><forenames>Hesham</forenames></author><author><keyname>Tadrous</keyname><forenames>John</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author></authors><title>Proactive Resource Allocation: Turning Predictable Behavior into
  Spectral Gain</title><categories>cs.IT cs.NI cs.SI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the novel concept of proactive resource allocation in
which the predictability of user behavior is exploited to balance the wireless
traffic over time, and hence, significantly reduce the bandwidth required to
achieve a given blocking/outage probability. We start with a simple model in
which the smart wireless devices are assumed to predict the arrival of new
requests and submit them to the network T time slots in advance. Using tools
from large deviation theory, we quantify the resulting prediction diversity
gain to establish that the decay rate of the outage event probabilities
increases linearly with the prediction duration T. This model is then
generalized to incorporate the effect of prediction errors and the randomness
in the prediction lookahead time T. Remarkably, we also show that, in the
cognitive networking scenario, the appropriate use of proactive resource
allocation by the primary users results in more spectral opportunities for the
secondary users at a marginal, or no, cost in the primary network outage.
Finally, we conclude by a discussion of the new research questions posed under
the umbrella of the proposed proactive (non-causal) wireless networking
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1812</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1812</id><created>2010-10-09</created><authors><author><keyname>Rahman</keyname><forenames>Muhammad Mahbubur</forenames></author><author><keyname>Nahar</keyname><forenames>Afroza</forenames></author></authors><title>Modified Bully Algorithm using Election Commission</title><categories>cs.DC</categories><comments>8 pages,6 figures</comments><journal-ref>MASAUM Journal of Computing(MJC),Vol.1 No.3,pp.439-446,October
  2009, ISSN 2076-0833</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electing leader is a vital issue not only in distributed computing but also
in communication network [1, 2, 3, 4, 5], centralized mutual exclusion
algorithm [6, 7], centralized control IPC, etc. A leader is required to make
synchronization between different processes. And different election algorithms
are used to elect a coordinator among the available processes in the system
such a way that there will be only one coordinator at any time. Bully election
algorithm is one of the classical and well-known approaches in coordinator
election process. This paper will present a modified version of bully election
algorithm using a new concept called election commission. This approach will
not only reduce redundant elections but also minimize total number of elections
and hence it will minimize message passing, network traffic, and complexity of
the existing system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1824</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1824</id><created>2010-10-09</created><authors><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author></authors><title>Implications of Inter-Rater Agreement on a Student Information Retrieval
  Evaluation</title><categories>cs.IR</categories><comments>7 pages, 3 figures, LWA 2010, Workshop IR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about an information retrieval evaluation on three different
retrieval-supporting services. All three services were designed to compensate
typical problems that arise in metadata-driven Digital Libraries, which are not
adequately handled by a simple tf-idf based retrieval. The services are: (1) a
co-word analysis based query expansion mechanism and re-ranking via (2)
Bradfordizing and (3) author centrality. The services are evaluated with
relevance assessments conducted by 73 information science students. Since the
students are neither information professionals nor domain experts the question
of inter-rater agreement is taken into consideration. Two important
implications emerge: (1) the inter-rater agreement rates were mainly fair to
moderate and (2) after a data-cleaning step which erased the assessments with
poor agreement rates the evaluation data shows that the three retrieval
services returned disjoint but still relevant result sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1826</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1826</id><created>2010-10-09</created><authors><author><keyname>Mainguy</keyname><forenames>Thomas</forenames></author></authors><title>A probabilistic top-down parser for minimalist grammars</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a probabilistic top-down parser for minimalist grammars.
Top-down parsers have the great advantage of having a certain predictive power
during the parsing, which takes place in a left-to-right reading of the
sentence. Such parsers have already been well-implemented and studied in the
case of Context-Free Grammars, which are already top-down, but these are
difficult to adapt to Minimalist Grammars, which generate sentences bottom-up.
I propose here a way of rewriting Minimalist Grammars as Linear Context-Free
Rewriting Systems, allowing to easily create a top-down parser. This rewriting
allows also to put a probabilistic field on these grammars, which can be used
to accelerate the parser. Finally, I propose a method of refining the
probabilistic field by using algorithms used in data compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1834</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1834</id><created>2010-10-09</created><authors><author><keyname>Liberti</keyname><forenames>Leo</forenames></author><author><keyname>Masson</keyname><forenames>Benoit</forenames></author><author><keyname>Lee</keyname><forenames>Jon</forenames></author><author><keyname>Lavor</keyname><forenames>Carlile</forenames></author><author><keyname>Mucherino</keyname><forenames>Antonio</forenames></author></authors><title>On the number of solutions of the discretizable molecular distance
  geometry problem</title><categories>cs.DM cs.CG q-bio.QM</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Generalized Discretizable Molecular Distance Geometry Problem is a
distance geometry problems that can be solved by a combinatorial algorithm
called ``Branch-and-Prune''. It was observed empirically that the number of
solutions of YES instances is always a power of two. We give a proof that this
event happens with probability one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1845</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1845</id><created>2010-10-09</created><updated>2011-01-05</updated><authors><author><keyname>Hu</keyname><forenames>Yanqing</forenames></author><author><keyname>Li</keyname><forenames>Yong</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author><author><keyname>Fan</keyname><forenames>Ying</forenames></author></authors><title>Navigation in non-uniform density social networks</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 1 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recent empirical investigations suggest a universal scaling law for the
spatial structure of social networks. It is found that the probability density
distribution of an individual to have a friend at distance $d$ scales as
$P(d)\propto d^{-1}$. Since population density is non-uniform in real social
networks, a scale invariant friendship network(SIFN) based on the above
empirical law is introduced to capture this phenomenon. We prove the time
complexity of navigation in 2-dimensional SIFN is at most $O(\log^4 n)$. In the
real searching experiment, individuals often resort to extra information
besides geography location. Thus, real-world searching process may be seen as a
projection of navigation in a $k$-dimensional SIFN($k&gt;2$). Therefore, we also
discuss the relationship between high and low dimensional SIFN. Particularly,
we prove a 2-dimensional SIFN is the projection of a 3-dimensional SIFN. As a
matter of fact, this result can also be generated to any $k$-dimensional SIFN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1847</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1847</id><created>2010-10-09</created><authors><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author><author><keyname>Romberg</keyname><forenames>Justin</forenames></author><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author></authors><title>Restricted Isometries for Partial Random Circulant Matrices</title><categories>cs.IT math.IT math.PR</categories><msc-class>94A20, 60B20, 46B09,</msc-class><journal-ref>Probab. Theory Related Fields, Vol. 156, num. 3--4, pp. 707-737,
  Aug. 2013</journal-ref><doi>10.1007/s00440-012-0441-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the theory of compressed sensing, restricted isometry analysis has become
a standard tool for studying how efficiently a measurement matrix acquires
information about sparse and compressible signals. Many recovery algorithms are
known to succeed when the restricted isometry constants of the sampling matrix
are small. Many potential applications of compressed sensing involve a
data-acquisition process that proceeds by convolution with a random pulse
followed by (nonrandom) subsampling. At present, the theoretical analysis of
this measurement technique is lacking. This paper demonstrates that the $s$th
order restricted isometry constant is small when the number $m$ of samples
satisfies $m \gtrsim (s \log n)^{3/2}$, where $n$ is the length of the pulse.
This bound improves on previous estimates, which exhibit quadratic scaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1853</identifier>
 <datestamp>2011-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1853</id><created>2010-10-09</created><authors><author><keyname>Privman</keyname><forenames>Vladimir</forenames></author></authors><title>Control of Noise in Chemical and Biochemical Information Processing</title><categories>cond-mat.soft cs.OH physics.bio-ph q-bio.MN</categories><comments>39 pages, 8 figures, PDF</comments><journal-ref>Israel J. Chem. 51, 118-131 (2011)</journal-ref><doi>10.1002/ijch.201000066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review models and approaches for error-control in order to prevent the
buildup of noise when gates for digital chemical and biomolecular computing
based on (bio)chemical reaction processes are utilized to realize stable,
scalable networks for information processing. Solvable rate-equation models
illustrate several recently developed methodologies for gate-function
optimization. We also survey future challenges and possible new research
avenues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1862</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1862</id><created>2010-10-09</created><authors><author><keyname>Huang</keyname><forenames>Longbo</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Utility Optimal Scheduling in Processing Networks</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of utility optimal scheduling in general
\emph{processing networks} with random arrivals and network conditions. These
are generalizations of traditional data networks where commodities in one or
more queues can be combined to produce new commodities that are delivered to
other parts of the network. This can be used to model problems such as
in-network data fusion, stream processing, and grid computing. Scheduling
actions are complicated by the \emph{underflow problem} that arises when some
queues with required components go empty. In this paper, we develop the
Perturbed Max-Weight algorithm (PMW) to achieve optimal utility. The idea of
PMW is to perturb the weights used by the usual Max-Weight algorithm to
``push'' queue levels towards non-zero values (avoiding underflows). We show
that when the perturbations are carefully chosen, PMW is able to achieve a
utility that is within $O(1/V)$ of the optimal value for any $V\geq1$, while
ensuring an average network backlog of $O(V)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1864</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1864</id><created>2010-10-09</created><updated>2012-07-16</updated><authors><author><keyname>Shevchuk</keyname><forenames>Roman</forenames></author><author><keyname>Snarskii</keyname><forenames>Andrew</forenames></author></authors><title>Transforming complex network to the acyclic one</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>13 pages, 8 figures</comments><doi>10.1016/j.physa.2012.07.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acyclic networks are a class of complex networks in which links are directed
and don't have closed loops. Here we present an algorithm for transforming an
ordinary undirected complex network into an acyclic one. Further analysis of an
acyclic network allows finding structural properties of the network. With our
approach one can find the communities and key nodes in complex networks. Also
we propose a new parameter of complex networks which can mark most vulnerable
nodes of the system. The proposed algorithm can be applied to finding
communities and bottlenecks in general complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1865</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1865</id><created>2010-10-09</created><authors><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Baricz</keyname><forenames>Arpad</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author></authors><title>Corrections to &quot;Unified Laguerre polynomial-series-based distribution of
  small-scale fading envelopes''</title><categories>math.PR cs.IT math.IT</categories><comments>2 pages, to be published in the IEEE Transactions on Vehicular
  Technology as a Correspondence</comments><journal-ref>Transactions on Vehicular Technology 60(1) (2011) 347-349</journal-ref><doi>10.1109/TVT.2010.2087368</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, we point out two typographical errors in Chai and
Tjhung's paper and we offer the correct formula of the unified Laguerre
polynomial-series-based cumulative distribution function (cdf) for small-scale
fading distributions. A Laguerre polynomial-series-based cdf formula for
non-central chi-square distribution is also provided as a special case of our
unified cdf result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1866</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1866</id><created>2010-10-09</created><authors><author><keyname>Brown</keyname><forenames>Daniel G.</forenames></author><author><keyname>Truszkowski</keyname><forenames>Jakub</forenames></author></authors><title>Fast error-tolerant quartet phylogeny algorithms</title><categories>q-bio.PE cs.CE cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for phylogenetic reconstruction using quartets that
returns the correct topology for $n$ taxa in $O(n \log n)$ time with high
probability, in a probabilistic model where a quartet is not consistent with
the true topology of the tree with constant probability, independent of other
quartets. Our incremental algorithm relies upon a search tree structure for the
phylogeny that is balanced, with high probability, no matter what the true
topology is. Our experimental results show that our method is comparable in
runtime to the fastest heuristics, while still offering consistency guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1872</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1872</id><created>2010-10-09</created><updated>2010-12-21</updated><authors><author><keyname>Ghilardi</keyname><forenames>Silvio</forenames><affiliation>Dipartimento di Scienze dell'Informazione, Univ. degli Studi di Milano</affiliation></author><author><keyname>Ranise</keyname><forenames>Silvio</forenames><affiliation>FBK-Irst, Trento</affiliation></author></authors><title>Backward Reachability of Array-based Systems by SMT solving: Termination
  and Invariant Synthesis</title><categories>cs.LO</categories><comments>Accepted for publication in Logical Methods in Computer Science</comments><proxy>LMCS</proxy><acm-class>D.2.4, F.3.1, I.2.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  21, 2010) lmcs:966</journal-ref><doi>10.2168/LMCS-6(4:10)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The safety of infinite state systems can be checked by a backward
reachability procedure. For certain classes of systems, it is possible to prove
the termination of the procedure and hence conclude the decidability of the
safety problem. Although backward reachability is property-directed, it can
unnecessarily explore (large) portions of the state space of a system which are
not required to verify the safety property under consideration. To avoid this,
invariants can be used to dramatically prune the search space. Indeed, the
problem is to guess such appropriate invariants. In this paper, we present a
fully declarative and symbolic approach to the mechanization of backward
reachability of infinite state systems manipulating arrays by Satisfiability
Modulo Theories solving. Theories are used to specify the topology and the data
manipulated by the system. We identify sufficient conditions on the theories to
ensure the termination of backward reachability and we show the completeness of
a method for invariant synthesis (obtained as the dual of backward
reachability), again, under suitable hypotheses on the theories. We also
present a pragmatic approach to interleave invariant synthesis and backward
reachability so that a fix-point for the set of backward reachable states is
more easily obtained. Finally, we discuss heuristics that allow us to derive an
implementation of the techniques in the model checker MCMT, showing remarkable
speed-ups on a significant set of safety problems extracted from a variety of
sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1886</identifier>
 <datestamp>2010-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1886</id><created>2010-10-09</created><updated>2010-12-22</updated><authors><author><keyname>Cole</keyname><forenames>Richard</forenames><affiliation>Courant Institute, New York University</affiliation></author><author><keyname>Correa</keyname><forenames>Jos&#xe9; R.</forenames><affiliation>Departamento de Ingenier&#xed;a Industrial, Universidad de Chile</affiliation></author><author><keyname>Gkatzelis</keyname><forenames>Vasilis</forenames><affiliation>Courant Institute, New York University</affiliation></author><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames><affiliation>Google Research, New York</affiliation></author><author><keyname>Olver</keyname><forenames>Neil</forenames><affiliation>Department of Mathematics, MIT</affiliation></author></authors><title>Inner Product Spaces for MinSum Coordination Mechanisms</title><categories>cs.GT cs.DS cs.MA</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study policies aiming to minimize the weighted sum of completion times of
jobs in the context of coordination mechanisms for selfish scheduling problems.
Our goal is to design local policies that achieve a good price of anarchy in
the resulting equilibria for unrelated machine scheduling. To obtain the
approximation bounds, we introduce a new technique that while conceptually
simple, seems to be quite powerful. With this method we are able to prove the
following results.
  First, we consider Smith's Rule, which orders the jobs on a machine in
ascending processing time to weight ratio, and show that it achieves an
approximation ratio of 4. We also demonstrate that this is the best possible
for deterministic non-preemptive strongly local policies. Since Smith's Rule is
always optimal for a given assignment, this may seem unsurprising, but we then
show that better approximation ratios can be obtained if either preemption or
randomization is allowed.
  We prove that ProportionalSharing, a preemptive strongly local policy,
achieves an approximation ratio of 2.618 for the weighted sum of completion
times, and an approximation ratio of 2.5 in the unweighted case. Again, we
observe that these bounds are tight. Next, we consider Rand, a natural
non-preemptive but randomized policy. We show that it achieves an approximation
ratio of at most 2.13; moreover, if the sum of the weighted completion times is
negligible compared to the cost of the optimal solution, this improves to \pi
/2.
  Finally, we show that both ProportionalSharing and Rand induce potential
games, and thus always have a pure Nash equilibrium (unlike Smith's Rule). This
also allows us to design the first \emph{combinatorial} constant-factor
approximation algorithm minimizing weighted completion time for unrelated
machine scheduling that achieves a factor of 2+ \epsilon for any \epsilon &gt; 0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1888</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1888</id><created>2010-10-09</created><authors><author><keyname>Icke</keyname><forenames>Ilknur</forenames></author><author><keyname>Rosenberg</keyname><forenames>Andrew</forenames></author></authors><title>Multi-Objective Genetic Programming Projection Pursuit for Exploratory
  Data Modeling</title><categories>cs.LG cs.NE</categories><comments>Submitted to the New York Academy of Sciences, 5th Annual Machine
  Learning Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For classification problems, feature extraction is a crucial process which
aims to find a suitable data representation that increases the performance of
the machine learning algorithm. According to the curse of dimensionality
theorem, the number of samples needed for a classification task increases
exponentially as the number of dimensions (variables, features) increases. On
the other hand, it is costly to collect, store and process data. Moreover,
irrelevant and redundant features might hinder classifier performance. In
exploratory analysis settings, high dimensionality prevents the users from
exploring the data visually. Feature extraction is a two-step process: feature
construction and feature selection. Feature construction creates new features
based on the original features and feature selection is the process of
selecting the best features as in filter, wrapper and embedded methods.
  In this work, we focus on feature construction methods that aim to decrease
data dimensionality for visualization tasks. Various linear (such as principal
components analysis (PCA), multiple discriminants analysis (MDA), exploratory
projection pursuit) and non-linear (such as multidimensional scaling (MDS),
manifold learning, kernel PCA/LDA, evolutionary constructive induction)
techniques have been proposed for dimensionality reduction. Our algorithm is an
adaptive feature extraction method which consists of evolutionary constructive
induction for feature construction and a hybrid filter/wrapper method for
feature selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1894</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1894</id><created>2010-10-10</created><authors><author><keyname>Zhang</keyname><forenames>Guo-Qiang</forenames></author></authors><title>Link power coordination for energy conservation in complex communication
  networks</title><categories>cs.NI cond-mat.stat-mech</categories><comments>6 pages, 4 figures</comments><doi>10.1209/0295-5075/92/28001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication networks consume huge, and rapidly growing, amount of energy.
However, a lot of the energy consumption is wasted due to the lack of global
link power coordination in these complex systems. This paper proposes several
link power coordination schemes to achieve energy-efficient routing by
progressively putting some links into energy saving mode and hence aggregating
traffic during periods of low traffic load. We show that the achievable energy
savings not only depend on the link power coordination schemes, but also on the
network topologies. In the random network, there is no scheme that can
significantly outperform others. In the scale-free network, when the largest
betweenness first (LBF) scheme is used, phase transition of the networks'
transmission capacities during the traffic cooling down phase is observed.
Motivated by this, a hybrid link power coordination scheme is proposed to
significantly reduce the energy consumption in the scale-free network. In a
real Internet Service Provider (ISP)'s router-level Internet topology, however,
the smallest betweenness first (SBF) scheme significantly outperforms other
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1899</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1899</id><created>2010-10-10</created><authors><author><keyname>Guang</keyname><forenames>Xuan</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>The Failure Probability at Sink Node of Random Linear Network Coding</title><categories>cs.IT math.IT</categories><comments>4 pages, 1 figure, to appear in Proceedings of ICITIS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In practice, since many communication networks are huge in scale or
complicated in structure even dynamic, the predesigned network codes based on
the network topology is impossible even if the topological structure is known.
Therefore, random linear network coding was proposed as an acceptable coding
technique. In this paper, we further study the performance of random linear
network coding by analyzing the failure probabilities at sink node for
different knowledge of network topology and get some tight and asymptotically
tight upper bounds of the failure probabilities. In particular, the worst cases
are indicated for these bounds. Furthermore, if the more information about the
network topology is utilized, the better upper bounds are obtained. These
bounds improve on the known ones. Finally, we also discuss the lower bound of
this failure probability and show that it is also asymptotically tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1904</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1904</id><created>2010-10-10</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>Weighted Indices for Evaluating the Quality of Research with Multiple
  Authorship</title><categories>cs.IR cs.CY cs.DL</categories><comments>12 pages, 9 figures, 4 tables</comments><msc-class>68M20</msc-class><acm-class>H.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Devising an index to measure the quality of research is a challenging task.
In this paper, we propose a set of indices to evaluate the quality of research
produced by an author. Our indices utilize a policy that assigns the weights to
multiple authors of a paper. We have considered two weight assignment policies:
positionally weighted and equally weighted. We propose two classes of weighted
indices: weighted h-indices and weighted citation h-cuts. Further, we compare
our weighted h-indices with the original h-index for a selected set of authors.
As opposed to h-index, our weighted h-indices take into account the weighted
contributions of individual authors in multi-authored papers, and may serve as
an improvement over h-index. The other class of weighted indices that we call
weighted citation h-cuts take into account the number of citations that are in
excess of those required to compute the index, and may serve as a supplement to
h-index or its variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1911</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1911</id><created>2010-10-10</created><authors><author><keyname>Andriyanova</keyname><forenames>Iryna</forenames></author><author><keyname>Tillich</keyname><forenames>Jean-Pierre</forenames></author></authors><title>On a Low-Rate TLDPC Code Ensemble and the Necessary Condition on the
  Linear Minimum Distance for Sparse-Graph Codes</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the issue of design of low-rate sparse-graph codes with
linear minimum distance in the blocklength. First, we define a necessary
condition which needs to be satisfied when the linear minimum distance is to be
ensured. The condition is formulated in terms of degree-1 and degree-2 variable
nodes and of low-weight codewords of the underlying code, and it generalizies
results known for turbo codes [8] and LDPC codes. Then, we present a new
ensemble of low-rate codes, which itself is a subclass of TLDPC codes [4], [5],
and which is designed under this necessary condition. The asymptotic analysis
of the ensemble shows that its iterative threshold is situated close to the
Shannon limit. In addition to the linear minimum distance property, it has a
simple structure and enjoys a low decoding complexity and a fast convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1938</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1938</id><created>2010-10-10</created><updated>2010-10-13</updated><authors><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author><author><keyname>Shelat</keyname><forenames>Ajit</forenames></author><author><keyname>Gupta</keyname><forenames>Amit</forenames></author></authors><title>New Frontiers of Network Security: The Threat Within</title><categories>cs.CR</categories><comments>4 Pages, Invited Paper in VCON'10: 2nd Vaagdevi International
  Conference on Information Technology for Real World Problems Vaagdevi College
  of Engineering, Warangal, Andhra Pradesh, India, December 9-11, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nearly 70% of information security threats originate from inside an
organization. Opportunities for insider threats have been increasing at an
alarming rate with the latest trends of mobility (portable devices like Laptop,
smart phones etc.), ubiquitous connectivity (wireless or through 3G
connectivity) and this trend increases as more and more web-based applications
are made available over the Internet. Insider threats are generally caused by
current or ex-employees, contractors or partners, who have authorized access to
the organization's network and servers. Theft of confidential information is
often for either material gain or for willful damage. Easy availability of
hacking tools on the Internet, USB devices and wireless connectivity provide
for easy break-ins. The net result is losses worth millions of dollars in terms
of IP theft, leakage of customer / individual information, etc. This paper
presents an understanding of Insider threats, attackers and their motives and
suggests mitigation techniques at the organization level
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1945</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1945</id><created>2010-10-10</created><authors><author><keyname>Hochbaum</keyname><forenames>Dorit S.</forenames></author></authors><title>Submodular problems - approximations and algorithms</title><categories>cs.DM cs.DS</categories><comments>14 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that any submodular minimization (SM) problem defined on a linear
constraint set with constraints having up to two variables per inequality, are
2-approximable in polynomial time. If the constraints are monotone (the two
variables appear with opposite sign coefficients) then the problems of
submodular minimization or supermodular maximization are polynomial time
solvable. The key idea is to link these problems to a submodular s,t-cut
problem defined here. This framework includes the problems: SM-vertex cover;
SM-2SAT; SM-min satisfiability; SM-edge deletion for clique, SM-node deletion
for biclique and others. We also introduce here the submodular closure problem
and and show that it is solvable in polynomial time and equivalent to the
submodular cut problem. All the results are extendible to multi-sets where each
element of a set may appear with a multiplicity greater than 1. For all these
NP-hard problems 2-approximations are the best possible in the sense that a
better approximation factor cannot be achieved in polynomial time unless NP=P.
The mechanism creates a relaxed &quot;monotone&quot; problem, solved as a submodular
closure problem, the solution to which is mapped to a half integral
super-optimal solution to the original problem. That half-integral solution has
the persistency property meaning that integer valued variables retain their
value in an optimal solution. This permits to delete the integer valued
variables, and restrict the search of an optimal solution to the smaller set of
remaining variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1948</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1948</id><created>2010-10-10</created><authors><author><keyname>Chan</keyname><forenames>Timothy M.</forenames></author><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author></authors><title>Transdichotomous Results in Computational Geometry, II: Offline Search</title><categories>cs.DS cs.CG</categories><comments>Journal version of the paper &quot;Voronoi Diagrams in n 2^O(sqrt{lglg n})
  Time&quot; from STOC 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reexamine fundamental problems from computational geometry in the word RAM
model, where input coordinates are integers that fit in a machine word. We
develop a new algorithm for offline point location, a two-dimensional analog of
sorting where one needs to order points with respect to segments. This result
implies, for example, that the convex hull of n points in three dimensions can
be constructed in (randomized) time n 2^O(sqrt{lglg n}). Similar bounds hold
for numerous other geometric problems, such as planar Voronoi diagrams, planar
off-line nearest neighbor search, line segment intersection, and triangulation
of non-simple polygons.
  In FOCS'06, we developed a data structure for online point location, which
implied a bound of O(n lg n/lglg n) for three-dimensional convex hulls and the
other problems. Our current bounds are dramatically better, and a convincing
improvement over the classic O(nlg n) algorithms. As in the field of integer
sorting, the main challenge is to find ways to manipulate information, while
avoiding the online problem (in that case, predecessor search).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1953</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1953</id><created>2010-10-10</created><updated>2010-11-02</updated><authors><author><keyname>August</keyname><forenames>Friedrich</forenames></author><author><keyname>Blanchard</keyname><forenames>Philippe</forenames></author><author><keyname>Delitzscher</keyname><forenames>Sascha</forenames></author><author><keyname>Hiller</keyname><forenames>Gerald</forenames></author><author><keyname>Krueger</keyname><forenames>Tyll</forenames></author></authors><title>Passive Supporters of Terrorism and Phase Transitions</title><categories>physics.soc-ph cs.SI</categories><comments>references added concerning previous work of S. Galam</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss some social contagion processes to describe the formation and
spread of radical opinions. The dynamics of opinion spread involves local
threshold processes as well as mean field effects. We calculate and observe
phase transitions in the dynamical variables resulting in a rapidly increasing
number of passive supporters. This strongly indicates that military solutions
are inappropriate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1955</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1955</id><created>2010-10-10</created><authors><author><keyname>Macauley</keyname><forenames>Matthew</forenames></author><author><keyname>Mortveit</keyname><forenames>Henning S.</forenames></author></authors><title>Coxeter Groups and Asynchronous Cellular Automata</title><categories>cs.DM math.DS</categories><comments>10 pages, 4 figures</comments><msc-class>68Q80, 37B99, 20F55</msc-class><journal-ref>ACRI 2010, LNCS 6350, pp. 409-418, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamics group of an asynchronous cellular automaton (ACA) relates
properties of its long term dynamics to the structure of Coxeter groups. The
key mathematical feature connecting these diverse fields is involutions.
Group-theoretic results in the latter domain may lead to insight about the
dynamics in the former, and vice-versa. In this article, we highlight some
central themes and common structures, and discuss novel approaches to some open
and open-ended problems. We introduce the state automaton of an ACA, and show
how the root automaton of a Coxeter group is essentially part of the state
automaton of a related ACA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1973</identifier>
 <datestamp>2011-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1973</id><created>2010-10-10</created><updated>2011-01-12</updated><authors><author><keyname>Galli</keyname><forenames>Stefano</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author><author><keyname>Wang</keyname><forenames>Zhifang</forenames></author></authors><title>For the Grid and Through the Grid: The Role of Power Line Communications
  in the Smart Grid</title><categories>cs.NI cs.IT cs.SY math.IT</categories><comments>26 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Is Power Line Communications (PLC) a good candidate for Smart Grid
applications? The objective of this paper is to address this important
question. To do so we provide an overview of what PLC can deliver today by
surveying its history and describing the most recent technological advances in
the area. We then address Smart Grid applications as instances of sensor
networking and network control problems and discuss the main conclusion one can
draw from the literature on these subjects. The application scenario of PLC
within the Smart Grid is then analyzed in detail. Since a necessary ingredient
of network planning is modeling, we also discuss two aspects of engineering
modeling that relate to our question. The first aspect is modeling the PLC
channel through fading models. The second aspect we review is the Smart Grid
control and traffic modeling problem which allows us to achieve a better
understanding of the communications requirements. Finally, this paper reports
recent studies on the electrical and topological properties of a sample power
distribution network. Power grid topological studies are very important for PLC
networking as the power grid is not only the information source \textit{but
also} the information delivery system - a unique feature when PLC is used for
the Smart Grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1982</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1982</id><created>2010-10-10</created><authors><author><keyname>Chen</keyname><forenames>Jingwei</forenames></author><author><keyname>Feng</keyname><forenames>Yong</forenames></author><author><keyname>Qin</keyname><forenames>Xiaolin</forenames></author><author><keyname>Zhang</keyname><forenames>Jingzhong</forenames></author></authors><title>Detecting Simultaneous Integer Relations for Several Real Vectors</title><categories>cs.SC cs.CC math.NT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm which either finds an nonzero integer vector ${\mathbf m}$ for
given $t$ real $n$-dimensional vectors ${\mathbf x}_1,...,{\mathbf x}_t$ such
that ${\mathbf x}_i^T{\mathbf m}=0$ or proves that no such integer vector with
norm less than a given bound exists is presented in this paper. The cost of the
algorithm is at most ${\mathcal O}(n^4 + n^3 \log \lambda(X))$ exact arithmetic
operations in dimension $n$ and the least Euclidean norm $\lambda(X)$ of such
integer vectors. It matches the best complexity upper bound known for this
problem. Experimental data show that the algorithm is better than an already
existing algorithm in the literature. In application, the algorithm is used to
get a complete method for finding the minimal polynomial of an unknown complex
algebraic number from its approximation, which runs even faster than the
corresponding \emph{Maple} built-in function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.1985</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.1985</id><created>2010-10-10</created><authors><author><keyname>Razaghi</keyname><forenames>Peyman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Relay Strategies Based on Cross-Determinism for the Broadcast Relay
  Channel</title><categories>cs.IT math.IT</categories><comments>Presented at 42nd Allerton Conference on Communications, Control, and
  Computing, Allerton, IL, 2010</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We consider a two-user Gaussian multiple-input multiple-output (MIMO)
broadcast channel with a common multiple-antenna relay, and a shared digital
(noiseless) link between the relay and the two destinations. For this channel,
this paper introduces an asymptotically sum-capacity-achieving
quantize-and-forward (QF) relay strategy. Our technique to design an
asymptotically optimal relay quantizer is based on identifying a
cross-deterministic relation between the relay observation, the source signal,
and the destination observation. In a relay channel, an approximate cross
deterministic relation corresponds to an approximately deterministic relation,
where the relay observation is to some extent a deterministic function of the
source and destination signals. We show that cross determinism can serve as a
measure for quantization penalty. By identifying an analogy between a
deterministic broadcast relay channel and a Gaussian MIMO relay channel, we
propose a three-stage dirty paper coding strategy, along with receiver
beamforming and quantization at the relay, to asymptotically achieve an
extended achievable rate region for the MIMO broadcast channel with a common
multiple-antenna relay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2000</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2000</id><created>2010-10-11</created><authors><author><keyname>Bouwmeester</keyname><forenames>Henricus</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author></authors><title>A Critical Path Approach to Analyzing Parallelism of Algorithmic
  Variants. Application to Cholesky Inversion</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms come with multiple variants which are obtained by changing the
mathematical approach from which the algorithm is derived. These variants offer
a wide spectrum of performance when implemented on a multicore platform and we
seek to understand these differences in performances from a theoretical point
of view. To that aim, we derive and present the critical path lengths of each
algorithmic variant for our application problem which enables us to determine a
lower bound on the time to solution. This metric provides an intuitive grasp of
the performance of a variant and we present numerical experiments to validate
the tightness of our lower bounds on practical applications. Our case study is
the Cholesky inversion and its use in computing the inverse of a symmetric
positive definite matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2006</identifier>
 <datestamp>2011-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2006</id><created>2010-10-11</created><updated>2011-06-07</updated><authors><author><keyname>Tsigaridas</keyname><forenames>Elias</forenames></author></authors><title>Improved complexity bounds for real root isolation using Continued
  Fractions</title><categories>cs.SC</categories><comments>The improved bound bound that was claimed in an earlier version is
  removed, since there was an error in the proof</comments><proxy>ccsd</proxy><report-no>RR2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of isolating the real roots of a square-free
polynomial with integer coefficients using (variants of) the continued fraction
algorithm (CF). We introduce a novel way to compute a lower bound on the
positive real roots of univariate polynomials. This allows us to derive a worst
case bound of $\sOB(d^6 + d^4\tau^2 + d^3\tau^2)$ for isolating the real roots
of a polynomial with integer coefficients using the classic variant
\cite{Akritas:implementation} of CF, where $d$ is the degree of the polynomial
and $\tau$ the maximum bitsize of its coefficients. This improves the previous
bound of Sharma \cite{sharma-tcs-2008} by a factor of $d^3$ and matches the
bound derived by Mehlhorn and Ray \cite{mr-jsc-2009} for another variant of CF;
it also matches the worst case bound of the subdivision-based solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2030</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2030</id><created>2010-10-11</created><updated>2011-07-15</updated><authors><author><keyname>Yang</keyname><forenames>Shengtian</forenames></author><author><keyname>Honold</keyname><forenames>Thomas</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaoyang</forenames></author><author><keyname>Qiu</keyname><forenames>Peiliang</forenames></author></authors><title>Weight Distributions of Regular Low-Density Parity-Check Codes over
  Finite Fields</title><categories>cs.IT math.IT</categories><comments>15 pages, 5 figures, accepted for publication in IEEE Transactions on
  Information Theory, July 2011</comments><journal-ref>IEEE Trans. Inf. Theory 57 (2011) 7507-7521</journal-ref><doi>10.1109/TIT.2011.2162642</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The average weight distribution of a regular low-density parity-check (LDPC)
code ensemble over a finite field is thoroughly analyzed. In particular, a
precise asymptotic approximation of the average weight distribution is derived
for the small-weight case, and a series of fundamental qualitative properties
of the asymptotic growth rate of the average weight distribution are proved.
Based on this analysis, a general result, including all previous results as
special cases, is established for the minimum distance of individual codes in a
regular LDPC code ensemble.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2055</identifier>
 <datestamp>2011-12-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2055</id><created>2010-10-11</created><authors><author><keyname>Marzuoli</keyname><forenames>Annalisa</forenames></author><author><keyname>Palumbo</keyname><forenames>Giandomenico</forenames></author></authors><title>Post Quantum Cryptography from Mutant Prime Knots</title><categories>math-ph cs.CR math.MP quant-ph</categories><comments>14 pages, 5 figures</comments><msc-class>68QXX (Theory of computing) 57M27 (Invariants of knots and
  3-manifolds) 68Q17 (Computational difficulty of problems)</msc-class><journal-ref>Int. J. Geom. Meth. in Mod. Phys. Vol 8, No.7 (2011) 1571-1581</journal-ref><doi>10.1142/S0219887811005798</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By resorting to basic features of topological knot theory we propose a
(classical) cryptographic protocol based on the `difficulty' of decomposing
complex knots generated as connected sums of prime knots and their mutants. The
scheme combines an asymmetric public key protocol with symmetric private ones
and is intrinsecally secure against quantum eavesdropper attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2067</identifier>
 <datestamp>2013-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2067</id><created>2010-10-11</created><updated>2013-02-25</updated><authors><author><keyname>Baez</keyname><forenames>John C.</forenames></author><author><keyname>Stay</keyname><forenames>Mike</forenames></author></authors><title>Algorithmic Thermodynamics</title><categories>math-ph cs.IT math.IT math.MP quant-ph</categories><comments>20 pages, one encapsulated postscript figure</comments><journal-ref>Computability of the Physical, Mathematical Structures in Computer
  Science 22 (2012), 771--787</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic entropy can be seen as a special case of entropy as studied in
statistical mechanics. This viewpoint allows us to apply many techniques
developed for use in thermodynamics to the subject of algorithmic information
theory. In particular, suppose we fix a universal prefix-free Turing machine
and let X be the set of programs that halt for this machine. Then we can regard
X as a set of 'microstates', and treat any function on X as an 'observable'.
For any collection of observables, we can study the Gibbs ensemble that
maximizes entropy subject to constraints on expected values of these
observables. We illustrate this by taking the log runtime, length, and output
of a program as observables analogous to the energy E, volume V and number of
molecules N in a container of gas. The conjugate variables of these observables
allow us to define quantities which we call the 'algorithmic temperature' T,
'algorithmic pressure' P and algorithmic potential' mu, since they are
analogous to the temperature, pressure and chemical potential. We derive an
analogue of the fundamental thermodynamic relation dE = T dS - P d V + mu dN,
and use it to study thermodynamic cycles analogous to those for heat engines.
We also investigate the values of T, P and mu for which the partition function
converges. At some points on the boundary of this domain of convergence, the
partition function becomes uncomputable. Indeed, at these points the partition
function itself has nontrivial algorithmic entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2102</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2102</id><created>2010-10-11</created><authors><author><keyname>El-Yaniv</keyname><forenames>Ran</forenames></author><author><keyname>Etzion-Rosenberg</keyname><forenames>Noam</forenames></author></authors><title>Hierarchical Multiclass Decompositions with Application to Authorship
  Determination</title><categories>cs.AI</categories><report-no>Technical report CS-200415, Technion</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is mainly concerned with the question of how to decompose
multiclass classification problems into binary subproblems. We extend known
Jensen-Shannon bounds on the Bayes risk of binary problems to hierarchical
multiclass problems and use these bounds to develop a heuristic procedure for
constructing hierarchical multiclass decomposition for multinomials. We test
our method and compare it to the well known &quot;all-pairs&quot; decomposition. Our
tests are performed using a new authorship determination benchmark test of
machine learning authors. The new method consistently outperforms the all-pairs
decomposition when the number of classes is small and breaks even on larger
multiclass problems. Using both methods, the classification accuracy we
achieve, using an SVM over a feature set consisting of both high frequency
single tokens and high frequency token-pairs, appears to be exceptionally high
compared to known results in authorship determination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2128</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2128</id><created>2010-10-11</created><authors><author><keyname>Rashidi</keyname><forenames>Moslem</forenames></author><author><keyname>Mansouri</keyname><forenames>Sara</forenames></author></authors><title>Parameter Selection in Periodic Nonuniform Sampling of Multiband Signals</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Periodic nonuniform sampling has been considered in literature as an
effective approach to reduce the sampling rate far below the Nyquist rate for
sparse spectrum multiband signals. In the presence of non-ideality the sampling
parameters play an important role on the quality of reconstructed signal. Also
the average sampling ratio is directly dependent on the sampling parameters
that they should be chosen for a minimum rate and complexity. In this paper we
consider the effect of sampling parameters on the reconstruction error and the
sampling ratio and suggest feasible approaches for achieving an optimal
sampling and reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2138</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2138</id><created>2010-10-11</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP</affiliation></author><author><keyname>Lavou&#xe9;</keyname><forenames>Elise</forenames><affiliation>SICOMOR</affiliation></author></authors><title>Combiner suivi de l'activite? et partage d'expe?riences en apprentissage
  par projet pour les acteurs tuteurs et apprenants</title><categories>cs.CY</categories><comments>8p</comments><proxy>ccsd</proxy><report-no>Axe 4</report-no><journal-ref>7\`eme Colloque Technologies de l'Information et de la
  Communication pour l'Enseignement (TICE 2010), Nancy : France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work aims to study tools offered to students and tutors involved in
face-to-face or blended project- based learning activities. Project-based
learning is often applied in the case of complex learning (i.e. which aims at
mak- ing learners acquire various linked skills or develop their behaviours).
In comparison to traditional learning, this type of learning relies on
co-development, collective responsibility and co-operation. Learners are the
principal actors of their learning. These trainings rest on rich and complex
organizations, particularly for tutors, and it is difficult to apply inno-
vative educational strategies. Our aim, in a bottom-up approach, is (1) to
observe, according to Knowledge Management methods, a course characterized by
these three criteria. The observed course concerns project management learning.
Its observation allows us (2) to highlight and to analyze the problems
encountered by the actors (students, tutors, designers) and (3) to propose
tools to solve or improve them. We particularly study the relevance and the
limits of the existing monitoring and experience sharing tools. We finally
propose a result in the form of the tool MEShaT (Monitoring and Experience
Sharing Tool) and end on the perspectives offered by these researches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2141</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2141</id><created>2010-10-11</created><updated>2011-08-18</updated><authors><author><keyname>Opsahl</keyname><forenames>Tore</forenames></author><author><keyname>Hogan</keyname><forenames>Bernie</forenames></author></authors><title>Modeling the evolution of continuously-observed networks: Communication
  in a Facebook-like community</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building on existing stochastic actor-oriented models for panel data, we
employ a conditional logistic framework to explore growth mechanisms for tie
creation in continuously-observed networks. This framework models the
likelihood of tie formation distinguishing it from hazard models that consider
time to tie formation. It enables multiple growth mechanisms for network
evolution (homophily, focus constraints, reinforcement, reciprocity, triadic
closure, and popularity) to be modeled simultaneously. We apply this framework
to communication within a Facebook-like community. The findings exemplify the
inadequacy of descriptive measures that test single mechanisms independently.
They also indicate how system design shapes behavior and network evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2148</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2148</id><created>2010-10-11</created><authors><author><keyname>Bonifati</keyname><forenames>Angela</forenames></author><author><keyname>Mecca</keyname><forenames>Giansalvatore</forenames></author><author><keyname>Sileo</keyname><forenames>Domenica</forenames></author><author><keyname>Summa</keyname><forenames>Gianvito</forenames></author></authors><title>Ontological Matchmaking in Recommender Systems</title><categories>cs.DB</categories><comments>28 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electronic marketplace offers great potential for the recommendation of
supplies. In the so called recommender systems, it is crucial to apply
matchmaking strategies that faithfully satisfy the predicates specified in the
demand, and take into account as much as possible the user preferences. We
focus on real-life ontology-driven matchmaking scenarios and identify a number
of challenges, being inspired by such scenarios. A key challenge is that of
presenting the results to the users in an understandable and clear-cut fashion
in order to facilitate the analysis of the results. Indeed, such scenarios
evoke the opportunity to rank and group the results according to specific
criteria. A further challenge consists of presenting the results to the user in
an asynchronous fashion, i.e. the 'push' mode, along with the 'pull' mode, in
which the user explicitly issues a query, and displays the results. Moreover,
an important issue to consider in real-life cases is the possibility of
submitting a query to multiple providers, and collecting the various results.
We have designed and implemented an ontology-based matchmaking system that
suitably addresses the above challenges. We have conducted a comprehensive
experimental study, in order to investigate the usability of the system, the
performance and the effectiveness of the matchmaking strategies with real
ontological datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2157</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2157</id><created>2010-10-11</created><authors><author><keyname>Rashidi</keyname><forenames>Moslem</forenames></author><author><keyname>Haghighi</keyname><forenames>Kasra</forenames></author><author><keyname>Owrang</keyname><forenames>Arash</forenames></author><author><keyname>Viberg</keyname><forenames>Mats</forenames></author></authors><title>A Wideband Spectrum Sensing Method for Cognitive Radio using Sub-Nyquist
  Sampling</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is a fundamental component in cognitive radio. A major
challenge in this area is the requirement of a high sampling rate in the
sensing of a wideband signal. In this paper a wideband spectrum sensing model
is presented that utilizes a sub-Nyquist sampling scheme to bring substantial
savings in terms of the sampling rate. The correlation matrix of a finite
number of noisy samples is computed and used by a subspace estimator to detect
the occupied and vacant channels of the spectrum. In contrast with common
methods, the proposedmethod does not need the knowledge of signal properties
that mitigates the uncertainty problem. We evaluate the performance of this
method by computing the probability of detecting signal occupancy in terms of
the number of samples and the SNR of randomly generated signals. The results
show a reliable detection even in low SNR and small number of samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2158</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2158</id><created>2010-10-11</created><authors><author><keyname>Rashidi</keyname><forenames>Moslem</forenames></author></authors><title>Non-uniform sampling and reconstruction of multi-band signals and its
  application in wideband spectrum sensing of cognitive radio</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling theories lie at the heart of signal processing devices and
communication systems. To accommodate high operating rates while retaining low
computational cost, efficient analog-to digital (ADC) converters must be
developed. Many of limitations encountered in current converters are due to a
traditional assumption that the sampling state needs to acquire the data at the
Nyquist rate, corresponding to twice the signal bandwidth. In this thesis a
method of sampling far below the Nyquist rate for sparse spectrum multiband
signals is investigated. The method is called periodic non-uniform sampling,
and it is useful in a variety of applications such as data converters, sensor
array imaging and image compression. Firstly, a model for the sampling system
in the frequency domain is prepared. It relates the Fourier transform of
observed compressed samples with the unknown spectrum of the signal. Next, the
reconstruction process based on the topic of compressed sensing is provided. We
show that the sampling parameters play an important role on the average sample
ratio and the quality of the reconstructed signal. The concept of condition
number and its effect on the reconstructed signal in the presence of noise is
introduced, and a feasible approach for choosing a sample pattern with a low
condition number is given. We distinguish between the cases of known spectrum
and unknown spectrum signals respectively. One of the model parameters is
determined by the signal band locations that in case of unknown spectrum
signals should be estimated from sampled data. Therefore, we applied both
subspace methods and non-linear least square methods for estimation of this
parameter. We also used the information theoretic criteria (Akaike and MDL) and
the exponential fitting test techniques for model order selection in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2160</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2160</id><created>2010-10-11</created><updated>2010-11-19</updated><authors><author><keyname>Huang</keyname><forenames>Xuqing</forenames></author><author><keyname>Gao</keyname><forenames>Jianxi</forenames></author><author><keyname>Buldyrev</keyname><forenames>Sergey V.</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Stanley</keyname><forenames>H. Eugene</forenames></author></authors><title>Robustness of interdependent networks under targeted attack</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>11 pages, 2 figures</comments><doi>10.1103/PhysRevE.83.065101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When an initial failure of nodes occurs in interdependent networks, a cascade
of failure between the networks occurs. Earlier studies focused on random
initial failures. Here we study the robustness of interdependent networks under
targeted attack on high or low degree nodes. We introduce a general technique
and show that the {\it targeted-attack} problem in interdependent networks can
be mapped to the {\it random-attack} problem in a transformed pair of
interdependent networks. We find that when the highly connected nodes are
protected and have lower probability to fail, in contrast to single scale free
(SF) networks where the percolation threshold $p_c=0$, coupled SF networks are
significantly more vulnerable with $p_c$ significantly larger than zero. The
result implies that interdependent networks are difficult to defend by
strategies such as protecting the high degree nodes that have been found useful
to significantly improve robustness of single networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2173</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2173</id><created>2010-10-11</created><authors><author><keyname>Lande</keyname><forenames>D.</forenames></author><author><keyname>Snarskii</keyname><forenames>A.</forenames></author><author><keyname>Zhenirovskyy</keyname><forenames>M.</forenames></author></authors><title>Complex network model of the phase transition on the wealth
  distributions - from Pareto to the society without middle class</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model of distribution of the wealth in a society based on the properties of
complex networks has been proposed. The wealth is interpreted as a consequence
of communication possibilities and proportional to the number of connections
possessed by a person (as a vertex of the social network). Numerical simulation
of wealth distribution shows a transition from the Pareto law to distribution
with a gap demonstrating the absence of the middle class. Such a transition has
been described as a second-order phase transition, the order parameter has been
introduced and the value of the critical exponent has been found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2186</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2186</id><created>2010-10-11</created><updated>2011-04-07</updated><authors><author><keyname>Mirtabatabaei</keyname><forenames>Anahita</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>On Opinion Dynamics in Heterogeneous Networks</title><categories>math-ph cs.SI math.MP physics.soc-ph</categories><comments>6 pages, ACC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the opinion dynamics model recently introduced by
Hegselmann and Krause: each agent in a group maintains a real number describing
its opinion; and each agent updates its opinion by averaging all other opinions
that are within some given confidence range. The confidence ranges are distinct
for each agent. This heterogeneity and state-dependent topology leads to
poorly-understood complex dynamic behavior. We classify the agents via their
interconnection topology and, accordingly, compute the equilibria of the
system. We conjecture that any trajectory of this model eventually converges to
a steady state under fixed topology. To establish this conjecture, we derive
two novel sufficient conditions: both conditions guarantee convergence and
constant topology for infinite time, while one condition also guarantees
monotonicity of the convergence. In the evolution under fixed topology for
infinite time, we define leader groups that determine the followers' rate and
direction of convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2196</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2196</id><created>2010-10-11</created><updated>2010-11-03</updated><authors><author><keyname>Glek</keyname><forenames>T.</forenames></author><author><keyname>Hubicka</keyname><forenames>J.</forenames></author></authors><title>Optimizing real world applications with GCC Link Time Optimization</title><categories>cs.PL</categories><comments>21 pages, published version</comments><msc-class>68N20</msc-class><journal-ref>Proceedings of the 2010 GCC Developers' Summit</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GCC has a new infrastructure to support a link time optimization (LTO). The
infrastructure is designed to allow linking of large applications using a
special mode (WHOPR) which support parallelization of the compilation process.
In this paper we present overview of the design and implementation of WHOPR and
present test results of its behavior when optimizing large applications. We
give numbers on compile time, memory usage and code quality comparisons to the
classical file by file based optimization model. In particular we focus on
Firefox web browser. We show main problems seen only when compiling a large
application, such as startup time and code size growth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2198</identifier>
 <datestamp>2012-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2198</id><created>2010-10-11</created><updated>2012-05-14</updated><authors><author><keyname>Aldroubi</keyname><forenames>Akram</forenames></author><author><keyname>Sekmen</keyname><forenames>Ali</forenames></author></authors><title>Nearness to Local Subspace Algorithm for Subspace and Motion
  Segmentation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing interest in computer science, engineering, and mathematics
for modeling signals in terms of union of subspaces and manifolds. Subspace
segmentation and clustering of high dimensional data drawn from a union of
subspaces are especially important with many practical applications in computer
vision, image and signal processing, communications, and information theory.
This paper presents a clustering algorithm for high dimensional data that comes
from a union of lower dimensional subspaces of equal and known dimensions. Such
cases occur in many data clustering problems, such as motion segmentation and
face recognition. The algorithm is reliable in the presence of noise, and
applied to the Hopkins 155 Dataset, it generates the best results to date for
motion segmentation. The two motion, three motion, and overall segmentation
rates for the video sequences are 99.43%, 98.69%, and 99.24%, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2236</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2236</id><created>2010-10-11</created><updated>2011-03-16</updated><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>On the Scaling Law for Compressive Sensing and its Applications</title><categories>cs.IT math.IT</categories><comments>Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  $\ell_1$ minimization can be used to recover sufficiently sparse unknown
signals from compressed linear measurements. In fact, exact thresholds on the
sparsity (the size of the support set), under which with high probability a
sparse signal can be recovered from i.i.d. Gaussian measurements, have been
computed and are referred to as &quot;weak thresholds&quot; \cite{D}. It was also known
that there is a tradeoff between the sparsity and the $\ell_1$ minimization
recovery stability. In this paper, we give a \emph{closed-form}
characterization for this tradeoff which we call the scaling law for
compressive sensing recovery stability. In a nutshell, we are able to show that
as the sparsity backs off $\varpi$ ($0&lt;\varpi&lt;1$) from the weak threshold of
$\ell_1$ recovery, the parameter for the recovery stability will scale as
$\frac{1}{\sqrt{1-\varpi}}$. Our result is based on a careful analysis through
the Grassmann angle framework for the Gaussian measurement matrix. We will
further discuss how this scaling law helps in analyzing the iterative
reweighted $\ell_1$ minimization algorithms. If the nonzero elements over the
signal support follow an amplitude probability density function (pdf)
$f(\cdot)$ whose $t$-th derivative $f^{t}(0) \neq 0$ for some integer $t \geq
0$, then a certain iterative reweighted $\ell_1$ minimization algorithm can be
analytically shown to lift the phase transition thresholds (weak thresholds) of
the plain $\ell_1$ minimization algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2247</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2247</id><created>2010-10-11</created><authors><author><keyname>Manchester</keyname><forenames>Ian R.</forenames></author><author><keyname>Tobenkin</keyname><forenames>Mark M.</forenames></author><author><keyname>Levashov</keyname><forenames>Michael</forenames></author><author><keyname>Tedrake</keyname><forenames>Russ</forenames></author></authors><title>Regions of Attraction for Hybrid Limit Cycles of Walking Robots</title><categories>math.OC cs.RO cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper illustrates the application of recent research in
region-of-attraction analysis for nonlinear hybrid limit cycles. Three example
systems are analyzed in detail: the van der Pol oscillator, the &quot;rimless
wheel&quot;, and the &quot;compass gait&quot;, the latter two being simplified models of
underactuated walking robots. The method used involves decomposition of the
dynamics about the target cycle into tangential and transverse components, and
a search for a Lyapunov function in the transverse dynamics using
sum-of-squares analysis (semidefinite programming). Each example illuminates
different aspects of the procedure, including optimization of transversal
surfaces, the handling of impact maps, optimization of the Lyapunov function,
and orbitally-stabilizing control design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2262</identifier>
 <datestamp>2012-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2262</id><created>2010-10-11</created><updated>2012-11-15</updated><authors><author><keyname>Shamsi</keyname><forenames>Davood</forenames></author><author><keyname>Taheri</keyname><forenames>Nicole</forenames></author><author><keyname>Zhu</keyname><forenames>Zhisu</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>On Sensor Network Localization Using SDP Relaxation</title><categories>math.MG cs.DS math.OC</categories><comments>20 pages, 4 figures, submitted to the Fields Institute Communications
  Series on Discrete Geometry and Optimization</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Semidefinite Programming (SDP) relaxation is an effective computational
method to solve a Sensor Network Localization problem, which attempts to
determine the locations of a group of sensors given the distances between some
of them [11]. In this paper, we analyze and determine new sufficient conditions
and formulations that guarantee that the SDP relaxation is exact, i.e., gives
the correct solution. These conditions can be useful for designing sensor
networks and managing connectivities in practice.
  Our main contribution is twofold: We present the first non-asymptotic bound
on the connectivity or radio range requirement of the sensors in order to
ensure the network is uniquely localizable. Determining this range is a key
component in the design of sensor networks, and we provide a result that leads
to a correct localization of each sensor, for any number of sensors. Second, we
introduce a new class of graphs that can always be correctly localized by an
SDP relaxation. Specifically, we show that adding a simple objective function
to the SDP relaxation model will ensure that the solution is correct when
applied to a triangulation graph. Since triangulation graphs are very sparse,
this is informationally efficient, requiring an almost minimal amount of
distance information. We also analyze a number objective functions for the SDP
relaxation to solve the localization problem for a general graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2285</identifier>
 <datestamp>2011-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2285</id><created>2010-10-11</created><updated>2011-09-09</updated><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author><author><keyname>Rakhlin</keyname><forenames>Alexander</forenames></author></authors><title>Information-based complexity, feedback and dynamics in convex
  programming</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>final version; to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the intrinsic limitations of sequential convex optimization through
the lens of feedback information theory. In the oracle model of optimization,
an algorithm queries an {\em oracle} for noisy information about the unknown
objective function, and the goal is to (approximately) minimize every function
in a given class using as few queries as possible. We show that, in order for a
function to be optimized, the algorithm must be able to accumulate enough
information about the objective. This, in turn, puts limits on the speed of
optimization under specific assumptions on the oracle and the type of feedback.
Our techniques are akin to the ones used in statistical literature to obtain
minimax lower bounds on the risks of estimation procedures; the notable
difference is that, unlike in the case of i.i.d. data, a sequential
optimization algorithm can gather observations in a {\em controlled} manner, so
that the amount of information at each step is allowed to change in time. In
particular, we show that optimization algorithms often obey the law of
diminishing returns: the signal-to-noise ratio drops as the optimization
algorithm approaches the optimum. To underscore the generality of the tools, we
use our approach to derive fundamental lower bounds for a certain active
learning problem. Overall, the present work connects the intuitive notions of
information in optimization, experimental design, estimation, and active
learning to the quantitative notion of Shannon information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2286</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2286</id><created>2010-10-11</created><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author></authors><title>Divergence-based characterization of fundamental limitations of adaptive
  dynamical systems</title><categories>cs.IT math.IT math.OC</categories><comments>8 pages, uses ieeeconf.cls; to appear in Proc. 48th Annual Allerton
  Conf. on Communication, Control and Computing (2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive dynamical systems arise in a multitude of contexts, e.g.,
optimization, control, communications, signal processing, and machine learning.
A precise characterization of their fundamental limitations is therefore of
paramount importance. In this paper, we consider the general problem of
adaptively controlling and/or identifying a stochastic dynamical system, where
our {\em a priori} knowledge allows us to place the system in a subset of a
metric space (the uncertainty set). We present an information-theoretic
meta-theorem that captures the trade-off between the metric complexity (or
richness) of the uncertainty set, the amount of information acquired online in
the process of controlling and observing the system, and the residual
uncertainty remaining after the observations have been collected. Following the
approach of Zames, we quantify {\em a priori} information by the Kolmogorov
(metric) entropy of the uncertainty set, while the information acquired online
is expressed as a sum of information divergences. The general theory is used to
derive new minimax lower bounds on the metric identification error, as well as
to give a simple derivation of the minimum time needed to stabilize an
uncertain stochastic linear system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2287</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2287</id><created>2010-10-11</created><authors><author><keyname>Al-Bataineh</keyname><forenames>Omar I.</forenames></author><author><keyname>van der Meyden</keyname><forenames>Ron</forenames></author></authors><title>Abstraction for Epistemic Model Checking of Dining Cryptographers-based
  Protocols</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes an abstraction for protocols that are based on multiple
rounds of Chaum's Dining Cryptographers protocol. It is proved that the
abstraction preserves a rich class of specifications in the logic of knowledge,
including specifications describing what an agent knows about other agents'
knowledge. This result can be used to optimize model checking of Dining
Cryptographers-based protocols, and applied within a methodology for
knowledge-based program implementation and verification. Some case studies of
such an application are given, for a protocol that uses the Dining
Cryptographers protocol as a primitive in an anonymous broadcast system.
Performance results are given for model checking knowledge-based specifications
in the concrete and abstract models of this protocol, and some new conclusions
about the protocol are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2296</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2296</id><created>2010-10-12</created><authors><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Das</keyname><forenames>Anita</forenames></author><author><keyname>Rajendraprasad</keyname><forenames>Deepak</forenames></author><author><keyname>Varma</keyname><forenames>Nithin M.</forenames></author></authors><title>Rainbow Connection Number and Connected Dominating Sets</title><categories>math.CO cs.DM</categories><comments>14 pages</comments><msc-class>O5C15, 05C69 (Primary), 05C12, 05C40 (Secondary)</msc-class><doi>10.1002/jgt.20643</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Rainbow connection number rc(G) of a connected graph G is the minimum number
of colours needed to colour the edges of G, so that every pair of vertices is
connected by at least one path in which no two edges are coloured the same. In
this paper we show that for every connected graph G, with minimum degree at
least 2, the rainbow connection number is upper bounded by {\gamma}_c(G) + 2,
where {\gamma}_c(G) is the connected domination number of G. Bounds of the form
diameter(G) \leq rc(G) \leq diameter(G) + c, 1 \leq c \leq 4, for many special
graph classes follow as easy corollaries from this result. This includes
interval graphs, AT-free graphs, circular arc graphs, threshold graphs, and
chain graphs all with minimum degree at least 2 and connected. We also show
that every bridge-less chordal graph G has rc(G) \leq 3.radius(G). In most of
these cases, we also demonstrate the tightness of the bounds. An extension of
this idea to two-step dominating sets is used to show that for every connected
graph on n vertices with minimum degree {\delta}, the rainbow connection number
is upper bounded by 3n/({\delta} + 1) + 3. This solves an open problem of
Schiermeyer (2009), improving the previously best known bound of 20n/{\delta}
by Krivelevich and Yuster (2010). Moreover, this bound is seen to be tight up
to additive factors by a construction of Caro et al. (2008).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2312</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2312</id><created>2010-10-12</created><updated>2013-04-27</updated><authors><author><keyname>Aksoy</keyname><forenames>Sinan</forenames></author><author><keyname>Azzam</keyname><forenames>Adam</forenames></author><author><keyname>Coppersmith</keyname><forenames>Chaya</forenames></author><author><keyname>Glass</keyname><forenames>Julie</forenames></author><author><keyname>Karaali</keyname><forenames>Gizem</forenames></author><author><keyname>Zhao</keyname><forenames>Xueying</forenames></author><author><keyname>Zhu</keyname><forenames>Xinjing</forenames></author></authors><title>A Cost-Minimizing Algorithm for School Choice</title><categories>math.OC cs.GT math.CO</categories><comments>ISAIM 2012 (International Symposium on Artificial Intelligence and
  Mathematics (ISAIM 2012), Fort Lauderdale, Florida, USA, January 9-11, 2012)
  Proceedings, 2012</comments><msc-class>90C27, 91A40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The school choice problem concerns the design and implementation of matching
mechanisms that produce school assignments for students within a given public
school district. In this note we define a simple student-optimal criterion that
is not met by any previously employed mechanism in the school choice
literature. We then use this criterion to adapt a well-known combinatorial
optimization technique (Hungarian algorithm) to the school choice problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2337</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2337</id><created>2010-10-12</created><authors><author><keyname>C&#xe1;mara</keyname><forenames>Javier</forenames><affiliation>INRIA, France</affiliation></author><author><keyname>Canal</keyname><forenames>Carlos</forenames><affiliation>University of M&#xe1;laga</affiliation></author><author><keyname>Sala&#xfc;n</keyname><forenames>Gwen</forenames><affiliation>INRIA, France</affiliation></author></authors><title>Proceedings International Workshop on Component and Service
  Interoperability</title><categories>cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 37, 2010</journal-ref><doi>10.4204/EPTCS.37</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of WCSI 2010, the International Workshop
on Component and Service Interoperability. WCSI 2010 was held in Malaga (Spain)
on June 29th, 2010 as a satellite event of the TOOLS 2010 Federated
Conferences. The papers published in this volume tackle different issues that
are currently central to our community, namely definition of expressive
interface languages, formal models and approaches to software composition and
adaptation, interface-based compatibility and substitutability, and
verification techniques for distributed software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2345</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2345</id><created>2010-10-12</created><authors><author><keyname>Albertoni</keyname><forenames>Riccardo</forenames></author><author><keyname>De Martino</keyname><forenames>Monica</forenames></author></authors><title>Using Context Dependent Semantic Similarity to Browse Information
  Resources: an Application for the Industrial Design</title><categories>cs.DL cs.IR</categories><journal-ref>First workshop on multimedia Annotation and Retrieval enabled by
  Shared Ontologies, Genoa, Italy, (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the semantic interpretation of information resources
(e.g., images, videos, 3D models). We present a case study of an approach based
on semantic and context dependent similarity applied to the industrial design.
Different application contexts are considered and modelled to browse a
repository of 3D digital objects according to different perspectives. The paper
briefly summarises the basic concepts behind the semantic similarity approach
and illustrates its application and results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2354</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2354</id><created>2010-10-12</created><authors><author><keyname>Karus</keyname><forenames>Siim</forenames></author><author><keyname>Dumas</keyname><forenames>Marlon</forenames></author></authors><title>Predicting Coding Effort in Projects Containing XML Code</title><categories>cs.SE</categories><acm-class>D.2.7; D.2.8; D.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of predicting the coding effort for a
subsequent year of development by analysing metrics extracted from project
repositories, with an emphasis on projects containing XML code. The study
considers thirteen open source projects and applies machine learning algorithms
to generate models to predict one-year coding effort, measured in terms of
lines of code added, modified and deleted. Both organisational and code metrics
associated to revisions are taken into account. The results show that coding
effort is highly determined by the expertise of developers while source code
metrics have little effect on improving the accuracy of estimations of coding
effort. The study also shows that models trained on one project are unreliable
at estimating effort in other projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2358</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2358</id><created>2010-10-12</created><authors><author><keyname>Campagna</keyname><forenames>Andrea</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>On Finding Frequent Patterns in Event Sequences</title><categories>cs.DS cs.DB</categories><comments>Appears in proceedings of ICDM '10: The 10th IEEE International
  Conference on Data Mining. Publisher: IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a directed acyclic graph with labeled vertices, we consider the problem
of finding the most common label sequences (&quot;traces&quot;) among all paths in the
graph (of some maximum length m). Since the number of paths can be huge, we
propose novel algorithms whose time complexity depends only on the size of the
graph, and on the frequency epsilon of the most frequent traces. In addition,
we apply techniques from streaming algorithms to achieve space usage that
depends only on epsilon, and not on the number of distinct traces. The abstract
problem considered models a variety of tasks concerning finding frequent
patterns in event sequences. Our motivation comes from working with a data set
of 2 million RFID readings from baggage trolleys at Copenhagen Airport. The
question of finding frequent passenger movement patterns is mapped to the above
problem. We report on experimental findings for this data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2368</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2368</id><created>2010-10-12</created><authors><author><keyname>Usatyuk</keyname><forenames>V. S.</forenames></author></authors><title>Lattice Problems and Their Reductions(Russian)</title><categories>cs.CR</categories><comments>12 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presets a review of lattice problems. Paper contains the main
eighteen problems with their reductions and referents to his cryptography
application. As an example of reduction, we detail analyze connection between
SVP and CVP. Moreover, we give an Ajtai theorem and demonstrate its role in
lattice based cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2371</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2371</id><created>2010-10-12</created><authors><author><keyname>Campagna</keyname><forenames>Andrea</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>On Finding Similar Items in a Stream of Transactions</title><categories>cs.DS cs.DB</categories><comments>Appears in proceedings of the IEEE International Workshop on
  Knowledge Discovery Using Cloud and Distributed Computing Platforms (KDCloud,
  2010); publisher: IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While there has been a lot of work on finding frequent itemsets in
transaction data streams, none of these solve the problem of finding similar
pairs according to standard similarity measures. This paper is a first attempt
at dealing with this, arguably more important, problem. We start out with a
negative result that also explains the lack of theoretical upper bounds on the
space usage of data mining algorithms for finding frequent itemsets: Any
algorithm that (even only approximately and with a chance of error) finds the
most frequent k-itemset must use space Omega(min{mb,n^k,(mb/phi)^k}) bits,
where mb is the number of items in the stream so far, n is the number of
distinct items and phi is a support threshold. To achieve any non-trivial space
upper bound we must thus abandon a worst-case assumption on the data stream. We
work under the model that the transactions come in random order, and show that
surprisingly, not only is small-space similarity mining possible for the most
common similarity measures, but the mining accuracy improves with the length of
the stream for any fixed support threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2379</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2379</id><created>2010-10-12</created><updated>2010-10-14</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Opthof</keyname><forenames>Tobias</forenames></author></authors><title>Remaining problems with the &quot;New Crown Indicator&quot; (MNCS) of the CWTS</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In their article, entitled &quot;Towards a new crown indicator: some theoretical
considerations,&quot; Waltman et al. (2010; at arXiv:1003.2167) show that the &quot;old
crown indicator&quot; of CWTS in Leiden was mathematically inconsistent and that one
should move to the normalization as applied in the &quot;new crown indicator.&quot;
Although we now agree about the statistical normalization, the &quot;new crown
indicator&quot; inherits the scientometric problems of the &quot;old&quot; one in treating
subject categories of journals as a standard for normalizing differences in
citation behavior among fields of science.
  We further note that the &quot;mean&quot; is not a proper statistics for measuring
differences among skewed distributions. Without changing the acronym of &quot;MNCS,&quot;
one could define the &quot;Median Normalized Citation Score.&quot; This would relate the
new crown indicator directly to the percentile approach that is, for example,
used in the Science and Engineering Indicators of US National Science Board
(2010). The median is by definition equal to the 50th percentile. The indicator
can thus easily be extended with the 1% (= 99th percentile) most highly-cited
papers (Bornmann et al., in press). The seeming disadvantage of having to use
non-parametric statistics is more than compensated by possible gains in the
precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2382</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2382</id><created>2010-10-12</created><updated>2011-06-27</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Altenbach</keyname><forenames>Fabian</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>Capacity Achieving Modulation for Fixed Constellations with Average
  Power Constraint</title><categories>cs.IT math.IT</categories><comments>Strict concavity assumption added to Propositions 2 and 3. This
  assumption is missing in the ICC 2011 proceedings version of this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity achieving probability mass function (PMF) of a finite signal
constellation with an average power constraint is in most cases non-uniform. A
common approach to generate non-uniform input PMFs is Huffman shaping, which
consists of first approximating the capacity achieving PMF by a sampled
Gaussian density and then to calculate the Huffman code of the sampled Gaussian
density. The Huffman code is then used as a prefix-free modulation code. This
approach showed good results in practice, can however lead to a significant gap
to capacity. In this work, a method is proposed that efficiently constructs
optimal prefix-free modulation codes for any finite signal constellation with
average power constraint in additive noise. The proposed codes operate as close
to capacity as desired. The major part of this work elaborates an analytical
proof of this property. The proposed method is applied to 64-QAM in AWGN and
numeric results are given, which show that, opposed to Huffman shaping, by
using the proposed method, it is possible to operate very close to capacity
over the whole range of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2384</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2384</id><created>2010-10-12</created><authors><author><keyname>Lupea</keyname><forenames>Mihaiela</forenames></author><author><keyname>Tatar</keyname><forenames>Doina</forenames></author><author><keyname>Marian</keyname><forenames>Zsuzsana</forenames></author></authors><title>Learning Taxonomy for Text Segmentation by Formal Concept Analysis</title><categories>cs.CL</categories><comments>Presented at Synasc 2010, Timisoara, Romania</comments><msc-class>68T50, 03H65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the problems of deriving a taxonomy from a text and
concept-oriented text segmentation are approached. Formal Concept Analysis
(FCA) method is applied to solve both of these linguistic problems. The
proposed segmentation method offers a conceptual view for text segmentation,
using a context-driven clustering of sentences. The Concept-oriented Clustering
Segmentation algorithm (COCS) is based on k-means linear clustering of the
sentences. Experimental results obtained using COCS algorithm are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2396</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2396</id><created>2010-10-12</created><authors><author><keyname>Schroeder</keyname><forenames>Matthias</forenames></author></authors><title>N^N^N does not satisfy Normann's condition</title><categories>math.LO cs.LO</categories><comments>10 pages</comments><msc-class>03D78, 03D65, 18B30, 54C35, 54D55</msc-class><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the Kleene-Kreisel space $N^N^N$ does not satisfy Normann's
condition. A topological space $X$ is said to fulfil Normann's condition, if
every functionally closed subset of $X$ is an intersection of clopen sets. The
investigation of this property is motivated by its strong relationship to a
problem in Computable Analysis. D. Normann has proved that in order to
establish non-coincidence of the extensional hierarchy and the intensional
hierarchy of functionals over the reals it is enough to show that $N^N^N$ fails
the above condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2412</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2412</id><created>2010-10-12</created><authors><author><keyname>Vabishchevich</keyname><forenames>Petr N.</forenames></author></authors><title>Splitting schemes for hyperbolic heat conduction equation</title><categories>cs.NA</categories><msc-class>80A20, 65M06, 65M12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rapid processes of heat transfer are not described by the standard heat
conduction equation. To take into account a finite velocity of heat transfer,
we use the hyperbolic model of heat conduction, which is connected with the
relaxation of heat fluxes. In this case, the mathematical model is based on a
hyperbolic equation of second order or a system of equations for the
temperature and heat fluxes. In this paper we construct for the hyperbolic heat
conduction equation the additive schemes of splitting with respect to
directions. Unconditional stability of locally one-dimensional splitting
schemes is established. New splitting schemes are proposed and studied for a
system of equations written in terms of the temperature and heat fluxes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2420</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2420</id><created>2010-10-12</created><updated>2012-02-03</updated><authors><author><keyname>Fijalkow</keyname><forenames>Nathana&#xeb;l</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Horn</keyname><forenames>Florian</forenames><affiliation>LIAFA</affiliation></author></authors><title>The surprizing complexity of generalized reachability games</title><categories>cs.CC cs.GT cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Games on graphs provide a natural and powerful model for reactive systems. In
this paper, we consider generalized reachability objectives, defined as
conjunctions of reachability objectives. We first prove that deciding the
winner in such games is $\PSPACE$-complete, although it is fixed-parameter
tractable with the number of reachability objectives as parameter. Moreover, we
consider the memory requirements for both players and give matching upper and
lower bounds on the size of winning strategies. In order to allow more
efficient algorithms, we consider subclasses of generalized reachability games.
We show that bounding the size of the reachability sets gives two natural
subclasses where deciding the winner can be done efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2432</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2432</id><created>2010-10-12</created><authors><author><keyname>Garg</keyname><forenames>Rachit Mohan</forenames></author><author><keyname>Kapoor</keyname><forenames>Shipra</forenames></author><author><keyname>Kumar</keyname><forenames>Kapil</forenames></author><author><keyname>Ansari</keyname><forenames>Mohd. Dilshad</forenames></author></authors><title>Transmitting Video-on-Demand Effectively</title><categories>cs.MM</categories><comments>5 pages</comments><journal-ref>Universal Journal of Computer Science and Engineering Technology
  (1) 1, October 2010, UniCSE</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now-a-days internet has become a vast source of entertainment &amp; new services
are available in quick succession which provides entertainment to the users.
One of this service i.e. Video-on-Demand is most hyped service in this context.
Transferring the video over the network with less error is the main objective
of the service providers. In this paper we present an algorithm for routing the
video to the user in an effective manner along with a method that ensures less
error rate than others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2433</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2433</id><created>2010-10-12</created><authors><author><keyname>Wang</keyname><forenames>Chih-Chun</forenames></author></authors><title>Capacity of 1-to-K Broadcast Packet Erasure Channels with Channel Output
  Feedback</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures. Published in Allerton 2010. The journal version
  of this work was submitted to IEEE Trans IT in May, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the 1-to-K broadcast packet erasure channel (PEC),
which is a generalization of the broadcast binary erasure channel from the
binary symbol to that of arbitrary finite fields GF(q) with sufficiently large
q. We consider the setting in which the source node has instant feedback of the
channel outputs of the K receivers after each transmission. Such a setting
directly models network coded packet transmission in the downlink direction
with integrated feedback mechanisms (such as Automatic Repeat reQuest (ARQ)).
  The main results of this paper are: (i) The capacity region for general
1-to-3 broadcast PECs, and (ii) The capacity region for two classes of 1-to-K
broadcast PECs: the symmetric PECs, and the spatially independent PECs with
one-sided fairness constraints. This paper also develops (iii) A pair of outer
and inner bounds of the capacity region for arbitrary 1-to-K broadcast PECs,
which can be evaluated by any linear programming solver. For most practical
scenarios, the outer and inner bounds meet and thus jointly characterize the
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2436</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2436</id><created>2010-10-12</created><authors><author><keyname>Wang</keyname><forenames>Chih-Chun</forenames></author></authors><title>Capacity of 1-to-K Broadcast Packet Erasure Channels with Channel Output
  Feedback (Full Version)</title><categories>cs.IT math.IT</categories><comments>29 pages, 10 figures. This manuscript was submitted to IEEE Trans IT
  in May 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the 1-to-K broadcast packet erasure channel (PEC),
which is a generalization of the broadcast binary erasure channel from the
binary symbol to that of arbitrary finite fields GF(q) with sufficiently large
q. We consider the setting in which the source node has instant feedback of the
channel outputs of the K receivers after each transmission. The capacity region
of the 1-to-K PEC with COF was previously known only for the case K=2. Such a
setting directly models network coded packet transmission in the downlink
direction with integrated feedback mechanisms (such as Automatic Repeat reQuest
(ARQ)).
  The main results of this paper are: (i) The capacity region for general
1-to-3 broadcast PECs, and (ii) The capacity region for two types of 1-to-$K$
broadcast PECs: the symmetric PECs, and the spatially independent PECs with
one-sided fairness constraints. This paper also develops (iii) A pair of outer
and inner bounds of the capacity region for arbitrary 1-to-K broadcast PECs,
which can be easily evaluated by any linear programming solver. The proposed
inner bound is proven by a new class of intersession network coding schemes,
termed the packet evolution schemes, which is based on the concept of code
alignment in GF(q) that is in parallel with the interference alignment
techniques for the Euclidean space. Extensive numerical experiments show that
the outer and inner bounds meet for almost all broadcast PECs encountered in
practical scenarios and thus effectively bracket the capacity of general 1-to-K
broadcast PECs with COF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2437</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2437</id><created>2010-10-12</created><authors><author><keyname>Mehanna</keyname><forenames>Omar</forenames></author><author><keyname>Marcos</keyname><forenames>John</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>On Achievable Rates of the Two-user Symmetric Gaussian Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>7 pages, to appear in Allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Han-Kobayashi (HK) achievable sum rate for the two-user
symmetric Gaussian interference channel. We find the optimal power split ratio
between the common and private messages (assuming no time-sharing), and derive
a closed form expression for the corresponding sum rate. This provides a finer
understanding of the achievable HK sum rate, and allows for precise comparisons
between this sum rate and that of orthogonal signaling. One surprising finding
is that despite the fact that the channel is symmetric, allowing for asymmetric
power split ratio at both users (i.e., asymmetric rates) can improve the sum
rate significantly. Considering the high SNR regime, we specify the
interference channel value above which the sum rate achieved using asymmetric
power splitting outperforms the symmetric case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2438</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2438</id><created>2010-10-12</created><updated>2010-10-13</updated><authors><author><keyname>Aldinucci</keyname><forenames>Marco</forenames></author><author><keyname>Coppo</keyname><forenames>Mario</forenames></author><author><keyname>Damiani</keyname><forenames>Ferruccio</forenames></author><author><keyname>Drocco</keyname><forenames>Maurizio</forenames></author><author><keyname>Torquati</keyname><forenames>Massimo</forenames></author><author><keyname>Troina</keyname><forenames>Angelo</forenames></author></authors><title>On Designing Multicore-aware Simulators for Biological Systems</title><categories>cs.DC cs.CE q-bio.QM</categories><comments>19 pages + cover page</comments><report-no>129/2010</report-no><acm-class>D.1.3; D.3.2; C.1.3; G.3; I.6; J.3</acm-class><journal-ref>Proc. of the 19th Euromicro Intl. Conf. on Parallel, Distributed
  and Network-Based Computing (PDP), Ayia Napa, Cyprus, Feb. 2011. IEEE</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stochastic simulation of biological systems is an increasingly popular
technique in bioinformatics. It often is an enlightening technique, which may
however result in being computational expensive. We discuss the main
opportunities to speed it up on multi-core platforms, which pose new challenges
for parallelisation techniques. These opportunities are developed in two
general families of solutions involving both the single simulation and a bulk
of independent simulations (either replicas of derived from parameter sweep).
Proposed solutions are tested on the parallelisation of the CWC simulator
(Calculus of Wrapped Compartments) that is carried out according to proposed
solutions by way of the FastFlow programming framework making possible fast
development and efficient execution on multi-cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2439</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2439</id><created>2010-10-12</created><updated>2010-10-13</updated><authors><author><keyname>Belavkin</keyname><forenames>Roman V.</forenames></author></authors><title>Conservation Law of Utility and Equilibria in Non-Zero Sum Games</title><categories>cs.GT cs.AI math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note demonstrates how one can define a transformation of a
non-zero sum game into a zero sum, so that the optimal mixed strategy achieving
equilibrium always exists. The transformation is equivalent to introduction of
a passive player into a game (a player with a singleton set of pure
strategies), whose payoff depends on the actions of the active players, and it
is justified by the law of conservation of utility in a game. In a transformed
game, each participant plays against all other players, including the passive
player. The advantage of this approach is that the transformed game is zero-sum
and has an equilibrium solution. The optimal strategy and the value of the new
game, however, can be different from strategies that are rational in the
original game. We demonstrate the principle using the Prisoner's Dilemma
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2440</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2440</id><created>2010-10-12</created><updated>2010-10-19</updated><authors><author><keyname>Palanisamy</keyname><forenames>Giriprakash</forenames></author><author><keyname>Devarakonda</keyname><forenames>Ranjeet</forenames></author><author><keyname>Green</keyname><forenames>Jim</forenames></author><author><keyname>Wilson</keyname><forenames>Bruce</forenames></author></authors><title>Enabling Data Discovery through Virtual Internet Repositories</title><categories>cs.DL cs.IR</categories><comments>5</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Mercury is a federated metadata harvesting, search and retrieval tool based
on both open source and software developed at Oak Ridge National Laboratory. It
was originally developed for NASA, and the Mercury development consortium now
includes funding from NASA, USGS, and DOE. A major new version of Mercury was
developed during 2007. This new version provides orders of magnitude
improvements in search speed, support for additional metadata formats,
integration with Google Maps for spatial queries, support for RSS delivery of
search results, among other features. Mercury provides a single portal to
information contained in disparate data management systems. It collects
metadata and key data from contributing project servers distributed around the
world and builds a centralized index. The Mercury search interfaces then allow
the users to perform simple, fielded, spatial and temporal searches across
these metadata sources. This centralized repository of metadata with
distributed data sources provides extremely fast search results to the user,
while allowing data providers to advertise the availability of their data and
maintain complete control and ownership of that data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2441</identifier>
 <datestamp>2013-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2441</id><created>2010-10-12</created><authors><author><keyname>Sejdinovic</keyname><forenames>Dino</forenames></author><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author></authors><title>Note on Noisy Group Testing: Asymptotic Bounds and Belief Propagation
  Reconstruction</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, presented at the Forty-Eighth Annual Allerton
  Conference on Communication, Control, and Computing, September 29 - October
  1, 2010, Monticello, IL, USA</comments><doi>10.1109/ALLERTON.2010.5707018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An information theoretic perspective on group testing problems has recently
been proposed by Atia and Saligrama, in order to characterise the optimal
number of tests. Their results hold in the noiseless case, where only false
positives occur, and where only false negatives occur. We extend their results
to a model containing both false positives and false negatives, developing
simple information theoretic bounds on the number of tests required. Based on
these bounds, we obtain an improved order of convergence in the case of false
negatives only. Since these results are based on (computationally infeasible)
joint typicality decoding, we propose a belief propagation algorithm for the
detection of defective items and compare its actual performance to the
theoretical bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2446</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2446</id><created>2010-10-12</created><authors><author><keyname>Schymura</keyname><forenames>Daria</forenames></author></authors><title>An upper bound on the volume of the symmetric difference of a body and a
  congruent copy</title><categories>math.MG cs.CG</categories><comments>12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let A be a bounded subset of IR^d. We give an upper bound on the volume of
the symmetric difference of A and f(A) where f is a translation, a rotation, or
the composition of both, a rigid motion. The volume is measured by the
d-dimensional Hausdorff measure, which coincides with the Lebesgue measure for
Lebesgue measurable sets. We bound the volume of the symmetric difference of A
and f(A) in terms of the (d-1)-dimensional volume of the boundary of A and the
maximal distance of a boundary point to its image under f. The boundary is
measured by the (d-1)-dimensional Hausdorff measure, which matches the surface
area for sufficiently nice sets. In the case of translations, our bound is
sharp. In the case of rotations, we get a sharp bound under the assumption that
the boundary is sufficiently nice. The motivation to study these bounds comes
from shape matching. For two shapes A and B in IR^d and a class of
transformations, the matching problem asks for a transformation f such that
f(A) and B match optimally. The quality of the match is measured by some
similarity measure, for instance the volume of overlap. Let A and B be bounded
subsets of IR^d, and let F be the function that maps a rigid motion r to the
volume of overlap of r(A) and B. Maximizing this function is a shape matching
problem, and knowing that F is Lipschitz continuous helps to solve it. We apply
our results to bound the difference |F(r) - F(s)| for rigid motions r,s that
are close, implying that F is Lipschitz continuous for many metrics on the
space of rigid motions. Depending on the metric, also a Lipschitz constant can
be deduced from the bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2447</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2447</id><created>2010-10-12</created><authors><author><keyname>Mal-Sarkar</keyname><forenames>Tatini</forenames></author><author><keyname>Bhunia</keyname><forenames>Swarup</forenames></author></authors><title>Collaborative Trust: A Novel Paradigm of Trusted Mobile Computing</title><categories>cs.CR</categories><comments>3 pages, internal technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With increasing complexity of modern-day mobile devices, security of these
devices in presence of myriad attacks by an intelligent adversary is becoming a
major issue. The vast majority of cell phones still remain unsecured from many
existing and emerging security threats. To address the security threats in
mobile devices we are exploring a technology, which we refer as &quot;Collaborative
Trust&quot;. It is a technology that uses a system of devices cooperating with each
other (working in a fixed or ad-hoc network) to achieve the individual security
of each device. The idea is that each device is insecure by itself, since in
many cases it is incapable of checking its safety by itself (e.g. when it is
compromised it may lose its ability to monitor its own trustworthiness), but
together, they can ensure each other's security in a collaborative manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2450</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2450</id><created>2010-10-12</created><updated>2010-10-19</updated><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Flat Zipper-Unfolding Pairs for Platonic Solids</title><categories>cs.CG cs.DM</categories><comments>15 pages, 14 figures, 8 references. v2: Added one new figure. v3:
  Replaced Fig. 13 to remove a duplicate unfolding, reducing from 21 to 20 the
  distinct unfoldings. v4: Replaced Fig. 13 again, 18 distinct unfoldings</comments><msc-class>52B10</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that four of the five Platonic solids' surfaces may be cut open with
a Hamiltonian path along edges and unfolded to a polygonal net each of which
can &quot;zipper-refold&quot; to a flat doubly covered parallelogram, forming a rather
compact representation of the surface. Thus these regular polyhedra have
particular flat &quot;zipper pairs.&quot; No such zipper pair exists for a dodecahedron,
whose Hamiltonian unfoldings are &quot;zip-rigid.&quot; This report is primarily an
inventory of the possibilities, and raises more questions than it answers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2454</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2454</id><created>2010-10-12</created><authors><author><keyname>Barenboim</keyname><forenames>Leonid</forenames></author><author><keyname>Elkin</keyname><forenames>Michael</forenames></author></authors><title>Distributed Deterministic Edge Coloring using Bounded Neighborhood
  Independence</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the {edge-coloring} problem in the message-passing model of
distributed computing. This is one of the most fundamental and well-studied
problems in this area. Currently, the best-known deterministic algorithms for
(2Delta -1)-edge-coloring requires O(Delta) + log-star n time \cite{PR01},
where Delta is the maximum degree of the input graph. Also, recent results of
\cite{BE10} for vertex-coloring imply that one can get an
O(Delta)-edge-coloring in O(Delta^{epsilon} \cdot \log n) time, and an
O(Delta^{1 + epsilon})-edge-coloring in O(log Delta log n) time, for an
arbitrarily small constant epsilon &gt; 0.
  In this paper we devise a drastically faster deterministic edge-coloring
algorithm. Specifically, our algorithm computes an O(Delta)-edge-coloring in
O(Delta^{epsilon}) + log-star n time, and an O(Delta^{1 +
epsilon})-edge-coloring in O(log Delta) + log-star n time. This result improves
the previous state-of-the-art {exponentially} in a wide range of Delta,
specifically, for 2^{Omega(\log-star n)} \leq Delta \leq polylog(n). In
addition, for small values of Delta our deterministic algorithm outperforms all
the existing {randomized} algorithms for this problem.
  On our way to these results we study the {vertex-coloring} problem on the
family of graphs with bounded {neighborhood independence}. This is a large
family, which strictly includes line graphs of r-hypergraphs for any r = O(1),
and graphs of bounded growth. We devise a very fast deterministic algorithm for
vertex-coloring graphs with bounded neighborhood independence. This algorithm
directly gives rise to our edge-coloring algorithms, which apply to {general}
graphs.
  Our main technical contribution is a subroutine that computes an
O(Delta/p)-defective p-vertex coloring of graphs with bounded neighborhood
independence in O(p^2) + \log-star n time, for a parameter p, 1 \leq p \leq
Delta.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2457</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2457</id><created>2010-10-12</created><updated>2014-07-22</updated><authors><author><keyname>de Castro</keyname><forenames>Yohann</forenames><affiliation>LM-Orsay</affiliation></author></authors><title>Optimal designs for Lasso and Dantzig selector using Expander Codes</title><categories>math.ST cs.IT math.IT math.PR stat.ME stat.ML stat.TH</categories><comments>Last version with optimal bounds</comments><msc-class>62G05, 62J05, 62J12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the high-dimensional regression problem using adjacency
matrices of unbalanced expander graphs. In this frame, we prove that the
$\ell_{2}$-prediction error and the $\ell_{1}$-risk of the lasso and the
Dantzig selector are optimal up to an explicit multiplicative constant. Thus we
can estimate a high-dimensional target vector with an error term similar to the
one obtained in a situation where one knows the support of the largest
coordinates in advance.
  Moreover, we show that these design matrices have an explicit restricted
eigenvalue. Precisely, they satisfy the restricted eigenvalue assumption and
the compatibility condition with an explicit constant.
  Eventually, we capitalize on the recent construction of unbalanced expander
graphs due to Guruswami, Umans, and Vadhan, to provide a deterministic
polynomial time construction of these design matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2460</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2460</id><created>2010-10-12</created><authors><author><keyname>Krawczyk</keyname><forenames>Malgorzata</forenames></author><author><keyname>Muchnik</keyname><forenames>Lev</forenames></author><author><keyname>Ma&#x144;ka-Kraso&#x144;</keyname><forenames>Anna</forenames></author><author><keyname>Ku&#x142;akowski</keyname><forenames>Krzysztof</forenames></author></authors><title>Line graphs as social networks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>11 pages, 4 figures</comments><doi>10.1016/j.physa.2011.03.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The line graphs are clustered and assortative. They share these topological
features with some social networks. We argue that this similarity reveals the
cliquey character of the social networks. In the model proposed here, a social
network is the line graph of an initial network of families, communities,
interest groups, school classes and small companies. These groups play the role
of nodes, and individuals are represented by links between these nodes. The
picture is supported by the data on the LiveJournal network of about 8 x 10^6
people. In particular, sharp maxima of the observed data of the degree
dependence of the clustering coefficient C(k) are associated with cliques in
the social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2465</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2465</id><created>2010-10-12</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Shin</keyname><forenames>Jung C.</forenames></author></authors><title>How to evaluate universities in terms of their relative citation
  impacts: Fractional counting of citations and the normalization of
  differences among disciplines</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractional counting of citations can improve on ranking of multi-disciplinary
research units (such as universities) by normalizing the differences among
fields of science in terms of differences in citation behavior. Furthermore,
normalization in terms of citing papers abolishes the unsolved questions in
scientometrics about the delineation of fields of science in terms of journals
and normalization when comparing among different journals. Using publication
and citation data of seven Korean research universities, we demonstrate the
advantages and the differences in the rankings, explain the possible
statistics, and suggest ways to visualize the differences in (citing) audiences
in terms of a network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2466</identifier>
 <datestamp>2015-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2466</id><created>2010-10-12</created><authors><author><keyname>Hung</keyname><forenames>Ruo-Wei</forenames></author></authors><title>Constructing Two Edge-Disjoint Hamiltonian Cycles in Locally Twisted
  Cubes</title><categories>cs.DC cs.DM</categories><comments>7 pages, 4 figures</comments><journal-ref>Theoretical Computer Science 412/35 (2011) 4747-4753</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $n$-dimensional hypercube network $Q_n$ is one of the most popular
interconnection networks since it has simple structure and is easy to
implement. The $n$-dimensional locally twisted cube, denoted by $LTQ_n$, an
important variation of the hypercube, has the same number of nodes and the same
number of connections per node as $Q_n$. One advantage of $LTQ_n$ is that the
diameter is only about half of the diameter of $Q_n$. Recently, some
interesting properties of $LTQ_n$ were investigated. In this paper, we
construct two edge-disjoint Hamiltonian cycles in the locally twisted cube
$LTQ_n$, for any integer $n\geqslant 4$. The presence of two edge-disjoint
Hamiltonian cycles provides an advantage when implementing algorithms that
require a ring structure by allowing message traffic to be spread evenly across
the locally twisted cube.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2472</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2472</id><created>2010-10-12</created><updated>2016-03-04</updated><authors><author><keyname>Dvorak</keyname><forenames>Zdenek</forenames></author><author><keyname>Kral</keyname><forenames>Dan</forenames></author><author><keyname>Thomas</keyname><forenames>Robin</forenames></author></authors><title>Three-coloring triangle-free graphs on surfaces I. Extending a coloring
  to a disk with one triangle</title><categories>cs.DM</categories><comments>18 pages, 2 figures; v3: further reviewer remarks incorporated</comments><msc-class>05C15</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a plane graph with exactly one triangle T and all other cycles of
length at least 5, and let C be a facial cycle of G of length at most six. We
prove that a 3-coloring of C does not extend to a 3-coloring of G if and only
if C has length exactly six and there is a color x such that either G has an
edge joining two vertices of C colored x, or T is disjoint from C and every
vertex of T is adjacent to a vertex of C colored x. This is a lemma to be used
in a future paper of this series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2511</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2511</id><created>2010-10-12</created><updated>2011-11-06</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>The use of machine learning with signal- and NLP processing of source
  code to fingerprint, detect, and classify vulnerabilities and weaknesses with
  MARFCAT</title><categories>cs.CR cs.PL</categories><comments>33 pages, 11 tables; some results presented at SATE2010; NIST,
  October 2011; shorter version of v5 appears in the NIST technical report at
  http://samate.nist.gov/docs/NIST_Special_Publication_500-283.pdf#page=49
  where its presentation is found at
  http://samate.nist.gov/docs/SATE2010/SATE10_13_Marfcat_Mokhov.pdf and the
  MARFCAT OSS release at
  http://sourceforge.net/projects/marf/files/Applications/MARFCAT/</comments><report-no>NIST SP 500-283</report-no><acm-class>K.6.5; D.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present a machine learning approach to static code analysis and
fingerprinting for weaknesses related to security, software engineering, and
others using the open-source MARF framework and the MARFCAT application based
on it for the NIST's SATE2010 static analysis tool exposition workshop found at
http://samate.nist.gov/SATE2010Workshop.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2521</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2521</id><created>2010-10-12</created><authors><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author><author><keyname>Johansson</keyname><forenames>Anders</forenames></author></authors><title>Cooperation, Norms, and Revolutions: A Unified Game-Theoretical Approach</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Helbing, D and Johansson, A (2010) Cooperation, Norms, and
  Revolutions: A Unified Game-Theoretical Approach. PLoS ONE 5(10): e12530</journal-ref><doi>10.1371/journal.pone.0012530</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperation is of utmost importance to society as a whole, but is often
challenged by individual self-interests. While game theory has studied this
problem extensively, there is little work on interactions within and across
groups with different preferences or beliefs. Yet, people from different social
or cultural backgrounds often meet and interact. This can yield conflict, since
behavior that is considered cooperative by one population might be perceived as
non-cooperative from the viewpoint of another.
  To understand the dynamics and outcome of the competitive interactions within
and between groups, we study game-dynamical replicator equations for multiple
populations with incompatible interests and different power (be this due to
different population sizes, material resources, social capital, or other
factors). These equations allow us to address various important questions: For
example, can cooperation in the prisoner's dilemma be promoted, when two
interacting groups have different preferences? Under what conditions can costly
punishment, or other mechanisms, foster the evolution of norms? When does
cooperation fail, leading to antagonistic behavior, conflict, or even
revolutions? And what incentives are needed to reach peaceful agreements
between groups with conflicting interests?
  Our detailed quantitative analysis reveals a large variety of interesting
results, which are relevant for society, law and economics, and have
implications for the evolution of language and culture as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2551</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2551</id><created>2010-10-12</created><authors><author><keyname>Rouayheb</keyname><forenames>Salim El</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Fractional Repetition Codes for Repair in Distributed Storage Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of exact Minimum-Bandwidth Regenerating (MBR) codes
for distributed storage systems, characterized by a low-complexity uncoded
repair process that can tolerate multiple node failures. These codes consist of
the concatenation of two components: an outer MDS code followed by an inner
repetition code. We refer to the inner code as a Fractional Repetition code
since it consists of splitting the data of each node into several packets and
storing multiple replicas of each on different nodes in the system.
  Our model for repair is table-based, and thus, differs from the random access
model adopted in the literature. We present constructions of Fractional
Repetition codes based on regular graphs and Steiner systems for a large set of
system parameters. The resulting codes are guaranteed to achieve the storage
capacity for random access repair. The considered model motivates a new
definition of capacity for distributed storage systems, that we call Fractional
Repetition capacity. We provide upper bounds on this capacity while a precise
expression remains an open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2571</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2571</id><created>2010-10-13</created><updated>2012-02-26</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Cooperative Precoding with Limited Feedback for MIMO Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>23 pages; 5 figures; this work was presented in part at Asilomar 2011
  and will appear in IEEE Trans. on Wireless Comm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-antenna precoding effectively mitigates the interference in wireless
networks. However, the resultant performance gains can be significantly
compromised in practice if the precoder design fails to account for the
inaccuracy in the channel state information (CSI) feedback. This paper
addresses this issue by considering finite-rate CSI feedback from receivers to
their interfering transmitters in the two-user multiple-input-multiple-output
(MIMO) interference channel, called cooperative feedback, and proposing a
systematic method for designing transceivers comprising linear precoders and
equalizers. Specifically, each precoder/equalizer is decomposed into inner and
outer components for nulling the cross-link interference and achieving array
gain, respectively. The inner precoders/equalizers are further optimized to
suppress the residual interference resulting from finite-rate cooperative
feedback. Further- more, the residual interference is regulated by additional
scalar cooperative feedback signals that are designed to control transmission
power using different criteria including fixed interference margin and maximum
sum throughput. Finally, the required number of cooperative precoder feedback
bits is derived for limiting the throughput loss due to precoder quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2572</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2572</id><created>2010-10-13</created><updated>2010-10-25</updated><authors><author><keyname>Qu</keyname><forenames>Yan-Qin</forenames></author><author><keyname>Xu</keyname><forenames>Xiu-Lian</forenames></author><author><keyname>Guan</keyname><forenames>Shan</forenames></author><author><keyname>Li</keyname><forenames>Kai-Jun</forenames></author><author><keyname>Pan</keyname><forenames>Si-Jun</forenames></author><author><keyname>Gu</keyname><forenames>Chang-Gui</forenames></author><author><keyname>Jiang</keyname><forenames>Yu-Mei</forenames></author><author><keyname>He</keyname><forenames>Da-Ren</forenames></author></authors><title>Empirical study on some interconnecting bilayer networks</title><categories>physics.soc-ph cs.SI</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript serves as an online supplement of a preprint, which presents
a study on a kind of bilayer networks where some nodes (called interconnecting
nodes) in two layers merge. A model showing an important general property of
the bilayer networks is proposed. Then the analytic discussion of the model is
compared with empirical conclusions. We present all the empirical observations
in this online supplement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2595</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2595</id><created>2010-10-13</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author></authors><title>Kolmogorov Complexity in perspective. Part II: Classification,
  Information Processing and Duality</title><categories>cs.LO cs.CC cs.IT math.IT physics.data-an</categories><comments>43 pages</comments><proxy>ccsd</proxy><journal-ref>Synthese / Synth\`ese (2010) 00</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey diverse approaches to the notion of information: from Shannon
entropy to Kolmogorov complexity. Two of the main applications of Kolmogorov
complexity are presented: randomness and classification. The survey is divided
in two parts published in a same volume. Part II is dedicated to the relation
between logic and information system, within the scope of Kolmogorov
algorithmic information theory. We present a recent application of Kolmogorov
complexity: classification using compression, an idea with provocative
implementation by authors such as Bennett, Vitanyi and Cilibrasi. This stresses
how Kolmogorov complexity, besides being a foundation to randomness, is also
related to classification. Another approach to classification is also
considered: the so-called &quot;Google classification&quot;. It uses another original and
attractive idea which is connected to the classification using compression and
to Kolmogorov complexity from a conceptual point of view. We present and unify
these different approaches to classification in terms of Bottom-Up versus
Top-Down operational modes, of which we point the fundamental principles and
the underlying duality. We look at the way these two dual modes are used in
different approaches to information system, particularly the relational model
for database introduced by Codd in the 70's. This allows to point out diverse
forms of a fundamental duality. These operational modes are also reinterpreted
in the context of the comprehension schema of axiomatic set theory ZF. This
leads us to develop how Kolmogorov's complexity is linked to intensionality,
abstraction, classification and information system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2597</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2597</id><created>2010-10-13</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>ASMs and Operational Algorithmic Completeness of Lambda Calculus</title><categories>cs.LO cs.CC math.LO</categories><comments>37 pages</comments><proxy>ccsd</proxy><journal-ref>Lecture notes in computer science LNCS 6300 (2010) 00</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that lambda calculus is a computation model which can step by step
simulate any sequential deterministic algorithm for any computable function
over integers or words or any datatype. More formally, given an algorithm above
a family of computable functions (taken as primitive tools, i.e., kind of
oracle functions for the algorithm), for every constant K big enough, each
computation step of the algorithm can be simulated by exactly K successive
reductions in a natural extension of lambda calculus with constants for
functions in the above considered family. The proof is based on a fixed point
technique in lambda calculus and on Gurevich sequential Thesis which allows to
identify sequential deterministic algorithms with Abstract State Machines. This
extends to algorithms for partial computable functions in such a way that
finite computations ending with exceptions are associated to finite reductions
leading to terms with a particular very simple feature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2604</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2604</id><created>2010-10-13</created><authors><author><keyname>Asperti</keyname><forenames>Andrea</forenames></author><author><keyname>Coen</keyname><forenames>Claudio Sacerdoti</forenames></author><author><keyname>Tassi</keyname><forenames>Enrico</forenames></author></authors><title>Regular Expressions, au point</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new technique for constructing a finite state deterministic
automaton from a regular expression, based on the idea of marking a suitable
set of positions inside the expression, intuitively representing the possible
points reached after the processing of an initial prefix of the input string.
Pointed regular expressions join the elegance and the symbolic appealingness of
Brzozowski's derivatives, with the effectiveness of McNaughton and Yamada's
labelling technique, essentially combining the best of the two approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2619</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2619</id><created>2010-10-13</created><updated>2011-04-18</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Riis</keyname><forenames>Soren</forenames></author></authors><title>Graph-theoretical Constructions for Graph Entropy and Network Coding
  Based Communications</title><categories>cs.IT cs.NI math.CO math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The guessing number of a directed graph (digraph), equivalent to the entropy
of that digraph, was introduced as a direct criterion on the solvability of a
network coding instance. This paper makes two contributions on the guessing
number. First, we introduce an undirected graph on all possible configurations
of the digraph, referred to as the guessing graph, which encapsulates the
essence of dependence amongst configurations. We prove that the guessing number
of a digraph is equal to the logarithm of the independence number of its
guessing graph. Therefore, network coding solvability is no more a problem on
the operations made by each node, but is simplified into a problem on the
messages that can transit through the network. By studying the guessing graph
of a given digraph, and how to combine digraphs or alphabets, we are thus able
to derive bounds on the guessing number of digraphs. Second, we construct
specific digraphs with high guessing numbers, yielding network coding instances
where a large amount of information can transit. We first propose a
construction of digraphs with finite parameters based on cyclic codes, with
guessing number equal to the degree of the generator polynomial. We then
construct an infinite class of digraphs with arbitrary girth for which the
ratio between the linear guessing number and the number of vertices tends to
one, despite these digraphs being arbitrarily sparse. These constructions yield
solvable network coding instances with a relatively small number of
intermediate nodes for which the node operations are known and linear, although
these instances are sparse and the sources are arbitrarily far from their
corresponding sinks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2621</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2621</id><created>2010-10-13</created><authors><author><keyname>Charpentier</keyname><forenames>Ana</forenames></author><author><keyname>Fontaine</keyname><forenames>Caroline</forenames></author><author><keyname>Furon</keyname><forenames>Teddy</forenames></author><author><keyname>Cox</keyname><forenames>Ingemar</forenames></author></authors><title>An Asymmetric Fingerprinting Scheme based on Tardos Codes</title><categories>cs.CR</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tardos codes are currently the state-of-the-art in the design of practical
collusion-resistant fingerprinting codes. Tardos codes rely on a secret vector
drawn from a publicly known probability distribution in order to generate each
Buyer's fingerprint. For security purposes, this secret vector must not be
revealed to the Buyers. To prevent an untrustworthy Provider forging a copy of
a Work with an innocent Buyer's fingerprint, previous asymmetric fingerprinting
algorithms enforce the idea of the Buyers generating their own fingerprint.
Applying this concept to Tardos codes is challenging since the fingerprint must
be based on this vector secret.
  This paper provides the first solution for an asymmetric fingerprinting
protocol dedicated to Tardos codes. The motivations come from a new attack, in
which an untrustworthy Provider by modifying his secret vector frames an
innocent Buyer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2623</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2623</id><created>2010-10-13</created><updated>2010-11-15</updated><authors><author><keyname>Kolchin</keyname><forenames>Konstantin</forenames></author></authors><title>Surface Curvature Effects on Reflectance from Translucent Materials</title><categories>cs.GR physics.optics</categories><comments>10 pages, 2 figures. The first version of this paper was published in
  the Communication Papers Proceedings of 18th International Conference on
  Computer Graphics, Visualization and Computer Vision 2010 - WSCG2010</comments><acm-class>I.4.1; I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the physically based techniques for rendering translucent objects use
the diffusion theory of light scattering in turbid media. The widely used
dipole diffusion model (Jensen et al. 2001) applies the diffusion-theory
formula derived for a planar interface to objects of arbitrary shapes. This
paper presents first results of our investigation of how surface curvature
affects the diffuse reflectance from translucent materials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2656</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2656</id><created>2010-10-13</created><updated>2011-09-07</updated><authors><author><keyname>Sir&#xe9;n</keyname><forenames>Jouni</forenames></author><author><keyname>V&#xe4;lim&#xe4;ki</keyname><forenames>Niko</forenames></author><author><keyname>M&#xe4;kinen</keyname><forenames>Veli</forenames></author></authors><title>Indexing Finite Language Representation of Population Genotypes</title><categories>cs.DS cs.CE q-bio.QM</categories><comments>This is the full version of the paper that was presented at WABI
  2011. The implementation is available at
  http://www.cs.helsinki.fi/group/suds/gcsa/</comments><doi>10.1007/978-3-642-23038-7_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the recent advances in DNA sequencing, it is now possible to have
complete genomes of individuals sequenced and assembled. This rich and focused
genotype information can be used to do different population-wide studies, now
first time directly on whole genome level. We propose a way to index population
genotype information together with the complete genome sequence, so that one
can use the index to efficiently align a given sequence to the genome with all
plausible genotype recombinations taken into account. This is achieved through
converting a multiple alignment of individual genomes into a finite automaton
recognizing all strings that can be read from the alignment by switching the
sequence at any time. The finite automaton is indexed with an extension of
Burrows-Wheeler transform to allow pattern search inside the plausible
recombinant sequences. The size of the index stays limited, because of the high
similarity of individual genomes. The index finds applications in variation
calling and in primer design. On a variation calling experiment, we found about
1.0% of matches to novel recombinants just with exact matching, and up to 2.4%
with approximate matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2667</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2667</id><created>2010-10-13</created><authors><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author></authors><title>Virtual Full-Duplex Wireless Communication via Rapid On-Off-Division
  Duplex</title><categories>cs.IT cs.NI math.IT</categories><comments>8 pages; Forty-Eighth Annual Allerton Conference on Communication,
  Control, and Computing, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel paradigm for design- ing the physical and
medium access control (MAC) layers of mobile ad hoc or peer-to-peer networks
formed by half-duplex radios. A node equipped with such a radio cannot
simultaneously transmit and receive useful signals at the same frequency.
Unlike in conventional designs, where a node's transmission frames are
scheduled away from its reception, each node transmits its signal through a
randomly generated on-off duplex mask (or signature) over every frame interval,
and receive a signal through each of its own off-slots. This is called rapid
on-off- division duplex (RODD). Over the period of a single frame, every node
can transmit a message to some or all of its peers, and may simultaneously
receive a message from each peer. Thus RODD achieves virtual full-duplex
communication using half-duplex radios and can simplify the design of higher
layers of a network protocol stack significantly. The throughput of RODD is
evaluated under some general settings, which is significantly larger than that
of ALOHA. RODD is especially efficient in case the dominant traffic is
simultaneous broadcast from nodes to their one-hop peers, such as in
spontaneous wireless social networks, emergency situations or on battlefield.
Important design issues of peer discovery, distribution of on-off signatures,
synchronization and error-control coding are also addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2669</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2669</id><created>2010-10-13</created><authors><author><keyname>Hinkelmann</keyname><forenames>Franziska</forenames></author><author><keyname>Arnold</keyname><forenames>Elizabeth</forenames></author></authors><title>Fast Gr\&quot;obner Basis Computation for Boolean Polynomials</title><categories>math.AG cs.SC math.AC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the Macaulay2 package BooleanGB, which computes a Gr\&quot;obner
basis for Boolean polynomials using a binary representation rather than
symbolic. We compare the runtime of several Boolean models from systems in
biology and give an application to Sudoku.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2686</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2686</id><created>2010-10-13</created><authors><author><keyname>Mroueh</keyname><forenames>Lina</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>How to Achieve the Optimal DMT of Selective Fading MIMO Channels?</title><categories>cs.IT math.IT</categories><comments>22 pages, 6 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a particular class of selective fading channel
corresponding to a channel that is selective either in time or in frequency.
For this class of channel, we propose a systematic way to achieve the optimal
DMT derived in Coronel and B\&quot;olcskei, IEEE ISIT, 2007 by extending the
non-vanishing determinant (NVD) criterion to the selective channel case. A new
code construction based on split NVD parallel codes is then proposed to satisfy
the NVD parallel criterion. This result is of significant interest not only in
its own right, but also because it settles a long-standing debate in the
literature related to the optimal DMT of selective fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2692</identifier>
 <datestamp>2011-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2692</id><created>2010-10-13</created><updated>2011-09-21</updated><authors><author><keyname>Tabassum</keyname><forenames>Hina</forenames></author><author><keyname>Dawy</keyname><forenames>Zaher</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed Slim</forenames></author></authors><title>Resource Allocation via Sum-Rate Maximization in the Uplink of
  Multi-Cell OFDMA Networks</title><categories>math.OC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider maximizing the sum-rate in the uplink of a
multi-cell OFDMA network. The problem has a non-convex combinatorial structure
and is known to be NP hard. Due to the inherent complexity of implementing the
optimal solution, firstly, we derive an upper and lower bound to the optimal
average network throughput. Moreover, we investigate the performance of a near
optimal single cell resource allocation scheme in the presence of ICI which
leads to another easily computable lower bound. We then develop a centralized
sub-optimal scheme that is composed of a geometric programming based power
control phase in conjunction with an iterative subcarrier allocation phase.
Although, the scheme is computationally complex, it provides an effective
benchmark for low complexity schemes even without the power control phase.
Finally, we propose less complex centralized and distributed schemes that are
well-suited for practical scenarios. The computational complexity of all
schemes is analyzed and performance is compared through simulations. Simulation
results demonstrate that the proposed low complexity schemes can achieve
comparable performance to the centralized sub-optimal scheme in various
scenarios. Moreover, comparisons with the upper and lower bounds provide
insight on the performance gap between the proposed schemes and the optimal
solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2705</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2705</id><created>2010-10-13</created><authors><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Ligett</keyname><forenames>Katrina</forenames></author></authors><title>Privacy-Compatibility For General Utility Metrics</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we present a complete characterization of the utility metrics
that allow for non-trivial differential privacy guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2706</identifier>
 <datestamp>2010-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2706</id><created>2010-10-13</created><authors><author><keyname>Visser</keyname><forenames>Willemien</forenames><affiliation>LTCI</affiliation></author></authors><title>Function and form of gestures in a collaborative design meeting</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>Gesture in embodied communication and human-computer interaction.
  8th International Gesture Workshop, GW 2009. Bielefeld, Germany, February
  25-27, 2009. Revised selected papers, Kopp, S. and Wachsmuth, I. (Ed.) (2010)
  61-72</journal-ref><doi>10.1007/978-3-642-12553-9_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the relationship between gestures' function and form in
design collaboration. It adopts a cognitive design research viewpoint. The
analysis is restricted to gesticulations and emblems. The data analysed come
from an empirical study conducted on an architectural design meeting. Based on
a previous analysis of the data, guided by our model of design as the
construction of representations, we distinguish representational and
organisational functions. The results of the present analysis are that, even if
form-function association tendencies exist, gestures with a particular function
may take various forms, and particular gestural movements as regards form can
fulfil different functions. Reconsidering these results and other research on
gesture, we formulate the assumption that, if formal characteristics do not
allow differentiating functional gestures in collaboration, context-dependent,
semantic characteristics may be more appropriate. We also envision the
possibility that closer inspection of the data reveal tendencies of another
nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2713</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2713</id><created>2010-10-13</created><updated>2011-07-16</updated><authors><author><keyname>Kang</keyname><forenames>Xiaohan</forenames></author><author><keyname>Jaramillo</keyname><forenames>Juan Jos&#xe9;</forenames></author><author><keyname>Ying</keyname><forenames>Lei</forenames></author></authors><title>A Strategy-Proof and Non-monetary Admission Control Mechanism for
  Wireless Access Networks</title><categories>cs.GT</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study admission control mechanisms for wireless access networks where (i)
each user has a minimum service requirement, (ii) the capacity of the access
network is limited, and (iii) the access point is not allowed to use monetary
mechanisms to guarantee that users do not lie when disclosing their minimum
service requirements. To guarantee truthfulness, we use auction theory to
design a mechanism where users compete to be admitted into the network. We
propose admission control mechanisms under which the access point intelligently
allocates resources based on the announced minimum service requirements to
ensure that users have no incentive to lie and the capacity constraint is
fulfilled. We also prove the properties that any feasible mechanism should
have.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2731</identifier>
 <datestamp>2013-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2731</id><created>2010-10-13</created><updated>2013-03-12</updated><authors><author><keyname>Negahban</keyname><forenames>Sahand N.</forenames></author><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Yu</keyname><forenames>Bin</forenames></author></authors><title>A Unified Framework for High-Dimensional Analysis of M-Estimators with
  Decomposable Regularizers</title><categories>math.ST cs.IT math.IT stat.ME stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/12-STS400 the Statistical
  Science (http://www.imstat.org/sts/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-STS-STS400</report-no><journal-ref>Statistical Science 2012, Vol. 27, No. 4, 538-557</journal-ref><doi>10.1214/12-STS400</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-dimensional statistical inference deals with models in which the the
number of parameters p is comparable to or larger than the sample size n. Since
it is usually impossible to obtain consistent procedures unless
$p/n\rightarrow0$, a line of recent work has studied models with various types
of low-dimensional structure, including sparse vectors, sparse and structured
matrices, low-rank matrices and combinations thereof. In such settings, a
general approach to estimation is to solve a regularized optimization problem,
which combines a loss function measuring how well the model fits the data with
some regularization function that encourages the assumed structure. This paper
provides a unified framework for establishing consistency and convergence rates
for such regularized M-estimators under high-dimensional scaling. We state one
main theorem and show how it can be used to re-derive some existing results,
and also to obtain a number of new results on consistency and convergence
rates, in both $\ell_2$-error and related norms. Our analysis also identifies
two key properties of loss and regularization functions, referred to as
restricted strong convexity and decomposability, that ensure corresponding
regularized M-estimators have fast convergence rates and which are optimal in
many well-studied cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2733</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2733</id><created>2010-10-13</created><updated>2011-12-28</updated><authors><author><keyname>Couprie</keyname><forenames>Camille</forenames><affiliation>LIGM</affiliation></author><author><keyname>Grady</keyname><forenames>Leo</forenames><affiliation>LIGM</affiliation></author><author><keyname>Talbot</keyname><forenames>Hugues</forenames><affiliation>LIGM</affiliation></author><author><keyname>Najman</keyname><forenames>Laurent</forenames><affiliation>LIGM</affiliation></author></authors><title>Combinatorial Continuous Maximal Flows</title><categories>cs.CV math.OC</categories><comments>26 pages</comments><proxy>ccsd</proxy><journal-ref>SIAM Journal on Imaging Sciences 4 (2011) 905-930</journal-ref><doi>10.1137/100799186</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum flow (and minimum cut) algorithms have had a strong impact on
computer vision. In particular, graph cuts algorithms provide a mechanism for
the discrete optimization of an energy functional which has been used in a
variety of applications such as image segmentation, stereo, image stitching and
texture synthesis. Algorithms based on the classical formulation of max-flow
defined on a graph are known to exhibit metrication artefacts in the solution.
Therefore, a recent trend has been to instead employ a spatially continuous
maximum flow (or the dual min-cut problem) in these same applications to
produce solutions with no metrication errors. However, known fast continuous
max-flow algorithms have no stopping criteria or have not been proved to
converge. In this work, we revisit the continuous max-flow problem and show
that the analogous discrete formulation is different from the classical
max-flow problem. We then apply an appropriate combinatorial optimization
technique to this combinatorial continuous max-flow CCMF problem to find a
null-divergence solution that exhibits no metrication artefacts and may be
solved exactly by a fast, efficient algorithm with provable convergence.
Finally, by exhibiting the dual problem of our CCMF formulation, we clarify the
fact, already proved by Nozawa in the continuous setting, that the max-flow and
the total variation problems are not always equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2741</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2741</id><created>2010-10-13</created><authors><author><keyname>Nosrat-Makouei</keyname><forenames>Behrang</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>MIMO Interference Alignment Over Correlated Channels with Imperfect CSI</title><categories>cs.IT math.IT</categories><comments>21 pages, 7 figures, submitted to IEEE Transactions on Signal
  Processing</comments><journal-ref>IEEE Transactions on Signal Processing, vol.59, no.6, pp.
  2783-2794, June 2011</journal-ref><doi>10.1109/TSP.2011.2124458</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment (IA), given uncorrelated channel components and
perfect channel state information, obtains the maximum degrees of freedom in an
interference channel. Little is known, however, about how the sum rate of IA
behaves at finite transmit power, with imperfect channel state information, or
antenna correlation. This paper provides an approximate closed-form
signal-to-interference-plus-noise-ratio (SINR) expression for IA over
multiple-input-multiple-output (MIMO) channels with imperfect channel state
information and transmit antenna correlation. Assuming linear processing at the
transmitters and zero-forcing receivers, random matrix theory tools are
utilized to derive an approximation for the post-processing SINR distribution
of each stream for each user. Perfect channel knowledge and i.i.d. channel
coefficients constitute special cases. This SINR distribution not only allows
easy calculation of useful performance metrics like sum rate and symbol error
rate, but also permits a realistic comparison of IA with other transmission
techniques. More specifically, IA is compared with spatial multiplexing and
beamforming and it is shown that IA may not be optimal for some performance
criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2745</identifier>
 <datestamp>2014-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2745</id><created>2010-10-13</created><updated>2014-01-27</updated><authors><author><keyname>Berry</keyname><forenames>Dominic W.</forenames></author></authors><title>High-order quantum algorithm for solving linear differential equations</title><categories>quant-ph cs.NA math.NA</categories><comments>14 pages, improved efficiency</comments><journal-ref>J. Phys. A: Math. Theor. 47, 105301 (2014)</journal-ref><doi>10.1088/1751-8113/47/10/105301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear differential equations are ubiquitous in science and engineering.
Quantum computers can simulate quantum systems, which are described by a
restricted type of linear differential equations. Here we extend quantum
simulation algorithms to general inhomogeneous sparse linear differential
equations, which describe many classical physical systems. We examine the use
of high-order methods to improve the efficiency. These provide scaling close to
$\Delta t^2$ in the evolution time $\Delta t$. As with other algorithms of this
type, the solution is encoded in amplitudes of the quantum state, and it is
possible to extract global features of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2757</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2757</id><created>2010-10-13</created><authors><author><keyname>Haque</keyname><forenames>Asif-ul</forenames></author><author><keyname>Ginsparg</keyname><forenames>Paul</forenames></author></authors><title>Last but not Least: Additional Positional Effects on Citation and
  Readership in arXiv</title><categories>cs.DL astro-ph.IM hep-ph hep-th physics.soc-ph</categories><comments>13p, appeared JASIST on-line first (12 Oct 2010)</comments><journal-ref>JASIST 61, 2381-2388 (Dec 2010)</journal-ref><doi>10.1002/asi.21428</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue investigation of the effect of position in announcements of newly
received articles, a single day artifact, with citations received over the
course of ensuing years. Earlier work [arXiv:0907.4740, arXiv:0805.0307]
focused on the &quot;visibility&quot; effect for positions near the beginnings of
announcements, and on the &quot;self-promotion&quot; effect associated to authors
intentionally aiming for these positions, with both found correlated to a later
enhanced citation rate. Here we consider a &quot;reverse-visibility&quot; effect for
positions near the ends of announcements, and on a &quot;procrastination&quot; effect
associated to submissions made within the 20 minute period just before the
daily deadline. For two large subcommunities of theoretical high energy
physics, we find a clear &quot;reverse-visibility&quot; effect, in which articles near
the ends of the lists receive a boost in both short-term readership and
long-term citations, almost comparable in size to the &quot;visibility&quot; effect
documented earlier. For one of those subcommunities, we find an additional
&quot;procrastination&quot; effect, in which last position articles submitted shortly
before the deadline have an even higher citation rate than those that land more
accidentally in that position. We consider and eliminate geographic effects as
responsible for the above, and speculate on other possible causes, including
&quot;oblivious&quot; and &quot;nightowl&quot; effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2787</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2787</id><created>2010-10-13</created><updated>2011-11-19</updated><authors><author><keyname>Ayach</keyname><forenames>Omar El</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Interference Alignment with Analog Channel State Feedback</title><categories>cs.IT math.IT</categories><comments>accepted, to appear in IEEE Transactions on Wireless Communications</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 11, no. 2, pp.
  626-636, February 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment (IA) is a multiplexing gain optimal transmission
strategy for the interference channel. While the achieved sum rate with IA is
much higher than previously thought possible, the improvement often comes at
the cost of requiring network channel state information at the transmitters.
This can be achieved by explicit feedback, a flexible yet potentially costly
approach that incurs large overhead. In this paper we propose analog feedback
as an alternative to limited feedback or reciprocity based alignment. We show
that the full multiplexing gain observed with perfect channel knowledge is
preserved by analog feedback and that the mean loss in sum rate is bounded by a
constant when signal-to-noise ratio is comparable in both forward and feedback
channels. When signal-to-noise ratios are not quite symmetric, a fraction of
the multiplexing gain is achieved. We consider the overhead of training and
feedback and use this framework to optimize the system's effective throughput.
We present simulation results to demonstrate the performance of IA with analog
feedback, verify our theoretical analysis, and extend our conclusions on
optimal training and feedback length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2789</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2789</id><created>2010-10-13</created><authors><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author></authors><title>Optimum Power and Rate Allocation for Coded V-BLAST: Average
  Optimization</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An analytical framework for performance analysis and optimization of coded
V-BLAST is developed. Average power and/or rate allocations to minimize the
outage probability as well as their robustness and dual problems are
investigated. Compact, closed-form expressions for the optimum allocations and
corresponding system performance are given. The uniform power allocation is
shown to be near optimum in the low outage regime in combination with the
optimum rate allocation. The average rate allocation provides the largest
performance improvement (extra diversity gain), and the average power
allocation offers a modest SNR gain limited by the number of transmit antennas
but does not increase the diversity gain. The dual problems are shown to have
the same solutions as the primal ones. All these allocation strategies are
shown to be robust. The reported results also apply to coded multiuser
detection and channel equalization systems relying on successive interference
cancelation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2802</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2802</id><created>2010-10-13</created><authors><author><keyname>Dhinakaran</keyname><forenames>Cynthia</forenames></author><author><keyname>lee</keyname><forenames>Jae Kwang</forenames></author><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author></authors><title>&quot;Reminder: please update your details&quot;: Phishing Trends</title><categories>cs.CR cs.NI</categories><comments>6 pages, 6 Figures, NETCOM 2009, IEEE CS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam messes up users inbox, consumes resources and spread attacks like DDoS,
MiM, Phishing etc., Phishing is a byproduct of email and causes financial loss
to users and loss of reputation to financial institutions. In this paper we
study the characteristics of phishing and technology used by phishers. In order
to counter anti phishing technology, phishers change their mode of operation;
therefore continuous evaluation of phishing helps us to combat phishers
effectively. We have collected seven hundred thousand spam from a corporate
server for a period of 13 months from February 2008 to February 2009. From the
collected date, we identified different kinds of phishing scams and mode of
their operation. Our observation shows that phishers are dynamic and depend
more on social engineering techniques rather than software vulnerabilities. We
believe that this study would be useful to develop more efficient anti phishing
methodologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2818</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2818</id><created>2010-10-13</created><updated>2011-07-29</updated><authors><author><keyname>Han</keyname><forenames>Kai</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Luo</keyname><forenames>Jun</forenames></author></authors><title>Duty-Cycle-Aware Minimum-Energy Multicasting in Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In duty-cycled wireless sensor networks, the nodes switch between active and
dormant states, and each node may determine its active/dormant schedule
independently. This complicates the Minimum-Energy Multicasting (MEM) problem,
which has been primarily studied in always-active wireless ad-hoc networks. In
this paper, we study the duty-cycle-aware MEM problem in wireless sensor
networks, and we present a formulation of the Minimum-Energy Multicast Tree
Construction and Scheduling (MEMTCS) problem. We prove that the MEMTCS problem
is NP-hard, and it is unlikely to have an approximation algorithm with a
performance ratio of $(1-o(1))\ln\Delta$, where $\Delta$ is the maximum node
degree in a network. We propose a polynomial-time approximation algorithm for
the MEMTCS problem with a performance ratio of $\mathcal{O}(H(\Delta+1))$,
where $H(\cdot)$ is the harmonic number. We also provide a distributed
implementation of our algorithm. Finally, we perform extensive simulations and
the results demonstrate that our algorithm significantly outperform other known
algorithms in terms of both the total energy cost and the transmission
redundancy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2822</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2822</id><created>2010-10-14</created><authors><author><keyname>Beugnard</keyname><forenames>Antoine</forenames><affiliation>Telecom Bretagne, Brest, France</affiliation></author><author><keyname>J&#xe9;z&#xe9;quel</keyname><forenames>Jean-Marc</forenames><affiliation>IRISA, Rennes, France</affiliation></author><author><keyname>Plouzeau</keyname><forenames>No&#xeb;l</forenames><affiliation>IRISA, Rennes, France</affiliation></author></authors><title>Contract Aware Components, 10 years after</title><categories>cs.SE</categories><comments>In Proceedings WCSI 2010, arXiv:1010.2337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 37, 2010, pp. 1-11</journal-ref><doi>10.4204/EPTCS.37.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of contract aware components has been published roughly ten years
ago and is now becoming mainstream in several fields where the usage of
software components is seen as critical. The goal of this paper is to survey
domains such as Embedded Systems or Service Oriented Architecture where the
notion of contract aware components has been influential. For each of these
domains we briefly describe what has been done with this idea and we discuss
the remaining challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2823</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2823</id><created>2010-10-14</created><authors><author><keyname>Lumpe</keyname><forenames>Markus</forenames><affiliation>Swinburne University of Technology, Australia</affiliation></author><author><keyname>Vasa</keyname><forenames>Rajesh</forenames><affiliation>Swinburne University of Technology, Australia</affiliation></author></authors><title>Partition Refinement of Component Interaction Automata: Why Structure
  Matters More Than Size</title><categories>cs.SE cs.FL</categories><comments>In Proceedings WCSI 2010, arXiv:1010.2337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 37, 2010, pp. 12-26</journal-ref><doi>10.4204/EPTCS.37.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automata-based modeling languages, like Component Interaction Automata, offer
an attractive means to capture and analyze the behavioral aspects of
interacting components. At the center of these modeling languages we find
finite state machines that allow for a fine-grained description how and when
specific service requests may interact with other components or the
environment. Unfortunately, automata-based approaches suffer from exponential
state explosion, a major obstacle to the successful application of these
formalisms in modeling real-world scenarios. In order to cope with the
complexity of individual specifications we can apply partition refinement, an
abstraction technique to alleviate the state explosion problem. But this
technique too exhibits exponential time and space complexity and, worse, does
not offer any guarantees for success. To better understand as to why partition
refinement succeeds in some cases while it fails in others, we conducted an
empirical study on the performance of a partition refinement algorithm for
Component Interaction Automata specifications. As a result we have identified
suitable predictors for the expected effectiveness of partition refinement. It
is the structure, not the size, of a specification that weighs heavier on the
outcome of partition refinement. In particular, Component Interaction Automata
specifications for real-world systems are capable of producing scale-free
networks containing structural artifacts that can assist the partition
refinement algorithm not only converge earlier, but also yield a significant
state space reduction on occasion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2824</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2824</id><created>2010-10-14</created><authors><author><keyname>Ameur-Boulifa</keyname><forenames>Rab&#xe9;a</forenames></author><author><keyname>Henrio</keyname><forenames>Ludovic</forenames></author><author><keyname>Madelaine</keyname><forenames>Eric</forenames></author></authors><title>Behavioural Models for Group Communications</title><categories>cs.DC</categories><comments>In Proceedings WCSI 2010, arXiv:1010.2337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 37, 2010, pp. 42-56</journal-ref><doi>10.4204/EPTCS.37.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group communication is becoming a more and more popular infrastructure for
efficient distributed applications. It consists in representing locally a group
of remote objects as a single object accessed in a single step; communications
are then broadcasted to all members. This paper provides models for automatic
verification of group-based applications, typically for detecting deadlocks or
checking message ordering. We show how to encode group communication, together
with different forms of synchronisation for group results. The proposed models
are parametric such that, for example, different group sizes or group members
could be experimented with the minimum modification of the original model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2825</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2825</id><created>2010-10-14</created><authors><author><keyname>Spalazzese</keyname><forenames>Romina</forenames><affiliation>Universit&#xe0; degli Studi dell'Aquila</affiliation></author><author><keyname>Inverardi</keyname><forenames>Paola</forenames><affiliation>Universit&#xe0; degli Studi dell'Aquila</affiliation></author></authors><title>Components Interoperability through Mediating Connector Patterns</title><categories>cs.SE</categories><comments>In Proceedings WCSI 2010, arXiv:1010.2337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 37, 2010, pp. 27-41</journal-ref><doi>10.4204/EPTCS.37.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key objective for ubiquitous environments is to enable system
interoperability between system's components that are highly heterogeneous. In
particular, the challenge is to embed in the system architecture the necessary
support to cope with behavioral diversity in order to allow components to
coordinate and communicate. The continuously evolving environment further asks
for an automated and on-the-fly approach. In this paper we present the design
building blocks for the dynamic and on-the-fly interoperability between
heterogeneous components. Specifically, we describe an Architectural Pattern
called Mediating Connector, that is the key enabler for communication. In
addition, we present a set of Basic Mediator Patterns, that describe the basic
mismatches which can occur when components try to interact, and their
corresponding solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2826</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2826</id><created>2010-10-14</created><authors><author><keyname>Ouederni</keyname><forenames>Meriem</forenames><affiliation>University of Malaga, Spain</affiliation></author><author><keyname>Sala&#xfc;n</keyname><forenames>Gwen</forenames><affiliation>Grenoble INP, INRIA-Grenoble, LIG</affiliation></author></authors><title>Tau Be or not Tau Be? - A Perspective on Service Compatibility and
  Substitutability</title><categories>cs.SE cs.LO</categories><comments>In Proceedings WCSI 2010, arXiv:1010.2337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 37, 2010, pp. 57-70</journal-ref><doi>10.4204/EPTCS.37.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main open research issues in Service Oriented Computing is to
propose automated techniques to analyse service interfaces. A first problem,
called compatibility, aims at determining whether a set of services (two in
this paper) can be composed together and interact with each other as expected.
Another related problem is to check the substitutability of one service with
another. These problems are especially difficult when behavioural descriptions
(i.e., message calls and their ordering) are taken into account in service
interfaces. Interfaces should capture as faithfully as possible the service
behaviour to make their automated analysis possible while not exhibiting
implementation details. In this position paper, we choose Labelled Transition
Systems to specify the behavioural part of service interfaces. In particular,
we show that internal behaviours (tau transitions) are necessary in these
transition systems in order to detect subtle errors that may occur when
composing a set of services together. We also show that tau transitions should
be handled differently in the compatibility and substitutability problem: the
former problem requires to check if the compatibility is preserved every time a
tau transition is traversed in one interface, whereas the latter requires a
precise analysis of tau branchings in order to make the substitution preserve
the properties (e.g., a compatibility notion) which were ensured before
replacement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2827</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2827</id><created>2010-10-14</created><authors><author><keyname>Messabihi</keyname><forenames>Mohamed</forenames></author><author><keyname>Andr&#xe9;</keyname><forenames>Pascal</forenames></author><author><keyname>Attiogb&#xe9;</keyname><forenames>Christian</forenames></author></authors><title>Multilevel Contracts for Trusted Components</title><categories>cs.SE</categories><comments>In Proceedings WCSI 2010, arXiv:1010.2337</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 37, 2010, pp. 71-85</journal-ref><doi>10.4204/EPTCS.37.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article contributes to the design and the verification of trusted
components and services. The contracts are declined at several levels to cover
then different facets, such as component consistency, compatibility or
correctness. The article introduces multilevel contracts and a
design+verification process for handling and analysing these contracts in
component models. The approach is implemented with the COSTO platform that
supports the Kmelia component model. A case study illustrates the overall
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2828</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2828</id><created>2010-10-14</created><authors><author><keyname>Khan</keyname><forenames>Abdul Malik</forenames><affiliation>Institut T&#xe9;l&#xe9;com, T&#xe9;l&#xe9;com Sudparis, CNRS UMR SAMOVAR, Evry, France</affiliation></author><author><keyname>Chabridon</keyname><forenames>Sophie</forenames><affiliation>Institut T&#xe9;l&#xe9;com, T&#xe9;l&#xe9;com Sudparis, CNRS UMR SAMOVAR, Evry, France</affiliation></author><author><keyname>Beugnard</keyname><forenames>Antoine</forenames><affiliation>Institut T&#xe9;l&#xe9;com, T&#xe9;l&#xe9;com Bretagne, Brest, France</affiliation></author></authors><title>A Reusable Component for Communication and Data Synchronization in
  Mobile Distributed Interactive Applications</title><categories>cs.DC</categories><comments>In Proceedings WCSI 2010, arXiv:1010.2337</comments><proxy>EPTCS</proxy><acm-class>D.2.2; D.2.11</acm-class><journal-ref>EPTCS 37, 2010, pp. 86-100</journal-ref><doi>10.4204/EPTCS.37.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Distributed Interactive Applications (DIA) such as multiplayer games,
where many participants are involved in a same game session and communicate
through a network, they may have an inconsistent view of the virtual world
because of the communication delays across the network. This issue becomes even
more challenging when communicating through a cellular network while executing
the DIA client on a mobile terminal. Consistency maintenance algorithms may be
used to obtain a uniform view of the virtual world. These algorithms are very
complex and hard to program and therefore, the implementation and the future
evolution of the application logic code become difficult. To solve this
problem, we propose an approach where the consistency concerns are handled
separately by a distributed component called a Synchronization Medium, which is
responsible for the communication management as well as the consistency
maintenance. We present the detailed architecture of the Synchronization Medium
and the generic interfaces it offers to DIAs. We evaluate our approach both
qualitatively and quantitatively. We first demonstrate that the Synchronization
Medium is a reusable component through the development of two game
applications, a car racing game and a space war game. A performance evaluation
then shows that the overhead introduced by the Synchronization Medium remains
acceptable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2830</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2830</id><created>2010-10-14</created><authors><author><keyname>Wang</keyname><forenames>Zilong</forenames></author><author><keyname>Gong</keyname><forenames>Guang</forenames></author><author><keyname>Feng</keyname><forenames>Rongquan</forenames></author></authors><title>A Generalized Construction of OFDM M-QAM Sequences With Low
  Peak-to-Average Power Ratio</title><categories>cs.IT math.IT</categories><comments>published by Advances in Mathematics of Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A construction of $2^{2n}$-QAM sequences is given and an upper bound of the
peak-to-mean envelope power ratio (PMEPR) is determined. Some former works can
be viewed as special cases of this construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2831</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2831</id><created>2010-10-14</created><authors><author><keyname>Feng</keyname><forenames>Rongquan</forenames></author><author><keyname>Gu</keyname><forenames>Zhenhua</forenames></author><author><keyname>Wang</keyname><forenames>Zilong</forenames></author><author><keyname>Wu</keyname><forenames>Hongfeng</forenames></author><author><keyname>Zhou</keyname><forenames>Kai</forenames></author></authors><title>On the Construction of Finite Oscillator Dictionary</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A finite oscillator dictionary which has important applications in sequences
designs and the compressive sensing was introduced by Gurevich, Hadani and
Sochen. In this paper, we first revisit closed formulae of the finite split
oscillator dictionary $\mathfrak{S}^s$ by a simple proof. Then we study the
non-split tori of the group $SL(2,\mathbb{F}_p)$. Finally, An explicit
algorithm for computing the finite non-split oscillator dictionary
$\mathfrak{S}^{ns}$ is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2832</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2832</id><created>2010-10-14</created><updated>2011-05-12</updated><authors><author><keyname>Batty</keyname><forenames>Christopher</forenames></author><author><keyname>Bridson</keyname><forenames>Robert</forenames></author></authors><title>A simple finite difference method for time-dependent, variable
  coefficient Stokes flow on irregular domains</title><categories>physics.comp-ph cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple and efficient variational finite difference method for
simulating time-dependent Stokes flow in the presence of irregular free
surfaces and moving solid boundaries. The method uses an embedded boundary
approach on staggered Cartesian grids, avoiding the need for expensive
remeshing operations, and can be applied to flows in both two and three
dimensions. It uses fully implicit backwards Euler integration to provide
stability and supports spatially varying density and viscosity, while requiring
the solution of just a single sparse, symmetric positive-definite linear system
per time step. By expressing the problem in a variational form, challenging
irregular domains are supported implicitly through the use of natural boundary
conditions. In practice, the discretization requires only centred finite
difference stencils and per-cell volume fractions, and is straightforward to
implement. The variational form further permits generalizations to coupling
other mechanics, all the while reducing to a sparse symmetric positive definite
matrix. We demonstrate consistent first order convergence of velocity in L1 and
Linf norms on a range of analytical test cases in two dimensions. Furthermore,
we apply our method as part of a simple Navier-Stokes solver to illustrate that
it can reproduce the characteristic jet buckling phenomenon of Newtonian
liquids at moderate viscosities, in both two and three dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2833</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2833</id><created>2010-10-14</created><authors><author><keyname>Yue</keyname><forenames>Weiya</forenames></author><author><keyname>Franco</keyname><forenames>John</forenames></author><author><keyname>Cao</keyname><forenames>Weiwei</forenames></author></authors><title>Improved Complexity Bound of Vertex Cover for Low degree Graph</title><categories>cs.DS</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use a new method to decrease the parameterized complexity
bound for finding the minimum vertex cover of connected max-degree-3 undirected
graphs. The key operation of this method is reduction of the size of a
particular subset of edges which we introduce in this paper and is called as
&quot;real-cycle&quot; subset. Using &quot;real-cycle&quot; reductions alone we compute a
complexity bound $O(1.15855^k)$ where $k$ is size of the optimal vertex cover.
Combined with other techniques, the complexity bound can be further improved to
be $O(1.1504^k)$. This is currently the best complexity bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2850</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2850</id><created>2010-10-14</created><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author></authors><title>Steering Fragments of Instruction Sequences</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A steering fragment of an instruction sequence consists of a sequence of
steering instructions. These are decision points involving the check of a
propositional statement in sequential logic. The question is addressed why
composed propositional statements occur in steering fragments given the fact
that a straightforward transformation allows their elimination. A survey is
provided of constraints that may be implicitly assumed when composed
propositional statements occur in a meaningful instruction sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2871</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2871</id><created>2010-10-14</created><updated>2010-10-25</updated><authors><author><keyname>Stein</keyname><forenames>Noah D.</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Exchangeable equilibria contradict exactness of the
  Papadimitriou-Roughgarden algorithm</title><categories>cs.GT math.OC</categories><comments>The authors have decided to withdraw this submission.
  Clarifications/corrections, if any, may follow at a later date</comments><report-no>LIDS Technical Report #2852</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The authors have decided to withdraw this submission.
Clarifications/corrections, if any, may follow at a later date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2881</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2881</id><created>2010-10-14</created><authors><author><keyname>Wu</keyname><forenames>Linlin</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author></authors><title>Service Level Agreement (SLA) in Utility Computing Systems</title><categories>cs.DC</categories><comments>27 pages, 4 tables, 6 figures</comments><report-no>Technical Report CLOUDS-TR-2010-5, Cloud Computing and Distributed
  Systems Laboratory, The University of Melbourne, Australia, September 3, 2010</report-no><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, extensive research has been conducted in the area of Service
Level Agreement (SLA) for utility computing systems. An SLA is a formal
contract used to guarantee that consumers' service quality expectation can be
achieved. In utility computing systems, the level of customer satisfaction is
crucial, making SLAs significantly important in these environments. Fundamental
issue is the management of SLAs, including SLA autonomy management or trade off
among multiple Quality of Service (QoS) parameters. Many SLA languages and
frameworks have been developed as solutions; however, there is no overall
classification for these extensive works. Therefore, the aim of this chapter is
to present a comprehensive survey of how SLAs are created, managed and used in
utility computing environment. We discuss existing use cases from Grid and
Cloud computing systems to identify the level of SLA realization in
state-of-art systems and emerging challenges for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2885</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2885</id><created>2010-10-14</created><authors><author><keyname>Polishchuk</keyname><forenames>Valentin</forenames></author><author><keyname>Sysikaski</keyname><forenames>Mikko</forenames></author></authors><title>Improved approximations for robust mincut and shortest path</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two-stage robust optimization the solution to a problem is built in two
stages: In the first stage a partial, not necessarily feasible, solution is
exhibited. Then the adversary chooses the &quot;worst&quot; scenario from a predefined
set of scenarios. In the second stage, the first-stage solution is extended to
become feasible for the chosen scenario. The costs at the second stage are
larger than at the first one, and the objective is to minimize the total cost
paid in the two stages.
  We give a 2-approximation algorithm for the robust mincut problem and a
({\gamma}+2)-approximation for the robust shortest path problem, where {\gamma}
is the approximation ratio for the Steiner tree. This improves the factors
(1+\sqrt2) and 2({\gamma}+2) from [Golovin, Goyal and Ravi. Pay today for a
rainy day: Improved approximation algorithms for demand-robust min-cut and
shortest path problems. STACS 2006]. In addition, our solution for robust
shortest path is simpler and more efficient than the earlier ones; this is
achieved by a more direct algorithm and analysis, not using some of the
standard demand-robust optimization techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2921</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2921</id><created>2010-10-14</created><updated>2010-10-19</updated><authors><author><keyname>Christiano</keyname><forenames>Paul</forenames></author><author><keyname>Kelner</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Madry</keyname><forenames>Aleksander</forenames></author><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Electrical Flows, Laplacian Systems, and Faster Approximation of Maximum
  Flow in Undirected Graphs</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new approach to computing an approximately maximum s-t flow in
a capacitated, undirected graph. This flow is computed by solving a sequence of
electrical flow problems. Each electrical flow is given by the solution of a
system of linear equations in a Laplacian matrix, and thus may be approximately
computed in nearly-linear time.
  Using this approach, we develop the fastest known algorithm for computing
approximately maximum s-t flows. For a graph having n vertices and m edges, our
algorithm computes a (1-\epsilon)-approximately maximum s-t flow in time
\tilde{O}(mn^{1/3} \epsilon^{-11/3}). A dual version of our approach computes a
(1+\epsilon)-approximately minimum s-t cut in time
\tilde{O}(m+n^{4/3}\eps^{-8/3}), which is the fastest known algorithm for this
problem as well. Previously, the best dependence on m and n was achieved by the
algorithm of Goldberg and Rao (J. ACM 1998), which can be used to compute
approximately maximum s-t flows in time \tilde{O}(m\sqrt{n}\epsilon^{-1}), and
approximately minimum s-t cuts in time \tilde{O}(m+n^{3/2}\epsilon^{-3}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2943</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2943</id><created>2010-10-14</created><authors><author><keyname>Mastrangeli</keyname><forenames>Massimo</forenames></author><author><keyname>Schmidt</keyname><forenames>Martin</forenames></author><author><keyname>Lacasa</keyname><forenames>Lucas</forenames></author></authors><title>The roundtable: an abstract model of conversation dynamics</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages, 4 figures, to be published in Journal of Artificial
  Societies and Social Simulation</comments><journal-ref>Journal of Artificial Societies and Social Simulation 13, 4 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Is it possible to abstract a formal mechanism originating schisms and
governing the size evolution of social conversations? In this work a
constructive solution to such problem is proposed: an abstract model of a
generic N-party turn-taking conversation. The model develops from simple yet
realistic assumptions derived from experimental evidence, abstracts from
conversation content and semantics while including topological information, and
is driven by stochastic dynamics. We find that a single mechanism - namely the
dynamics of conversational party's individual fitness, as related to
conversation size - controls the development of the self-organized schisming
phenomenon. Potential generalizations of the model - including individual
traits and preferences, memory effects and more elaborated conversational
topologies - may find important applications also in other fields of research,
where dynamically-interacting and networked agents play a fundamental role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2955</identifier>
 <datestamp>2013-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2955</id><created>2010-10-14</created><updated>2012-05-06</updated><authors><author><keyname>Liu</keyname><forenames>Guangcan</forenames></author><author><keyname>Lin</keyname><forenames>Zhouchen</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Yu</keyname><forenames>Yong</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Robust Recovery of Subspace Structures by Low-Rank Representation</title><categories>cs.IT cs.CV cs.LG math.IT</categories><comments>IEEE Trans. Pattern Analysis and Machine Intelligence</comments><journal-ref>IEEE Trans. Pattern Analysis and Machine Intelligence, 35(2013)
  171-184</journal-ref><doi>10.1109/TPAMI.2012.88</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we address the subspace recovery problem. Given a set of data
samples (vectors) approximately drawn from a union of multiple subspaces, our
goal is to segment the samples into their respective subspaces and correct the
possible errors as well. To this end, we propose a novel method termed Low-Rank
Representation (LRR), which seeks the lowest-rank representation among all the
candidates that can represent the data samples as linear combinations of the
bases in a given dictionary. It is shown that LRR well solves the subspace
recovery problem: when the data is clean, we prove that LRR exactly captures
the true subspace structures; for the data contaminated by outliers, we prove
that under certain conditions LRR can exactly recover the row space of the
original data and detect the outlier as well; for the data corrupted by
arbitrary errors, LRR can also approximately recover the row space with
theoretical guarantees. Since the subspace membership is provably determined by
the row space, these further imply that LRR can perform robust subspace
segmentation and error correction, in an efficient way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2958</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2958</id><created>2010-10-14</created><authors><author><keyname>Panozzo</keyname><forenames>Daniele</forenames></author><author><keyname>Puppo</keyname><forenames>Enrico</forenames></author></authors><title>Simplification of cross-field topology</title><categories>cs.CG</categories><report-no>TR-10-08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an innovative algorithm that simplifies the topology of a
cross-field. Our algorithm works through macro-operations that allow us editing
the graph of separatrices, which is extracted from a cross-field, while
maintaining it topologically consistent. We present preliminary results of our
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2983</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2983</id><created>2010-10-14</created><authors><author><keyname>Howard</keyname><forenames>Stephen D.</forenames></author><author><keyname>Cochran</keyname><forenames>Douglas</forenames></author><author><keyname>Moran</keyname><forenames>William</forenames></author><author><keyname>Cohen</keyname><forenames>Frederick R.</forenames></author></authors><title>Estimation and Registration on Graphs</title><categories>cs.NI stat.AP</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A statistical framework is introduced for a broad class of problems involving
synchronization or registration of data across a sensor network in the presence
of noise. This framework enables an estimation-theoretic approach to the design
and characterization of synchronization algorithms. The Fisher information is
expressed in terms of the distribution of the measurement noise and standard
mathematical descriptors of the network's graph structure for several important
cases. This leads to maximum likelihood and approximate maximum-likelihood
registration algorithms and also to distributed iterative algorithms that, when
they converge, attain statistically optimal solutions. The relationship between
optimal estimation in this setting and Kirchhoff's laws is also elucidated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2985</identifier>
 <datestamp>2013-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2985</id><created>2010-10-14</created><updated>2012-02-15</updated><authors><author><keyname>Foucaud</keyname><forenames>Florent</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Naserasr</keyname><forenames>Reza</forenames><affiliation>LaBRI, LRI</affiliation></author><author><keyname>Parreau</keyname><forenames>Aline</forenames><affiliation>IF</affiliation></author></authors><title>Characterizing extremal digraphs for identifying codes and extremal
  cases of Bondy's theorem on induced subsets</title><categories>cs.DM math.CO</categories><proxy>ccsd</proxy><journal-ref>Graphs and Combinatorics 29, 3 (2013) 463-473</journal-ref><doi>10.1007/s00373-012-1136-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An identifying code of a (di)graph $G$ is a dominating subset $C$ of the
vertices of $G$ such that all distinct vertices of $G$ have distinct
(in)neighbourhoods within $C$. In this paper, we classify all finite digraphs
which only admit their whole vertex set in any identifying code. We also
classify all such infinite oriented graphs. Furthermore, by relating this
concept to a well known theorem of A. Bondy on set systems we classify the
extremal cases for this theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2989</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2989</id><created>2010-10-14</created><authors><author><keyname>Petrosyan</keyname><forenames>P. A.</forenames></author><author><keyname>Torosyan</keyname><forenames>A. Yu.</forenames></author><author><keyname>Khachatryan</keyname><forenames>N. A.</forenames></author></authors><title>Interval total colorings of graphs</title><categories>cs.DM</categories><comments>23 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A total coloring of a graph $G$ is a coloring of its vertices and edges such
that no adjacent vertices, edges, and no incident vertices and edges obtain the
same color. An \emph{interval total $t$-coloring} of a graph $G$ is a total
coloring of $G$ with colors $1,2,\...,t$ such that at least one vertex or edge
of $G$ is colored by $i$, $i=1,2,\...,t$, and the edges incident to each vertex
$v$ together with $v$ are colored by $d_{G}(v)+1$ consecutive colors, where
$d_{G}(v)$ is the degree of the vertex $v$ in $G$. In this paper we investigate
some properties of interval total colorings. We also determine exact values of
the least and the greatest possible number of colors in such colorings for some
classes of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2992</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2992</id><created>2010-10-14</created><authors><author><keyname>Balakrishnan</keyname><forenames>A. V.</forenames></author><author><keyname>Mazumdar</keyname><forenames>Ravi R.</forenames></author></authors><title>On Powers of Gaussian White Noise</title><categories>cs.IT math.IT math.PR</categories><comments>10 pages</comments><msc-class>28C20, 60G30</msc-class><journal-ref>IEEE Trans. on Information Theory, Vol 57 (11), 2011 pp. 7629-7634</journal-ref><doi>10.1109/TIT.2011.2158062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical Gaussian white noise in communications and signal processing is
viewed as the limit of zero mean second order Gaussian processes with a
compactly supported flat spectral density as the support goes to infinity. The
difficulty of developing a theory to deal with nonlinear transformations of
white noise has been to interpret the corresponding limits. In this paper we
show that a renormalization and centering of powers of band-limited Gaussian
processes is Gaussian white noise and as a consequence, homogeneous polynomials
under suitable renormalization remain white noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2993</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2993</id><created>2010-10-14</created><authors><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Ozel</keyname><forenames>Omur</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Broadcasting with an Energy Harvesting Rechargeable Transmitter</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications, October
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the transmission completion time minimization
problem in a two-user additive white Gaussian noise (AWGN) broadcast channel,
where the transmitter is able to harvest energy from the nature, using a
rechargeable battery. The harvested energy is modeled to arrive at the
transmitter randomly during the course of transmissions. The transmitter has a
fixed number of packets to be delivered to each receiver. Our goal is to
minimize the time by which all of the packets for both users are delivered to
their respective destinations. To this end, we optimize the transmit powers and
transmission rates intended for both users. We first analyze the structural
properties of the optimal transmission policy. We prove that the optimal total
transmit power has the same structure as the optimal single-user transmit
power. We also prove that there exists a cut-off power level for the stronger
user. If the optimal total transmit power is lower than this cut-off level, all
transmit power is allocated to the stronger user, and when the optimal total
transmit power is larger than this cut-off level, all transmit power above this
level is allocated to the weaker user. Based on these structural properties of
the optimal policy, we propose an algorithm that yields the globally optimal
off-line scheduling policy. Our algorithm is based on the idea of reducing the
two-user broadcast channel problem into a single-user problem as much as
possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.2997</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.2997</id><created>2010-10-14</created><authors><author><keyname>Dekel</keyname><forenames>Yael</forenames></author><author><keyname>Gurel-Gurevich</keyname><forenames>Ori</forenames></author><author><keyname>Peres</keyname><forenames>Yuval</forenames></author></authors><title>Finding Hidden Cliques in Linear Time with High Probability</title><categories>math.CO cs.DM math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given a graph $G$ with $n$ vertices, where a random subset of $k$
vertices has been made into a clique, and the remaining edges are chosen
independently with probability $\tfrac12$. This random graph model is denoted
$G(n,\tfrac12,k)$. The hidden clique problem is to design an algorithm that
finds the $k$-clique in polynomial time with high probability. An algorithm due
to Alon, Krivelevich and Sudakov uses spectral techniques to find the hidden
clique with high probability when $k = c \sqrt{n}$ for a sufficiently large
constant $c &gt; 0$. Recently, an algorithm that solves the same problem was
proposed by Feige and Ron. It has the advantages of being simpler and more
intuitive, and of an improved running time of $O(n^2)$. However, the analysis
in the paper gives success probability of only $2/3$. In this paper we present
a new algorithm for finding hidden cliques that both runs in time $O(n^2)$, and
has a failure probability that is less than polynomially small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3003</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3003</id><created>2010-10-14</created><authors><author><keyname>Bollen</keyname><forenames>Johan</forenames></author><author><keyname>Mao</keyname><forenames>Huina</forenames></author><author><keyname>Zeng</keyname><forenames>Xiao-Jun</forenames></author></authors><title>Twitter mood predicts the stock market</title><categories>cs.CE cs.CL cs.SI physics.soc-ph</categories><journal-ref>Journal of Computational Science, 2(1), March 2011, Pages 1-8</journal-ref><doi>10.1016/j.jocs.2010.12.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Behavioral economics tells us that emotions can profoundly affect individual
behavior and decision-making. Does this also apply to societies at large, i.e.,
can societies experience mood states that affect their collective decision
making? By extension is the public mood correlated or even predictive of
economic indicators? Here we investigate whether measurements of collective
mood states derived from large-scale Twitter feeds are correlated to the value
of the Dow Jones Industrial Average (DJIA) over time. We analyze the text
content of daily Twitter feeds by two mood tracking tools, namely OpinionFinder
that measures positive vs. negative mood and Google-Profile of Mood States
(GPOMS) that measures mood in terms of 6 dimensions (Calm, Alert, Sure, Vital,
Kind, and Happy). We cross-validate the resulting mood time series by comparing
their ability to detect the public's response to the presidential election and
Thanksgiving day in 2008. A Granger causality analysis and a Self-Organizing
Fuzzy Neural Network are then used to investigate the hypothesis that public
mood states, as measured by the OpinionFinder and GPOMS mood time series, are
predictive of changes in DJIA closing values. Our results indicate that the
accuracy of DJIA predictions can be significantly improved by the inclusion of
specific public mood dimensions but not others. We find an accuracy of 87.6% in
predicting the daily up and down changes in the closing values of the DJIA and
a reduction of the Mean Average Percentage Error by more than 6%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3007</identifier>
 <datestamp>2013-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3007</id><created>2010-10-14</created><updated>2013-12-06</updated><authors><author><keyname>Fawzi</keyname><forenames>Omar</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Sen</keyname><forenames>Pranab</forenames></author></authors><title>From Low-Distortion Norm Embeddings to Explicit Uncertainty Relations
  and Efficient Information Locking</title><categories>quant-ph cs.CC math.MG</categories><comments>60 pages, 5 figures. v4: published version</comments><acm-class>F.1.1; E.4</acm-class><journal-ref>Journal of the ACM, Vol. 60, No. 6, Article 44, November 2013</journal-ref><doi>10.1145/2518131</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of quantum uncertainty relations is the essential reason that
some classically impossible cryptographic primitives become possible when
quantum communication is allowed. One direct operational manifestation of these
uncertainty relations is a purely quantum effect referred to as information
locking. A locking scheme can be viewed as a cryptographic protocol in which a
uniformly random n-bit message is encoded in a quantum system using a classical
key of size much smaller than n. Without the key, no measurement of this
quantum state can extract more than a negligible amount of information about
the message, in which case the message is said to be &quot;locked&quot;. Furthermore,
knowing the key, it is possible to recover, that is &quot;unlock&quot;, the message. In
this paper, we make the following contributions by exploiting a connection
between uncertainty relations and low-distortion embeddings of L2 into L1. We
introduce the notion of metric uncertainty relations and connect it to
low-distortion embeddings of L2 into L1. A metric uncertainty relation also
implies an entropic uncertainty relation. We prove that random bases satisfy
uncertainty relations with a stronger definition and better parameters than
previously known. Our proof is also considerably simpler than earlier proofs.
We apply this result to show the existence of locking schemes with key size
independent of the message length. We give efficient constructions of metric
uncertainty relations. The bases defining these metric uncertainty relations
are computable by quantum circuits of almost linear size. This leads to the
first explicit construction of a strong information locking scheme. Moreover,
we present a locking scheme that is close to being implementable with current
technology. We apply our metric uncertainty relations to exhibit communication
protocols that perform quantum equality testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3033</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3033</id><created>2010-10-14</created><authors><author><keyname>Bhagavatula</keyname><forenames>Ramya</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Adaptive Bit Partitioning for Multicell Intercell Interference Nulling
  with Delayed Limited Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing, July 2010</comments><doi>10.1109/TSP.2011.2146777</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Base station cooperation can exploit knowledge of the users' channel state
information (CSI) at the transmitters to manage co-channel interference. Users
have to feedback CSI of the desired and interfering channels using
finite-bandwidth backhaul links. Existing codebook designs for single-cell
limited feedback can be used for multicell cooperation by partitioning the
available feedback resources between the multiple channels. In this paper, a
new feedback-bit allocation strategy is proposed, as a function of the delays
in the communication links and received signal strengths in the downlink.
Channel temporal correlation is modeled as a function of delay using the
Gauss-Markov model. Closed-form expressions for bit partitions are derived to
allocate more bits to quantize the stronger channels with smaller delays and
fewer bits to weaker channels with larger delays, assuming random vector
quantization. Cellular network simulations are used to show that the proposed
algorithm yields higher sum-rates than an equal-bit allocation technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3034</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3034</id><created>2010-10-14</created><authors><author><keyname>Bhaskar</keyname><forenames>Umang</forenames></author><author><keyname>Fleischer</keyname><forenames>Lisa</forenames></author><author><keyname>Anshelevich</keyname><forenames>Elliot</forenames></author></authors><title>A Stackelberg Strategy for Routing Flow over Time</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Routing games are used to to understand the impact of individual users'
decisions on network efficiency. Most prior work on routing games uses a
simplified model of network flow where all flow exists simultaneously, and
users care about either their maximum delay or their total delay. Both of these
measures are surrogates for measuring how long it takes to get all of a user's
traffic through the network. We attempt a more direct study of how competition
affects network efficiency by examining routing games in a flow over time
model. We give an efficiently computable Stackelberg strategy for this model
and show that the competitive equilibrium under this strategy is no worse than
a small constant times the optimal, for two natural measures of optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3039</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3039</id><created>2010-10-14</created><authors><author><keyname>Monks</keyname><forenames>Maria</forenames></author></authors><title>Closure properties of predicates recognized by deterministic and
  non-deterministic asynchronous automata</title><categories>math.LO cs.LO math.GR</categories><comments>22 pages, 3 figures</comments><msc-class>03D05</msc-class><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let A be a finite alphabet and let L contained in (A*)^n be an n-variable
language over A. We say that L is regular if it is the language accepted by a
synchronous n-tape finite state automaton, it is quasi-regular if it is
accepted by an asynchronous n-tape automaton, and it is weakly regular if it is
accepted by a non-deterministic asynchronous n-tape automaton. We investigate
the closure properties of the classes of regular, quasi-regular, and weakly
regular languages under first-order logic, and apply these observations to an
open decidability problem in automatic group theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3045</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3045</id><created>2010-10-14</created><authors><author><keyname>Meira</keyname><forenames>Silvio R. L.</forenames></author><author><keyname>Buregio</keyname><forenames>Vanilson A. A.</forenames></author><author><keyname>Nascimento</keyname><forenames>Leandro M.</forenames></author><author><keyname>de Figueiredo</keyname><forenames>Elaine G. M.</forenames></author><author><keyname>Neto</keyname><forenames>Misael</forenames></author><author><keyname>Encarna&#xe7;&#xe3;o</keyname><forenames>Bruno P.</forenames></author><author><keyname>Garcia</keyname><forenames>Vin&#xed;cius</forenames></author></authors><title>The Emerging Web of Social Machines</title><categories>cs.SE</categories><comments>This is a very early report of work in progress; authors welcome all
  sorts of comments and contributions; at some stage in the future, we hope to
  submit a later version of this report to be considered for publication in a
  learned journal. Corresponding author: silvio@meira.com,
  http://twitter.com/srlm This work was partially supported by the National
  Institute of Science and Technology for Software Engineering (INES,
  http://www.ines.org.br), funded by CNPq and FACEPE, grants 573964/2008-4 and
  APQ-1037-1.03/08</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We define a notion of social machine and envisage an algebra that can
describe networks of such. To start with, social machines are defined as tuples
of input, output, processes, constraints, state, requests and responses; apart
from defining the machines themselves, the algebra defines a set of connectors
and conditionals that can be used to describe the interactions between any
number of machines in a multitude of ways, as a means to represent real
machines interacting in the real web, such as Twitter, Twitter running on top
of Amazon AWS, mashups built using Twitter and, obviously, other social
machines. This work is not a theoretical paper as yet; but, in more than one
sense, we think we have found a way to describe web based information systems
and are starting to work on what could be a practical way of dealing with the
complexity of this emerging web of social machines that is all around us. This
version should be read as work in progress and comments, observations, bugs...
are most welcome and should be sent to the email of the first, corresponding
author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3053</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3053</id><created>2010-10-14</created><authors><author><keyname>Kolb</keyname><forenames>Lars</forenames></author><author><keyname>Thor</keyname><forenames>Andreas</forenames></author><author><keyname>Rahm</keyname><forenames>Erhard</forenames></author></authors><title>Parallel Sorted Neighborhood Blocking with MapReduce</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud infrastructures enable the efficient parallel execution of
data-intensive tasks such as entity resolution on large datasets. We
investigate challenges and possible solutions of using the MapReduce
programming model for parallel entity resolution. In particular, we propose and
evaluate two MapReduce-based implementations for Sorted Neighborhood blocking
that either use multiple MapReduce jobs or apply a tailored data replication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3060</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3060</id><created>2010-10-14</created><updated>2011-07-20</updated><authors><author><keyname>Brown</keyname><forenames>Brielin</forenames></author><author><keyname>Flammia</keyname><forenames>Steven T.</forenames></author><author><keyname>Schuch</keyname><forenames>Norbert</forenames></author></authors><title>Computational Difficulty of Computing the Density of States</title><categories>quant-ph cs.CC</categories><comments>v2: Accepted version. 9 pages, 1 figure</comments><journal-ref>Phys. Rev. Lett. 107, 040501 (2011)</journal-ref><doi>10.1103/PhysRevLett.107.040501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational difficulty of computing the ground state
degeneracy and the density of states for local Hamiltonians. We show that the
difficulty of both problems is exactly captured by a class which we call #BQP,
which is the counting version of the quantum complexity class QMA. We show that
#BQP is not harder than its classical counting counterpart #P, which in turn
implies that computing the ground state degeneracy or the density of states for
classical Hamiltonians is just as hard as it is for quantum Hamiltonians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3071</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3071</id><created>2010-10-15</created><authors><author><keyname>Ramalingam</keyname><forenames>Neevan</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>On the Rate Achievable for Gaussian Relay Channels Using Superposition
  Forwarding</title><categories>cs.IT math.IT</categories><comments>19 pages. 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the achievable rate of the superposition of block Markov encoding
(decode-and-forward) and side information encoding (compress-and-forward) for
the three-node Gaussian relay channel. It is generally believed that the
superposition can out perform decode-and-forward or compress-and-forward due to
its generality. We prove that within the class of Gaussian distributions, this
is not the case: the superposition scheme only achieves a rate that is equal to
the maximum of the rates achieved by decode-and-forward or compress-and-forward
individually. We also present a superposition scheme that combines broadcast
with decode-and-forward, which even though does not achieve a higher rate than
decode-and-forward, provides us the insight to the main result mentioned above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3083</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3083</id><created>2010-10-15</created><updated>2010-11-04</updated><authors><author><keyname>Adsul</keyname><forenames>Bharat</forenames></author><author><keyname>Garg</keyname><forenames>Jugal</forenames></author><author><keyname>Mehta</keyname><forenames>Ruta</forenames></author><author><keyname>Sohoni</keyname><forenames>Milind</forenames></author></authors><title>Rank-1 Bi-matrix Games: A Homeomorphism and a Polynomial Time Algorithm</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a rank-1 bimatrix game (A,B), i.e., where rank(A+B)=1, we construct a
suitable linear subspace of the rank-1 game space and show that this subspace
is homeomorphic to its Nash equilibrium correspondence. Using this
homeomorphism, we give the first polynomial time algorithm for computing an
exact Nash equilibrium of a rank-1 bimatrix game. This settles an open question
posed in Kannan and Theobald (SODA 2007) and Theobald (2007). In addition, we
give a novel algorithm to enumerate all the Nash equilibria of a rank-1 game
and show that a similar technique may also be applied for finding a Nash
equilibrium of any bimatrix game. This technique also proves the existence,
oddness and the index theorem of Nash equilibria in a bimatrix game. Further,
we extend the rank-1 homeomorphism result to a fixed rank game space, and give
a fixed point formulation on $[0,1]^k$ for solving a rank-k game. The
homeomorphism and the fixed point formulation are piece-wise linear and
considerably simpler than the classical constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3091</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3091</id><created>2010-10-15</created><updated>2013-12-16</updated><authors><author><keyname>Golovin</keyname><forenames>Daniel</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author><author><keyname>Ray</keyname><forenames>Debajyoti</forenames></author></authors><title>Near-Optimal Bayesian Active Learning with Noisy Observations</title><categories>cs.LG cs.AI cs.DS</categories><comments>15 pages. Version 2 contains only one major change, namely an amended
  proof of Lemma 6</comments><acm-class>I.2.6; G.3; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the fundamental problem of Bayesian active learning with noise,
where we need to adaptively select from a number of expensive tests in order to
identify an unknown hypothesis sampled from a known prior distribution. In the
case of noise-free observations, a greedy algorithm called generalized binary
search (GBS) is known to perform near-optimally. We show that if the
observations are noisy, perhaps surprisingly, GBS can perform very poorly. We
develop EC2, a novel, greedy active learning algorithm and prove that it is
competitive with the optimal policy, thus obtaining the first competitiveness
guarantees for Bayesian active learning with noisy observations. Our bounds
rely on a recently discovered diminishing returns property called adaptive
submodularity, generalizing the classical notion of submodular set functions to
adaptive policies. Our results hold even if the tests have non-uniform cost and
their noise is correlated. We also propose EffECXtive, a particularly fast
approximation of EC2, and evaluate it on a Bayesian experimental design problem
involving human subjects, intended to tease apart competing economic theories
of how people make decisions under uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3096</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3096</id><created>2010-10-15</created><authors><author><keyname>Turgut</keyname><forenames>Deniz</forenames></author><author><keyname>Atilgan</keyname><forenames>Ali Rana</forenames></author><author><keyname>Atilgan</keyname><forenames>Canan</forenames></author></authors><title>Assortative Mixing in Close-Packed Spatial Networks</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>24 pages, 4 figures</comments><doi>10.1371/journal.pone.0015551</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general relation for the dependence of nearest neighbor degree correlations
on degree is derived. Dependence of local clustering on degree is shown to be
the sole determining factor of assortative versus disassortative mixing in
networks. The characteristics of networks derived from spatial atomic/molecular
systems exemplified by self-organized residue networks and block copolymers,
atomic clusters and well-compressed polymeric melts are studied. Distributions
of statistical properties of the networks are presented. For these
densely-packed systems, assortative mixing in the network construction is found
to apply, and conditions are derived for a simple linear dependence. Together,
these measures (i) reveal patterns that are common to close-packed clusters of
atoms/molecules, (ii) identify the type of surface effects prominent in
different systems, and (iii) associate fingerprints that may be used to
classify networks with varying types of correlations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3100</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3100</id><created>2010-10-15</created><authors><author><keyname>Diertens</keyname><forenames>B.</forenames></author></authors><title>On Object-Orientation</title><categories>cs.SE</categories><report-no>TCS1001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although object-orientation has been around for several decades, its key
concept abstraction has not been exploited for proper application of
object-orientation in other phases of software development than the
implementation phase. We mention some issues that lead to a lot of confusion
and obscurity with object-orientation and its application in software
development. We describe object-orientation as abstract as possible such that
it can be applied to all phases of software development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3125</identifier>
 <datestamp>2012-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3125</id><created>2010-10-15</created><updated>2011-08-01</updated><authors><author><keyname>Vladimirov</keyname><forenames>Igor G.</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>A Quasi-separation Principle and Newton-like Scheme for Coherent Quantum
  LQG Control</title><categories>quant-ph cs.SY math.DS math.OC</categories><comments>24 pages, 2 figures, accepted for publication, 18th IFAC World
  Congress, Milan, Italy, 28 August - 2 September, 2011</comments><msc-class>81Q93, 81S25, 93E20 (Primary) 49J50, 58C20, 49M15 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with constructing an optimal controller in the
coherent quantum Linear Quadratic Gaussian problem. A coherent quantum
controller is itself a quantum system and is required to be physically
realizable. The use of coherent control avoids the need for classical
measurements, which inherently entail the loss of quantum information. Physical
realizability corresponds to the equivalence of the controller to an open
quantum harmonic oscillator and relates its state-space matrices to the
Hamiltonian, coupling and scattering operators of the oscillator. The
Hamiltonian parameterization of the controller is combined with Frechet
differentiation of the LQG cost with respect to the state-space matrices to
obtain equations for the optimal controller. A quasi-separation principle for
the gain matrices of the quantum controller is established, and a Newton-like
iterative scheme for numerical solution of the equations is outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3132</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3132</id><created>2010-10-15</created><updated>2011-12-20</updated><authors><author><keyname>Matusiak</keyname><forenames>Ewa</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Sub-Nyquist Sampling of Short Pulses</title><categories>cs.IT math.IT</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop sub-Nyquist sampling systems for analog signals comprised of
several, possibly overlapping, finite duration pulses with unknown shapes and
time positions. Efficient sampling schemes when either the pulse shape or the
locations of the pulses are known have been previously developed. To the best
of our knowledge, stable and low-rate sampling strategies for continuous
signals that are superpositions of unknown pulses without knowledge of the
pulse locations have not been derived. The goal in this paper is to fill this
gap. We propose a multichannel scheme based on Gabor frames that exploits the
sparsity of signals in time and enables sampling multipulse signals at
sub-Nyquist rates. Moreover, if the signal is additionally essentially
multiband, then the sampling scheme can be adapted to lower the sampling rate
without knowing the band locations. We show that, with proper preprocessing,
the necessary Gabor coefficients, can be recovered from the samples using
standard methods of compressed sensing. In addition, we provide error estimates
on the reconstruction and analyze the proposed architecture in the presence of
noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3133</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3133</id><created>2010-10-15</created><updated>2011-03-16</updated><authors><author><keyname>Busic</keyname><forenames>Ana</forenames></author><author><keyname>Mairesse</keyname><forenames>Jean</forenames></author><author><keyname>Marcovici</keyname><forenames>Irene</forenames></author></authors><title>Probabilistic cellular automata, invariant measures, and perfect
  sampling</title><categories>math.PR cs.DM</categories><msc-class>Primary: 37B15, 60J05, 60J22. Secondary: 37A25, 60K35, 68Q80</msc-class><acm-class>G.3; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A probabilistic cellular automaton (PCA) can be viewed as a Markov chain. The
cells are updated synchronously and independently, according to a distribution
depending on a finite neighborhood. We investigate the ergodicity of this
Markov chain. A classical cellular automaton is a particular case of PCA. For a
1-dimensional cellular automaton, we prove that ergodicity is equivalent to
nilpotency, and is therefore undecidable. We then propose an efficient perfect
sampling algorithm for the invariant measure of an ergodic PCA. Our algorithm
does not assume any monotonicity property of the local rule. It is based on a
bounding process which is shown to be also a PCA. Last, we focus on the PCA
Majority, whose asymptotic behavior is unknown, and perform numerical
experiments using the perfect sampling procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3150</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3150</id><created>2010-10-15</created><authors><author><keyname>Fang</keyname><forenames>Yong</forenames></author></authors><title>Application of DAC Codeword Spectrum: Expansion Factor</title><categories>cs.IT math.IT</categories><comments>12 pages, 3 figures, submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Arithmetic Coding (DAC) proves to be an effective implementation
of Slepian-Wolf Coding (SWC), especially for short data blocks. To study the
property of DAC codewords, the author has proposed the concept of DAC codeword
spectrum. For equiprobable binary sources, the problem was formatted as solving
a system of functional equations. Then, to calculate DAC codeword spectrum in
general cases, three approximation methods have been proposed. In this paper,
the author makes use of DAC codeword spectrum as a tool to answer an important
question: how many (including proper and wrong) paths will be created during
the DAC decoding, if no path is pruned? The author introduces the concept of
another kind of DAC codeword spectrum, i.e. time spectrum, while the
originally-proposed DAC codeword spectrum is called path spectrum from now on.
To measure how fast the number of decoding paths increases, the author
introduces the concept of expansion factor which is defined as the ratio of
path numbers between two consecutive decoding stages. The author reveals the
relation between expansion factor and path/time spectrum, and proves that the
number of decoding paths of any DAC codeword increases exponentially as the
decoding proceeds. Specifically, when symbols `0' and `1' are mapped onto
intervals [0, q) and [(1-q), 1), where 0.5&lt;q&lt;1, the author proves that
expansion factor converges to 2q as the decoding proceeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3163</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3163</id><created>2010-10-15</created><authors><author><keyname>Gligoroski</keyname><forenames>Danilo</forenames></author><author><keyname>Knapskog</keyname><forenames>Svein Johan</forenames></author><author><keyname>Markovski</keyname><forenames>Smile</forenames></author><author><keyname>&#xd8;deg&#xe5;rd</keyname><forenames>Rune Steinsmo</forenames></author><author><keyname>Jensen</keyname><forenames>Rune Erlend</forenames></author><author><keyname>Perret</keyname><forenames>Ludovic</forenames></author><author><keyname>Faug&#xe8;re</keyname><forenames>Jean-Charles</forenames></author></authors><title>The Digital Signature Scheme MQQ-SIG</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document contains the Intellectual Property Statement and the technical
description of the MQQ-SIG - a new public key digital signature scheme. The
complete scientific publication covering the design rationale and the security
analysis will be given in a separate publication. MQQ-SIG consists of $n -
\frac{n}{4}$ quadratic polynomials with $n$ Boolean variables where n=160, 196,
224 or 256.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3171</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3171</id><created>2010-10-15</created><updated>2011-04-18</updated><authors><author><keyname>Pan</keyname><forenames>Raj Kumar</forenames></author><author><keyname>Kivel&#xe4;</keyname><forenames>Mikko</forenames></author><author><keyname>Saram&#xe4;ki</keyname><forenames>Jari</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>Using explosive percolation in analysis of real-world networks</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>6 pages, 4 figures. Published version. Elongated to include the
  results and figures of finite-size scaling and modularity analysis</comments><journal-ref>Phys. Rev. E 83, 046112 (2011)</journal-ref><doi>10.1103/PhysRevE.83.046112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply a variant of the explosive percolation procedure to large real-world
networks, and show with finite-size scaling that the university class, ordinary
or explosive, of the resulting percolation transition depends on the structural
properties of the network as well as the number of unoccupied links considered
for comparison in our procedure. We observe that in our social networks, the
percolation clusters close to the critical point are related to the community
structure. This relationship is further highlighted by applying the procedure
to model networks with pre-defined communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3172</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3172</id><created>2010-10-15</created><authors><author><keyname>Sutherland</keyname><forenames>Michael S.</forenames></author><author><keyname>Baughman</keyname><forenames>Brian M.</forenames></author><author><keyname>Beatty</keyname><forenames>James J.</forenames></author></authors><title>CRT: A numerical tool for propagating ultra-high energy cosmic rays
  through Galactic magnetic field models</title><categories>astro-ph.IM astro-ph.CO astro-ph.GA astro-ph.HE cs.CE physics.comp-ph</categories><comments>12 pages, 9 figures</comments><journal-ref>Astroparticle Physics, Volume 34, Issue 4, p. 198-204. (2010)</journal-ref><doi>10.1016/j.astropartphys.2010.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deflection of ultra high energy cosmic rays (UHECRs) by the Galactic magnetic
field (GMF) may be sufficiently strong to hinder identification of the UHECR
source distribution. A common method for determining the effect of GMF models
on source identification efforts is backtracking cosmic rays. We present the
public numerical tool CRT for propagating charged particles through Galactic
magnetic field models by numerically integrating the relativistic equation of
motion. It is capable of both forward- and back-tracking particles with varying
compositions through pre-defined and custom user-created magnetic fields. These
particles are injected from various types of sources specified and distributed
according to the user. Here, we present a description of some source and
magnetic field model implementations, as well as validation of the integration
routines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3177</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3177</id><created>2010-10-15</created><authors><author><keyname>Rong</keyname><forenames>Xin</forenames></author></authors><title>Introduction to the iDian</title><categories>cs.AI</categories><comments>4 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The iDian (previously named as the Operation Agent System) is a framework
designed to enable computer users to operate software in natural language.
Distinct from current speech-recognition systems, our solution supports
format-free combinations of orders, and is open to both developers and
customers. We used a multi-layer structure to build the entire framework,
approached rule-based natural language processing, and implemented demos
narrowing down to Windows, text-editing and a few other applications. This
essay will firstly give an overview of the entire system, and then scrutinize
the functions and structure of the system, and finally discuss the prospective
de-velopment, esp. on-line interaction functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3190</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3190</id><created>2010-10-15</created><updated>2011-05-27</updated><authors><author><keyname>Biswas</keyname><forenames>Soumyajyoti</forenames></author><author><keyname>Chandra</keyname><forenames>Anjan Kumar</forenames></author><author><keyname>Chatterjee</keyname><forenames>Arnab</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Bikas K.</forenames></author></authors><title>Phase transitions and non-equilibrium relaxation in kinetic models of
  opinion formation</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.comp-ph</categories><comments>11 pages, 8 eps figures, 1 table. Contribution for proceedings of
  Statphys-Kolkata-VII 26-30 November, 2010</comments><journal-ref>Journal of Physics: Conference Series 297 (2011) 012004</journal-ref><doi>10.1088/1742-6596/297/1/012004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review in details some recently proposed kinetic models of opinion
dynamics. We discuss the several variants including a generalised model. We
provide mean field estimates for the critical points, which are numerically
supported with reasonable accuracy. Using non-equilibrium relaxation
techniques, we also investigate the nature of phase transitions observed in
these models. We study the nature of correlations as the critical points are
approached, and comment on the universality of the phase transitions observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3197</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3197</id><created>2010-10-14</created><authors><author><keyname>Salehkaleybar</keyname><forenames>Saber</forenames></author><author><keyname>Majd</keyname><forenames>Seyyed Arash</forenames></author><author><keyname>Pakravan</keyname><forenames>Mohammad Reza</forenames></author></authors><title>QoS-Aware Joint Policies in Cognitive Radio Networks</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most challenging problems in Opportunistic Spectrum Access (OSA)
is to design channel sensing-based protocol in multi secondary users (SUs)
network. Quality of Service (QoS) requirements for SUs have significant
implications on this protocol design. In this paper, we propose a new method to
find joint policies for SUs which not only guarantees QoS requirements but also
maximizes network throughput. We use Decentralized Partially Observable Markov
Decision Process (Dec-POMDP) to formulate interactions between SUs. Meanwhile,
a tractable approach for Dec-POMDP is utilized to extract sub-optimum joint
policies for large horizons. Among these policies, the joint policy which
guarantees QoS requirements is selected as the joint sensing strategy for SUs.
To show the efficiency of the proposed method, we consider two SUs trying to
access two-channel primary users (PUs) network modeled by discrete Markov
chains. Simulations demonstrate three interesting findings: 1- Optimum joint
policies for large horizons can be obtained using the proposed method. 2- There
exists a joint policy for the assumed QoS constraints. 3- Our method
outperforms other related works in terms of network throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3201</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3201</id><created>2010-10-15</created><authors><author><keyname>Ferbus-Zanda</keyname><forenames>Marie</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Grigorieff</keyname><forenames>Serge</forenames><affiliation>LIAFA</affiliation></author></authors><title>Kolmogorov Complexity in perspective. Part I: Information Theory and
  Randomnes</title><categories>cs.LO cs.CC cs.IT math.IT</categories><comments>40 pages</comments><proxy>ccsd</proxy><journal-ref>Synthese / Synth\`ese (2010) 00</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey diverse approaches to the notion of information: from Shannon
entropy to Kolmogorov complexity. Two of the main applications of Kolmogorov
complexity are presented: randomness and classification. The survey is divided
in two parts in the same volume. Part I is dedicated to information theory and
the mathematical formalization of randomness based on Kolmogorov complexity.
This last application goes back to the 60's and 70's with the work of
Martin-L\&quot;of, Schnorr, Chaitin, Levin, and has gained new impetus in the last
years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3233</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3233</id><created>2010-10-15</created><authors><author><keyname>White</keyname><forenames>Joshua</forenames></author><author><keyname>Pilbeam</keyname><forenames>Adam</forenames></author></authors><title>A Survey of Virtualization Technologies With Performance Testing</title><categories>cs.DC</categories><comments>6 Pages, 2 Tables, 4 Plots</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtualization has rapidly become a go-to technology for increasing
efficiency in the data center. With virtualization technologies providing
tremendous flexibility, even disparate architectures may be deployed on a
single machine without interference. Awareness of limitations and requirements
of physical hosts to be used for virtualization is important. This paper
reviews the present virtualization methods, virtual computing software, and
provides a brief analysis of the performance issues inherent to each. In the
end we present testing results of KVM-QEMU on two current Multi-Core CPU
Architectures and System Configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3263</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3263</id><created>2010-10-15</created><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Ye</keyname><forenames>Yuli</forenames></author></authors><title>Syntactic Complexity of Ideal and Closed Languages</title><categories>cs.FL</categories><comments>22 pages, 8 figures in .eepic format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The state complexity of a regular language is the number of states in the
minimal deterministic automaton accepting the language. The syntactic
complexity of a regular language is the cardinality of its syntactic semigroup.
The syntactic complexity of a subclass of regular languages is the worst-case
syntactic complexity taken as a function of the state complexity $n$ of
languages in that class. We study the syntactic complexity of the class of
regular ideal languages and their complements, the closed languages. We prove
that $n^{n-1}$ is a tight upper bound on the complexity of right ideals and
prefix-closed languages, and that there exist left ideals and suffix-closed
languages of syntactic complexity $n^{n-1}+n-1$, and two-sided ideals and
factor-closed languages of syntactic complexity $n^{n-2}+(n-2)2^{n-2}+1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3294</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3294</id><created>2010-10-15</created><authors><author><keyname>Elsabagh</keyname><forenames>Mohamed</forenames></author><author><keyname>Abdallah</keyname><forenames>Yara</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>ARQ Security in Wi-Fi and RFID Networks</title><categories>cs.CR cs.IT math.IT</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present two practical ARQ-Based security schemes for Wi-Fi
and RFID networks. Our proposed schemes enhance the confidentiality and
authenticity functions of these networks, respectively. Both schemes build on
the same idea; by exploiting the statistical independence between the multipath
fading experienced by the legitimate nodes and potential adversaries, secret
keys are established and then are continuously updated. The continuous key
update property of both schemes makes them capable of defending against all of
the passive eavesdropping attacks and most of the currently-known active
attacks against either Wi-Fi or RFID networks. However, each scheme is tailored
to best suit the requirements of its respective paradigm. In Wi-Fi networks, we
overlay, rather than completely replace, the current Wi-Fi security protocols.
Thus, our Wi-Fi scheme can be readily implemented via only minor modifications
over the IEEE 802.11 standards. On the other hand, the proposed RFID scheme
introduces the first provably secure low cost RFID authentication protocol. The
proposed schemes impose a throughput-security tradeoff that is shown, through
our analytical and experimental results, to be practically acceptable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3304</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3304</id><created>2010-10-15</created><updated>2012-03-08</updated><authors><author><keyname>Baryshnikov</keyname><forenames>Yuliy</forenames></author><author><keyname>Tucci</keyname><forenames>Gabriel H.</forenames></author></authors><title>Asymptotic Traffic Flow in a Hyperbolic Network: Definition and
  Properties of the Core</title><categories>math.GR cond-mat.stat-mech cs.NI math.MG</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the asymptotic traffic flow in Gromov's hyperbolic
graphs. We prove that under certain mild hypotheses the traffic flow in a
hyperbolic graph tends to pass through a finite set of highly congested nodes.
These nodes are called the &quot;core&quot; of the graph. We provide a formal definition
of the core in a very general context and we study the properties of this set
for several graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3305</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3305</id><created>2010-10-15</created><updated>2012-03-08</updated><authors><author><keyname>Baryshnikov</keyname><forenames>Yuliy</forenames></author><author><keyname>Tucci</keyname><forenames>Gabriel H.</forenames></author></authors><title>Asymptotic Traffic Flow in a Hyperbolic Network: Non-uniform Traffic</title><categories>math.GR cond-mat.stat-mech cs.NI math-ph math.MG math.MP</categories><comments>11 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the asymptotic traffic flow in Gromov's hyperbolic
graphs when the traffic decays exponentially with the distance. We prove that
under general conditions, there exists a phase transition between local and
global traffic. More specifically, assume that the traffic rate between two
nodes $u$ and $v$ is given by $R(u,v)=\beta^{-d(u,v)}$ where $d(u,v)$ is the
distance between the nodes. Then there exists a constant $\beta_c$ that depends
on the geometry of the network such that if $1&lt;\beta&lt;\beta_c$ the traffic is
global and there is a small set of highly congested nodes called the core.
However, if $\beta&gt;\beta_c$ then the traffic is essentially local and the core
is empty which implies very small congestion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3312</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3312</id><created>2010-10-15</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Ge</keyname><forenames>Gennian</forenames></author><author><keyname>Ji</keyname><forenames>Lijun</forenames></author><author><keyname>Ling</keyname><forenames>San</forenames></author><author><keyname>Yin</keyname><forenames>Jianxing</forenames></author></authors><title>List Decodability at Small Radii</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>to appear in Designs, Codes, and Cryptography (accepted October 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  $A'(n,d,e)$, the smallest $\ell$ for which every binary error-correcting code
of length $n$ and minimum distance $d$ is decodable with a list of size $\ell$
up to radius $e$, is determined for all $d\geq 2e-3$. As a result, $A'(n,d,e)$
is determined for all $e\leq 4$, except for 42 values of $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3319</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3319</id><created>2010-10-16</created><updated>2011-02-28</updated><authors><author><keyname>Shakir</keyname><forenames>M. Zeeshan</forenames></author><author><keyname>Durrani</keyname><forenames>Tariq S.</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Hadamard Upper Bound (HUB) on Optimum Joint Decoding Capacity of Wyner
  Gaussian Cellular MAC</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3325</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3325</id><created>2010-10-16</created><authors><author><keyname>Dua</keyname><forenames>Arun</forenames></author></authors><title>Wireless Sensor Network based Future of Telecom Applications</title><categories>cs.HC cs.NE</categories><comments>8 pages,4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A system and method for enabling human beings to communicate by way of their
monitored brain activity. The brain activity of an individual is monitored and
transmitted to a remote location (e.g. by satellite). At the remote location,
the monitored brain activity is compared with pre-recorded normalized brain
activity curves, waveforms, or patterns to determine if a match or substantial
match is found. If such a match is found, then the computer at the remote
location determines that the individual was attempting to communicate the word,
phrase, or thought corresponding to the matched stored normalized signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3337</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3337</id><created>2010-10-16</created><authors><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>How to use our talents based on Information Theory - or spending time
  wisely</title><categories>cs.IT math.IT math.OC physics.soc-ph stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the allocation of finite resources in the presence of a
logarithmic diminishing return law, in analogy to some results from Information
Theory. To exemplify the problem we assume that the proposed logarithmic law is
applied to the problem of how to spend our time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3348</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3348</id><created>2010-10-16</created><updated>2011-02-09</updated><authors><author><keyname>Andr&#xe1;s</keyname><forenames>Szil&#xe1;rd</forenames></author><author><keyname>Baricz</keyname><forenames>&#xc1;rp&#xe1;d</forenames></author><author><keyname>Sun</keyname><forenames>Yin</forenames></author></authors><title>The generalized Marcum $Q-$function: an orthogonal polynomial approach</title><categories>math.CA cs.IT math.IT</categories><comments>11 pages</comments><journal-ref>Acta Universitatis Sapientiae Mathematica 3(1) (2011) 60-76</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel power series representation of the generalized Marcum $Q-$function of
positive order involving generalized Laguerre polynomials is presented. The
absolute convergence of the proposed power series expansion is showed, together
with a convergence speed analysis by means of truncation error. A brief review
of related studies and some numerical results are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3367</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3367</id><created>2010-10-16</created><updated>2012-05-05</updated><authors><author><keyname>Dvorak</keyname><forenames>Zdenek</forenames></author><author><keyname>Mohar</keyname><forenames>Bojan</forenames></author></authors><title>Spectrally degenerate graphs: Hereditary case</title><categories>math.CO cs.DM</categories><comments>Updated after reviewer comments. 14 pages, no figures</comments><msc-class>05C50</msc-class><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the spectral radius of a tree whose maximum degree is D
cannot exceed 2sqrt{D-1}. Similar upper bound holds for arbitrary planar
graphs, whose spectral radius cannot exceed sqrt{8D}+10, and more generally,
for all d-degenerate graphs, where the corresponding upper bound is sqrt{4dD}.
Following this, we say that a graph G is spectrally d-degenerate if every
subgraph H of G has spectral radius at most sqrt{d.Delta(H)}. In this paper we
derive a rough converse of the above-mentioned results by proving that each
spectrally d-degenerate graph G contains a vertex whose degree is at most
4dlog_2(D/d) (if D&gt;=2d). It is shown that the dependence on D in this upper
bound cannot be eliminated, as long as the dependence on d is subexponential.
It is also proved that the problem of deciding if a graph is spectrally
d-degenerate is co-NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3411</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3411</id><created>2010-10-17</created><authors><author><keyname>Ibrahim</keyname><forenames>Mohamed</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>A Hidden Markov Model for Localization Using Low-End GSM Cell Phones</title><categories>cs.NI</categories><comments>6 pages, 5 figures, submitted to ICC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research in location determination for GSM phones has gained interest
recently as it enables a wide set of location based services. RSSI-based
techniques have been the preferred method for GSM localization on the handset
as RSSI information is available in all cell phones. Although the GSM standard
allows for a cell phone to receive signal strength information from up to seven
cell towers, many of today's cell phones are low-end phones, with limited API
support, that gives only information about the associated cell tower. In
addition, in many places in the world, the density of cell towers is very small
and therefore, the available cell tower information for localization is very
limited. This raises the challenge of accurately determining the cell phone
location with very limited information, mainly the RSSI of the associated cell
tower. In this paper we propose a Hidden Markov Model based solution that
leverages the signal strength history from only the associated cell tower to
achieve accurate GSM localization. We discuss the challenges of implementing
our system and present the details of our system and how it addresses the
challenges. To evaluate our proposed system, we implemented it on Androidbased
phones. Results for two different testbeds, representing urban and rural
environments, show that our system provides at least 156% enhancement in median
error in rural areas and at least 68% enhancement in median error in urban
areas compared to current RSSI-based GSM localization systems
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3425</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3425</id><created>2010-10-17</created><authors><author><keyname>Dawid</keyname><forenames>A. Philip</forenames></author><author><keyname>Didelez</keyname><forenames>Vanessa</forenames></author></authors><title>Identifying the consequences of dynamic treatment strategies: A
  decision-theoretic overview</title><categories>math.ST cs.AI stat.TH</categories><comments>49 pages, 15 figures</comments><msc-class>62C05, 62A01</msc-class><journal-ref>Statistics Surveys 2010, Vol. 4, 184-231</journal-ref><doi>10.1214/10-SS081</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider the problem of learning about and comparing the consequences of
dynamic treatment strategies on the basis of observational data. We formulate
this within a probabilistic decision-theoretic framework. Our approach is
compared with related work by Robins and others: in particular, we show how
Robins's 'G-computation' algorithm arises naturally from this
decision-theoretic perspective. Careful attention is paid to the mathematical
and substantive conditions required to justify the use of this formula. These
conditions revolve around a property we term stability, which relates the
probabilistic behaviours of observational and interventional regimes. We show
how an assumption of 'sequential randomization' (or 'no unmeasured
confounders'), or an alternative assumption of 'sequential irrelevance', can be
used to infer stability. Probabilistic influence diagrams are used to simplify
manipulations, and their power and limitations are discussed. We compare our
approach with alternative formulations based on causal DAGs or potential
response models. We aim to show that formulating the problem of assessing
dynamic treatment strategies as a problem of decision analysis brings clarity,
simplicity and generality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3427</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3427</id><created>2010-10-17</created><updated>2011-04-16</updated><authors><author><keyname>Halldorsson</keyname><forenames>Magnus M.</forenames></author></authors><title>Wireless Scheduling with Power Control</title><categories>cs.NI cs.DC cs.DS</categories><comments>Revised full version</comments><acm-class>F.2.2; C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the scheduling of arbitrary wireless links in the physical model
of interference to minimize the time for satisfying all requests. We study here
the combined problem of scheduling and power control, where we seek both an
assignment of power settings and a partition of the links so that each set
satisfies the signal-to-interference-plus-noise (SINR) constraints.
  We give an algorithm that attains an approximation ratio of $O(\log n \cdot
\log\log \Delta)$, where $n$ is the number of links and $\Delta$ is the ratio
between the longest and the shortest link length. Under the natural assumption
that lengths are represented in binary, this gives the first approximation
ratio that is polylogarithmic in the size of the input. The algorithm has the
desirable property of using an oblivious power assignment, where the power
assigned to a sender depends only on the length of the link. We give evidence
that this dependence on $\Delta$ is unavoidable, showing that any
reasonably-behaving oblivious power assignment results in a $\Omega(\log\log
\Delta)$-approximation.
  These results hold also for the (weighted) capacity problem of finding a
maximum (weighted) subset of links that can be scheduled in a single time slot.
In addition, we obtain improved approximation for a bidirectional variant of
the scheduling problem, give partial answers to questions about the utility of
graphs for modeling physical interference, and generalize the setting from the
standard 2-dimensional Euclidean plane to doubling metrics. Finally, we explore
the utility of graph models in capturing wireless interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3460</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3460</id><created>2010-10-17</created><updated>2012-05-01</updated><authors><author><keyname>Zhang</keyname><forenames>Teng</forenames></author><author><keyname>Szlam</keyname><forenames>Arthur</forenames></author><author><keyname>Wang</keyname><forenames>Yi</forenames></author><author><keyname>Lerman</keyname><forenames>Gilad</forenames></author></authors><title>Hybrid Linear Modeling via Local Best-fit Flats</title><categories>cs.CV stat.ML</categories><comments>This version adds some clarifications and numerical experiments as
  well as strengthens the previous theorem. For face experiments, we use here
  the Extended Yale Face Database B (cropped faces unlike previous version).
  This database points to a failure mode of our algorithms, but we suggest and
  successfully test a workaround</comments><journal-ref>International Journal of Computer Vision Volume 100, Issue 3
  (2012), Page 217-240</journal-ref><doi>10.1007/s11263-012-0535-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple and fast geometric method for modeling data by a union of
affine subspaces. The method begins by forming a collection of local best-fit
affine subspaces, i.e., subspaces approximating the data in local
neighborhoods. The correct sizes of the local neighborhoods are determined
automatically by the Jones' $\beta_2$ numbers (we prove under certain geometric
conditions that our method finds the optimal local neighborhoods). The
collection of subspaces is further processed by a greedy selection procedure or
a spectral method to generate the final model. We discuss applications to
tracking-based motion segmentation and clustering of faces under different
illuminating conditions. We give extensive experimental evidence demonstrating
the state of the art accuracy and speed of the suggested algorithms on these
problems and also on synthetic hybrid linear data as well as the MNIST
handwritten digits data; and we demonstrate how to use our algorithms for fast
determination of the number of affine subspaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3467</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3467</id><created>2010-10-17</created><authors><author><keyname>Kavukcuoglu</keyname><forenames>Koray</forenames></author><author><keyname>Ranzato</keyname><forenames>Marc'Aurelio</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Fast Inference in Sparse Coding Algorithms with Applications to Object
  Recognition</title><categories>cs.CV cs.LG</categories><report-no>CBLL-TR-2008-12-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adaptive sparse coding methods learn a possibly overcomplete set of basis
functions, such that natural image patches can be reconstructed by linearly
combining a small subset of these bases. The applicability of these methods to
visual object recognition tasks has been limited because of the prohibitive
cost of the optimization algorithms required to compute the sparse
representation. In this work we propose a simple and efficient algorithm to
learn basis functions. After training, this model also provides a fast and
smooth approximator to the optimal representation, achieving even better
accuracy than exact sparse coding algorithms on visual object recognition
tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3469</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3469</id><created>2010-10-17</created><updated>2010-10-19</updated><authors><author><keyname>Gong</keyname><forenames>Shuping</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert. C.</forenames></author></authors><title>Decoding the `Nature Encoded' Messages for Distributed Energy Generation
  Control in Microgrid</title><categories>cs.IT math.IT</categories><comments>It has been submitted to IEEE International Conference on
  Communications (ICC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The communication for the control of distributed energy generation (DEG) in
microgrid is discussed. Due to the requirement of realtime transmission, weak
or no explicit channel coding is used for the message of system state. To
protect the reliability of the uncoded or weakly encoded messages, the system
dynamics are considered as a `nature encoding' similar to convolution code, due
to its redundancy in time. For systems with or without explicit channel coding,
two decoding procedures based on Kalman filtering and Pearl's Belief
Propagation, in a similar manner to Turbo processing in traditional data
communication systems, are proposed. Numerical simulations have demonstrated
the validity of the schemes, using a linear model of electric generator dynamic
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3484</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3484</id><created>2010-10-18</created><authors><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>O'Donnell</keyname><forenames>Ryan</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author><author><keyname>Wu</keyname><forenames>Yi</forenames></author></authors><title>Hardness Results for Agnostically Learning Low-Degree Polynomial
  Threshold Functions</title><categories>cs.LG</categories><comments>full version of SODA'11 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hardness results for maximum agreement problems have close connections to
hardness results for proper learning in computational learning theory. In this
paper we prove two hardness results for the problem of finding a low degree
polynomial threshold function (PTF) which has the maximum possible agreement
with a given set of labeled examples in $\R^n \times \{-1,1\}.$ We prove that
for any constants $d\geq 1, \eps &gt; 0$,
  {itemize}
  Assuming the Unique Games Conjecture, no polynomial-time algorithm can find a
degree-$d$ PTF that is consistent with a $(\half + \eps)$ fraction of a given
set of labeled examples in $\R^n \times \{-1,1\}$, even if there exists a
degree-$d$ PTF that is consistent with a $1-\eps$ fraction of the examples.
  It is $\NP$-hard to find a degree-2 PTF that is consistent with a $(\half +
\eps)$ fraction of a given set of labeled examples in $\R^n \times \{-1,1\}$,
even if there exists a halfspace (degree-1 PTF) that is consistent with a $1 -
\eps$ fraction of the examples.
  {itemize}
  These results immediately imply the following hardness of learning results:
(i) Assuming the Unique Games Conjecture, there is no better-than-trivial
proper learning algorithm that agnostically learns degree-$d$ PTFs under
arbitrary distributions; (ii) There is no better-than-trivial learning
algorithm that outputs degree-2 PTFs and agnostically learns halfspaces (i.e.
degree-1 PTFs) under arbitrary distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3488</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3488</id><created>2010-10-18</created><updated>2010-12-08</updated><authors><author><keyname>Karra</keyname><forenames>Satish</forenames></author></authors><title>Diffusion of a fluid through a viscoelastic solid</title><categories>cs.CE math-ph math.MP physics.flu-dyn</categories><comments>26 pages, 7 figures, submitted to International Journal of Solids and
  Structures</comments><msc-class>74D10, 74F20</msc-class><journal-ref>Mechanics of Materials 66 (2013): 120-133</journal-ref><doi>10.1016/j.mechmat.2013.06.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the diffusion of a fluid through a viscoelastic
solid undergoing large deformations. Using ideas from the classical theory of
mixtures and a thermodynamic framework based on the notion of maximization of
the rate of entropy production, the constitutive relations for a mixture of a
viscoelastic solid and a fluid (specifically Newtonian fluid) are derived. By
prescribing forms for the specific Helmholtz potential and the rate of
dissipation, we derive the relations for the partial stress in the solid, the
partial stress in the fluid, the interaction force between the solid and the
fluid, and the evolution equation of the natural configuration of the solid. We
also use the assumption that the volume of the mixture is equal to the sum of
the volumes of the two constituents in their natural state as a constraint.
Results from the developed model are shown to be in good agreement with the
experimental data for the diffusion of various solvents through high
temperature polyimides that are used in the aircraft industry. The swelling of
a viscoelastic solid under the application of an external force is also
studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3519</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3519</id><created>2010-10-18</created><authors><author><keyname>Chen</keyname><forenames>Zichong</forenames></author><author><keyname>Barrenetxea</keyname><forenames>Guillermo</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Distributed Successive Approximation Coding using Broadcast Advantage:
  The Two-Encoder Case</title><categories>cs.IT math.IT</categories><comments>In Proceedings of the 48th Annual Allerton Conference on
  Communication, Control and Computing, University of Illinois, Monticello, IL,
  September 29 - October 1, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional distributed source coding rarely considers the possible link
between separate encoders. However, the broadcast nature of wireless
communication in sensor networks provides a free gossip mechanism which can be
used to simplify encoding/decoding and reduce transmission power. Using this
broadcast advantage, we present a new two-encoder scheme which imitates the
ping-pong game and has a successive approximation structure. For the quadratic
Gaussian case, we prove that this scheme is successively refinable on the
{sum-rate, distortion pair} surface, which is characterized by the
rate-distortion region of the distributed two-encoder source coding. A
potential energy saving over conventional distributed coding is also
illustrated. This ping-pong distributed coding idea can be extended to the
multiple encoder case and provides the theoretical foundation for a new class
of distributed image coding method in wireless scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3525</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3525</id><created>2010-10-18</created><authors><author><keyname>Scharnhorst</keyname><forenames>Andrea</forenames></author><author><keyname>Garfield</keyname><forenames>Eugene</forenames></author></authors><title>Tracing scientific influence</title><categories>physics.soc-ph cs.DL</categories><comments>25 pages LaTex</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scientometrics is the field of quantitative studies of scholarly activity. It
has been used for systematic studies of the fundamentals of scholarly practice
as well as for evaluation purposes. Although advocated from the very beginning
the use of scientometrics as an additional method for science history is still
under explored. In this paper we show how a scientometric analysis can be used
to shed light on the reception history of certain outstanding scholars. As a
case, we look into citation patterns of a specific paper by the American
sociologist Robert K. Merton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3541</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3541</id><created>2010-10-18</created><authors><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Xie</keyname><forenames>Xiao-Yi</forenames></author><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>Heterogenous scaling in interevent time of on-line bookmarking</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.physa.2011.02.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the statistical properties of bookmarking behaviors
in Delicious.com. We find that the interevent time distributions of bookmarking
decays powerlike as interevent time increases at both individual and population
level. Remarkably, we observe a significant change in the exponent when
interevent time increases from intra-day to inter-day range. In addition,
dependence of exponent on individual Activity is found to be different in the
two ranges. These results suggests that mechanisms driving human actions are
different in intra- and inter-day range. Instead of monotonically increasing
with Activity, we find that inter-day exponent peaks at value around 3. We
further show that less active users are more likely to resemble poisson process
in bookmarking. Based on the temporal-preference model, preliminary
explanations for this dependence have been given . Finally, a universal
behavior in inter-day scale is observed by considering the rescaled variable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3547</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3547</id><created>2010-10-18</created><updated>2011-04-28</updated><authors><author><keyname>Vilone</keyname><forenames>Daniele</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Angel</forenames></author><author><keyname>G&#xf3;mez-Garde&#xf1;es</keyname><forenames>Jes&#xfa;s</forenames></author></authors><title>Random Topologies and the emergence of cooperation: the role of
  short-cuts</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Journal of Statistical Mechanics: Theory and Experiment, P04019
  (2011)</journal-ref><doi>10.1088/1742-5468/2011/04/P04019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study in detail the role of short-cuts in promoting the emergence of
cooperation in a network of agents playing the Prisoner's Dilemma Game (PDG).
We introduce a model whose topology interpolates between the one-dimensional
euclidean lattice (a ring) and the complete graph by changing the value of one
parameter (the probability p to add a link between two nodes not already
connected in the euclidean configuration). We show that there is a region of
values of p in which cooperation is largely enhanced, whilst for smaller values
of p only a few cooperators are present in the final state, and for p
\rightarrow 1- cooperation is totally suppressed. We present analytical
arguments that provide a very plausible interpretation of the simulation
results, thus unveiling the mechanism by which short-cuts contribute to promote
(or suppress) cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3548</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3548</id><created>2010-10-18</created><updated>2011-08-25</updated><authors><author><keyname>Alpay</keyname><forenames>Daniel</forenames></author><author><keyname>Lewkowicz</keyname><forenames>Izchak</forenames></author></authors><title>The positive real lemma and construction of all realizations of
  generalized positive rational functions</title><categories>math.OC cs.SY math.CV</categories><msc-class>15B48, 26C15, 47L07, 93B15, 15A45, 93B52, 93D10, 94C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We here extend the well known Positive Real Lemma (also known as the
Kalman-Yakubovich-Popov Lemma) to complex matrix-valued generalized positive
rational function, when non-minimal realizations are considered. We then
exploit this result to provide an easy construction procedure of all (not
necessarily minimal) state space realizations of generalized positive
functions. As a by-product, we partition all state space realizations into
subsets: Each is identified with a set of matrices satisfying the same Lyapunov
inclusion and thus form a convex invertible cone, cic in short. Moreover, this
approach enables us to characterize systems which may be brought to be
generalized positive through static output feedback. The formulation through
Lyapunov inclusions suggests the introduction of an equivalence class of
rational functions of various dimensions associated with the same system
matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3601</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3601</id><created>2010-10-18</created><updated>2010-10-19</updated><authors><author><keyname>Liva</keyname><forenames>Gianluigi</forenames></author><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>High-Throughput Random Access via Codes on Graphs</title><categories>cs.IT math.IT</categories><comments>Presented at the Future Network and MobileSummit 2010 Conference,
  Florence (Italy), June 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, contention resolution diversity slotted ALOHA (CRDSA) has been
introduced as a simple but effective improvement to slotted ALOHA. It relies on
MAC burst repetitions and on interference cancellation to increase the
normalized throughput of a classic slotted ALOHA access scheme. CRDSA allows
achieving a larger throughput than slotted ALOHA, at the price of an increased
average transmitted power. A way to trade-off the increment of the average
transmitted power and the improvement of the throughput is presented in this
paper. Specifically, it is proposed to divide each MAC burst in k sub-bursts,
and to encode them via a (n,k) erasure correcting code. The n encoded
sub-bursts are transmitted over the MAC channel, according to specific
time/frequency-hopping patterns. Whenever n-e&gt;=k sub-bursts (of the same burst)
are received without collisions, erasure decoding allows recovering the
remaining e sub-bursts (which were lost due to collisions). An interference
cancellation process can then take place, removing in e slots the interference
caused by the e recovered sub-bursts, possibly allowing the correct decoding of
sub-bursts related to other bursts. The process is thus iterated as for the
CRDSA case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3605</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3605</id><created>2010-10-18</created><updated>2010-11-26</updated><authors><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Theran</keyname><forenames>Louis</forenames></author></authors><title>The rigidity transition in random graphs</title><categories>math.CO cond-mat.dis-nn cond-mat.stat-mech cs.CG cs.DS</categories><comments>To appear in SODA'11. Added proofs omitted from the proceedings
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we add rigid bars between points in the plane, at what point is there a
giant (linear-sized) rigid component, which can be rotated and translated, but
which has no internal flexibility? If the points are generic, this depends only
on the combinatorics of the graph formed by the bars. We show that if this
graph is an Erdos-Renyi random graph G(n,c/n), then there exists a sharp
threshold for a giant rigid component to emerge. For c &lt; c_2, w.h.p. all rigid
components span one, two, or three vertices, and when c &gt; c_2, w.h.p. there is
a giant rigid component. The constant c_2 \approx 3.588 is the threshold for
2-orientability, discovered independently by Fernholz and Ramachandran and
Cain, Sanders, and Wormald in SODA'07. We also give quantitative bounds on the
size of the giant rigid component when it emerges, proving that it spans a
(1-o(1))-fraction of the vertices in the (3+2)-core. Informally, the (3+2)-core
is maximal induced subgraph obtained by starting from the 3-core and then
inductively adding vertices with 2 neighbors in the graph obtained so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3613</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3613</id><created>2010-10-18</created><authors><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Ge</forenames></author><author><keyname>Chen</keyname><forenames>Biao</forenames></author></authors><title>The Common Information of N Dependent Random Variables</title><categories>cs.IT math.IT</categories><comments>8 pages, 4 figures,presented at the Forty-Eighth Annual Allerton
  Conference on Communication, Control, and Computing, September 29 - October
  1, 2010, Monticello, IL, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper generalizes Wyner's definition of common information of a pair of
random variables to that of $N$ random variables. We prove coding theorems that
show the same operational meanings for the common information of two random
variables generalize to that of $N$ random variables. As a byproduct of our
proof, we show that the Gray-Wyner source coding network can be generalized to
$N$ source squences with $N$ decoders. We also establish a monotone property of
Wyner's common information which is in contrast to other notions of the common
information, specifically Shannon's mutual information and G\'{a}cs and
K\&quot;{o}rner's common randomness. Examples about the computation of Wyner's
common information of $N$ random variables are also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3615</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3615</id><created>2010-10-18</created><authors><author><keyname>Martin</keyname><forenames>St&#xe9;phane</forenames><affiliation>LIF</affiliation></author><author><keyname>Urso</keyname><forenames>Pascal</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Weiss</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>Scalable XML Collaborative Editing with Undo short paper</title><categories>cs.DB</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commutative Replicated Data-Type (CRDT) is a new class of algorithms that
ensures scalable consistency of replicated data. It has been successfully
applied to collaborative editing of texts without complex concurrency control.
In this paper, we present a CRDT to edit XML data. Compared to existing
approaches for XML collaborative editing, our approach is more scalable and
handles all the XML editing aspects : elements, contents, attributes and undo.
Indeed, undo is recognized as an important feature for collaborative editing
that allows to overcome system complexity through error recovery or
collaborative conflict resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3619</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3619</id><created>2010-10-15</created><authors><author><keyname>Ghosh</keyname><forenames>Souvik</forenames></author><author><keyname>Ghosh</keyname><forenames>Soumyadip</forenames></author></authors><title>A strong law for the rate of growth of long latency periods in cloud
  computing service</title><categories>cs.DC math.PR math.ST stat.TH</categories><comments>22 pages</comments><msc-class>60F10 (Primary), 60F15 (Secondary), 60G99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud-computing shares a common pool of resources across customers at a scale
that is orders of magnitude larger than traditional multi-user systems.
Constituent physical compute servers are allocated multiple &quot;virtual machines&quot;
(VM) to serve simultaneously. Each VM user should ideally be unaffected by
others' demand. Naturally, this environment produces new challenges for the
service providers in meeting customer expectations while extracting an
efficient utilization from server resources. We study a new cloud service
metric that measures prolonged latency or delay suffered by customers. We model
the workload process of a cloud server and analyze the process as the customer
population grows. The capacity required to ensure that average workload does
not exceed a threshold over long segments is characterized. This can be used by
cloud operators to provide service guarantees on avoiding long durations of
latency. As part of the analysis, we provide a uniform large-deviation
principle for collections of random variables that is of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3633</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3633</id><created>2010-10-18</created><updated>2013-09-03</updated><authors><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>Razgon</keyname><forenames>Igor</forenames></author></authors><title>Fixed-parameter tractability of multicut parameterized by the size of
  the cutset</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an undirected graph $G$, a collection $\{(s_1,t_1),..., (s_k,t_k)\}$ of
pairs of vertices, and an integer $p$, the Edge Multicut problem ask if there
is a set $S$ of at most $p$ edges such that the removal of $S$ disconnects
every $s_i$ from the corresponding $t_i$. Vertex Multicut is the analogous
problem where $S$ is a set of at most $p$ vertices. Our main result is that
both problems can be solved in time $2^{O(p^3)}... n^{O(1)}$, i.e.,
fixed-parameter tractable parameterized by the size $p$ of the cutset in the
solution. By contrast, it is unlikely that an algorithm with running time of
the form $f(p)... n^{O(1)}$ exists for the directed version of the problem, as
we show it to be W[1]-hard parameterized by the size of the cutset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3640</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3640</id><created>2010-10-18</created><updated>2011-03-09</updated><authors><author><keyname>Kopecki</keyname><forenames>Steffen</forenames></author></authors><title>On the Iterated Hairpin Completion</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The (bounded) hairpin completion and its iterated versions are operations on
formal lan- guages which have been inspired by the hairpin formation in
DNA-biochemistry. The paper answers two questions asked in the literature about
the iterated hairpin completion.
  The first question is whether the class of regular languages is closed under
iterated bounded hairpin completion. Here we show that this is true by
providing a more general result which applies to all the classes of languages
which are closed under finite union, intersection with regular sets, and
concatenation with regular sets. In particular, all Chomsky classes and all
standard complexity classes are closed under iterated bounded hairpin
completion.
  In the second part of the paper we address the question whether the iterated
hairpin completion of a singleton is always regular. In contrast to the first
question, this one has a negative answer. We exhibit an example of a singleton
language whose iterated hairpin completion is not regular, actually it is not
context-free, but context-sensitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3674</identifier>
 <datestamp>2013-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3674</id><created>2010-10-18</created><updated>2013-03-12</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Ponse</keyname><forenames>A.</forenames></author><author><keyname>Staudt</keyname><forenames>D. J. C.</forenames></author></authors><title>Short-circuit logic</title><categories>cs.LO math.LO</categories><comments>59 pages, 7 tables, 3 figures; Daan Staudt is added as an extra
  author; normal forms for FSCL are defined and completeness of its
  axiomatization is proved</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short-circuit evaluation denotes the semantics of propositional connectives
in which the second argument is evaluated only if the first argument does not
suffice to determine the value of the expression. In programming, short-circuit
evaluation is widely used, with sequential conjunction and disjunction as
primitive connectives.
  A short-circuit logic is a variant of propositional logic (PL) that can be
defined with help of Hoare's conditional, a ternary connective comparable to
if-then-else, and that implies all identities that follow from four basic
axioms for the conditional and can be expressed in PL (e.g., axioms for
associativity of conjunction and double negation shift). In the absence of side
effects, short-circuit evaluation characterizes PL. However, short-circuit
evaluation admits the possibility to model side effects and gives rise to
various different short-circuit logics. The first extreme case is FSCL (free
short-circuit logic), which characterizes the setting in which evaluation of
each atom (propositional variable) can yield a side effect. The other extreme
case is MSCL (memorizing short-circuit logic), the most identifying variant we
distinguish below PL. In MSCL, only a very restricted type of side effects can
be modelled, while sequential conjunction is non-commutative. We provide
axiomatizations for FSCL and MSCL.
  Extending MSCL with one simple axiom yields SSCL (static short-circuit logic,
or sequential PL), for which we also provide a completeness result. We briefly
discuss two variants in between FSCL and MSCL, among which a logic that admits
contraction of atoms and of their negations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3685</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3685</id><created>2010-10-18</created><authors><author><keyname>Blondel</keyname><forenames>Vincent</forenames><affiliation>INMA</affiliation></author><author><keyname>Gaubert</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Saclay - Ile de France, CMAP</affiliation></author><author><keyname>Portier</keyname><forenames>Natacha</forenames><affiliation>LIP</affiliation></author></authors><title>The set of realizations of a max-plus linear sequence is semi-polyhedral</title><categories>cs.DS</categories><proxy>ccsd</proxy><report-no>Research Report RRLIP 2010-33</report-no><journal-ref>Journal of Computer and System Sciences, Volume 77, Issue 4, July
  2011, Pages 820-833</journal-ref><doi>10.1016/j.jcss.2010.08.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the set of realizations of a given dimension of a max-plus
linear sequence is a finite union of polyhedral sets, which can be computed
from any realization of the sequence. This yields an (expensive) algorithm to
solve the max-plus minimal realization problem. These results are derived from
general facts on rational expressions over idempotent commutative semirings: we
show more generally that the set of values of the coefficients of a commutative
rational expression in one letter that yield a given max-plus linear sequence
is a semi-algebraic set in the max-plus sense. In particular, it is a finite
union of polyhedral sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3726</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3726</id><created>2010-10-18</created><authors><author><keyname>Chia</keyname><forenames>Yeow Khiang</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Cascade, Triangular and Two Way Source Coding with degraded side
  information at the second user</title><categories>cs.IT math.IT</categories><comments>29 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Cascade and Triangular rate-distortion problems where the
same side information is available at the source node and User 1, and the side
information available at User 2 is a degraded version of the side information
at the source node and User 1. We characterize the rate-distortion region for
these problems. For the Cascade setup, we showed that, at User 1, decoding and
re-binning the codeword sent by the source node for User 2 is optimum. We then
extend our results to the Two way Cascade and Triangular setting, where the
source node is interested in lossy reconstruction of the side information at
User 2 via a rate limited link from User 2 to the source node. We characterize
the rate distortion regions for these settings. Complete explicit
characterizations for all settings are also given in the Quadratic Gaussian
case. We conclude with two further extensions: A triangular source coding
problem with a helper, and an extension of our Two Way Cascade setting in the
Quadratic Gaussian case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3757</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3757</id><created>2010-10-18</created><authors><author><keyname>Macon</keyname><forenames>Kevin T.</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author></authors><title>Community Structure in the United Nations General Assembly</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>9 pages plus 11 tables and 6 multi-part figures; Also available from
  http://www.amath.unc.edu/Faculty/mucha/Reprints/PhysA_UN.pdf, containing
  high-res map representations of the tables not in original submission.</comments><journal-ref>Physica A 391, 343-361 (2012)</journal-ref><doi>10.1016/j.physa.2011.06.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the community structure of networks representing voting on
resolutions in the United Nations General Assembly. We construct networks from
the voting records of the separate annual sessions between 1946 and 2008 in
three different ways: (1) by considering voting similarities as weighted
unipartite networks; (2) by considering voting similarities as weighted, signed
unipartite networks; and (3) by examining signed bipartite networks in which
countries are connected to resolutions. For each formulation, we detect
communities by optimizing network modularity using an appropriate null model.
We compare and contrast the results that we obtain for these three different
network representations. In so doing, we illustrate the need to consider
multiple resolution parameters and explore the effectiveness of each network
representation for identifying voting groups amidst the large amount of
agreement typical in General Assembly votes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3783</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3783</id><created>2010-10-18</created><authors><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author></authors><title>Unifying the Landscape of Cell-Probe Lower Bounds</title><categories>cs.DS cs.CC cs.CG</categories><comments>To appear in SIAM Journal on Computing (SICOMP). The conference
  version appeared in FOCS'08 under the title &quot;(Data) Structures&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a large fraction of the data-structure lower bounds known today
in fact follow by reduction from the communication complexity of lopsided
(asymmetric) set disjointness. This includes lower bounds for:
  * high-dimensional problems, where the goal is to show large space lower
bounds.
  * constant-dimensional geometric problems, where the goal is to bound the
query time for space O(n polylog n).
  * dynamic problems, where we are looking for a trade-off between query and
update time. (In this case, our bounds are slightly weaker than the originals,
losing a lglg n factor.)
  Our reductions also imply the following new results:
  * an Omega(lg n / lglg n) bound for 4-dimensional range reporting, given
space O(n polylog n). This is quite timely, since a recent result solved 3D
reporting in O(lglg n) time, raising the prospect that higher dimensions could
also be easy.
  * a tight space lower bound for the partial match problem, for constant query
time.
  * the first lower bound for reachability oracles.
  In the process, we prove optimal randomized lower bounds for lopsided set
disjointness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3796</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3796</id><created>2010-10-19</created><authors><author><keyname>Brescia</keyname><forenames>M.</forenames></author><author><keyname>Longo</keyname><forenames>G.</forenames></author><author><keyname>Pasian</keyname><forenames>F.</forenames></author></authors><title>Mining Knowledge in Astrophysical Massive Data Sets</title><categories>astro-ph.IM cs.AI</categories><comments>Pages 845-849 1rs International Conference on Frontiers in
  Diagnostics Technologies</comments><journal-ref>Elsevier, Nuclear Instruments and Methods in Physics Research
  Section A: Accelerators, Spectrometers, Detectors and Associated Equipment
  Volume 623, Issue 2, 11 November 2010</journal-ref><doi>10.1016/j.nima.2010.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern scientific data mainly consist of huge datasets gathered by a very
large number of techniques and stored in very diversified and often
incompatible data repositories. More in general, in the e-science environment,
it is considered as a critical and urgent requirement to integrate services
across distributed, heterogeneous, dynamic &quot;virtual organizations&quot; formed by
different resources within a single enterprise. In the last decade, Astronomy
has become an immensely data rich field due to the evolution of detectors
(plates to digital to mosaics), telescopes and space instruments. The Virtual
Observatory approach consists into the federation under common standards of all
astronomical archives available worldwide, as well as data analysis, data
mining and data exploration applications. The main drive behind such effort
being that once the infrastructure will be completed, it will allow a new type
of multi-wavelength, multi-epoch science which can only be barely imagined.
Data Mining, or Knowledge Discovery in Databases, while being the main
methodology to extract the scientific information contained in such MDS
(Massive Data Sets), poses crucial problems since it has to orchestrate complex
problems posed by transparent access to different computing environments,
scalability of algorithms, reusability of resources, etc. In the present paper
we summarize the present status of the MDS in the Virtual Observatory and what
is currently done and planned to bring advanced Data Mining methodologies in
the case of the DAME (DAta Mining &amp; Exploration) project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3806</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3806</id><created>2010-10-19</created><updated>2010-12-27</updated><authors><author><keyname>Tsukada</keyname><forenames>Takeshi</forenames><affiliation>Tohoku University</affiliation></author><author><keyname>Igarashi</keyname><forenames>Atsushi</forenames><affiliation>Kyoto University</affiliation></author></authors><title>A Logical Foundation for Environment Classifiers</title><categories>cs.PL</categories><proxy>LMCS</proxy><acm-class>D.3.3, F.3.3, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  18, 2010) lmcs:1065</journal-ref><doi>10.2168/LMCS-6(4:8)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Taha and Nielsen have developed a multi-stage calculus {\lambda}{\alpha} with
a sound type system using the notion of environment classifiers. They are
special identifiers, with which code fragments and variable declarations are
annotated, and their scoping mechanism is used to ensure statically that
certain code fragments are closed and safely runnable. In this paper, we
investigate the Curry-Howard isomorphism for environment classifiers by
developing a typed {\lambda}-calculus {\lambda}|&gt;. It corresponds to
multi-modal logic that allows quantification by transition variables---a
counterpart of classifiers---which range over (possibly empty) sequences of
labeled transitions between possible worlds. This interpretation will reduce
the &quot;run&quot; construct---which has a special typing rule in
{\lambda}{\alpha}---and embedding of closed code into other code fragments of
different stages---which would be only realized by the cross-stage persistence
operator in {\lambda}{\alpha}---to merely a special case of classifier
application. {\lambda}|&gt; enjoys not only basic properties including subject
reduction, confluence, and strong normalization but also an important property
as a multi-stage calculus: time-ordered normalization of full reduction. Then,
we develop a big-step evaluation semantics for an ML-like language based on
{\lambda}|&gt; with its type system and prove that the evaluation of a well-typed
{\lambda}|&gt; program is properly staged. We also identify a fragment of the
language, where erasure evaluation is possible. Finally, we show that the proof
system augmented with a classical axiom is sound and complete with respect to a
Kripke semantics of the logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3810</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3810</id><created>2010-10-19</created><authors><author><keyname>Yu</keyname><forenames>Hao</forenames></author><author><keyname>Zhang</keyname><forenames>Shunqing</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Game Theoretical Power Control for Open-Loop Overlaid Network MIMO
  Systems with Partial Cooperation</title><categories>cs.IT cs.GT math.IT</categories><comments>18pages, 7 figures, IEEE Transactions on Wireless Communication,
  accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network MIMO is considered to be a key solution for the next generation
wireless systems in breaking the interference bottleneck in cellular systems.
In the MIMO systems, open-loop transmission scheme is used to support mobile
stations (MSs) with high mobilities because the base stations (BSs) do not need
to track the fast varying channel fading. In this paper, we consider an
open-loop network MIMO system with $K$ BSs serving K private MSs and $M^c$
common MS based on a novel partial cooperation overlaying scheme. Exploiting
the heterogeneous path gains between the private MSs and the common MSs, each
of the $K$ BSs serves a private MS non-cooperatively and the $K$ BSs also serve
the $M^c$ common MSs cooperatively. The proposed scheme does not require closed
loop instantaneous channel state information feedback, which is highly
desirable for high mobility users. Furthermore, we formulate the long-term
distributive power allocation problem between the private MSs and the common
MSs at each of the $K$ BSs using a partial cooperative game. We show that the
long-term power allocation game has a unique Nash Equilibrium (NE) but standard
best response update may not always converge to the NE. As a result, we propose
a low-complexity distributive long-term power allocation algorithm which only
relies on the local long-term channel statistics and has provable convergence
property. Through numerical simulations, we show that the proposed open-loop
SDMA scheme with long-term distributive power allocation can achieve
significant performance advantages over the other reference baseline schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3812</identifier>
 <datestamp>2012-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3812</id><created>2010-10-19</created><updated>2010-10-20</updated><authors><author><keyname>Dhesi</keyname><forenames>Aman</forenames></author><author><keyname>Kar</keyname><forenames>Purushottam</forenames></author></authors><title>Random Projection Trees Revisited</title><categories>cs.DS cs.CG math.DG stat.ML</categories><comments>Accepted for publication at NIPS 2010. This version corrects an
  incorrect usage of the term Assouad dimension - acknowledgments : James Lee</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Random Projection Tree structures proposed in [Freund-Dasgupta STOC08]
are space partitioning data structures that automatically adapt to various
notions of intrinsic dimensionality of data. We prove new results for both the
RPTreeMax and the RPTreeMean data structures. Our result for RPTreeMax gives a
near-optimal bound on the number of levels required by this data structure to
reduce the size of its cells by a factor $s \geq 2$. We also prove a packing
lemma for this data structure. Our final result shows that low-dimensional
manifolds have bounded Local Covariance Dimension. As a consequence we show
that RPTreeMean adapts to manifold dimension as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3815</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3815</id><created>2010-10-19</created><updated>2010-10-22</updated><authors><author><keyname>Gao</keyname><forenames>Lei</forenames></author><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author><author><keyname>Fan</keyname><forenames>Chao</forenames></author><author><keyname>Liu</keyname><forenames>Xue-Jiao</forenames></author></authors><title>Individual and Group Dynamics in Purchasing Activity</title><categories>physics.soc-ph cs.CE</categories><journal-ref>Physica A 392 (2013) 343-349</journal-ref><doi>10.1016/j.physa.2012.07.047</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  As a major part of the daily operation in an enterprise, purchasing frequency
is of constant change. Recent approaches on the human dynamics can provide some
new insights into the economic behaviors of companies in the supply chain. This
paper captures the attributes of creation times of purchase orders to an
individual vendor, as well as to all vendors, and further investigates whether
they have some kind of dynamics by applying logarithmic binning to the
construction of distribution plot. It's found that the former displays a
power-law distribution with approximate exponent 2.0, while the latter is
fitted by a mixture distribution with both power-law and exponential
characteristics. Obviously, two distinctive characteristics are presented for
the interval time distribution from the perspective of individual dynamics and
group dynamics. Actually, this mixing feature can be attributed to the fitting
deviations as they are negligible for individual dynamics, but those of
different vendors are cumulated and then lead to an exponential factor for
group dynamics. To better describe the mechanism generating the heterogeneity
of purchase order assignment process from the objective company to all its
vendors, a model driven by product life cycle is introduced, and then the
analytical distribution and the simulation result are obtained, which are in
good line with the empirical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3816</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3816</id><created>2010-10-19</created><updated>2011-10-03</updated><authors><author><keyname>Choudhary</keyname><forenames>Niket K.</forenames></author><author><keyname>Ginjupalli</keyname><forenames>Rakesh</forenames></author><author><keyname>Navada</keyname><forenames>Sandeep</forenames></author><author><keyname>Khanna</keyname><forenames>Gaurav</forenames></author></authors><title>An Exploration of OpenCL for a Numerical Relativity Application</title><categories>gr-qc cs.DC physics.comp-ph</categories><comments>6 pages, 1 table; Accepted for publication in Parallel and
  Distributed Computing and Systems (PDCS 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently there is considerable interest in making use of many-core processor
architectures, such as Nvidia and AMD graphics processing units (GPUs) for
scientific computing. In this work we explore the use of the Open Computing
Language (OpenCL) for a typical Numerical Relativity application: a time-domain
Teukolsky equation solver (a linear, hyperbolic, partial differential equation
solver using finite-differencing). OpenCL is the only vendor-agnostic and
multi-platform parallel computing framework that has been adopted by all major
processor vendors. Therefore, it allows us to write portable source-code and
run it on a wide variety of compute hardware and perform meaningful
comparisons. The outcome of our experimentation suggests that it is relatively
straightforward to obtain order-of-magnitude gains in overall application
performance by making use of many-core GPUs over multi-core CPUs and this fact
is largely independent of the specific hardware architecture and vendor. We
also observe that a single high-end GPU can match the performance of a
small-sized, message-passing based CPU cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3862</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3862</id><created>2010-10-19</created><authors><author><keyname>Krishna</keyname><forenames>A. V. N.</forenames><affiliation>Indur Institute of Engg. &amp; Tech., India</affiliation></author><author><keyname>Babu</keyname><forenames>A. Vinaya</forenames><affiliation>J.N.T.U.H, Hyderabad</affiliation></author></authors><title>A New Non Linear, Time Stamped &amp; Feed Back Model Based Encryption
  Mechanism with Acknowledgement Support</title><categories>cs.CR</categories><comments>6 pages</comments><journal-ref>IJoAT Vol 1, No 2 (October 2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a model is going to be used which develops data distributed over
a identified value which is used as nonce (IV). The model considers an
equilibrium equation which is a function of non linear relationships, time
variant and nonce variant values and takes the feed back of earlier round as
input to the present round. The process is repeated for different timings which
are used as time stamps in the encryption mechanism. Thus this model generates
a distributed sequence which is used as sub key. This model supports very
important parameters in symmetric data encryption schemes like non linear
relationships between different values used in the model, variable key length,
timeliness of encryption mechanism and also acknowledgement between the
participating parties. It also supports feed back mode which provides necessary
strength against crypto analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3867</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3867</id><created>2010-10-19</created><authors><author><keyname>Bargeton</keyname><forenames>Alexandre</forenames><affiliation>CAOR</affiliation></author><author><keyname>Moutarde</keyname><forenames>Fabien</forenames><affiliation>CAOR</affiliation></author><author><keyname>Nashashibi</keyname><forenames>Fawzi</forenames><affiliation>CAOR</affiliation></author><author><keyname>Puthon</keyname><forenames>Anne-Sophie</forenames><affiliation>CAOR</affiliation></author></authors><title>Joint interpretation of on-board vision and static GPS cartography for
  determination of correct speed limit</title><categories>cs.CV</categories><proxy>ccsd</proxy><journal-ref>17th ITS world congress (ITSwc'2010), Busan : Korea, Republic Of
  (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here a first prototype of a &quot;Speed Limit Support&quot; Advance Driving
Assistance System (ADAS) producing permanent reliable information on the
current speed limit applicable to the vehicle. Such a module can be used either
for information of the driver, or could even serve for automatic setting of the
maximum speed of a smart Adaptive Cruise Control (ACC). Our system is based on
a joint interpretation of cartographic information (for static reference
information) with on-board vision, used for traffic sign detection and
recognition (including supplementary sub-signs) and visual road lines
localization (for detection of lane changes). The visual traffic sign detection
part is quite robust (90% global correct detection and recognition for main
speed signs, and 80% for exit-lane sub-signs detection). Our approach for joint
interpretation with cartography is original, and logic-based rather than
probability-based, which allows correct behaviour even in cases, which do
happen, when both vision and cartography may provide the same erroneous
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3880</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3880</id><created>2010-10-19</created><authors><author><keyname>Bianzino</keyname><forenames>Aruna Prem</forenames></author><author><keyname>Chaudet</keyname><forenames>Claude</forenames></author><author><keyname>Rossi</keyname><forenames>Dario</forenames></author><author><keyname>Rougier</keyname><forenames>Jean-Louis</forenames></author></authors><title>A Survey of Green Networking Research</title><categories>cs.NI</categories><comments>Index Terms: Green Networking; Wired Networks; Adaptive Link Rate;
  Interface Proxying; Energy-aware Infrastructures; Energy-aware Applications.
  18 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reduction of unnecessary energy consumption is becoming a major concern in
wired networking, because of the potential economical benefits and of its
expected environmental impact. These issues, usually referred to as &quot;green
networking&quot;, relate to embedding energy-awareness in the design, in the devices
and in the protocols of networks. In this work, we first formulate a more
precise definition of the &quot;green&quot; attribute. We furthermore identify a few
paradigms that are the key enablers of energy-aware networking research. We
then overview the current state of the art and provide a taxonomy of the
relevant work, with a special focus on wired networking. At a high level, we
identify four branches of green networking research that stem from different
observations on the root causes of energy waste, namely (i) Adaptive Link Rate,
(ii) Interface proxying, (iii) Energy-aware infrastructures and (iv)
Energy-aware applications. In this work, we do not only explore specific
proposals pertaining to each of the above branches, but also offer a
perspective for research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3898</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3898</id><created>2010-10-19</created><updated>2010-12-29</updated><authors><author><keyname>Devarakonda</keyname><forenames>Ranjeet</forenames></author><author><keyname>Palanisamy</keyname><forenames>Giri</forenames></author><author><keyname>Wilson</keyname><forenames>Bruce</forenames></author></authors><title>Advancements in scientific data searching, sharing and retrieval</title><categories>cs.IR</categories><comments>This paper has been withdrawn by the authors. Planning to submit a
  journal paper</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The Open Archive Initiative Protocol for Metadata Handling (OAI-PMHiii) is a
standard that is seeing increased use as a means for exchanging structured
metadata. OAI-PMH implementations must support Dublin Core as a metadata
standard, with other metadata formats as optional. We have developed tools
which enable Mercury to consume metadata from OAI-PMH services in any of the
metadata formats we support (Dublin Core, Darwin Core, FCDC CSDGM, GCMD DIF,
EML, and ISO 19115/19137). We are also making ORNL DAAC metadata available
through OAI-PMH for other metadata tools to utilize. This paper describes
Mercury capabilities with multiple metadata formats, in general, and, more
specifically, the results of our OAI-PMH implementations and the lessons
learned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3909</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3909</id><created>2010-10-19</created><authors><author><keyname>Chelouah</keyname><forenames>Abdelkader</forenames></author></authors><title>Diffieties and Liouvillian Systems</title><categories>cs.SY</categories><comments>submitted</comments><msc-class>93B17, 93B27, 93C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Liouvillian systems were initially introduced within the framework of
differential algebra. They can be seen as a natural extension of differential
flat systems. Many physical non flat systems seem to be Liouvillian. We present
in this paper an alternative definition to this class of systems using the
language of diffieties and infinite prolongation theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3935</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3935</id><created>2010-10-19</created><authors><author><keyname>Aguiar</keyname><forenames>Pedro M. Q.</forenames></author><author><keyname>Guerreiro</keyname><forenames>Rui F. C.</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Bruno B.</forenames></author></authors><title>3-D Rigid Models from Partial Views - Global Factorization</title><categories>cs.CV</categories><comments>21 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The so-called factorization methods recover 3-D rigid structure from motion
by factorizing an observation matrix that collects 2-D projections of features.
These methods became popular due to their robustness - they use a large number
of views, which constrains adequately the solution - and computational
simplicity - the large number of unknowns is computed through an SVD, avoiding
non-linear optimization. However, they require that all the entries of the
observation matrix are known. This is unlikely to happen in practice, due to
self-occlusion and limited field of view. Also, when processing long videos,
regions that become occluded often appear again later. Current factorization
methods process these as new regions, leading to less accurate estimates of 3-D
structure. In this paper, we propose a global factorization method that infers
complete 3-D models directly from the 2-D projections in the entire set of
available video frames. Our method decides whether a region that has become
visible is a region that was seen before, or a previously unseen region, in a
global way, i.e., by seeking the simplest rigid object that describes well the
entire set of observations. This global approach increases significantly the
accuracy of the estimates of the 3-D shape of the scene and the 3-D motion of
the camera. Experiments with artificial and real videos illustrate the good
performance of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3941</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3941</id><created>2010-10-19</created><authors><author><keyname>Singh</keyname><forenames>Angad</forenames></author><author><keyname>Starobinski</keyname><forenames>David</forenames></author></authors><title>Exact Analysis of Rate Adaptation Algorithms in Wireless LANs</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rate adaptation plays a key role in determining the performance of wireless
LANs. In this paper, we introduce a semi-Markovian framework to analyze the
performance of two of the most popular rate adaptation algorithms used in
wireless LANs, namely Automatic Rate Fallback (ARF) and Adaptive Automatic Rate
Fallback (AARF). Given our modeling assumptions, the analysis is exact and
provides closed form expressions for the achievable throughput of ARF and AARF.
We illustrate the benefit of our analysis by numerically comparing the
throughput performance of ARF and AARF in two different channel regimes. The
results show that neither of these algorithms consistently outperforms the
other. We thus propose and analyze a new variant to AARF, called Persistent
AARF (or PAARF), and show that it achieves a good compromise between the two
algorithms, often performing close to the best algorithm in each of the studied
regimes. The numerical results also shed light into the impact of MAC overhead
on the performance of the three algorithms. In particular, they show that the
more conservative strategies AARF and PAARF scale better as the bit rate
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3947</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3947</id><created>2010-10-19</created><authors><author><keyname>Pires</keyname><forenames>Bernardo Esteves</forenames></author><author><keyname>Aguiar</keyname><forenames>Pedro M. Q.</forenames></author></authors><title>Maximum Likelihood Mosaics</title><categories>cs.CV</categories><comments>13 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The majority of the approaches to the automatic recovery of a panoramic image
from a set of partial views are suboptimal in the sense that the input images
are aligned, or registered, pair by pair, e.g., consecutive frames of a video
clip. These approaches lead to propagation errors that may be very severe,
particularly when dealing with videos that show the same region at disjoint
time intervals. Although some authors have proposed a post-processing step to
reduce the registration errors in these situations, there have not been
attempts to compute the optimal solution, i.e., the registrations leading to
the panorama that best matches the entire set of partial views}. This is our
goal. In this paper, we use a generative model for the partial views of the
panorama and develop an algorithm to compute in an efficient way the Maximum
Likelihood estimate of all the unknowns involved: the parameters describing the
alignment of all the images and the panorama itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3951</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3951</id><created>2010-10-19</created><authors><author><keyname>Lopes</keyname><forenames>Cristina Videira</forenames></author><author><keyname>Aguiar</keyname><forenames>Pedro M. Q.</forenames></author></authors><title>Alternatives to speech in low bit rate communication systems</title><categories>cs.MM cs.SD</categories><comments>4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a framework and a method with which speech communication
can be analyzed. The framework consists of a set of low bit rate, short-range
acoustic communication systems, such as speech, but that are quite different
from speech. The method is to systematically compare these systems according to
different objective functions such as data rate, computational overhead,
psychoacoustic effects and semantics. One goal of this study is to better
understand the nature of human communication. Another goal is to identify
acoustic communication systems that are more efficient than human speech for
some specific purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3956</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3956</id><created>2010-10-19</created><authors><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author><author><keyname>Djouadi</keyname><forenames>Seddik M.</forenames></author></authors><title>Combating False Reports for Secure Networked Control in Smart Grid via
  Trustiness Evaluation</title><categories>cs.CR cs.SY</categories><comments>It has been submitted to IEEE International Conference on
  Communications (ICC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart grid, equipped with modern communication infrastructures, is subject to
possible cyber attacks. Particularly, false report attacks which replace the
sensor reports with fraud ones may cause the instability of the whole power
grid or even result in a large area blackout. In this paper, a trustiness
system is introduced to the controller, who computes the trustiness of
different sensors by comparing its prediction, obtained from Kalman filtering,
on the system state with the reports from sensor. The trustiness mechanism is
discussed and analyzed for the Linear Quadratic Regulation (LQR) controller.
Numerical simulations show that the trustiness system can effectively combat
the cyber attacks to smart grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3976</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3976</id><created>2010-10-19</created><authors><author><keyname>Chuzhoy</keyname><forenames>Julia</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>On Graph Crossing Number and Edge Planarization</title><categories>cs.DS cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an n-vertex graph G, a drawing of G in the plane is a mapping of its
vertices into points of the plane, and its edges into continuous curves,
connecting the images of their endpoints. A crossing in such a drawing is a
point where two such curves intersect. In the Minimum Crossing Number problem,
the goal is to find a drawing of G with minimum number of crossings. The value
of the optimal solution, denoted by OPT, is called the graph's crossing number.
This is a very basic problem in topological graph theory, that has received a
significant amount of attention, but is still poorly understood
algorithmically. The best currently known efficient algorithm produces drawings
with $O(\log^2 n)(n + OPT)$ crossings on bounded-degree graphs, while only a
constant factor hardness of approximation is known. A closely related problem
is Minimum Edge Planarization, in which the goal is to remove a
minimum-cardinality subset of edges from G, such that the remaining graph is
planar. Our main technical result establishes the following connection between
the two problems: if we are given a solution of cost k to the Minimum Edge
Planarization problem on graph G, then we can efficiently find a drawing of G
with at most $\poly(d)\cdot k\cdot (k+OPT)$ crossings, where $d$ is the maximum
degree in G. This result implies an $O(n\cdot \poly(d)\cdot
\log^{3/2}n)$-approximation for Minimum Crossing Number, as well as improved
algorithms for special cases of the problem, such as, for example, k-apex and
bounded-genus graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3981</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3981</id><created>2010-10-19</created><authors><author><keyname>Behboodi</keyname><forenames>Arash</forenames></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author></authors><title>Broadcasting over the Relay Channel with Oblivious Cooperative Strategy</title><categories>cs.IT math.IT</categories><comments>6 pages, presented at Allerton 2010</comments><msc-class>94A15, 62B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of information transmission over the
simultaneous relay channel with two users (or two possible channel outcomes)
where for one of them the more suitable strategy is Decode-and-Forward (DF)
while for the other one is Compress-and-Forward (CF). In this setting, it is
assumed that the source wishes to send common and private informations to each
of the users (or channel outcomes). This problem is relevant to: (i) the
transmission of information over the broadcast relay channel (BRC) with
different relaying strategies and (ii) the transmission of information over the
conventional relay channel where the source is oblivious to the coding strategy
of relay. A novel coding that integrates simultaneously DF and CF schemes is
proposed and an inner bound on the capacity region is derived for the case of
general memoryless BRCs. As special case, the Gaussian BRC is studied where it
is shown that by means of the suggested broadcast coding the common rate can be
improved compared to existing strategies. Applications of these results arise
in broadcast scenarios with relays or in wireless scenarios where the source
does not know whether the relay is collocated with the source or with the
destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3983</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3983</id><created>2010-10-19</created><updated>2011-01-03</updated><authors><author><keyname>Devarakonda</keyname><forenames>Ranjeet</forenames></author><author><keyname>Palanisamy</keyname><forenames>Giri</forenames></author><author><keyname>Green</keyname><forenames>Jim</forenames></author></authors><title>Digitizing scientific data and data retrieval techniques</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Storing data is easy, but finding and using data is not. It is desirable that
the data is stored in a structured format, which can be preserved and retrieved
in future. Creating Metadata for the data is one way of creating structured
data formats. Metadata can provide Multidisciplinary data access and will
foster more robust scientific discoveries. In the recent years, there has been
significant advancement in the areas of scientific data management and
retrieval techniques, particularly in terms of standards and protocols for
archiving data and metadata. New search technologies are being implemented
around these protocols, which makes searching easy, fast and yet robust.
Scientific data is generally rich, not easy to understand, and spread across
different places. In order to integrate these pieces together, a data archive
and an associated metadata is generated. This data should be stored in a format
that can be locatable, retrievable and understandable, more importantly it
should be in a form that will continue to be accessible as technology changes,
such as XML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3988</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3988</id><created>2010-10-19</created><authors><author><keyname>Wu</keyname><forenames>Pei</forenames></author><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Liu</keyname><forenames>Weiping</forenames></author><author><keyname>Jin</keyname><forenames>Cihang</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Time-aware Collaborative Filtering with the Piecewise Decay Function</title><categories>cs.IR physics.soc-ph</categories><comments>4 pages. 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we determine the appropriate decay function for item-based
collaborative filtering (CF). Instead of intuitive deduction, we introduce the
Similarity-Signal-to-Noise-Ratio (SSNR) to quantify the impacts of rated items
on current recommendations. By measuring the variation of SSNR over time, drift
in user interest is well visualized and quantified. Based on the trend changes
of SSNR, the piecewise decay function is thus devised and incorporated to build
our time-aware CF algorithm. Experiments show that the proposed algorithm
strongly outperforms the conventional item-based CF algorithm and other
time-aware algorithms with various decay functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.3995</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.3995</id><created>2010-10-19</created><updated>2012-08-06</updated><authors><author><keyname>Ng</keyname><forenames>H. T.</forenames></author><author><keyname>Nori</keyname><forenames>Franco</forenames></author></authors><title>An iterative approach for amplitude amplification with nonorthogonal
  measurements</title><categories>quant-ph cs.DS math.NA</categories><comments>21 pages, 5 figures; title changed, major revisions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using three coupled harmonic oscillators, we present an
amplitude-amplification method for factorization of an integer. We generalize
the method in [arXiv:1007.4338] by employing non-orthogonal measurements on the
harmonic oscillator. This method can increase the probability of obtaining the
factors by repeatedly using the nonlinear interactions between the oscillators
and non-orthogonal measurements. However, this approach requires an exponential
amount of resources for implementation. Thus, this method cannot provide a
speed-up over classical algorithms unless its limitations are resolved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4007</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4007</id><created>2010-10-19</created><authors><author><keyname>Amirtharajan</keyname><forenames>R.</forenames></author><author><keyname>Behera</keyname><forenames>Sandeep Kumar</forenames></author><author><keyname>Swarup</keyname><forenames>Motamarri Abhilash</forenames></author><author><keyname>K</keyname><forenames>Mohamed Ashfaaq</forenames></author><author><keyname>Rayappan</keyname><forenames>John Bosco Balaguru</forenames></author></authors><title>Colour Guided Colour Image Steganography</title><categories>cs.MM</categories><comments>Universal Journal of Computer Science and Engineering Technology
  (UniCSE)</comments><journal-ref>1 (1), 16-23, Oct. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information security has become a cause of concern because of the electronic
eavesdropping. Capacity, robustness and invisibility are important parameters
in information hiding and are quite difficult to achieve in a single algorithm.
This paper proposes a novel steganography technique for digital color image
which achieves the purported targets. The professed methodology employs a
complete random scheme for pixel selection and embedding of data. Of the three
colour channels (Red, Green, Blue) in a given colour image, the least two
significant bits of any one of the channels of the color image is used to
channelize the embedding capacity of the remaining two channels. We have
devised three approaches to achieve various levels of our desired targets. In
the first approach, Red is the default guide but it results in localization of
MSE in the remaining two channels, which makes it slightly vulnerable. In the
second approach, user gets the liberty to select the guiding channel (Red,
Green or Blue) to guide the remaining two channels. It will increase the
robustness and imperceptibility of the embedded image however the MSE factor
will still remain as a drawback. The third approach improves the performance
factor as a cyclic methodology is employed and the guiding channel is selected
in a cyclic fashion. This ensures the uniform distribution of MSE, which gives
better robustness and imperceptibility along with enhanced embedding capacity.
The imperceptibility has been enhanced by suitably adapting optimal pixel
adjustment process (OPAP) on the stego covers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4009</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4009</id><created>2010-10-19</created><authors><author><keyname>Durand</keyname><forenames>Fabien</forenames><affiliation>LAMFA</affiliation></author></authors><title>Cobham's theorem for substitutions</title><categories>math.CO cs.DM math.DS</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The seminal theorem of Cobham has given rise during the last 40 years to a
lot of works around non-standard numeration systems and has been extended to
many contexts. In this paper, as a result of fifteen years of improvements, we
obtain a complete and general version for the so-called substitutive sequences.
Let $\alpha$ and $\beta$ be two multiplicatively independent Perron numbers.
Then, a sequence $x\in A^\mathbb{N}$, where $A$ is a finite alphabet, is both
$\alpha$-substitutive and $\beta$-substitutive if and only if $x$ is ultimately
periodic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4018</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4018</id><created>2010-10-19</created><authors><author><keyname>Kari</keyname><forenames>Chadi</forenames></author></authors><title>A Paradigm for Channel Assignment and Data Migration in Distributed
  Systems</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript, we consider the problems of channel assignment in
wireless networks and data migration in heterogeneous storage systems. We show
that a soft edge coloring approach to both problems gives rigorous
approximation guarantees. In the channel assignment problem arising in wireless
networks a pair of edges incident to a vertex are said to be conflicting if the
channels assigned to them are the same. Our goal is to assign channels (color
edges) so that the number of conflicts is minimized. The problem is NP-hard by
a reduction from Edge coloring and we present two combinatorial algorithms for
this case. The first algorithm is based on a distributed greedy method and
gives a solution with at most $2(1-\frac{1}{k})|E|$ more conflicts than the
optimal solution.The approximation ratio if the second algorithm is $1 +
\frac{|V|}{|E|}$, which gives a ($1 + o(1)$)-factor for dense graphs and is the
best possible unless P = NP. We also consider the data migration problem in
heterogeneous storage systems. In such systems, data layouts may need to be
reconfigured over time for load balancing or in the event of system
failure/upgrades. It is critical to migrate data to their target locations as
quickly as possible to obtain the best performance of the system. Most of the
previous results on data migration assume that each storage node can perform
only one data transfer at a time. However, storage devices tend to have
heterogeneous capabilities as devices may be added over time due to storage
demand increase. We develop algorithms to minimize the data migration time. We
show that it is possible to find an optimal migration schedule when all $c_v$'s
are even. Furthermore, though the problem is NP-hard in general, we give an
efficient soft edge coloring algorithm that offers a rigorous $(1 +
o(1))$-approximation guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4021</identifier>
 <datestamp>2010-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4021</id><created>2010-10-19</created><authors><author><keyname>Rodrigues</keyname><forenames>Jos&#xe9; J.</forenames></author><author><keyname>Xavier</keyname><forenames>Jo&#xe3;o M. F.</forenames></author><author><keyname>Aguiar</keyname><forenames>Pedro M. Q.</forenames></author></authors><title>ANSIG - An Analytic Signature for Arbitrary 2D Shapes (or Bags of
  Unlabeled Points)</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In image analysis, many tasks require representing two-dimensional (2D)
shape, often specified by a set of 2D points, for comparison purposes. The
challenge of the representation is that it must not only capture the
characteristics of the shape but also be invariant to relevant transformations.
Invariance to geometric transformations, such as translation, rotation, and
scale, has received attention in the past, usually under the assumption that
the points are previously labeled, i.e., that the shape is characterized by an
ordered set of landmarks. However, in many practical scenarios, the points
describing the shape are obtained from automatic processes, e.g., edge or
corner detection, thus without labels or natural ordering. Obviously, the
combinatorial problem of computing the correspondences between the points of
two shapes in the presence of the aforementioned geometrical distortions
becomes a quagmire when the number of points is large. We circumvent this
problem by representing shapes in a way that is invariant to the permutation of
the landmarks, i.e., we represent bags of unlabeled 2D points. Within our
framework, a shape is mapped to an analytic function on the complex plane,
leading to what we call its analytic signature (ANSIG). To store an ANSIG, it
suffices to sample it along a closed contour in the complex plane. We show that
the ANSIG is a maximal invariant with respect to the permutation group, i.e.,
that different shapes have different ANSIGs and shapes that differ by a
permutation (or re-labeling) of the landmarks have the same ANSIG. We further
show how easy it is to factor out geometric transformations when comparing
shapes using the ANSIG representation. Finally, we illustrate these
capabilities with shape-based image classification experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4050</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4050</id><created>2010-10-19</created><authors><author><keyname>L&#xe9;ger</keyname><forenames>Flavien</forenames></author><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Efficient Matrix Completion with Gaussian Models</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general framework based on Gaussian models and a MAP-EM algorithm is
introduced in this paper for solving matrix/table completion problems. The
numerical experiments with the standard and challenging movie ratings data show
that the proposed approach, based on probably one of the simplest probabilistic
models, leads to the results in the same ballpark as the state-of-the-art, at a
lower computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4052</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4052</id><created>2010-10-19</created><updated>2013-11-08</updated><authors><author><keyname>Cheng</keyname><forenames>Jialong</forenames></author><author><keyname>Sitharam</keyname><forenames>Meera</forenames></author></authors><title>Maxwell-independence: a new rank estimate for 3D rigidity matroids</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of combinatorially determining the rank of the 3-dimensional
bar-joint {\em rigidity matroid} of a graph is an important open problem in
combinatorial rigidity theory. Maxwell's condition states that the edges of a
graph $G=(V, E)$ are {\em independent} in its $d$-dimensional generic rigidity
matroid only if $(a)$ the number of edges $|E|$ $\le$ $d|V| - {d+1\choose 2}$,
and $(b)$ this holds for every induced subgraph with at least $d$ vertices. We
call such graphs {\em Maxwell-independent} in $d$ dimensions. Laman's theorem
shows that the converse holds for $d=2$ and thus every maximal
Maxwell-independent set of $G$ has size equal to the rank of the 2-dimensional
generic rigidity matroid. While this is false for $d=3$, we show that every
maximal, Maxwell-independent set of a graph $G$ has size at least the rank of
the 3-dimensional generic rigidity matroid of $G$. This answers a question
posed by Tib\'or Jord\'an at the 2008 rigidity workshop at BIRS
\cite{bib:birs}.
  Along the way, we construct subgraphs (1) that yield alternative formulae for
a rank upper bound for Maxwell-independent graphs and (2) that contain a
maximal (true) independent set. We extend this bound to special classes of
non-Maxwell-independent graphs. One further consequence is a simpler proof of
correctness for existing algorithms that give rank bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4059</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4059</id><created>2010-10-19</created><updated>2011-06-24</updated><authors><author><keyname>Kolev</keyname><forenames>Vasil</forenames></author></authors><title>Multiplierless Modules for Forward and Backward Integer Wavelet
  Transform</title><categories>cs.AR cs.CV</categories><comments>7 pages, The ACM proceedings of CompSysTech 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is about the architecture of a lossless wavelet filter bank with
reprogrammable logic. It is based on second generation of wavelets with a
reduced of number of operations. A new basic structure for parallel
architecture and modules to forward and backward integer discrete wavelet
transform is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4065</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4065</id><created>2010-10-19</created><authors><author><keyname>Fischer</keyname><forenames>Bernhard</forenames></author></authors><title>Model-Based Development of Distributed Embedded Systems by the Example
  of the Scicos/SynDEx Framework</title><categories>cs.SY cs.AR cs.SE</categories><comments>146 pages, Master's Thesis</comments><acm-class>C.0; C.1.m; D.2.2; D.2.11; D.4.7; D.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The embedded systems engineering industry faces increasing demands for more
functionality, rapidly evolving components, and shrinking schedules. Abilities
to quickly adapt to changes, develop products with safe design, minimize
project costs, and deliver timely are needed. Model-based development (MBD)
follows a separation of concerns by abstracting systems with an appropriate
intensity. MBD promises higher comprehension by modeling on several
abstraction-levels, formal verification, and automated code generation. This
thesis demonstrates MBD with the Scicos/SynDEx framework on a distributed
embedded system. Scicos is a modeling and simulation environment for hybrid
systems. SynDEx is a rapid prototyping integrated development environment for
distributed systems. Performed examples implement well-known control algorithms
on a target system containing several networked microcontrollers, sensors, and
actuators. The addressed research question tackles the feasibility of MBD for
medium-sized embedded systems. In the case of single-processor applications
experiments show that the comforts of tool-provided simulation, verification,
and code-generation have to be weighed against an additional memory consumption
in dynamic and static memory compared to a hand-written approach. Establishing
a near-seamless modeling-framework with Scicos/SynDEx is expensive. An
increased development effort indicates a high price for developing single
applications, but might pay off for product families. A further drawback was
that the distributed code generated with SynDEx could not be adapted to
microcontrollers without a significant alteration of the scheduling tables. The
Scicos/SynDEx framework forms a valuable tool set that, however, still needs
many improvements. Therefore, its usage is only recommended for experimental
purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4070</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4070</id><created>2010-10-19</created><authors><author><keyname>Gu</keyname><forenames>Xianfeng David</forenames></author><author><keyname>Guo</keyname><forenames>Ren</forenames></author><author><keyname>Luo</keyname><forenames>Feng</forenames></author><author><keyname>Zeng</keyname><forenames>Wei</forenames></author></authors><title>Discrete Laplace-Beltrami Operator Determines Discrete Riemannian Metric</title><categories>cs.DM math.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Laplace-Beltrami operator of a smooth Riemannian manifold is determined
by the Riemannian metric. Conversely, the heat kernel constructed from its
eigenvalues and eigenfunctions determines the Riemannian metric. This work
proves the analogy on Euclidean polyhedral surfaces (triangle meshes), that the
discrete Laplace-Beltrami operator and the discrete Riemannian metric (unique
up to a scaling) are mutually determined by each other. Given an Euclidean
polyhedral surface, its Riemannian metric is represented as edge lengths,
satisfying triangle inequalities on all faces. The Laplace-Beltrami operator is
formulated using the cotangent formula, where the edge weight is defined as the
sum of the cotangent of angles against the edge. We prove that the edge lengths
can be determined by the edge weights unique up to a scaling using the
variational approach. First, we show that the space of all possible metrics of
a polyhedral surface is convex. Then, we construct a special energy defined on
the metric space, such that the gradient of the energy equals to the edge
weights. Third, we show the Hessian matrix of the energy is positive definite,
restricted on the tangent space of the metric space, therefore the energy is
convex. Finally, by the fact that the parameter on a convex domain and the
gradient of a convex function defined on the domain have one-to-one
correspondence, we show the edge weights determines the polyhedral metric
unique up to a scaling. The constructive proof leads to a computational
algorithm that finds the unique metric on a topological triangle mesh from a
discrete Laplace-Beltrami operator matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4084</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4084</id><created>2010-10-19</created><authors><author><keyname>Talukder</keyname><forenames>Kamrul Hasan</forenames></author><author><keyname>Harada</keyname><forenames>Koichi</forenames></author></authors><title>Haar Wavelet Based Approach for Image Compression and Quality Assessment
  of Compressed Image</title><categories>cs.MM</categories><comments>8 pages. arXiv admin note: text overlap with standard references on
  JPEG without attribution</comments><journal-ref>IAENG International Journal of Applied Mathematics, Volume 36,
  Issue 1, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing growth of technology and the entrance into the digital
age, we have to handle a vast amount of information every time which often
presents difficulties. So, the digital information must be stored and retrieved
in an efficient and effective manner, in order for it to be put to practical
use. Wavelets provide a mathematical way of encoding information in such a way
that it is layered according to level of detail. This layering facilitates
approximations at various intermediate stages. These approximations can be
stored using a lot less space than the original data. Here a low complex 2D
image compression method using wavelets as the basis functions and the approach
to measure the quality of the compressed image are presented. The particular
wavelet chosen and used here is the simplest wavelet form namely the Haar
Wavelet. The 2D discret wavelet transform (DWT) has been applied and the detail
matrices from the information matrix of the image have been estimated. The
reconstructed image is synthesized using the estimated detail matrices and
information matrix provided by the Wavelet transform. The quality of the
compressed images has been evaluated using some factors like Compression Ratio
(CR), Peak Signal to Noise Ratio (PSNR), Mean Opinion Score (MOS), Picture
Quality Scale (PQS) etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4088</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4088</id><created>2010-10-19</created><authors><author><keyname>Toyota</keyname><forenames>Norihito</forenames></author></authors><title>Generalized Clustering Coefficients and Milgram Condition for q-th
  Degrees of Separation</title><categories>cs.SI physics.soc-ph</categories><comments>5 pages, 4 figures,Presented at 2010 SICE Annual Conference,
  Taipei,TAIWAN, August 18-21, 2010 August 18-21,2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a series of generalized clustering coefficients based on String
formalism given by Aoyama, using adjacent matrix in networks. We numerically
evaluate Milgram condition proposed in order to explore q-th degrees of
separation in scale free networks and small world networks. We find that scale
free network with exponent 3 just shows 6-degrees of separation. Moreover we
find some relations between separation numbers and generalized clustering
coefficient in both networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4092</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4092</id><created>2010-10-19</created><updated>2011-04-14</updated><authors><author><keyname>Wang</keyname><forenames>Deqing</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Liu</keyname><forenames>Rui</forenames></author><author><keyname>Lin</keyname><forenames>Mengxiang</forenames></author><author><keyname>Wu</keyname><forenames>Wenjun</forenames></author><author><keyname>Hu</keyname><forenames>Hongping</forenames></author></authors><title>Predicting Bugs' Components via Mining Bug Reports</title><categories>cs.SE</categories><comments>some wrongs. new version will come</comments><journal-ref>Journal of Software, Vol 7, No 5, 2012</journal-ref><doi>10.4304/jsw.7.5.1149-1154</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The number of bug reports in complex software increases dramatically. Now
bugs are triaged manually, bug triage or assignment is a labor-intensive and
time-consuming task. Without knowledge about the structure of the software,
testers often specify the component of a new bug wrongly. Meanwhile, it is
difficult for triagers to determine the component of the bug only by its
description. We dig out the components of 28,829 bugs in Eclipse bug project
have been specified wrongly and modified at least once. It results in these
bugs have to be reassigned and delays the process of bug fixing. The average
time of fixing wrongly-specified bugs is longer than that of
correctly-specified ones. In order to solve the problem automatically, we use
historical fixed bug reports as training corpus and build classifiers based on
support vector machines and Na\&quot;ive Bayes to predict the component of a new
bug. The best prediction accuracy reaches up to 81.21% on our validation corpus
of Eclipse project. Averagely our predictive model can save about 54.3 days for
triagers and developers to repair a bug. Keywords: bug reports; bug triage;
text classification; predictive model
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4098</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4098</id><created>2010-10-19</created><authors><author><keyname>Shen</keyname><forenames>Hua-Wei</forenames></author><author><keyname>Cheng</keyname><forenames>Xue-Qi</forenames></author></authors><title>Spectral methods for the detection of network community structure: a
  comparative analysis</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>13 pages, 9 figures</comments><msc-class>90B10 Network models, deterministic, 91D30 Social networks</msc-class><journal-ref>J. Stat. Mech. (2010) P10020</journal-ref><doi>10.1088/1742-5468/2010/10/P10020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral analysis has been successfully applied at the detection of community
structure of networks, respectively being based on the adjacency matrix, the
standard Laplacian matrix, the normalized Laplacian matrix, the modularity
matrix, the correlation matrix and several other variants of these matrices.
However, the comparison between these spectral methods is less reported. More
importantly, it is still unclear which matrix is more appropriate for the
detection of community structure. This paper answers the question through
evaluating the effectiveness of these five matrices against the benchmark
networks with heterogeneous distributions of node degree and community size.
Test results demonstrate that the normalized Laplacian matrix and the
correlation matrix significantly outperform the other three matrices at
identifying the community structure of networks. This indicates that it is
crucial to take into account the heterogeneous distribution of node degree when
using spectral analysis for the detection of community structure. In addition,
to our surprise, the modularity matrix exhibits very similar performance to the
adjacency matrix, which indicates that the modularity matrix does not gain
desired benefits from using the configuration model as reference network with
the consideration of the node degree heterogeneity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4108</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4108</id><created>2010-10-20</created><authors><author><keyname>Orecchia</keyname><forenames>Lorenzo</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>Towards an SDP-based Approach to Spectral Methods: A Nearly-Linear-Time
  Algorithm for Graph Partitioning and Decomposition</title><categories>cs.DS</categories><comments>To appear in SODA 2011</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the following graph partitioning problem: The
input is an undirected graph $G=(V,E),$ a balance parameter $b \in (0,1/2]$ and
a target conductance value $\gamma \in (0,1).$ The output is a cut which, if
non-empty, is of conductance at most $O(f),$ for some function $f(G, \gamma),$
and which is either balanced or well correlated with all cuts of conductance at
most $\gamma.$ Spielman and Teng gave an $\tilde{O}(|E|/\gamma^{2})$-time
algorithm for $f= \sqrt{\gamma \log^{3}|V|}$ and used it to decompose graphs
into a collection of near-expanders. We present a new spectral algorithm for
this problem which runs in time $\tilde{O}(|E|/\gamma)$ for $f=\sqrt{\gamma}.$
Our result yields the first nearly-linear time algorithm for the classic
Balanced Separator problem that achieves the asymptotically optimal
approximation guarantee for spectral methods. Our method has the advantage of
being conceptually simple and relies on a primal-dual semidefinite-programming
SDP approach. We first consider a natural SDP relaxation for the Balanced
Separator problem. While it is easy to obtain from this SDP a certificate of
the fact that the graph has no balanced cut of conductance less than $\gamma,$
somewhat surprisingly, we can obtain a certificate for the stronger correlation
condition. This is achieved via a novel separation oracle for our SDP and by
appealing to Arora and Kale's framework to bound the running time. Our result
contains technical ingredients that may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4110</identifier>
 <datestamp>2014-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4110</id><created>2010-10-20</created><updated>2014-01-19</updated><authors><author><keyname>Sun</keyname><forenames>Hongyang</forenames></author><author><keyname>He</keyname><forenames>Yuxiong</forenames></author><author><keyname>Hsu</keyname><forenames>Wen-Jing</forenames></author><author><keyname>Fan</keyname><forenames>Rui</forenames></author></authors><title>Energy-Efficient Multiprocessor Scheduling for Flow Time and Makespan</title><categories>cs.DS</categories><journal-ref>Theoretical Computer Science, 550, 2014</journal-ref><doi>10.1016/j.tcs.2014.07.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider energy-efficient scheduling on multiprocessors, where the speed
of each processor can be individually scaled, and a processor consumes power
$s^{\alpha}$ when running at speed $s$, for $\alpha&gt;1$. A scheduling algorithm
needs to decide at any time both processor allocations and processor speeds for
a set of parallel jobs with time-varying parallelism. The objective is to
minimize the sum of the total energy consumption and certain performance
metric, which in this paper includes total flow time and makespan. For both
objectives, we present instantaneous parallelism clairvoyant (IP-clairvoyant)
algorithms that are aware of the instantaneous parallelism of the jobs at any
time but not their future characteristics, such as remaining parallelism and
work. For total flow time plus energy, we present an $O(1)$-competitive
algorithm, which significantly improves upon the best known non-clairvoyant
algorithm and is the first constant competitive result on multiprocessor speed
scaling for parallel jobs. In the case of makespan plus energy, which is
considered for the first time in the literature, we present an
$O(\ln^{1-1/\alpha}P)$-competitive algorithm, where $P$ is the total number of
processors. We show that this algorithm is asymptotically optimal by providing
a matching lower bound. In addition, we also study non-clairvoyant scheduling
for total flow time plus energy, and present an algorithm that achieves $O(\ln
P)$-competitive for jobs with arbitrary release time and
$O(\ln^{1/\alpha}P)$-competitive for jobs with identical release time. Finally,
we prove an $\Omega(\ln^{1/\alpha}P)$ lower bound on the competitive ratio of
any non-clairvoyant algorithm, matching the upper bound of our algorithm for
jobs with identical release time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4138</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4138</id><created>2010-10-20</created><authors><author><keyname>L\Horincz</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Palotai</keyname><forenames>Zsolt</forenames></author><author><keyname>Szirtes</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Sparse and silent coding in neural circuits</title><categories>cs.NE</categories><comments>19 pages, 2 figures and 4 tables with pseudocodes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse coding algorithms are about finding a linear basis in which signals
can be represented by a small number of active (non-zero) coefficients. Such
coding has many applications in science and engineering and is believed to play
an important role in neural information processing. However, due to the
computational complexity of the task, only approximate solutions provide the
required efficiency (in terms of time). As new results show, under particular
conditions there exist efficient solutions by minimizing the magnitude of the
coefficients (`$l_1$-norm') instead of minimizing the size of the active subset
of features (`$l_0$-norm'). Straightforward neural implementation of these
solutions is not likely, as they require \emph{a priori} knowledge of the
number of active features. Furthermore, these methods utilize iterative
re-evaluation of the reconstruction error, which in turn implies that final
sparse forms (featuring `population sparseness') can only be reached through
the formation of a series of non-sparse representations, which is in contrast
with the overall sparse functioning of the neural systems (`lifetime
sparseness'). In this article we present a novel algorithm which integrates our
previous `$l_0$-norm' model on spike based probabilistic optimization for
sparse coding with ideas coming from novel `$l_1$-norm' solutions.
  The resulting algorithm allows neurally plausible implementation and does not
require an exactly defined sparseness level thus it is suitable for
representing natural stimuli with a varying number of features. We also
demonstrate that the combined method significantly extends the domain where
optimal solutions can be found by `$l_1$-norm' based algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4160</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4160</id><created>2010-10-20</created><updated>2012-01-19</updated><authors><author><keyname>Nikitopoulos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Ascheid</keyname><forenames>Gerd</forenames></author></authors><title>MIMO APP Receiver Processing with Performance-Determined Complexity</title><categories>cs.IT math.IT</categories><comments>An extended version of this work has been submitted for publication
  consideration</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typical receiver processing, targeting always the best achievable bit error
rate performance, can result in a waste of resources, especially, when the
transmission conditions are such that the best performance is orders of
magnitude better than the required. In this work, a processing framework is
proposed which allows adjusting the processing requirements to the transmission
conditions and the required bit error rate. It applies a-posteriori probability
receivers operating over multiple-input multiple-output channels. It is
demonstrated that significant complexity savings can be achieved both at the
soft, sphere-decoder based detector and the channel decoder with only minor
modifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4203</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4203</id><created>2010-10-18</created><authors><author><keyname>Crespo</keyname><forenames>Jo&#xe3;o B. F. P.</forenames></author><author><keyname>Aguiar</keyname><forenames>Pedro M. Q.</forenames></author></authors><title>Revisiting Complex Moments For 2D Shape Representation and Image
  Normalization</title><categories>cs.CV</categories><comments>69 pages, 20 figures</comments><doi>10.1109/TIP.2011.2146264</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When comparing 2D shapes, a key issue is their normalization. Translation and
scale are easily taken care of by removing the mean and normalizing the energy.
However, defining and computing the orientation of a 2D shape is not so simple.
In fact, although for elongated shapes the principal axis can be used to define
one of two possible orientations, there is no such tool for general shapes. As
we show in the paper, previous approaches fail to compute the orientation of
even noiseless observations of simple shapes. We address this problem. In the
paper, we show how to uniquely define the orientation of an arbitrary 2D shape,
in terms of what we call its Principal Moments. We show that a small subset of
these moments suffice to represent the underlying 2D shape and propose a new
method to efficiently compute the shape orientation: Principal Moment Analysis.
Finally, we discuss how this method can further be applied to normalize
grey-level images. Besides the theoretical proof of correctness, we describe
experiments demonstrating robustness to noise and illustrating the method with
real images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4205</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4205</id><created>2010-10-15</created><authors><author><keyname>Mohammed</keyname><forenames>Riyazuddin</forenames></author></authors><title>Information Analysis of DNA Sequences</title><categories>cs.CE cs.IT math.IT</categories><comments>22 pages doc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of differentiating the informational content of coding (exons)
and non-coding (introns) regions of a DNA sequence is one of the central
problems of genomics. The introns are estimated to be nearly 95% of the DNA and
since they do not seem to participate in the process of transcription of
amino-acids, they have been termed &quot;junk DNA.&quot; Although it is believed that the
non-coding regions in genomes have no role in cell growth and evolution,
demonstration that these regions carry useful information would tend to falsify
this belief. In this paper, we consider entropy as a measure of information by
modifying the entropy expression to take into account the varying length of
these sequences. Exons are usually much shorter in length than introns;
therefore the comparison of the entropy values needs to be normalized. A length
correction strategy was employed using randomly generated nucleonic base
strings built out of the alphabet of the same size as the exons under question.
Our analysis shows that introns carry nearly as much of information as exons,
disproving the notion that they do not carry any information. The entropy
findings of this paper are likely to be of use in further study of other
challenging works like the analysis of symmetry models of the genetic code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4207</identifier>
 <datestamp>2010-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4207</id><created>2010-10-20</created><updated>2010-11-14</updated><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Rocquencourt, LIENS</affiliation></author></authors><title>Convex Analysis and Optimization with Submodular Functions: a Tutorial</title><categories>cs.LG math.OC stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Set-functions appear in many areas of computer science and applied
mathematics, such as machine learning, computer vision, operations research or
electrical networks. Among these set-functions, submodular functions play an
important role, similar to convex functions on vector spaces. In this tutorial,
the theory of submodular functions is presented, in a self-contained way, with
all results shown from first principles. A good knowledge of convex analysis is
assumed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4229</identifier>
 <datestamp>2012-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4229</id><created>2010-10-20</created><updated>2012-09-28</updated><authors><author><keyname>Brandenberg</keyname><forenames>Rene</forenames></author><author><keyname>Koenig</keyname><forenames>Stefan</forenames></author></authors><title>No dimension independent Core-Sets for Containment under Homothetics</title><categories>cs.CG</categories><comments>Discrete &amp; Computational Geometry, 2012; The final publication is
  available at http://www.springerlink.com</comments><msc-class>52A35, 52A40, 52B12, 52B15, 52B55, 68W25</msc-class><doi>10.1007/s00454-012-9462-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the containment problem under homothetics which has the
minimal enclosing ball (MEB) problem as a prominent representative. We connect
the problem to results in classic convex geometry and introduce a new series of
radii, which we call core-radii. For the MEB problem, these radii have already
been considered from a different point of view and sharp inequalities between
them are known. In this paper sharp inequalities between core-radii for general
containment under homothetics are obtained. Moreover, the presented
inequalities are used to derive sharp upper bounds on the size of core-sets for
containment under homothetics. In the MEB case, this yields a tight (dimension
independent) bound for the size of such core-sets. In the general case, we show
that there are core-sets of size linear in the dimension and that this bound
stays sharp even if the container is required to be symmetric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4237</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4237</id><created>2010-10-20</created><updated>2010-12-31</updated><authors><author><keyname>Xu</keyname><forenames>Huan</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author></authors><title>Robust PCA via Outlier Pursuit</title><categories>cs.LG cs.IT math.IT stat.ML</categories><comments>26 pages, appeared in NIPS 2010. v2 has typos corrected, some
  re-writing. results essentially unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Singular Value Decomposition (and Principal Component Analysis) is one of the
most widely used techniques for dimensionality reduction: successful and
efficiently computable, it is nevertheless plagued by a well-known,
well-documented sensitivity to outliers. Recent work has considered the setting
where each point has a few arbitrarily corrupted components. Yet, in
applications of SVD or PCA such as robust collaborative filtering or
bioinformatics, malicious agents, defective genes, or simply corrupted or
contaminated experiments may effectively yield entire points that are
completely corrupted.
  We present an efficient convex optimization-based algorithm we call Outlier
Pursuit, that under some mild assumptions on the uncorrupted points (satisfied,
e.g., by the standard generative assumption in PCA problems) recovers the exact
optimal low-dimensional subspace, and identifies the corrupted points. Such
identification of corrupted points that do not conform to the low-dimensional
approximation, is of paramount interest in bioinformatics and financial
applications, and beyond. Our techniques involve matrix decomposition using
nuclear norm minimization, however, our results, setup, and approach,
necessarily differ considerably from the existing line of work in matrix
completion and matrix decomposition, since we develop an approach to recover
the correct column space of the uncorrupted matrix, rather than the exact
matrix itself. In any problem where one seeks to recover a structure rather
than the exact initial matrices, techniques developed thus far relying on
certificates of optimality, will fail. We present an important extension of
these methods, that allows the treatment of such problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4247</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4247</id><created>2010-10-20</created><authors><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>A Parameterized Centrality Metric for Network Analysis</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>11 pages, submitted to Physical Review E</comments><journal-ref>Physical Review E83(6):066118, 2011</journal-ref><doi>10.1103/PhysRevE.83.066118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A variety of metrics have been proposed to measure the relative importance of
nodes in a network. One of these, alpha-centrality [Bonacich, 2001], measures
the number of attenuated paths that exist between nodes. We introduce a
normalized version of this metric and use it to study network structure,
specifically, to rank nodes and find community structure of the network.
Specifically, we extend the modularity-maximization method [Newman and Girvan,
2004] for community detection to use this metric as the measure of node
connectivity. Normalized alpha-centrality is a powerful tool for network
analysis, since it contains a tunable parameter that sets the length scale of
interactions. By studying how rankings and discovered communities change when
this parameter is varied allows us to identify locally and globally important
nodes and structures. We apply the proposed method to several benchmark
networks and show that it leads to better insight into network structure than
alternative methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4249</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4249</id><created>2010-10-20</created><updated>2010-10-20</updated><authors><author><keyname>Halld&#xf3;rsson</keyname><forenames>Magn&#xfa;s M&#xe1;r</forenames></author><author><keyname>Mitra</keyname><forenames>Pradipta</forenames></author></authors><title>Wireless Capacity with Oblivious Power in General Metrics</title><categories>cs.DS cs.NI</categories><comments>16 pages, 1 figures (to appear in SODA 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of a wireless network is the maximum possible amount of
simultaneous communication, taking interference into account.
  Formally, we treat the following problem. Given is a set of links, each a
sender-receiver pair located in a metric space, and an assignment of power to
the senders. We seek a maximum subset of links that are feasible in the SINR
model: namely, the signal received on each link should be larger than the sum
of the interferences from the other links. We give a constant-factor
approximation that holds for any length-monotone, sub-linear power assignment
and any distance metric.
  We use this to give essentially tight characterizations of capacity
maximization under power control using oblivious power assignments.
Specifically, we show that the mean power assignment is optimal for capacity
maximization of bi-directional links, and give a tight $\theta(\log
n)$-approximation of scheduling bi-directional links with power control using
oblivious power. For uni-directional links we give a nearly optimal $O(\log n +
\log \log \Delta)$-approximation to the power control problem using mean power,
where $\Delta$ is the ratio of longest and shortest links. Combined, these
results clarify significantly the centralized complexity of wireless
communication problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4251</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4251</id><created>2010-10-20</created><authors><author><keyname>Wissbrock</keyname><forenames>Fabian</forenames></author></authors><title>$O(\alpha_s^3 T_F^2 N_F)$ Contributions to the Heavy Flavor Wilson
  Coefficients of the Structure Function $F_2(x,Q^2)$ at $Q^2 \gg m^2$</title><categories>hep-ph cs.DM hep-ex math-ph math.MP</categories><comments>Diploma Thesis, 143 pages, 29 figures, 1 style file</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The massive 3-loop fermion-loop corrections $\propto C_A N_f T_F^2$ and $C_F
N_f T_F^2$ to the massive operator matrix elements $A_{Qg}$,
$A_{Qq}^{\rm{PS}}$, $A_{qq,Q}^{\rm{PS}}$, $A_{qq,Q}^{\rm{NS}}$ and
$A_{qq,Q}^{\rm{NS,TR}} have been obtained for general values of $N$. Thereby
the corresponding contributions to the asymptotic heavy flavor Wilson
coefficients of the structure function $F_2(x,Q^2)$ and of transversity in the
region $Q^2 \geq 10 \cdot m^2$ are known. Our method is based on direct
integration, avoiding the integration-by-parts technique, which is advantageous
due to the compactness of the intermediate and final results. We also obtain
the corresponding contributions to the 3-loop anomalous dimensions and confirm
results in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4253</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4253</id><created>2010-10-20</created><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author></authors><title>Large-Scale Clustering Based on Data Compression</title><categories>cs.LG</categories><journal-ref>Proceeding of the 8th International Conference on Information
  Technology : New Generations, April 11-13, 2011, Las Vegas, Nevada, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the clustering problem for large data sets. We propose
an approach based on distributed optimization. The clustering problem is
formulated as an optimization problem of maximizing the classification gain. We
show that the optimization problem can be reformulated and decomposed into
small-scale sub optimization problems by using the Dantzig-Wolfe decomposition
method. Generally speaking, the Dantzig-Wolfe method can only be used for
convex optimization problems, where the duality gaps are zero. Even though, the
considered optimization problem in this paper is non-convex, we prove that the
duality gap goes to zero, as the problem size goes to infinity. Therefore, the
Dantzig-Wolfe method can be applied here. In the proposed approach, the
clustering problem is iteratively solved by a group of computers coordinated by
one center processor, where each computer solves one independent small-scale
sub optimization problem during each iteration, and only a small amount of data
communication is needed between the computers and center processor. Numerical
results show that the proposed approach is effective and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4272</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4272</id><created>2010-10-20</created><authors><author><keyname>Bunimovich</keyname><forenames>L. A.</forenames></author><author><keyname>Webb</keyname><forenames>B. Z.</forenames></author></authors><title>Isospectral Reductions of Dynamical Networks</title><categories>math.DS cs.SI physics.soc-ph</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general and flexible procedure which allows for the reduction
(or expansion) of any dynamical network while preserving the spectrum of the
network's adjacency matrix. Computationally, this process is simple and easily
implemented for the analysis of any network. Moreover, it is possible to
isospectrally reduce a network with respect to any network characteristic
including centrality, betweenness, etc. This procedure also establishes new
equivalence relations which partition all dynamical networks into spectrally
equivalent classes. Here, we present general facts regarding isospectral
network transformations which we then demonstrate in simple examples. Overall,
our procedure introduces new possibilities for the analysis of networks in ways
that are easily visualized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4280</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4280</id><created>2010-10-20</created><authors><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author></authors><title>Rational Convex Programs, Their Feasibility, and the Arrow-Debreu Nash
  Bargaining Game</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decade, combinatorial algorithms have been obtained for exactly
solving several nonlinear convex programs. We first provide a formal context to
this activity by introducing the notion of {\em rational convex programs} --
this also enables us to identify a number of questions for further study. So
far, such algorithms were obtained for total problems only. Our main
contribution is developing the methodology for handling non-total problems,
i.e., their associated convex programs may be infeasible for certain settings
of the parameters.
  The specific problem we study pertains to a Nash bargaining game, called
ADNB, which is derived from the linear case of the Arrow-Debreu market model.
We reduce this game to computing an equilibrium in a new market model called
{\em flexible budget market}, and we obtain primal-dual algorithms for
determining feasibility, as well as giving a proof of infeasibility and finding
an equilibrium. We give an application of our combinatorial algorithm for ADNB
to an important &quot;fair&quot; throughput allocation problem on a wireless channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4281</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4281</id><created>2010-10-20</created><authors><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author></authors><title>Non-Separable, Quasiconcave Utilities are Easy -- in a Perfect Price
  Discrimination Market Model</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent results, establishing evidence of intractability for such restrictive
utility functions as additively separable, piecewise-linear and concave, under
both Fisher and Arrow-Debreu market models, have prompted the question of
whether we have failed to capture some essential elements of real markets,
which seem to do a good job of finding prices that maintain parity between
supply and demand.
  The main point of this paper is to show that even non-separable, quasiconcave
utility functions can be handled efficiently in a suitably chosen, though
natural, realistic and useful, market model; our model allows for perfect price
discrimination. Our model supports unique equilibrium prices and, for the
restriction to concave utilities, satisfies both welfare theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4293</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4293</id><created>2010-10-20</created><authors><author><keyname>Morrison</keyname><forenames>Greg</forenames></author><author><keyname>Mahadevan</keyname><forenames>L.</forenames></author></authors><title>Generalized Erdos Numbers</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI math.HO</categories><comments>4 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple real-valued generalization of the well known
integer-valued Erdos number as a topological, non-metric measure of the
`closeness' felt between two nodes in an undirected, weighted graph. These
real-valued Erdos numbers are asymmetric and are able to distinguish between
network topologies that standard distance metrics view as identical. We use
this measure to study some simple analytically tractable networks, and show the
utility of our measure to devise a ratings scheme based on the generalized
Erdos number that we deploy on the data from the NetFlix prize, and find a
significant improvement in our ratings prediction over a baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4314</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4314</id><created>2010-10-20</created><authors><author><keyname>Yu</keyname><forenames>Guoshen</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Statistical Compressive Sensing of Gaussian Mixture Models</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new framework of compressive sensing (CS), namely statistical compressive
sensing (SCS), that aims at efficiently sampling a collection of signals that
follow a statistical distribution and achieving accurate reconstruction on
average, is introduced. For signals following a Gaussian distribution, with
Gaussian or Bernoulli sensing matrices of O(k) measurements, considerably
smaller than the O(k log(N/k)) required by conventional CS, where N is the
signal dimension, and with an optimal decoder implemented with linear
filtering, significantly faster than the pursuit decoders applied in
conventional CS, the error of SCS is shown tightly upper bounded by a constant
times the k-best term approximation error, with overwhelming probability. The
failure probability is also significantly smaller than that of conventional CS.
Stronger yet simpler results further show that for any sensing matrix, the
error of Gaussian SCS is upper bounded by a constant times the k-best term
approximation with probability one, and the bound constant can be efficiently
calculated. For signals following Gaussian mixture models, SCS with a piecewise
linear decoder is introduced and shown to produce for real images better
results than conventional CS based on sparse models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4327</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4327</id><created>2010-10-20</created><updated>2010-11-30</updated><authors><author><keyname>Bel&#xe1;k</keyname><forenames>V&#xe1;clav</forenames></author><author><keyname>Karnstedt</keyname><forenames>Marcel</forenames></author><author><keyname>Hayes</keyname><forenames>Conor</forenames></author></authors><title>Cross-Community Dynamics in Science: How Information Retrieval Affects
  Semantic Web and Vice Versa</title><categories>cs.SI cs.IR physics.soc-ph</categories><comments>Extended version of a paper 'Life-Cycles and Mutual Effects of
  Scientific Communities' presented at ASNA 2010 conference in Zurich
  (http://www.asna.ch). 28 pages, 7 tables, and 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community effects on the behaviour of individuals, the community itself and
other communities can be observed in a wide range of applications. This is true
in scientific research, where communities of researchers have increasingly to
justify their impact and progress to funding agencies. While previous work has
tried to explain and analyse such phenomena, there is still a great potential
for increasing the quality and accuracy of this analysis, especially in the
context of cross-community effects. In this work, we propose a general
framework consisting of several different techniques to analyse and explain
such dynamics. The proposed methodology works with arbitrary community
algorithms and incorporates meta-data to improve the overall quality and
expressiveness of the analysis. We suggest and discuss several approaches to
understand, interpret and explain particular phenomena, which themselves are
identified in an automated manner. We illustrate the benefits and strengths of
our approach by exposing highly interesting in-depth details of cross-community
effects between two closely related and well established areas of scientific
research. We finally conclude and highlight the important open issues on the
way towards understanding, defining and eventually predicting typical
life-cycles and classes of communities in the context of cross-community
effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4369</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4369</id><created>2010-10-21</created><updated>2011-05-06</updated><authors><author><keyname>Zhang</keyname><forenames>Guofeng</forenames></author><author><keyname>James</keyname><forenames>Matthew R.</forenames></author></authors><title>Direct and Indirect Couplings in Coherent Feedback Control of Linear
  Quantum Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>33 pages, 7 figures; accepted for publication in IEEE Transactions on
  Automatic Control, October 2010</comments><journal-ref>IEEE Transactions on Automatic Control,56(7): 1535-1550, 2011</journal-ref><doi>10.1109/TAC.2010.2096010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to study and design direct and indirect
couplings for use in coherent feedback control of a class of linear quantum
stochastic systems. A general physical model for a nominal linear quantum
system coupled directly and indirectly to external systems is presented.
Fundamental properties of stability, dissipation, passivity, and gain for this
class of linear quantum models are presented and characterized using complex
Lyapunov equations and linear matrix inequalities (LMIs). Coherent $H^\infty$
and LQG synthesis methods are extended to accommodate direct couplings using
multistep optimization. Examples are given to illustrate the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4385</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4385</id><created>2010-10-21</created><authors><author><keyname>Hern&#xe1;ndez</keyname><forenames>Hugo</forenames></author><author><keyname>Baumgartner</keyname><forenames>Tobias</forenames></author><author><keyname>Blesa</keyname><forenames>Maria J.</forenames></author><author><keyname>Blum</keyname><forenames>Christian</forenames></author><author><keyname>Kr&#xf6;ller</keyname><forenames>Alexander</forenames></author><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author></authors><title>A Protocol for Self-Synchronized Duty-Cycling in Sensor Networks:
  Generic Implementation in Wiselib</title><categories>cs.AI</categories><comments>Accepted for the proceedings of MSN 2010 (The 6th International
  Conference on Mobile Ad-hoc and Sensor Networks)</comments><acm-class>I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present a protocol for self-synchronized duty-cycling in
wireless sensor networks with energy harvesting capabilities. The protocol is
implemented in Wiselib, a library of generic algorithms for sensor networks.
Simulations are conducted with the sensor network simulator Shawn. They are
based on the specifications of real hardware known as iSense sensor nodes. The
experimental results show that the proposed mechanism is able to adapt to
changing energy availabilities. Moreover, it is shown that the system is very
robust against packet loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4408</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4408</id><created>2010-10-21</created><authors><author><keyname>Clarkson</keyname><forenames>Kenneth L.</forenames></author><author><keyname>Hazan</keyname><forenames>Elad</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>Sublinear Optimization for Machine Learning</title><categories>cs.LG</categories><comments>extended abstract appeared in FOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give sublinear-time approximation algorithms for some optimization
problems arising in machine learning, such as training linear classifiers and
finding minimum enclosing balls. Our algorithms can be extended to some
kernelized versions of these problems, such as SVDD, hard margin SVM, and
L2-SVM, for which sublinear-time algorithms were not known before. These new
algorithms use a combination of a novel sampling techniques and a new
multiplicative update algorithm. We give lower bounds which show the running
times of many of our algorithms to be nearly best possible in the unit-cost RAM
model. We also give implementations of our algorithms in the semi-streaming
setting, obtaining the first low pass polylogarithmic space and sublinear time
algorithms achieving arbitrary approximation factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4411</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4411</id><created>2010-10-21</created><authors><author><keyname>Oliveira</keyname><forenames>Fabiano de S.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Revisiting deadlock prevention: a probabilistic approach</title><categories>cs.DC cs.OS</categories><journal-ref>Networks 63 (2014), 203-210</journal-ref><doi>10.1002/net.21537</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the deadlock-prevention problem by focusing on priority digraphs
instead of the traditional wait-for digraphs. This has allowed us to formulate
deadlock prevention in terms of prohibiting the occurrence of directed cycles
even in the most general of wait models (the so-called AND-OR model, in which
prohibiting wait-for directed cycles is generally overly restrictive). For a
particular case in which the priority digraphs are somewhat simplified, we
introduce a Las Vegas probabilistic mechanism for resource granting and analyze
its key aspects in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4422</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4422</id><created>2010-10-21</created><updated>2012-08-09</updated><authors><author><keyname>Griggio</keyname><forenames>Alberto</forenames><affiliation>FBK-Irst, Trento, Italy</affiliation></author><author><keyname>Le</keyname><forenames>Thi Thieu Hoa</forenames><affiliation>DISI, University of Trento, Italy</affiliation></author><author><keyname>Sebastiani</keyname><forenames>Roberto</forenames><affiliation>DISI, University of Trento, Italy</affiliation></author></authors><title>Efficient Interpolant Generation in Satisfiability Modulo Linear Integer
  Arithmetic</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 10,
  2012) lmcs:1033</journal-ref><doi>10.2168/LMCS-8(3:3)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of computing Craig interpolants in SAT and SMT has recently
received a lot of interest, mainly for its applications in formal verification.
Efficient algorithms for interpolant generation have been presented for some
theories of interest ---including that of equality and uninterpreted functions,
linear arithmetic over the rationals, and their combination--- and they are
successfully used within model checking tools. For the theory of linear
arithmetic over the integers (LA(Z)), however, the problem of finding an
interpolant is more challenging, and the task of developing efficient
interpolant generators for the full theory LA(Z) is still the objective of
ongoing research. In this paper we try to close this gap. We build on previous
work and present a novel interpolation algorithm for SMT(LA(Z)), which exploits
the full power of current state-of-the-art SMT(LA(Z)) solvers. We demonstrate
the potential of our approach with an extensive experimental evaluation of our
implementation of the proposed algorithm in the MathSAT SMT solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4423</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4423</id><created>2010-10-21</created><authors><author><keyname>Steenken</keyname><forenames>Dominik</forenames><affiliation>University of Paderborn</affiliation></author><author><keyname>Wehrheim</keyname><forenames>Heike</forenames><affiliation>University of Paderborn</affiliation></author><author><keyname>Wonisch</keyname><forenames>Daniel</forenames><affiliation>University of Paderborn</affiliation></author></authors><title>Towards A Shape Analysis for Graph Transformation Systems</title><categories>cs.PL cs.LO</categories><comments>17 pages, 7 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphs and graph transformation systems are a frequently used modelling
technique for a wide range of different domains, cover- ing areas as diverse as
refactorings, network topologies or reconfigurable software. Being a formal
method, graph transformation systems lend themselves to a formal analysis. This
has inspired the development of various verification methods, in particular
also model checking tools. In this paper, we present a verification technique
for infinite-state graph transformation systems. The technique employs the
abstraction principle used in shape analysis of programs, summarising possibly
infinitely many nodes thus giving shape graphs. The technique has been
implemented using the 3-valued logical foundations of standard shape analysis.
We exemplify the approach on an example from the railway domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4458</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4458</id><created>2010-10-21</created><updated>2010-11-14</updated><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author></authors><title>Variable time amplitude amplification and a faster quantum algorithm for
  solving systems of linear equations</title><categories>quant-ph cs.CC cs.DS</categories><comments>17 pages, no figures, v2: various small corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two new quantum algorithms. Our first algorithm is a
generalization of amplitude amplification to the case when parts of the quantum
algorithm that is being amplified stop at different times.
  Our second algorithm uses the first algorithm to improve the running time of
Harrow et al. algorithm for solving systems of linear equations from O(kappa^2
log N) to O(kappa log^3 kappa log N) where \kappa is the condition number of
the system of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4466</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4466</id><created>2010-10-21</created><authors><author><keyname>El-Yaniv</keyname><forenames>Ran</forenames></author><author><keyname>Nisenson</keyname><forenames>Mordechai</forenames></author></authors><title>On the Foundations of Adversarial Single-Class Classification</title><categories>cs.LG cs.AI</categories><comments>52 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by authentication, intrusion and spam detection applications we
consider single-class classification (SCC) as a two-person game between the
learner and an adversary. In this game the learner has a sample from a target
distribution and the goal is to construct a classifier capable of
distinguishing observations from the target distribution from observations
emitted from an unknown other distribution. The ideal SCC classifier must
guarantee a given tolerance for the false-positive error (false alarm rate)
while minimizing the false negative error (intruder pass rate). Viewing SCC as
a two-person zero-sum game we identify both deterministic and randomized
optimal classification strategies for different game variants. We demonstrate
that randomized classification can provide a significant advantage. In the
deterministic setting we show how to reduce SCC to two-class classification
where in the two-class problem the other class is a synthetically generated
distribution. We provide an efficient and practical algorithm for constructing
and solving the two class problem. The algorithm distinguishes low density
regions of the target distribution and is shown to be consistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4475</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4475</id><created>2010-10-21</created><authors><author><keyname>Panda</keyname><forenames>Manoj K.</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>State Dependent Attempt Rate Modeling of Single Cell IEEE~802.11 WLANs
  with Homogeneous Nodes and Poisson Packet Arrivals</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analytical models for IEEE 802.11-based WLANs are invariably based on
approximations, such as the well-known \textit{decoupling approximation}
proposed by Bianchi for modeling single cell WLANs consisting of saturated
nodes. In this paper, we provide a new approach to model the situation when the
nodes are not saturated. We study a State Dependent Attempt Rate (SDAR)
approximation to model $M$ queues (one queue per node) served by the CSMA/CA
protocol as standardized in the IEEE 802.11 DCF MAC protocol. The approximation
is that, when $n$ of the $M$ queues are non-empty, the transmission attempt
probability of the $n$ non-empty nodes is given by the long-term transmission
attempt probability of $n$ &quot;saturated&quot; nodes as provided by Bianchi's model.
The SDAR approximation reduces a single cell WLAN with non-saturated nodes to a
&quot;coupled queue system&quot;. When packets arrive to the $M$ queues according to
independent Poisson processes, we provide a Markov model for the coupled queue
system with SDAR service. \textit{The main contribution of this paper is to
provide an analysis of the coupled queue process by studying a lower
dimensional process, and by introducing a certain conditional independence
approximation}. We show that the SDAR model of contention provides an accurate
model for the DCF MAC protocol in single cells, and report the simulation
speed-ups thus obtained by our \textit{model-based simulation}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4484</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4484</id><created>2010-10-21</created><updated>2010-10-26</updated><authors><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames></author></authors><title>A Type II lattice of norm 8 in dimension 72</title><categories>cs.IT math.IT</categories><comments>withdrawn, result incorrect</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Type II lattice of norm 8 in dimension 72 is obtained by Construction A
applied to an extended Quadratic Residue code over Z8. Its automorphism group
contains a subgroup isomorphic to PSL(2,71).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4498</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4498</id><created>2010-10-21</created><authors><author><keyname>Parshani</keyname><forenames>Roni</forenames></author><author><keyname>Buldyrev</keyname><forenames>Sergey V.</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author></authors><title>The critical effect of dependency groups on the function of networks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>5 pages, 4 figures</comments><doi>10.1073/pnas.1008404108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current network models assume one type of links to define the relations
between the network entities. However, many real networks can only be correctly
described using two different types of relations. Connectivity links that
enable the nodes to function cooperatively as a network and dependency links
that bind the failure of one network element to the failure of other network
elements. Here we present for the first time an analytical framework for
studying the robustness of networks that include both connectivity and
dependency links. We show that the synergy between the two types of failures
leads to an iterative process of cascading failures that has a devastating
effect on the network stability and completely alters the known assumptions
regarding the robustness of networks. We present exact analytical results for
the dramatic change in the network behavior when introducing dependency links.
For a high density of dependency links the network disintegrates in a form of a
first order phase transition while for a low density of dependency links the
network disintegrates in a second order transition. Moreover, opposed to
networks containing only connectivity links where a broader degree distribution
results in a more robust network, when both types of links are present a broad
degree distribution leads to higher vulnerability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4499</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4499</id><created>2010-10-21</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Hedonic Coalition Formation for Distributed Task Allocation among
  Wireless Agents</title><categories>cs.IT cs.GT math.IT</categories><comments>to appear, IEEE Transactions on Mobile Computing</comments><journal-ref>IEEE Transactions on Mobile Computing, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous wireless agents such as unmanned aerial vehicles or mobile base
stations present a great potential for deployment in next-generation wireless
networks. While current literature has been mainly focused on the use of agents
within robotics or software applications, we propose a novel usage model for
self-organizing agents suited to wireless networks. In the proposed model, a
number of agents are required to collect data from several arbitrarily located
tasks. Each task represents a queue of packets that require collection and
subsequent wireless transmission by the agents to a central receiver. The
problem is modeled as a hedonic coalition formation game between the agents and
the tasks that interact in order to form disjoint coalitions. Each formed
coalition is modeled as a polling system consisting of a number of agents which
move between the different tasks present in the coalition, collect and transmit
the packets. Within each coalition, some agents can also take the role of a
relay for improving the packet success rate of the transmission. The proposed
algorithm allows the tasks and the agents to take distributed decisions to join
or leave a coalition, based on the achieved benefit in terms of effective
throughput, and the cost in terms of delay. As a result of these decisions, the
agents and tasks structure themselves into independent disjoint coalitions
which constitute a Nash-stable network partition. Moreover, the proposed
algorithm allows the agents and tasks to adapt the topology to environmental
changes such as the arrival/removal of tasks or the mobility of the tasks.
Simulation results show how the proposed algorithm improves the performance, in
terms of average player (agent or task) payoff, of at least 30.26% (for a
network of 5 agents with up to 25 tasks) relatively to a scheme that allocates
nearby tasks equally among agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4501</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4501</id><created>2010-10-21</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author></authors><title>Coalition Formation Games for Collaborative Spectrum Sensing</title><categories>cs.IT cs.GT math.IT</categories><comments>IEEE Transactions on Vehicular Technology, to appear</comments><journal-ref>IEEE Transactions on Vehicular Technology, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative Spectrum Sensing (CSS) between secondary users (SUs) in
cognitive networks exhibits an inherent tradeoff between minimizing the
probability of missing the detection of the primary user (PU) and maintaining a
reasonable false alarm probability (e.g., for maintaining a good spectrum
utilization). In this paper, we study the impact of this tradeoff on the
network structure and the cooperative incentives of the SUs that seek to
cooperate for improving their detection performance. We model the CSS problem
as a non-transferable coalitional game, and we propose distributed algorithms
for coalition formation. First, we construct a distributed coalition formation
(CF) algorithm that allows the SUs to self-organize into disjoint coalitions
while accounting for the CSS tradeoff. Then, the CF algorithm is complemented
with a coalitional voting game for enabling distributed coalition formation
with detection probability guarantees (CF-PD) when required by the PU. The
CF-PD algorithm allows the SUs to form minimal winning coalitions (MWCs), i.e.,
coalitions that achieve the target detection probability with minimal costs.
For both algorithms, we study and prove various properties pertaining to
network structure, adaptation to mobility and stability. Simulation results
show that CF reduces the average probability of miss per SU up to 88.45%
relative to the non-cooperative case, while maintaining a desired false alarm.
For CF-PD, the results show that up to 87.25% of the SUs achieve the required
detection probability through MWC
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4502</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4502</id><created>2010-10-21</created><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Kamphans</keyname><forenames>Tom</forenames></author><author><keyname>Schweer</keyname><forenames>Nils</forenames></author></authors><title>Online Square Packing</title><categories>cs.DS cs.CG</categories><comments>24 pages, 10 figures; full version of extended abstract that appeared
  in WADS 2009</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the problem of packing squares in an online fashion: Given a
semi-infinite strip of width 1 and an unknown sequence of squares of side
length in [0,1] that arrive from above, one at a time. The objective is to pack
these items as they arrive, minimizing the resulting height. Just like in the
classical game of Tetris, each square must be moved along a collision-free path
to its final destination. In addition, we account for gravity in both motion
(squares must never move up) and position (any final destination must be
supported from below). A similar problem has been considered before; the best
previous result is by Azar and Epstein, who gave a 4-competitive algorithm in a
setting without gravity (i.e., with the possibility of letting squares &quot;hang in
the air&quot;) based on ideas of shelf-packing: Squares are assigned to different
horizontal levels, allowing an analysis that is reminiscent of some bin-packing
arguments. We apply a geometric analysis to establish a competitive factor of
3.5 for the bottom-left heuristic and present a 34/13=2.615...-competitive
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4504</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4504</id><created>2010-10-21</created><updated>2012-06-26</updated><authors><author><keyname>Pe&#xf1;a</keyname><forenames>Jose M.</forenames></author></authors><title>Reading Dependencies from Covariance Graphs</title><categories>stat.ML cs.AI math.ST stat.TH</categories><comments>Changes from v1 to v2: Minor cosmetic changes, plus the addition of
  reference (Richardson and Spirtes, 2002) in page 8. Changes from v2 to v3:
  Addition of some references; International Journal of Approximate Reasoning,
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The covariance graph (aka bi-directed graph) of a probability distribution
$p$ is the undirected graph $G$ where two nodes are adjacent iff their
corresponding random variables are marginally dependent in $p$. In this paper,
we present a graphical criterion for reading dependencies from $G$, under the
assumption that $p$ satisfies the graphoid properties as well as weak
transitivity and composition. We prove that the graphical criterion is sound
and complete in certain sense. We argue that our assumptions are not too
restrictive. For instance, all the regular Gaussian probability distributions
satisfy them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4506</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4506</id><created>2010-10-21</created><authors><author><keyname>Parshani</keyname><forenames>Roni</forenames></author><author><keyname>Rozenblat</keyname><forenames>Celine</forenames></author><author><keyname>Ietri</keyname><forenames>Daniele</forenames></author><author><keyname>Ducruet</keyname><forenames>Cesar</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author></authors><title>Inter-similarity between coupled networks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>4 pages, 3 figures</comments><doi>10.1209/0295-5075/92/68002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies have shown that a system composed from several randomly
interdependent networks is extremely vulnerable to random failure. However,
real interdependent networks are usually not randomly interdependent, rather a
pair of dependent nodes are coupled according to some regularity which we coin
inter-similarity. For example, we study a system composed from an
interdependent world wide port network and a world wide airport network and
show that well connected ports tend to couple with well connected airports. We
introduce two quantities for measuring the level of inter-similarity between
networks (i) Inter degree-degree correlation (IDDC) (ii) Inter-clustering
coefficient (ICC). We then show both by simulation models and by analyzing the
port-airport system that as the networks become more inter-similar the system
becomes significantly more robust to random failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4517</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4517</id><created>2010-10-21</created><updated>2011-04-16</updated><authors><author><keyname>Bouvrie</keyname><forenames>Jake</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques</forenames></author></authors><title>Synchronization and Redundancy: Implications for Robustness of Neural
  Learning and Decision Making</title><categories>q-bio.NC cs.NE</categories><comments>Preprint, accepted for publication in Neural Computation</comments><msc-class>92B99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning and decision making in the brain are key processes critical to
survival, and yet are processes implemented by non-ideal biological building
blocks which can impose significant error. We explore quantitatively how the
brain might cope with this inherent source of error by taking advantage of two
ubiquitous mechanisms, redundancy and synchronization. In particular we
consider a neural process whose goal is to learn a decision function by
implementing a nonlinear gradient dynamics. The dynamics, however, are assumed
to be corrupted by perturbations modeling the error which might be incurred due
to limitations of the biology, intrinsic neuronal noise, and imperfect
measurements. We show that error, and the associated uncertainty surrounding a
learned solution, can be controlled in large part by trading off
synchronization strength among multiple redundant neural systems against the
noise amplitude. The impact of the coupling between such redundant systems is
quantified by the spectrum of the network Laplacian, and we discuss the role of
network topology in synchronization and in reducing the effect of noise. A
range of situations in which the mechanisms we model arise in brain science are
discussed, and we draw attention to experimental evidence suggesting that
cortical circuits capable of implementing the computations of interest here can
be found on several scales. Finally, simulations comparing theoretical bounds
to the relevant empirical quantities show that the theoretical estimates we
derive can be tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4529</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4529</id><created>2010-10-21</created><authors><author><keyname>Marcinkowski</keyname><forenames>Jerzy</forenames></author><author><keyname>Michaliszyn</keyname><forenames>Jakub</forenames></author></authors><title>The Last Paper on the Halpern-Shoham Interval Temporal Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Halpern-Shoham logic is a modal logic of time intervals. Some effort has
been put in last ten years to classify fragments of this beautiful logic with
respect to decidability of its satisfiability problem. We contribute to this
effort by showing - what we believe is quite an unexpected result - that the
logic of subintervals, the fragment of the Halpern-Shoham where only the
operator &quot;during&quot;, or D, is allowed, is undecidable over discrete structures.
This is surprising as this logic is decidable over dense orders and its
reflexive variant is known to be decidable over discrete structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4533</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4533</id><created>2010-10-13</created><authors><author><keyname>Albert</keyname><forenames>Elvira</forenames></author><author><keyname>Arenas</keyname><forenames>Puri</forenames></author><author><keyname>Puebla</keyname><forenames>Germ&#xe1;n</forenames></author><author><keyname>Hermenegildo</keyname><forenames>Manuel</forenames></author></authors><title>Certificate size reduction in Abstraction-Carrying Code</title><categories>cs.PL</categories><comments>35 pages, 1 figure, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Carrying Code (ACC) has recently been proposed as a framework for mobile code
safety in which the code supplier provides a program together with an
abstraction (or abstract model of the program) whose validity entails
compliance with a predefined safety policy. The advantage of providing a
(fixpoint) abstraction to the code consumer is that its validity is checked in
a single pass (i.e., one iteration) of an abstract interpretation-based
checker. A main challenge to make ACC useful in practice is to reduce the size
of certificates as much as possible while at the same time not increasing
checking time. The intuitive idea is to only include in the certificate
information that the checker is unable to reproduce without iterating. We
introduce the notion of reduced certificate which characterizes the subset of
the abstraction which a checker needs in order to validate (and re-construct)
the full certificate in a single pass. Based on this notion, we instrument a
generic analysis algorithm with the necessary extensions in order to identify
the information relevant to the checker. Interestingly, the fact that the
reduced certificate omits (parts of) the abstraction has implications in the
design of the checker. We provide the sufficient conditions which allow us to
ensure that 1) if the checker succeeds in validating the certificate, then the
certificate is valid for the program (correctness) and 2) the checker will
succeed for any reduced certificate which is valid (completeness). Our approach
has been implemented and benchmarked within the ciaopp system. The experimental
results show that our proposal is able to greatly reduce the size of
certificates in practice.To appear in Theory and Practice of Logic Programming
(TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4535</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4535</id><created>2010-10-21</created><updated>2010-11-16</updated><authors><author><keyname>Hochbaum</keyname><forenames>Dorit S.</forenames></author></authors><title>Replacing spectral techniques for expander ratio, normalized cut and
  conductance by combinatorial flow algorithms</title><categories>math.OC cs.CC math.CO</categories><comments>The paper was submitted to ArXiv system by author</comments><journal-ref>Operations Research Vol. 61, No. 1, January-February 2013, pp.
  184-198</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several challenging problem in clustering, partitioning and imaging have
traditionally been solved using the &quot;spectral technique&quot;. These problems
include the normalized cut problem, the graph expander ratio problem, the
Cheeger constant problem and the conductance problem. These problems share
several common features: all seek a bipartition of a set of elements; the
problems are formulated as a form of ratio cut; the formulation as discrete
optimization is shown here to be equivalent to a quadratic ratio, sometimes
referred to as the Raleigh ratio, on discrete variables and a single sum
constraint which we call the balance or orthogonality constraint; when the
discrete nature of the variables is disregarded, the continuous relaxation is
solved by the spectral method. Indeed the spectral relaxation technique is a
dominant method providing an approximate solution to these problems.
  We propose an algorithm for these problems which involves a relaxation of the
orthogonality constraint only. This relaxation is shown here to be solved
optimally, and in strongly polynomial time, in O(mn log((n^2) / m) for a graph
on $n$ nodes and $m$ edges. The algorithm, using HPF (Hochbaum's Pseudo-Flow)
as subroutine, is efficient enough to be used to solve these bi-partitioning
problems on millions of elements and more than 300 million edges within less
than 10 minutes. It is also demonstrated, via a preliminary experimental study,
that the results of the combinatorial algorithm proposed often improve
dramatically on the quality of the results of the spectral method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4548</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4548</id><created>2010-10-21</created><updated>2011-10-22</updated><authors><author><keyname>Iyengar</keyname><forenames>Aravind</forenames></author><author><keyname>Papaleo</keyname><forenames>Marco</forenames></author><author><keyname>Siegel</keyname><forenames>Paul</forenames></author><author><keyname>Wolf</keyname><forenames>Jack</forenames></author><author><keyname>Vanelli-Coralli</keyname><forenames>Alessandro</forenames></author><author><keyname>Corazza</keyname><forenames>Giovanni</forenames></author></authors><title>Windowed Decoding of Protograph-based LDPC Convolutional Codes over
  Erasure Channels</title><categories>cs.IT math.IT</categories><comments>18 pages, 9 figures, accepted for publication in the IEEE
  Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a windowed decoding scheme for LDPC convolutional codes that is
based on the belief-propagation (BP) algorithm. We discuss the advantages of
this decoding scheme and identify certain characteristics of LDPC convolutional
code ensembles that exhibit good performance with the windowed decoder. We will
consider the performance of these ensembles and codes over erasure channels
with and without memory. We show that the structure of LDPC convolutional code
ensembles is suitable to obtain performance close to the theoretical limits
over the memoryless erasure channel, both for the BP decoder and windowed
decoding. However, the same structure imposes limitations on the performance
over erasure channels with memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4561</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4561</id><created>2010-10-21</created><updated>2011-02-06</updated><authors><author><keyname>Kiaei</keyname><forenames>Ali Akbar</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeed Bagheri</forenames></author><author><keyname>Khasteh</keyname><forenames>Seyed Hossein</forenames></author><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Samani</keyname><forenames>Ali Reza Ghatreh</forenames></author></authors><title>New S-norm and T-norm Operators for Active Learning Method</title><categories>cs.AI</categories><comments>11 pages, 20 figures, under review of SPRINGER (Fuzzy Optimization
  and Decision Making)</comments><acm-class>I.5.1; F.4.1; H.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active Learning Method (ALM) is a soft computing method used for modeling and
control based on fuzzy logic. All operators defined for fuzzy sets must serve
as either fuzzy S-norm or fuzzy T-norm. Despite being a powerful modeling
method, ALM does not possess operators which serve as S-norms and T-norms which
deprive it of a profound analytical expression/form. This paper introduces two
new operators based on morphology which satisfy the following conditions:
First, they serve as fuzzy S-norm and T-norm. Second, they satisfy Demorgans
law, so they complement each other perfectly. These operators are investigated
via three viewpoints: Mathematics, Geometry and fuzzy logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4603</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4603</id><created>2010-10-21</created><authors><author><keyname>Iyengar</keyname><forenames>Aravind R.</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author></authors><title>Write Channel Model for Bit-Patterned Media Recording</title><categories>cs.IT math.IT</categories><comments>11 pages, 12 figures, journal</comments><doi>10.1109/TMAG.2010.2080667</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new write channel model for bit-patterned media recording that
reflects the data dependence of write synchronization errors. It is shown that
this model accommodates both substitution-like errors and insertion-deletion
errors whose statistics are determined by an underlying channel state process.
We study information theoretic properties of the write channel model, including
the capacity, symmetric information rate, Markov-1 rate and the zero-error
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4609</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4609</id><created>2010-10-22</created><authors><author><keyname>Karakashian</keyname><forenames>Shant</forenames></author><author><keyname>Woodward</keyname><forenames>Robert</forenames></author><author><keyname>Choueiry</keyname><forenames>Berthe Y.</forenames></author><author><keyname>Prestwhich</keyname><forenames>Steven</forenames></author><author><keyname>Freuder</keyname><forenames>Eugene C.</forenames></author></authors><title>A Partial Taxonomy of Substitutability and Interchangeability</title><categories>cs.AI</categories><comments>18 pages, The 10th International Workshop on Symmetry in Constraint
  Satisfaction Problems (SymCon'10)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Substitutability, interchangeability and related concepts in Constraint
Programming were introduced approximately twenty years ago and have given rise
to considerable subsequent research. We survey this work, classify, and relate
the different concepts, and indicate directions for future work, in particular
with respect to making connections with research into symmetry breaking. This
paper is a condensed version of a larger work in progress.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4612</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4612</id><created>2010-10-22</created><updated>2011-07-22</updated><authors><author><keyname>Friedlander</keyname><forenames>Michael P.</forenames></author><author><keyname>Mansour</keyname><forenames>Hassan</forenames></author><author><keyname>Saab</keyname><forenames>Rayan</forenames></author><author><keyname>Yilmaz</keyname><forenames>Ozgur</forenames></author></authors><title>Recovering Compressively Sampled Signals Using Partial Support
  Information</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>22 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study recovery conditions of weighted $\ell_1$ minimization
for signal reconstruction from compressed sensing measurements when partial
support information is available. We show that if at least 50% of the (partial)
support information is accurate, then weighted $\ell_1$ minimization is stable
and robust under weaker conditions than the analogous conditions for standard
$\ell_1$ minimization. Moreover, weighted $\ell_1$ minimization provides better
bounds on the reconstruction error in terms of the measurement noise and the
compressibility of the signal to be recovered. We illustrate our results with
extensive numerical experiments on synthetic data and real audio and video
signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4639</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4639</id><created>2010-10-22</created><authors><author><keyname>Rodrigues</keyname><forenames>Antonio Wendell De Oliveira</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Guyomarch</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Menach</keyname><forenames>Yvonnick Le</forenames><affiliation>L2EP</affiliation></author><author><keyname>Dekeyser</keyname><forenames>Jean-Luc</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author></authors><title>Parallel Sparse Matrix Solver on the GPU Applied to Simulation of
  Electrical Machines</title><categories>cs.DC</categories><proxy>ccsd</proxy><journal-ref>Compumag 2009, Florianopolis : Brazil (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, several industrial applications are being ported to parallel
architectures. In fact, these platforms allow acquire more performance for
system modelling and simulation. In the electric machines area, there are many
problems which need speed-up on their solution. This paper examines the
parallelism of sparse matrix solver on the graphics processors. More
specifically, we implement the conjugate gradient technique with input matrix
stored in CSR, and Symmetric CSR and CSC formats. This method is one of the
most efficient iterative methods available for solving the finite-element basis
functions of Maxwell's equations. The GPU (Graphics Processing Unit), which is
used for its implementation, provides mechanisms to parallel the algorithm.
Thus, it increases significantly the computation speed in relation to serial
code on CPU based systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4672</identifier>
 <datestamp>2011-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4672</id><created>2010-10-22</created><updated>2011-06-16</updated><authors><author><keyname>Girard</keyname><forenames>Antoine</forenames></author></authors><title>Controller Synthesis for Safety and Reachability via Approximate
  Bisimulation</title><categories>cs.SY cs.LO math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of controller design using
approximately bisimilar abstractions with an emphasis on safety and
reachability specifications. We propose abstraction-based approaches to solve
both classes of problems. We start by synthesizing a controller for an
approximately bisimilar abstraction. Then, using a concretization procedure, we
obtain a controller for our initial system that is proved &quot;correct by design&quot;.
We provide guarantees of performance by giving estimates of the distance of the
synthesized controller to the maximal (i.e the most permissive) safety
controller or to the time-optimal reachability controller. Finally, we use the
presented techniques combined with discrete approximately bisimilar
abstractions of switched systems developed recently, for switching controller
synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4690</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4690</id><created>2010-10-22</created><authors><author><keyname>Li</keyname><forenames>Wei-Chiang</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author><author><keyname>Lin</keyname><forenames>Che</forenames></author><author><keyname>Chi</keyname><forenames>Chong-Yung</forenames></author></authors><title>A convex approximation approach to Weighted Sum Rate Maximization of
  Multiuser MISO Interference Channel under outage constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers weighted sum rate maximization of multiuser
multiple-input single-output interference channel (MISO-IFC) under outage
constraints. The outage-constrained weighted sum rate maximization problem is a
nonconvex optimization problem and is difficult to solve. While it is possible
to optimally deal with this problem in an exhaustive search manner by finding
all the Pareto-optimal rate tuples in the (discretized) outage-constrained
achievable rate region, this approach, however, suffers from a prohibitive
computational complexity and is feasible only when the number of
transmitter-receive pairs is small. In this paper, we propose a convex
optimization based approximation method for efficiently handling the
outage-constrained weighted sum rate maximization problem. The proposed
approximation method consists of solving a sequence of convex optimization
problems, and thus can be efficiently implemented by interior-point methods.
Simulation results show that the proposed method can yield near-optimal
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4702</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4702</id><created>2010-10-22</created><authors><author><keyname>Liu</keyname><forenames>D.</forenames></author><author><keyname>Wang</keyname><forenames>H.</forenames></author><author><keyname>Van Mieghem</keyname><forenames>P.</forenames></author></authors><title>Spectral Perturbation and Reconstructability of Complex Networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>9 pages, 10 figures</comments><journal-ref>Physical Review E, 81, 016101(2010)</journal-ref><doi>10.1103/PhysRevE.81.016101</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In recent years, many network perturbation techniques, such as topological
perturbations and service perturbations, were employed to study and improve the
robustness of complex networks. However, there is no general way to evaluate
the network robustness. In this paper, we propose a new global measure for a
network, the reconstructability coefficient {\theta}, defined as the maximum
number of eigenvalues that can be removed, subject to the condition that the
adjacency matrix can be reconstructed exactly. Our main finding is that a
linear scaling law, E[{\theta}]=aN, seems universal, in that it holds for all
networks that we have studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4726</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4726</id><created>2010-10-22</created><authors><author><keyname>Agarwala</keyname><forenames>Edward K.</forenames></author><author><keyname>Chiel</keyname><forenames>Hillel J.</forenames></author><author><keyname>Thomas</keyname><forenames>Peter J.</forenames></author></authors><title>Information Maximization Fails to Maximize Expected Utility in a Simple
  Foraging Model</title><categories>q-bio.OT cs.IT math.IT physics.bio-ph</categories><comments>52 pages, 14 figures</comments><msc-class>92B05</msc-class><acm-class>J.3; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information theory has explained the organization of many biological
phenomena, from the physiology of sensory receptive fields to the variability
of certain DNA sequence ensembles. Some scholars have proposed that information
should provide the central explanatory principle in biology, in the sense that
any behavioral strategy that is optimal for an organism's survival must
necessarily involve efficient information processing. We challenge this view by
providing a counterexample. We present an analytically tractable model for a
particular instance of a perception-action loop: a creature searching for a
food source confined to a one-dimensional ring world. The model incorporates
the statistical structure of the creature's world, the effects of the
creature's actions on that structure, and the creature's strategic decision
process. The model takes the form of a Markov process on an infinite
dimensional state space. To analyze it we construct an exact coarse graining
that reduces the model to a Markov process on a finite number of &quot;information
states&quot;. This technique allows us to make quantitative comparisons between the
performance of an information-theoretically optimal strategy with other
candidate strategies on a food gathering task. We find that: 1. Information
optimal search does not necessarily optimize utility (expected food gain). 2.
The rank ordering of search strategies by information performance does not
predict their ordering by expected food obtained. 3. The relative advantage of
different strategies depends on the statistical structure of the environment,
in particular the variability of motion of the source. We conclude that there
is no simple relationship between information and utility. Behavioral
optimality does not imply information efficiency, nor is there a simple
tradeoff between gaining information about a food source versus obtaining the
food itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4727</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4727</id><created>2010-10-22</created><authors><author><keyname>Bruns</keyname><forenames>Bryan</forenames></author></authors><title>Navigating the Topology of 2x2 Games: An Introductory Note on Payoff
  Families, Normalization, and Natural Order</title><categories>cs.GT</categories><comments>8 pages including 4 figures in text and 4 plates</comments><msc-class>91A05 (Primary), 91A44, 91A70 (Secondary)</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Robinson-Goforth topology of swaps in adjoining payoffs elegantly
arranges 2x2 ordinal games in accordance with important properties including
symmetry, number of dominant strategies and Nash Equilibria, and alignment of
interests. Adding payoff families based on Nash Equilibria illustrates an
additional aspect of this order and aids visualization of the topology. Making
ties through half-swaps not only creates simpler games within the topology,
but, in reverse, breaking ties shows the evolution of preferences, yielding a
natural ordering for the topology of 2x2 games with ties. An ordinal game not
only represents an equivalence class of games with real values, but also a
discrete equivalent of the normalized version of those games. The topology
provides coordinates which could be used to identify related games in a
semantic web ontology and facilitate comparative analysis of agent-based
simulations and other research in game theory, as well as charting
relationships and potential moves between games as a tool for institutional
analysis and design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4747</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4747</id><created>2010-10-22</created><updated>2011-04-22</updated><authors><author><keyname>Franceschet</keyname><forenames>Massimo</forenames></author></authors><title>Collaboration in computer science: a network science approach. Part I</title><categories>cs.SI cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Co-authorship in publications within a discipline uncovers interesting
properties of the analysed field. We represent collaboration in academic papers
of computer science in terms of differently grained networks, including those
sub-networks that emerge from conference and journal co-authorship only. We
take advantage of the network science paraphernalia to take a picture of
computer science collaboration including all papers published in the field
since 1936. We investigate typical bibliometric properties like scientific
productivity of authors and collaboration level in papers, as well as
large-scale network properties like reachability and average separation
distance among scholars, distribution of the number of scholar collaborators,
network resilience and dependence on star collaborators, network clustering,
and network assortativity by number of collaborators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4751</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4751</id><created>2010-10-22</created><authors><author><keyname>Ram&#xed;rez</keyname><forenames>Ignacio</forenames><affiliation>University of Minnesota</affiliation></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames><affiliation>University of Minnesota</affiliation></author></authors><title>Sparse coding and dictionary learning based on the MDL principle</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The power of sparse signal coding with learned dictionaries has been
demonstrated in a variety of applications and fields, from signal processing to
statistical inference and machine learning. However, the statistical properties
of these models, such as underfitting or overfitting given sets of data, are
still not well characterized in the literature. This work aims at filling this
gap by means of the Minimum Description Length (MDL) principle -- a well
established information-theoretic approach to statistical inference. The
resulting framework derives a family of efficient sparse coding and modeling
(dictionary learning) algorithms, which by virtue of the MDL principle, are
completely parameter free. Furthermore, such framework allows to incorporate
additional prior information in the model, such as Markovian dependencies, in a
natural way. We demonstrate the performance of the proposed framework with
results for image denoising and classification tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4760</identifier>
 <datestamp>2011-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4760</id><created>2010-10-22</created><updated>2011-03-09</updated><authors><author><keyname>Jancar</keyname><forenames>Petr</forenames></author></authors><title>A Short Decidability Proof for DPDA Language Equivalence via First-Order
  Grammars</title><categories>cs.FL</categories><comments>28 pages, version 4 reworks the main proof and omits the
  nondeterministic case where a problem was found by G. Senizergues</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main aim of the paper is to give a short self-contained proof of the
decidability of language equivalence for deterministic pushdown automata, which
is the famous problem solved by G. Senizergues, for which C. Stirling has
derived a primitive recursive complexity upper bound. The proof here is given
in the framework of first-order grammars, which seems to be particularly apt
for the aim. An appendix presents a modification of Stirling's approach,
yielding a complexity bound of the form tetr(2,g(n)) where tetr is the
(nonelementary) operator of iterated exponentiation (tetration) and g is an
elementary function of the input size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4784</identifier>
 <datestamp>2010-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4784</id><created>2010-10-22</created><authors><author><keyname>&#x17d;liobait&#x117;</keyname><forenames>Indr&#x117;</forenames></author></authors><title>Learning under Concept Drift: an Overview</title><categories>cs.AI</categories><comments>Technical report, Vilnius University, 2009 techniques, related areas,
  applications</comments><report-no>2009</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concept drift refers to a non stationary learning problem over time. The
training and the application data often mismatch in real life problems. In this
report we present a context of concept drift problem 1. We focus on the issues
relevant to adaptive training set formation. We present the framework and
terminology, and formulate a global picture of concept drift learners design.
We start with formalizing the framework for the concept drifting data in
Section 1. In Section 2 we discuss the adaptivity mechanisms of the concept
drift learners. In Section 3 we overview the principle mechanisms of concept
drift learners. In this chapter we give a general picture of the available
algorithms and categorize them based on their properties. Section 5 discusses
the related research fields and Section 5 groups and presents major concept
drift applications. This report is intended to give a bird's view of concept
drift research field, provide a context of the research and position it within
broad spectrum of research fields and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4786</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4786</id><created>2010-10-22</created><updated>2010-10-26</updated><authors><author><keyname>Cristani</keyname><forenames>Matteo</forenames></author><author><keyname>Karafili</keyname><forenames>Erisa</forenames></author><author><keyname>Vigan&#xf2;</keyname><forenames>Luca</forenames></author></authors><title>Blocking Underhand Attacks by Hidden Coalitions (Extended Version)</title><categories>cs.CR cs.LO cs.MA</categories><comments>13 pages, short version in Proceedings of ICAART 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similar to what happens between humans in the real world, in open multi-agent
systems distributed over the Internet, such as online social networks or wiki
technologies, agents often form coalitions by agreeing to act as a whole in
order to achieve certain common goals. However, agent coalitions are not always
a desirable feature of a system, as malicious or corrupt agents may collaborate
in order to subvert or attack the system. In this paper, we consider the
problem of hidden coalitions, whose existence and the purposes they aim to
achieve are not known to the system, and which carry out so-called underhand
attacks. We give a first approach to hidden coalitions by introducing a
deterministic method that blocks the actions of potentially dangerous agents,
i.e. possibly belonging to such coalitions. We also give a non-deterministic
version of this method that blocks the smallest set of potentially dangerous
agents. We calculate the computational cost of our two blocking methods, and
prove their soundness and completeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4812</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4812</id><created>2010-10-22</created><authors><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author><author><keyname>Vasilakos</keyname><forenames>Athanasios</forenames></author></authors><title>Polynomial Bottleneck Congestion Games with Optimal Price of Anarchy</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study {\em bottleneck congestion games} where the social cost is
determined by the worst congestion of any resource. These games directly relate
to network routing problems and also job-shop scheduling problems. In typical
bottleneck congestion games, the utility costs of the players are determined by
the worst congested resources that they use. However, the resulting Nash
equilibria are inefficient, since the price of anarchy is proportional on the
number of resources which can be high. Here we show that we can get smaller
price of anarchy with the bottleneck social cost metric. We introduce the {\em
polynomial bottleneck games} where the utility costs of the players are
polynomial functions of the congestion of the resources that they use. In
particular, the delay function for any resource $r$ is $C_{r}^\M$, where $C_r$
is the congestion measured as the number of players that use $r$, and $\M \geq
1$ is an integer constant that defines the degree of the polynomial. The
utility cost of a player is the sum of the individual delays of the resources
that it uses. The social cost of the game remains the same, namely, it is the
worst bottleneck resource congestion: $\max_{r} C_r$. We show that polynomial
bottleneck games are very efficient and give price of anarchy
$O(|R|^{1/(\M+1)})$, where $R$ is the set of resources. This price of anarchy
is tight, since we demonstrate a game with price of anarchy
$\Omega(|R|^{1/(\M+1)})$, for any $\M \geq 1$. We obtain our tight bounds by
using two proof techniques: {\em transformation}, which we use to convert
arbitrary games to simpler games, and {\em expansion}, which we use to bound
the price of anarchy in a simpler game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4813</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4813</id><created>2010-10-22</created><authors><author><keyname>Berriman</keyname><forenames>G. Bruce</forenames></author><author><keyname>Deelman</keyname><forenames>Ewa</forenames></author><author><keyname>Juve</keyname><forenames>Gideon</forenames></author><author><keyname>Regelson</keyname><forenames>Moira</forenames></author><author><keyname>Plavchan</keyname><forenames>Peter</forenames></author></authors><title>The Application of Cloud Computing to Astronomy: A Study of Cost and
  Performance</title><categories>astro-ph.IM cs.DC</categories><comments>7 pages, accepted for publication in the Proceedings of the e-Science
  in Astronomy Conference (Brisbane, Australia, December 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is a powerful new technology that is widely used in the
business world. Recently, we have been investigating the benefits it offers to
scientific computing. We have used three workflow applications to compare the
performance of processing data on the Amazon EC2 cloud with the performance on
the Abe high-performance cluster at the National Center for Supercomputing
Applications (NCSA). We show that the Amazon EC2 cloud offers better
performance and value for processor- and memory-limited applications than for
I/O-bound applications. We provide an example of how the cloud is well suited
to the generation of a science product: an atlas of periodograms for the
210,000 light curves released by the NASA Kepler Mission. This atlas will
support the identification of periodic signals, including those due to
transiting exoplanets, in the Kepler data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4816</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4816</id><created>2010-10-22</created><authors><author><keyname>Aileni</keyname><forenames>Anvesh</forenames></author></authors><title>Cluster based Key Management in Wireless Sensor Networks</title><categories>cs.CR</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks consist of sensor nodes with limited computational
and communication capabilities. In this paper, the whole network of sensor
nodes is divided into clusters based on their physical locations. In addition,
efficient ways of key distribution among the nodes within the cluster and among
controllers of each cluster are discussed. Also, inter and intra cluster
communications are presented in detail. The security of the entire network
through efficient key management by taking into consideration the network's
power capabilities is discussed. A graphical representation of the simulation
on the scheme is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4820</identifier>
 <datestamp>2012-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4820</id><created>2010-10-22</created><updated>2012-05-17</updated><authors><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author><author><keyname>Meyn</keyname><forenames>Sean P.</forenames></author></authors><title>Random-Time, State-Dependent Stochastic Drift for Markov Chains and
  Application to Stochastic Stabilization Over Erasure Channels</title><categories>math.OC cs.IT cs.SY math.IT</categories><comments>To appear in IEEE Transactions on Automatic Control</comments><msc-class>93E03, 94A15, 60J05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that state-dependent, multi-step Lyapunov bounds lead to greatly
simplified verification theorems for stability for large classes of Markov
chain models. This is one component of the &quot;fluid model&quot; approach to stability
of stochastic networks. In this paper we extend the general theory to
randomized multi-step Lyapunov theory to obtain criteria for stability and
steady-state performance bounds, such as finite moments.
  These results are applied to a remote stabilization problem, in which a
controller receives measurements from an erasure channel with limited capacity.
Based on the general results in the paper it is shown that stability of the
closed loop system is assured provided that the channel capacity is greater
than the logarithm of the unstable eigenvalue, plus an additional correction
term. The existence of a finite second moment in steady-state is established
under additional conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4822</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4822</id><created>2010-10-22</created><authors><author><keyname>Juve</keyname><forenames>Gideon</forenames></author><author><keyname>Deelman</keyname><forenames>Ewa</forenames></author><author><keyname>Vahi</keyname><forenames>Karan</forenames></author><author><keyname>Mehta</keyname><forenames>Gaurang</forenames></author><author><keyname>Berriman</keyname><forenames>Bruce</forenames></author><author><keyname>Berman</keyname><forenames>Benjamin P.</forenames></author><author><keyname>Maechling</keyname><forenames>Phil</forenames></author></authors><title>Data Sharing Options for Scientific Workflows on Amazon EC2</title><categories>astro-ph.IM cs.DC</categories><comments>9 pages, 7 figures. Accepted for publication in the Proceedings of
  Supercomputing 10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient data management is a key component in achieving good performance
for scientific workflows in distributed environments. Workflow applications
typically communicate data between tasks using files. When tasks are
distributed, these files are either transferred from one computational node to
another, or accessed through a shared storage system. In grids and clusters,
workflow data is often stored on network and parallel file systems. In this
paper we investigate some of the ways in which data can be managed for
workflows in the cloud. We ran experiments using three typical workflow
applications on Amazon's EC2. We discuss the various storage and file systems
we used, describe the issues and problems we encountered deploying them on EC2,
and analyze the resulting performance and cost of the workflows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4824</identifier>
 <datestamp>2012-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4824</id><created>2010-10-22</created><updated>2012-08-23</updated><authors><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author></authors><title>On Optimal Causal Coding of Partially Observed Markov Sources in Single
  and Multi-Terminal Settings</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><msc-class>94A15, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal causal coding of a partially observed Markov process is studied,
where the cost to be minimized is a bounded, non-negative, additive, measurable
single-letter function of the source and the receiver output. A structural
result is obtained extending Witsenhausen's and Walrand-Varaiya's structural
results on optimal real-time coders to a partially observed setting. The
decentralized (multi-terminal) setup is also considered. For the case where the
source is an i.i.d. process, it is shown that the optimal decentralized causal
coding of correlated observations problem admits a solution which is
memoryless. For Markov sources, a counterexample to a natural separation
conjecture is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4830</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4830</id><created>2010-10-22</created><updated>2012-01-03</updated><authors><author><keyname>Lawrence</keyname><forenames>Neil D.</forenames></author></authors><title>A Unifying Probabilistic Perspective for Spectral Dimensionality
  Reduction: Insights and New Models</title><categories>cs.AI</categories><comments>26 pages,11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new perspective on spectral dimensionality reduction which
views these methods as Gaussian Markov random fields (GRFs). Our unifying
perspective is based on the maximum entropy principle which is in turn inspired
by maximum variance unfolding. The resulting model, which we call maximum
entropy unfolding (MEU) is a nonlinear generalization of principal component
analysis. We relate the model to Laplacian eigenmaps and isomap. We show that
parameter fitting in the locally linear embedding (LLE) is approximate maximum
likelihood MEU. We introduce a variant of LLE that performs maximum likelihood
exactly: Acyclic LLE (ALLE). We show that MEU and ALLE are competitive with the
leading spectral approaches on a robot navigation visualization and a human
motion capture data set. Finally the maximum likelihood perspective allows us
to introduce a new approach to dimensionality reduction based on L1
regularization of the Gaussian random field via the graphical lasso.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4843</identifier>
 <datestamp>2010-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4843</id><created>2010-10-23</created><updated>2010-12-07</updated><authors><author><keyname>Brescia</keyname><forenames>Massimo</forenames></author><author><keyname>Longo</keyname><forenames>Giuseppe</forenames></author><author><keyname>Djorgovski</keyname><forenames>George S.</forenames></author><author><keyname>Cavuoti</keyname><forenames>Stefano</forenames></author><author><keyname>D'Abrusco</keyname><forenames>Raffaele</forenames></author><author><keyname>Donalek</keyname><forenames>Ciro</forenames></author><author><keyname>Di Guido</keyname><forenames>Alessandro</forenames></author><author><keyname>Fiore</keyname><forenames>Michelangelo</forenames></author><author><keyname>Garofalo</keyname><forenames>Mauro</forenames></author><author><keyname>Laurino</keyname><forenames>Omar</forenames></author><author><keyname>Mahabal</keyname><forenames>Ashish</forenames></author><author><keyname>Manna</keyname><forenames>Francesco</forenames></author><author><keyname>Nocella</keyname><forenames>Alfonso</forenames></author><author><keyname>d'Angelo</keyname><forenames>Giovanni</forenames></author><author><keyname>Paolillo</keyname><forenames>Maurizio</forenames></author></authors><title>DAME: A Web Oriented Infrastructure for Scientific Data Mining &amp;
  Exploration</title><categories>astro-ph.IM astro-ph.GA cs.DB cs.DC cs.SE</categories><comments>16 pages, 9 figures, software available at
  http://voneural.na.infn.it/beta_info.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, many scientific areas share the same need of being able to deal
with massive and distributed datasets and to perform on them complex knowledge
extraction tasks. This simple consideration is behind the international efforts
to build virtual organizations such as, for instance, the Virtual Observatory
(VObs). DAME (DAta Mining &amp; Exploration) is an innovative, general purpose,
Web-based, VObs compliant, distributed data mining infrastructure specialized
in Massive Data Sets exploration with machine learning methods. Initially fine
tuned to deal with astronomical data only, DAME has evolved in a general
purpose platform which has found applications also in other domains of human
endeavor. We present the products and a short outline of a science case,
together with a detailed description of main features available in the beta
release of the web application now released.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4845</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4845</id><created>2010-10-23</created><authors><author><keyname>Bernardo</keyname><forenames>Danilo Valeros</forenames></author><author><keyname>Hoang</keyname><forenames>Doan B</forenames></author></authors><title>Securing data transfer in the cloud through introducing identification
  packet and UDT-authentication option field: a characterization</title><categories>cs.NI cs.CR</categories><comments>17 pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.2, No.4, October 2010</journal-ref><doi>10.5121/ijnsa.2010.2402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of various technologies has since pushed researchers to develop
new protocols that support high density data transmissions in Wide Area
Networks. Many of these protocols are TCP protocol variants, which have
demonstrated better performance in simulation and several limited network
experiments but have limited practical applications because of implementation
and installation difficulties. On the other hand, users who need to transfer
bulk data (e.g., in grid/cloud computing) usually turn to application level
solutions where these variants do not fair well. Among protocols considered in
the application level solutions are UDP-based protocols, such as UDT (UDP-based
Data Transport Protocol) for cloud /grid computing. Despite the promising
development of protocols like UDT, what remains to be a major challenge that
current and future network designers face is to achieve survivability and
security of data and networks. Our previous research surveyed various security
methodologies which led to the development of a framework for UDT. In this
paper we present lowerlevel security by introducing an Identity Packet (IP) and
Authentication Option (AO) for UDT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4850</identifier>
 <datestamp>2010-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4850</id><created>2010-10-23</created><updated>2010-11-30</updated><authors><author><keyname>Nedjar</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIF</affiliation></author><author><keyname>Pesci</keyname><forenames>Fabien</forenames><affiliation>LIF</affiliation></author><author><keyname>Lakhal</keyname><forenames>Lotfi</forenames><affiliation>LIF</affiliation></author><author><keyname>Cicchetti</keyname><forenames>Rosine</forenames><affiliation>LIF</affiliation></author></authors><title>Treillis des concepts skylines : Analyse multidimensionnelle des
  skylines fond\'ee sur les ensembles en accord</title><categories>cs.DB</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The skyline concept has been introduced in order to exhibit the best objects
according to all the criterion combinations and makes it possible to analyse
the relationships between skyline objects. Like the data cube, the skycube is
so voluminous that reduction approaches are really necessary. In this paper, we
define an approach which partially materializes the skycube. The underlying
idea is to discard from the representation the skycuboids which can be computed
again the most easily. To meet this reduction objective, we characterize a
formal framework: the agree concept lattice. From this structure, we derive the
skyline concept lattice which is one of its constrained instances. The strong
points of our approach are: (i) it is attribute oriented; (ii) it provides a
boundary for the number of lattice nodes; (iii) it facilitates the navigation
within the Skycuboids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4854</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4854</id><created>2010-10-23</created><authors><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Implicit and explicit communication in decentralized control</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>Presented at Allerton'10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been substantial progress recently in understanding toy problems of
purely implicit signaling. These are problems where the source and the channel
are implicit -- the message is generated endogenously by the system, and the
plant itself is used as a channel. In this paper, we explore how implicit and
explicit communication can be used synergistically to reduce control costs. The
setting is an extension of Witsenhausen's counterexample where a rate-limited
external channel connects the two controllers. Using a semi-deterministic
version of the problem, we arrive at a binning-based strategy that can
outperform the best known strategies by an arbitrarily large factor. We also
show that our binning-based strategy attains within a constant factor of the
optimal cost for an asymptotically infinite-length version of the problem
uniformly over all problem parameters and all rates on the external channel.
For the scalar case, although our results yield approximate optimality for each
fixed rate, we are unable to prove approximately-optimality uniformly over all
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4855</identifier>
 <datestamp>2011-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4855</id><created>2010-10-23</created><updated>2011-02-16</updated><authors><author><keyname>Grover</keyname><forenames>Pulkit</forenames></author><author><keyname>Woyach</keyname><forenames>Kristen Ann</forenames></author><author><keyname>Sahai</keyname><forenames>Anant</forenames></author></authors><title>Towards a communication-theoretic understanding of system-level power
  consumption</title><categories>cs.IT cs.CC math.IT</categories><comments>24 pages, 13 figures, revision of our submission to JSAC Special
  issue on energy-efficient wireless communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional communication theory focuses on minimizing transmit power.
However, communication links are increasingly operating at shorter ranges where
transmit power can be significantly smaller than the power consumed in
decoding. This paper models the required decoding power and investigates the
minimization of total system power from two complementary perspectives.
  First, an isolated point-to-point link is considered. Using new lower bounds
on the complexity of message-passing decoding, lower bounds are derived on
decoding power. These bounds show that 1) there is a fundamental tradeoff
between transmit and decoding power; 2) unlike the implications of the
traditional &quot;waterfall&quot; curve which focuses on transmit power, the total power
must diverge to infinity as error probability goes to zero; 3) Regular LDPCs,
and not their known capacity-achieving irregular counterparts, can be shown to
be power order optimal in some cases; and 4) the optimizing transmit power is
bounded away from the Shannon limit.
  Second, we consider a collection of links. When systems both generate and
face interference, coding allows a system to support a higher density of
transmitter-receiver pairs (assuming interference is treated as noise).
However, at low densities, uncoded transmission may be more power-efficient in
some cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4858</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4858</id><created>2010-10-23</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Ansari</keyname><forenames>Nirwan</forenames></author><author><keyname>Walid</keyname><forenames>Anwar I.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>S-MATE: Secure Coding-based Multipath Adaptive Traffic Engineering</title><categories>cs.NI cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been several approaches to provisioning traffic between core
network nodes in Internet Service Provider (ISP) networks. Such approaches aim
to minimize network delay, increase network capacity, and enhance network
security services. MATE (Multipath Adaptive Traffic Engineering) protocol has
been proposed for multipath adaptive traffic engineering between an ingress
node (source) and an egress node (destination). Its novel idea is to avoid
network congestion and attacks that might exist in edge and node disjoint paths
between two core network nodes.
  This paper builds an adaptive, robust, and reliable traffic engineering
scheme for better performance of communication network operations. This will
also provision quality of service (QoS) and protection of traffic engineering
to maximize network efficiency. Specifically, we present a new approach, S-MATE
(secure MATE) is developed to protect the network traffic between two core
nodes (routers or switches) in a cloud network. S-MATE secures against a single
link attack/failure by adding redundancy in one of the operational paths
between the sender and receiver. The proposed scheme can be built to secure
core networks such as optical and IP networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4865</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4865</id><created>2010-10-23</created><authors><author><keyname>Zhao</keyname><forenames>Qingchun</forenames></author><author><keyname>Yin</keyname><forenames>Hongxi</forenames></author></authors><title>Suggested Rules for Designing Secure Communication Systems Utilizing
  Chaotic Lasers: A Survey</title><categories>cs.CR</categories><comments>5 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Chaotic communications based on semiconductor lasers have aroused great
research interest since 1990s. Physical-layer encryption using chaotic lasers
is an alternative to transmit message rapidly and confidentially. There are
some practical devices and setups for optical chaotic communications, which are
intuitively considered to be secure. However, there is lack of a set of
security evaluation rules for these communication setups. According to the
recent literature, we summarize several criteria for optical chaotic
communications to evaluate the security and point out some methods to enhance
the security. These criteria and suggested rules are very helpful in designing
secure communication systems using chaotic lasers. Finally we propose some
possible hot topics on security analysis of optical chaotic communications in
future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4876</identifier>
 <datestamp>2011-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4876</id><created>2010-10-23</created><updated>2011-02-24</updated><authors><author><keyname>Antepli</keyname><forenames>Mehmet Akif</forenames></author><author><keyname>Uysal-Biyikoglu</keyname><forenames>Elif</forenames></author><author><keyname>Erkal</keyname><forenames>Hakan</forenames></author></authors><title>Optimal Packet Scheduling on an Energy Harvesting Broadcast Link</title><categories>cs.IT math.IT</categories><comments>25 pages, 6 figures, added lemma and theorems, added reference,
  corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimization of transmission completion time for a given number of bits
per user in an energy harvesting communication system, where energy harvesting
instants are known in an offline manner is considered. An achievable rate
region with structural properties satisfied by the 2-user AWGN Broadcast
Channel capacity region is assumed. It is shown that even though all data are
available at the beginning, a non-negative amount of energy from each energy
harvest is deferred for later use such that the transmit power starts at its
lowest value and rises as time progresses. The optimal scheduler ends the
transmission to both users at the same time. Exploiting the special structure
in the problem, the iterative offline algorithm, FlowRight, from earlier
literature, is adapted and proved to solve this problem. The solution has
polynomial complexity in the number of harvests used, and is observed to
converge quickly on numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4887</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4887</id><created>2010-10-23</created><authors><author><keyname>Channa</keyname><forenames>Muhammad Ibrahim</forenames></author><author><keyname>Ahmed</keyname><forenames>Kazi M.</forenames></author></authors><title>Emergency Response Communications and Associated Security Challenges</title><categories>cs.NI</categories><comments>14 pages and 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The natural or man-made disaster demands an efficient communication and
coordination among first responders to save life and other community resources.
Normally, the traditional communication infrastructures such as land line or
cellular networks are damaged and don't provide adequate communication services
to first responders for exchanging emergency related information. Wireless ad
hoc networks such as mobile ad hoc networks, wireless sensor networks and
wireless mesh networks are the promising alternatives in such type of
situations. The security requirements for emergency response communications
include privacy, data integrity, authentication, key management, access control
and availability. Various ad hoc communication frameworks have been proposed
for emergency response situations. The majority of the proposed frameworks
don't provide adequate security services for reliable and secure information
exchange. This paper presents a survey of the proposed emergency response
communication frameworks and the potential security services required by them
to provide reliable and secure information exchange during emergency
situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4891</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4891</id><created>2010-10-23</created><authors><author><keyname>Ramachandran</keyname><forenames>Prabhu</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author></authors><title>Mayavi: a package for 3D visualization of scientific data</title><categories>cs.SE</categories><proxy>ccsd</proxy><journal-ref>Computing and Science and Engineering 13, 2 (2011) 40-51</journal-ref><doi>10.1109/MCSE.2011.35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mayavi is an open-source, general-purpose, 3D scientific visualization
package. It seeks to provide easy and interactive tools for data visualization
that fit with the scientific user's workflow. For this purpose, Mayavi provides
several entry points: a full-blown interactive application; a Python library
with both a MATLAB-like interface focused on easy scripting and a feature-rich
object hierarchy; widgets associated with these objects for assembling in a
domain-specific application, and plugins that work with a general purpose
application-building framework. In this article, we present an overview of the
various features of Mayavi, we then provide insight on the design and
engineering decisions made in implementing Mayavi, and finally discuss a few
novel applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4893</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4893</id><created>2010-10-23</created><authors><author><keyname>Sprechmann</keyname><forenames>Pablo</forenames></author><author><keyname>Ramirez</keyname><forenames>Ignacio</forenames></author><author><keyname>Cancela</keyname><forenames>Pablo</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Collaborative Sources Identification in Mixed Signals via Hierarchical
  Sparse Modeling</title><categories>cs.CV</categories><comments>4 pages, 3 figures, submitted to ICASSP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A collaborative framework for detecting the different sources in mixed
signals is presented in this paper. The approach is based on C-HiLasso, a
convex collaborative hierarchical sparse model, and proceeds as follows. First,
we build a structured dictionary for mixed signals by concatenating a set of
sub-dictionaries, each one of them learned to sparsely model one of a set of
possible classes. Then, the coding of the mixed signal is performed by
efficiently solving a convex optimization problem that combines standard
sparsity with group and collaborative sparsity. The present sources are
identified by looking at the sub-dictionaries automatically selected in the
coding. The collaborative filtering in C-HiLasso takes advantage of the
temporal/spatial redundancy in the mixed signals, letting collections of
samples collaborate in identifying the classes, while allowing individual
samples to have different internal sparse representations. This collaboration
is critical to further stabilize the sparse representation of signals, in
particular the class/sub-dictionary selection. The internal sparsity inside the
sub-dictionaries, as naturally incorporated by the hierarchical aspects of
C-HiLasso, is critical to make the model consistent with the essence of the
sub-dictionaries that have been trained for sparse representation of each
individual class. We present applications from speaker and instrument
identification and texture separation. In the case of audio signals, we use
sparse modeling to describe the short-term power spectrum envelopes of harmonic
sounds. The proposed pitch independent method automatically detects the number
of sources on a recording.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4911</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4911</id><created>2010-10-23</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>The Capacity Region of the 3-User Gaussian Interference Channel with
  Mixed Strong-Very Strong Interference</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the 3-user Gaussian interference channel and provide an outer
bound on its capacity region. Under some conditions, which we call the mixed
strong-very strong interference conditions, this outer bound is achievable.
These conditions correspond to the case where at each receiver, one transmitter
is causing strong interference and the other is causing very strong
interference. Therefore, we characterize the capacity region of the 3-user
interference channel with mixed strong-very strong interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4920</identifier>
 <datestamp>2015-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4920</id><created>2010-10-23</created><updated>2015-12-11</updated><authors><author><keyname>Hajiaghayi</keyname><forenames>Mahdi</forenames></author><author><keyname>Dong</keyname><forenames>Min</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>Jointly Optimal Channel Pairing and Power Allocation for Multichannel
  Multihop Relaying</title><categories>cs.IT cs.NI cs.PF math.IT</categories><comments>15 pages. IEEE Transactions on Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 59, pp.4998-5012,
  October 2011</journal-ref><doi>10.1109/TSP.2011.2161475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of channel pairing and power allocation in a
multichannel multihop relay network to enhance the end-to-end data rate. Both
amplify-and-forward (AF) and decode-and-forward (DF) relaying strategies are
considered. Given fixed power allocation to the channels, we show that channel
pairing over multiple hops can be decomposed into independent pairing problems
at each relay, and a sorted-SNR channel pairing strategy is sum-rate optimal,
where each relay pairs its incoming and outgoing channels by their SNR order.
For the joint optimization of channel pairing and power allocation under both
total and individual power constraints, we show that the problem can be
decoupled into two subproblems solved separately. This separation principle is
established by observing the equivalence between sorting SNRs and sorting
channel gains in the jointly optimal solution. It significantly reduces the
computational complexity in finding the jointly optimal solution. It follows
that the channel pairing problem in joint optimization can be again decomposed
into independent pairing problems at each relay based on sorted channel gains.
The solution for optimizing power allocation for DF relaying is also provided,
as well as an asymptotically optimal solution for AF relaying. Numerical
results are provided to demonstrate substantial performance gain of the jointly
optimal solution over some suboptimal alternatives. It is also observed that
more gain is obtained from optimal channel pairing than optimal power
allocation through judiciously exploiting the variation among multiple
channels. Impact of the variation of channel gain, the number of channels, and
the number of hops on the performance gain is also studied through numerical
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4925</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4925</id><created>2010-10-24</created><authors><author><keyname>Chen</keyname><forenames>Victor</forenames></author><author><keyname>Sudan</keyname><forenames>Madhu</forenames></author><author><keyname>Xie</keyname><forenames>Ning</forenames></author></authors><title>Property Testing via Set-Theoretic Operations</title><categories>cs.DS</categories><comments>Appears in ICS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two testable properties $\mathcal{P}_{1}$ and $\mathcal{P}_{2}$, under
what conditions are the union, intersection or set-difference of these two
properties also testable? We initiate a systematic study of these basic
set-theoretic operations in the context of property testing. As an application,
we give a conceptually different proof that linearity is testable, albeit with
much worse query complexity. Furthermore, for the problem of testing
disjunction of linear functions, which was previously known to be one-sided
testable with a super-polynomial query complexity, we give an improved analysis
and show it has query complexity $O(1/\eps^2)$, where $\eps$ is the distance
parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4934</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4934</id><created>2010-10-24</created><authors><author><keyname>Miszczak</keyname><forenames>Jaros&#x142;aw Adam</forenames></author><author><keyname>Sobota-Miszczak</keyname><forenames>Izabela</forenames></author></authors><title>Design-on-demand or how to create a target-oriented social web-site</title><categories>cs.CY cs.HC</categories><comments>12 pages, no figures</comments><acm-class>H.3.5; I.5.2; K.6.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an informal methodology for developing on-line applications,
which is, to some extent, complementary to the Web 2.0 aspects of web
development. The presented methodology is suitable for developing low-cost and
non-cost web sites targeted at medium-sized communities. We present basic
building blocks used in the described strategy. To achieve a better
understanding of the discussed concepts we comment on their application during
the realization of two web projects. We focus on the role of community-driven
development, which is crucial for projects of the discussed type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4951</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4951</id><created>2010-10-24</created><updated>2012-07-19</updated><authors><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Manzuri-Shalmani</keyname><forenames>Mohammad T.</forenames></author><author><keyname>safayani</keyname><forenames>Meharn</forenames></author></authors><title>Local Component Analysis for Nonparametric Bayes Classifier</title><categories>cs.CV cs.LG</categories><comments>This paper has been withdrawn by the author due to an error in
  experimental results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The decision boundaries of Bayes classifier are optimal because they lead to
maximum probability of correct decision. It means if we knew the prior
probabilities and the class-conditional densities, we could design a classifier
which gives the lowest probability of error. However, in classification based
on nonparametric density estimation methods such as Parzen windows, the
decision regions depend on the choice of parameters such as window width.
Moreover, these methods suffer from curse of dimensionality of the feature
space and small sample size problem which severely restricts their practical
applications. In this paper, we address these problems by introducing a novel
dimension reduction and classification method based on local component
analysis. In this method, by adopting an iterative cross-validation algorithm,
we simultaneously estimate the optimal transformation matrices (for dimension
reduction) and classifier parameters based on local information. The proposed
method can classify the data with complicated boundary and also alleviate the
course of dimensionality dilemma. Experiments on real data show the superiority
of the proposed algorithm in term of classification accuracies for pattern
classification applications like age, facial expression and character
recognition. Keywords: Bayes classifier, curse of dimensionality dilemma,
Parzen window, pattern classification, subspace learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4952</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4952</id><created>2010-10-24</created><authors><author><keyname>Simalango</keyname><forenames>Mikael Fernandus</forenames></author><author><keyname>Kang</keyname><forenames>Mun-Young</forenames></author><author><keyname>Oh</keyname><forenames>Sangyoon</forenames></author></authors><title>Towards Constraint-based High Performance Cloud System in the Process of
  Cloud Computing Adoption in an Organization</title><categories>cs.DC</categories><comments>11 pages, 5 figures; Proceedings of 1st KIITA Conference on Smart
  Enterprise, Seoul, South Korea, October 21st, 2010, pp. 45-55</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cloud computing is penetrating into various domains and environments, from
theoretical computer science to economy, from marketing hype to educational
curriculum and from R&amp;D lab to enterprise IT infrastructure. Yet, the currently
developing state of cloud computing leaves several issues to address and also
affects cloud computing adoption by organizations. In this paper, we explain
how the transition into the cloud can occur in an organization and describe the
mechanism for transforming legacy infrastructure into a virtual
infrastructure-based cloud. We describe the state of the art of infrastructural
cloud, which is essential in the decision making on cloud adoption, and
highlight the challenges that can limit the scale and speed of the adoption. We
then suggest a strategic framework for designing a high performance cloud
system. This framework is applicable when transformation cloudbased deployment
model collides with some constraints. We give an example of the implementation
of the framework in a design of a budget-constrained high availability cloud
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4953</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4953</id><created>2010-10-24</created><authors><author><keyname>Bandyopadhyay</keyname><forenames>Soumyadip</forenames></author></authors><title>Equivalence Checking in Embedded Systems Design Verification using PRES+
  model</title><categories>cs.LO cs.FL</categories><comments>i want to replace the previous report, arXiv:1007.2131, by this
  report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we focus on some aspects related to modeling and formal
verification of embedded systems. Many models have been proposed to represent
embedded systems. These models encompass a broad range of styles,
characteristics, and application domains and include the extensions of finite
state machines, data flow graphs, communication processes and Petri nets. In
this report, we have used a PRES+ model (Petri net based Representation for
Embedded Systems) as an extension of classical Petri net model that captures
concurrency, timing behaviour of embedded systems; it allows systems to be
representative in different levels of abstraction and improves expressiveness
by allowing the token to carry information. Modeling using PRES+, as discussed
above, may be convenient for specifying the input behaviour because it supports
concurrency. However, there is no equivalence checking method reported in the
literature for PRES+ models to the best of our knowledge. In contrast,
equivalence checking of FSMD models exist. As a first step, therefore, we seek
to devise an algorithm to translate PRES+ models to FSMD models and we seek to
hand execute our algorithm on a real life example and we have to translate two
versions of PRES+ models to FSMD models. Then using existing equivalence
checker we have checked the equivalence between two FSMD models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4965</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4965</id><created>2010-10-24</created><authors><author><keyname>Ohara</keyname><forenames>Atsumi</forenames></author><author><keyname>Matsuzoe</keyname><forenames>Hiroshi</forenames></author><author><keyname>Amari</keyname><forenames>Shun-ichi</forenames></author></authors><title>Dually flat structure with escort probability and its application to
  alpha-Voronoi diagrams</title><categories>cond-mat.stat-mech cs.IT math.DG math.IT</categories><comments>Several results in this paper can be found in the conference paper
  [36] without complete proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies geometrical structure of the manifold of escort
probability distributions and shows its new applicability to information
science. In order to realize escort probabilities we use a conformal
transformation that flattens so-called alpha-geometry of the space of discrete
probability distributions, which well characterizes nonadditive statistics on
the space. As a result escort probabilities are proved to be flat coordinates
of the usual probabilities for the derived dually flat structure. Finally, we
demonstrate that escort probabilities with the new structure admits a simple
algorithm to compute Voronoi diagrams and centroids with respect to
alpha-divergences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4971</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4971</id><created>2010-10-24</created><authors><author><keyname>Cho</keyname><forenames>Won-kuk</forenames></author><author><keyname>Goh</keyname><forenames>K. -I.</forenames></author><author><keyname>Kim</keyname><forenames>I. -M.</forenames></author></authors><title>Correlated couplings and robustness of coupled networks</title><categories>physics.data-an cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>4 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most real-world complex systems can be modelled by coupled networks with
multiple layers. How and to what extent the pattern of couplings between
network layers may influence the interlaced structure and function of coupled
networks are not clearly understood. Here we study the impact of correlated
inter-layer couplings on the network robustness of coupled networks using
percolation concept. We found that the positive correlated inter-layer coupling
enhaces network robustness in the sense that it lowers the percolation
threshold of the interlaced network than the negative correlated coupling case.
At the same time, however, positive inter-layer correlation leads to smaller
giant component size in the well-connected region, suggesting potential
disadvantage for network connectivity, as demonstrated also with some
real-world coupled network structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4980</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4980</id><created>2010-10-24</created><authors><author><keyname>Zeng</keyname><forenames>Meng</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>On Design of Collaborative Beamforming for Two-Way Relay Networks</title><categories>cs.IT math.IT</categories><comments>new version of the previously posted, single column double spacing,
  24 pages</comments><doi>10.1109/TSP.2011.2107906</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-way relay network, where two source nodes, S1 and S2,
exchange information through a cluster of relay nodes. The relay nodes receive
the sum signal from S1 and S2 in the first time slot. In the second time slot,
each relay node multiplies its received signal by a complex coefficient and
retransmits the signal to the two source nodes, which leads to a collaborative
two-way beamforming system. By applying the principle of analog network coding,
each receiver at S1 and S2 cancels the &quot;self-interference&quot; in the received
signal from the relay cluster and decodes the message. This paper studies the
2-dimensional achievable rate region for such a two-way relay network with
collaborative beamforming. With different assumptions of channel reciprocity
between the source-relay and relay-source channels, the achievable rate region
is characterized under two setups. First, with reciprocal channels, we
investigate the achievable rate regions when the relay cluster is subject to a
sum-power constraint or individual-power constraints. We show that the optimal
beamforming vectors obtained from solving the weighted sum inverse-SNR
minimization (WSISMin) problems are sufficient to characterize the
corresponding achievable rate region. Furthermore, we derive the closed form
solutions for those optimal beamforming vectors and consequently propose the
partially distributed algorithms to implement the optimal beamforming, where
each relay node only needs the local channel information and one global
parameter. Second, with the non-reciprocal channels, the achievable rate
regions are also characterized for both the sum-power constraint case and the
individual-power constraint case. Although no closed-form solutions are
available under this setup, we present efficient numerical algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4981</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4981</id><created>2010-10-24</created><authors><author><keyname>Banks</keyname><forenames>Jacqueline</forenames></author><author><keyname>Garrabrant</keyname><forenames>Scott</forenames></author><author><keyname>Huber</keyname><forenames>Mark L.</forenames></author><author><keyname>Perizzolo</keyname><forenames>Anne</forenames></author></authors><title>Using TPA to count linear extensions</title><categories>math.PR cs.DS</categories><comments>12 pages, 4 algorithms</comments><msc-class>65C05, 06A07</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A linear extension of a poset $P$ is a permutation of the elements of the set
that respects the partial order. Let $L(P)$ denote the number of linear
extensions. It is a #P complete problem to determine $L(P)$ exactly for an
arbitrary poset, and so randomized approximation algorithms that draw randomly
from the set of linear extensions are used. In this work, the set of linear
extensions is embedded in a larger state space with a continuous parameter ?.
The introduction of a continuous parameter allows for the use of a more
efficient method for approximating $L(P)$ called TPA. Our primary result is
that it is possible to sample from this continuous embedding in time that as
fast or faster than the best known methods for sampling uniformly from linear
extensions. For a poset containing $n$ elements, this means we can approximate
$L(P)$ to within a factor of $1 + \epsilon$ with probability at least $1 -
\delta$ using an expected number of random bits and comparisons in the poset
which is at most $O(n^3(ln n)(ln L(P))\epsilon^{-2}\ln \delta^{-1}).$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4986</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4986</id><created>2010-10-24</created><authors><author><keyname>Panaousis</keyname><forenames>Emmanouil A.</forenames></author><author><keyname>Drew</keyname><forenames>George</forenames></author><author><keyname>Millar</keyname><forenames>Grant P.</forenames></author><author><keyname>Ramrekha</keyname><forenames>Tipu A.</forenames></author><author><keyname>Politis</keyname><forenames>Christos</forenames></author></authors><title>A Testbed Implementation for Securing OLSR in Mobile Ad hoc Networks</title><categories>cs.NI</categories><comments>20 pages, 13 figures</comments><journal-ref>E.A. Panaousis, G. Drew, G. Millar, T.A. Ramrekha, C. Politis, &quot;A
  Test-bed Implementation for Securing OLSR in Mobile Ad-hoc Networks,&quot;
  International Journal of Network Security &amp; Its Applications, Vol. 2, No. 4,
  October, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contemporary personal computing devices are increasingly required to be
portable and mobile enabling user's wireless access, to wired network
infrastructures and services. This approach to mobile computing and
communication is only appropriate in situations where a coherent infrastructure
is available. There are many situations where these requirements are not
fulfilled such as; developing nations, rural areas, natural disasters, and
military conflicts to name but a few. A practical solution is to use mobile
devices interconnected via a wireless medium to form a network, known as a
Mobile Ad-hoc Network (MANET), and provide the services normally found in wired
networks. Security in MANETs is an issue of paramount importance due to the
wireless nature of the communication links. Additionally due to the lack of
central administration security issues are different from conventional
networks. For the purposes of this article we have used the &quot;WMN test-bed&quot; to
enable secure routing in MANETs. The use of cryptography is an efficient proven
way of securing data in communications, but some cryptographic algorithms are
not as efficient as others and require more processing power, which is
detrimental to MANETs. In this article we have assessed different cryptographic
approaches to securing the OLSR (Optimised Link State Routing) protocol to
provide a basis for research. We conclude the paper with a series of
performance evaluation results regarding different cryptographic and hashing
schemes. Our findings clearly show that the most efficient combination of
algorithms used for authentication and encryption are SHA-1 and AES
respectively. Using this combination over their counterparts will lead to a
considerable reduction in processing time and delay on the network, creating an
efficient transaction moving towards satisfying resource constraints and
security requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.4999</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.4999</id><created>2010-10-24</created><authors><author><keyname>Fricke</keyname><forenames>Gregory K.</forenames></author><author><keyname>Rogers</keyname><forenames>Bruce W.</forenames></author><author><keyname>Garg</keyname><forenames>Devendra P.</forenames></author></authors><title>On the Stability of Swarm Consensus Under Noisy Control</title><categories>nlin.AO cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Representation of a swarm of independent robotic agents under graph-theoretic
constructs allows for more formal analysis of convergence properties. We
consider the local and global convergence behavior of an N-member swarm of
agents in a modified consensus problem wherein the connectivity of agents is
governed by probabilistic functions. The addition of a random walk control
ensures Lyapunov stability of the swarm consensus. Simulation results are given
and planned experiments are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5016</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5016</id><created>2010-10-24</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>Shapira</keyname><forenames>Asaf</forenames></author></authors><title>A Unified Framework for Testing Linear-Invariant Properties</title><categories>cs.DS math.CO</categories><comments>Preliminary full version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of the interplay between the testability of properties of Boolean
functions and the invariances acting on their domain which preserve the
property was initiated by Kaufman and Sudan (STOC 2008). Invariance with
respect to F_2-linear transformations is arguably the most common symmetry
exhibited by natural properties of Boolean functions on the hypercube. Hence,
an important goal in Property Testing is to describe necessary and sufficient
conditions for the testability of linear-invariant properties. This direction
was explicitly proposed for investigation in a recent survey of Sudan.
  We obtain the following results:
  1. We show that every linear-invariant property that can be characterized by
forbidding induced solutions to a (possibly infinite) set of linear equations
can be tested with one-sided error.
  2. We show that every linear-invariant property that can be tested with
one-sided error can be characterized by forbidding induced solutions to a
(possibly infinite) set of systems of linear equations.
  We conjecture that our result from item (1) can be extended to cover systems
of linear equations. We further show that the validity of this conjecture would
have the following implications:
  1. It would imply that every linear-invariant property that is closed under
restrictions to linear subspaces is testable with one-sided error. Such a
result would unify several previous results on testing Boolean functions, such
as the testability of low-degree polynomials and of Fourier dimensionality.
  2. It would imply that a linear-invariant property P is testable with
one-sided error if and only if P is closed under restrictions to linear
subspaces, thus resolving Sudan's problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5023</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5023</id><created>2010-10-24</created><authors><author><keyname>Might</keyname><forenames>Matthew</forenames></author><author><keyname>Darais</keyname><forenames>David</forenames></author></authors><title>Yacc is dead</title><categories>cs.PL</categories><comments>18 pages; submitted October 2009 to ESOP; rejected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two novel approaches to parsing context-free languages. The first
approach is based on an extension of Brzozowski's derivative from regular
expressions to context-free grammars. The second approach is based on a
generalization of the derivative to parser combinators. The payoff of these
techniques is a small (less than 250 lines of code), easy-to-implement parsing
library capable of parsing arbitrary context-free grammars into lazy parse
forests. Implementations for both Scala and Haskell are provided. Preliminary
experiments with S-Expressions parsed millions of tokens per second, which
suggests this technique is efficient enough for use in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5034</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5034</id><created>2010-10-24</created><authors><author><keyname>Grigoriev</keyname><forenames>Dima</forenames></author><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author></authors><title>Authentication from matrix conjugation</title><categories>cs.CR</categories><comments>6 pages</comments><journal-ref>Groups, Complexity, and Cryptology 1 (2009), 199--206</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an authentication scheme where forgery (a.k.a. impersonation)
seems infeasible without finding the prover's long-term private key. The latter
would follow from solving the conjugacy search problem in the platform
(noncommutative) semigroup, i.e., to recovering X from X^{-1}AX and A. The
platform semigroup that we suggest here is the semigroup of nxn matrices over
truncated multivariable polynomials over a ring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5036</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5036</id><created>2010-10-25</created><authors><author><keyname>Uddin</keyname><forenames>Mueen</forenames></author><author><keyname>Rahman</keyname><forenames>Azizah Abdul</forenames></author></authors><title>Dynamic Multi Layer Signature based Intrusion Detection system Using
  Mobile Agents</title><categories>cs.CR</categories><comments>13 pages, IJNSA Journal Accepted Paper</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.2, No.4, October 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Intrusion detection systems have become a key component in ensuring the
safety of systems and networks. As networks grow in size and speed continues to
increase, it is crucial that efficient scalable techniques should be developed
for IDS systems. Signature based detection is the most extensively used threat
detection technique for Intrusion Detection Systems (IDS). One of the foremost
challenges for signaturebased IDS systems is how to keep up with large volume
of incoming traffic when each packet needs to be compared with every signature
in the database. When an IDS cannot keep up with the traffic flood, all it can
do is to drop packets, therefore, may miss potential attacks. This paper
proposes a new model called Dynamic Multi-Layer Signature based IDS using
Mobile Agents, which can detect imminent threats with very high success rate by
dynamically and automatically creating and using small and efficient multiple
databases, and at the same time, provide mechanism to update these small
signature databases at regular intervals using Mobile Agents
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5037</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5037</id><created>2010-10-25</created><authors><author><keyname>Uddin</keyname><forenames>Mueen</forenames></author><author><keyname>Rahman</keyname><forenames>Azizah Abdul</forenames></author></authors><title>Server Consolidation: An Approach to make Data Centers Energy Efficient
  and Green</title><categories>cs.OH</categories><comments>7 pages, IJSER Journal accepted paper</comments><journal-ref>International Journal of Scientific &amp; Engineering Research, Volume
  1, Issue 1, October-2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Data centers are the building blocks of IT business organizations providing
the capabilities of centralized repository for storage, management, networking
and dissemination of data. With the rapid increase in the capacity and size of
data centers, there is a continuous increase in the demand for energy
consumption. These data centers not only consume a tremendous amount of energy
but are riddled with IT inefficiencies. All data center are plagued with
thousands of servers as major components. These servers consume huge energy
without performing useful work. In an average server environment, 30% of the
servers are &quot;dead&quot; only consuming energy, without being properly utilized.
Their utilization ratio is only 5 to 10 percent. This paper focuses on the use
of an emerging technology called virtualization to achieve energy efficient
data centers by providing a solution called server consolidation. It increases
the utilization ratio up to 50% saving huge amount of energy. Server
consolidation helps in implementing green data centers to ensure that IT
infrastructure contributes as little as possible to the emission of green house
gases, and helps to regain power and cooling capacity, recapture resilience and
dramatically reducing energy costs and total cost of ownership.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5051</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5051</id><created>2010-10-25</created><authors><author><keyname>Goswami</keyname><forenames>Sanchari</forenames></author><author><keyname>Biswas</keyname><forenames>Soham</forenames></author><author><keyname>Sen</keyname><forenames>Parongama</forenames></author></authors><title>Complex Networks: effect of subtle changes in nature of randomness</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>6 pages, 11 figures, to be published in Physica A</comments><journal-ref>Physica A 390, 972 (2011)</journal-ref><doi>10.1016/j.physa.2010.10.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two different classes of network models, namely, the Watts Strogatz type
and the Euclidean type, subtle changes have been introduced in the randomness.
In the Watts Strogatz type network, rewiring has been done in different ways
and although the qualitative results remain same, finite differences in the
exponents are observed. In the Euclidean type networks, where at least one
finite phase transition occurs, two models differing in a similar way have been
considered. The results show a possible shift in one of the phase transition
points but no change in the values of the exponents. The WS and Euclidean type
models are equivalent for extreme values of the parameters; we compare their
behaviour for intermediate values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5081</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5081</id><created>2010-10-25</created><updated>2011-03-01</updated><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Fanelli</keyname><forenames>Angelo</forenames></author><author><keyname>Gravin</keyname><forenames>Nick</forenames></author><author><keyname>Shiryaev</keyname><forenames>Dmitry</forenames></author></authors><title>Dynamics of Profit-Sharing Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important task in the analysis of multiagent systems is to understand how
groups of selfish players can form coalitions, i.e., work together in teams. In
this paper, we study the dynamics of coalition formation under bounded
rationality. We consider settings where each team's profit is given by a convex
function, and propose three profit-sharing schemes, each of which is based on
the concept of marginal utility. The agents are assumed to be myopic, i.e.,
they keep changing teams as long as they can increase their payoff by doing so.
We study the properties (such as closeness to Nash equilibrium or total profit)
of the states that result after a polynomial number of such moves, and prove
bounds on the price of anarchy and the price of stability of the corresponding
games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5092</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5092</id><created>2010-10-25</created><authors><author><keyname>Rivoire</keyname><forenames>Olivier</forenames></author><author><keyname>Leibler</keyname><forenames>Stanislas</forenames></author></authors><title>The Value of Information for Populations in Varying Environments</title><categories>q-bio.PE cond-mat.stat-mech cs.IT math.IT</categories><doi>10.1007/s10955-011-0166-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of information pervades informal descriptions of biological
systems, but formal treatments face the problem of defining a quantitative
measure of information rooted in a concept of fitness, which is itself an
elusive notion. Here, we present a model of population dynamics where this
problem is amenable to a mathematical analysis. In the limit where any
information about future environmental variations is common to the members of
the population, our model is equivalent to known models of financial
investment. In this case, the population can be interpreted as a portfolio of
financial assets and previous analyses have shown that a key quantity of
Shannon's communication theory, the mutual information, sets a fundamental
limit on the value of information. We show that this bound can be violated when
accounting for features that are irrelevant in finance but inherent to
biological systems, such as the stochasticity present at the individual level.
This leads us to generalize the measures of uncertainty and information usually
encountered in information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5113</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5113</id><created>2010-10-25</created><authors><author><keyname>Spiliotis</keyname><forenames>Konstantinos G.</forenames></author><author><keyname>Siettos</keyname><forenames>Constantinos I.</forenames></author></authors><title>Coarse-Grained Analysis of Microscopic Neuronal Simulators on Networks:
  Bifurcation and Rare-events computations</title><categories>cs.SI nlin.AO physics.bio-ph q-bio.NC</categories><journal-ref>Neurocomputing, 74, 3576-3589 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how the Equation-Free approach for mutliscale computations can be
exploited to extract, in a computational strict and systematic way the emergent
dynamical attributes, from detailed large-scale microscopic stochastic models,
of neurons that interact on complex networks. In particular we show how the
Equation-Free approach can be exploited to perform system-level tasks such as
bifurcation, stability analysis and estimation of mean appearance times of rare
events, bypassing the need for obtaining analytical approximations, providing
an &quot;on-demand&quot; model reduction. Using the detailed simulator as a black-box
timestepper, we compute the coarse-grained equilibrium bifurcation diagrams,
examine the stability of the solution branches and perform a rare-events
analysis with respect to certain characteristics of the underlying network
topology such as the connectivity degree
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5128</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5128</id><created>2010-10-25</created><authors><author><keyname>Ayadi</keyname><forenames>Ahmed</forenames></author><author><keyname>Maill&#xe9;</keyname><forenames>Patrick</forenames></author><author><keyname>Ros</keyname><forenames>David</forenames></author></authors><title>TCP over low-power and lossy networks: tuning the segment size to
  minimize energy consumption</title><categories>cs.NI</categories><comments>TELECOM Bretagne Research Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-power and Lossy Networks (LLNs), like wireless networks based upon the
IEEE 802.15.4 standard, have strong energy constraints, and are moreover
subject to frequent transmission errors, not only due to congestion but also to
collisions and to radio channel conditions. This paper introduces an analytical
model to compute the total energy consumption in an LLN due to the TCP
protocol. The model allows us to highlight some tradeoffs as regards the choice
of the TCP maximum segment size, of the Forward Error Correction (FEC)
redundancy ratio, and of the number of link-layer retransmissions, in order to
minimize the total energy consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5141</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5141</id><created>2010-10-25</created><updated>2012-08-13</updated><authors><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Generalized Approximate Message Passing for Estimation with Random
  Linear Mixing</title><categories>cs.IT math.IT</categories><comments>22 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the estimation of an i.i.d.\ random vector observed through a
linear transform followed by a componentwise, probabilistic (possibly
nonlinear) measurement channel. A novel algorithm, called generalized
approximate message passing (GAMP), is presented that provides computationally
efficient approximate implementations of max-sum and sum-problem loopy belief
propagation for such problems. The algorithm extends earlier approximate
message passing methods to incorporate arbitrary distributions on both the
input and output of the transform and can be applied to a wide range of
problems in nonlinear compressed sensing and learning.
  Extending an analysis by Bayati and Montanari, we argue that the asymptotic
componentwise behavior of the GAMP method under large, i.i.d. Gaussian
transforms is described by a simple set of state evolution (SE) equations. From
the SE equations, one can \emph{exactly} predict the asymptotic value of
virtually any componentwise performance metric including mean-squared error or
detection accuracy. Moreover, the analysis is valid for arbitrary input and
output distributions, even when the corresponding optimization problems are
non-convex. The results match predictions by Guo and Wang for relaxed belief
propagation on large sparse matrices and, in certain instances, also agree with
the optimal performance predicted by the replica method. The GAMP methodology
thus provides a computationally efficient methodology, applicable to a large
class of non-Gaussian estimation problems with precise asymptotic performance
guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5163</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5163</id><created>2010-10-25</created><authors><author><keyname>Bajovic</keyname><forenames>Dragana</forenames></author><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author><author><keyname>Sinopoli</keyname><forenames>Bruno</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Distributed Detection over Time Varying Networks: Large Deviations
  Analysis</title><categories>cs.IT math.IT</categories><comments>8 pages, in 48th Allerton Conference on Communication, Control, and
  Computing, Oct. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply large deviations theory to study asymptotic performance of running
consensus distributed detection in sensor networks. Running consensus is a
stochastic approximation type algorithm, recently proposed. At each time step
k, the state at each sensor is updated by a local averaging of the sensor's own
state and the states of its neighbors (consensus) and by accounting for the new
observations (innovation). We assume Gaussian, spatially correlated
observations. We allow the underlying network be time varying, provided that
the graph that collects the union of links that are online at least once over a
finite time window is connected. This paper shows through large deviations
that, under stated assumptions on the network connectivity and sensors'
observations, the running consensus detection asymptotically approaches in
performance the optimal centralized detection. That is, the Bayes probability
of detection error (with the running consensus detector) decays exponentially
to zero as k goes to infinity at the Chernoff information rate-the best
achievable rate of the asymptotically optimal centralized detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5176</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5176</id><created>2010-10-25</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Distributed Trust Management Framework for Detecting Malicious Packet
  Dropping Nodes in a Mobile Ad Hoc Network</title><categories>cs.CR</categories><comments>No. of pages: 13, No. of figures: 4, No. tables: 1</comments><journal-ref>International Journal of Network Security and its Applications
  (IJNSA), Vol: 2, No: 4, pp. 92- 104, 2010. ISSN: Online: 0974 - 9330. Print:
  0975 - 2307</journal-ref><doi>10.5121/ijnsa.2010.2408</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multi-hop mobile ad hoc network (MANET) mobile nodes communicate with
each other forming a cooperative radio network. Security remains a major
challenge for these networks due to their features of open medium, dynamically
changing topologies, reliance on cooperative algorithms, absence of centralized
monitoring points, and lack of any clear lines of defense. Most of the
currently existing security algorithms designed for these networks are
insecure, in efficient, and have low detection accuracy for nodes'
misbehaviour. In this paper, a new approach has been proposed to bring out the
complementary relationship between key distribution and misbehaviour detection
for developing an integrated security solution for MANETs. The redundancy of
routing information in ad hoc networks is utilized to develop a highly reliable
protocol that works even in presence of transient network partitioning and
Byzantine failure of nodes. The proposed mechanism is fully co-operative, and
thus it is more robust as the vulnerabilities of the election algorithms used
for choosing the subset of nodes for cooperation are absent. Simulation results
show the effectiveness of the proposed protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5197</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5197</id><created>2010-10-25</created><updated>2010-11-23</updated><authors><author><keyname>Bousquet</keyname><forenames>Nicolas</forenames></author><author><keyname>Daligault</keyname><forenames>Jean</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>Multicut is FPT</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G=(V,E)$ be a graph on $n$ vertices and $R$ be a set of pairs of
vertices in $V$ called \emph{requests}. A \emph{multicut} is a subset $F$ of
$E$ such that every request $xy$ of $R$ is cut by $F$, \i.e. every $xy$-path of
$G$ intersects $F$. We show that there exists an $O(f(k)n^c)$ algorithm which
decides if there exists a multicut of size at most $k$. In other words, the
\M{} problem parameterized by the solution size $k$ is Fixed-Parameter
Tractable. The proof extends to vertex multicuts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5278</identifier>
 <datestamp>2012-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5278</id><created>2010-10-25</created><updated>2012-04-11</updated><authors><author><keyname>Koller</keyname><forenames>Christian</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author><author><keyname>Vatta</keyname><forenames>Francesca</forenames></author><author><keyname>Zigangirov</keyname><forenames>Kamil S.</forenames></author><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Analysis and Design of Tuned Turbo Codes</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory</comments><doi>10.1109/TIT.2012.2195711</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been widely observed that there exists a fundamental trade-off between
the minimum (Hamming) distance properties and the iterative decoding
convergence behavior of turbo-like codes. While capacity achieving code
ensembles typically are asymptotically bad in the sense that their minimum
distance does not grow linearly with block length, and they therefore exhibit
an error floor at moderate-to-high signal to noise ratios, asymptotically good
codes usually converge further away from channel capacity. In this paper, we
introduce the concept of tuned turbo codes, a family of asymptotically good
hybrid concatenated code ensembles, where asymptotic minimum distance growth
rates, convergence thresholds, and code rates can be traded-off using two
tuning parameters, {\lambda} and {\mu}. By decreasing {\lambda}, the asymptotic
minimum distance growth rate is reduced in exchange for improved iterative
decoding convergence behavior, while increasing {\lambda} raises the asymptotic
minimum distance growth rate at the expense of worse convergence behavior, and
thus the code performance can be tuned to fit the desired application. By
decreasing {\mu}, a similar tuning behavior can be achieved for higher rate
code ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5290</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5290</id><created>2010-10-25</created><updated>2011-03-16</updated><authors><author><keyname>Mirzal</keyname><forenames>Andri</forenames></author></authors><title>Converged Algorithms for Orthogonal Nonnegative Matrix Factorizations</title><categories>cs.LG cs.NA</categories><comments>55 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper proposes uni-orthogonal and bi-orthogonal nonnegative matrix
factorization algorithms with robust convergence proofs. We design the
algorithms based on the work of Lee and Seung [1], and derive the converged
versions by utilizing ideas from the work of Lin [2]. The experimental results
confirm the theoretical guarantees of the convergences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5291</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5291</id><created>2010-10-25</created><authors><author><keyname>Ma</keyname><forenames>Wenping</forenames></author><author><keyname>Sun</keyname><forenames>Shaohui</forenames></author></authors><title>New Class of Optimal Frequency-Hopping Sequences by Polynomial Residue
  Class Rings</title><categories>cs.IT math.IT</categories><comments>10 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, using the theory of polynomial residue class rings, a new
construction is proposed for frequency hopping patterns having optimal Hamming
autocorrelation with respect to the well-known $Lempel$-$Greenberger$ bound.
Based on the proposed construction, many new $Peng$-$Fan$ optimal families of
frequency hopping sequences are obtained. The parameters of these sets of
frequency hopping sequences are new and flexible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5308</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5308</id><created>2010-10-25</created><authors><author><keyname>Bliudze</keyname><forenames>Simon</forenames></author><author><keyname>Bruni</keyname><forenames>Roberto</forenames></author><author><keyname>Grohmann</keyname><forenames>Davide</forenames></author><author><keyname>Silva</keyname><forenames>Alexandra</forenames></author></authors><title>Proceedings Third Interaction and Concurrency Experience: Guaranteed
  Interaction</title><categories>cs.LO cs.DC cs.MA</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010</journal-ref><doi>10.4204/EPTCS.38</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 3rd Interaction and Concurrency
Experience (ICE 2010) workshop, which was held in Amsterdam, Netherlands on
10th of June 2010 as a satellite event of DisCoTec'10. Each year, the workshop
focuses on a specific topic: the topic of ICE 2010 was Guaranteed Interactions,
by which we mean, for example, guaranteeing safety, reactivity, quality of
service or satisfaction of analysis hypotheses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5310</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5310</id><created>2010-10-25</created><updated>2010-11-06</updated><authors><author><keyname>Avenda&#xf1;o</keyname><forenames>Mart&#xed;n</forenames></author><author><keyname>Ibrahim</keyname><forenames>Ashraf</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author><author><keyname>Rusek</keyname><forenames>Korben</forenames></author></authors><title>Faster p-adic Feasibility for Certain Multivariate Sparse Polynomials</title><categories>math.NT cs.CC</categories><comments>31 pages, 3 figures, submitted for publication. This version corrects
  various typos and clarifies the proof of Assertion (3)(c) of the main theorem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms revealing new families of polynomials allowing
sub-exponential detection of p-adic rational roots, relative to the sparse
encoding. For instance, we show that the case of honest n-variate (n+1)-nomials
is doable in NP and, for p exceeding the Newton polytope volume and not
dividing any coefficient, in constant time. Furthermore, using the theory of
linear forms in p-adic logarithms, we prove that the case of trinomials in one
variable can be done in NP. The best previous complexity bounds for these
problems were EXPTIME or worse. Finally, we prove that detecting p-adic
rational roots for sparse polynomials in one variable is NP-hard with respect
to randomized reductions. The last proof makes use of an efficient construction
of primes in certain arithmetic progressions. The smallest n where detecting
p-adic rational roots for n-variate sparse polynomials is NP-hard appears to
have been unknown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5318</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5318</id><created>2010-10-26</created><updated>2010-12-30</updated><authors><author><keyname>Berstel</keyname><forenames>Jean</forenames></author><author><keyname>Boasson</keyname><forenames>Luc</forenames></author><author><keyname>Carton</keyname><forenames>Olivier</forenames></author><author><keyname>Fagnot</keyname><forenames>Isabelle</forenames></author></authors><title>Minimization of Automata</title><categories>cs.FL</categories><comments>This paper is the manuscript of chapter 10 of the Handbook &quot;Automata:
  from Mathematics to Applications&quot; to be published by the European
  Mathematical Society</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter is concerned with the design and analysis of algorithms for
minimizing finite automata. Getting a minimal automaton is a fundamental issue
in the use and implementation of finite automata tools in frameworks like text
processing, image analysis, linguistic computer science, and many other
applications. There are two main families of minimization algorithms. The first
by a sequence of refinements of a partition of the set of states, the second by
a sequence of fusions or merges of states. Hopcroft's and Moore's algorithms
belong to the first family, the linear-time minimization of acyclic automata of
Revuz belongs to the second family.
  One of our studies is upon the comparison of the nature of Moore's and
Hopcroft's algorithms. This gives some new insight in both algorithms. As we
shall see, these algorithms are quite different both in behavior and in
complexity. In particular, we show that it is not possible to simulate the
computations of one of the algorithm by the other. We describe the minimization
algorithm by fusion for so-called local automata. A special case of
minimization is the construction o minimal automata for finite sets. We
consider briefly this case, and in particular describe incremental algorithms.
Finally, we consider the case of updating a minimal automaton when a word is
added or removed from the set it recognizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5342</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5342</id><created>2010-10-26</created><authors><author><keyname>Gavinsky</keyname><forenames>Dmitry</forenames></author><author><keyname>Ito</keyname><forenames>Tsuyoshi</forenames></author></authors><title>Quantum Fingerprints that Keep Secrets</title><categories>quant-ph cs.CR</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new type of cryptographic primitive that we call hiding
fingerprinting. A (quantum) fingerprinting scheme translates a binary string of
length $n$ to $d$ (qu)bits, typically $d\ll n$, such that given any string $y$
and a fingerprint of $x$, one can decide with high accuracy whether $x=y$.
Classical fingerprinting schemes cannot hide information very well: a classical
fingerprint of $x$ that guarantees error at most $\epsilon$ necessarily reveals
$\Omega(\log(1/\ epsilon))$ bits about $x$. We call a scheme hiding if it
reveals $o(\log(1/\epsilon))$ bits; accordingly, no classical scheme is hiding.
For any constant $c$, we construct two kinds of hiding fingerprinting schemes,
both mapping $n$-bit strings to $O(\log n)$ qubits and guaranteeing one-sided
error probability at most $1/n^c$. The first kind uses pure states and leaks at
most $O(1)$ bits, and the second kind uses mixed states and leaks at most
$1/n^c$ bits, where the &quot;leakage&quot; is bounded via accessible information. The
schemes are computationally efficient. Our mixed-state scheme is optimal, as
shown via a generic strategy that extracts $1/\poly(n)$ bits from any
fingerprint over $O(\log n)$ qubits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5377</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5377</id><created>2010-10-26</created><authors><author><keyname>Peel</keyname><forenames>Leto</forenames></author></authors><title>Estimating Network Parameters for Selecting Community Detection
  Algorithms</title><categories>cs.SI physics.soc-ph</categories><comments>In proceedings of The 13th International Conference on Information
  Fusion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of algorithm selection for community
detection. The aim of community detection is to identify sets of nodes in a
network which are more interconnected relative to their connectivity to the
rest of the network. A large number of algorithms have been developed to tackle
this problem, but as with any machine learning task there is no
&quot;one-size-fits-all&quot; and each algorithm excels in a specific part of the problem
space. This paper examines the performance of algorithms developed for weighted
networks against those using unweighted networks for different parts of the
problem space (parameterised by the intra/inter community links). It is then
demonstrated how the choice of algorithm (weighted/unweighted) can be made
based only on the observed network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5382</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5382</id><created>2010-10-26</created><authors><author><keyname>Asoodeh</keyname><forenames>Shahab</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Wang</keyname><forenames>Ligong</forenames></author></authors><title>It takes half the energy of a photon to send one bit reliably on the
  Poisson channel with feedback</title><categories>cs.IT math.IT</categories><comments>A slightly extended version of a paper that appeared in the
  Proceedings of the Sixth Joint Workshop on Coding and Communications (JWCC),
  Relais San Maurizio, Santo Stefano Belbo, Italy, October 17-19, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the transmission of a single bit over the continuous-time Poisson
channel with noiseless feedback. We show that to send the bit reliably
requires, on the average, half the energy of a photon. In the absence of
peak-power constraints this holds irrespective of the intensity of the dark
current. We also solve for the energy required to send $log_{2} M$ bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5388</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5388</id><created>2010-10-26</created><authors><author><keyname>Cariolaro</keyname><forenames>Gianfranco</forenames></author><author><keyname>Vigato</keyname><forenames>Alberto</forenames></author></authors><title>Helstrom's Theory on Quantum Binary Decision Revisited</title><categories>cs.IT math.IT quant-ph</categories><comments>5 pages, 0 figures, submitted to conference ISIT2011</comments><report-no>1569374959</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a binary system specified by the density operators r0 and r1 and by the
prior probabilities q0 and q1, Helstrom's theory permits the evaluation of the
optimal measurement operators and of the corresponding maximum correct
detection probability. The theory is based on the eigendecomposition (EID) of
the operator, given by the difference of the weighted density operators, namely
D = q1r1-q0r0. In general, this EID is obtained explicitly only with pure
states, whereas with mixed states it must be carried out numerically. In this
letter we show that the same evaluation can be performed on the basis of a
modified version of the Gram matrix. The advantage is due to the fact that the
outer products of density operators are replaced by inner product, with a
considerable dimensionality reduction. At the limit, in quantum optical
communications the density operators have infinite dimensions, whereas the
inner products are simply scalar quantities. The Gram matrix approach permits
the explicit (not numerical) evaluation of a binary system performance in cases
not previously developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5391</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5391</id><created>2010-10-26</created><authors><author><keyname>Charlier</keyname><forenames>Emilie</forenames></author><author><keyname>Lacroix</keyname><forenames>Anne</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>Multi-dimensional sets recognizable in all abstract numeration systems</title><categories>cs.FL</categories><comments>11 pages</comments><msc-class>68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the subsets of N^d that are S-recognizable for all abstract
numeration systems S are exactly the 1-recognizable sets. This generalizes a
result of Lecomte and Rigo in the one-dimensional setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5412</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5412</id><created>2010-10-26</created><updated>2010-10-27</updated><authors><author><keyname>Bonami</keyname><forenames>Pierre</forenames><affiliation>LIF</affiliation></author></authors><title>On optimizing over lift-and-project closures</title><categories>cs.RO math.OC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lift-and-project closure is the relaxation obtained by computing all
lift-and-project cuts from the initial formulation of a mixed integer linear
program or equivalently by computing all mixed integer Gomory cuts read from
all tableau's corresponding to feasible and infeasible bases. In this paper, we
present an algorithm for approximating the value of the lift-and-project
closure. The originality of our method is that it is based on a very simple cut
generation linear programming problem which is obtained from the original
linear relaxation by simply modifying the bounds on the variables and
constraints. This separation LP can also be seen as the dual of the cut
generation LP used in disjunctive programming procedures with a particular
normalization. We study some properties of this separation LP in particular
relating it to the equivalence between lift-and-project cuts and Gomory cuts
shown by Balas and Perregaard. Finally, we present some computational
experiments and comparisons with recent related works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5416</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5416</id><created>2010-10-26</created><updated>2011-11-03</updated><authors><author><keyname>Rajesh</keyname><forenames>R.</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Capacity of Fading Gaussian Channel with an Energy Harvesting Sensor
  Node</title><categories>cs.IT math.IT</categories><comments>6 Pages, To be presented at IEEE GLOBECOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network life time maximization is becoming an important design goal in
wireless sensor networks. Energy harvesting has recently become a preferred
choice for achieving this goal as it provides near perpetual operation. We
study such a sensor node with an energy harvesting source and compare various
architectures by which the harvested energy is used. We find its Shannon
capacity when it is transmitting its observations over a fading AWGN channel
with perfect/no channel state information provided at the transmitter. We
obtain an achievable rate when there are inefficiencies in energy storage and
the capacity when energy is spent in activities other than transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5421</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5421</id><created>2010-10-26</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>On the Mesh Array for Matrix Multiplication</title><categories>cs.DC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents new properties of the mesh array for matrix
multiplication. In contrast to the standard array that requires 3n-2 steps to
complete its computation, the mesh array requires only 2n-1 steps. Symmetries
of the mesh array computed values are presented which enhance the efficiency of
the array for specific applications. In multiplying symmetric matrices, the
results are obtained in 3n/2+1 steps. The mesh array is examined for its
application as a scrambling system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5426</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5426</id><created>2010-10-26</created><authors><author><keyname>Zheng</keyname><forenames>Shuai</forenames></author><author><keyname>Huang</keyname><forenames>Kaiqi</forenames></author><author><keyname>Tan</keyname><forenames>Tieniu</forenames></author></authors><title>Translation-Invariant Representation for Cumulative Foot Pressure Images</title><categories>cs.AI</categories><comments>6 pages</comments><journal-ref>Shuai Zheng, Kaiqi Huang and Tieniu Tan. Translation Invariant
  Representation for Cumulative foot pressure Image, The second CJK Joint
  Workshop on Pattern Recognition(CJKPR), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human can be distinguished by different limb movements and unique ground
reaction force. Cumulative foot pressure image is a 2-D cumulative ground
reaction force during one gait cycle. Although it contains pressure spatial
distribution information and pressure temporal distribution information, it
suffers from several problems including different shoes and noise, when putting
it into practice as a new biometric for pedestrian identification. In this
paper, we propose a hierarchical translation-invariant representation for
cumulative foot pressure images, inspired by the success of Convolutional deep
belief network for digital classification. Key contribution in our approach is
discriminative hierarchical sparse coding scheme which helps to learn useful
discriminative high-level visual features. Based on the feature representation
of cumulative foot pressure images, we develop a pedestrian recognition system
which is invariant to three different shoes and slight local shape change.
Experiments are conducted on a proposed open dataset that contains more than
2800 cumulative foot pressure images from 118 subjects. Evaluations suggest the
effectiveness of the proposed method and the potential of cumulative foot
pressure images as a biometric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5445</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5445</id><created>2010-10-26</created><authors><author><keyname>Bertsimas</keyname><forenames>Dimitris</forenames></author><author><keyname>Brown</keyname><forenames>David B.</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author></authors><title>Theory and Applications of Robust Optimization</title><categories>math.OC cs.CE</categories><comments>50 pages</comments><msc-class>90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we survey the primary research, both theoretical and applied,
in the area of Robust Optimization (RO). Our focus is on the computational
attractiveness of RO approaches, as well as the modeling power and broad
applicability of the methodology. In addition to surveying prominent
theoretical results of RO, we also present some recent results linking RO to
adaptable models for multi-stage decision-making problems. Finally, we
highlight applications of RO across a wide spectrum of domains, including
finance, statistics, learning, and various areas of engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5456</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5456</id><created>2010-10-26</created><authors><author><keyname>Shur</keyname><forenames>Arseny M.</forenames></author></authors><title>Combinatorial Characterization of Formal Languages</title><categories>cs.FL cs.DM math.CO</categories><comments>41 page 1 figure, 1 table</comments><msc-class>68Q70 68R15 05C50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is an extended abstract of the dissertation presented by the
author for the doctoral degree in physics and mathematics (in Russia). The main
characteristic studied in the dissertation is combinatorial complexity, which
is a &quot;counting&quot; function associated with a language and returning the number of
words of given length in this language. For several classes of languages, a
variety of problems about combinatorial complexity and its connections to other
parameters of languages are studied. A brief introduction to the topic and the
formulations of results are presented. No proofs are given; instead, the papers
containing the proofs are cited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5470</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5470</id><created>2010-10-26</created><updated>2011-01-14</updated><authors><author><keyname>Gavalda</keyname><forenames>Ricard</forenames></author><author><keyname>Lopez-Valdes</keyname><forenames>Maria</forenames></author><author><keyname>Mayordomo</keyname><forenames>Elvira</forenames></author><author><keyname>Vinodchandran</keyname><forenames>N. V.</forenames></author></authors><title>Resource-bounded Dimension in Computational Learning Theory</title><categories>cs.CC cs.LG</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the relation between computational learning theory and
resource-bounded dimension. We intend to establish close connections between
the learnability/nonlearnability of a concept class and its corresponding size
in terms of effective dimension, which will allow the use of powerful dimension
techniques in computational learning and viceversa, the import of learning
results into complexity via dimension. Firstly, we obtain a tight result on the
dimension of online mistake-bound learnable classes. Secondly, in relation with
PAC learning, we show that the polynomial-space dimension of PAC learnable
classes of concepts is zero. This provides a hypothesis on effective dimension
that implies the inherent unpredictability of concept classes (the classes that
verify this property are classes not efficiently PAC learnable using any
hypothesis). Thirdly, in relation to space dimension of classes that are
learnable by membership query algorithms, the main result proves that
polynomial-space dimension of concept classes learnable by a membership-query
algorithm is zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5471</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5471</id><created>2010-10-26</created><authors><author><keyname>Shabani</keyname><forenames>Redjan F.</forenames></author></authors><title>The nature of individual choice: a formalism for utility function based
  on set theory</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the theory of social choice the research is focused around the projection
of individual preference orders to the social preference order. Also, the
justification of the preference order formalism begins with the concept of
utility i.e. an alternative is preferred to another one if the utility over the
first is higher then the utility over the second. In this paper is proposed an
ideal model of measuring utilities by considering individuals and alternatives
no more as atomic concepts but as being composed by other entities. Furthermore
is proposed a formal definition of evaluation processes based on utilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5478</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5478</id><created>2010-10-26</created><authors><author><keyname>Br&#xe4;nnstr&#xf6;m</keyname><forenames>&#xc5;ke</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author><author><keyname>Blasius</keyname><forenames>Bernd</forenames></author><author><keyname>Dieckmann</keyname><forenames>Ulf</forenames></author></authors><title>Consequences of fluctuating group size for the evolution of cooperation</title><categories>q-bio.PE cs.SI physics.soc-ph</categories><comments>22 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studies of cooperation have traditionally focused on discrete games such as
the well-known prisoner's dilemma, in which players choose between two pure
strategies: cooperation and defection. Increasingly, however, cooperation is
being studied in continuous games that feature a continuum of strategies
determining the level of cooperative investment. For the continuous snowdrift
game, it has been shown that a gradually evolving monomorphic population may
undergo evolutionary branching, resulting in the emergence of a defector
strategy that coexists with a cooperator strategy. This phenomenon has been
dubbed the 'tragedy of the commune'. Here we study the effects of fluctuating
group size on the tragedy of the commune and derive analytical conditions for
evolutionary branching. Our results show that the effects of fluctuating group
size on evolutionary dynamics critically depend on the structure of payoff
functions. For games with additively separable benefits and costs, fluctuations
in group size make evolutionary branching less likely, and sufficiently large
fluctuations in group size can always turn an evolutionary branching point into
a locally evolutionarily stable strategy. For games with multiplicatively
separable benefits and costs, fluctuations in group size can either prevent or
induce the tragedy of the commune. For games with general interactions between
benefits and costs, we derive a general classification scheme based on second
derivatives of the payoff function, to elucidate when fluctuations in group
size help or hinder cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5493</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5493</id><created>2010-10-26</created><updated>2011-07-25</updated><authors><author><keyname>Tonoyan</keyname><forenames>Tigran</forenames></author></authors><title>On Wireless Scheduling Using the Mean Power Assignment</title><categories>cs.NI</categories><doi>10.1007/978-3-642-19754-3_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the problem of scheduling with power control in wireless
networks is studied: given a set of communication requests, one needs to assign
the powers of the network nodes, and schedule the transmissions so that they
can be done in a minimum time, taking into account the signal interference of
concurrently transmitting nodes. The signal interference is modeled by SINR
constraints. Approximation algorithms are given for this problem, which use the
mean power assignment. The problem of schduling with fixed mean power
assignment is also considered, and approximation guarantees are proven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5497</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5497</id><created>2010-10-26</created><authors><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>Multiparty Equality Function Computation in Networks with Point-to-Point
  Links</title><categories>cs.IT cs.DC math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we study the multiparty communication complexity problem of
the multiparty equality function (MEQ): EQ(x_1,...,x_n) = 1 if x_1=...=x_n, and
0 otherwise. The input vector (x_1,...,x_n) is distributed among n&gt;=2 nodes,
with x_i known to node i, where x_i is chosen from the set {1,...,M}, for some
integer M&gt;0.
  Instead of the &quot;number on the forehand&quot; model, we consider a point-to-point
communication model (similar to the message passing model), which we believe is
more realistic in networking settings. We assume a synchronous fully connected
network of n nodes, the node IDs (identifiers) are common knowledge. We assume
that all point-to-point communication channels/links are private such that when
a node transmits, only the designated recipient can receive the message. The
identity of the sender is known to the recipient.
  We demonstrate that traditional techniques generalized from two-party
communication complexity problem are not sufficient to obtain tight bounds
under the point-to-point communication model. We then introduce techniques
which significantly reduce the space of protocols to study. These techniques
are used to study some instances of the MEQ problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5504</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5504</id><created>2010-10-26</created><authors><author><keyname>Myers</keyname><forenames>Seth A.</forenames></author><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author></authors><title>On the Convexity of Latent Social Network Inference</title><categories>cs.SI physics.soc-ph</categories><comments>NIPS, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many real-world scenarios, it is nearly impossible to collect explicit
social network data. In such cases, whole networks must be inferred from
underlying observations. Here, we formulate the problem of inferring latent
social networks based on network diffusion or disease propagation data. We
consider contagions propagating over the edges of an unobserved social network,
where we only observe the times when nodes became infected, but not who
infected them. Given such node infection times, we then identify the optimal
network that best explains the observed data. We present a maximum likelihood
approach based on convex programming with a l1-like penalty term that
encourages sparsity. Experiments on real and synthetic data reveal that our
method near-perfectly recovers the underlying network structure as well as the
parameters of the contagion propagation model. Moreover, our approach scales
well as it can infer optimal networks of thousands of nodes in a matter of
minutes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5506</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5506</id><created>2010-10-26</created><updated>2013-11-19</updated><authors><author><keyname>Lai</keyname><forenames>Ching-Yi</forenames></author><author><keyname>Brun</keyname><forenames>Todd A.</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Dualities and Identities for Entanglement-Assisted Quantum Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>24 pages, 3 figures, to be published in Quantum Information
  Processing. A new section about EA hashing bound is included in the new
  version</comments><journal-ref>Quantum Information Processing, vol. 13, no. 4, pages 957-990
  (April 2014)</journal-ref><doi>10.1007/s11128-013-0704-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dual of an entanglement-assisted quantum error-correcting (EAQEC) code is
the code resulting from exchanging the original code's information qubits with
its ebits. To introduce this notion, we show how entanglement-assisted (EA)
repetition codes and accumulator codes are dual to each other, much like their
classical counterparts, and we give an explicit, general quantum shift-register
circuit that encodes both classes of codes.We later show that our constructions
are optimal, and this result completes our understanding of these dual classes
of codes. We also establish the Gilbert-Varshamov bound and the Plotkin bound
for EAQEC codes, and we use these to examine the existence of some EAQEC codes.
Finally, we provide upper bounds on the block error probability when
transmitting maximal-entanglement EAQEC codes over the depolarizing channel,
and we derive variations of the hashing bound for EAQEC codes, which is a lower
bound on the maximum rate at which reliable communication over Pauli channels
is possible with the use of pre-shared entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5511</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5511</id><created>2010-10-26</created><authors><author><keyname>Stobbe</keyname><forenames>Peter</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Efficient Minimization of Decomposable Submodular Functions</title><categories>cs.LG math.OC</categories><comments>Expanded version of paper for Neural Information Processing Systems
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many combinatorial problems arising in machine learning can be reduced to the
problem of minimizing a submodular function. Submodular functions are a natural
discrete analog of convex functions, and can be minimized in strongly
polynomial time. Unfortunately, state-of-the-art algorithms for general
submodular minimization are intractable for larger problems. In this paper, we
introduce a novel subclass of submodular minimization problems that we call
decomposable. Decomposable submodular functions are those that can be
represented as sums of concave functions applied to modular functions. We
develop an algorithm, SLG, that can efficiently minimize decomposable
submodular functions with tens of thousands of variables. Our algorithm
exploits recent results in smoothed convex minimization. We apply SLG to
synthetic benchmarks and a joint classification-and-segmentation task, and show
that it outperforms the state-of-the-art general purpose submodular
minimization algorithms by several orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5524</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5524</id><created>2010-10-26</created><authors><author><keyname>Mezghani</keyname><forenames>Amine</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>Analysis of 1-bit Output Noncoherent Fading Channels in the Low SNR
  Regime</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, 2009 IEEE International Symposium on Information
  Theory, ISIT 2009, Seoul, Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider general multi-antenna fading channels with coarsely quantized
outputs, where the channel is unknown to the transmitter and receiver. This
analysis is of interest in the context of sensor network communication where
low power and low cost are key requirements (e.g. standard IEEE 802.15.4
applications). This is also motivated by highly energy constrained
communications devices where sampling the signal may be more energy consuming
than processing or transmitting it. Therefore the analog-to-digital converters
(ADCs) for such applications should be low-resolution, in order to reduce their
cost and power consumption. In this paper, we consider the extreme case of only
1-bit ADC for each receive signal component. We derive asymptotics of the
mutual information up to the second order in the signal-to-noise ratio (SNR)
under average and peak power constraints and study the impact of quantization.
We show that up to second order in SNR, the mutual information of a system with
two-level (sign) output signals incorporates only a power penalty factor of
almost 1.96 dB compared to the system with infinite resolution for all channels
of practical interest. This generalizes a recent result for the coherent case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5526</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5526</id><created>2010-10-26</created><authors><author><keyname>Mezghani</keyname><forenames>Amine</forenames></author><author><keyname>Ivrlac</keyname><forenames>Michel T.</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>Achieving near-Capacity on Large Discrete Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures, 2008 International Symposium on Information
  Theory and its Applications (ISITA2008), Auckland, New Zealand</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method to increase the capacity achieved by uniform prior in
discrete memoryless channels (DMC) with high input cardinality. It consists in
appropriately reducing the input set. Different design criteria of the input
subset are discussed. We develop an efficient algorithm to solve this problem
based on the maximization of the cut-off rate. The method is applied to a
mono-bit transceiver MIMO system, and it is shown that the capacity can be
approached within tenths of a dB by employing standard binary codes while
avoiding the use of distribution shapers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5529</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5529</id><created>2010-10-26</created><authors><author><keyname>Mezghani</keyname><forenames>Amine</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>Belief Propagation based MIMO Detection Operating on Quantized Channel
  Output</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figure, 2010 IEEE International Symposium on Information
  Theory (ISIT 2010), Austin, Texas</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multiple-antenna communications, as bandwidth and modulation order
increase, system components must work with demanding tolerances. In particular,
high resolution and high sampling rate analog-to-digital converters (ADCs) are
often prohibitively challenging to design. Therefore ADCs for such applications
should be low-resolution. This paper provides new insights into the problem of
optimal signal detection based on quantized received signals for multiple-input
multiple-output (MIMO) channels. It capitalizes on previous works which
extensively analyzed the unquantized linear vector channel using graphical
inference methods. In particular, a &quot;loopy&quot; belief propagation-like (BP) MIMO
detection algorithm, operating on quantized data with low complexity, is
proposed. In addition, we study the impact of finite receiver resolution in
fading channels in the large-system limit by means of a state evolution
analysis of the BP algorithm, which refers to the limit where the number of
transmit and receive antennas go to infinity with a fixed ratio. Simulations
show that the theoretical findings might give accurate results even with
moderate number of antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5532</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5532</id><created>2010-10-26</created><authors><author><keyname>Mezghani</keyname><forenames>Amine</forenames></author><author><keyname>Antreich</keyname><forenames>Felix</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>Multiple Parameter Estimation With Quantized Channel Output</title><categories>cs.IT math.IT</categories><comments>9 pages, 9 figures, International ITG Workshop on Smart Antennas -
  WSA 2010, Bremen, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general problem formulation for optimal parameter estimation
based on quantized observations, with application to antenna array
communication and processing (channel estimation, time-of-arrival (TOA) and
direction-of-arrival (DOA) estimation). The work is of interest in the case
when low resolution A/D-converters (ADCs) have to be used to enable higher
sampling rate and to simplify the hardware. An Expectation-Maximization (EM)
based algorithm is proposed for solving this problem in a general setting.
Besides, we derive the Cramer-Rao Bound (CRB) and discuss the effects of
quantization and the optimal choice of the ADC characteristic. Numerical and
analytical analysis reveals that reliable estimation may still be possible even
when the quantization is very coarse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5537</identifier>
 <datestamp>2012-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5537</id><created>2010-10-26</created><updated>2012-04-25</updated><authors><author><keyname>Miranskyy</keyname><forenames>A. V.</forenames></author><author><keyname>Davison</keyname><forenames>M.</forenames></author><author><keyname>Reesor</keyname><forenames>M.</forenames></author><author><keyname>Murtaza</keyname><forenames>S. S.</forenames></author></authors><title>Using entropy measures for comparison of software traces</title><categories>cs.SE cs.IT math.IT</categories><comments>Extended version appears in Information Sciences</comments><msc-class>94A17</msc-class><acm-class>D.2.5; G.2.3; H.1.1</acm-class><journal-ref>Information Sciences 203 (2012) pp. 59-72</journal-ref><doi>10.1016/j.ins.2012.03.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of execution paths (also known as software traces) collected
from a given software product can help in a number of areas including software
testing, software maintenance and program comprehension. The lack of a scalable
matching algorithm operating on detailed execution paths motivates the search
for an alternative solution.
  This paper proposes the use of word entropies for the classification of
software traces. Using a well-studied defective software as an example, we
investigate the application of both Shannon and extended entropies
(Landsberg-Vedral, R\'{e}nyi and Tsallis) to the classification of traces
related to various software defects. Our study shows that using entropy
measures for comparisons gives an efficient and scalable method for comparing
traces. The three extended entropies, with parameters chosen to emphasize rare
events, all perform similarly and are superior to the Shannon entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5545</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5545</id><created>2010-10-26</created><updated>2013-12-20</updated><authors><author><keyname>James</keyname><forenames>Ryan G.</forenames></author><author><keyname>Mahoney</keyname><forenames>John R.</forenames></author><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>Many Roads to Synchrony: Natural Time Scales and Their Algorithms</title><categories>nlin.CD cs.FL cs.IT math.DS math.IT</categories><comments>17 pages, 16 figures:
  http://cse.ucdavis.edu/~cmg/compmech/pubs/kro.htm. Santa Fe Institute Working
  Paper 10-11-025</comments><journal-ref>Phys. Rev. E 89, 042135 (2014)</journal-ref><doi>10.1103/PhysRevE.89.042135</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two important time scales---the Markov and cryptic orders---that
monitor how an observer synchronizes to a finitary stochastic process. We show
how to compute these orders exactly and that they are most efficiently
calculated from the epsilon-machine, a process's minimal unifilar model.
Surprisingly, though the Markov order is a basic concept from stochastic
process theory, it is not a probabilistic property of a process. Rather, it is
a topological property and, moreover, it is not computable from any
finite-state model other than the epsilon-machine. Via an exhaustive survey, we
close by demonstrating that infinite Markov and infinite cryptic orders are a
dominant feature in the space of finite-memory processes. We draw out the roles
played in statistical mechanical spin systems by these two complementary length
scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5562</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5562</id><created>2010-10-26</created><authors><author><keyname>Scheibler</keyname><forenames>Robin</forenames></author><author><keyname>Hurley</keyname><forenames>Paul</forenames></author><author><keyname>Chebira</keyname><forenames>Amina</forenames></author></authors><title>Fast Continuous Haar and Fourier Transforms of Rectilinear Polygons from
  VLSI Layouts</title><categories>cs.CE cs.CG cs.DS</categories><comments>10 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop the pruned continuous Haar transform and the fast continuous
Fourier series, two fast and efficient algorithms for rectilinear polygons.
Rectilinear polygons are used in VLSI processes to describe design and mask
layouts of integrated circuits. The Fourier representation is at the heart of
many of these processes and the Haar transform is expected to play a major role
in techniques envisioned to speed up VLSI design. To ensure correct printing of
the constantly shrinking transistors and simultaneously handle their
increasingly large number, ever more computationally intensive techniques are
needed. Therefore, efficient algorithms for the Haar and Fourier transforms are
vital. We derive the complexity of both algorithms and compare it to that of
discrete transforms traditionally used in VLSI. We find a significant reduction
in complexity when the number of vertices of the polygons is small, as is the
case in VLSI layouts. This analysis is completed by an implementation and a
benchmark of the continuous algorithms and their discrete counterpart. We show
that on tested VLSI layouts the pruned continuous Haar transform is 5 to 25
times faster, while the fast continuous Fourier series is 1.5 to 3 times
faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5565</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5565</id><created>2010-10-27</created><authors><author><keyname>Lambertz</keyname><forenames>Christian</forenames><affiliation>University of Mannheim</affiliation></author><author><keyname>Majster-Cederbaum</keyname><forenames>Mila</forenames><affiliation>University of Mannheim</affiliation></author></authors><title>Port Protocols for Deadlock-Freedom of Component Systems</title><categories>cs.LO</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 7-11</journal-ref><doi>10.4204/EPTCS.38.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In component-based development, approaches for property verification exist
that avoid building the global system behavior of the component model.
Typically, these approaches rely on the analysis of the local behavior of fixed
sized subsystems of components. In our approach, we want to avoid not only the
analysis of the global behavior but also of the local behaviors of the
components. Instead, we consider very small parts of the local behaviors called
port protocols that suffice to verify properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5566</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5566</id><created>2010-10-27</created><authors><author><keyname>Carbone</keyname><forenames>Marco</forenames><affiliation>IT University of Copenhagen</affiliation></author><author><keyname>Debois</keyname><forenames>S&#xf8;ren</forenames><affiliation>IT University of Copenhagen</affiliation></author></authors><title>A Graphical Approach to Progress for Structured Communication in Web
  Services</title><categories>cs.PL cs.LO cs.NI</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 13-27</journal-ref><doi>10.4204/EPTCS.38.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a graphical representation of session invocation
interdependency in order to prove progress for the pi-calculus with sessions
under the usual session typing discipline. We show that those processes whose
associated dependency graph is acyclic can be brought to reduce. We call such
processes transparent processes. Additionally, we prove that for well-typed
processes where services contain no free names, such acyclicity is preserved by
the reduction semantics.
  Our results encompass programs (processes containing neither free nor
restricted session channels) and higher-order sessions (delegation).
Furthermore, we give examples suggesting that transparent processes constitute
a large enough class of processes with progress to have applications in modern
session-based programming languages for web services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5567</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5567</id><created>2010-10-27</created><authors><author><keyname>Hernandez</keyname><forenames>Alejandro Mario</forenames><affiliation>Technical University of Denmark</affiliation></author><author><keyname>Nielson</keyname><forenames>Flemming</forenames><affiliation>Technical University of Denmark</affiliation></author></authors><title>History-sensitive versus future-sensitive approaches to security in
  distributed systems</title><categories>cs.CR cs.DC cs.PL</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 29-43</journal-ref><doi>10.4204/EPTCS.38.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the use of aspect-oriented techniques as a flexible way to deal
with security policies in distributed systems. Recent work suggests to use
aspects for analysing the future behaviour of programs and to make access
control decisions based on this; this gives the flavour of dealing with
information flow rather than mere access control. We show in this paper that it
is beneficial to augment this approach with history-based components as is the
traditional approach in reference monitor-based approaches to mandatory access
control. Our developments are performed in an aspect-oriented coordination
language aiming to describe the Bell-LaPadula policy as elegantly as possible.
Furthermore, the resulting language has the capability of combining both
history- and future-sensitive policies, providing even more flexibility and
power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5568</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5568</id><created>2010-10-27</created><authors><author><keyname>Bodei</keyname><forenames>Chiara</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Pisa</affiliation></author><author><keyname>Dinh</keyname><forenames>Viet Dung</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Pisa</affiliation></author><author><keyname>Ferrari</keyname><forenames>Gian Luigi</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Pisa</affiliation></author></authors><title>Safer in the Clouds (Extended Abstract)</title><categories>cs.CR</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 45-49</journal-ref><doi>10.4204/EPTCS.38.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We outline the design of a framework for modelling cloud computing
systems.The approach is based on a declarative programming model which takes
the form of a lambda-calculus enriched with suitable mechanisms to express and
enforce application-level security policies governing usages of resources
available in the clouds. We will focus on the server side of cloud systems, by
adopting a pro-active approach, where explicit security policies regulate
server's behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5569</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5569</id><created>2010-10-27</created><authors><author><keyname>Lanese</keyname><forenames>Ivan</forenames><affiliation>Focus Team, University of Bologna/INRIA</affiliation></author></authors><title>Static vs Dynamic SAGAs</title><categories>cs.PL</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 51-65</journal-ref><doi>10.4204/EPTCS.38.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SAGAs calculi (or simply SAGAs) have been proposed by Bruni et al. as a model
for long-running transactions. The approach therein can be considered static,
while a dynamic approach has been proposed by Lanese and Zavattaro. In this
paper we first extend both static SAGAs (in the centralized interruption
policy) and dynamic SAGAs to deal with nesting, then we compare the two
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5570</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5570</id><created>2010-10-27</created><authors><author><keyname>Bartoletti</keyname><forenames>Massimo</forenames><affiliation>Dipartimento di Matematica e Informatica, Universit&#xe0; degli Studi di Cagliari</affiliation></author><author><keyname>Zunino</keyname><forenames>Roberto</forenames><affiliation>Dipartimento di Ingegneria e Scienza dell'Informazione, Universit&#xe0; degli studi di Trento</affiliation></author></authors><title>Primitives for Contract-based Synchronization</title><categories>cs.PL cs.LO cs.SE</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 67-82</journal-ref><doi>10.4204/EPTCS.38.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate how contracts can be used to regulate the interaction between
processes. To do that, we study a variant of the concurrent constraints
calculus presented in [1], featuring primitives for multi-party synchronization
via contracts. We proceed in two directions. First, we exploit our primitives
to model some contract-based interactions. Then, we discuss how several models
for concurrency can be expressed through our primitives. In particular, we
encode the pi-calculus and graph rewriting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5571</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5571</id><created>2010-10-27</created><authors><author><keyname>Lemerre</keyname><forenames>Matthieu</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>David</keyname><forenames>Vincent</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>Aussagu&#xe8;s</keyname><forenames>Christophe</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>Vidal-Naquet</keyname><forenames>Guy</forenames><affiliation>SUPELEC</affiliation></author></authors><title>An Introduction to Time-Constrained Automata</title><categories>cs.LO cs.FL cs.OS cs.SE</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 83-98</journal-ref><doi>10.4204/EPTCS.38.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present time-constrained automata (TCA), a model for hard real-time
computation in which agents behaviors are modeled by automata and constrained
by time intervals.
  TCA actions can have multiple start time and deadlines, can be aperiodic, and
are selected dynamically following a graph, the time-constrained automaton.
This allows expressing much more precise time constraints than classical
periodic or sporadic model, while preserving the ease of scheduling and
analysis.
  We provide some properties of this model as well as their scheduling
semantics. We show that TCA can be automatically derived from source-code, and
optimally scheduled on single processors using a variant of EDF. We explain how
time constraints can be used to guarantee communication determinism by
construction, and to study when possible agent interactions happen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5572</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5572</id><created>2010-10-27</created><authors><author><keyname>Beohar</keyname><forenames>Harsh</forenames><affiliation>TU/e</affiliation></author><author><keyname>Cuijpers</keyname><forenames>Pieter</forenames><affiliation>TU/e</affiliation></author></authors><title>A theory of desynchronisable closed loop system</title><categories>cs.LO</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 38, 2010, pp. 99-114</journal-ref><doi>10.4204/EPTCS.38.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of implementing a supervisory controller is non-trivial, even though
different theories exist that allow automatic synthesis of these controllers in
the form of automata. One of the reasons for this discord is due to the
asynchronous interaction between a plant and its controller in implementations,
whereas the existing supervisory control theories assume synchronous
interaction. As a consequence the implementation suffer from the so-called
inexact synchronisation problem. In this paper we address the issue of inexact
synchronisation in a process algebraic setting, by solving a more general
problem of refinement. We construct an asynchronous closed loop system by
introducing a communication medium in a given synchronous closed loop system.
Our goal is to find sufficient conditions under which a synchronous closed loop
system is branching bisimilar to its corresponding asynchronous closed loop
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5573</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5573</id><created>2010-10-27</created><authors><author><keyname>Sirdey</keyname><forenames>Renaud</forenames><affiliation>Commissariat &#xe0; l'Energie Atomique, France</affiliation></author><author><keyname>Aubry</keyname><forenames>Pascal</forenames><affiliation>Commissariat &#xe0; l'Energie Atomique, France</affiliation></author></authors><title>A linear programming approach to general dataflow process network
  verification and dimensioning</title><categories>cs.DC cs.SE</categories><comments>In Proceedings ICE 2010, arXiv:1010.5308</comments><proxy>EPTCS</proxy><acm-class>F3.1</acm-class><journal-ref>EPTCS 38, 2010, pp. 115-119</journal-ref><doi>10.4204/EPTCS.38.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present linear programming-based sufficient conditions,
some of them polynomial-time, to establish the liveness and memory boundedness
of general dataflow process networks. Furthermore, this approach can be used to
obtain safe upper bounds on the size of the channel buffers of such a network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5582</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5582</id><created>2010-10-27</created><authors><author><keyname>Leroy</keyname><forenames>Xavier</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Mechanized semantics</title><categories>cs.PL</categories><proxy>ccsd</proxy><journal-ref>Logics and languages for reliability and security, J. Esparza and
  B. Spanfelner and O. Grumberg (Ed.) (2010) 195-224</journal-ref><doi>10.3233/978-1-60750-100-8-195</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this lecture is to show how modern theorem provers---in this
case, the Coq proof assistant---can be used to mechanize the specification of
programming languages and their semantics, and to reason over individual
programs and over generic program transformations, as typically found in
compilers. The topics covered include: operational semantics (small-step,
big-step, definitional interpreters); a simple form of denotational semantics;
axiomatic semantics and Hoare logic; generation of verification conditions,
with application to program proof; compilation to virtual machine code and its
proof of correctness; an example of an optimizing program transformation (dead
code elimination) and its proof of correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5584</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5584</id><created>2010-10-27</created><authors><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames></author></authors><title>A derivational rephrasing experiment for question answering</title><categories>cs.IR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Knowledge Management, variations in information expressions have proven a
real challenge. In particular, classical semantic relations (e.g. synonymy) do
not connect words with different parts-of-speech. The method proposed tries to
address this issue. It consists in building a derivational resource from a
morphological derivation tool together with derivational guidelines from a
dictionary in order to store only correct derivatives. This resource, combined
with a syntactic parser, a semantic disambiguator and some derivational
patterns, helps to reformulate an original sentence while keeping the initial
meaning in a convincing manner This approach has been evaluated in three
different ways: the precision of the derivatives produced from a lemma; its
ability to provide well-formed reformulations from an original sentence,
preserving the initial meaning; its impact on the results coping with a real
issue, ie a question answering task . The evaluation of this approach through a
question answering system shows the pros and cons of this system, while
foreshadowing some interesting future developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5595</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5595</id><created>2010-10-27</created><updated>2010-11-23</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Zvesper</keyname><forenames>Jonathan A.</forenames></author></authors><title>The Role of Monotonicity in the Epistemic Analysis of Strategic Games</title><categories>cs.GT math.LO</categories><comments>20 pages</comments><journal-ref>Games 2010, 1(4), 381-394; see
  http://www.mdpi.com/2073-4336/1/4/381/</journal-ref><doi>10.3390/g1040381</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  It is well-known that in finite strategic games true common belief (or common
knowledge) of rationality implies that the players will choose only strategies
that survive the iterated elimination of strictly dominated strategies. We
establish a general theorem that deals with monotonic rationality notions and
arbitrary strategic games and allows to strengthen the above result to
arbitrary games, other rationality notions, and transfinite iterations of the
elimination process. We also clarify what conclusions one can draw for the
customary dominance notions that are not monotonic. The main tool is Tarski's
Fixpoint Theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5608</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5608</id><created>2010-10-27</created><updated>2010-11-18</updated><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Tang</keyname><forenames>Ao Kevin</forenames></author></authors><title>A Generalized Coupon Collector Problem</title><categories>cs.IT cs.DM cs.PF math.IT</categories><comments>20 pages, 6 figures, preprint</comments><msc-class>Primary-60G70, Secondary-60C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides analysis to a generalized version of the coupon collector
problem, in which the collector gets $d$ distinct coupons each run and she
chooses the one that she has the least so far. On the asymptotic case when the
number of coupons $n$ goes to infinity, we show that on average $\frac{n\log
n}{d} + \frac{n}{d}(m-1)\log\log{n}+O(mn)$ runs are needed to collect $m$ sets
of coupons. An efficient exact algorithm is also developed for any finite case
to compute the average needed runs exactly. Numerical examples are provided to
verify our theoretical predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5610</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5610</id><created>2010-10-27</created><authors><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Chen</keyname><forenames>Qiang</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author><author><keyname>Cheong</keyname><forenames>Loong-Fah</forenames></author></authors><title>Selective Image Super-Resolution</title><categories>cs.CV</categories><comments>20 pages, 5 figures. Submitted to Computer Vision and Image
  Understanding in March 2010. Keywords: image super resolution, semantic image
  segmentation, vision system, vision application</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a vision system that performs image Super Resolution
(SR) with selectivity. Conventional SR techniques, either by multi-image fusion
or example-based construction, have failed to capitalize on the intrinsic
structural and semantic context in the image, and performed &quot;blind&quot; resolution
recovery to the entire image area. By comparison, we advocate example-based
selective SR whereby selectivity is exemplified in three aspects: region
selectivity (SR only at object regions), source selectivity (object SR with
trained object dictionaries), and refinement selectivity (object boundaries
refinement using matting). The proposed system takes over-segmented
low-resolution images as inputs, assimilates recent learning techniques of
sparse coding (SC) and grouped multi-task lasso (GMTL), and leads eventually to
a framework for joint figure-ground separation and interest object SR. The
efficiency of our framework is manifested in our experiments with subsets of
the VOC2009 and MSRC datasets. We also demonstrate several interesting vision
applications that can build on our system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5623</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5623</id><created>2010-10-27</created><authors><author><keyname>Carofiglio</keyname><forenames>Giovanna</forenames></author><author><keyname>Muscariello</keyname><forenames>Luca</forenames></author><author><keyname>Rossi</keyname><forenames>Dario</forenames></author><author><keyname>Testa</keyname><forenames>Claudio</forenames></author><author><keyname>Valenti</keyname><forenames>Silvio</forenames></author></authors><title>Rethinking low extra delay background transport protocols</title><categories>cs.NI</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BitTorrent has recently introduced LEDBAT, a novel application-layer
congestion control protocol for data exchange. The protocol design starts from
the assumption that network bottlenecks are at the access of the network, and
that thus user traffic competes creating self-inducing congestion. To relieve
from this phenomenon, LEDBAT is designed to quickly infer that self-induced
congestion is approaching (by detecting relative changes of the one-way delay
in the transmission path), and to react by reducing the sending rate prior that
congestion occurs. Prior work has however shown LEDBAT to be affected by a
latecomer advantage, where newly arriving connections can starve already
existing flows. In this work, we propose modifications to the congestion window
update mechanism of the LEDBAT protocol that aim at solving this issue,
guaranteeing thus intra-protocol fairness and efficiency. Closed-form
expressions for the stationary throughput and queue occupancy are provided via
a fluid model, whose accuracy is confirmed by means of ns2 packet level
simulations. Our results show that the proposed change can effective solve the
latecomer issue, without affecting the other original LEDBAT goals at the same
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5624</identifier>
 <datestamp>2015-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5624</id><created>2010-10-27</created><updated>2012-05-05</updated><authors><author><keyname>Esperet</keyname><forenames>Louis</forenames><affiliation>G-SCOP</affiliation></author><author><keyname>Gravier</keyname><forenames>Sylvain</forenames><affiliation>IF</affiliation></author><author><keyname>Montassier</keyname><forenames>Mickael</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Ochem</keyname><forenames>Pascal</forenames><affiliation>LRI</affiliation></author><author><keyname>Parreau</keyname><forenames>Aline</forenames><affiliation>IF</affiliation></author></authors><title>Locally identifying coloring of graphs</title><categories>cs.DM math.CO</categories><comments>21 pages</comments><proxy>ccsd</proxy><journal-ref>Electron. J. Combin. 19(2) (2012), #P40</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of locally identifying coloring of a graph. A proper
vertex-coloring c of a graph G is said to be locally identifying, if for any
adjacent vertices u and v with distinct closed neighborhood, the sets of colors
that appear in the closed neighborhood of u and v are distinct. Let
$\chi_{lid}(G)$ be the minimum number of colors used in a locally identifying
vertex-coloring of G. In this paper, we give several bounds on $\chi_{lid}$ for
different families of graphs (planar graphs, some subclasses of perfect graphs,
graphs with bounded maximum degree) and prove that deciding whether
$\chi_{lid}(G)=3$ for a subcubic bipartite graph $G$ with large girth is an
NP-complete problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5642</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5642</id><created>2010-10-27</created><authors><author><keyname>Xiong</keyname><forenames>Hu</forenames></author><author><keyname>Chen</keyname><forenames>Zhong</forenames></author></authors><title>Privacy-Preserving English Auction Protocol with Round Efficiency</title><categories>cs.GT cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A privacy-preserving English auction protocol with round efficiency based on
a modified ring signature has been proposed in this paper. The proposed
protocol has three appealing characteristic: First, it offers conditional
privacy-preservation: on the one hand, the bidder is anonymous to the public,
on the other hand, only the collaboration of auctioneer and registration
manager can reveal the true identity of a malicious bidder. Second, it does not
require to maintain a black list which records the evicted malicious bidders.
Finally, it is efficient: it saves the communication round complexity comparing
with previously proposed solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5644</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5644</id><created>2010-10-27</created><authors><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author><author><keyname>Hollanti</keyname><forenames>Camilla</forenames></author><author><keyname>Oggier</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames></author></authors><title>Fast-Decodable Asymmetric Space-Time Codes from Division Algebras</title><categories>cs.IT math.IT math.RA</categories><comments>26 pages, 1 figure, submitted to IEEE Trans. Inf. Theory, October
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input double-output (MIDO) codes are important in the near-future
wireless communications, where the portable end-user device is physically small
and will typically contain at most two receive antennas. Especially tempting is
the 4 x 2 channel due to its immediate applicability in the digital video
broadcasting (DVB). Such channels optimally employ rate-two space-time (ST)
codes consisting of (4 x 4) matrices. Unfortunately, such codes are in general
very complex to decode, hence setting forth a call for constructions with
reduced complexity.
  Recently, some reduced complexity constructions have been proposed, but they
have mainly been based on different ad hoc methods and have resulted in
isolated examples rather than in a more general class of codes. In this paper,
it will be shown that a family of division algebra based MIDO codes will always
result in at least 37.5% worst-case complexity reduction, while maintaining
full diversity and, for the first time, the non-vanishing determinant (NVD)
property. The reduction follows from the fact that, similarly to the Alamouti
code, the codes will be subsets of matrix rings of the Hamiltonian quaternions,
hence allowing simplified decoding. At the moment, such reductions are among
the best known for rate-two MIDO codes. Several explicit constructions are
presented and shown to have excellent performance through computer simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5661</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5661</id><created>2010-10-27</created><updated>2011-11-11</updated><authors><author><keyname>Shen</keyname><forenames>Minqi</forenames></author><author><keyname>H&#xf8;st-Madsen</keyname><forenames>Anders</forenames></author></authors><title>The Wideband Slope of Interference Channels: The Large Bandwidth Case</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that minimum received energy per bit in the interference
channel is -1.59dB as if there were no interference. Thus, the best way to
mitigate interference is to operate the interference channel in the low-SNR
regime. However, when the SNR is small but non-zero, minimum energy per bit
alone does not characterize performance. Verdu introduced the wideband slope
S_0 to characterize the performance in this regime. We show that a wideband
slope of S_0/S_{0,no interference}=1/2 is achievable. This result is similar to
recent results on degrees of freedom in the high SNR regime, and we use a type
of interference alignment using delays to obtain the result. We also show that
in many cases the wideband slope is upper bounded by S_0/S_{0,no
interference}&lt;=1/2 for large number of users K .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5665</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5665</id><created>2010-10-27</created><authors><author><keyname>Roy</keyname><forenames>Pritam</forenames></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author></authors><title>Safety-Guarantee Controller Synthesis for Cyber-Physical Systems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The verification and validation of cyber-physical systems is known to be a
difficult problem due to the different modeling abstractions used for control
components and for software components. A recent trend to address this
difficulty is to reduce the need for verification by adopting correct-by-design
methodologies. According to the correct-by-design paradigm, one seeks to
automatically synthesize a controller that can be refined into code and that
enforces temporal specifications on the cyber-physical system. In this paper we
consider an instance of this problem where the specifications are given by a
fragment of Linear Temporal Logic (LTL) and the physical environment is
described by a smooth differential equation. The contribution of this paper is
to show that synthesis for cyber-physical systems is viable by considering a
fragment of LTL that is expressive enough to describe interesting properties
but simple enough to avoid Safra's construction. We report on two examples
illustrating a preliminary implementation of these techniques on the tool
PESSOALTL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5691</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5691</id><created>2010-10-27</created><updated>2011-02-15</updated><authors><author><keyname>Tseng</keyname><forenames>Chia-Shiang</forenames></author><author><keyname>Chen</keyname><forenames>Chang-Ching</forenames></author><author><keyname>Lin</keyname><forenames>Che</forenames></author></authors><title>A Bio-Inspired Robust Adaptive Random Search Algorithm for Distributed
  Beamforming</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, In proc. ICC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A bio-inspired robust adaptive random search algorithm (BioRARSA), designed
for distributed beamforming for sensor and relay networks, is proposed in this
work. It has been shown via a systematic framework that BioRARSA converges in
probability and its convergence time scales linearly with the number of
distributed transmitters. More importantly, extensive simulation results
demonstrate that the proposed BioRARSA outperforms existing adaptive
distributed beamforming schemes by as large as 29.8% on average. This increase
in performance results from the fact that BioRARSA can adaptively adjust its
sampling stepsize via the &quot;swim&quot; behavior inspired by the bacterial foraging
mechanism. Hence, the convergence time of BioRARSA is insensitive to the
initial sampling stepsize of the algorithm, which makes it robust against the
dynamic nature of distributed wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5694</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5694</id><created>2010-10-27</created><authors><author><keyname>Baillie</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Demaille</keyname><forenames>Akim</forenames></author><author><keyname>Hocquet</keyname><forenames>Quentin</forenames></author><author><keyname>Nottale</keyname><forenames>Matthieu</forenames></author></authors><title>Events! (Reactivity in urbiscript)</title><categories>cs.PL cs.RO</categories><comments>DSLRob'10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urbi SDK is a software platform for the development of portable robotic
applications. It features the Urbi UObject C++ middleware, to manage hardware
drivers and/or possibly remote software components, and urbiscript, a domain
specific programming language to orchestrate them. Reactivity is a key feature
of Urbi SDK, embodied in events in urbiscript. This paper presents the support
for events in urbiscript.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5699</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5699</id><created>2010-10-27</created><updated>2012-04-25</updated><authors><author><keyname>Tanigawa</keyname><forenames>Shin-ichi</forenames></author></authors><title>Generic Rigidity Matroids with Dilworth Truncations</title><categories>math.CO cs.DM math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the linear matroid that defines generic rigidity of
$d$-dimensional body-rod-bar frameworks (i.e., structures consisting of
disjoint bodies and rods mutually linked by bars) can be obtained from the
union of ${d+1 \choose 2}$ graphic matroids by applying variants of Dilworth
truncation $n_r$ times, where $n_r$ denotes the number of rods. This leads to
an alternative proof of Tay's combinatorial characterizations of generic
rigidity of rod-bar frameworks and that of identified body-hinge frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5717</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5717</id><created>2010-10-27</created><authors><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author></authors><title>PPZ For More Than Two Truth Values - An Algorithm for Constraint
  Satisfaction Problems</title><categories>cs.DS</categories><comments>18 pages</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the so-called ppz algorithm for (d,k)-CSP problems for general
values of d (number of values a variable can take) and k (number of literals
per constraint). To analyze its success probability, we prove a correlation
inequality for submodular functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5720</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5720</id><created>2010-10-27</created><authors><author><keyname>Steudel</keyname><forenames>Bastian</forenames></author><author><keyname>Ay</keyname><forenames>Nihat</forenames></author></authors><title>Information-theoretic inference of common ancestors</title><categories>cs.IT math.IT</categories><comments>18 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A directed acyclic graph (DAG) partially represents the conditional
independence structure among observations of a system if the local Markov
condition holds, that is, if every variable is independent of its
non-descendants given its parents. In general, there is a whole class of DAGs
that represents a given set of conditional independence relations. We are
interested in properties of this class that can be derived from observations of
a subsystem only. To this end, we prove an information theoretic inequality
that allows for the inference of common ancestors of observed parts in any DAG
representing some unknown larger system. More explicitly, we show that a large
amount of dependence in terms of mutual information among the observations
implies the existence of a common ancestor that distributes this information.
Within the causal interpretation of DAGs our result can be seen as a
quantitative extension of Reichenbach's Principle of Common Cause to more than
two variables. Our conclusions are valid also for non-probabilistic
observations such as binary strings, since we state the proof for an
axiomatized notion of mutual information that includes the stochastic as well
as the algorithmic version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5734</identifier>
 <datestamp>2012-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5734</id><created>2010-10-27</created><updated>2012-03-15</updated><authors><author><keyname>Peleg</keyname><forenames>Tomer</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author></authors><title>Exploiting Statistical Dependencies in Sparse Representations for Signal
  Recovery</title><categories>cs.IT math.IT</categories><comments>18 pages, 6 figures, to appear in IEEE Trans. on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signal modeling lies at the core of numerous signal and image processing
applications. A recent approach that has drawn considerable attention is sparse
representation modeling, in which the signal is assumed to be generated as a
combination of a few atoms from a given dictionary. In this work we consider a
Bayesian setting and go beyond the classic assumption of independence between
the atoms. The main goal of this paper is to introduce a statistical model that
takes such dependencies into account and show how this model can be used for
sparse signal recovery. We follow the suggestion of two recent works and assume
that the sparsity pattern is modeled by a Boltzmann machine, a commonly used
graphical model. For general dependency models, exact MAP and MMSE estimation
of the sparse representation becomes computationally complex. To simplify the
computations, we propose greedy approximations of the MAP and MMSE estimators.
We then consider a special case in which exact MAP is feasible, by assuming
that the dictionary is unitary and the dependency model corresponds to a
certain sparse graph. Exploiting this structure, we develop an efficient
message passing algorithm that recovers the underlying signal. When the model
parameters defining the underlying graph are unknown, we suggest an algorithm
that learns these parameters directly from the data, leading to an iterative
scheme for adaptive sparse signal recovery. The effectiveness of our approach
is demonstrated on real-life signals - patches of natural images - where we
compare the denoising performance to that of previous recovery methods that do
not exploit the statistical dependencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5742</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5742</id><created>2010-10-27</created><updated>2012-03-19</updated><authors><author><keyname>Zhang</keyname><forenames>Liangquan</forenames></author></authors><title>Stochastic Verification Theorem of Forward-Backward Controlled Systems
  for Viscosity Solutions</title><categories>math.OC cs.SY</categories><journal-ref>Systems &amp; Control Letters 61 (2012) 649-654</journal-ref><doi>10.1016/j.sysconle.2012.02.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the controlled system described by
forward-backward stochastic differential equations with the control contained
in drift, diffusion and generator of BSDE. A new verification theorem is
derived within the framework of viscosity solutions without involving any
derivatives of the value functions. It is worth to pointing out that this
theorem has wider applicability than the restrictive classical verification
theorems. As a relevant problem, the optimal stochastic feedback controls for
forward-backward system are discussed as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5749</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5749</id><created>2010-10-27</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Harre</keyname><forenames>Michael</forenames></author><author><keyname>Olbrich</keyname><forenames>Eckehard</forenames></author><author><keyname>Bertschinger</keyname><forenames>Nils</forenames></author><author><keyname>Jost</keyname><forenames>Juergen</forenames></author></authors><title>Hysteresis effects of changing parameters of noncooperative games</title><categories>cs.GT</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We adapt the method used by Jaynes to derive the equilibria of statistical
physics to instead derive equilibria of bounded rational game theory. We
analyze the dependence of these equilibria on the parameters of the underlying
game, focusing on hysteresis effects. In particular, we show that by gradually
imposing individual-specific tax rates on the players of the game, and then
gradually removing those taxes, the players move from a poor equilibrium to one
that is better for all of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5756</identifier>
 <datestamp>2014-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5756</id><created>2010-10-27</created><updated>2011-03-26</updated><authors><author><keyname>Kullmann</keyname><forenames>Oliver</forenames></author><author><keyname>Zhao</keyname><forenames>Xishun</forenames></author></authors><title>On variables with few occurrences in conjunctive normal forms</title><categories>cs.DM math.CO</categories><comments>14 pages. Revision contains more explanations, and more information
  regarding the sharpness of the bound</comments><msc-class>05D99, 68R05</msc-class><acm-class>F.2.2; G.2.2</acm-class><journal-ref>SAT 2011, LNCS 6695, page 33-46</journal-ref><doi>10.1007/978-3-642-21581-0_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the question of the existence of variables with few occurrences
in boolean conjunctive normal forms (clause-sets). Let mvd(F) for a clause-set
F denote the minimal variable-degree, the minimum of the number of occurrences
of variables. Our main result is an upper bound mvd(F) &lt;= nM(surp(F)) &lt;=
surp(F) + 1 + log_2(surp(F)) for lean clause-sets F in dependency on the
surplus surp(F).
  - Lean clause-sets, defined as having no non-trivial autarkies, generalise
minimally unsatisfiable clause-sets.
  - For the surplus we have surp(F) &lt;= delta(F) = c(F) - n(F), using the
deficiency delta(F) of clause-sets, the difference between the number of
clauses and the number of variables.
  - nM(k) is the k-th &quot;non-Mersenne&quot; number, skipping in the sequence of
natural numbers all numbers of the form 2^n - 1.
  We conjecture that this bound is nearly precise for minimally unsatisfiable
clause-sets.
  As an application of the upper bound we obtain that (arbitrary!) clause-sets
F with mvd(F) &gt; nM(surp(F)) must have a non-trivial autarky (so clauses can be
removed satisfiability-equivalently by an assignment satisfying some clauses
and not touching the other clauses). It is open whether such an autarky can be
found in polynomial time.
  As a future application we discuss the classification of minimally
unsatisfiable clause-sets depending on the deficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5764</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5764</id><created>2010-10-27</created><updated>2012-01-10</updated><authors><author><keyname>Randriambololona</keyname><forenames>Hugues</forenames></author></authors><title>(2,1)-separating systems beyond the probabilistic bound</title><categories>math.CO cs.IT math.AG math.IT</categories><comments>Version 7 is a shortened version, so that numbering should match with
  the journal version (to appear soon). Material on convexity and separation in
  discrete and continuous spaces has been removed. Readers interested in this
  material should consult version 6 instead</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building on previous results of Xing, we give new lower bounds on the rate of
intersecting codes over large alphabets. The proof is constructive, and uses
algebraic geometry, although nothing beyond the basic theory of linear systems
on curves. Then, using these new bounds within a concatenation argument, we
construct binary (2,1)-separating systems of asymptotic rate exceeding the one
given by the probabilistic method, which was the best lower bound available up
to now. This answers (negatively) the question of whether this probabilistic
bound was exact, which has remained open for more than 30 years. (By the way,
we also give a formulation of the separation property in terms of metric
convexity, which may be an inspirational source for new research problems.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5771</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5771</id><created>2010-10-27</created><authors><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Reward and cooperation in the spatial public goods game</title><categories>physics.soc-ph cs.SI</categories><comments>6 two-column pages, 5 figures; accepted for publication in
  Europhysics Letters</comments><journal-ref>EPL 92 (2010) 38003</journal-ref><doi>10.1209/0295-5075/92/38003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The promise of punishment and reward in promoting public cooperation is
debatable. While punishment is traditionally considered more successful than
reward, the fact that the cost of punishment frequently fails to offset gains
from enhanced cooperation has lead some to reconsider reward as the main
catalyst behind collaborative efforts. Here we elaborate on the &quot;stick versus
carrot&quot; dilemma by studying the evolution of cooperation in the spatial public
goods game, where besides the traditional cooperators and defectors, rewarding
cooperators supplement the array of possible strategies. The latter are willing
to reward cooperative actions at a personal cost, thus effectively downgrading
pure cooperators to second-order free-riders due to their unwillingness to bear
these additional costs. Consequently, we find that defection remains viable,
especially if the rewarding is costly. Rewards, however, can promote
cooperation, especially if the synergetic effects of cooperation are low.
Surprisingly, moderate rewards may promote cooperation better than high
rewards, which is due to the spontaneous emergence of cyclic dominance between
the three strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5793</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5793</id><created>2010-10-27</created><updated>2011-01-27</updated><authors><author><keyname>Serrano</keyname><forenames>M. Angeles</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author></authors><title>Percolation in self-similar networks</title><categories>cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>4 pages, 3 figures</comments><journal-ref>Phys. Rev. Lett. 106, 048701 (2011)</journal-ref><doi>10.1103/PhysRevLett.106.048701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a simple proof that graphs in a general class of self-similar
networks have zero percolation threshold. The considered self-similar networks
include random scale-free graphs with given expected node degrees and zero
clustering, scale-free graphs with finite clustering and metric structure,
growing scale-free networks, and many real networks. The proof and the
derivation of the giant component size do not require the assumption that
networks are treelike. Our results rely only on the observation that
self-similar networks possess a hierarchy of nested subgraphs whose average
degree grows with their depth in the hierarchy. We conjecture that this
property is pivotal for percolation in networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5806</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5806</id><created>2010-10-27</created><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>Inner and Outer Bounds for the Gaussian Cognitive Interference Channel
  and New Capacity Results</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE transaction of Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of the Gaussian cognitive interference channel, a variation of
the classical two-user interference channel where one of the transmitters
(referred to as cognitive) has knowledge of both messages, is known in several
parameter regimes but remains unknown in general. In this paper we provide a
comparative overview of this channel model as we proceed through our
contributions: we present a new outer bound based on the idea of a broadcast
channel with degraded message sets, and another series of outer bounds obtained
by transforming the cognitive channel into channels with known capacity. We
specialize the largest known inner bound derived for the discrete memoryless
channel to the Gaussian noise channel and present several simplified schemes
evaluated for Gaussian inputs in closed form which we use to prove a number of
results. These include a new set of capacity results for the a) &quot;primary
decodes cognitive&quot; regime, a subset of the &quot;strong interference&quot; regime that is
not included in the &quot;very strong interference&quot; regime for which capacity was
known, and for the b) &quot;S-channel&quot; in which the primary transmitter does not
interfere with the cognitive receiver. Next, for a general Gaussian cognitive
interference channel, we determine the capacity to within one bit/s/Hz and to
within a factor two regardless of channel parameters, thus establishing rate
performance guarantees at high and low SNR, respectively. We also show how
different simplified transmission schemes achieve a constant gap between inner
and outer bound for specific channels. Finally, we numerically evaluate and
compare the various simplified achievable rate regions and outer bounds in
parameter regimes where capacity is unknown, leading to further insight on the
capacity region of the Gaussian cognitive interference channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5829</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5829</id><created>2010-10-27</created><authors><author><keyname>Gao</keyname><forenames>Jianxi</forenames></author><author><keyname>Buldyrev</keyname><forenames>Sergey V.</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Stanley</keyname><forenames>H. Eugene</forenames></author></authors><title>Robustness of a Network of Networks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>7 pages, 3 figures</comments><journal-ref>Phys. Rev. Lett. 107, 195701 (2011)</journal-ref><doi>10.1103/PhysRevLett.107.195701</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Almost all network research has been focused on the properties of a single
network that does not interact and depends on other networks. In reality, many
real-world networks interact with other networks. Here we develop an analytical
framework for studying interacting networks and present an exact percolation
law for a network of $n$ interdependent networks. In particular, we find that
for $n$ Erd\H{o}s-R\'{e}nyi networks each of average degree $k$, the giant
component, $P_{\infty}$, is given by $P_{\infty}=p[1-\exp(-kP_{\infty})]^n$
where $1-p$ is the initial fraction of removed nodes. Our general result
coincides for $n=1$ with the known Erd\H{o}s-R\'{e}nyi second-order phase
transition for a single network. For any $n \geq 2$ cascading failures occur
and the transition becomes a first-order percolation transition. The new law
for $P_{\infty}$ shows that percolation theory that is extensively studied in
physics and mathematics is a limiting case ($n=1$) of a more general general
and different percolation law for interdependent networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5854</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5854</id><created>2010-10-28</created><updated>2010-10-29</updated><authors><author><keyname>Khalid</keyname><forenames>Shahrukh</forenames></author><author><keyname>Khan</keyname><forenames>Adnan Ali</forenames></author></authors><title>An Alternative Approach to Data Acquisition Using Keyboard Emulation
  Technique</title><categories>cs.HC</categories><comments>4 pages, 7 figures, conference</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A number of data acquisition systems depend on human interface to access
computer for measuring, processing and analyzing data and to prepare it for
presentation and storage. Data acquisition software is installed on the
computer and all intended operations are performed manually. The data
acquisition software requires user intervention for operations like selection
of measurement setup, acquisition and storage of data to computer. The duty of
users becomes laborious if the data acquisition process lasts for a long
duration and requires continuous repetition of steps. An appropriate solution
to overcome such problem is to replace the physical operator with a virtual
user. This software generated simulated user sits at the data acquisition
process through out and automate all the intended steps of data acquisition.
This paper presents a new approach for data acquisition by using keyboard
emulation technique. A keyboard emulation software is developed which runs
beside the main data acquisition software and acts as a virtual user. All the
operations which require user interface are performed through fully automated
computer program. The developed software/system is executed in a real time
environment and the functionality of the software is verified. In the end,
potential application areas of the designed keyboard emulation software are
explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5875</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5875</id><created>2010-10-28</created><authors><author><keyname>Stoianov</keyname><forenames>Nikolai Todorov</forenames></author><author><keyname>Tselkov</keyname><forenames>Veselin Tsenov</forenames></author></authors><title>E-Net Models of a Software System for E-Mail Security</title><categories>cs.CR</categories><comments>6 pages, 3 figures, Mathematics and Education in Mathematics, 2002
  Proceedings of the Thirty First Spring Conference of the Union of Bulgarian
  Mathematicians,pp.198-203, ISBN 954-8880-11-3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents solutions for cryptography protection in MS Outlook. The
solutions comprise the authors' experience in development and implementation of
systems for information security in the Automated Information Systems of
Bulgarian Armed Forces. The architecture, the models and the methods are being
explained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5881</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5881</id><created>2010-10-28</created><updated>2011-07-08</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Jones</keyname><forenames>Mark</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>Kernels for Below-Upper-Bound Parameterizations of the Hitting Set and
  Directed Dominating Set Problems</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the {\sc Hitting Set} problem, we are given a collection $\cal F$ of
subsets of a ground set $V$ and an integer $p$, and asked whether $V$ has a
$p$-element subset that intersects each set in $\cal F$. We consider two
parameterizations of {\sc Hitting Set} below tight upper bounds: $p=m-k$ and
$p=n-k$. In both cases $k$ is the parameter. We prove that the first
parameterization is fixed-parameter tractable, but has no polynomial kernel
unless coNP$\subseteq$NP/poly. The second parameterization is W[1]-complete,
but the introduction of an additional parameter, the degeneracy of the
hypergraph $H=(V,{\cal F})$, makes the problem not only fixed-parameter
tractable, but also one with a linear kernel. Here the degeneracy of
$H=(V,{\cal F})$ is the minimum integer $d$ such that for each $X\subset V$ the
hypergraph with vertex set $V\setminus X$ and edge set containing all edges of
$\cal F$ without vertices in $X$, has a vertex of degree at most $d.$
  In {\sc Nonblocker} ({\sc Directed Nonblocker}), we are given an undirected
graph (a directed graph) $G$ on $n$ vertices and an integer $k$, and asked
whether $G$ has a set $X$ of $n-k$ vertices such that for each vertex $y\not\in
X$ there is an edge (arc) from a vertex in $X$ to $y$. {\sc Nonblocker} can be
viewed as a special case of {\sc Directed Nonblocker} (replace an undirected
graph by a symmetric digraph). Dehne et al. (Proc. SOFSEM 2006) proved that
{\sc Nonblocker} has a linear-order kernel. We obtain a linear-order kernel for
{\sc Directed Nonblocker}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5890</identifier>
 <datestamp>2014-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5890</id><created>2010-10-28</created><authors><author><keyname>Kapanowski</keyname><forenames>Andrzej</forenames></author></authors><title>Python for education: the exact cover problem</title><categories>cs.DS</categories><comments>13 pages, 4 figures, 3 tables</comments><journal-ref>The Python Papers 6, 4 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Python implementation of Algorithm X by Knuth is presented. Algorithm X finds
all solutions to the exact cover problem. The exemplary results for
pentominoes, Latin squares and Sudoku are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5891</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5891</id><created>2010-10-28</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN, DIE</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author><author><keyname>Guillaume</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>A new muscle fatigue and recovery model and its ergonomics application
  in human simulation</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Virtual and Physical Prototyping 5, 3 (2010) 123 - 137</journal-ref><doi>10.1080/17452759.2010.504056</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although automatic techniques have been employed in manufacturing industries
to increase productivity and efficiency, there are still lots of manual
handling jobs, especially for assembly and maintenance jobs. In these jobs,
musculoskeletal disorders (MSDs) are one of the major health problems due to
overload and cumulative physical fatigue. With combination of conventional
posture analysis techniques, digital human modelling and simulation (DHM)
techniques have been developed and commercialized to evaluate the potential
physical exposures. However, those ergonomics analysis tools are mainly based
on posture analysis techniques, and until now there is still no fatigue index
available in the commercial software to evaluate the physical fatigue easily
and quickly. In this paper, a new muscle fatigue and recovery model is proposed
and extended to evaluate joint fatigue level in manual handling jobs. A special
application case is described and analyzed by digital human simulation
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5908</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5908</id><created>2010-10-28</created><updated>2013-02-07</updated><authors><author><keyname>Pereira</keyname><forenames>Jos&#xe9; C.</forenames></author><author><keyname>Lobo</keyname><forenames>Fernando G.</forenames></author></authors><title>An Optimized Divide-and-Conquer Algorithm for the Closest-Pair Problem
  in the Planar Case</title><categories>cs.CG</categories><comments>This is a more complete version (14 pages) of the paper already
  published in the Journal of Computer Science and Technology (see Journal
  Reference)</comments><acm-class>F.2</acm-class><journal-ref>Journal of Computer Science and Technology, 2012,27(4): 891-986</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an engineered version of the divide-and-conquer algorithm for
finding the closest pair of points, within a given set of points in the
XY-plane. For this version of the algorithm we show that only two pairwise
comparisons are required in the combine step, for each point that lies in the 2
delta-wide vertical slab. The correctness of the algorithm is shown for all
Minkowski distances with p&gt;=1. We also show empirically that, although the time
complexity of the algorithm is still O(n lg n), the reduction in the total
number of comparisons leads to a significant reduction in the total execution
time, for inputs with size sufficiently large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5935</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5935</id><created>2010-10-28</created><authors><author><keyname>Jucovschi</keyname><forenames>Constantin</forenames></author></authors><title>Editing Knowledge in Large Mathematical Corpora. A case study with
  Semantic LaTeX (sTeX)</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Before we can get the whole potential of employing computers in the process
of managing mathematical `knowledge', we have to convert informal knowledge
into machine-oriented representations. How exactly to support this process so
that it becomes as effortless as possible is one of the main unsolved problems
of Mathematical Knowledge Management.
  Two independent projects in formalization of mathematical content showed that
many of the time consuming tasks could be significantly reduced if adequate
tool support were available. It was also established that similar tasks are
typical for object oriented languages and that they are to a large extent
solved by Integrated Development Environments (IDE).
  This thesis starts by analyzing the opportunities where formalization process
can benefit from software support. A list of research questions is compiled
along with a set of software requirements which are then used for developing a
new IDE for the semantic \TeX{} (\stex{}) format. The result of the current
research is that, indeed, IDEs can be very useful in the process of
formalization and presents a set of best practices for implementing such IDEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5937</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5937</id><created>2010-10-28</created><authors><author><keyname>Geyer</keyname><forenames>Markus</forenames></author><author><keyname>Kaufmann</keyname><forenames>Michael</forenames></author><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>Upward Point-Set Embeddability</title><categories>cs.DS</categories><doi>10.1007/978-3-642-18381-2_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of Upward Point-Set Embeddability, that is the problem
of deciding whether a given upward planar digraph $D$ has an upward planar
embedding into a point set $S$. We show that any switch tree admits an upward
planar straight-line embedding into any convex point set. For the class of
$k$-switch trees, that is a generalization of switch trees (according to this
definition a switch tree is a $1$-switch tree), we show that not every
$k$-switch tree admits an upward planar straight-line embedding into any convex
point set, for any $k \geq 2$. Finally we show that the problem of Upward
Point-Set Embeddability is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5938</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5938</id><created>2010-10-28</created><updated>2011-06-18</updated><authors><author><keyname>Yap</keyname><forenames>Han Lun</forenames></author><author><keyname>Rozell</keyname><forenames>Christopher J.</forenames></author></authors><title>Stable Takens' Embeddings for Linear Dynamical Systems</title><categories>cs.SY cs.IT math.DS math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Takens' Embedding Theorem remarkably established that concatenating M
previous outputs of a dynamical system into a vector (called a delay coordinate
map) can be a one-to-one mapping of a low-dimensional attractor from the system
state space. However, Takens' theorem is fragile in the sense that even small
imperfections can induce arbitrarily large errors in this attractor
representation. We extend Takens' result to establish deterministic, explicit
and non-asymptotic sufficient conditions for a delay coordinate map to form a
stable embedding in the restricted case of linear dynamical systems and
observation functions. Our work is inspired by the field of Compressive Sensing
(CS), where results guarantee that low-dimensional signal families can be
robustly reconstructed if they are stably embedded by a measurement operator.
However, in contrast to typical CS results, i) our sufficient conditions are
independent of the size of the ambient state space, and ii) some system and
measurement pairs have fundamental limits on the conditioning of the embedding
(i.e., how close it is to an isometry), meaning that further measurements
beyond some point add no further significant value. We use several simple
simulations to explore the conditions of the main results, including the
tightness of the bounds and the convergence speed of the stable embedding. We
also present an example task of estimating the attractor dimension from
time-series data to highlight the value of stable embeddings over traditional
Takens' embeddings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5939</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5939</id><created>2010-10-28</created><authors><author><keyname>Mryglod</keyname><forenames>Olesya</forenames></author><author><keyname>Holovatch</keyname><forenames>Yurij</forenames></author><author><keyname>Mryglod</keyname><forenames>Ihor</forenames></author></authors><title>Analysis of temporal characteristics of the editorial processing in
  scientific periodicals</title><categories>cs.DL physics.data-an</categories><comments>4 pages, 5 figures</comments><journal-ref>Proc of the XII International PhD Workshop [OWD-2010], Poland,
  Wis{\l}a, 23-26 October, 2010, - P. 47-50</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first part of our work is connected with the analysis of typical random
variables for the specific human-initiated process. We study the data
characterizing editorial work with received manuscripts in several scientific
journals. In such a way we found the waiting time distributions that could be
called the typical for an ordinary peer-review scientific journal. In the
second part of this study a model of editorial processing of received
manuscripts is developed. Within the model, different scenarios of the
manuscript editorial processing are examined. Combining the results of the
quantitative experiment and model simulations we arrive to the set of
conclusions about time characteristics of editorial process in scientific
journals and a peer-review contribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5943</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5943</id><created>2010-10-28</created><updated>2010-11-02</updated><authors><author><keyname>Chojnacki</keyname><forenames>Szymon</forenames></author><author><keyname>K&#x142;opotek</keyname><forenames>Mieczys&#x142;aw</forenames></author></authors><title>Random Graph Generator for Bipartite Networks Modeling</title><categories>cs.AI cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this article is to introduce a new iterative algorithm with
properties resembling real life bipartite graphs. The algorithm enables us to
generate wide range of random bigraphs, which features are determined by a set
of parameters.We adapt the advances of last decade in unipartite complex
networks modeling to the bigraph setting. This data structure can be observed
in several situations. However, only a few datasets are freely available to
test the algorithms (e.g. community detection, influential nodes
identification, information retrieval) which operate on such data. Therefore,
artificial datasets are needed to enhance development and testing of the
algorithms. We are particularly interested in applying the generator to the
analysis of recommender systems. Therefore, we focus on two characteristics
that, besides simple statistics, are in our opinion responsible for the
performance of neighborhood based collaborative filtering algorithms. The
features are node degree distribution and local clustering coeficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5951</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5951</id><created>2010-10-28</created><updated>2010-10-29</updated><authors><author><keyname>Datta</keyname><forenames>Samir</forenames><affiliation>Chennai Mathematical Institute, India</affiliation></author><author><keyname>Krishnamurthy</keyname><forenames>Nagarajan</forenames><affiliation>Chennai Mathematical Institute, India</affiliation></author></authors><title>Some Tractable Win-Lose Games</title><categories>cs.GT cs.CC</categories><comments>We have fixed an error in the proof of Lemma 4.5. The proof is in
  Section 4.1 on &quot;Stitching cycles together&quot;, pages 6-7. We have reworded the
  statement of Lemma 4.5 as well (on page 6)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining a Nash equilibrium in a $2$-player non-zero sum game is known to
be PPAD-hard (Chen and Deng (2006), Chen, Deng and Teng (2009)). The problem,
even when restricted to win-lose bimatrix games, remains PPAD-hard (Abbott,
Kane and Valiant (2005)). However, there do exist polynomial time tractable
classes of win-lose bimatrix games - such as, very sparse games (Codenotti,
Leoncini and Resta (2006)) and planar games (Addario-Berry, Olver and Vetta
(2007)).
  We extend the results in the latter work to $K_{3,3}$ minor-free games and a
subclass of $K_5$ minor-free games. Both these classes of games strictly
contain planar games. Further, we sharpen the upper bound to unambiguous
logspace, a small complexity class contained well within polynomial time. Apart
from these classes of games, our results also extend to a class of games that
contain both $K_{3,3}$ and $K_5$ as minors, thereby covering a large and
non-trivial class of win-lose bimatrix games. For this class, we prove an upper
bound of nondeterministic logspace, again a small complexity class within
polynomial time. Our techniques are primarily graph theoretic and use
structural characterizations of the considered minor-closed families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5954</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5954</id><created>2010-10-28</created><authors><author><keyname>Chojnacki</keyname><forenames>Szymon</forenames></author><author><keyname>K&#x142;opotek</keyname><forenames>Mieczys&#x142;aw</forenames></author></authors><title>Random Graphs for Performance Evaluation of Recommender Systems</title><categories>cs.AI cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this article is to introduce a new analytical framework
dedicated to measuring performance of recommender systems. The standard
approach is to assess the quality of a system by means of accuracy related
statistics. However, the specificity of the environments in which recommender
systems are deployed requires to pay much attention to speed and memory
requirements of the algorithms. Unfortunately, it is implausible to assess
accurately the complexity of various algorithms with formal tools. This can be
attributed to the fact that such analyses are usually based on an assumption of
dense representation of underlying data structures. Whereas, in real life the
algorithms operate on sparse data and are implemented with collections
dedicated for them. Therefore, we propose to measure the complexity of
recommender systems with artificial datasets that posses real-life properties.
We utilize recently developed bipartite graph generator to evaluate how
state-of-the-art recommender systems' behavior is determined and diversified by
topological properties of the generated datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5963</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5963</id><created>2010-10-28</created><authors><author><keyname>Bouvel</keyname><forenames>Mathilde</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Ferrari</keyname><forenames>Luca</forenames><affiliation>DSI</affiliation></author></authors><title>On the enumeration of d-minimal permutations</title><categories>math.CO cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest an approach for the enumeration of minimal permutations having d
descents which uses skew Young tableaux. We succeed in finding a general
expression for the number of such permutations in terms of (several) sums of
determinants. We then generalize the class of skew Young tableaux under
consideration; this allows in particular to discover some presumably new
results concerning Eulerian numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5974</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5974</id><created>2010-10-28</created><authors><author><keyname>Bonsma</keyname><forenames>Paul</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author></authors><title>Feedback Vertex Set in Mixed Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mixed graph is a graph with both directed and undirected edges. We present
an algorithm for deciding whether a given mixed graph on $n$ vertices contains
a feedback vertex set (FVS) of size at most $k$, in time $2^{O(k)}k! O(n^4)$.
This is the first fixed parameter tractable algorithm for FVS that applies to
both directed and undirected graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5975</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5975</id><created>2010-10-28</created><updated>2012-06-29</updated><authors><author><keyname>Foucaud</keyname><forenames>Florent</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Klasing</keyname><forenames>Ralf</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Kosowski</keyname><forenames>Adrian</forenames><affiliation>LaBRI, INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Raspaud</keyname><forenames>Andr&#xe9;</forenames><affiliation>LaBRI</affiliation></author></authors><title>On the size of identifying codes in triangle-free graphs</title><categories>cs.DM math.CO</categories><proxy>ccsd</proxy><journal-ref>Discrete Applied Mathematics 160, 10-11 (2012) 1532-1546</journal-ref><doi>10.1016/j.dam.2012.02.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an undirected graph $G$, a subset $C\subseteq V(G)$ such that $C$ is a
dominating set of $G$, and each vertex in $V(G)$ is dominated by a distinct
subset of vertices from $C$, is called an identifying code of $G$. The concept
of identifying codes was introduced by Karpovsky, Chakrabarty and Levitin in
1998. For a given identifiable graph $G$, let $\M(G)$ be the minimum
cardinality of an identifying code in $G$. In this paper, we show that for any
connected identifiable triangle-free graph $G$ on $n$ vertices having maximum
degree $\Delta\geq 3$, $\M(G)\le n-\tfrac{n}{\Delta+o(\Delta)}$. This bound is
asymptotically tight up to constants due to various classes of graphs including
$(\Delta-1)$-ary trees, which are known to have their minimum identifying code
of size $n-\tfrac{n}{\Delta-1+o(1)}$. We also provide improved bounds for
restricted subfamilies of triangle-free graphs, and conjecture that there
exists some constant $c$ such that the bound $\M(G)\le n-\tfrac{n}{\Delta}+c$
holds for any nontrivial connected identifiable graph $G$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.5990</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.5990</id><created>2010-10-28</created><updated>2011-11-17</updated><authors><author><keyname>Tian</keyname><forenames>Liang</forenames></author><author><keyname>Shi</keyname><forenames>Da-Ning</forenames></author></authors><title>The Nature of Explosive Percolation Phase Transition</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>5 pages, 4 figures</comments><journal-ref>Physics Letters A, Volume 391, Issue 4, 15 February 2012, Pages
  1234-1242</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this Letter, we show that the explosive percolation is a novel continuous
phase transition. The order-parameter-distribution histogram at the percolation
threshold is studied in Erd\H{o}s-R\'{e}nyi networks, scale-free networks, and
square lattice. In finite system, two well-defined Gaussian-like peaks coexist,
and the valley between the two peaks is suppressed with the system size
increasing. This finite-size effect always appears in typical first-order phase
transition. However, both of the two peaks shift to zero point in a power law
manner, which indicates the explosive percolation is continuous in the
thermodynamic limit. The nature of explosive percolation in all the three
structures belongs to this novel continuous phase transition. Various scaling
exponents concerning the order-parameter-distribution are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6020</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6020</id><created>2010-10-28</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>The Effect of Spatial Coupling on Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>8 Pages, 7 figures. This is a slightly modified version of the paper
  which appeared in the 48th Annual Allerton Conference on Communication,
  Control, and Computing September 29 - October 1, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it was observed that spatially-coupled LDPC code ensembles approach
the Shannon capacity for a class of binary-input memoryless symmetric (BMS)
channels. The fundamental reason for this was attributed to a &quot;threshold
saturation&quot; phenomena derived by Kudekar, Richardson and Urbanke. In
particular, it was shown that the belief propagation (BP) threshold of the
spatially coupled codes is equal to the maximum a posteriori (MAP) decoding
threshold of the underlying constituent codes. In this sense, the BP threshold
is saturated to its maximum value. Moreover, it has been empirically observed
that the same phenomena also occurs when transmitting over more general classes
of BMS channels. In this paper, we show that the effect of spatial coupling is
not restricted to the realm of channel coding. The effect of coupling also
manifests itself in compressed sensing. Specifically, we show that
spatially-coupled measurement matrices have an improved sparsity to sampling
threshold for reconstruction algorithms based on verification decoding. For
BP-based reconstruction algorithms, this phenomenon is also tested empirically
via simulation. At the block lengths accessible via simulation, the effect is
quite small and it seems that spatial coupling is not providing the gains one
might expect. Based on the threshold analysis, however, we believe this
warrants further study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6032</identifier>
 <datestamp>2012-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6032</id><created>2010-10-25</created><authors><author><keyname>Donner</keyname><forenames>Reik V.</forenames></author><author><keyname>Small</keyname><forenames>Michael</forenames></author><author><keyname>Donges</keyname><forenames>Jonathan F.</forenames></author><author><keyname>Marwan</keyname><forenames>Norbert</forenames></author><author><keyname>Zou</keyname><forenames>Yong</forenames></author><author><keyname>Xiang</keyname><forenames>Ruoxi</forenames></author><author><keyname>Kurths</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Recurrence-based time series analysis by means of complex network
  methods</title><categories>nlin.CD cs.SI physics.data-an physics.soc-ph</categories><comments>To be published in International Journal of Bifurcation and Chaos
  (2011)</comments><journal-ref>International Journal of Bifurcation and Chaos 21(4), 1019-1046
  (2011)</journal-ref><doi>10.1142/S0218127411029021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks are an important paradigm of modern complex systems sciences
which allows quantitatively assessing the structural properties of systems
composed of different interacting entities. During the last years, intensive
efforts have been spent on applying network-based concepts also for the
analysis of dynamically relevant higher-order statistical properties of time
series. Notably, many corresponding approaches are closely related with the
concept of recurrence in phase space. In this paper, we review recent
methodological advances in time series analysis based on complex networks, with
a special emphasis on methods founded on recurrence plots. The potentials and
limitations of the individual methods are discussed and illustrated for
paradigmatic examples of dynamical systems as well as for real-world time
series. Complex network measures are shown to provide information about
structural features of dynamical systems that are complementary to those
characterized by other methods of time series analysis and, hence,
substantially enrich the knowledge gathered from other existing (linear as well
as nonlinear) approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6057</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6057</id><created>2010-10-28</created><authors><author><keyname>Bassily</keyname><forenames>Raef</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Ergodic Secret Alignment</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, October 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce two new achievable schemes for the fading
multiple access wiretap channel (MAC-WT). In the model that we consider, we
assume that perfect knowledge of the state of all channels is available at all
the nodes in a causal fashion. Our schemes use this knowledge together with the
time varying nature of the channel model to align the interference from
different users at the eavesdropper perfectly in a one-dimensional space while
creating a higher dimensionality space for the interfering signals at the
legitimate receiver hence allowing for better chance of recovery. While we
achieve this alignment through signal scaling at the transmitters in our first
scheme (scaling based alignment (SBA)), we let nature provide this alignment
through the ergodicity of the channel coefficients in the second scheme
(ergodic secret alignment (ESA)). For each scheme, we obtain the resulting
achievable secrecy rate region. We show that the secrecy rates achieved by both
schemes scale with SNR as 1/2log(SNR). Hence, we show the sub-optimality of the
i.i.d. Gaussian signaling based schemes with and without cooperative jamming by
showing that the secrecy rates achieved using i.i.d. Gaussian signaling with
cooperative jamming do not scale with SNR. In addition, we introduce an
improved version of our ESA scheme where we incorporate cooperative jamming to
achieve higher secrecy rates. Moreover, we derive the necessary optimality
conditions for the power control policy that maximizes the secrecy sum rate
achievable by our ESA scheme when used solely and with cooperative jamming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6091</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6091</id><created>2010-10-28</created><updated>2011-03-04</updated><authors><author><keyname>Zanette</keyname><forenames>Damian H.</forenames></author></authors><title>Network motifs in music sequences</title><categories>physics.soc-ph cs.CL physics.data-an</categories><comments>This paper has been withdrawn by the author because it needs a deep
  methodological revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author because it needs a deep
methodological revision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6096</identifier>
 <datestamp>2010-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6096</id><created>2010-10-28</created><authors><author><keyname>Akhoundi</keyname><forenames>Mohammad Amin Ahmad</forenames></author><author><keyname>Valavi</keyname><forenames>Ehsan</forenames></author></authors><title>Multi-Sensor Fuzzy Data Fusion Using Sensors with Different
  Characteristics</title><categories>cs.SY</categories><comments>It is submitted to CSI journal of computer science and engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new approach to multisensor data fusion, suggesting by
considering information about the sensors' different characteristics,
aggregation of data acquired by individual sensors can be done more efficient.
Same as the most effective sensors' characteristics, especially in control
systems, our focus is on sensors' accuracy and frequency response. A rule-based
fuzzy system is presented for fusion of raw data obtained from the sensors
having complement characteristics in accuracy and bandwidth. Furthermore, a
fuzzy predictor system is also suggested aiming to extremely high accuracy for
highly sensitive applications. The great advantages of the proposed sensor
fusion system are revealed on simulation results of a control system utilizing
the fusion system for output estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6112</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6112</id><created>2010-10-28</created><authors><author><keyname>Chen</keyname><forenames>Yu-Fang</forenames><affiliation>Academia Sinica, Taiwan</affiliation></author><author><keyname>Rezine</keyname><forenames>Ahmed</forenames><affiliation>Uppsala University, Sweden</affiliation></author></authors><title>Proceedings 12th International Workshop on Verification of
  Infinite-State Systems</title><categories>cs.FL cs.CC cs.LO cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010</journal-ref><doi>10.4204/EPTCS.39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of the INFINITY workshop is to provide a forum for researchers
interested in the development of formal methods and algorithmic techniques for
the analysis of systems with infinitely many states, and their application in
automated verification of complex software and hardware systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6148</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6148</id><created>2010-10-29</created><updated>2011-07-11</updated><authors><author><keyname>De Persis</keyname><forenames>Claudio</forenames></author><author><keyname>Sailer</keyname><forenames>Rudolf</forenames></author><author><keyname>Wirth</keyname><forenames>Fabian</forenames></author></authors><title>On a small-gain approach to distributed event-triggered control</title><categories>math.OC cs.SY</categories><comments>30 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the problem of stabilizing large-scale systems by distributed
controllers, where the controllers exchange information via a shared limited
communication medium is addressed. Event-triggered sampling schemes are
proposed, where each system decides when to transmit new information across the
network based on the crossing of some error thresholds. Stability of the
interconnected large-scale system is inferred by applying a generalized
small-gain theorem. Two variations of the event-triggered controllers which
prevent the occurrence of the Zeno phenomenon are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6155</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6155</id><created>2010-10-29</created><authors><author><keyname>Dragomir</keyname><forenames>Iulia</forenames></author><author><keyname>Ober</keyname><forenames>Iulian</forenames></author></authors><title>Well-formedness and typing rules for UML Composite Structures</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Starting from version 2.0, UML introduced hierarchical composite structures,
which are an expressive way of defining complex software architectures, but
which have a very loosely defined semantics in the standard. In this paper we
propose a set of consistency rules that disambiguate the meaning of UML
composite structures. Our primary goal was to have an operational model of
composite structures for the OMEGA UML profile, an executable profile dedicated
to the formal specification and validation of real-time systems, developed in a
past project to which we contributed. However, the rules and principles stated
here are applicable to other hierarchical component models based on the same
concepts, such as SysML. The presented ruleset is supported by an OCL
formalization which is described in this report. This formalization was applied
on different complex models for the evaluation and validation of the proposed
principles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6165</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6165</id><created>2010-10-29</created><authors><author><keyname>Pfander</keyname><forenames>G&#xf6;tz E.</forenames></author></authors><title>Sampling of operators</title><categories>math.FA cs.IT math.CA math.IT</categories><msc-class>Primary 42B35, 94A20, Secondary 35S05, 47B35, 94A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling and reconstruction of functions is a central tool in science. A key
result is given by the sampling theorem for bandlimited functions attributed to
Whittaker, Shannon, Nyquist, and Kotelnikov. We develop an analogous sampling
theory for operators which we call bandlimited if their Kohn-Nirenberg symbols
are bandlimited. We prove sampling theorems for such operators and show that
they are extensions of the classical sampling theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6166</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6166</id><created>2010-10-29</created><authors><author><keyname>Laufer</keyname><forenames>Rafael</forenames></author><author><keyname>Dubois-Ferri&#xe8;re</keyname><forenames>Henri</forenames></author><author><keyname>Kleinrock</keyname><forenames>Leonard</forenames></author></authors><title>Polynomial-Time Algorithms for Multirate Anypath Routing in Wireless
  Multihop Networks</title><categories>cs.NI cs.DS</categories><comments>14 pages, 11 figures</comments><report-no>UCLA-CSD-TR100034</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a new routing paradigm that generalizes
opportunistic routing for wireless multihop networks. In multirate anypath
routing, each node uses both a set of next hops and a selected transmission
rate to reach a destination. Using this rate, a packet is broadcast to the
nodes in the set and one of them forwards the packet on to the destination. To
date, there has been no theory capable of jointly optimizing both the set of
next hops and the transmission rate used by each node. We solve this by
introducing two polynomial-time routing algorithms and provide the proof of
their optimality. The proposed algorithms run in roughly the same running time
as regular shortest-path algorithms, and are therefore suitable for deployment
in routing protocols. We conducted measurements in an 802.11b testbed network,
and our trace-driven analysis shows that multirate anypath routing performs on
average 80% and up to 6.4 times better than anypath routing with a fixed rate
of 11 Mbps. If the rate is fixed at 1 Mbps instead, performance improves by up
to one order of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6178</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6178</id><created>2010-10-29</created><authors><author><keyname>Bohte</keyname><forenames>Sander M.</forenames></author><author><keyname>Rombouts</keyname><forenames>Jaldert O.</forenames></author></authors><title>Fractionally Predictive Spiking Neurons</title><categories>q-bio.NC cs.NE</categories><comments>13 pages, 5 figures, in Advances in Neural Information Processing
  2010</comments><acm-class>C.1.3; I.5.1; I.2.6; G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent experimental work has suggested that the neural firing rate can be
interpreted as a fractional derivative, at least when signal variation induces
neural adaptation. Here, we show that the actual neural spike-train itself can
be considered as the fractional derivative, provided that the neural signal is
approximated by a sum of power-law kernels. A simple standard thresholding
spiking neuron suffices to carry out such an approximation, given a suitable
refractory response. Empirically, we find that the online approximation of
signals with a sum of power-law kernels is beneficial for encoding signals with
slowly varying components, like long-memory self-similar signals. For such
signals, the online power-law kernel approximation typically required less than
half the number of spikes for similar SNR as compared to sums of similar but
exponentially decaying kernels. As power-law kernels can be accurately
approximated using sums or cascades of weighted exponentials, we demonstrate
that the corresponding decoding of spike-trains by a receiving neuron allows
for natural and transparent temporal signal filtering by tuning the weights of
the decoding kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6200</identifier>
 <datestamp>2013-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6200</id><created>2010-10-29</created><updated>2012-03-30</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author><author><keyname>Ozlen</keyname><forenames>Melih</forenames></author></authors><title>A tree traversal algorithm for decision problems in knot theory and
  3-manifold topology</title><categories>math.GT cs.CG</categories><comments>28 pages, 7 figures; v2: minor revisions; to appear in Algorithmica</comments><msc-class>Primary 57N10, 52B55, Secondary 90C05, 57N35</msc-class><journal-ref>Algorithmica 65 (2013), no. 4, 772-801</journal-ref><doi>10.1007/s00453-012-9645-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In low-dimensional topology, many important decision algorithms are based on
normal surface enumeration, which is a form of vertex enumeration over a
high-dimensional and highly degenerate polytope. Because this enumeration is
subject to extra combinatorial constraints, the only practical algorithms to
date have been variants of the classical double description method. In this
paper we present the first practical normal surface enumeration algorithm that
breaks out of the double description paradigm. This new algorithm is based on a
tree traversal with feasibility and domination tests, and it enjoys a number of
advantages over the double description method: incremental output,
significantly lower time and space complexity, and a natural suitability for
parallelisation. Experimental comparisons of running times are included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6214</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6214</id><created>2010-10-29</created><authors><author><keyname>Emiris</keyname><forenames>Ioannis Z.</forenames><affiliation>DI</affiliation></author><author><keyname>Moroz</keyname><forenames>Guillaume</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>The assembly modes of rigid 11-bar linkages</title><categories>cs.RO cs.SC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing an m-bar linkage with a maximal number of assembly modes is
important in robot kinematics, and has further applications in structural
biology and computational geometry. A related question concerns the number of
assembly modes of rigid mechanisms as a function of their nodes n, which is
uniquely defined given m. Rigid 11-bar linkages, where n=7, are the simplest
planar linkages for which these questions were still open. It will be proven
that the maximal number of assembly modes of such linkages is exactly 56. The
rigidity of a linkage is captured by a polynomial system derived from distance,
or Cayley-Menger, matrices. The upper bound on the number of assembly modes is
obtained as the mixed volume of a 5x5 system. An 11-bar linkage admitting 56
configurations is constructed using stochastic optimisation methods. This
yields a general lower bound of $\Omega(2.3^n)$ on the number of assembly
modes, slightly improving the current record of $\Omega(2.289^n)$, while the
best known upper bound is roughly $4^n$. Our methods are straightforward and
have been implemented in Maple. They are described in general terms
illustrating the fact that they can be readily extended to other planar or
spatial linkages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6231</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6231</id><created>2010-10-29</created><updated>2013-04-22</updated><authors><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>A polynomial-time algorithm for estimating the partition function of the
  ferromagnetic Ising model on a regular matroid</title><categories>cs.CC math.CO</categories><comments>New Lemma 4 provides a smoother derivation of the two lemmas now
  numbered 5 and 6. The old Lemma 2 is not now needed, and the appendix is
  shorter. Various clarifications have been made and typos corrected</comments><msc-class>68W25, 05B35, 82B20</msc-class><journal-ref>SICOMP 42(3) 1132-1157 (2013)</journal-ref><doi>10.1137/110851213</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the computational difficulty of approximating the partition
function of the ferromagnetic Ising model on a regular matroid. Jerrum and
Sinclair have shown that there is a fully polynomial randomised approximation
scheme (FPRAS) for the class of graphic matroids. On the other hand, the
authors have previously shown, subject to a complexity-theoretic assumption,
that there is no FPRAS for the class of binary matroids, which is a proper
superset of the class of graphic matroids. In order to map out the region where
approximation is feasible, we focus on the class of regular matroids, an
important class of matroids which properly includes the class of graphic
matroids, and is properly included in the class of binary matroids. Using
Seymour's decomposition theorem, we give an FPRAS for the class of regular
matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6234</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6234</id><created>2010-10-29</created><authors><author><keyname>Bombini</keyname><forenames>Grazia</forenames></author><author><keyname>Ros</keyname><forenames>Raquel</forenames></author><author><keyname>Ferilli</keyname><forenames>Stefano</forenames></author><author><keyname>de Mantaras</keyname><forenames>Ramon Lopez</forenames></author></authors><title>Analysing the behaviour of robot teams through relational sequential
  pattern mining</title><categories>cs.AI cs.LG cs.MA</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report outlines the use of a relational representation in a Multi-Agent
domain to model the behaviour of the whole system. A desired property in this
systems is the ability of the team members to work together to achieve a common
goal in a cooperative manner. The aim is to define a systematic method to
verify the effective collaboration among the members of a team and comparing
the different multi-agent behaviours. Using external observations of a
Multi-Agent System to analyse, model, recognize agent behaviour could be very
useful to direct team actions. In particular, this report focuses on the
challenge of autonomous unsupervised sequential learning of the team's
behaviour from observations. Our approach allows to learn a symbolic sequence
(a relational representation) to translate raw multi-agent, multi-variate
observations of a dynamic, complex environment, into a set of sequential
behaviours that are characteristic of the team in question, represented by a
set of sequences expressed in first-order logic atoms. We propose to use a
relational learning algorithm to mine meaningful frequent patterns among the
relational sequences to characterise team behaviours. We compared the
performance of two teams in the RoboCup four-legged league environment, that
have a very different approach to the game. One uses a Case Based Reasoning
approach, the other uses a pure reactive behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6242</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6242</id><created>2010-10-29</created><authors><author><keyname>Hurault-Plantet</keyname><forenames>Martine</forenames><affiliation>LIMSI</affiliation></author><author><keyname>Naulleau</keyname><forenames>Elie</forenames><affiliation>CREM-EA3476</affiliation></author><author><keyname>Jacquemin</keyname><forenames>Bernard</forenames><affiliation>CREM-EA3476</affiliation></author></authors><title>GraphDuplex: visualisation simultan\'ee de N r\'eseaux coupl\'es 2 par 2</title><categories>cs.IR</categories><proxy>ccsd</proxy><journal-ref>Conf\'erence en Recherche d'Information et Applications (CORIA
  2009), Prequ'\^ile de Giens : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While social network analysis often focuses on graph structure of social
actors, an increasing number of communication networks now provide textual
content within social activity (email, instant messaging, blogging,
collaboration networks). We present an open source visualization software,
GraphDuplex, which brings together social structure and textual content, adding
a semantic dimension to social analysis. GraphDuplex eventually connects any
number of social or semantic graphs together, and through dynamic queries
enables user interaction and exploration across multiple graphs of different
nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6247</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6247</id><created>2010-10-29</created><authors><author><keyname>Johnson</keyname><forenames>L. F.</forenames></author></authors><title>Symmetry in Shannon's Noiseless Coding Theorem</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statements of Shannon's Noiseless Coding Theorem by various authors,
including the original, are reviewed and clarified. Traditional statements of
the theorem are often unclear as to when it applies. A new notation is
introduced and the domain of application is clarified. An examination of the
bounds of the Theorem leads to a new symmetric restatement. It is shown that
the extended upper bound is an acheivable upper bound, giving symmetry to the
theorem.The relation of information entropy to the physical entropy of Gibbs
and Boltmann is illustrated. Consequently, the study of Shannon Entropy is
strongly related to physics and there is a physical theory of information. This
paper is the beginning of of an attempt to clarify these relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6255</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6255</id><created>2010-10-29</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>On the Capacity of the 2-user Gaussian MAC Interfering with a P2P Link</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multiple access channel and a point-to-point channel sharing the same
medium for communications are considered. We obtain an outer bound for the
capacity region of this setup, and we show that this outer bound is achievable
in some cases. These cases are mainly when interference is strong or very
strong. A sum capacity upper bound is also obtained, which is nearly tight if
the interference power at the receivers is low. In this case, using Gaussian
codes and treating interference as noise achieves a sum rate close to the upper
bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6280</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6280</id><created>2010-10-29</created><updated>2011-06-07</updated><authors><author><keyname>Tutuncuoglu</keyname><forenames>Kaya</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Optimum Transmission Policies for Battery Limited Energy Harvesting
  Nodes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications, September
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless networks with energy harvesting battery powered nodes are quickly
emerging as a viable option for future wireless networks with extended
lifetime. Equally important to their counterpart in the design of energy
harvesting radios are the design principles that this new networking paradigm
calls for. In particular, unlike wireless networks considered up to date, the
energy replenishment process and the storage constraints of the rechargeable
batteries need to be taken into account in designing efficient transmission
strategies. In this work, we consider such transmission policies for
rechargeable nodes, and identify the optimum solution for two related problems.
Specifically, the transmission policy that maximizes the short term throughput,
i.e., the amount of data transmitted in a finite time horizon is found. In
addition, we show the relation of this optimization problem to another, namely,
the minimization of the transmission completion time for a given amount of
data, and solve that as well. The transmission policies are identified under
the constraints on energy causality, i.e., energy replenishment process, as
well as the energy storage, i.e., battery capacity. The power-rate relationship
for this problem is assumed to be an increasing concave function, as dictated
by information theory. For battery replenishment, a model with discrete packets
of energy arrivals is considered. We derive the necessary conditions that the
throughput-optimal allocation satisfies, and then provide the algorithm that
finds the optimal transmission policy with respect to the short-term throughput
and the minimum transmission completion time. Numerical results are presented
to confirm the analytical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1010.6290</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1010.6290</id><created>2010-10-29</created><updated>2012-03-20</updated><authors><author><keyname>Tian</keyname><forenames>Ye</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Symmetric Capacity of the Gaussian Interference Channel with an
  Out-of-Band Relay to within 1.15 Bits</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, accepted March 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the Gaussian interference channel (IC) with a relay, which
transmits and receives in a band that is orthogonal to the IC. The channel
associated with the relay is thus an out-of-band relay channel (OBRC). The
focus is on a symmetric channel model, in order to assess the fundamental
impact of the OBRC on the signal interaction of the IC, in the simplest
possible setting. First, the linear deterministic model is investigated and the
sum capacity of this channel is established for all possible channel
parameters. In particular, it is observed that the impact of OBRC, as its links
get stronger, is similar to that of output feedback for the IC. The insights
obtained from the deterministic model are then used to design achievable
schemes for the Gaussian model. The interference links are classified as
extremely strong, very strong, strong, moderate, weak, and very weak. For
strong and moderate interference, separate encoding is near optimal. For very
strong and extremely strong interference, the interference links provide side
information to the destinations, which can help the transmission through the
OBRC. For weak or very weak interference, an extension of the Han-Kobayashi
scheme for the IC is utilized, where the messages are split into common and
private. To achieve higher rates, it is beneficial to further split the common
message into two parts, and the OBRC plays an important role in decoding the
common message. It is shown that our strategy achieves the symmetric capacity
to within 1.14625 bits per channel use with duplexing factor 0.5, and 1.27125
bits per channel use for arbitrary duplexing factors, for all channel
parameters. An important observation from the constant gap result is that
strong interference can be beneficial with the presence of an OBR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0014</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0014</id><created>2010-10-29</created><updated>2014-12-25</updated><authors><author><keyname>Yanofsky</keyname><forenames>Noson S.</forenames></author></authors><title>Galois Theory of Algorithms</title><categories>math.RA cs.DM cs.LO math.CT math.GR</categories><comments>25 pages, 1 figure. Fixed an error, corrected typos, and added a
  section on homotopy theory</comments><msc-class>06A15, 11R32, 03C05, 08A70, 03D20</msc-class><acm-class>F.4.1; F.1.1; D.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many different programs are the implementation of the same algorithm. The
collection of programs can be partitioned into different classes corresponding
to the algorithms they implement. This makes the collection of algorithms a
quotient of the collection of programs. Similarly, there are many different
algorithms that implement the same computable function. The collection of
algorithms can be partitioned into different classes corresponding to what
computable function they implement. This makes the collection of computable
functions into a quotient of the collection of algorithms. Algorithms are
intermediate between programs and functions:
  Programs $\twoheadrightarrow$ Algorithms $\twoheadrightarrow$ Functions.
  \noindent Galois theory investigates the way that a subobject sits inside an
object. We investigate how a quotient object sits inside an object. By looking
at the Galois group of programs, we study the intermediate types of algorithms
possible and the types of structures these algorithms can have.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0027</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0027</id><created>2010-10-29</created><updated>2011-06-29</updated><authors><author><keyname>Aggarwal</keyname><forenames>Rohit</forenames></author><author><keyname>Assaad</keyname><forenames>Mohamad</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Joint Scheduling and Resource Allocation in the OFDMA Downlink: Utility
  Maximization under Imperfect Channel-State Information</title><categories>cs.IT cs.NI math.IT</categories><doi>10.1109/TSP.2011.2162953</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of simultaneous user-scheduling, power-allocation,
and rate-selection in an OFDMA downlink, with the goal of maximizing expected
sum-utility under a sum-power constraint. In doing so, we consider a family of
generic goodput-based utilities that facilitate, e.g., throughput-based
pricing, quality-of-service enforcement, and/or the treatment of practical
modulation-and-coding schemes (MCS). Since perfect knowledge of channel state
information (CSI) may be difficult to maintain at the base-station, especially
when the number of users and/or subchannels is large, we consider scheduling
and resource allocation under imperfect CSI, where the channel state is
described by a generic probability distribution. First, we consider the
&quot;continuous&quot; case where multiple users and/or code rates can time-share a
single OFDMA subchannel and time slot. This yields a non-convex optimization
problem that we convert into a convex optimization problem and solve exactly
using a dual optimization approach. Second, we consider the &quot;discrete&quot; case
where only a single user and code rate is allowed per OFDMA subchannel per time
slot. For the mixed-integer optimization problem that arises, we discuss the
connections it has with the continuous case and show that it can solved exactly
in some situations. For the other situations, we present a bound on the
optimality gap. For both cases, we provide algorithmic implementations of the
obtained solution. Finally, we study, numerically, the performance of the
proposed algorithms under various degrees of CSI uncertainty, utilities, and
OFDMA system configurations. In addition, we demonstrate advantages relative to
existing state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0036</identifier>
 <datestamp>2012-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0036</id><created>2010-10-29</created><updated>2012-12-15</updated><authors><author><keyname>Johnson</keyname><forenames>B. D.</forenames></author><author><keyname>Crutchfield</keyname><forenames>J. P.</forenames></author><author><keyname>Ellison</keyname><forenames>C. J.</forenames></author><author><keyname>McTague</keyname><forenames>C. S.</forenames></author></authors><title>Enumerating Finitary Processes</title><categories>cs.FL math.CO math.DS math.ST nlin.CD stat.TH</categories><comments>8 pages, 3 figures, 4 tables;
  http://users.cse.ucdavis.edu/~cmg/compmech/pubs/efp.htm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to efficiently enumerate a class of finite-memory stochastic
processes using the causal representation of epsilon-machines. We characterize
epsilon-machines in the language of automata theory and adapt a recent
algorithm for generating accessible deterministic finite automata, pruning this
over-large class down to that of epsilon-machines. As an application, we
exactly enumerate topological epsilon-machines up to eight states and
six-letter alphabets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0041</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0041</id><created>2010-10-29</created><updated>2011-01-17</updated><authors><author><keyname>Boots</keyname><forenames>Byron</forenames></author><author><keyname>Gordon</keyname><forenames>Geoffrey J.</forenames></author></authors><title>Predictive State Temporal Difference Learning</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approach to value function approximation which combines
linear temporal difference reinforcement learning with subspace identification.
In practical applications, reinforcement learning (RL) is complicated by the
fact that state is either high-dimensional or partially observable. Therefore,
RL methods are designed to work with features of state rather than state
itself, and the success or failure of learning is often determined by the
suitability of the selected features. By comparison, subspace identification
(SSID) methods are designed to select a feature set which preserves as much
information as possible about state. In this paper we connect the two
approaches, looking at the problem of reinforcement learning with a large set
of features, each of which may only be marginally useful for value function
approximation. We introduce a new algorithm for this situation, called
Predictive State Temporal Difference (PSTD) learning. As in SSID for predictive
state representations, PSTD finds a linear compression operator that projects a
large set of features down to a small set that preserves the maximum amount of
predictive information. As in RL, PSTD then uses a Bellman recursion to
estimate a value function. We discuss the connection between PSTD and prior
approaches in RL and SSID. We prove that PSTD is statistically consistent,
perform several experiments that illustrate its properties, and demonstrate its
potential on a difficult optimal stopping problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0046</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0046</id><created>2010-10-30</created><updated>2012-03-01</updated><authors><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>A non-expert view on Turing machines, Proof Verifiers, and Mental
  reasoning</title><categories>cs.CC cs.FL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper explores known results related to the problem of identifying if a
given program terminates on all inputs -- this is a simple generalization of
the halting problem. We will see how this problem is related and the notion of
proof verifiers. We also see how verifying if a program is terminating involves
reasoning through a tower of axiomatic theories -- such a tower of theories is
known as Turing progressions and was first studied by Alan Turing in the
1930's. We will see that this process has a natural connection to ordinal
numbers. The paper is presented from the perspective of a non-expert in the
field of logic and proof theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0051</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0051</id><created>2010-10-30</created><authors><author><keyname>Ciobanu</keyname><forenames>Gabriel</forenames><affiliation>Iasi, Romania</affiliation></author><author><keyname>Koutny</keyname><forenames>Maciej</forenames><affiliation>Newcastle, UK</affiliation></author></authors><title>Proceedings Fourth Workshop on Membrane Computing and Biologically
  Inspired Process Calculi 2010</title><categories>cs.LO cs.CE cs.DC</categories><proxy>EPTCS</proxy><acm-class>F.1.1; F.1.2</acm-class><journal-ref>EPTCS 40, 2010</journal-ref><doi>10.4204/EPTCS.40</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 4th Workshop on Membrane Computing and Biologically Inspired Process
Calculi (MeCBIC 2010) is organized in Jena as a satellite event of the Eleventh
International Conference on Membrane Computing (CMC11). Biological membranes
play a fundamental role in the complex reactions which take place in cells of
living organisms. The importance of this role has been considered in two
different types of formalisms introduced recently. Membrane systems were
introduced as a class of distributed parallel computing devices inspired by the
observation that any biological system is a complex hierarchical structure,
with a flow of biochemical substances and information that underlies their
functioning. The modeling and analysis of biological systems has also attracted
considerable interest of the process algebra research community. Thus the
notions of membranes and compartments have been explicitly represented in a
family of calculi, such as ambients and brane calculi. A cross fertilization of
these two research areas has recently started. A deeper investigation of the
relationships between these related formalisms is interesting, as it is
important to understand the crucial similarities and the differences. The main
aim of the workshop is to bring together researchers working on membrane
computing, in biologically inspired process calculi, and in other related
fields, in order to present recent results and to discuss new ideas concerning
such formalisms, their properties and relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0078</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0078</id><created>2010-10-30</created><updated>2010-11-09</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Schmied</keyname><forenames>Richard</forenames></author><author><keyname>Viehmann</keyname><forenames>Claus</forenames></author></authors><title>Approximating Subdense Instances of Covering Problems</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study approximability of subdense instances of various covering problems
on graphs, defined as instances in which the minimum or average degree is
Omega(n/psi(n)) for some function psi(n)=omega(1) of the instance size. We
design new approximation algorithms as well as new polynomial time
approximation schemes (PTASs) for those problems and establish first
approximation hardness results for them. Interestingly, in some cases we were
able to prove optimality of the underlying approximation ratios, under usual
complexity-theoretic assumptions. Our results for the Vertex Cover problem
depend on an improved recursive sampling method which could be of independent
interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0093</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0093</id><created>2010-10-30</created><authors><author><keyname>Celebi</keyname><forenames>M. Emre</forenames></author></authors><title>Fast Color Quantization Using Weighted Sort-Means Clustering</title><categories>cs.CV cs.GR</categories><comments>30 pages, 2 figures, 4 tables</comments><acm-class>I.4.1</acm-class><journal-ref>Journal of the Optical Society of America A 26 (2009) 2434-2443</journal-ref><doi>10.1364/JOSAA.26.002434</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Color quantization is an important operation with numerous applications in
graphics and image processing. Most quantization methods are essentially based
on data clustering algorithms. However, despite its popularity as a general
purpose clustering algorithm, k-means has not received much respect in the
color quantization literature because of its high computational requirements
and sensitivity to initialization. In this paper, a fast color quantization
method based on k-means is presented. The method involves several modifications
to the conventional (batch) k-means algorithm including data reduction, sample
weighting, and the use of triangle inequality to speed up the nearest neighbor
search. Experiments on a diverse set of images demonstrate that, with the
proposed modifications, k-means becomes very competitive with state-of-the-art
color quantization methods in terms of both effectiveness and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0097</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0097</id><created>2010-10-30</created><authors><author><keyname>Scheinberg</keyname><forenames>Katya</forenames></author><author><keyname>Ma</keyname><forenames>Shiqian</forenames></author><author><keyname>Goldfarb</keyname><forenames>Donald</forenames></author></authors><title>Sparse Inverse Covariance Selection via Alternating Linearization
  Methods</title><categories>cs.LG math.OC stat.ML</categories><journal-ref>NIPS 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian graphical models are of great interest in statistical learning.
Because the conditional independencies between different nodes correspond to
zero entries in the inverse covariance matrix of the Gaussian distribution, one
can learn the structure of the graph by estimating a sparse inverse covariance
matrix from sample data, by solving a convex maximum likelihood problem with an
$\ell_1$-regularization term. In this paper, we propose a first-order method
based on an alternating linearization technique that exploits the problem's
special structure; in particular, the subproblems solved in each iteration have
closed-form solutions. Moreover, our algorithm obtains an $\epsilon$-optimal
solution in $O(1/\epsilon)$ iterations. Numerical experiments on both synthetic
and real data from gene association networks show that a practical version of
this algorithm outperforms other competitive algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0098</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0098</id><created>2010-10-30</created><authors><author><keyname>Mossakowski</keyname><forenames>Till</forenames></author><author><keyname>Moratz</keyname><forenames>Reinhard</forenames></author></authors><title>Qualitative Reasoning about Relative Direction on Adjustable Levels of
  Granularity</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important issue in Qualitative Spatial Reasoning is the representation of
relative direction. In this paper we present simple geometric rules that enable
reasoning about relative direction between oriented points. This framework, the
Oriented Point Algebra OPRA_m, has a scalable granularity m. We develop a
simple algorithm for computing the OPRA_m composition tables and prove its
correctness. Using a composition table, algebraic closure for a set of OPRA
statements is sufficient to solve spatial navigation tasks. And it turns out
that scalable granularity is useful in these navigation tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0108</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0108</id><created>2010-10-30</created><updated>2011-05-17</updated><authors><author><keyname>Ailon</keyname><forenames>Nir</forenames></author></authors><title>An Active Learning Algorithm for Ranking from Pairwise Preferences with
  an Almost Optimal Query Complexity</title><categories>cs.DS</categories><comments>Fixed a tiny error in theorem 3.1 statement</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of learning to rank from pairwise preferences, and solve
a long-standing open problem that has led to development of many heuristics but
no provable results for our particular problem. Given a set $V$ of $n$
elements, we wish to linearly order them given pairwise preference labels. A
pairwise preference label is obtained as a response, typically from a human, to
the question &quot;which if preferred, u or v?$ for two elements $u,v\in V$. We
assume possible non-transitivity paradoxes which may arise naturally due to
human mistakes or irrationality. The goal is to linearly order the elements
from the most preferred to the least preferred, while disagreeing with as few
pairwise preference labels as possible. Our performance is measured by two
parameters: The loss and the query complexity (number of pairwise preference
labels we obtain). This is a typical learning problem, with the exception that
the space from which the pairwise preferences is drawn is finite, consisting of
${n\choose 2}$ possibilities only. We present an active learning algorithm for
this problem, with query bounds significantly beating general (non active)
bounds for the same error guarantee, while almost achieving the information
theoretical lower bound. Our main construct is a decomposition of the input
s.t. (i) each block incurs high loss at optimum, and (ii) the optimal solution
respecting the decomposition is not much worse than the true opt. The
decomposition is done by adapting a recent result by Kenyon and Schudy for a
related combinatorial optimization problem to the query efficient setting. We
thus settle an open problem posed by learning-to-rank theoreticians and
practitioners: What is a provably correct way to sample preference labels? To
further show the power and practicality of our solution, we show how to use it
in concert with an SVM relaxation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0126</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0126</id><created>2010-10-31</created><authors><author><keyname>Fan</keyname><forenames>Zhengping</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author><author><keyname>Zhang</keyname><forenames>Yunong</forenames></author></authors><title>Using topological characteristics to evaluate complex network models can
  be misleading</title><categories>cs.NI stat.AP</categories><comments>15 pags, 7 figures, submitted to Phys. A</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical models are frequently used to represent topological structures of
various complex networks. Current criteria to assess different models of a
network mainly rely on how close a model matches the network in terms of
topological characteristics. Typical topological metrics are clustering
coefficient, distance distribution, the largest eigenvalue of the adjacency
matrix, and the gap between the first and the second largest eigenvalues, which
are widely used to evaluate and compare different models of a network. In this
paper, we show that evaluating complex network models based on the current
topological metrics can be quite misleading. Taking several models of the
AS-level Internet as examples, we show that although a model seems to be good
to describe the Internet in terms of the aforementioned topological
characteristics, it is far from being realistic to represent the real Internet
in performances such as robustness in resisting intentional attacks and traffic
load distributions. We further show that it is not useful to assess network
models by examining some topological characteristics such as clustering
coefficient and distance distribution, if robustness of the Internet against
random node removals is the only concern. Our findings shed new lights on how
to reasonably evaluate different models of a network, not only the Internet but
also other types of complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0136</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0136</id><created>2010-10-31</created><authors><author><keyname>Reniers</keyname><forenames>M. A.</forenames></author><author><keyname>Willemse</keyname><forenames>T. A. C.</forenames></author></authors><title>Folk Theorems on the Correspondence between State-Based and Event-Based
  Systems</title><categories>cs.LO cs.FL</categories><comments>Full version of SOFSEM 2011 paper</comments><doi>10.1007/978-3-642-18381-2_41</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kripke Structures and Labelled Transition Systems are the two most prominent
semantic models used in concurrency theory. Both models are commonly believed
to be equi-expressive. One can find many ad-hoc embeddings of one of these
models into the other. We build upon the seminal work of De Nicola and
Vaandrager that firmly established the correspondence between stuttering
equivalence in Kripke Structures and divergence-sensitive branching
bisimulation in Labelled Transition Systems. We show that their embeddings can
also be used for a range of other equivalences of interest, such as strong
bisimilarity, simulation equivalence, and trace equivalence. Furthermore, we
extend the results by De Nicola and Vaandrager by showing that there are
additional translations that allow one to use minimisation techniques in one
semantic domain to obtain minimal representatives in the other semantic domain
for these equivalences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0148</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0148</id><created>2010-10-31</created><authors><author><keyname>Johnson</keyname><forenames>L. F.</forenames></author></authors><title>Golden and Alternating, fast simple O(lg n) algorithms for Fibonacci</title><categories>cs.DM cs.DS math.CO</categories><comments>11 pages, 1 table This paper illustrates the importance of
  considering storage size when running experiments and that the results of
  expermential comparsion of algorithms in a well known paper are at best
  unreliable because of register overflow. The two presented algorithms are
  concise but readable</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two very fast and simple O(lg n) algorithms for individual Fibonacci numbers
are given and compared to competing algorithms. A simple O(lg n) recursion is
derived that can also be applied to Lucas. A formula is given to estimate the
largest n, where F_n does not overflow the implementation's data type. The
danger of timing runs on input that is too large for the computer
representation leads to false research results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0168</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0168</id><created>2010-10-31</created><updated>2010-12-30</updated><authors><author><keyname>Gingl</keyname><forenames>Zoltan</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author></authors><title>Ultimate crack and lack of any security in the statistical key exchange
  protocol with random signals and feedback</title><categories>quant-ph cs.CR</categories><comments>We have to withdraw our earlier claim because errors have been
  identified in the calculation and computer simulations. However, we do
  believe that the protocol can be cracked in a similar fashion that needs only
  a few measurement, no statistics. Thus we hope that this new family of
  attacks can be developed into some efficient tool. However, the &quot;how&quot; is
  still an open question thus the Liu-protocol should be considered secure
  until such solution is found</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deterministically crack the secure, statistical key exchange protocol
based on feedback proposed by Pao-Lo Liu [ J. Lightwave Techology 27 (2009) pp.
5230-34]. The crack is ultimate and absolute because it works under idealized
conditions, and produces much higher data visibility for the eavesdropper than
the protocol provides for Alice and Bob. Even with the most idealistic driving
noise spectrum stated by Liu, during the most secure phase of the protocol, far
away from the transients, where the system is already in its most secure
steady-state, the eavesdropper has 100% success rate in identifying the key
bits, at the same time when Alice and Bob have less than 100% success rate
while using the Liu protocol. No statistics is needed, Eve can extract the
secure bit from two samples of the signal in the two direction. Thus the
Liu-protocol offers no security against the attack described in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0180</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0180</id><created>2010-10-31</created><updated>2011-06-16</updated><authors><author><keyname>Dani</keyname><forenames>Varsha</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author></authors><title>Independent sets in random graphs from the weighted second moment method</title><categories>cs.CC cond-mat.stat-mech math.CO math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove new lower bounds on the likely size of a maximum independent set in
a random graph with a given average degree. Our method is a weighted version of
the second moment method, where we give each independent set a weight based on
the total degree of its vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0187</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0187</id><created>2010-10-31</created><authors><author><keyname>Amrahov</keyname><forenames>&#x15e;ahin Emrah</forenames></author><author><keyname>Nooraden</keyname><forenames>Orhan A.</forenames></author></authors><title>A Distributed AI Aided 3D Domino Game</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the article a turn-based game played on four computers connected via
network is investigated. There are three computers with natural intelligence
and one with artificial intelligence. Game table is seen by each player's own
view point in all players' monitors. Domino pieces are three dimensional. For
distributed systems TCP/IP protocol is used. In order to get 3D image,
Microsoft XNA technology is applied. Domino 101 game is nondeterministic game
that is result of the game depends on the initial random distribution of the
pieces. Number of the distributions is equal to the multiplication of following
combinations: . Moreover, in this game that is played by four people, players
are divided into 2 pairs. Accordingly, we cannot predict how the player uses
the dominoes that is according to the dominoes of his/her partner or according
to his/her own dominoes. The fact that the natural intelligence can be a player
in any level affects the outcome. These reasons make it difficult to develop an
AI. In the article four levels of AI are developed. The AI in the first level
is equivalent to the intelligence of a child who knows the rules of the game
and recognizes the numbers. The AI in this level plays if it has any domino,
suitable to play or says pass. In most of the games which can be played on the
internet, the AI does the same. But the AI in the last level is a master
player, and it can develop itself according to its competitors' levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0190</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0190</id><created>2010-10-31</created><authors><author><keyname>Amrahov</keyname><forenames>&#x15e;ahin Emrah</forenames></author><author><keyname>Aybar</keyname><forenames>Fatih</forenames></author><author><keyname>Do&#x11f;an</keyname><forenames>Serhat</forenames></author></authors><title>Prunnig Algorithm of Generation a Minimal Set of Rule Reducts Based on
  Rough Set Theory</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper it is considered rule reduct generation problem, based on Rough
Set Theory. Rule Reduct Generation (RG) and Modified Rule Generation (MRG)
algorithms are well-known. Alternative to these algorithms Pruning Algorithm of
Generation A Minimal Set of Rule Reducts, or briefly Pruning Rule Generation
(PRG) algorithm is developed. PRG algorithm uses tree structured data type. PRG
algorithm is compared with RG and MRG algorithms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0192</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0192</id><created>2010-10-31</created><authors><author><keyname>McLaughlin</keyname><forenames>Mark</forenames></author><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author><author><keyname>Malone</keyname><forenames>Paul</forenames></author></authors><title>Digital Identity in The Absence of Authorities: A New Socio-Technical
  Approach</title><categories>cs.CY</categories><comments>19 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On the Internet large service providers tend to control the digital
identities of users. These defacto identity authorities wield significant power
over users, compelling them to comply with non-negotiable terms, before access
to services is granted. In doing so, users expose themselves to privacy risks,
manipulation and exploitation via direct marketing. Against this backdrop, the
emerging areas of Digital Ecosystems and user-centric identity emphasise
decentralised environments with independent self-determining entities that
control their own data and identity. We show that recent advances in
user-centric identity, federated identity and trust have prepared the ground
for decentralised identity provisioning. We show how social trust, rather than
blind deference to authorities, can provide a basis for identity, where risks
can be weighed and compared rather than merely accepted. Fundamentally, we are
considering the move from authority-centric centralised identity provisioning
to user-centric distributed identity provisioning. Finally, we highlight the
potential impacts of distributed identity provisioning in the Information
Society and give a brief roadmap for its general implementation and adoption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0208</identifier>
 <datestamp>2013-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0208</id><created>2010-10-31</created><updated>2013-04-02</updated><authors><author><keyname>Bruggeman</keyname><forenames>Jeroen</forenames></author></authors><title>Network Diversity and Economic Development: a Comment</title><categories>cs.SI physics.soc-ph</categories><comments>A more recent paper [http://arxiv.org/abs/1212.5969] substantiates
  the same idea with an empirical study, thereby rendering the old, more
  speculative, version superfluous</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network diversity yields context-dependent benefits that are not yet
fully-understood. I elaborate on a recently introduced distinction between tie
strength diversity and information source diversity, and explain when, how, and
why they matter. The issue whether there are benefits to specialization is the
key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0217</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0217</id><created>2010-10-31</created><authors><author><keyname>Demri</keyname><forenames>St&#xe9;phane</forenames><affiliation>LSV, CNRS, ENSC, INRIA, France</affiliation></author></authors><title>On Selective Unboundedness of VASS</title><categories>cs.FL cs.CC cs.LO</categories><comments>In Proceedings INFINITY 2010, arXiv:1010.6112</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010, pp. 1-15</journal-ref><doi>10.4204/EPTCS.39.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous properties of vector addition systems with states amount to checking
the (un)boundedness of some selective feature (e.g., number of reversals, run
length). Some of these features can be checked in exponential space by using
Rackoff's proof or its variants, combined with Savitch's theorem. However, the
question is still open for many others, e.g., reversal-boundedness. In the
paper, we introduce the class of generalized unboundedness properties that can
be verified in exponential space by extending Rackoff's technique, sometimes in
an unorthodox way. We obtain new optimal upper bounds, for example for
place-boundedness problem, reversal-boundedness detection (several variants
exist), strong promptness detection problem and regularity detection. Our
analysis is sufficiently refined so as we also obtain a polynomial-space bound
when the dimension is fixed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0218</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0218</id><created>2010-10-31</created><authors><author><keyname>Boucheneb</keyname><forenames>Hanifa</forenames><affiliation>Laboratoire VeriForm, &#xc9;cole Polytechnique de Montr&#xe9;al, Canada</affiliation></author><author><keyname>Barkaoui</keyname><forenames>Kamel</forenames><affiliation>Laboratoire CEDRIC, Conservatoire National des Arts et M&#xe9;tiers, France</affiliation></author></authors><title>On interleaving in {P,A}-Time Petri nets with strong semantics</title><categories>cs.FL cs.LO</categories><comments>In Proceedings INFINITY 2010, arXiv:1010.6112</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010, pp. 17-31</journal-ref><doi>10.4204/EPTCS.39.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the reachability analysis of {P,A}-Time Petri nets
({P,A}-TPN in short) in the context of strong semantics. It investigates the
convexity of the union of state classes reached by different interleavings of
the same set of transitions. In BB08, the authors have considered the T-TPN
model and its Contracted State Class Graph (CSCG) and shown that this union is
not necessarily convex. They have however established some sufficient
conditions which ensure convexity. This paper shows that for the CSCG of
{P,A}-TPN, this union is convex and can be computed without computing
intermediate state classes. These results allow to improve the forward
reachability analysis by agglomerating, in the same state class, all state
classes reached by different interleavings of the same set of transitions
(abstraction by convex-union).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0219</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0219</id><created>2010-10-31</created><authors><author><keyname>Maler</keyname><forenames>Oded</forenames><affiliation>CNRS-VERIMAG, University of Grenoble, France</affiliation></author><author><keyname>Larsen</keyname><forenames>Kim G.</forenames><affiliation>CISS and CS Aalborg University, Denmark</affiliation></author><author><keyname>Krogh</keyname><forenames>Bruce H.</forenames><affiliation>Department of EC Carnegie Mellon University, USA</affiliation></author></authors><title>On Zone-Based Analysis of Duration Probabilistic Automata</title><categories>cs.FL cs.LO</categories><comments>In Proceedings INFINITY 2010, arXiv:1010.6112</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010, pp. 33-46</journal-ref><doi>10.4204/EPTCS.39.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an extension of the zone-based algorithmics for analyzing timed
automata to handle systems where timing uncertainty is considered as
probabilistic rather than set-theoretic. We study duration probabilistic
automata (DPA), expressing multiple parallel processes admitting memoryfull
continuously-distributed durations. For this model we develop an extension of
the zone-based forward reachability algorithm whose successor operator is a
density transformer, thus providing a solution to verification and performance
evaluation problems concerning acyclic DPA (or the bounded-horizon behavior of
cyclic DPA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0220</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0220</id><created>2010-10-31</created><authors><author><keyname>Peschanski</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>UPMC-LIP6</affiliation></author><author><keyname>Klaudel</keyname><forenames>Hanna</forenames><affiliation>Universit&#xe9; Evry-Ibisc</affiliation></author><author><keyname>Devillers</keyname><forenames>Raymond</forenames><affiliation>Universit&#xe9; Libre de Bruxelles</affiliation></author></authors><title>A Decidable Characterization of a Graphical Pi-calculus with Iterators</title><categories>cs.FL cs.LO</categories><comments>In Proceedings INFINITY 2010, arXiv:1010.6112</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010, pp. 47-61</journal-ref><doi>10.4204/EPTCS.39.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the Pi-graphs, a visual paradigm for the modelling and
verification of mobile systems. The language is a graphical variant of the
Pi-calculus with iterators to express non-terminating behaviors. The
operational semantics of Pi-graphs use ground notions of labelled transition
and bisimulation, which means standard verification techniques can be applied.
We show that bisimilarity is decidable for the proposed semantics, a result
obtained thanks to an original notion of causal clock as well as the automatic
garbage collection of unused names.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0221</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0221</id><created>2010-10-31</created><authors><author><keyname>Boigelot</keyname><forenames>Bernard</forenames><affiliation>Institut Montefiore, Belgium</affiliation></author><author><keyname>Brusten</keyname><forenames>Julien</forenames><affiliation>Institut Montefiore, Belgium</affiliation></author><author><keyname>Degbomont</keyname><forenames>Jean-Fran&#xe7;ois</forenames><affiliation>Institut Montefiore, Belgium</affiliation></author></authors><title>Implicit Real Vector Automata</title><categories>cs.FL cs.LO</categories><comments>In Proceedings INFINITY 2010, arXiv:1010.6112</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010, pp. 63-76</journal-ref><doi>10.4204/EPTCS.39.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the symbolic representation of non-convex real
polyhedra, i.e., sets of real vectors satisfying arbitrary Boolean combinations
of linear constraints. We develop an original data structure for representing
such sets, based on an implicit and concise encoding of a known structure, the
Real Vector Automaton. The resulting formalism provides a canonical
representation of polyhedra, is closed under Boolean operators, and admits an
efficient decision procedure for testing the membership of a vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0222</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0222</id><created>2010-10-31</created><authors><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames><affiliation>INRIA Rennes Bretagne Atlantique</affiliation></author><author><keyname>Morvan</keyname><forenames>Christophe</forenames><affiliation>Universit&#xe9; Paris-Est and INRIA Rennes Bretagne Atlantique</affiliation></author></authors><title>Probabilistic regular graphs</title><categories>cs.FL cs.LO</categories><comments>In Proceedings INFINITY 2010, arXiv:1010.6112</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010, pp. 77-90</journal-ref><doi>10.4204/EPTCS.39.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deterministic graph grammars generate regular graphs, that form a structural
extension of configuration graphs of pushdown systems. In this paper, we study
a probabilistic extension of regular graphs obtained by labelling the terminal
arcs of the graph grammars by probabilities. Stochastic properties of these
graphs are expressed using PCTL, a probabilistic extension of computation tree
logic. We present here an algorithm to perform approximate verification of PCTL
formulae. Moreover, we prove that the exact model-checking problem for PCTL on
probabilistic regular graphs is undecidable, unless restricting to qualitative
properties. Our results generalise those of EKM06, on probabilistic pushdown
automata, using similar methods combined with graph grammars techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0223</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0223</id><created>2010-10-31</created><authors><author><keyname>Andr&#xe9;</keyname><forenames>&#xc9;tienne</forenames><affiliation>LSV, CNRS, ENSC, France</affiliation></author></authors><title>IMITATOR II: A Tool for Solving the Good Parameters Problem in Timed
  Automata</title><categories>cs.FL cs.LO</categories><comments>In Proceedings INFINITY 2010, arXiv:1010.6112</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 39, 2010, pp. 91-99</journal-ref><doi>10.4204/EPTCS.39.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here Imitator II, a new version of Imitator, a tool implementing
the &quot;inverse method&quot; for parametric timed automata: given a reference valuation
of the parameters, it synthesizes a constraint such that, for any valuation
satisfying this constraint, the system behaves the same as under the reference
valuation in terms of traces, i.e., alternating sequences of locations and
actions. Imitator II also implements the &quot;behavioral cartography algorithm&quot;,
allowing us to solve the following good parameters problem: find a set of
valuations within a given bounded parametric domain for which the system
behaves well. We present new features and optimizations of the tool, and give
results of applications to various examples of asynchronous circuits and
communication protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0227</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0227</id><created>2010-10-31</created><authors><author><keyname>Weston</keyname><forenames>Stuart</forenames></author><author><keyname>Natusch</keyname><forenames>Tim</forenames></author><author><keyname>Gulyaev</keyname><forenames>Sergei</forenames></author></authors><title>Radio Astronomy and eVLBI using KAREN</title><categories>astro-ph.IM cs.NI</categories><comments>Accepted for the 17th Electronics New Zealand Conference 2010, 5
  pages, 6 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kiwi Advanced Research and Education Network (KAREN) has been used to
transfer large volumes of radio astronomical data between the AUT Radio
Astronomical Observatory at Warkworth, New Zealand and the international
organisations with which we are collaborating and conducting observations. Here
we report on the current status of connectivity and on the results of testing
different data transfer protocols. We investigate new UDP protocols such as
&quot;tsunami&quot; and UDT and demonstrate that the UDT protocol is more efficient than
&quot;tsunami&quot; and ftp. We report on our initial steps towards real-time eVLBI and
the attempt to directly stream data from the radio telescope receiving system
to the correlation centre without intermediate buffering/recording.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0233</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0233</id><created>2010-10-31</created><updated>2010-11-03</updated><authors><author><keyname>Liu</keyname><forenames>Weiming</forenames></author><author><keyname>Li</keyname><forenames>Sanjiang</forenames></author></authors><title>Reasoning about Cardinal Directions between Extended Objects: The
  Hardness Result</title><categories>cs.AI</categories><comments>24 pages, 24 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cardinal direction calculus (CDC) proposed by Goyal and Egenhofer is a
very expressive qualitative calculus for directional information of extended
objects. Early work has shown that consistency checking of complete networks of
basic CDC constraints is tractable while reasoning with the CDC in general is
NP-hard. This paper shows, however, if allowing some constraints unspecified,
then consistency checking of possibly incomplete networks of basic CDC
constraints is already intractable. This draws a sharp boundary between the
tractable and intractable subclasses of the CDC. The result is achieved by a
reduction from the well-known 3-SAT problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0234</identifier>
 <datestamp>2015-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0234</id><created>2010-10-31</created><authors><author><keyname>Shao</keyname><forenames>Jia</forenames></author><author><keyname>Buldyrev</keyname><forenames>Sergey V.</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Stanley</keyname><forenames>H. Eugene</forenames></author></authors><title>Cascade of failures in coupled network systems with multiple
  support-dependent relations</title><categories>physics.data-an cs.SI nlin.CD physics.soc-ph</categories><doi>10.1103/PhysRevE.83.036116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study, both analytically and numerically, the cascade of failures in two
coupled network systems A and B, where multiple support-dependent relations are
randomly built between nodes of networks A and B. In our model we assume that
each node in one network can function only if it has at least a single support
node in the other network. If both networks A and B are Erd\H{o}s-R\'enyi
networks, A and B, with (i) sizes $N^A$ and $N^B$, (ii) average degrees $a$ and
$b$, and (iii) $c^{AB}_0N^B$ support links from network A to B and
$c^{BA}_0N^B$ support links from network B to A, we find that under random
attack with removal of fractions $(1-R^A)N^A$ and $(1-R^B)N^B$ nodes
respectively, the percolating giant components of both networks at the end of
the cascading failures, $\mu^A_\infty$ and $\mu^B_\infty$, are given by the
percolation laws $\mu^A_\infty = R^A [1-\exp{({-c^{BA}_0\mu^B_\infty})}]
[1-\exp{({-a\mu^A_\infty})}]$ and $\mu^B_\infty = R^B
[1-\exp{({-c^{AB}_0\mu^A_\infty})}] [1-\exp{({-b\mu^B_\infty})}]$. In the limit
of $c^{BA}_0 \to \infty$ and $c^{AB}_0 \to \infty$, both networks become
independent, and the giant components are equivalent to a random attack on a
single Erd\H{o}s-R\'enyi network. We also test our theory on two coupled
scale-free networks, and find good agreement with the simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0235</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0235</id><created>2010-10-31</created><authors><author><keyname>Koppaka</keyname><forenames>Sisir</forenames></author><author><keyname>Mudigere</keyname><forenames>Dheevatsa</forenames></author><author><keyname>Narasimhan</keyname><forenames>Srihari</forenames></author><author><keyname>Narayanan</keyname><forenames>Babu</forenames></author></authors><title>Fast Histograms using Adaptive CUDA Streams</title><categories>cs.DC cs.PF</categories><comments>5 pages, 5 figures, 4 tables, to appear in Student Research
  Symposium, High Performance Computing 2010, Goa, India (www.hipc.org)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Histograms are widely used in medical imaging, network intrusion detection,
packet analysis and other stream-based high throughput applications. However,
while porting such software stacks to the GPU, the computation of the histogram
is a typical bottleneck primarily due to the large impact on kernel speed by
atomic operations. In this work, we propose a stream-based model implemented in
CUDA, using a new adaptive kernel that can be optimized based on latency hidden
CPU compute. We also explore the tradeoffs of using the new kernel vis-\`a-vis
the stock NVIDIA SDK kernel, and discuss an intelligent kernel switching method
for the stream based on a degeneracy criterion that is adaptively computed from
the input stream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0250</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0250</id><created>2010-11-01</created><authors><author><keyname>Soni</keyname><forenames>Sangeeta</forenames></author><author><keyname>Namjoshi</keyname><forenames>Yogendra</forenames></author></authors><title>Delineation of Raw Plethysmograph using Wavelets for Mobile based Pulse
  Oximeters</title><categories>cs.CE</categories><comments>Proceedings of 5th Innovative Conference on Embedded Systems, Mobile
  Communication and Computing, Pg. 74-84, ISBN 023-033-045-2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The non-invasive pulse-oximeter is a crucial parameter in continuous
monitoring systems. It plays a vital role from admission of the patient to
surgeries with general anaesthesia. The paper proposes the application of
wavelet transform to delineate the raw plethysmograph signals obtained from
basic portable and mobile-powered electronic hardware. The paper primarily
focuses on finding peaks and baseline from noisy infrared and red waveforms
which are responsible for calculating heart-rate and oxygen saturation
percentages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0253</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0253</id><created>2010-11-01</created><authors><author><keyname>Jiang</keyname><forenames>Albert Xin</forenames></author><author><keyname>Leyton-Brown</keyname><forenames>Kevin</forenames></author></authors><title>Polynomial-time Computation of Exact Correlated Equilibrium in Compact
  Games</title><categories>cs.GT cs.CC</categories><comments>15 pages</comments><msc-class>68Q01</msc-class><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a landmark paper, Papadimitriou and Roughgarden described a
polynomial-time algorithm (&quot;Ellipsoid Against Hope&quot;) for computing sample
correlated equilibria of concisely-represented games. Recently, Stein, Parrilo
and Ozdaglar showed that this algorithm can fail to find an exact correlated
equilibrium, but can be easily modified to efficiently compute approximate
correlated equilibria. Currently, it remains unresolved whether the algorithm
can be modified to compute an exact correlated equilibrium. We show that it
can, presenting a variant of the Ellipsoid Against Hope algorithm that
guarantees the polynomial-time identification of exact correlated equilibrium.
Our new algorithm differs from the original primarily in its use of a
separation oracle that produces cuts corresponding to pure-strategy profiles.
As a result, we no longer face the numerical precision issues encountered by
the original approach, and both the resulting algorithm and its analysis are
considerably simplified. Our new separation oracle can be understood as a
derandomization of Papadimitriou and Roughgarden's original separation oracle
via the method of conditional probabilities. Also, the equilibria returned by
our algorithm are distributions with polynomial-sized supports, which are
simpler (in the sense of being representable in fewer bits) than the mixtures
of product distributions produced previously; no tractable algorithm has
previously been proposed for identifying such equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0268</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0268</id><created>2010-11-01</created><authors><author><keyname>Cheng</keyname><forenames>Chih-Hong</forenames></author><author><keyname>Ruess</keyname><forenames>Harald</forenames></author><author><keyname>Knoll</keyname><forenames>Alois</forenames></author><author><keyname>Buckl</keyname><forenames>Christian</forenames></author></authors><title>A Game-theoretic Approach for Synthesizing Fault-Tolerant Embedded
  Systems</title><categories>cs.GT cs.DC cs.SE</categories><comments>The extended version of the paper &quot;Synthesis of Fault-Tolerant
  Embedded Systems using Games: from Theory to Practice&quot; in VMCAI'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an approach for fault-tolerant synthesis by
combining predefined patterns for fault-tolerance with algorithmic game
solving. A non-fault-tolerant system, together with the relevant fault
hypothesis and fault-tolerant mechanism templates in a pool are translated into
a distributed game, and we perform an incomplete search of strategies to cope
with undecidability. The result of the game is translated back to executable
code concretizing fault-tolerant mechanisms using constraint solving. The
overall approach is implemented to a prototype tool chain and is illustrated
using examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0271</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0271</id><created>2010-11-01</created><authors><author><keyname>Li</keyname><forenames>Menghui</forenames></author><author><keyname>Guan</keyname><forenames>Shuguang</forenames></author><author><keyname>Lai</keyname><forenames>C. -H.</forenames></author></authors><title>Spontaneous Formation of Dynamical Groups in an Adaptive Networked
  System</title><categories>cond-mat.dis-nn cs.SI nlin.AO physics.soc-ph</categories><comments>14 page, 5 figures</comments><journal-ref>New Journal of Physics 12 (2010) 103032</journal-ref><doi>10.1088/1367-2630/12/10/103032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate a model of an adaptive networked dynamical
system, where the coupling strengths among phase oscillators coevolve with the
phase states. It is shown that in this model the oscillators can spontaneously
differentiate into two dynamical groups after a long time evolution. Within
each group, the oscillators have similar phases, while oscillators in different
groups have approximately opposite phases. The network gradually converts from
the initial random structure with a uniform distribution of connection
strengths into a modular structure which is characterized by strong intra
connections and weak inter connections. Furthermore, the connection strengths
follow a power law distribution, which is a natural consequence of the
coevolution of the network and the dynamics. Interestingly, it is found that if
the inter connections are weaker than a certain threshold, the two dynamical
groups will almost decouple and evolve independently. These results are helpful
in further understanding the empirical observations in many social and
biological networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1011.0278</identifier>
 <datestamp>2010-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1011.0278</id><created>2010-11-01</created><authors><author><keyname>Ibrahim</keyname><forenames>Rosziati</forenames></author><author><keyname>yen</keyname><forenames>Siow Yen</forenames></author></authors><title>Formalization of the data flow diagram rules for consistency check</title><categories>cs.SE</categories><comments>17 pages</comments><msc-class>aircc.org</msc-class><doi>10.5121/ijsea.2010.1406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In system development life cycle (SDLC), a system model can be developed
using Data Flow Diagram (DFD). DFD is graphical diagrams for specifying,
constructing and visualizing the model of a system. DFD is used in defining the
requirements in a graphical view. In this paper, we focus on DFD and its rules
for drawing and defining the diagrams. We then formalize these rules and
develop the tool based on the formalized rules. The formalized rules for
consistency check between the diagrams are used in developing the tool. This is
to ensure the syntax for drawing the diagrams is correct and strictly followed.
The tool automates the process of manual consistency check between data flow
diagrams.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="16000" completeListSize="102538">1122234|17001</resumptionToken>
</ListRecords>
</OAI-PMH>
