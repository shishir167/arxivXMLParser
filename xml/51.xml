<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T02:01:26Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|50001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2079</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2079</id><created>2013-09-09</created><authors><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Mendes</keyname><forenames>Nuno</forenames></author><author><keyname>Pires</keyname><forenames>Norberto</forenames></author><author><keyname>Moreira</keyname><forenames>Paulo</forenames></author></authors><title>CAD-based robot programming: The role of Fuzzy-PI force control in
  unstructured environments</title><categories>cs.RO</categories><comments>IEEE International Conference on Automation Science and Engineering,
  CASE 2010, pp. 362-367, Toronto, Canada, 2010</comments><doi>10.1109/COASE.2010.5584058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More and more, new ways of interaction between humans and robots are desired,
something that allow us to program a robot in an intuitive way, quickly and
with a high-level of abstraction from the robot language. In this paper is
presented a CAD-based system that allows users with basic skills in CAD and
without skills in robot programming to generate robot programs from a CAD model
of a robotic cell. When the CAD model reproduces exactly the real scenario, the
system presents a satisfactory performance. On the contrary, when the CAD model
does not reproduce exactly the real scenario or the calibration process is
poorly done, we are dealing with uncertain (unstructured environment). In order
to minimize or eliminate the previously mentioned problems, it was introduced
sensory feedback (force and torque sensing) in the robotic framework. By
controlling the end-effector pose and specifying its relationship to the
interaction/contact forces, robot programmers can ensure that the robot
maneuvers in an unstructured environment, damping possible impacts and also
increasing the tolerance to positioning errors from the calibration process.
Fuzzy-PI reasoning was used as a force control technique. The effectiveness of
the proposed approach was evaluated in a series of experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2080</identifier>
 <datestamp>2014-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2080</id><created>2013-09-09</created><authors><author><keyname>Bellodi</keyname><forenames>Elena</forenames></author><author><keyname>Riguzzi</keyname><forenames>Fabrizio</forenames></author></authors><title>Structure Learning of Probabilistic Logic Programs by Searching the
  Clause Space</title><categories>cs.LG cs.AI</categories><comments>44 pages, 12 figures</comments><doi>10.1017/S1471068413000689</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning probabilistic logic programming languages is receiving an increasing
attention and systems are available for learning the parameters (PRISM,
LeProbLog, LFI-ProbLog and EMBLEM) or both the structure and the parameters
(SEM-CP-logic and SLIPCASE) of these languages. In this paper we present the
algorithm SLIPCOVER for &quot;Structure LearnIng of Probabilistic logic programs by
searChing OVER the clause space&quot;. It performs a beam search in the space of
probabilistic clauses and a greedy search in the space of theories, using the
log likelihood of the data as the guiding heuristics. To estimate the log
likelihood SLIPCOVER performs Expectation Maximization with EMBLEM. The
algorithm has been tested on five real world datasets and compared with
SLIPCASE, SEM-CP-logic, Aleph and two algorithms for learning Markov Logic
Networks (Learning using Structural Motifs (LSM) and ALEPH++ExactL1). SLIPCOVER
achieves higher areas under the precision-recall and ROC curves in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2081</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2081</id><created>2013-09-09</created><authors><author><keyname>Mendes</keyname><forenames>Nuno</forenames></author><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Pires</keyname><forenames>Norberto</forenames></author><author><keyname>Loureiro</keyname><forenames>Altino</forenames></author></authors><title>Discretization and fitting of nominal data for autonomous robots</title><categories>cs.RO</categories><comments>Expert Systems with Applications</comments><journal-ref>Expert Systems with Applications, Volume 40, Issue 4, March 2013,
  Pages 1143-1151</journal-ref><doi>10.1016/j.eswa.2012.08.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents methodologies to discretize nominal robot paths extracted
from 3-D CAD drawings. Behind robot path discretization is the ability to have
a robot adjusting the traversed paths so that the contact between robot tool
and work-piece is properly maintained. In addition, a hybrid force/motion
control system based on Fuzzy-PI control is proposed to adjust robot paths with
external sensory feedback. All these capabilities allow to facilitate the robot
programming process and to increase the robots autonomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2084</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2084</id><created>2013-09-09</created><authors><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Pereira</keyname><forenames>D&#xe1;rio</forenames></author><author><keyname>Pires</keyname><forenames>Norberto</forenames></author><author><keyname>Moreira</keyname><forenames>Paulo</forenames></author></authors><title>Real-Time and Continuous Hand Gesture Spotting: an Approach Based on
  Artificial Neural Networks</title><categories>cs.RO cs.CV</categories><comments>2013 IEEE International Conference on Robotics and Automation (ICRA)
  pp. 178-183, Karlsruhe, Germany, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New and more natural human-robot interfaces are of crucial interest to the
evolution of robotics. This paper addresses continuous and real-time hand
gesture spotting, i.e., gesture segmentation plus gesture recognition. Gesture
patterns are recognized by using artificial neural networks (ANNs) specifically
adapted to the process of controlling an industrial robot. Since in continuous
gesture recognition the communicative gestures appear intermittently with the
noncommunicative, we are proposing a new architecture with two ANNs in series
to recognize both kinds of gesture. A data glove is used as interface
technology. Experimental results demonstrated that the proposed solution
presents high recognition rates (over 99% for a library of ten gestures and
over 96% for a library of thirty gestures), low training and learning time and
a good capacity to generalize from particular situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2086</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2086</id><created>2013-09-09</created><authors><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Mendes</keyname><forenames>Nuno</forenames></author><author><keyname>Ara&#xfa;jo</keyname><forenames>Ricardo</forenames></author><author><keyname>Pires</keyname><forenames>J. Norberto</forenames></author><author><keyname>Moreira</keyname><forenames>A. Paulo</forenames></author></authors><title>High-level robot programming based on CAD: dealing with unpredictable
  environments</title><categories>cs.RO</categories><comments>Industrial Robot: An International Journal</comments><journal-ref>Industrial Robot: An International Journal, Vol. 39 Iss: 3, 2012,
  pp.294 - 303</journal-ref><doi>10.1108/01439911211217125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose - The purpose of this paper is to present a CAD-based human-robot
interface that allows non-expert users to teach a robot in a manner similar to
that used by human beings to teach each other.
  Design/methodology/approach - Intuitive robot programming is achieved by
using CAD drawings to generate robot programs off-line. Sensory feedback allows
minimization of the effects of uncertainty, providing information to adjust the
robot paths during robot operation.
  Findings - It was found that it is possible to generate a robot program from
a common CAD drawing and run it without any major concerns about calibration or
CAD model accuracy.
  Research limitations/implications - A limitation of the proposed system has
to do with the fact that it was designed to be used for particular
technological applications.
  Practical implications - Since most manufacturing companies have CAD packages
in their facilities today, CAD-based robot programming may be a good option to
program robots without the need for skilled robot programmers.
  Originality/value - The paper proposes a new CAD-based robot programming
system. Robot programs are directly generated from a CAD drawing running on a
commonly available 3D CAD package (Autodesk Inventor) and not from a
commercial, computer aided robotics (CAR) software, making it a simple CAD
integrated solution. This is a low-cost and low-setup time system where no
advanced robot programming skills are required to operate it. In summary, robot
programs are generated with a high-level of abstraction from the robot
language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2089</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2089</id><created>2013-09-09</created><authors><author><keyname>Ferreira</keyname><forenames>Marcos</forenames></author><author><keyname>Moreira</keyname><forenames>Ant&#xf3;nio Paulo</forenames></author><author><keyname>Neto</keyname><forenames>Pedro</forenames></author></authors><title>A low-cost laser scanning solution for flexible robotic cells: spray
  coating</title><categories>cs.RO</categories><comments>The International Journal of Advanced Manufacturing Technology</comments><journal-ref>The International Journal of Advanced Manufacturing Technology,
  Volume 58, Issue 9-12, 2012, pp 1031-1041</journal-ref><doi>10.1007/s00170-011-3452-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an adaptive and low-cost robotic coating platform for small
production series is presented. This new platform presents a flexible
architecture that enables fast/automatic system adaptive behaviour without
human intervention. The concept is based on contactless technology, using
artificial vision and laser scanning to identify and characterize different
workpieces travelling on a conveyor. Using laser triangulation, the workpieces
are virtually reconstructed through a simplified cloud of three-dimensional
(3D) points. From those reconstructed models, several algorithms are
implemented to extract information about workpieces profile (pattern
recognition), size, boundary and pose. Such information is then used to on-line
adjust the base robot programmes. These robot programmes are off-line generated
from a 3D computer-aided design model of each different workpiece profile.
Finally, the robotic manipulator executes the coating process after its base
programmes have been adjusted. This is a low-cost and fully autonomous system
that allows adapting the robots behaviour to different manufacturing
situations. It means that the robot is ready to work over any piece at any
time, and thus, small production series can be reduced to as much as a
one-object series. No skilled workers and large setup times are needed to
operate it. Experimental results showed that this solution proved to be
efficient and can be applied not only for spray coating purposes but also for
many other industrial processes (automatic manipulation, pick-and-place,
inspection, etc.).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2090</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2090</id><created>2013-09-09</created><authors><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Pires</keyname><forenames>Norberto</forenames></author><author><keyname>Moreira</keyname><forenames>Paulo</forenames></author></authors><title>Accelerometer-based control of an industrial robotic arm</title><categories>cs.RO</categories><comments>The 18th IEEE International Symposium on Robot and Human Interactive
  Communication, 2009. RO-MAN 2009. pp. 1192-1197, Toyama, Japan, 2009</comments><doi>10.1109/ROMAN.2009.5326285</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of industrial robots are still programmed using the typical teaching
process, through the use of the robot teach pendant. In this paper is proposed
an accelerometer-based system to control an industrial robot using two low-cost
and small 3-axis wireless accelerometers. These accelerometers are attached to
the human arms, capturing its behavior (gestures and postures). An Artificial
Neural Network (ANN) trained with a back-propagation algorithm was used to
recognize arm gestures and postures, which then will be used as input in the
control of the robot. The aim is that the robot starts the movement almost at
the same time as the user starts to perform a gesture or posture (low response
time). The results show that the system allows the control of an industrial
robot in an intuitive way. However, the achieved recognition rate of gestures
and postures (92%) should be improved in future, keeping the compromise with
the system response time (160 milliseconds). Finally, the results of some tests
performed with an industrial robot are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2093</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2093</id><created>2013-09-09</created><authors><author><keyname>Neto</keyname><forenames>Pedro</forenames></author><author><keyname>Pires</keyname><forenames>Norberto</forenames></author><author><keyname>Moreira</keyname><forenames>Paulo</forenames></author></authors><title>High-level programming and control for industrial robotics: using a
  hand-held accelerometer-based input device for gesture and posture
  recognition</title><categories>cs.RO</categories><comments>Industrial Robot: An International Journal</comments><journal-ref>Industrial Robot: An International Journal, Vol. 37 Iss: 2, 2010,
  pp.137 - 147</journal-ref><doi>10.1108/01439911011018911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose - Most industrial robots are still programmed using the typical
teaching process, through the use of the robot teach pendant. This is a tedious
and time-consuming task that requires some technical expertise, and hence new
approaches to robot programming are required. The purpose of this paper is to
present a robotic system that allows users to instruct and program a robot with
a high-level of abstraction from the robot language.
  Design/methodology/approach - The paper presents in detail a robotic system
that allows users, especially non-expert programmers, to instruct and program a
robot just showing it what it should do, in an intuitive way. This is done
using the two most natural human interfaces (gestures and speech), a force
control system and several code generation techniques. Special attention will
be given to the recognition of gestures, where the data extracted from a motion
sensor (three-axis accelerometer) embedded in the Wii remote controller was
used to capture human hand behaviours. Gestures (dynamic hand positions) as
well as manual postures (static hand positions) are recognized using a
statistical approach and artificial neural networks.
  Practical implications - The key contribution of this paper is that it offers
a practical method to program robots by means of gestures and speech, improving
work efficiency and saving time.
  Originality/value - This paper presents an alternative to the typical robot
teaching process, extending the concept of human-robot interaction and
co-worker scenario. Since most companies do not have engineering resources to
make changes or add new functionalities to their robotic manufacturing systems,
this system constitutes a major advantage for small- to medium-sized
enterprises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2094</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2094</id><created>2013-09-09</created><updated>2013-09-10</updated><authors><author><keyname>Lorenz</keyname><forenames>Dirk A.</forenames></author><author><keyname>Sch&#xf6;pfer</keyname><forenames>Frank</forenames></author><author><keyname>Wenger</keyname><forenames>Stephan</forenames></author></authors><title>The Linearized Bregman Method via Split Feasibility Problems: Analysis
  and Generalizations</title><categories>math.OC cs.CV cs.NA math.NA</categories><msc-class>68U10, 65K10, 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linearized Bregman method is a method to calculate sparse solutions to
systems of linear equations. We formulate this problem as a split feasibility
problem, propose an algorithmic framework based on Bregman projections and
prove a general convergence result for this framework. Convergence of the
linearized Bregman method will be obtained as a special case. Our approach also
allows for several generalizations such as other objective functions,
incremental iterations, incorporation of non-gaussian noise models or box
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2103</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2103</id><created>2013-09-09</created><authors><author><keyname>Alvarez</keyname><forenames>Gregory</forenames></author><author><keyname>Berenguer</keyname><forenames>Charles</forenames></author></authors><title>Puzzle Encryption Algorithm</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document describes the symmetric encryption algorithm called Puzzle. It
is free and open. The objective of this paper is to get an opinion about its
security from the cryptology community. It is separated in two parts, a
technical description of the algorithm and its cryptanalysis. The algorithm has
some interesting properties :
  The block size is variable and unknown from an attacker. The size of the key
has no limit and is unknown from an attacker. The key size does not affect the
algorithm speed (using a 256 bit key is the same as using a 1024 bit key). The
algorithm is much faster than the average cryptographic function. Experimental
test showed 600 Mo/s - 4 cycles/byte on an Intel Core 2 Duo P8600 2.40GHz and
1,2 Go/s - 2 cycles/byte on an Intel i5-3210M 2.50GHz. Both CPU had only 2
cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2128</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2128</id><created>2013-09-09</created><updated>2013-09-17</updated><authors><author><keyname>Bowler</keyname><forenames>Nathan</forenames><affiliation>Department of Mathematics, Universit&#xe4;t Hamburg</affiliation></author><author><keyname>Goncharov</keyname><forenames>Sergey</forenames><affiliation>Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg</affiliation></author><author><keyname>Levy</keyname><forenames>Paul Blain</forenames><affiliation>School of Computer Science, University of Birmingham</affiliation></author><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames><affiliation>Department of Computer Science, Friedrich-Alexander-Universit&#xe4;t Erlangen-N&#xfc;rnberg</affiliation></author></authors><title>Exploring the Boundaries of Monad Tensorability on Set</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  18, 2013) lmcs:740</journal-ref><doi>10.2168/LMCS-9(3:22)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a composition operation on monads, equivalently presented as large
equational theories. Specifically, we discuss the existence of tensors, which
are combinations of theories that impose mutual commutation of the operations
from the component theories. As such, they extend the sum of two theories,
which is just their unrestrained combination. Tensors of theories arise in
several contexts; in particular, in the semantics of programming languages, the
monad transformer for global state is given by a tensor. We present two main
results: we show that the tensor of two monads need not in general exist by
presenting two counterexamples, one of them involving finite powerset (i.e. the
theory of join semilattices); this solves a somewhat long-standing open
problem, and contrasts with recent results that had ruled out previously
expected counterexamples. On the other hand, we show that tensors with bounded
powerset monads do exist from countable powerset upwards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2132</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2132</id><created>2013-09-09</created><authors><author><keyname>Dugu&#xe9;</keyname><forenames>Nicolas</forenames><affiliation>LIFO</affiliation></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames><affiliation>LIFO</affiliation></author><author><keyname>Perez</keyname><forenames>Anthony</forenames><affiliation>LIFO</affiliation></author></authors><title>R\^ole communautaire des capitalistes sociaux dans Twitter</title><categories>cs.CY</categories><proxy>ccsd</proxy><journal-ref>4\`eme Conf\'erence sur les mod\`eles et l'analyse de r\'eseaux :
  approches math\'ematiques et informatiques, Saint-\'Etienne : France (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Les capitalistes sociaux sont des utilisateurs de m\'edias sociaux tels que
Twitter, appliquant diverses techniques pour obtenir un maximum de
visibilit\'e. Ils peuvent \^etre n\'efastes \`a l'\'equilibre du service, dans
la mesure o\`u leurs comptes, en gagnant en importance sans r\'eelle raison de
contenu, rendent difficile l'acc\`es \`a un contenu pertinent. Dans ce travail,
nous nous int\'eressons \`a leur caract\'erisation d'un point de vue purement
topologique, i.e. sans consid\'erer la nature des contenus partag\'es. Nous
utilisons pour cela la notion de r\^ole communautaire, qui est bas\'ee sur la
structure de communaut\'es du r\'eseau \'etudi\'e. Nous apportons des
modifications \`a des mesures pr\'ec\'edemment d\'efinies \`a cet effet, et
proposons une m\'ethode objective de d\'etection des r\^oles. Nous appliquons
ensuite notre m\'ethode \`a l'analyse d'un r\'eseau repr\'esentant Twitter. Nos
r\'esultats montrent que les r\^oles que nous identifions via nos mesures se
r\'ev\`elent particuli\`erement coh\'erents par rapport aux capitalistes
sociaux du r\'eseau Twitter, dont le comportement est clairement
identifi\'e---Social capitalists are social media users taking advantage of
various methods to maximize their visibility. This results in artificially
important accounts, in the sense this importance is not backed by any real
content. The risk is then to see those accounts hiding relevant contents and
therefore preventing other users to access them. In this work, we want to
characterize social capitalists from a purely topological perspective, i.e.
without considering the nature of the shared contents. For this purpose, we use
the notion of community role, based on the community structure of the studied
network. We modify some measures previously designed for this matter, and
propose an objective method to determine roles. We then apply this method to
the analysis of a Twitter network. Our results show the roles identified
through our measures are particularly consistent with Twitter's social
capitalists, whose behavior was clearly identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2137</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2137</id><created>2013-09-09</created><authors><author><keyname>Harju</keyname><forenames>Tero</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Mike</forenames></author></authors><title>Square-Free Shuffles of Words</title><categories>cs.DM cs.FL math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $u \shuffle v$ denote the set of all shuffles of the words $u$ and $v$.
It is shown that for each integer $n \geq 3$ there exists a square-free ternary
word $u$ of length $n$ such that $u\shuffle u$ contains a square-free word.
This property is then shown to also hold for infinite words, i.e., there exists
an infinite square-free word $u$ on three letters such that $u$ can be shuffled
with itself to produce an infinite square-free word $w \in u \shuffle u$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2138</identifier>
 <datestamp>2014-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2138</id><created>2013-09-09</created><updated>2014-05-23</updated><authors><author><keyname>Spaenlehauer</keyname><forenames>Pierre-Jean</forenames></author></authors><title>On the Complexity of Computing Critical Points with Gr\&quot;obner Bases</title><categories>cs.SC</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the critical points of a polynomial function $q\in\mathbb
Q[X_1,\ldots,X_n]$ restricted to the vanishing locus $V\subset\mathbb R^n$ of
polynomials $f_1,\ldots, f_p\in\mathbb Q[X_1,\ldots, X_n]$ is of first
importance in several applications in optimization and in real algebraic
geometry. These points are solutions of a highly structured system of
multivariate polynomial equations involving maximal minors of a Jacobian
matrix. We investigate the complexity of solving this problem by using
Gr\&quot;obner basis algorithms under genericity assumptions on the coefficients of
the input polynomials. The main results refine known complexity bounds (which
depend on the maximum $D=\max(deg(f_1),\ldots,deg(f_p),deg(q))$) to bounds
which depend on the list of degrees $(deg(f_1),\ldots,deg(f_p),deg(q))$: we
prove that the Gr\&quot;obner basis computation can be performed in
$\delta^{O(\log(A)/\log(G))}$ arithmetic operations in $\mathbb Q$, where
$\delta$ is the algebraic degree of the ideal vanishing on the critical points,
and $A$ and $G$ are the arithmetic and geometric average of a multiset
constructed from the sequence of degrees. As a by-product, we prove that
solving such generic optimization problems with Gr\&quot;obner bases requires at
most $D^{O(n)}$ arithmetic operations in $\mathbb Q$, which meets the best
known complexity bound for this problem. Finally, we illustrate these
complexity results with experiments, giving evidence that these bounds are
relevant for applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2139</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2139</id><created>2013-09-09</created><authors><author><keyname>Wang</keyname><forenames>Yongxin</forenames></author><author><keyname>Sandrasegaran</keyname><forenames>Kumbesan</forenames></author><author><keyname>Zhu</keyname><forenames>Xinning</forenames></author><author><keyname>Fei</keyname><forenames>Jingjing</forenames></author><author><keyname>Kong</keyname><forenames>Xiaoying</forenames></author><author><keyname>Lin</keyname><forenames>Cheng-Chung</forenames></author></authors><title>Frequency and time domain packet scheduling based on channel prediction
  with imperfect CQI in LTE</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel-dependent scheduling of transmission of data packets in a wireless
system is based on measurement and feedback of the channel quality. To
alleviate the performance degradation due to simultaneous multiple imperfect
channel quality information (CQI), a simple and efficient packet scheduling
(PS) algorithm is developed in downlink LTE system for real time traffic. A
frequency domain channel predictor based on Kalman filter is first developed to
restore the true CQI from erroneous channel quality feedback. Then, a time
domain grouping technique employing the joint of Proportional Fair (PF) and
Modified Largest Weighted Delay First (M-LWDF) algorithms is used. It was
proved this proposal achieves better performance in terms of system throughput
and packet loss ratio by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2143</identifier>
 <datestamp>2014-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2143</id><created>2013-09-09</created><updated>2014-01-17</updated><authors><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Alnuweiri</keyname><forenames>Hussein</forenames></author></authors><title>Secure Layered Transmission in Multicast Systems with Wireless
  Information and Power Transfer</title><categories>cs.IT math.IT</categories><comments>7 pages, 3 figures, accepted for presentation at the IEEE
  International Conference on Communications (ICC), Sydney, Australia, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers downlink multicast transmit beamforming for secure
layered transmission systems with wireless simultaneous information and power
transfer. We study the power allocation algorithm design for minimizing the
total transmit power in the presence of passive eavesdroppers and energy
harvesting receivers. The algorithm design is formulated as a non-convex
optimization problem. Our problem formulation promotes the dual use of energy
signals in providing secure communication and facilitating efficient energy
transfer. Besides, we take into account a minimum required power for energy
harvesting at the idle receivers and heterogeneous quality of service (QoS)
requirements for the multicast video receivers. In light of the intractability
of the problem, we reformulate the considered problem by replacing a non-convex
probabilistic constraint with a convex deterministic constraint. Then, a
semidefinite programming relaxation (SDR) approach is adopted to obtain an
upper solution for the reformulated problem. Subsequently, sufficient
conditions for the global optimal solution of the reformulated problem are
revealed. Furthermore, we propose two suboptimal power allocation schemes based
on the upper bound solution. Simulation results demonstrate the excellent
performance and significant transmit power savings achieved by the proposed
schemes compared to isotropic energy signal generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2152</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2152</id><created>2013-09-09</created><authors><author><keyname>Kuppusamy</keyname><forenames>K. S.</forenames></author><author><keyname>Francis</keyname><forenames>Leena Mary</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>COSMOS A Context Sensitive Model For Dynamic Configuration Of
  Smartphones Using Multifactor Analysis</title><categories>cs.HC</categories><comments>12 Pages, 5 Figures</comments><msc-class>68U35</msc-class><journal-ref>International Journal of Information Technology, Modeling and
  Computing (IJITMC) Vol.1, No.3,August 2013, ISSN: 2320-7493</journal-ref><doi>10.5121/ijitmc.2013.1302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the prolific growth in usage of smartphones across the spectrum of
people in the society it becomes mandatory to handle and configure these
devices effectively to achieve optimum results from it. This paper proposes a
context sensitive model termed COSMOS (COntext Sensitive MOdel for Smartphones)
for configuring the smartphones using multifactor analysis with the help of
decision trees. The COSMOS model proposed in this paper facilitates the
configuration of various smartphone settings implicitly based on the user's
current context, without interrupting the user for various inputs. The COSMOS
model also proposes multiple context parameters like location, scheduler data,
recent call log settings etc to decide the appropriate settings for the
smartphones. The proposed model is validated by a prototype implementation in
the Android platform. Various tests were conducted in the implementation and
the settings relevancy metric value of 90.95% confirms the efficiency of the
proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2156</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2156</id><created>2013-09-09</created><authors><author><keyname>de Rugy-Altherre</keyname><forenames>Nicolas</forenames></author></authors><title>Determinant versus Permanent: salvation via generalization? The
  algebraic complexity of the Fermionant and the Immanant</title><categories>cs.CC</categories><comments>Initially published in CIE2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fermionant can be seen as a generalization of both the permanent (for
$k=-1$) and the determinant. We demonstrate that it is VNP-complete for most
cases. Furthermore it is #P-complete for the cases. The immanant is also a
generalization of the permanent (for a Young diagram with a single line) and of
the determinant (when the Young diagram is a column). We demonstrate that the
immanant of any family of Young diagrams with bounded width and at least n
boxes at the right of the first column is VNP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2168</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2168</id><created>2013-09-09</created><updated>2015-02-16</updated><authors><author><keyname>Gondzio</keyname><forenames>Jacek</forenames></author><author><keyname>Gonz&#xe1;lez-Brevis</keyname><forenames>Pablo</forenames></author><author><keyname>Munari</keyname><forenames>Pedro</forenames></author></authors><title>Large-scale optimization with the primal-dual column generation method</title><categories>math.OC cs.LG cs.NA</categories><comments>28 pages, 1 figure, minor revision, scaled CPU times</comments><report-no>Technical Report ERGO 13-014</report-no><msc-class>90C25, 90C06, 90C51, 90C90, 90C05, 49M27, 65K05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primal-dual column generation method (PDCGM) is a general-purpose column
generation technique that relies on the primal-dual interior point method to
solve the restricted master problems. The use of this interior point method
variant allows to obtain suboptimal and well-centered dual solutions which
naturally stabilizes the column generation. As recently presented in the
literature, reductions in the number of calls to the oracle and in the CPU
times are typically observed when compared to the standard column generation,
which relies on extreme optimal dual solutions. However, these results are
based on relatively small problems obtained from linear relaxations of
combinatorial applications. In this paper, we investigate the behaviour of the
PDCGM in a broader context, namely when solving large-scale convex optimization
problems. We have selected applications that arise in important real-life
contexts such as data analysis (multiple kernel learning problem),
decision-making under uncertainty (two-stage stochastic programming problems)
and telecommunication and transportation networks (multicommodity network flow
problem). In the numerical experiments, we use publicly available benchmark
instances to compare the performance of the PDCGM against recent results for
different methods presented in the literature, which were the best available
results to date. The analysis of these results suggests that the PDCGM offers
an attractive alternative over specialized methods since it remains competitive
in terms of number of iterations and CPU times even for large-scale
optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2172</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2172</id><created>2013-09-09</created><updated>2015-06-19</updated><authors><author><keyname>Rossi</keyname><forenames>Wilbert Samuel</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author></authors><title>Average resistance of toroidal graphs</title><categories>math.OC cs.SY</categories><comments>24 pages, 6 figures, to appear in SIAM Journal on Control and
  Optimization (SICON)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The average effective resistance of a graph is a relevant performance index
in many applications, including distributed estimation and control of network
systems. In this paper, we study how the average resistance depends on the
graph topology and specifically on the dimension of the graph. We concentrate
on $d$-dimensional toroidal grids and we exploit the connection between
resistance and Laplacian eigenvalues. Our analysis provides tight estimates of
the average resistance, which are key to study its asymptotic behavior when the
number of nodes grows to infinity. In dimension two, the average resistance
diverges: in this case, we are able to capture its rate of growth when the
sides of the grid grow at different rates. In higher dimensions, the average
resistance is bounded uniformly in the number of nodes: in this case, we
conjecture that its value is of order $1/d$ for large $d$. We prove this fact
for hypercubes and when the side lengths go to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2175</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2175</id><created>2013-09-09</created><updated>2014-01-06</updated><authors><author><keyname>Asztalos</keyname><forenames>Andrea</forenames></author><author><keyname>Sreenivasan</keyname><forenames>Sameet</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw K.</forenames></author><author><keyname>Korniss</keyname><forenames>Gyorgy</forenames></author></authors><title>Cascading failures in spatially-embedded random networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>13 pages, 15 figures</comments><journal-ref>PLoS ONE 9(1): e84563 (2014)</journal-ref><doi>10.1371/journal.pone.0084563</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cascading failures constitute an important vulnerability of interconnected
systems. Here we focus on the study of such failures on networks in which the
connectivity of nodes is constrained by geographical distance. Specifically, we
use random geometric graphs as representative examples of such spatial
networks, and study the properties of cascading failures on them in the
presence of distributed flow. The key finding of this study is that the process
of cascading failures is non-self-averaging on spatial networks, and thus,
aggregate inferences made from analyzing an ensemble of such networks lead to
incorrect conclusions when applied to a single network, no matter how large the
network is. We demonstrate that this lack of self-averaging disappears with the
introduction of a small fraction of long-range links into the network. We
simulate the well studied preemptive node removal strategy for cascade
mitigation and show that it is largely ineffective in the case of spatial
networks. We introduce an altruistic strategy designed to limit the loss of
network nodes in the event of a cascade triggering failure and show that it
performs better than the preemptive strategy. Finally, we consider a real-world
spatial network viz. a European power transmission network and validate that
our findings from the study of random geometric graphs are also borne out by
simulations of cascading failures on the empirical network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2179</identifier>
 <datestamp>2014-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2179</id><created>2013-08-21</created><updated>2014-02-13</updated><authors><author><keyname>Saez</keyname><forenames>Yessica</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Mingesz</keyname><forenames>Robert</forenames></author><author><keyname>Gingl</keyname><forenames>Zoltan</forenames></author><author><keyname>Granqvist</keyname><forenames>Claes G.</forenames></author></authors><title>Current and voltage based bit errors and their combined mitigation for
  the Kirchhoff-law-Johnson-noise secure key exchange</title><categories>cs.CR cs.ET</categories><comments>9 pages, accepted for publication in Journal of Computational
  Electronics</comments><doi>10.1007/s10825-013-0515-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We classify and analyze bit errors in the current measurement mode of the
Kirchhoff-law-Johnson-noise (KLJN) key distribution. The error probability
decays exponentially with increasing bit exchange period and fixed bandwidth,
which is similar to the error probability decay in the voltage measurement
mode. We also analyze the combination of voltage and current modes for error
removal. In this combination method, the error probability is still an
exponential function that decays with the duration of the bit exchange period,
but it has superior fidelity to the former schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2183</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2183</id><created>2013-09-09</created><authors><author><keyname>Khaze</keyname><forenames>Seyyed Reza</forenames></author><author><keyname>Masdari</keyname><forenames>Mohammad</forenames></author><author><keyname>Hojjatkhah</keyname><forenames>Sohrab</forenames></author></authors><title>Application of Artificial Neural Networks in Estimating Participation in
  Elections</title><categories>cs.NE cs.CY</categories><journal-ref>International Journal of Information Technology, Modeling and
  Computing (IJITMC) Vol.1, No.3,August 2013</journal-ref><doi>10.5121/ijitmc.2013.1303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is approved that artificial neural networks can be considerable effective
in anticipating and analyzing flows in which traditional methods and statics
are not able to solve. in this article, by using two-layer feedforward network
with tan-sigmoid transmission function in input and output layers, we can
anticipate participation rate of public in kohgiloye and boyerahmad province in
future presidential election of islamic republic of iran with 91% accuracy. the
assessment standards of participation such as confusion matrix and roc diagrams
have been approved our claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2199</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2199</id><created>2013-09-09</created><authors><author><keyname>Grabowicz</keyname><forenames>Przemyslaw A.</forenames></author><author><keyname>Aiello</keyname><forenames>Luca Maria</forenames></author><author><keyname>Egu&#xed;luz</keyname><forenames>V&#xed;ctor M.</forenames></author><author><keyname>Jaimes</keyname><forenames>Alejandro</forenames></author></authors><title>Distinguishing Topical and Social Groups Based on Common Identity and
  Bond Theory</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>10 pages, 6 figures, 2 tables</comments><acm-class>H.3.5; H.1.2</acm-class><journal-ref>2013. In Proceedings of the sixth ACM international conference on
  Web search and data mining (WSDM '13). ACM, New York, NY, USA, 627-636</journal-ref><doi>10.1145/2433396.2433475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social groups play a crucial role in social media platforms because they form
the basis for user participation and engagement. Groups are created explicitly
by members of the community, but also form organically as members interact. Due
to their importance, they have been studied widely (e.g., community detection,
evolution, activity, etc.). One of the key questions for understanding how such
groups evolve is whether there are different types of groups and how they
differ. In Sociology, theories have been proposed to help explain how such
groups form. In particular, the common identity and common bond theory states
that people join groups based on identity (i.e., interest in the topics
discussed) or bond attachment (i.e., social relationships). The theory has been
applied qualitatively to small groups to classify them as either topical or
social. We use the identity and bond theory to define a set of features to
classify groups into those two categories. Using a dataset from Flickr, we
extract user-defined groups and automatically-detected groups, obtained from a
community detection algorithm. We discuss the process of manual labeling of
groups into social or topical and present results of predicting the group label
based on the defined features. We directly validate the predictions of the
theory showing that the metrics are able to forecast the group type with high
accuracy. In addition, we present a comparison between declared and detected
groups along topicality and sociality dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2208</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2208</id><created>2013-09-09</created><authors><author><keyname>Akhtar</keyname><forenames>Md. Amir Khusru</forenames></author><author><keyname>Sahoo</keyname><forenames>G.</forenames></author></authors><title>A Novel Methodology to Overcome Routing Misbehavior in MANET using
  Retaliation Model</title><categories>cs.NI</categories><comments>16 pages, 6 figures, 3 tables</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  5, No. 4, August 2013</journal-ref><doi>10.5121/ijwmn.2013.5414</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MANET is a cooperative network in which nodes are responsible for forwarding
as well as routing. Noncooperation is still a big challenge that certainly
degrades the performance and reliability of a MANET. This paper presents a
novel methodology to overcome routing misbehavior in MANET using Retaliation
Model. In this model node misbehavior is watched and an equivalent misbehavior
is given in return. This model employs several parameters such as number of
packets forwarded, number of packets received for forwarding, packet forwarding
ratio etc. to calculate Grade and Bonus Points. The Grade is used to isolate
selfish nodes from the routing paths and the Bonus Points defines the number of
packets dropped by an honest node in retaliation over its misconducts. The
implementation is done in &quot;GloMoSim&quot; on top of the DSR protocol. We obtained up
to 40% packet delivery ratio with a cost of a minimum of 7.5% overhead compared
to DSR. To minimize total control traffic overhead we have included the FG
Model with our model and it reduces the overhead up to 75%. This model enforces
cooperation due to its stricter punishment strategy and justifies its name.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2233</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2233</id><created>2013-09-09</created><authors><author><keyname>G&#xf6;z&#xfc;pek</keyname><forenames>Didem</forenames></author><author><keyname>Alag&#xf6;z</keyname><forenames>Fatih</forenames></author></authors><title>A Fair Scheduling Model for Centralized Cognitive Radio Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate throughput maximizing, max-min fair, weighted max-min fair, and
proportionally fair scheduling problems for cognitive radio networks managed by
a centralized cognitive base station. We propose a very general scheduling
model accomplishing goals such as making frequency, time slot, and data rate
allocation to secondary users with possibly multiple antennas, in a
heterogenous multi-channel and multi-user scenario. Moreover, our schedulers
ensure that reliable communication between the cognitive base station and
secondary users are maintained, no collisions occur among secondary users, and
primary users in the service area of the cognitive base station are not
disturbed. Two distinctive features of our fair schedulers are that they
provide joint temporal and throughput fairness, and take throughput values
experienced by secondary users in the recent past, referred to as window size,
into account and use this information in the current scheduling decision. We
also propose a heuristic algorithm for our fair schedulers and demonstrate
through simulations that our proposed heuristic yields very close solutions to
the values obtained from the optimization softwares. Furthermore, we make
extensive simulations to evaluate our schedulers' performance in terms of both
total throughput and fairness for varying number of secondary users,
frequencies, antennas, and window size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2236</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2236</id><created>2013-09-09</created><authors><author><keyname>Bose</keyname><forenames>Subhonmesh</forenames></author><author><keyname>Bodine-Baron</keyname><forenames>Elizabeth</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author><author><keyname>Wierman</keyname><forenames>Adam</forenames></author></authors><title>The Cost of an Epidemic over a Complex Network: A Random Matrix Approach</title><categories>cs.SI physics.soc-ph</categories><comments>25 pages, 12 figures. Submitted to Informs Journal of Mathematics of
  Operations Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we quantify the total economic impact of an epidemic over a
complex network using tools from random matrix theory. Incorporating the direct
and indirect costs of infection, we calculate the disease cost in the large
graph limit for an SIS (Susceptible - Infected - Susceptible) infection
process. We also give an upper bound on this cost for arbitrary finite graphs
and illustrate both calculated costs using extensive simulations on random and
real-world networks. We extend these calculations by considering the total
social cost of an epidemic, accounting for both the immunization and disease
costs for various immunization strategies and determining the optimal
immunization. Our work focuses on the transient behavior of the epidemic, in
contrast to previous research, which typically focuses on determining the
steady-state system equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2238</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2238</id><created>2013-09-09</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Probability and the Classical/Quantum Divide</title><categories>quant-ph cs.IT math.IT</categories><comments>12 pages; 1 figure</comments><journal-ref>NeuroQuantology, vol. 11, pp. 600-606, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of distinguishing between classical and
quantum domains in macroscopic phenomena using tests based on probability and
it presents a condition on the ratios of the outcomes being the same (Ps) to
being different (Pn). Given three events, Ps/Pn for the classical case, where
there are no 3-way coincidences, is one-half whereas for the quantum state it
is one-third. For non-maximally entangled objects we find that so long as r &lt;
5.83, we can separate them from classical objects using a probability test. For
maximally entangled particles (r = 1), we propose that the value of 5/12 be
used for Ps/Pn to separate classical and quantum states when no other
information is available and measurements are noisy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2240</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2240</id><created>2013-09-09</created><authors><author><keyname>Schmitzer</keyname><forenames>Bernhard</forenames></author><author><keyname>Schn&#xf6;rr</keyname><forenames>Christoph</forenames></author></authors><title>Contour Manifolds and Optimal Transport</title><categories>math.DG cs.CV</categories><comments>33 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Describing shapes by suitable measures in object segmentation, as proposed in
[24], allows to combine the advantages of the representations as parametrized
contours and indicator functions. The pseudo-Riemannian structure of optimal
transport can be used to model shapes in ways similar as with contours, while
the Kantorovich functional enables the application of convex optimization
methods for global optimality of the segmentation functional.
  In this paper we provide a mathematical study of the shape measure
representation and its relation to the contour description. In particular we
show that the pseudo-Riemannian structure of optimal transport, when restricted
to the set of shape measures, yields a manifold which is diffeomorphic to the
manifold of closed contours. A discussion of the metric induced by optimal
transport and the corresponding geodesic equation is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2250</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2250</id><created>2013-09-09</created><authors><author><keyname>Chauhan</keyname><forenames>R. C. S.</forenames></author><author><keyname>Singh</keyname><forenames>Y. N.</forenames></author><author><keyname>Asthana</keyname><forenames>R.</forenames></author></authors><title>A Search Algorithm to Find Multiple Sets of One Dimensional Unipolar
  (Optical) Orthogonal Codes with Same Code-length and Low Weight</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a search algorithm to find multiple sets of one
dimensional unipolar (optical) orthogonal codes characterized by parameters,
binary code sequence of length (n bits) and weight w (number of bit 1s in the
sequence) as well as auto-correlation and cross-correlation constraint
respectively for the codes within a set. For a given code length n and code
weight w all possible difference sets, with auto-correlation constraints lying
from 1 to w-1 can be designed with distinct code serial number. For given
cross-correlation constraint from 1 to w-1 Multiple sets can be searched out of
the codes with auto-correlation constraints less than or equal to given
auto-correlation constraint using proposed algorithm. The searched multiple
sets can be sorted as having number of codes not less than the upper bound of
the sets given by Johnson bound. These one dimensional unipolar orthogonal
codes have their application in incoherent optical code division multiple
access systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2254</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2254</id><created>2013-09-09</created><authors><author><keyname>Chauhan</keyname><forenames>Ram Chandra Singh</forenames><affiliation>MIEEE</affiliation></author><author><keyname>Singh</keyname><forenames>Yatindra Nath</forenames><affiliation>SMIEEE</affiliation></author><author><keyname>Asthana</keyname><forenames>Rachna</forenames><affiliation>MIEEE</affiliation></author></authors><title>Design of Two Dimensional Unipolar (Optical) Orthogonal Codes Through
  One Dimensional Unipolar (Optical) Orthogonal Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an algorithm for construction of multiple sets of two
dimensional (2D) or matrix unipolar (optical) orthogonal codes has been
proposed. Representations of these 2D codes in difference of positions
representation (DoPR) have also been discussed along-with conventional weighted
positions representation (WPR) of the code. This paper also proposes less
complex methods for calculation of auto-correlation as well as
cross-correlation constraints within set of matrix codes. The multiple sets of
matrix codes provide flexibility for selection of optical orthogonal codes set
in wavelength-hopping time-spreading (WHTS) optical code division multiple
access (CDMA) system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2304</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2304</id><created>2013-09-09</created><authors><author><keyname>Wolper</keyname><forenames>James S.</forenames></author></authors><title>Information Theory and Moduli of Riemann Surfaces</title><categories>math.AG cs.IT math.IT</categories><comments>1 figure</comments><msc-class>14H42, 14A15, 94A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One interpretation of Torelli's Theorem, which asserts that a compact Riemann
Surface $X$ of genus $g &gt; 1$ is determined by the $g(g+1)/2$ entries of the
period matrix, is that the period matrix is a message about $X$. Since this
message depends on only $3g-3$ moduli, it is sparse, or at least approximately
so, in the sense of information theory. Thus, methods from information theory
may be useful in reconstructing the period matrix, and hence the Riemann
surface, from a small subset of the periods. The results here show that, with
high probability, any set of $3g-3$ periods form moduli for the surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2328</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2328</id><created>2013-09-09</created><authors><author><keyname>Serres</keyname><forenames>Olivier</forenames></author><author><keyname>Kayi</keyname><forenames>Abdullah</forenames></author><author><keyname>Anbar</keyname><forenames>Ahmad</forenames></author><author><keyname>El-Ghazawi</keyname><forenames>Tarek</forenames></author></authors><title>Hardware Support for Address Mapping in PGAS Languages; a UPC Case Study</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Partitioned Global Address Space (PGAS) programming model strikes a
balance between the locality-aware, but explicit, message-passing model and the
easy-to-use, but locality-agnostic, shared memory model. However, the PGAS rich
memory model comes at a performance cost which can hinder its potential for
scalability and performance. To contain this overhead and achieve full
performance, compiler optimizations may not be sufficient and manual
optimizations are typically added. This, however, can severely limit the
productivity advantage. Such optimizations are usually targeted at reducing
address translation overheads for shared data structures. This paper proposes a
hardware architectural support for PGAS, which allows the processor to
efficiently handle shared addresses. This eliminates the need for such
hand-tuning, while maintaining the performance and productivity of PGAS
languages. We propose to avail this hardware support to compilers by
introducing new instructions to efficiently access and traverse the PGAS memory
space. A prototype compiler is realized by extending the Berkeley Unified
Parallel C (UPC) compiler. It allows unmodified code to use the new
instructions without the user intervention, thereby creating a real productive
programming environment. Two implementations are realized: the first is
implemented using the full system simulator Gem5, which allows the evaluation
of the performance gain. The second is implemented using a softcore processor
Leon3 on an FPGA to verify the implementability and to parameterize the cost of
the new hardware and its instructions. The new instructions show promising
results for the NAS Parallel Benchmarks implemented in UPC. A speedup of up to
5.5x is demonstrated for unmodified and unoptimized codes. Unoptimized code
performance using this hardware was shown to also surpass the performance of
manually optimized code by up to 10%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2334</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2334</id><created>2013-09-09</created><authors><author><keyname>Almowuena</keyname><forenames>Saleh</forenames></author></authors><title>An Efficient Key Agreement Scheme for Wireless Sensor Networks Using
  Third Parties</title><categories>cs.CR cs.DC</categories><comments>15 pages, 6 figures</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.4, No.4, August 2013</journal-ref><doi>10.5121/ijasuc.2013.4401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contributes to the challenging field of security for wireless
sensor networks by introducing a key agreement scheme in which sensor nodes
create secure radio connections with their neighbours depending on the aid of
third parties. These third parties are responsible only for the pair-wise key
establishment among sensor nodes, so they do not observe the physical
phenomenon nor route data packets to other nodes. The proposed method is
explained here with respect to four important issues: how secret shares are
distributed, how local neighbours are discovered, how legitimate third parties
are verified, and how secure channels are established. Moreover, the
performance of the scheme is analyzed with regards to five metrics: local
connectivity, resistance to node capture, memory usage, communication overhead,
and computational burden. Our scheme not only secures the transmission channels
of nodes but also guarantees high local connectivity of the sensor network, low
usage of memory resources, perfect network resilience against node capture, and
complete prevention against impersonation attacks. As it is demonstrated in
this paper, using a number of third parties equals to 10% of the total number
of sensor nodes in the area of interest, the proposed method can achieve at
least 99.42% local connectivity with a very low usage of available storage
resources (less than 385 bits on each sensor node).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2339</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2339</id><created>2013-09-09</created><authors><author><keyname>Cata&#xf1;o</keyname><forenames>N&#xe9;stor</forenames></author><author><keyname>Rueda</keyname><forenames>Camilo</forenames></author><author><keyname>Wahls</keyname><forenames>Tim</forenames></author></authors><title>A Machine-Checked Proof for a Translation of Event-B Machines to JML</title><categories>cs.SE cs.LO cs.PL</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a machine-checked soundness proof of a translation of Event-B to
the Java Modeling Language (JML). The translation is based on an operator
EventB2Jml that maps Evnet-B events to JML method specifications, and
deterministic and non-deterministic assignments to JML method post-conditions.
This translation has previously been implemented as the EventB2Jml tool. We
adopted a taking our own medicine approach in the formalisation of our proof so
that Event-B as well as JML are formalised in Event-B and the proof is
discharged with the Rodin platform. Hence, for any Event-B substitution
(whether an event or an assignment) and for the JML method specification
obtained by applying EventB2Jml to the substitution, we prove that the
semantics of the JML method specification is simulated by the semantics of the
substitution. Therefore, the JML specification obtained as translation from the
Event-B substitution is a refinement of the substitution. Our proof includes
invariants and the standard Event-B initialising event, but it does not include
full machines or Event-B contexts. We assume that the semantics of JML and
Event-B operate both on the same initial and final states, and we justify our
assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2343</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2343</id><created>2013-09-09</created><authors><author><keyname>MolavianJazi</keyname><forenames>Ebrahim</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author></authors><title>A Finite-Blocklength Perspective on Gaussian Multi-Access Channels</title><categories>cs.IT math.IT</categories><comments>For submission to IEEE Trans. Information Theory, 43 pages, 1 Figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the growing application of wireless multi-access networks with
stringent delay constraints, we investigate the Gaussian multiple access
channel (MAC) in the finite blocklength regime. Building upon information
spectrum concepts, we develop several non-asymptotic inner bounds on channel
coding rates over the Gaussian MAC with a given finite blocklength, positive
average error probability, and maximal power constraints. Employing Central
Limit Theorem (CLT) approximations, we also obtain achievable second-order
coding rates for the Gaussian MAC based on an explicit expression for its
dispersion matrix. We observe that, unlike the pentagon shape of the asymptotic
capacity region, the second-order region has a curved shape with no sharp
corners.
  A main emphasis of the paper is to provide a new perspective on the procedure
of handling input cost constraints for tight achievability proofs. Contrary to
the complicated achievability techniques in the literature, we show that with a
proper choice of input distribution, tight bounds can be achieved via the
standard random coding argument and a modified typicality decoding. In
particular, we prove that codebooks generated randomly according to independent
uniform distributions on the respective &quot;power shells&quot; perform far better than
both independent and identically distributed (i.i.d.) Gaussian inputs and TDMA
with power control. Interestingly, analogous to an error exponent result of
Gallager, the resulting achievable region lies roughly halfway between that of
the i.i.d. Gaussian inputs and that of a hypothetical &quot;sum-power shell&quot; input.
However, dealing with such a non-i.i.d. input requires additional analysis such
as a new change of measure technique and application of a Berry-Esseen CLT for
functions of random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2348</identifier>
 <datestamp>2014-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2348</id><created>2013-09-09</created><updated>2014-06-29</updated><authors><author><keyname>AbdelGawad</keyname><forenames>Moez A.</forenames></author></authors><title>An Overview of Nominal-Typing versus Structural-Typing in
  Object-Oriented Programming (with code examples)</title><categories>cs.PL</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NOOP is a mathematical model of nominally-typed OOP that proves the
identification of inheritance and subtyping in mainstream nominally-typed OO
programming languages and the validity of this identification. This report
gives an overview of the main notions in OOP relevant to constructing a
mathematical model of OOP such as NOOP. The emphasis in this report is on
defining nominality, nominal typing and nominal subtyping of mainstream
nominally-typed OO languages, and on contrasting the three notions with their
counterparts in structurally-typed OO languages, i.e., with structurality,
structural typing and structural subtyping, respectively. An additional
appendix demonstrates these notions and other related notions, and the
differences between them, using some simple code examples. A detailed, more
technical comparison between nominal typing and structural typing in OOP is
presented in other publications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2350</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2350</id><created>2013-09-09</created><authors><author><keyname>Shahrampour</keyname><forenames>Shahin</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Exponentially Fast Parameter Estimation in Networks Using Distributed
  Dual Averaging</title><categories>cs.LG cs.SI math.OC stat.ML</categories><comments>6 pages, To appear in Conference on Decision and Control 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an optimization-based view of distributed parameter
estimation and observational social learning in networks. Agents receive a
sequence of random, independent and identically distributed (i.i.d.) signals,
each of which individually may not be informative about the underlying true
state, but the signals together are globally informative enough to make the
true state identifiable. Using an optimization-based characterization of
Bayesian learning as proximal stochastic gradient descent (with
Kullback-Leibler divergence from a prior as a proximal function), we show how
to efficiently use a distributed, online variant of Nesterov's dual averaging
method to solve the estimation with purely local information. When the true
state is globally identifiable, and the network is connected, we prove that
agents eventually learn the true parameter using a randomized gossip scheme. We
demonstrate that with high probability the convergence is exponentially fast
with a rate dependent on the KL divergence of observations under the true state
from observations under the second likeliest state. Furthermore, our work also
highlights the possibility of learning under continuous adaptation of network
which is a consequence of employing constant, unit stepsize for the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2351</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2351</id><created>2013-09-09</created><authors><author><keyname>Lopez-Pablos</keyname><forenames>Rodrigo</forenames><affiliation>Universidad Nacional de La Matanza y Universidad Tecnol&#xf3;gica Nacional</affiliation></author></authors><title>Elementos de ingenier\'ia de explotaci\'on de la informaci\'on aplicados
  a la investigaci\'on tributaria fiscal</title><categories>cs.AI</categories><comments>30 pages, 7 figures, written in Castilian, Artificial Intelligence
  (cs.AI), Computers and Society (cs.CY)</comments><acm-class>I.2.4; K.4.1</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  By introducing elements of information mining to tax analysis, by means of
data mining software and advanced computational concepts of artificial
intelligence, the problem of tax evader's crime against public property has
been addressed. Through an empirical approach from a hypothetical case of use,
induction algorithms, neural networks and bayesian networks are applied to
determine the feasibility of its heuristic application by the tax public
administrator. Different strategies are explored to facilitate the work of
local and regional federal tax inspectors, considering their limited
computational capabilities, but equally effective for those social scientist
committed to handcrafting tax research.
  -----
  Apresentando a introdu\c{c}\~ao de elementos de explora\c{c}\~ao de
informa\c{c}\~oes para an\'alise fiscal, por meio de software de
minera\c{c}\~ao de dados e conceitos avan\c{c}ados computacionais de
intelig\^encia artificial, foi abordado o problema do crime de sonegador fiscal
contra o patrim\^onio p\'ublico. Atrav\'es de uma abordagem emp\'irica a partir
de um caso hipot\'etico de uso, os algoritmos de indu\c{c}\~ao, redes neurais e
redes bayesianas s\~ao aplicados para determinar a viabilidade de sua
aplica\c{c}\~ao heur\'istica pelo administrador p\'ublico tribut\'ario.
Diferentes estrat\'egias s\~ao exploradas para facilitar o trabalho dos
inspectores tribut\'arios federais locais e regionais, tendo em conta as suas
capacidades computacionais limitados, mas igualmente eficaz para aqueles
cientista social comprometido com a investiga\c{c}\~ao fiscal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2355</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2355</id><created>2013-09-09</created><authors><author><keyname>Mackey</keyname><forenames>Kirsch N.</forenames></author><author><keyname>McCann</keyname><forenames>Roy A.</forenames></author></authors><title>An Optimal Load-Frequency Control Method for Inverter-Based Renewable
  Energy Transmission</title><categories>cs.SY</categories><comments>5 pages, 7 figures, IEEE Green Technologies Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The frequency droop response of conventional turbine driven synchronous
generators with respect to load increases is normally used in order to have
stable operating characteristics for multiple generators operating in parallel
over large geographical regions. This presents a challenge for renewable energy
sources that interface to the transmission grid through static inverters that
do not exhibit an intrinsic frequency droop characteristic. This paper provides
a technique for designing optimal load frequency controllers as transmission
line inverters fed from renewable energy sources that allows for fast dynamic
response due to variable solar and wind conditions while maintain stability to
interconnected synchronous generators. A control technique based on LQG
optimization theory is presented. Detailed analysis of a three-area system in a
region of mixed wind and solar photovoltaic sources is modeled in a manner that
confirms the effectiveness of the disclosed load-frequency control method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2357</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2357</id><created>2013-09-09</created><authors><author><keyname>Elster</keyname><forenames>Anne C.</forenames></author></authors><title>Software for Science: Some Personal Reflections</title><categories>cs.CY cs.DC</categories><comments>4-page draft for SC13 workshop WSSSPE</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  As computer systems become more and more complex, software and tools lag more
and more behind. This is especially true for scientific software that often
demands high performance, and thus needs to take advantage of parallelisms,
memory hierarchies and other software and systems. How do we help bridge this
ever-increasing gap?
  This paper describes some of my experiences and thoughts regarding licensing,
code sharing, code maintenance, open access publishing, and educations and
training. Details include my recent experiences with getting industrial funding
for GPL licensed software, BSD issues, sharing code on GitHub, and how I
inspire students to take my 4th year Parallel Computing elective which this
semester has over 50 students enrolled. Some thoughts and comments regarding
why both optimization and data locality are such a central issue for scientific
software is also included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2359</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2359</id><created>2013-09-09</created><authors><author><keyname>Ravi</keyname><forenames>Bolimera</forenames></author><author><keyname>Kumar</keyname><forenames>T. Kishore</forenames></author></authors><title>Speech Enhancement using Kernel and Normalized Kernel Affine Projection
  Algorithm</title><categories>cs.MM cs.SD</categories><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.4, No.4, August 2013</journal-ref><doi>10.5121/sipij.2013.4411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to investigate the speech signal enhancement using
Kernel Affine Projection Algorithm (KAPA) and Normalized KAPA. The removal of
background noise is very important in many applications like speech
recognition, telephone conversations, hearing aids, forensic, etc. Kernel
adaptive filters shown good performance for removal of noise. If the evaluation
of background noise is more slowly than the speech, i.e., noise signal is more
stationary than the speech, we can easily estimate the noise during the pauses
in speech. Otherwise it is more difficult to estimate the noise which results
in degradation of speech. In order to improve the quality and intelligibility
of speech, unlike time and frequency domains, we can process the signal in new
domain like Reproducing Kernel Hilbert Space (RKHS) for high dimensional to
yield more powerful nonlinear extensions. For experiments, we have used the
database of noisy speech corpus (NOIZEUS). From the results, we observed the
removal noise in RKHS has great performance in signal to noise ratio values in
comparison with conventional adaptive filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2371</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2371</id><created>2013-09-10</created><authors><author><keyname>Shrivastava</keyname><forenames>Arpna</forenames></author><author><keyname>Jain</keyname><forenames>R. C.</forenames></author></authors><title>Performance analysis of modified algorithm for finding multilevel
  association rules</title><categories>cs.DB</categories><journal-ref>Computer Science &amp; Engineering: An International Journal (CSEIJ),
  Vol. 3, No. 4, August 2013</journal-ref><doi>10.5121/cseij.2013.3401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multilevel association rules explore the concept hierarchy at multiple levels
which provides more specific information. Apriori algorithm explores the single
level association rules. Many implementations are available of Apriori
algorithm. Fast Apriori implementation is modified to develop new algorithm for
finding multilevel association rules. In this study the performance of this new
algorithm is analyzed in terms of running time in seconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2375</identifier>
 <datestamp>2013-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2375</id><created>2013-09-10</created><updated>2013-10-08</updated><authors><author><keyname>Shalev-Shwartz</keyname><forenames>Shai</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Accelerated Proximal Stochastic Dual Coordinate Ascent for Regularized
  Loss Minimization</title><categories>stat.ML cs.LG cs.NA stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a proximal version of the stochastic dual coordinate ascent
method and show how to accelerate the method using an inner-outer iteration
procedure. We analyze the runtime of the framework and obtain rates that
improve state-of-the-art results for various key machine learning optimization
problems including SVM, logistic regression, ridge regression, Lasso, and
multiclass SVM. Experiments validate our theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2387</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2387</id><created>2013-09-10</created><authors><author><keyname>Benmoussa</keyname><forenames>Yahia</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Boukhobza</keyname><forenames>Jalil</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Benazzouz</keyname><forenames>Djamel</forenames><affiliation>MSS</affiliation></author><author><keyname>Hadjadj-Aoul</keyname><forenames>Yassine</forenames><affiliation>INRIA - IRISA</affiliation></author></authors><title>DyPS: Dynamic Processor Switching for Energy-Aware Video Decoding on
  Multi-core SoCs</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>EWiLi, the Embedded Operating Systems Workshop, Toulouse : France
  (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In addition to General Purpose Processors (GPP), Multicore SoCs equipping
modern mobile devices contain specialized Digital Signal Processor designed
with the aim to provide better performance and low energy consumption
properties. However, the experimental measurements we have achieved revealed
that system overhead, in case of DSP video decoding, causes drastic
performances drop and energy efficiency as compared to the GPP decoding. This
paper describes DyPS, a new approach for energy-aware processor switching (GPP
or DSP) according to the video quality . We show the pertinence of our solution
in the context of adaptive video decoding and describe an implementation on an
embedded Linux operating system with the help of the GStreamer framework. A
simple case study showed that DyPS achieves 30% energy saving while sustaining
the decoding performance
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2388</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2388</id><created>2013-09-10</created><authors><author><keyname>Schmidt</keyname><forenames>Mark</forenames><affiliation>INRIA Paris - Rocquencourt, LIENS</affiliation></author><author><keyname>Roux</keyname><forenames>Nicolas Le</forenames><affiliation>INRIA Paris - Rocquencourt, LIENS</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Paris - Rocquencourt, LIENS</affiliation></author></authors><title>Minimizing Finite Sums with the Stochastic Average Gradient</title><categories>math.OC cs.LG stat.CO stat.ML</categories><comments>arXiv admin note: text overlap with arXiv:1202.6258</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the stochastic average gradient (SAG) method for optimizing the
sum of a finite number of smooth convex functions. Like stochastic gradient
(SG) methods, the SAG method's iteration cost is independent of the number of
terms in the sum. However, by incorporating a memory of previous gradient
values the SAG method achieves a faster convergence rate than black-box SG
methods. The convergence rate is improved from O(1/k^{1/2}) to O(1/k) in
general, and when the sum is strongly-convex the convergence rate is improved
from the sub-linear O(1/k) to a linear convergence rate of the form O(p^k) for
p &lt; 1. Further, in many cases the convergence rate of the new method is also
faster than black-box deterministic gradient methods, in terms of the number of
gradient evaluations. Numerical experiments indicate that the new algorithm
often dramatically outperforms existing SG and deterministic gradient methods,
and that the performance may be further improved through the use of non-uniform
sampling strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2394</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2394</id><created>2013-09-10</created><updated>2013-10-30</updated><authors><author><keyname>Avanzini</keyname><forenames>Martin</forenames><affiliation>University of Innsbruck, Austria</affiliation></author><author><keyname>Moser</keyname><forenames>Georg</forenames><affiliation>University of Innsbruck, Austria</affiliation></author></authors><title>Polynomial Path Orders</title><categories>cs.LO</categories><comments>LMCS version. This article supersedes arXiv:1209.3793</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 4 (November
  1, 2013) lmcs:807</journal-ref><doi>10.2168/LMCS-9(4:9)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the complexity analysis of constructor term
rewrite systems and its ramification in implicit computational complexity. We
introduce a path order with multiset status, the polynomial path order POP*,
that is applicable in two related, but distinct contexts. On the one hand POP*
induces polynomial innermost runtime complexity and hence may serve as a
syntactic, and fully automatable, method to analyse the innermost runtime
complexity of term rewrite systems. On the other hand POP* provides an
order-theoretic characterisation of the polytime computable functions: the
polytime computable functions are exactly the functions computable by an
orthogonal constructor TRS compatible with POP*.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2399</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2399</id><created>2013-09-10</created><authors><author><keyname>Chaplick</keyname><forenames>Steven</forenames></author><author><keyname>Fulek</keyname><forenames>Radoslav</forenames></author><author><keyname>Klav&#xed;k</keyname><forenames>Pavel</forenames></author></authors><title>Extending Partial Representations of Circle Graphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The partial representation extension problem is a recently introduced
generalization of the recognition problem. A circle graph is an intersection
graph of chords of a circle. We study the partial representation extension
problem for circle graphs, where the input consists of a graph G and a partial
representation R' giving some pre-drawn chords that represent an induced
subgraph of G. The question is whether one can extend R' to a representation R
of the entire G, i.e., whether one can draw the remaining chords into a
partially pre-drawn representation.
  Our main result is a polynomial-time algorithm for partial representation
extension of circle graphs. To show this, we describe the structure of all
representation a circle graph based on split decomposition. This can be of an
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2402</identifier>
 <datestamp>2014-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2402</id><created>2013-09-10</created><authors><author><keyname>Fan</keyname><forenames>Rui</forenames></author><author><keyname>Zhao</keyname><forenames>Jichang</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Anger is More Influential Than Joy: Sentiment Correlation in Weibo</title><categories>cs.SI physics.soc-ph</categories><journal-ref>PLoS ONE 9(10): e110184, 2014</journal-ref><doi>10.1371/journal.pone.0110184</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed the tremendous growth of the online social media.
In China, Weibo, a Twitter-like service, has attracted more than 500 million
users in less than four years. Connected by online social ties, different users
influence each other emotionally. We find the correlation of anger among users
is significantly higher than that of joy, which indicates that angry emotion
could spread more quickly and broadly in the network. While the correlation of
sadness is surprisingly low and highly fluctuated. Moreover, there is a
stronger sentiment correlation between a pair of users if they share more
interactions. And users with larger number of friends posses more significant
sentiment influence to their neighborhoods. Our findings could provide insights
for modeling sentiment influence and propagation in online social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2404</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2404</id><created>2013-09-10</created><authors><author><keyname>Pratiwi</keyname><forenames>Dian</forenames></author></authors><title>Implementation of Function Point Analysis in Measuring The Volume
  Estimation of Software System in Object Oriented and Structural Model of
  Academic System</title><categories>cs.SE</categories><comments>4 pages, 5 figures, 6 tables</comments><journal-ref>International Journal of Computer Applications (0975-8887), Volume
  70, No.10, May 2013</journal-ref><doi>10.5120/11995-7879</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the software development required a fidelity and accuracy in determining
the size or value of the software to fit the operation is executed. Various
methods of calculation has been widely applied to estimate the size, and one of
them is by using the method of Function Point Analysis (FPA). The method is
then applied by author to measure the complexity of an academic information
system by using the two modeling approaches, namely object oriented and
structural models. Measurements in this paper consists of several stages,
namely describing the information system that will be built into the UML models
and structured. Then the model is analyzed by calculating Crude Function Points
(CRP), Relative Complexity Adjustment Factor (RCAF), and then calculate its
function point. From the result of a calculation using the FPA to the academic
system software development, FP values of object oriented model obtained for
174,64 and the FP value of structured models for 180,93. The result of function
point that will be used by developers in determining the price and cost of
software systems to be built.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2409</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2409</id><created>2013-09-10</created><authors><author><keyname>Robinson-Garcia</keyname><forenames>Nicolas</forenames></author><author><keyname>Torres-Salinas</keyname><forenames>Daniel</forenames></author><author><keyname>Campanario</keyname><forenames>J. M.</forenames></author><author><keyname>L&#xf3;pez-C&#xf3;zar</keyname><forenames>Emilio Delgado</forenames></author></authors><title>Letter to the editor: Against the Resilience of Rejected Manuscripts</title><categories>cs.DL</categories><comments>This letter is accepted for publication in the Journal of the
  American Society for Information Science and Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter we propose the development of guidelines by the main editors
associations as well as protocols within online journal management systems for
keeping track of rejected manuscripts that are resubmitted as well as for the
interchange of referees reports between journals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2413</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2413</id><created>2013-09-10</created><authors><author><keyname>L&#xf3;pez-C&#xf3;zar</keyname><forenames>Emilio Delgado</forenames></author><author><keyname>Robinson-Garcia</keyname><forenames>Nicol&#xe1;s</forenames></author><author><keyname>Torres-Salinas</keyname><forenames>Daniel</forenames></author></authors><title>The Google Scholar Experiment: how to index false papers and manipulate
  bibliometric indicators</title><categories>cs.DL</categories><comments>This paper has been accepted for publication in the Journal of the
  American Society for Information Science and Technology. It is based on a
  previous working paper available at arXiv:1212.0638.pdf. arXiv admin note:
  substantial text overlap with arXiv:1212.0638</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Google Scholar has been well received by the research community. Its promises
of free, universal and easy access to scientific literature as well as the
perception that it covers better than other traditional multidisciplinary
databases the areas of the Social Sciences and the Humanities have contributed
to the quick expansion of Google Scholar Citations and Google Scholar Metrics:
two new bibliometric products that offer citation data at the individual level
and at journal level. In this paper we show the results of a experiment
undertaken to analyze Google Scholar's capacity to detect citation counting
manipulation. For this, six documents were uploaded to an institutional web
domain authored by a false researcher and referencing all the publications of
the members of the EC3 research group at the University of Granada. The
detection of Google Scholar of these papers outburst the citations included in
the Google Scholar Citations profiles of the authors. We discuss the effects of
such outburst and how it could affect the future development of such products
not only at individual level but also at journal level, especially if Google
Scholar persists with its lack of transparency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2422</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2422</id><created>2013-09-10</created><authors><author><keyname>Gehrke</keyname><forenames>Mai</forenames><affiliation>LIAFA</affiliation></author></authors><title>Stone duality, topological algebra, and recognition</title><categories>math.LO cs.FL cs.LO math.GN math.RA</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our main result is that any topological algebra based on a Boolean space is
the extended Stone dual space of a certain associated Boolean algebra with
additional operations. A particular case of this result is that the profinite
completion of any abstract algebra is the extended Stone dual space of the
Boolean algebra of recognizable subsets of the abstract algebra endowed with
certain residuation operations. These results identify a connection between
topological algebra as applied in algebra and Stone duality as applied in
logic, and show that the notion of recognition originating in computer science
is intrinsic to profinite completion in mathematics in general. This connection
underlies a number of recent results in automata theory including a
generalization of Eilenberg-Reiterman theory for regular languages and a new
notion of compact recognition applying beyond the setting of regular languages.
The purpose of this paper is to give the underlying duality theoretic result in
its general form. Further we illustrate the power of the result by providing a
few applications in topological algebra and language theory. In particular, we
give a simple proof of the fact that any topological algebra quotient of a
profinite algebra which is again based on a Boolean space is in fact a
profinite algebra and we derive the conditions dual to the ones of the original
Eilenberg theorem in a fully modular manner. We cast our results in the setting
of extended Priestley duality for distributive lattices with additional
operations as some classes of languages of interest in automata fail to be
closed under complementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2423</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2423</id><created>2013-09-10</created><updated>2013-09-26</updated><authors><author><keyname>Joseph</keyname><forenames>Anumol</forenames></author><author><keyname>Anusudha</keyname><forenames>K.</forenames></author></authors><title>Robust watermarking based on DWT SVD</title><categories>cs.MM cs.CR</categories><comments>paper has bee withdrawn by the author due to error in equation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital information revolution has brought about many advantages and new
issues. The protection of ownership and the prevention of unauthorized
manipulation of digital audio, image, and video materials has become an
important concern due to the ease of editing and perfect reproduction.
Watermarking is identified as a major means to achieve copyright protection. It
is a branch of information hiding which is used to hide proprietary information
in digital media like photographs, digital music, digital video etc. In this
paper, a new image watermarking algorithm that is robust against various
attacks is presented. DWT (Discrete Wavelet Transform) and SVD (Singular Value
Decomposition) have been used to embed two watermarks in the HL and LH bands of
the host image. Simulation evaluation demonstrates that the proposed technique
withstand various attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2426</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2426</id><created>2013-09-10</created><authors><author><keyname>Rai</keyname><forenames>Rashmi</forenames></author><author><keyname>Sahoo</keyname><forenames>G.</forenames></author><author><keyname>Mehfuz</keyname><forenames>S.</forenames></author></authors><title>Securing Software as a Service Model of Cloud Computing: Issues and
  Solutions</title><categories>cs.DC cs.CR</categories><journal-ref>International Journal on Cloud Computing: Services and
  Architecture (IJCCSA) ,Vol.3, No.4, August 2013</journal-ref><doi>10.5121/ijccsa.2013.3401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing, undoubtedly, has become the buzzword in the IT industry
today. Looking at the potential impact it has on numerous business applications
as well as in our everyday life, it can certainly be said that this disruptive
technology is here to stay. Many of the features that make cloud computing
attractive, have not just challenged the existing security system, but have
also revealed new security issues. This paper provides an insightful analysis
of the existing status on cloud computing security issues based on a detailed
survey carried by the author. It also makes an attempt to describe the security
challenges in Software as a Service (SaaS) model of cloud computing and also
endeavors to provide future security research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2434</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2434</id><created>2013-09-10</created><updated>2014-04-22</updated><authors><author><keyname>Kemman</keyname><forenames>Max</forenames></author><author><keyname>Kleppe</keyname><forenames>Martijn</forenames></author><author><keyname>Scagliola</keyname><forenames>Stef</forenames></author></authors><title>Just Google It - Digital Research Practices of Humanities Scholars</title><categories>cs.DL</categories><comments>Final publication Please cite as Kemman, Max, Martijn Kleppe and Stef
  Scagliola. 'Just Google It'. In: Clare Mills, Michael Pidd and Esther Ward.
  Proceedings of the Digital Humanities Congress 2012. Studies in the Digital
  Humanities. Sheffield: HRI Online Publications, 2014. Available online at:
  &lt;http://www.hrionline.ac.uk/openbook/chapter/dhc2012-kemman&gt;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transition from analogue to digital archives and the recent explosion of
online content offers researchers novel ways of engaging with data. The crucial
question for ensuring a balance between the supply and demand-side of data, is
whether this trend connects to existing scholarly practices and to the average
search skills of researchers. To gain insight into this process we conducted a
survey among nearly three hundred (N= 288) humanities scholars in the
Netherlands and Belgium with the aim of finding answers to the following
questions: 1) To what extent are digital databases and archives used? 2) What
are the preferences in search functionalities 3) Are there differences in
search strategies between novices and experts of information retrieval? Our
results show that while scholars actively engage in research online they mainly
search for text and images. General search systems such as Google and JSTOR are
predominant, while large-scale collections such as Europeana are rarely
consulted. Searching with keywords is the dominant search strategy and advanced
search options are rarely used. When comparing novice and more experienced
searchers, the first tend to have a more narrow selection of search engines,
and mostly use keywords. Our overall findings indicate that Google is the key
player among available search engines. This dominant use illustrates the
paradoxical attitude of scholars toward Google: while provenance and context
are deemed key academic requirements, the workings of the Google algorithm
remain unclear. We conclude that Google introduces a black box into digital
scholarly practices, indicating scholars will become increasingly dependent on
such black boxed algorithms. This calls for a reconsideration of the academic
principles of provenance and context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2444</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2444</id><created>2013-09-10</created><updated>2016-02-22</updated><authors><author><keyname>Guazzone</keyname><forenames>Marco</forenames></author><author><keyname>Anglano</keyname><forenames>Cosimo</forenames></author><author><keyname>Sereno</keyname><forenames>Matteo</forenames></author></authors><title>A Game-Theoretic Approach to Distributed Coalition Formation in
  Energy-Aware Cloud Federations (Extended Version)</title><categories>cs.DC cs.GT</categories><comments>Added publisher info and citation notice</comments><acm-class>C.2.4; K.6.4</acm-class><journal-ref>2014 14th IEEE/ACM International Symposium on Cluster, Cloud and
  Grid Computing (CCGrid), 2014, pp. 618-625</journal-ref><doi>10.1109/CCGrid.2014.37</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Federations among sets of Cloud Providers (CPs), whereby a set of CPs agree
to mutually use their own resources to run the VMs of other CPs, are considered
a promising solution to the problem of reducing the energy cost. In this paper,
we address the problem of federation formation for a set of CPs, whose solution
is necessary to exploit the potential of cloud federations for the reduction of
the energy bill. We devise a distributed algorithm, based on cooperative game
theory, that allows a set of CPs to cooperatively set up their federations in
such a way that their individual profit is increased with respect to the case
in which they work in isolation, and we show that, by using our algorithm and
the proposed CPs' utility function, they are able to self-organize into
Nash-stable federations and, by means of iterated executions, to adapt
themselves to environmental changes. Numerical results are presented to
demonstrate the effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2458</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2458</id><created>2013-09-10</created><authors><author><keyname>G</keyname><forenames>Karthik Reddy.</forenames><affiliation>Department of Electronics and Communication Engineering, G. Pulla Reddy Engineering college, Kurnool, A.P, India</affiliation></author></authors><title>Low power-area designs of 1bit full adder in cadence virtuoso platform</title><categories>cs.AR</categories><comments>10 pages</comments><journal-ref>International Journal of VLSI design &amp; Communication Systems
  (VLSICS) Vol.4, No.4,page no. 55-64, August 2013</journal-ref><doi>10.5121/vlsic.2013.4406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power consumption has emerged as a primary design constraint for integrated
circuits (ICs). In the Nano meter technology regime, leakage power has become a
major component of total power. Full adder is the basic functional unit of an
ALU. The power consumption of a processor is lowered by lowering the power
consumption of an ALU, and the power consumption of an ALU can be lowered by
lowering the power consumption of Full adder. So the full adder designs with
low power characteristics are becoming more popular these days. This proposed
work illustrates the design of the low-power less transistor full adder designs
using cadence tool and virtuoso platform, the entire simulations have been done
on 180nm single n-well CMOS bulk technology, in virtuoso platform of cadence
tool with the supply voltage 1.8V and frequency of 100MHz. These circuits
consume less power with maximum (6T design)of 93.1% power saving compare to
conventional 28T design and 80.2% power saving compare to SERF design without
much delay degradation. The proposed circuit exploits the advantage of GDI
technique and pass transistor logic
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2460</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2460</id><created>2013-09-10</created><authors><author><keyname>Kruschel</keyname><forenames>Christian</forenames></author><author><keyname>Lorenz</keyname><forenames>Dirk A.</forenames></author></authors><title>Computing and Analyzing Recoverable Supports for Sparse Reconstruction</title><categories>math.OC cs.CG math.CO</categories><msc-class>52B05, 94A12, 15A29</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing computational experiments involving $\ell_1$ minimization with
linear constraints in a finite-dimensional, real-valued space for receiving a
sparse solution with a precise number $k$ of nonzero entries is, in general,
difficult. Several conditions were introduced which guarantee that, for small
$k$ and for certain matrices, simply placing entries with desired
characteristics on a randomly chosen support will produce vectors which can be
recovered by $\ell_1$ minimization.
  In this work, we consider the case of large $k$ and propose both a
methodology to quickly check whether a given vector is recoverable, and to
construct vectors with the largest possible support. Moreover, we gain new
insights in the recoverability in a non-asymptotic regime. The theoretical
results are illustrated with computational experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2471</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2471</id><created>2013-09-10</created><authors><author><keyname>Singh</keyname><forenames>Harinder</forenames></author><author><keyname>Kumar</keyname><forenames>Parteek</forenames></author></authors><title>Implementation of nlization framework for verbs, pronouns and
  determiners with eugene</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UNL system is designed and implemented by a nonprofit organization, UNDL
Foundation at Geneva in 1999. UNL applications are application softwares that
allow end users to accomplish natural language tasks, such as translating,
summarizing, retrieving or extracting information, etc. Two major web based
application softwares are Interactive ANalyzer (IAN), which is a natural
language analysis system. It represents natural language sentences as semantic
networks in the UNL format. Other application software is dEep-to-sUrface
GENErator (EUGENE), which is an open-source interactive NLizer. It generates
natural language sentences out of semantic networks represented in the UNL
format. In this paper, NLization framework with EUGENE is focused, while using
UNL system for accomplishing the task of machine translation. In whole
NLization process, EUGENE takes a UNL input and delivers an output in natural
language without any human intervention. It is language-independent and has to
be parametrized to the natural language input through a dictionary and a
grammar, provided as separate interpretable files. In this paper, it is
explained that how UNL input is syntactically and semantically analyzed with
the UNL-NL T-Grammar for NLization of UNL sentences involving verbs, pronouns
and determiners for Punjabi natural language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2473</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2473</id><created>2013-09-10</created><authors><author><keyname>Ganesan</keyname><forenames>Abhinav</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Interference Alignment with Diversity for the $2 \times 2$ $X$-Network
  with three antennas</title><categories>cs.IT math.IT</categories><comments>11 pages, 3 figures. arXiv admin note: substantial text overlap with
  arXiv:1304.1432</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment is known to achieve the maximum sum DoF of
$\frac{4M}{3}$ in the $2 \times 2$ $X$-Network (i.e., two-transmitter (Tx)
two-receiver (Rx) $X$-Network) with $M$ antennas at each node, as demonstrated
by Jafar and Shamai. Recently, an Alamouti code based transmission scheme,
which we call the Li-Jafarkhani-Jafar (LJJ) scheme, was proposed for the $2
\times 2$ $X$-Network with two antennas at each node. This scheme achieves a
sum degrees of freedom (DoF) of $\frac{8}{3}$ and also a diversity gain of two
when fixed finite constellations are employed at each Tx. In the LJJ scheme,
each Tx required the knowledge of only its own channel unlike the Jafar-Shamai
scheme which required global CSIT to achieve the maximum possible sum DoF of
$\frac{8}{3}$. Bit error rate (BER) is an important performance metric when the
coding length is finite. This work first proposes a new STBC for a three
transmit antenna single user MIMO system. Building on this STBC, we extend the
LJJ scheme to the $2 \times 2$ $X$-Network with three antennas at each node.
Local channel knowledge is assumed at each Tx. It is shown that the proposed
scheme achieves the maximum possible sum DoF of 4. A diversity gain of 3 is
also guaranteed when fixed finite constellation inputs are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2476</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2476</id><created>2013-09-10</created><authors><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Patel</keyname><forenames>Sangita</forenames></author><author><keyname>Dash</keyname><forenames>Shiba Prasad</forenames></author><author><keyname>Sharma</keyname><forenames>Burle</forenames></author></authors><title>TRANS outperforms MTF for two special types of request sequences without
  locality of reference</title><categories>cs.DS</categories><comments>9 Pages, Proceedings of International Conference on Communication,
  Computing and Security (ICCCS)-2012, India.
  http://www.sciencedirect.com/science/article/pii/S2212017312006123</comments><journal-ref>Procedia Technology, Elsevier, Vol 6, pages 556-563, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various list accessing algorithms have been proposed in the literature and
their performances have been analyzed theoretically and experimentally.
Move-To-Front (MTF) and Transpose (TRANS) are two well known primitive list
accessing algorithms. MTF has been proved to be the best performing online
algorithm till date in the literature for real life inputs and practical
applications with locality of reference. It has been shown that when storage
space is extremely limited and pointers for lists cannot be used, then array
implementation of TRANS gives efficient reorganization. Use of MTF is extensive
in the literature whereas, the use of TRANS is rare. As mentioned as an open
problem in literature, direct bounds on the behavior and performance of various
list accessing algorithms are needed to allow realistic comparisons. Since it
has been shown that no single optimal permutation algorithm exists, it becomes
necessary to characterize the circumstances that indicate the advantage in
using a particular list accessing algorithm. Motivated by above challenging
research issue, in this paper we have made an analytical study for evaluating
the performance of TRANS list accessing algorithm using two special types of
request sequences without locality of reference. We have compared the
performance of TRANS with MTF and observed that TRANS outperforms MTF for these
considered types of request sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2485</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2485</id><created>2013-09-10</created><authors><author><keyname>Kordon</keyname><forenames>Fabrice</forenames></author><author><keyname>Linard</keyname><forenames>Alban</forenames></author><author><keyname>Beccuti</keyname><forenames>Marco</forenames></author><author><keyname>Buchs</keyname><forenames>Didier</forenames></author><author><keyname>Fronc</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Hillah</keyname><forenames>Lom-Messan</forenames></author><author><keyname>Hulin-Hubard</keyname><forenames>Francis</forenames></author><author><keyname>Legond-Aubry</keyname><forenames>Fabrice</forenames></author><author><keyname>Lohmann</keyname><forenames>Niels</forenames></author><author><keyname>Marechal</keyname><forenames>Alexis</forenames></author><author><keyname>Paviot-Adet</keyname><forenames>Emmanuel</forenames></author><author><keyname>Pommereau</keyname><forenames>Franck</forenames></author><author><keyname>Rodr&#xed;guez</keyname><forenames>C&#xe9;sar</forenames></author><author><keyname>Rohr</keyname><forenames>Christian</forenames></author><author><keyname>Thierry-Mieg</keyname><forenames>Yann</forenames></author><author><keyname>Wimmel</keyname><forenames>Harro</forenames></author><author><keyname>Wolf</keyname><forenames>Karsten</forenames></author></authors><title>Model Checking Contest @ Petri Nets, Report on the 2013 edition</title><categories>cs.SE</categories><comments>one main report (422 pages) and two annexes (1386 and 1740 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document presents the results of the Model Checking Contest held at
Petri Nets 2013 in Milano. This contest aimed at a fair and experimental
evaluation of the performances of model checking techniques applied to Petri
nets. This is the third edition after two successful editions in 2011 and 2012.
  The participating tools were compared on several examinations (state space
generation and evaluation of several types of formul{\ae} -- reachability, LTL,
CTL for various classes of atomic propositions) run on a set of common models
(Place/Transition and Symmetric Petri nets).
  After a short overview of the contest, this paper provides the raw results
from the contest, model per model and examination per examination. An HTML
version of this report is also provided (http://mcc.lip6.fr).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2486</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2486</id><created>2013-09-10</created><authors><author><keyname>Ding</keyname><forenames>Ying</forenames></author><author><keyname>Song</keyname><forenames>Min</forenames></author><author><keyname>Han</keyname><forenames>Jia</forenames></author><author><keyname>Yu</keyname><forenames>Qi</forenames></author><author><keyname>Yan</keyname><forenames>Erjia</forenames></author><author><keyname>Lin</keyname><forenames>Lili</forenames></author><author><keyname>Chambers</keyname><forenames>Tamy</forenames></author></authors><title>Entitymetrics: Measuring the Impact of Entities</title><categories>cs.DL</categories><journal-ref>PLOS ONE 8(8): e71416, 2013</journal-ref><doi>10.1371/journal.pone.0071416</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes entitymetrics to measure the impact of knowledge units.
Entitymetrics highlight the importance of entities embedded in scientific
literature for further knowledge discovery. In this paper, we use Metformin, a
drug for diabetes, as an example to form an entity-entity citation network
based on literature related to Metformin. We then calculate the network
features and compare the centrality ranks of biological entities with results
from Comparative Toxicogenomics Database (CTD). The comparison demonstrates the
usefulness of entitymetrics to detect most of the outstanding interactions
manually curated in CTD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2489</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2489</id><created>2013-09-10</created><updated>2015-04-02</updated><authors><author><keyname>Diertens</keyname><forenames>Bob</forenames></author></authors><title>Refinement in the Function-Behaviour-Structure Framework</title><categories>cs.SE</categories><report-no>tcs1301v2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce refinement in the function-behaviour-structure framework for
design, as described by John Gero, in order to deal with complexity. We do this
by connecting the frameworks for the design of two models, one the refinement
of the other. The result is a framework for the design of an object that
supports levels of abstraction in the design. This framework can easily be
extended for the design of an object on more than two levels of abstraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2502</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2502</id><created>2013-09-10</created><updated>2013-12-26</updated><authors><author><keyname>Simonetto</keyname><forenames>Andrea</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Distributed Maximum Likelihood Sensor Network Localization</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2014.2302746</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a class of convex relaxations to solve the sensor network
localization problem, based on a maximum likelihood (ML) formulation. This
class, as well as the tightness of the relaxations, depends on the noise
probability density function (PDF) of the collected measurements. We derive a
computational efficient edge-based version of this ML convex relaxation class
and we design a distributed algorithm that enables the sensor nodes to solve
these edge-based convex programs locally by communicating only with their close
neighbors. This algorithm relies on the alternating direction method of
multipliers (ADMM), it converges to the centralized solution, it can run
asynchronously, and it is computation error-resilient. Finally, we compare our
proposed distributed scheme with other available methods, both analytically and
numerically, and we argue the added value of ADMM, especially for large-scale
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2505</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2505</id><created>2013-09-10</created><authors><author><keyname>Gishkori</keyname><forenames>Shahzad</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author></authors><title>Compressed Sensing for Block-Sparse Smooth Signals</title><categories>stat.ML cs.IT math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present reconstruction algorithms for smooth signals with block sparsity
from their compressed measurements. We tackle the issue of varying group size
via group-sparse least absolute shrinkage selection operator (LASSO) as well as
via latent group LASSO regularizations. We achieve smoothness in the signal via
fusion. We develop low-complexity solvers for our proposed formulations through
the alternating direction method of multipliers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2506</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2506</id><created>2013-09-10</created><authors><author><keyname>Maqqor</keyname><forenames>Ahlam</forenames></author><author><keyname>Halli</keyname><forenames>Akram</forenames></author><author><keyname>Satori</keyname><forenames>Khaled</forenames></author></authors><title>A multi-stream hmm approach to offline handwritten arabic word
  recognition</title><categories>cs.CV</categories><comments>12 pages,13 figure,International Journal on Natural Language
  Computing(IJNLC),ISSN:2278-1307[Online];2319-4111[Print],August 2013, Volume
  2, Number 4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In This paper we presented new approach for cursive Arabic text recognition
system. The objective is to propose methodology analytical offline recognition
of handwritten Arabic for rapid implementation. The first part in the writing
recognition system is the preprocessing phase is the preprocessing phase to
prepare the data was introduces and extracts a set of simple statistical
features by two methods : from a window which is sliding long that text line
the right to left and the approach VH2D (consists in projecting every character
on the abscissa, on the ordinate and the diagonals 45{\deg} and 135{\deg}) . It
then injects the resulting feature vectors to Hidden Markov Model (HMM) and
combined the two HMM by multi-stream approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2511</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2511</id><created>2013-09-10</created><authors><author><keyname>Darulova</keyname><forenames>Eva</forenames></author><author><keyname>Kuncak</keyname><forenames>Viktor</forenames></author></authors><title>On Sound Compilation of Reals</title><categories>cs.PL</categories><report-no>EPFL-REPORT-187498</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Writing accurate numerical software is hard because of many sources of
unavoidable uncertainties, including finite numerical precision of
implementations. We present a programming model where the user writes a program
in a real-valued implementation and specification language that explicitly
includes different types of uncertainties. We then present a compilation
algorithm that generates a conventional implementation that is guaranteed to
meet the desired precision with respect to real numbers. Our verification step
generates verification conditions that treat different uncertainties in a
unified way and encode reasoning about floating-point roundoff errors into
reasoning about real numbers. Such verification conditions can be used as a
standardized format for verifying the precision and the correctness of
numerical programs. Due to their often non-linear nature, precise reasoning
about such verification conditions remains difficult. We show that current
state-of-the art SMT solvers do not scale well to solving such verification
conditions. We propose a new procedure that combines exact SMT solving over
reals with approximate and sound affine and interval arithmetic. We show that
this approach overcomes scalability limitations of SMT solvers while providing
improved precision over affine and interval arithmetic. Using our initial
implementation we show the usefullness and effectiveness of our approach on
several examples, including those containing non-linear computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2512</identifier>
 <datestamp>2014-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2512</id><created>2013-09-10</created><updated>2014-04-09</updated><authors><author><keyname>Audrito</keyname><forenames>Giorgio</forenames></author><author><keyname>Tomescu</keyname><forenames>Alexandru I.</forenames></author><author><keyname>Wagner</keyname><forenames>Stephan</forenames></author></authors><title>Enumeration of the adjunctive hierarchy of hereditarily finite sets</title><categories>cs.LO math.CO</categories><msc-class>03E20, 05A99, 03E05</msc-class><acm-class>F.4.1; G.2.1</acm-class><doi>10.1093/logcom/exu062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hereditarily finite sets (sets which are finite and have only hereditarily
finite sets as members) are basic mathematical and computational objects, and
also stand at the basis of some programming languages. This raises the need for
efficient representation of such sets, for example by numbers. In 2008, Kirby
proposed an adjunctive hierarchy of hereditarily finite sets, based on the fact
that they can also be seen as built up from the empty set by repeated
adjunction, that is, by the addition of a new single element drawn from the
already existing sets to an already existing set. Determining the cardinality
$a_n$ of each level of this hierarchy, problem crucial in establishing whether
the natural adjunctive hierarchy leads to an efficient encoding by numbers, was
left open.
  In this paper we solve this problem. Our results can be generalized to
hereditarily finite sets with atoms, or can be further refined by imposing
restrictions on rank, on cardinality, or on the maximum level from where the
new adjoined element can be drawn. We also show that $a_n$ satisfies the
asymptotic formula $a_n = C^{2^n} + O(C^{2^{n-1}})$, for a constant $C \approx
1.3399$, which is a too fast asymptotic growth for practical purposes. We thus
propose a very natural variant of the adjunctive hierarchy, whose asymptotic
behavior we prove to be $\Theta(2^n)$. To our knowledge, this is the first
result of this kind.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2517</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2517</id><created>2013-09-10</created><authors><author><keyname>Vishwanath</keyname><forenames>R. H.</forenames></author><author><keyname>Leena</keyname><forenames>S.</forenames></author><author><keyname>Srikantaiah</keyname><forenames>K. C.</forenames></author><author><keyname>Kumar</keyname><forenames>K. Shreekrishna</forenames></author><author><keyname>Shenoy</keyname><forenames>P. Deepa</forenames></author><author><keyname>Venugopal</keyname><forenames>K. R.</forenames></author><author><keyname>Iyengar</keyname><forenames>S. S.</forenames></author><author><keyname>Patnaik</keyname><forenames>L. M.</forenames></author></authors><title>Forecasting Stock Time-Series using Data Approximation and Pattern
  Sequence Similarity</title><categories>cs.DB</categories><comments>11 pages</comments><journal-ref>International Journal of Information Processing, 7(2), 90-100,
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time series analysis is the process of building a model using statistical
techniques to represent characteristics of time series data. Processing and
forecasting huge time series data is a challenging task. This paper presents
Approximation and Prediction of Stock Time-series data (APST), which is a two
step approach to predict the direction of change of stock price indices. First,
performs data approximation by using the technique called Multilevel Segment
Mean (MSM). In second phase, prediction is performed for the approximated data
using Euclidian distance and Nearest-Neighbour technique. The computational
cost of data approximation is O(n ni) and computational cost of prediction task
is O(m |NN|). Thus, the accuracy and the time required for prediction in the
proposed method is comparatively efficient than the existing Label Based
Forecasting (LBF) method [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2525</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2525</id><created>2013-09-10</created><updated>2013-10-29</updated><authors><author><keyname>Mehta</keyname><forenames>Rahul</forenames></author></authors><title>Max-Flows on Sparse and Dense Networks</title><categories>cs.DS</categories><comments>This paper has been withdrawn due to issues relating to nonsaturating
  pushes and the validity of the labeling. A slightly modified result is
  contained in the paper &quot;A New Push-Relabel Algorithm for the Max-Flow
  Problem&quot;</comments><msc-class>05C21, 68R10</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an improved algorithm for the maximum flow problem
on general networks with $n$ vertices and $m$ arcs. We show how to solve the
problem in $O(mn)$ time, when $m = O(n^{2-\epsilon})$, for some $0 &lt;\epsilon
\leq 1$. This improves upon the results of both Orlin and King, et. al., who
solved the problem in $O(mn + m^{31/16} \log^2 n)$ and $O(mn\log_{m/n\log n}n)$
time, respectively. Our main result is reducing the number of nonsaturating
pushes to $O(mn)$ across all scaling phases. Our algorithm can be seen as
complementary to King, et. al., in the sense that we solve the max-flow problem
in $O(mn)$ time when $m = O(n^{2-\epsilon})$ (all sparse and non-dense
networks), whereas King, et. al. solve it in $O(mn)$ time when $m =
\Omega(n^{1+\epsilon})$ (all dense and non-sparse networks).
  Our improvement is reached by a novel combination of Ahuja and Orlin's excess
scaling method and Orlin's compact flow networks. To our knowledge, this is the
first $O(mn)$ time max-flow algorithm that runs on this range of networks.
Further, we extend the range of Orlin's $O(mn)$ time algorithm from
$O(n^{16/15-\epsilon})$ to $O(n^{2-\epsilon})$, which is an improvement of
approximately $O(n^{0.94})$. Our result also establishes that the problem can
be solved for all $n$ and $m$ using exclusively the push-relabel method. We
also give improved algorithms for parametric flows and efficiently constructing
Gomory-Hu trees, and suggest a new approach to the minimum-cost flow problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2529</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2529</id><created>2013-09-10</created><authors><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Syrgkanis</keyname><forenames>Vasilis</forenames></author></authors><title>Limits of Efficiency in Sequential Auctions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the efficiency of sequential first-price item auctions at (subgame
perfect) equilibrium. This auction format has recently attracted much
attention, with previous work establishing positive results for unit-demand
valuations and negative results for submodular valuations. This leaves a large
gap in our understanding between these valuation classes. In this work we
resolve this gap on the negative side. In particular, we show that even in the
very restricted case in which each bidder has either an additive valuation or a
unit-demand valuation, there exist instances in which the inefficiency at
equilibrium grows linearly with the minimum of the number of items and the
number of bidders. Moreover, these inefficient equilibria persist even under
iterated elimination of weakly dominated strategies. Our main result implies
linear inefficiency for many natural settings, including auctions with gross
substitute valuations, capacitated valuations, budget-additive valuations, and
additive valuations with hard budget constraints on the payments. Another
implication is that the inefficiency in sequential auctions is driven by the
maximum number of items contained in any player's optimal set, and this is
tight. For capacitated valuations, our results imply a lower bound that equals
the maximum capacity of any bidder, which is tight following the upper-bound
technique established by Paes Leme et al. \cite{PaesLeme2012}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2533</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2533</id><created>2013-09-10</created><authors><author><keyname>Benmoussa</keyname><forenames>Yahia</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Boukhobza</keyname><forenames>Jalil</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Senn</keyname><forenames>Eric</forenames><affiliation>Lab-STICC</affiliation></author><author><keyname>Benazzouz</keyname><forenames>Djamel</forenames><affiliation>MSS</affiliation></author></authors><title>Evaluation of the Performance/Energy Overhead in DSP Video Decoding and
  its Implications</title><categories>cs.AR cs.MM</categories><proxy>ccsd</proxy><journal-ref>Annual Metting of the GDR SoC SiP, Lyon : France (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video decoding is considered as one of the most compute and energy intensive
application in energy constrained mobile devices. Some specific processing
units, such as DSPs, are added to those devices in order to optimize the
performance and the energy consumption. However, in DSP video decoding, the
inter-processor communication overhead may have a considerable impact on the
performance and the energy consumption. In this paper, we propose to evaluate
this overhead and analyse its impact on the performance and the energy
consumption as compared to the GPP decoding. Our work revealed that the GPP can
be the best choice in many cases due to the a significant overhead in DSP
decoding which may represents 30% of the total decoding energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2543</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2543</id><created>2013-09-10</created><authors><author><keyname>Deb</keyname><forenames>Supratim</forenames></author><author><keyname>Monogioudis</keyname><forenames>Pantelis</forenames></author></authors><title>Learning Based Uplink Interference Management in 4G LTE Cellular Systems</title><categories>cs.NI</categories><comments>Submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LTEs uplink (UL) efficiency critically depends on how the interference across
different cells is controlled. The unique characteristics of LTEs modulation
and UL resource assignment poses considerable challenges in achieving this goal
because most LTE deployments have 1:1 frequency re-use, and the uplink
interference can vary considerably across successive time slots. In this work,
we propose LeAP, a measurement data driven machine learning paradigm for power
control to manage up-link interference in LTE. The data driven approach has the
inherent advantage that the solution adapts based on network traffic,
propagation and network topology, that is increasingly heterogeneous with
multiple cell-overlays. LeAP system design consists of the following
components: (i) design of user equipment (UE) measurement statistics that are
succinct, yet expressive enough to capture the network dynamics, and (ii)
design of two learning based algorithms that use the reported measurements to
set the power control parameters and optimize the network performance. LeAP is
standards compliant and can be implemented in centralized SON (self organized
networking) server resource (cloud). We perform extensive evaluations using
radio network plans from real LTE network operational in a major metro area in
United States. Our results show that, compared to existing approaches, LeAP
provides a 4.9x gain in the 20th percentile of user data rate, and 3.25x gain
in median data rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2546</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2546</id><created>2013-09-10</created><authors><author><keyname>Yan</keyname><forenames>Erjia</forenames></author></authors><title>Finding knowledge paths among scientific disciplines</title><categories>cs.DL</categories><comments>31 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discovers patterns of knowledge dissemination among scientific
disciplines. While the transfer of knowledge is largely unobservable, citations
from one discipline to another have been proven to be an effective proxy to
study disciplinary knowledge flow. This study constructs a knowledge flow
network in that a node represents a Journal Citation Report subject category
and a link denotes the citations from one subject category to another. Using
the concept of shortest path, several quantitative measurements are proposed
and applied to a knowledge flow network. Based on an examination of subject
categories in Journal Citation Report, this paper finds that social science
domains tend to be more self-contained and thus it is more difficult for
knowledge from other domains to flow into them; at the same time, knowledge
from science domains, such as biomedicine-, chemistry-, and physics-related
domains can access and be accessed by other domains more easily. This paper
also finds that social science domains are more disunified than science
domains, as three fifths of the knowledge paths from one social science domain
to another need at least one science domain to serve as an intermediate. This
paper contributes to discussions on disciplinarity and interdisciplinarity by
providing empirical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2558</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2558</id><created>2013-09-10</created><authors><author><keyname>Forni</keyname><forenames>Fulvio</forenames></author><author><keyname>Sepulchre</keyname><forenames>Rodolphe</forenames></author><author><keyname>van der Schaft</keyname><forenames>Arjan</forenames></author></authors><title>On differential passivity of physical systems</title><categories>cs.SY math.DS</categories><comments>52nd IEEE Conference on Decision and Control, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential passivity is a property that allows to check with a pointwise
criterion that a system is incrementally passive, a property that is relevant
to study interconnected systems in the context of regulation, synchronization,
and estimation. The paper investigates how restrictive is the property,
focusing on a class of open gradient systems encountered in the coenergy
modeling framework of physical systems, in particular the Brayton-Moser
formalism for nonlinear electrical circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2574</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2574</id><created>2013-09-09</created><authors><author><keyname>Shi</keyname><forenames>Guodong</forenames></author><author><keyname>Proutiere</keyname><forenames>Alexandre</forenames></author><author><keyname>Johansson</keyname><forenames>Mikael</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author></authors><title>Randomized Consensus with Attractive and Repulsive Links</title><categories>cs.SY cs.MA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study convergence properties of a randomized consensus algorithm over a
graph with both attractive and repulsive links. At each time instant, a node is
randomly selected to interact with a random neighbor. Depending on if the link
between the two nodes belongs to a given subgraph of attractive or repulsive
links, the node update follows a standard attractive weighted average or a
repulsive weighted average, respectively. The repulsive update has the opposite
sign of the standard consensus update. In this way, it counteracts the
consensus formation and can be seen as a model of link faults or malicious
attacks in a communication network, or the impact of trust and antagonism in a
social network. Various probabilistic convergence and divergence conditions are
established. A threshold condition for the strength of the repulsive action is
given for convergence in expectation: when the repulsive weight crosses this
threshold value, the algorithm transits from convergence to divergence. An
explicit value of the threshold is derived for classes of attractive and
repulsive graphs. The results show that a single repulsive link can sometimes
drastically change the behavior of the consensus algorithm. They also
explicitly show how the robustness of the consensus algorithm depends on the
size and other properties of the graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2593</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2593</id><created>2013-09-10</created><authors><author><keyname>Kumar</keyname><forenames>K. S. Sesh</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Maximizing submodular functions using probabilistic graphical models</title><categories>cs.LG math.OC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximizing submodular functions; while this
problem is known to be NP-hard, several numerically efficient local search
techniques with approximation guarantees are available. In this paper, we
propose a novel convex relaxation which is based on the relationship between
submodular functions, entropies and probabilistic graphical models. In a
graphical model, the entropy of the joint distribution decomposes as a sum of
marginal entropies of subsets of variables; moreover, for any distribution, the
entropy of the closest distribution factorizing in the graphical model provides
an bound on the entropy. For directed graphical models, this last property
turns out to be a direct consequence of the submodularity of the entropy
function, and allows the generalization of graphical-model-based upper bounds
to any submodular functions. These upper bounds may then be jointly maximized
with respect to a set, while minimized with respect to the graph, leading to a
convex variational inference scheme for maximizing submodular functions, based
on outer approximations of the marginal polytope and maximum likelihood bounded
treewidth structures. By considering graphs of increasing treewidths, we may
then explore the trade-off between computational complexity and tightness of
the relaxation. We also present extensions to constrained problems and
maximizing the difference of submodular functions, which include all possible
set functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2597</identifier>
 <datestamp>2013-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2597</id><created>2013-09-10</created><authors><author><keyname>Venkateswarlu</keyname><forenames>Bondu</forenames></author><author><keyname>Raju</keyname><forenames>Prof G. S. V. Prasad</forenames></author></authors><title>Mine Blood Donors Information through Improved K-Means Clustering</title><categories>cs.DB</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of accidents and health diseases which are increasing at an
alarming rate are resulting in a huge increase in the demand for blood. There
is a necessity for the organized analysis of the blood donor database or blood
banks repositories. Clustering analysis is one of the data mining applications
and K-means clustering algorithm is the fundamental algorithm for modern
clustering techniques. K-means clustering algorithm is traditional approach and
iterative algorithm. At every iteration, it attempts to find the distance from
the centroid of each cluster to each and every data point. This paper gives the
improvement to the original k-means algorithm by improving the initial
centroids with distribution of data. Results and discussions show that improved
K-means algorithm produces accurate clusters in less computation time to find
the donors information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2643</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2643</id><created>2013-09-10</created><authors><author><keyname>Brassard</keyname><forenames>Gilles</forenames></author><author><keyname>Tapp</keyname><forenames>Alain</forenames></author><author><keyname>Touchette</keyname><forenames>Dave</forenames></author></authors><title>Noisy Interactive Quantum Communication</title><categories>quant-ph cs.IT math.IT</categories><comments>49 pages, no figures</comments><acm-class>E.4; F.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of simulating protocols in a quantum communication
setting over noisy channels. This problem falls at the intersection of quantum
information theory and quantum communication complexity, and is of particular
importance for real-world applications of interactive quantum protocols, which
can be proved to have exponentially lower communication costs than their
classical counterparts for some problems. To the best of our knowledge, these
are the first results regarding the quantum version of this problem, first
studied by Schulman in a classical setting (FOCS '92, STOC '93). We simulate a
length N quantum communication protocol by a length O(N) protocol. Our
simulation strategy has a far higher communication rate than the naive one that
encodes each particular round of communication to achieve comparable success.
In particular, such a strategy would have a communication rate going to 0 in
the worst interaction case as the length of the protocols increases, in
contrast to our strategy, which has a communication rate proportional to the
capacity of the channel used. Under adversarial noise, our strategy can
withstand error rates up to 1/2 when parties preshare perfect entanglement, and
this even if they are only allowed noisy classical communication. We show that
this is optimal. This is in contrast to the case of the naive strategy, which
would not work for any constant fraction of errors in this model. When the
parties do not preshare entanglement, we show how to tolerate adversarial error
rates close to the maximum tolerable for one-way quantum data transmission. In
a random noise setting with a quantum channel of capacity Q &gt; 0, the
communication rate is proportional to Q.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2648</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2648</id><created>2013-09-10</created><authors><author><keyname>SalahEldeen</keyname><forenames>Hany M.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Resurrecting My Revolution: Using Social Link Neighborhood in Bringing
  Context to the Disappearing Web</title><categories>cs.IR cs.DL</categories><comments>Published IN TPDL 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work we reported that resources linked in tweets disappeared at
the rate of 11% in the first year followed by 7.3% each year afterwards. We
also found that in the first year 6.7%, and 14.6% in each subsequent year, of
the resources were archived in public web archives. In this paper we revisit
the same dataset of tweets and find that our prior model still holds and the
calculated error for estimating percentages missing was about 4%, but we found
the rate of archiving produced a higher error of about 11.5%. We also
discovered that resources have disappeared from the archives themselves (7.89%)
as well as reappeared on the live web after being declared missing (6.54%). We
have also tested the availability of the tweets themselves and found that
10.34% have disappeared from the live web. To mitigate the loss of resources on
the live web, we propose the use of a &quot;tweet signature&quot;. Using the Topsy API,
we extract the top five most frequent terms from the union of all tweets about
a resource, and use these five terms as a query to Google. We found that using
tweet signatures results in discovering replacement resources with 70+% textual
similarity to the missing resource 41% of the time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2655</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2655</id><created>2013-09-10</created><authors><author><keyname>K&#xf6;hler</keyname><forenames>Sven</forenames></author><author><keyname>Lud&#xe4;scher</keyname><forenames>Bertram</forenames></author><author><keyname>Zinn</keyname><forenames>Daniel</forenames></author></authors><title>First-Order Provenance Games</title><categories>cs.DB cs.LO</categories><journal-ref>Peter Buneman Festschrift, LNCS 8000, 2013</journal-ref><doi>10.1007/978-3-642-41660-6_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new model of provenance, based on a game-theoretic approach to
query evaluation. First, we study games G in their own right, and ask how to
explain that a position x in G is won, lost, or drawn. The resulting notion of
game provenance is closely related to winning strategies, and excludes from
provenance all &quot;bad moves&quot;, i.e., those which unnecessarily allow the opponent
to improve the outcome of a play. In this way, the value of a position is
determined by its game provenance. We then define provenance games by viewing
the evaluation of a first-order query as a game between two players who argue
whether a tuple is in the query answer. For RA+ queries, we show that game
provenance is equivalent to the most general semiring of provenance polynomials
N[X]. Variants of our game yield other known semirings. However, unlike
semiring provenance, game provenance also provides a &quot;built-in&quot; way to handle
negation and thus to answer why-not questions: In (provenance) games, the
reason why x is not won, is the same as why x is lost or drawn (the latter is
possible for games with draws). Since first-order provenance games are
draw-free, they yield a new provenance model that combines how- and why-not
provenance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2660</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2660</id><created>2013-09-10</created><authors><author><keyname>Bohg</keyname><forenames>Jeannette</forenames></author><author><keyname>Morales</keyname><forenames>Antonio</forenames></author><author><keyname>Asfour</keyname><forenames>Tamim</forenames></author><author><keyname>Kragic</keyname><forenames>Danica</forenames></author></authors><title>Data-Driven Grasp Synthesis - A Survey</title><categories>cs.RO</categories><comments>20 pages, 30 Figures, submitted to IEEE Transactions on Robotics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the work on data-driven grasp synthesis and the methodologies for
sampling and ranking candidate grasps. We divide the approaches into three
groups based on whether they synthesize grasps for known, familiar or unknown
objects. This structure allows us to identify common object representations and
perceptual processes that facilitate the employed data-driven grasp synthesis
technique. In the case of known objects, we concentrate on the approaches that
are based on object recognition and pose estimation. In the case of familiar
objects, the techniques use some form of a similarity matching to a set of
previously encountered objects. Finally for the approaches dealing with unknown
objects, the core part is the extraction of specific features that are
indicative of good grasps. Our survey provides an overview of the different
methodologies and discusses open problems in the area of robot grasping. We
also draw a parallel to the classical approaches that rely on analytic
formulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2675</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2675</id><created>2013-09-06</created><authors><author><keyname>McColl</keyname><forenames>Rob</forenames></author><author><keyname>Ediger</keyname><forenames>David</forenames></author><author><keyname>Poovey</keyname><forenames>Jason</forenames></author><author><keyname>Campbell</keyname><forenames>Dan</forenames></author><author><keyname>Bader</keyname><forenames>David</forenames></author></authors><title>A Brief Study of Open Source Graph Databases</title><categories>cs.DB cs.DS cs.SE</categories><comments>WSSSPE13, 4 Pages, 18 Pages with Appendix, 25 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  With the proliferation of large irregular sparse relational datasets, new
storage and analysis platforms have arisen to fill gaps in performance and
capability left by conventional approaches built on traditional database
technologies and query languages. Many of these platforms apply graph
structures and analysis techniques to enable users to ingest, update, query and
compute on the topological structure of these relationships represented as
set(s) of edges between set(s) of vertices. To store and process Facebook-scale
datasets, they must be able to support data sources with billions of edges,
update rates of millions of updates per second, and complex analysis kernels.
These platforms must provide intuitive interfaces that enable graph experts and
novice programmers to write implementations of common graph algorithms. In this
paper, we explore a variety of graph analysis and storage platforms. We compare
their capabil- ities, interfaces, and performance by implementing and computing
a set of real-world graph algorithms on synthetic graphs with up to 256 million
edges. In the spirit of full disclosure, several authors are affiliated with
the development of STINGER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2676</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2676</id><created>2013-09-10</created><updated>2014-08-01</updated><authors><author><keyname>Giryes</keyname><forenames>Raja</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author></authors><title>Greedy Signal Space Methods for incoherence and beyond</title><categories>math.NA cs.IT math.IT</categories><msc-class>41A46, 68Q25, 68W20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sampling (CoSa) has provided many methods for signal recovery of
signals compressible with respect to an orthonormal basis. However, modern
applications have sparked the emergence of approaches for signals not sparse in
an orthonormal basis but in some arbitrary, perhaps highly overcomplete,
dictionary. Recently, several &quot;signal-space&quot; greedy methods have been proposed
to address signal recovery in this setting. However, such methods inherently
rely on the existence of fast and accurate projections which allow one to
identify the most relevant atoms in a dictionary for any given signal, up to a
very strict accuracy. When the dictionary is highly overcomplete, no such
projections are currently known; the requirements on such projections do not
even hold for incoherent or well-behaved dictionaries. In this work, we provide
an alternate analysis for signal space greedy methods which enforce assumptions
on these projections which hold in several settings including those when the
dictionary is incoherent or structurally coherent. These results align more
closely with traditional results in the standard CoSa literature and improve
upon previous work in the signal space setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2677</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2677</id><created>2013-09-10</created><authors><author><keyname>Pop</keyname><forenames>Cristina-Maria</forenames></author><author><keyname>Frey</keyname><forenames>Erwin</forenames></author></authors><title>Language change in a multiple group society</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 9 figures</comments><report-no>LMU-ASC 053/13</report-no><doi>10.1103/PhysRevE.88.022814</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The processes leading to change in languages are manifold. In order to reduce
ambiguity in the transmission of information, agreement on a set of conventions
for recurring problems is favored. In addition to that, speakers tend to use
particular linguistic variants associated with the social groups they identify
with. The influence of other groups propagating across the speech community as
new variant forms sustains the competition between linguistic variants. With
the utterance selection model, an evolutionary description of language change,
Baxter et al. [Phys. Rev. E 73, 046118 (2006)] have provided a mathematical
formulation of the interactions inside a group of speakers, exploring the
mechanisms that lead to or inhibit the fixation of linguistic variants. In this
paper, we take the utterance selection model one step further by describing a
speech community consisting of multiple interacting groups. Tuning the
interaction strength between groups allows us to gain deeper understanding
about the way in which linguistic variants propagate and how their distribution
depends on the group partitioning. Both for the group size and the number of
groups we find scaling behaviors with two asymptotic regimes. If groups are
strongly connected, the dynamics is that of the standard utterance selection
model, whereas if their coupling is weak, the magnitude of the latter along
with the system size governs the way consensus is reached. Furthermore, we find
that a high influence of the interlocutor on a speaker's utterances can act as
a counterweight to group segregation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2679</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2679</id><created>2013-09-10</created><authors><author><keyname>Graells-Garrido</keyname><forenames>Eduardo</forenames></author><author><keyname>Baeza-Yates</keyname><forenames>Ricardo</forenames></author></authors><title>Caracterizando la Web Chilena</title><categories>cs.SI</categories><comments>In Spanish. Published in &quot;Revista Bits de Ciencia&quot; vol. 2, 2009.
  Department of Computer Science, University of Chile. Available in
  http://www.dcc.uchile.cl/revista</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This article presents a characterization of the web space from Chile in 2007.
The characterization shows distributions of sites and domains, analysis of
document content and server configuration. In addition, the network structure
of the chilean Web is analyzed, determining components based on hyperlink
structure at the document and site levels.
  Original Abstract: En este art\'iculo se muestra una caracterizaci\'on del
espacio web de Chile para el a\~no 2007. Se muestran distribuciones de sitios y
dominios, caracterizaci\'on del contenido en base a tipos de documento, asi
como configuraci\'on de los servidores. Se estudia la estructura de la red
creada mediante hiperv\'inculos en los documentos y c\'omo las diferentes
componentes de esta estructura var\'ian cuando los hiperv\'inculos son
agregados a nivel de sitios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2685</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2685</id><created>2013-09-10</created><authors><author><keyname>Marigo</keyname><forenames>Francesco</forenames></author></authors><title>Complete Valuations on Finite Distributive Lattices</title><categories>cs.DM math.CO</categories><msc-class>06Dxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize the finite distributive lattices which admit a complete
valuation, that is bijective over a set of consecutive natural numbers, with
the additional conditions of completeness (Definition 2.3). We prove that such
lattices are downset lattices of finite posets of dimension at most two, and
determine a realizer through a recursive relation between weights on the poset
associated to valuation. The relation shows that the weights count chains in
the complementary poset. Conversely, we prove that a valuation defined on a
poset of dimension at most two, through the weight function which counts chains
in the complementary poset, is complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2687</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2687</id><created>2013-09-10</created><authors><author><keyname>Su</keyname><forenames>Han</forenames></author></authors><title>CrowdPlanner: A Crowd-Based Route Recommendation System</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CrowdPlanner -- a novel crowd-based route recommendation system has been
developed, which requests human workers to evaluate candidates routes
recommended by different sources and methods, and determine the best route
based on the feedbacks of these workers. Our system addresses two critical
issues in its core components: a) task generation component generates a series
of informative and concise questions with optimized ordering for a given
candidate route set so that workers feel comfortable and easy to answer; and b)
worker selection component utilizes a set of selection criteria and an
efficient algorithm to find the most eligible workers to answer the questions
with high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2690</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2690</id><created>2013-09-10</created><authors><author><keyname>Chukwuka</keyname><forenames>Eleazar</forenames></author><author><keyname>Arshad</keyname><forenames>Kamran</forenames></author></authors><title>Energt Efficient MAC Protocols for Wireless Sensor Network: A Survey</title><categories>cs.IT cs.NI math.IT</categories><comments>16 pages</comments><doi>10.5121/ijwmn.2013.5406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Network (WSN) is an attractive choice for a variety of
applications as no wired infrastructure is needed. Other wireless networks are
not as energy constrained as WSNs, because they may be plugged into the mains
supply or equipped with batteries that are rechargeable and replaceable. Among
others, one of the main sources of energy depletion in WSN is communications
controlled by the Medium Access Control (MAC) protocols. An extensive survey of
energy efficient MAC protocols is presented in this article. We categorise WSN
MAC protocols in the following categories: controlled access (CA), random
access (RA), slotted protocols (SP) and hybrid protocols (HP). We further
discuss how energy efficient MAC protocols have developed from fixed sleep/wake
cycles through adaptive to dynamic cycles, thus becoming more responsive to
traffic load variations. Finally we present open research questions on MAC
layer design for WSNs in terms of energy efficiency
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2693</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2693</id><created>2013-09-10</created><authors><author><keyname>Pillac</keyname><forenames>Victor</forenames></author><author><keyname>Van Henetenryck</keyname><forenames>Pascal</forenames></author><author><keyname>Even</keyname><forenames>Caroline</forenames></author></authors><title>A Conflict-Based Path-Generation Heuristic for Evacuation Planning</title><categories>cs.AI math.OC</categories><comments>Technical report</comments><report-no>NICTA VRL-7393</report-no><msc-class>90C27</msc-class><acm-class>G.1.6; H.4.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Evacuation planning and scheduling is a critical aspect of disaster
management and national security applications. This paper proposes a
conflict-based path-generation approach for evacuation planning. Its key idea
is to generate evacuation routes lazily for evacuated areas and to optimize the
evacuation over these routes in a master problem. Each new path is generated to
remedy conflicts in the evacuation and adds new columns and a new row in the
master problem. The algorithm is applied to massive flood scenarios in the
Hawkesbury-Nepean river (West Sydney, Australia) which require evacuating in
the order of 70,000 persons. The proposed approach reduces the number of
variables from 4,500,000 in a Mixed Integer Programming (MIP) formulation to
30,000 in the case study. With this approach, realistic evacuations scenarios
can be solved near-optimally in real time, supporting both evacuation planning
in strategic, tactical, and operational environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2712</identifier>
 <datestamp>2014-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2712</id><created>2013-09-10</created><updated>2014-02-18</updated><authors><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Song</keyname><forenames>Wentu</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>On Block Security of Regenerating Codes at the MBR Point for Distributed
  Storage Systems</title><categories>cs.IT math.CO math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A passive adversary can eavesdrop stored content or downloaded content of
some storage nodes, in order to learn illegally about the file stored across a
distributed storage system (DSS). Previous work in the literature focuses on
code constructions that trade storage capacity for perfect security. In other
words, by decreasing the amount of original data that it can store, the system
can guarantee that the adversary, which eavesdrops up to a certain number of
storage nodes, obtains no information (in Shannon's sense) about the original
data. In this work we introduce the concept of block security for DSS and
investigate minimum bandwidth regenerating (MBR) codes that are block secure
against adversaries of varied eavesdropping strengths. Such MBR codes guarantee
that no information about any group of original data units up to a certain size
is revealed, without sacrificing the storage capacity of the system. The size
of such secure groups varies according to the number of nodes that the
adversary can eavesdrop. We show that code constructions based on Cauchy
matrices provide block security. The opposite conclusion is drawn for codes
based on Vandermonde matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2721</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2721</id><created>2013-09-10</created><updated>2013-09-20</updated><authors><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Asymptotically Optimal Beamforming for Video Streaming in Multi-Antenna
  Interference Networks</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn since there are also some results that
  need to be modified and strengthened in it. We will also upload our modified
  work to arXiv in the future</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider queue-aware beamforming control for video
streaming applications in multi-antenna interference network. Using heavy
traffic approximation technique, we first derive the diffusion limit for the
discrete time queuing system. Based on the diffusion limit, we formulate an
infinite horizon ergodic control problem to minimize the average power costs of
the base stations subject to the constraints on the playback interruption costs
and buffer overflow costs of the mobile users. To deal with the queue coupling
challenge, we utilize the weak interference coupling property in the network to
derive a closed-form approximate value function of the optimality equation as
well as the associated error bound using perturbation analysis. Based on the
closed-form approximate value function, we propose a low complexity queue-aware
beamforming control algorithm, which is asymptotically optimal for sufficiently
small cross-channel path gain. Finally, the proposed scheme is compared with
various baselines through simulations and it is shown that significant
performance gain can be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2729</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2729</id><created>2013-09-11</created><updated>2014-05-11</updated><authors><author><keyname>Sharma</keyname><forenames>Ankit</forenames></author><author><keyname>Vondr&#xe1;k</keyname><forenames>Jan</forenames></author></authors><title>Multiway Cut, Pairwise Realizable Distributions, and Descending
  Thresholds</title><categories>cs.DS</categories><comments>This is an updated version and is the full version of STOC 2014 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design new approximation algorithms for the Multiway Cut problem,
improving the previously known factor of 1.32388 [Buchbinder et al., 2013].
  We proceed in three steps. First, we analyze the rounding scheme of
Buchbinder et al., 2013 and design a modification that improves the
approximation to (3+sqrt(5))/4 (approximately 1.309017). We also present a
tight example showing that this is the best approximation one can achieve with
the type of cuts considered by Buchbinder et al., 2013: (1) partitioning by
exponential clocks, and (2) single-coordinate cuts with equal thresholds.
  Then, we prove that this factor can be improved by introducing a new rounding
scheme: (3) single-coordinate cuts with descending thresholds. By combining
these three schemes, we design an algorithm that achieves a factor of (10 + 4
sqrt(3))/13 (approximately 1.30217). This is the best approximation factor that
we are able to verify by hand.
  Finally, we show that by combining these three rounding schemes with the
scheme of independent thresholds from Karger et al., 2004, the approximation
factor can be further improved to 1.2965. This approximation factor has been
verified only by computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2734</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2734</id><created>2013-09-11</created><authors><author><keyname>Murano</keyname><forenames>Koki</forenames></author><author><keyname>Shimobaba</keyname><forenames>Tomoyoshi</forenames></author><author><keyname>Sugiyama</keyname><forenames>Atsushi</forenames></author><author><keyname>Takada</keyname><forenames>Naoki</forenames></author><author><keyname>Kakue</keyname><forenames>Takashi</forenames></author><author><keyname>Oikawa</keyname><forenames>Minoru</forenames></author><author><keyname>Ito</keyname><forenames>Tomoyoshi</forenames></author></authors><title>Fast computation of computer-generated hologram using Xeon Phi
  coprocessor</title><categories>physics.comp-ph cs.DC physics.optics</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report fast computation of computer-generated holograms (CGHs) using Xeon
Phi coprocessors, which have massively x86-based processors on one chip,
recently released by Intel. CGHs can generate arbitrary light wavefronts, and
therefore, are promising technology for many applications: for example,
three-dimensional displays, diffractive optical elements, and the generation of
arbitrary beams. CGHs incur enormous computational cost. In this paper, we
describe the implementations of several CGH generating algorithms on the Xeon
Phi, and the comparisons in terms of the performance and the ease of
programming between the Xeon Phi, a CPU and graphics processing unit (GPU).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2735</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2735</id><created>2013-09-11</created><authors><author><keyname>Zhao</keyname><forenames>Pengkai</forenames></author><author><keyname>Daneshrad</keyname><forenames>Babak</forenames></author></authors><title>Adaptive Switching Between Single/Concurrent Link Scheme in Single Hop
  MIMO Networks</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Concurrent link communications built on multi-antenna systems have been
widely adopted for spatial resource exploitation. MIMA-MAC, a classical MIMO
MAC protocol utilizing concurrent link scheme, is able to provide superior link
throughput over conventional single link MAC (under certain isolated link
topologies). However, when utilizing rich link adaptation functions in MIMO
systems, there exists a non-ignorable probability that MIMA-MAC's throughput
will be lower than that of single link scheme (such probability is dominated by
the statistics of instantaneous link topology and channel response). Inspired
by this critical observation, and for adapting to various link topologies, this
paper will present a novel MAC design that can adaptively switch between single
or concurrent link scheme. With the aim of absolutely outperforming the single
link MAC, here our optimization criterion is to guarantee a throughput result
that is either better than or at least equal to single link MAC's counterpart.
To highlight the design rationale, we first present an idealized implementation
having network information perfectly known in a non-causal way. Then for
realistic applications, we further develop a practical MAC implementation
dealing with realistic system impairments (distributed handshaking and
imperfect channel estimation). Simulation results validate that link throughput
in our MAC is higher than or equal to single link MAC's counterpart with
minimized outage probabilities. And for ergodic link throughput, our proposed
MAC can outperform the single link MAC and MIMA-MAC by around 20{%}-30{%}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2747</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2747</id><created>2013-09-11</created><authors><author><keyname>Zhou</keyname><forenames>Junping</forenames></author><author><keyname>Su</keyname><forenames>Weihua</forenames></author><author><keyname>Yin</keyname><forenames>Minghao</forenames></author></authors><title>Approximate Counting CSP Solutions Using Partition Function</title><categories>cs.AI</categories><comments>14 pages, 2 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new approximate method for counting the number of the solutions
for constraint satisfaction problem (CSP). The method derives from the
partition function based on introducing the free energy and capturing the
relationship of probabilities of variables and constraints, which requires the
marginal probabilities. It firstly obtains the marginal probabilities using the
belief propagation, and then computes the number of solutions according to the
partition function. This allows us to directly plug the marginal probabilities
into the partition function and efficiently count the number of solutions for
CSP. The experimental results show that our method can solve both random
problems and structural problems efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2749</identifier>
 <datestamp>2014-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2749</id><created>2013-09-11</created><authors><author><keyname>Machado</keyname><forenames>Raphael C. S.</forenames></author><author><keyname>de Figueiredo</keyname><forenames>Celina M. H.</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author></authors><title>Complexity of colouring problems restricted to unichord-free and
  \{square,unichord\}-free graphs</title><categories>cs.DM math.CO</categories><msc-class>05C85</msc-class><journal-ref>Discrete Applied Mathematics. Volume 164, Part 1, 19 February
  2014, Pages 191-199</journal-ref><doi>10.1016/j.dam.2012.02.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A \emph{unichord} in a graph is an edge that is the unique chord of a cycle.
A \emph{square} is an induced cycle on four vertices. A graph is
\emph{unichord-free} if none of its edges is a unichord. We give a slight
restatement of a known structure theorem for unichord-free graphs and use it to
show that, with the only exception of the complete graph $K_4$, every
square-free, unichord-free graph of maximum degree~3 can be total-coloured with
four colours. Our proof can be turned into a polynomial time algorithm that
actually outputs the colouring. This settles the class of square-free,
unichord-free graphs as a class for which edge-colouring is NP-complete but
total-colouring is polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2752</identifier>
 <datestamp>2015-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2752</id><created>2013-09-11</created><authors><author><keyname>Moreno</keyname><forenames>Juan C.</forenames></author><author><keyname>Prasath</keyname><forenames>V. B. S.</forenames></author><author><keyname>Santos</keyname><forenames>Gil</forenames></author><author><keyname>Proenca</keyname><forenames>Hugo</forenames></author></authors><title>Robust Periocular Recognition By Fusing Sparse Representations of Color
  and Geometry Information</title><categories>cs.CV</categories><comments>23 pages, 5 figures, 3 tables</comments><msc-class>65F22, 65F50, 94A08</msc-class><acm-class>I.4.8, I.4.10, G.1.3, G.1.6</acm-class><doi>10.1007/s11265-015-1023-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a re-weighted elastic net (REN) model for biometric
recognition. The new model is applied to data separated into geometric and
color spatial components. The geometric information is extracted using a fast
cartoon - texture decomposition model based on a dual formulation of the total
variation norm allowing us to carry information about the overall geometry of
images. Color components are defined using linear and nonlinear color spaces,
namely the red-green-blue (RGB), chromaticity-brightness (CB) and
hue-saturation-value (HSV). Next, according to a Bayesian fusion-scheme, sparse
representations for classification purposes are obtained. The scheme is
numerically solved using a gradient projection (GP) algorithm. In the empirical
validation of the proposed model, we have chosen the periocular region, which
is an emerging trait known for its robustness against low quality data. Our
results were obtained in the publicly available UBIRIS.v2 data set and show
consistent improvements in recognition effectiveness when compared to related
state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2765</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2765</id><created>2013-09-11</created><authors><author><keyname>Songsiri</keyname><forenames>Patoomsiri</forenames></author><author><keyname>Phetkaew</keyname><forenames>Thimaporn</forenames></author><author><keyname>Kijsirikul</keyname><forenames>Boonserm</forenames></author></authors><title>Enhancements of Multi-class Support Vector Machine Construction from
  Binary Learners using Generalization Performance</title><categories>cs.LG stat.ML</categories><comments>17 pages, 13 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose several novel methods for enhancing the multi-class SVMs by
applying the generalization performance of binary classifiers as the core idea.
This concept will be applied on the existing algorithms, i.e., the Decision
Directed Acyclic Graph (DDAG), the Adaptive Directed Acyclic Graphs (ADAG), and
Max Wins. Although in the previous approaches there have been many attempts to
use some information such as the margin size and the number of support vectors
as performance estimators for binary SVMs, they may not accurately reflect the
actual performance of the binary SVMs. We show that the generalization ability
evaluated via a cross-validation mechanism is more suitable to directly extract
the actual performance of binary SVMs. Our methods are built around this
performance measure, and each of them is crafted to overcome the weakness of
the previous algorithm. The proposed methods include the Reordering Adaptive
Directed Acyclic Graph (RADAG), Strong Elimination of the classifiers (SE),
Weak Elimination of the classifiers (WE), and Voting based Candidate Filtering
(VCF). Experimental results demonstrate that our methods give significantly
higher accuracy than all of the traditional ones. Especially, WE provides
significantly superior results compared to Max Wins which is recognized as the
state of the art algorithm in terms of both accuracy and classification speed
with two times faster in average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2772</identifier>
 <datestamp>2014-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2772</id><created>2013-09-11</created><updated>2014-05-21</updated><authors><author><keyname>Sutra</keyname><forenames>Pierre</forenames></author><author><keyname>Rivi&#xe8;re</keyname><forenames>Etienne</forenames></author><author><keyname>Felber</keyname><forenames>Pascal</forenames></author></authors><title>A Practical Distributed Universal Construction with Unknown Participants</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern distributed systems employ atomic read-modify-write primitives to
coordinate concurrent operations. Such primitives are typically built on top of
a central server, or rely on an agreement protocol. Both approaches provide a
universal construction, that is, a general mechanism to construct atomic and
responsive objects. These two techniques are however known to be inherently
costly. As a consequence, they may result in bottlenecks in applications using
them for coordination. In this paper, we investigate another direction to
implement a universal construction. Our idea is to delegate the implementation
of the universal construction to the clients, and solely implement a
distributed shared atomic memory at the servers side. The construction we
propose is obstruction-free. It can be implemented in a purely asynchronous
manner, and it does not assume the knowledge of the participants. It is built
on top of grafarius and racing objects, two novel shared abstractions that we
introduce in detail. To assess the benefits of our approach, we present a
prototype implementation on top of the Cassandra data store, and compare it
empirically to the Zookeeper coordination service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2787</identifier>
 <datestamp>2015-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2787</id><created>2013-09-11</created><updated>2015-03-11</updated><authors><author><keyname>Zhang</keyname><forenames>Hyde</forenames></author><author><keyname>Soiland-Reyes</keyname><forenames>Stian</forenames></author><author><keyname>Goble</keyname><forenames>Carole</forenames></author></authors><title>Taverna Mobile: Taverna workflows on Android</title><categories>cs.SE</categories><comments>Abstract, 3 pages, 2 figures. Submitted for Oral communication at
  NETTAB 2013 on 2013-09-10. Accepted 2013-09-14. Published 2013-10-14 in
  EMBnet.journal.
  http://journal.embnet.org/index.php/embnetjournal/article/view/727 Taverna
  Mobile: http://dev.mygrid.org.uk/wiki/display/tav/Taverna+Mobile</comments><acm-class>C.2.4; C.5.3; D.2.13; K.4.3; K.6.3</acm-class><journal-ref>EMBnet.Journal 2013, 19(B), pp. 43-45</journal-ref><doi>10.14806/ej.19.B.727</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Researchers are often on the move, say at conferences or projects meetings,
and as workflows are becoming ubiquitous in the scientific process, having
access to scientific workflows from a mobile device would be a significant
advantage. We therefore have developed Taverna Mobile, an application for
Android phones which allows browsing of existing workflows, executing them, and
reviewing the results.
  Taverna Mobile does not aim to reproduce the full experience of building
workflows in the Taverna Workbench, rather it focuses on tasks we have deemed
relevant to a scientist that is not at her desk. For instance, when visiting a
conference she might hear about someone's workflow, which she can quickly
locate and mark for later exploration. When in the biology lab, faced with
updated scientific data, the scientist can rerun her own workflow with new
inputs. While commuting, she can monitor the status of a long-running job.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2788</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2788</id><created>2013-09-11</created><authors><author><keyname>Dillo</keyname><forenames>Ingrid</forenames></author><author><keyname>van Horik</keyname><forenames>Rene</forenames></author><author><keyname>Scharnhorst</keyname><forenames>Andrea</forenames></author></authors><title>Training in Data Curation as Service in a Federated Data Infrastructure
  - the FrontOffice-BackOffice Model</title><categories>cs.DL cs.CY</categories><comments>TPDL 2013, accepted for workshop Education in Data Curation, preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing volume and importance of research data leads to the emergence
of research data infrastructures in which data management plays an important
role. As a consequence, practices at digital archives and libraries change. In
this paper, we focus on a possible alliance between archives and libraries
around training activities in data curation. We introduce a so-called
\emph{FrontOffice--BackOffice model} and discuss experiences of its
implementation in the Netherlands. In this model, an efficient division of
tasks relies on a distributed infrastructure in which research institutions
(i.e., universities) use centralized storage and data curation services
provided by national research data archives. The training activities are aimed
at information professionals working at those research institutions, for
instance as digital librarians. We describe our experiences with the course
\emph{DataIntelligence4Librarians}. Eventually, we reflect about the
international dimension of education and training around data curation and
stewardship.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2789</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2789</id><created>2013-09-11</created><authors><author><keyname>Femijemilohun</keyname><forenames>Oladunni</forenames></author><author><keyname>Walker</keyname><forenames>Stuart</forenames></author></authors><title>Empirical Performance Evaluation of Enhanced Throughput Schemes of
  IEEE802.11 Technology in Wireless Area Networks</title><categories>cs.NI</categories><comments>16 pages,14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success in the growing wireless standards can be measured by the
achievement of quality of service (QoS) specifications by the designers. The
IEEE802.11 wireless standards are widely accepted as wireless technology for
wireless LAN. Efforts have been made over the years by the task group to
provide adequate number of QoS enhancement schemes for the increasing numbers
of multimedia applications. This paper examines the empirical performances of
ad hoc wireless networks deployed on IEEE802.11 standard variants. A survey to
some of the QoS schemes incorporated in IEEE802.11 wireless PHY layers were
carried out. Then the effects of this enhancement schemes in relation to data
throughput and system capacity and reliability in the newest technology
deployed on IEEE802.11ac standards was investigated using real time
applications and simulation based approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2796</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2796</id><created>2013-09-11</created><updated>2014-07-26</updated><authors><author><keyname>Cicalese</keyname><forenames>Ferdinando</forenames></author><author><keyname>Laber</keyname><forenames>Eduardo</forenames></author><author><keyname>Saettler</keyname><forenames>Aline Medeiros</forenames></author></authors><title>Decision Trees for Function Evaluation - Simultaneous Optimization of
  Worst and Expected Cost</title><categories>cs.DS cs.AI cs.LG</categories><comments>A preliminary version of this paper was accepted for presentation at
  ICML 2014</comments><msc-class>68Q25, 68W25, 68Q32, 68T05</msc-class><acm-class>F.2; F.2.2; I.2; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In several applications of automatic diagnosis and active learning a central
problem is the evaluation of a discrete function by adaptively querying the
values of its variables until the values read uniquely determine the value of
the function. In general, the process of reading the value of a variable might
involve some cost, computational or even a fee to be paid for the experiment
required for obtaining the value. This cost should be taken into account when
deciding the next variable to read. The goal is to design a strategy for
evaluating the function incurring little cost (in the worst case or in
expectation according to a prior distribution on the possible variables'
assignments). Our algorithm builds a strategy (decision tree) which attains a
logarithmic approxima- tion simultaneously for the expected and worst cost
spent. This is best possible under the assumption that $P \neq NP.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2797</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2797</id><created>2013-09-09</created><authors><author><keyname>Inoue</keyname><forenames>Hiroyasu</forenames></author><author><keyname>Liu</keyname><forenames>Yang-Yu</forenames></author></authors><title>Revealing the intricate effect of collaboration on innovation</title><categories>physics.soc-ph cs.DL cs.SI physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Japan and U.S. patent records of several decades to demonstrate
the effect of collaboration on innovation. We find that statistically inventor
teams slightly outperform solo inventors while company teams perform equally
well as solo companies. By tracking the performance record of individual teams
we find that inventor teams' performance generally degrades with more repeat
collaborations. Though company teams' performance displays strongly bursty
behavior, long-term collaboration does not significantly help innovation at
all. To systematically study the effect of repeat collaboration, we define the
repeat collaboration number of a team as the average number of collaborations
over all the teammate pairs. We find that mild repeat collaboration improves
the performance of Japanese inventor teams and U.S. company teams. Yet,
excessive repeat collaboration does not significantly help innovation at both
the inventor and company levels in both countries. To control for unobserved
heterogeneity, we perform a detailed regression analysis and the results are
consistent with our simple observations. The presented results reveal the
intricate effect of collaboration on innovation, which may also be observed in
other creative projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2798</identifier>
 <datestamp>2014-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2798</id><created>2013-09-11</created><updated>2014-03-02</updated><authors><author><keyname>Roux</keyname><forenames>St&#xe9;phane Le</forenames></author></authors><title>Lazy beats crazy: a spurious yet mathematical justification for
  laissez-faire</title><categories>cs.GT</categories><comments>27 pages</comments><msc-class>91A18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In perfect-information games in extensive form, common knowledge of
rationality triggers backward induction, which yields a Nash equilibrium. That
result assumes much about the players' knowledge, while it holds only for a
subclass of the games in extensive form. Alternatively, this article defines a
non-deterministic evolutionary process, by myopic and lazy improvements, that
settles exactly at Nash equilibrium (in extensive form). Importantly, the
strategical changes that the process allows depend only on the structure of the
game tree, they are independent from the actual preferences. Nonetheless, the
process terminates if the players have acyclic preferences; and even if some
preferences are cyclic, the players with acyclic preferences stop improving
eventually. This result is then generalised in games played on DAGs or infinite
trees, and it is also refined by assigning probabilities to the process and
perturbing it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2802</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2802</id><created>2013-09-11</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Chmelik</keyname><forenames>Martin</forenames></author><author><keyname>Tracol</keyname><forenames>Mathieu</forenames></author></authors><title>What is Decidable about Partially Observable Markov Decision Processes
  with {\omega}-Regular Objectives</title><categories>cs.LO</categories><comments>Full version of the CSL 2013 paper. arXiv admin note: text overlap
  with arXiv:1308.4846</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider partially observable Markov decision processes (POMDPs) with
{\omega}-regular conditions specified as parity objectives. The class of
{\omega}-regular languages extends regular languages to infinite strings and
provides a robust specification language to express all properties used in
verification, and parity objectives are canonical forms to express
{\omega}-regular conditions. The qualitative analysis problem given a POMDP and
a parity objective asks whether there is a strategy to ensure that the
objective is satis- fied with probability 1 (resp. positive probability). While
the qualitative analysis problems are known to be undecidable even for very
special cases of parity objectives, we establish decidability (with optimal
complexity) of the qualitative analysis problems for POMDPs with all parity
objectives under finite- memory strategies. We establish optimal (exponential)
memory bounds and EXPTIME-completeness of the qualitative analysis problems
under finite-memory strategies for POMDPs with parity objectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2805</identifier>
 <datestamp>2015-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2805</id><created>2013-09-11</created><authors><author><keyname>Altarelli</keyname><forenames>F.</forenames></author><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Dall'Asta</keyname><forenames>L.</forenames></author><author><keyname>Wakeling</keyname><forenames>J. R.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Containing epidemic outbreaks by message-passing techniques</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI q-bio.PE</categories><journal-ref>Phys. Rev. X 4, 021024, 2014</journal-ref><doi>10.1103/PhysRevX.4.021024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of targeted network immunization can be defined as the one of
finding a subset of nodes in a network to immunize or vaccinate in order to
minimize a tradeoff between the cost of vaccination and the final (stationary)
expected infection under a given epidemic model. Although computing the
expected infection is a hard computational problem, simple and efficient
mean-field approximations have been put forward in the literature in recent
years. The optimization problem can be recast into a constrained one in which
the constraints enforce local mean-field equations describing the average
stationary state of the epidemic process. For a wide class of epidemic models,
including the susceptible-infected-removed and the
susceptible-infected-susceptible models, we define a message-passing approach
to network immunization that allows us to study the statistical properties of
epidemic outbreaks in the presence of immunized nodes as well as to find
(nearly) optimal immunization sets for a given choice of parameters and costs.
The algorithm scales linearly with the size of the graph and it can be made
efficient even on large networks. We compare its performance with topologically
based heuristics, greedy methods, and simulated annealing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2806</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2806</id><created>2013-09-11</created><updated>2014-12-28</updated><authors><author><keyname>Bytev</keyname><forenames>V.</forenames></author><author><keyname>Kniehl</keyname><forenames>B.</forenames></author></authors><title>HYPERgeometric functions DIfferential REduction: MATHEMATICA based
  packages for differential reduction of generalized hypergeometric functions:
  Horn hypergeometric functions of two variables</title><categories>math-ph cs.SC hep-ph hep-th math.MP</categories><comments>minor corrections, publushed version</comments><doi>10.1016/j.cpc.2013.05.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  HYPERDIRE is a project devoted to the creation of a set of Mathematica-based
programs for the differential reduction of hypergeometric functions. The
current version allows for manipulations involving the full set of Horn-type
hypergeometric functions of two variables, including 30 functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2819</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2819</id><created>2013-09-11</created><authors><author><keyname>Oliveira</keyname><forenames>Roberto Imbuzeiro</forenames></author></authors><title>Stochastic processes with random contexts: a characterization, and
  adaptive estimators for the transition probabilities</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>22 pages. Soon to be submitted to IEEE Transactions on Information
  Theory</comments><msc-class>60F99, 62M09, 62B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the concept of random context representations for the
transition probabilities of a finite-alphabet stochastic process. Processes
with these representations generalize context tree processes (a.k.a. variable
length Markov chains), and are proven to coincide with processes whose
transition probabilities are almost surely continuous functions of the
(infinite) past. This is similar to a classical result by Kalikow about
continuous transition probabilities. Existence and uniqueness of a minimal
random context representation are proven, and an estimator of the transition
probabilities based on this representation is shown to have very good &quot;pastwise
adaptativity&quot; properties. In particular, it achieves minimax performance, up to
logarithmic factors, for binary renewal processes with bounded $2+\gamma$
moments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2827</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2827</id><created>2013-09-11</created><updated>2013-09-12</updated><authors><author><keyname>Anishchenko</keyname><forenames>Anastasiia</forenames></author><author><keyname>Blumen</keyname><forenames>Alexander</forenames></author><author><keyname>Muelken</keyname><forenames>Oliver</forenames></author></authors><title>Geometrical aspects of quantum walks on random two-dimensional
  structures</title><categories>quant-ph cond-mat.stat-mech cs.IT math.IT</categories><comments>7 pages, 4 figures</comments><doi>10.1103/PhysRevE.88.062126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the transport properties of continuous-time quantum walks (CTQW)
over finite two-dimensional structures with a given number of randomly placed
bonds and with different aspect ratios (AR). Here, we focus on the transport
from, say, the left side to the right side of the structure where absorbing
sites are placed. We do so by analyzing the long-time average of the survival
probability of CTQW. We compare the results to the classical continuous-time
random walk case (CTRW). For small AR (landscape configurations) we observe
only small differences between the quantum and the classical transport
properties, i.e., roughly the same number of bonds is needed to facilitate the
transport. However, with increasing AR (portrait configurations) a much larger
number of bonds is needed in the CTQW case than in the CTRW case. While for
CTRW the number of bonds needed decreases when going from small AR to large AR,
for CTRW this number is large for small AR, has a minimum for the square
configuration, and increases again for increasing AR. We corroborate our
findings for large AR by showing that the corresponding quantum eigenstates are
strongly localized in situations in which the transport is facilitated in the
CTRW case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2842</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2842</id><created>2013-09-11</created><authors><author><keyname>Bertrand</keyname><forenames>Nathalie</forenames></author><author><keyname>Bouyer</keyname><forenames>Patricia</forenames></author><author><keyname>Brihaye</keyname><forenames>Thomas</forenames></author><author><keyname>Stainer</keyname><forenames>Amelie</forenames></author></authors><title>Emptiness and Universality Problems in Timed Automata with Positive
  Frequency</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The languages of infinite timed words accepted by timed automata are
traditionally defined using Buchi-like conditions. These acceptance conditions
focus on the set of locations visited infinitely often along a run, but
completely ignore quantitative timing aspects. In this paper we propose a
natural quantitative semantics for timed automata based on the so-called
frequency, which measures the proportion of time spent in the accepting
locations. We study various properties of timed languages accepted with
positive frequency, and in particular the emptiness and universality problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2848</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2848</id><created>2013-09-11</created><authors><author><keyname>Kadir</keyname><forenames>Shabnam N.</forenames></author><author><keyname>Goodman</keyname><forenames>Dan F. M.</forenames></author><author><keyname>Harris</keyname><forenames>Kenneth D.</forenames></author></authors><title>High-dimensional cluster analysis with the Masked EM Algorithm</title><categories>q-bio.QM cs.LG q-bio.NC stat.AP</categories><comments>10 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cluster analysis faces two problems in high dimensions: first, the `curse of
dimensionality' that can lead to overfitting and poor generalization
performance; and second, the sheer time taken for conventional algorithms to
process large amounts of high-dimensional data. In many applications, only a
small subset of features provide information about the cluster membership of
any one data point, however this informative feature subset may not be the same
for all data points. Here we introduce a `Masked EM' algorithm for fitting
mixture of Gaussians models in such cases. We show that the algorithm performs
close to optimally on simulated Gaussian data, and in an application of `spike
sorting' of high channel-count neuronal recordings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2853</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2853</id><created>2013-09-11</created><authors><author><keyname>Denis</keyname><forenames>Alexandre</forenames><affiliation>LORIA</affiliation></author><author><keyname>Cruz-Lara</keyname><forenames>Samuel</forenames><affiliation>LORIA</affiliation></author><author><keyname>Bellalem</keyname><forenames>Nadia</forenames><affiliation>LORIA</affiliation></author></authors><title>General Purpose Textual Sentiment Analysis and Emotion Detection Tools</title><categories>cs.CL</categories><comments>Workshop on Emotion and Computing (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Textual sentiment analysis and emotion detection consists in retrieving the
sentiment or emotion carried by a text or document. This task can be useful in
many domains: opinion mining, prediction, feedbacks, etc. However, building a
general purpose tool for doing sentiment analysis and emotion detection raises
a number of issues, theoretical issues like the dependence to the domain or to
the language but also pratical issues like the emotion representation for
interoperability. In this paper we present our sentiment/emotion analysis
tools, the way we propose to circumvent the di culties and the applications
they are used for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2869</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2869</id><created>2013-09-11</created><authors><author><keyname>Asghar</keyname><forenames>Muhammad Rizwan</forenames></author><author><keyname>Russello</keyname><forenames>Giovanni</forenames></author></authors><title>ACTORS: A Goal-driven Approach for Capturing and Managing Consent in
  e-Health Systems</title><categories>cs.CY</categories><comments>The final version of this paper has been published at POLICY 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of patient's consent plays a major role in granting access to
medical data. In typical healthcare systems, consent is captured by a form that
the patient has to fill in and sign. In e-Health systems, the paper-form
consent is being replaced by the integration of the notion of consent in the
mechanisms that regulate the access to the medical data. This helps in
empowering the patient with the capability of granting and revoking consent in
a more effective manner. However, the process of granting and revoking consent
greatly varies according to the situation in which the patient is. Our main
argument is that such a level of detail is very difficult and error-prone to
capture as a set of authorisation policies. In this paper, we present ACTORS, a
goal-driven approach to manage consent. The main idea behind ACTORS is to
leverage the goal-driven approach of Teleo-Reactive (TR) programming for
managing consent that takes into account changes regarding the domains and
contexts in which the patient is providing her consent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2870</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2870</id><created>2013-09-11</created><authors><author><keyname>Wang</keyname><forenames>Qingchuan</forenames></author><author><keyname>He</keyname><forenames>Chen</forenames></author><author><keyname>Jiang</keyname><forenames>Lingge</forenames></author></authors><title>Analytical Framework of LDGM-based Iterative Quantization with
  Decimation</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While iterative quantizers based on low-density generator-matrix (LDGM) codes
have been shown to be able to achieve near-ideal distortion performance with
comparatively moderate block length and computational complexity requirements,
their analysis remains difficult due to the presence of decimation steps. In
this paper, considering the use of LDGM-based quantizers in a class of
symmetric source coding problems, with the alphabet being either binary or
non-binary, it is proved rigorously that, as long as the degree distribution
satisfies certain conditions that can be evaluated with density evolution (DE),
the belief propagation (BP) marginals used in the decimation step have
vanishing mean-square error compared to the exact marginals when the block
length and iteration count goes to infinity, which potentially allows
near-ideal distortion performances to be achieved. This provides a sound
theoretical basis for the degree distribution optimization methods previously
proposed in the literature and already found to be effective in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2877</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2877</id><created>2013-09-11</created><authors><author><keyname>Johansson</keyname><forenames>Fredrik</forenames></author></authors><title>Rigorous high-precision computation of the Hurwitz zeta function and its
  derivatives</title><categories>cs.SC math.NT</categories><comments>15 pages, 2 figures</comments><msc-class>65D20, 68W30, 33F05, 11-04, 11M06, 11M35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the use of the Euler-Maclaurin formula to numerically evaluate the
Hurwitz zeta function $\zeta(s,a)$ for $s, a \in \mathbb{C}$, along with an
arbitrary number of derivatives with respect to $s$, to arbitrary precision
with rigorous error bounds. Techniques that lead to a fast implementation are
discussed. We present new record computations of Stieltjes constants, Keiper-Li
coefficients and the first nontrivial zero of the Riemann zeta function,
obtained using an open source implementation of the algorithms described in
this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2898</identifier>
 <datestamp>2015-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2898</id><created>2013-09-11</created><updated>2015-07-09</updated><authors><author><keyname>Boyac&#x131;</keyname><forenames>Arman</forenames></author><author><keyname>Ekim</keyname><forenames>T&#x131;naz</forenames></author><author><keyname>Shalom</keyname><forenames>Mordechai</forenames></author><author><keyname>Zaks</keyname><forenames>Shmuel</forenames></author></authors><title>Graphs of Edge-Intersecting Non-Splitting Paths in a Tree: Towards Hole
  Representations-Part I</title><categories>cs.DM</categories><comments>Presented in WG 2013, 39th International Workshop on Graph-Theoretic
  Concepts in Computer Science, Submitted to Discrete Applied Mathematics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a tree and a set ${\cal P}$ of non-trivial simple paths on it,
$VPT({\cal P})$ is the VPT graph (i.e. the vertex intersection graph) of the
paths ${\cal P}$ of the tree $T$, and $EPT({\cal P})$ is the EPT graph (i.e.
the edge intersection graph) of ${\cal P}$. These graphs have been extensively
studied in the literature. Given two (edge) intersecting paths in a graph,
their \emph{split vertices} is the set of vertices having degree at least $3$
in their union. A pair of (edge) intersecting paths is termed
\emph{non-splitting} if they do not have split vertices (namely if their union
is a path).
  In this work, motivated by an application in all-optical networks, we define
the graph $ENPT({\cal P})$ of edge-intersecting non-splitting paths of a tree,
termed the ENPT graph, as the (edge) graph having a vertex for each path in
${\cal P}$, and an edge between every pair of paths that are both
edge-intersecting and non-splitting. A graph $G$ is an ENPT graph if there is a
tree $T$ and a set of paths ${\cal P}$ of $T$ such that $G=ENPT({\cal P})$, and
we say that $&lt;T,{\cal P}&gt;$ is a \emph{representation} of $G$. We first show
that cycles, trees and complete graphs are ENPT graphs.
  Our work follows the lines of Golumbic and Jamison's research in which they
defined the EPT graph class, and characterized the representations of chordless
cycles (holes). It turns out that ENPT holes have a more complex structure than
EPT holes. In our analysis, we assume that the EPT graph corresponding to a
representation of an ENPT hole is given. We also introduce three assumptions
$(P1)$, $(P2)$, $(P3)$ defined on EPT, ENPT pairs of graphs. In this Part I,
using the results of Golumbic and Jamison as building blocks, we characterize
(a) EPT, ENPT pairs that satisfy $(P1)$, $(P2)$, $(P3)$, and (b) the unique
minimal representation of such pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2900</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2900</id><created>2013-09-11</created><authors><author><keyname>Hannigan</keyname><forenames>Joseph</forenames></author><author><keyname>Hernandez</keyname><forenames>Guillermo</forenames></author><author><keyname>Medina</keyname><forenames>Richard M.</forenames></author><author><keyname>Roos</keyname><forenames>Patrcik</forenames></author><author><keyname>Shakarian</keyname><forenames>Paulo</forenames></author></authors><title>Mining for Spatially-Near Communities in Geo-Located Social Networks</title><categories>cs.SI physics.soc-ph</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Current approaches to community detection in social networks often ignore the
spatial location of the nodes. In this paper, we look to extract spatially-near
communities in a social network. We introduce a new metric to measure the
quality of a community partition in a geolocated social networks called
&quot;spatially-near modularity&quot; a value that increases based on aspects of the
network structure but decreases based on the distance between nodes in the
communities. We then look to find an optimal partition with respect to this
measure - which should be an &quot;ideal&quot; community with respect to both social ties
and geographic location. Though an NP-hard problem, we introduce two heuristic
algorithms that attempt to maximize this measure and outperform non-geographic
community finding by an order of magnitude. Applications to counter-terrorism
are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2904</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2904</id><created>2013-09-11</created><authors><author><keyname>Ponniah</keyname><forenames>Jonathan</forenames></author><author><keyname>Hu</keyname><forenames>Yih-Chun</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>A System-Theoretic Clean Slate Approach to Provably Secure Ad Hoc
  Wireless Networking</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Traditionally, wireless network protocols have been designed for performance.
Subsequently, as attacks have been identified, patches have been developed.
This has resulted in an &quot;arms race&quot; development process of discovering
vulnerabilities and then patching them. The fundamental difficulty with this
approach is that other vulnerabilities may still exist. No provable security or
performance guarantees can ever be provided.
  We develop a system-theoretic approach to security that provides a complete
protocol suite with provable guarantees, as well as proof of min-max optimality
with respect to any given utility function of source-destination rates. Our
approach is based on a model capturing the essential features of an adhoc
wireless network that has been infiltrated with hostile nodes. We consider any
collection of nodes, some good and some bad, possessing specified capabilities
vis-a-vis cryptography, wireless communication and clocks. The good nodes do
not know the bad nodes. The bad nodes can collaborate perfectly, and are
capable of any disruptive acts ranging from simply jamming to non-cooperation
with the protocols in any manner they please.
  The protocol suite caters to the complete life-cycle, all the way from birth
of nodes, through all phases of ad hoc network formation, leading to an
optimized network carrying data reliably. It provably achieves the min-max of
the utility function, where the max is over all protocol suites published and
followed by the good nodes, while the min is over all Byzantine behaviors of
the bad nodes. Under the protocol suite, the bad nodes do not benefit from any
actions other than jamming or cooperating.
  This approach supersedes much previous work that deals with several types of
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2915</identifier>
 <datestamp>2014-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2915</id><created>2013-09-11</created><updated>2014-10-03</updated><authors><author><keyname>Saldi</keyname><forenames>Naci</forenames></author><author><keyname>Linder</keyname><forenames>Tam&#xe1;s</forenames></author><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author></authors><title>Randomized Quantization and Source Coding with Constrained Output
  Distribution</title><categories>cs.IT math.IT</categories><comments>To appear in the IEEE Transactions on Information Theory</comments><msc-class>94A29</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies fixed-rate randomized vector quantization under the
constraint that the quantizer's output has a given fixed probability
distribution. A general representation of randomized quantizers that includes
the common models in the literature is introduced via appropriate mixtures of
joint probability measures on the product of the source and reproduction
alphabets. Using this representation and results from optimal transport theory,
the existence of an optimal (minimum distortion) randomized quantizer having a
given output distribution is shown under various conditions. For sources with
densities and the mean square distortion measure, it is shown that this optimum
can be attained by randomizing quantizers having convex codecells. For
stationary and memoryless source and output distributions a rate-distortion
theorem is proved, providing a single-letter expression for the optimum
distortion in the limit of large block-lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2920</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2920</id><created>2013-09-11</created><authors><author><keyname>Jiang</keyname><forenames>Chunxiao</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Liu</keyname><forenames>K. J. Ray</forenames></author></authors><title>Evolutionary Information Diffusion over Social Networks</title><categories>cs.GT cs.SI physics.soc-ph</categories><doi>10.1109/TSP.2014.2339799</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks have become ubiquitous in our daily life, as such it has
attracted great research interests recently. A key challenge is that it is of
extremely large-scale with tremendous information flow, creating the phenomenon
of &quot;Big Data&quot;. Under such a circumstance, understanding information diffusion
over social networks has become an important research issue. Most of the
existing works on information diffusion analysis are based on either network
structure modeling or empirical approach with dataset mining. However, the
information diffusion is also heavily influenced by network users' decisions,
actions and their socio-economic connections, which is generally ignored in
existing works. In this paper, we propose an evolutionary game theoretic
framework to model the dynamic information diffusion process in social
networks. Specifically, we analyze the framework in uniform degree and
non-uniform degree networks and derive the closed-form expressions of the
evolutionary stable network states. Moreover, the information diffusion over
two special networks, Erd\H{o}s-R\'enyi random network and the
Barab\'asi-Albert scale-free network, are also highlighted. To verify our
theoretical analysis, we conduct experiments by using both synthetic networks
and real-world Facebook network, as well as real-world information spreading
dataset of Twitter and Memetracker. Experiments shows that the proposed game
theoretic framework is effective and practical in modeling the social network
users' information forwarding behaviors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2922</identifier>
 <datestamp>2013-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2922</id><created>2013-09-11</created><authors><author><keyname>Jiang</keyname><forenames>Chunxiao</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Liu</keyname><forenames>K. J. Ray</forenames></author></authors><title>Indian Buffet Game with Negative Network Externality and Non-Bayesian
  Social Learning</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How users in a dynamic system perform learning and make decision become more
and more important in numerous research fields. Although there are some works
in the social learning literatures regarding how to construct belief on an
uncertain system state, few study has been conducted on incorporating social
learning with decision making. Moreover, users may have multiple concurrent
decisions on different objects/resources and their decisions usually negatively
influence each other's utility, which makes the problem even more challenging.
In this paper, we propose an Indian Buffet Game to study how users in a dynamic
system learn the uncertain system state and make multiple concurrent decisions
by not only considering the current myopic utility, but also taking into
account the influence of subsequent users' decisions. We analyze the proposed
Indian Buffet Game under two different scenarios: customers request multiple
dishes without budget constraint and with budget constraint. For both cases, we
design recursive best response algorithms to find the subgame perfect Nash
equilibrium for customers and characterize special properties of the Nash
equilibrium profile under homogeneous setting. Moreover, we introduce a
non-Bayesian social learning algorithm for customers to learn the system state,
and theoretically prove its convergence. Finally, we conduct simulations to
validate the effectiveness and efficiency of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2963</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2963</id><created>2013-09-11</created><authors><author><keyname>Shakarian</keyname><forenames>Paulo</forenames></author><author><keyname>Eyre</keyname><forenames>Sean</forenames></author><author><keyname>Paulo</keyname><forenames>Damon</forenames></author></authors><title>A Scalable Heuristic for Viral Marketing Under the Tipping Model</title><categories>cs.SI physics.soc-ph</categories><comments>arXiv admin note: substantial text overlap with arXiv:1205.4431</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In a &quot;tipping&quot; model, each node in a social network, representing an
individual, adopts a property or behavior if a certain number of his incoming
neighbors currently exhibit the same. In viral marketing, a key problem is to
select an initial &quot;seed&quot; set from the network such that the entire network
adopts any behavior given to the seed. Here we introduce a method for quickly
finding seed sets that scales to very large networks. Our approach finds a set
of nodes that guarantees spreading to the entire network under the tipping
model. After experimentally evaluating 31 real-world networks, we found that
our approach often finds seed sets that are several orders of magnitude smaller
than the population size and outperform nodal centrality measures in most
cases. In addition, our approach scales well - on a Friendster social network
consisting of 5.6 million nodes and 28 million edges we found a seed set in
under 3.6 hours. Our experiments also indicate that our algorithm provides
small seed sets even if high-degree nodes are removed. Lastly, we find that
highly clustered local neighborhoods, together with dense network-wide
community structures, suppress a trend's ability to spread under the tipping
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2966</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2966</id><created>2013-09-11</created><authors><author><keyname>Hanwell</keyname><forenames>Marcus D.</forenames></author><author><keyname>Perera</keyname><forenames>Amitha</forenames></author><author><keyname>Turner</keyname><forenames>Wes</forenames></author><author><keyname>O'Leary</keyname><forenames>Patrick</forenames></author><author><keyname>Osterdahl</keyname><forenames>Katie</forenames></author><author><keyname>Hoffman</keyname><forenames>Bill</forenames></author><author><keyname>Schroeder</keyname><forenames>Will</forenames></author></authors><title>Sustainable Software Ecosystems for Open Science</title><categories>cs.SE cs.CY</categories><comments>Workshop on Sustainable Software: Practices and Experiences, 4 pages,
  3 figures</comments><doi>10.6084/m9.figshare.790756</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Sustainable software ecosystems are difficult to build, and require concerted
effort, community norms and collaborations. In science it is especially
important to establish communities in which faculty, staff, students and
open-source professionals work together and treat software as a first-class
product of scientific investigation-just as mathematics is treated in the
physical sciences. Kitware has a rich history of establishing collaborative
projects in the science, engineering and medical research fields, and continues
to work on improving that model as new technologies and approaches become
available. This approach closely follows and is enhanced by the movement
towards practicing open, reproducible research in the sciences where data,
source code, methodology and approach are all available so that complex
experiments can be independently reproduced and verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2979</identifier>
 <datestamp>2014-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2979</id><created>2013-09-11</created><authors><author><keyname>Chicano</keyname><forenames>Francisco</forenames></author><author><keyname>Sutton</keyname><forenames>Andrew M.</forenames></author><author><keyname>Whitley</keyname><forenames>L. Darrell</forenames></author><author><keyname>Alba</keyname><forenames>Enrique</forenames></author></authors><title>Fitness Probability Distribution of Bit-Flip Mutation</title><categories>cs.DM</categories><comments>Submitted to Evolutionary Computation Journal (MIT Press)</comments><doi>10.1162/EVCO_a_00130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bit-flip mutation is a common mutation operator for evolutionary algorithms
applied to optimize functions over binary strings. In this paper, we develop
results from the theory of landscapes and Krawtchouk polynomials to exactly
compute the probability distribution of fitness values of a binary string
undergoing uniform bit-flip mutation. We prove that this probability
distribution can be expressed as a polynomial in p, the probability of flipping
each bit. We analyze these polynomials and provide closed-form expressions for
an easy linear problem (Onemax), and an NP-hard problem, MAX-SAT. We also
discuss some implications of the results for runtime analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.2987</identifier>
 <datestamp>2015-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.2987</id><created>2013-09-11</created><updated>2015-01-26</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author></authors><title>The Average Sensitivity of an Intersection of Half Spaces</title><categories>cs.CC math.CO math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove new bounds on the average sensitivity of the indicator function of
an intersection of $k$ halfspaces. In particular, we prove the optimal bound of
$O(\sqrt{n\log(k)})$. This generalizes a result of Nazarov, who proved the
analogous result in the Gaussian case, and improves upon a result of Harsha,
Klivans and Meka. Furthermore, our result has implications for the runtime
required to learn intersections of halfspaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3006</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3006</id><created>2013-09-11</created><updated>2013-09-25</updated><authors><author><keyname>Al-Wassai</keyname><forenames>Firouz Abdullah</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author></authors><title>The Classification Accuracy of Multiple-Metric Learning Algorithm on
  Multi-Sensor Fusion</title><categories>cs.CV</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in title the paper</comments><journal-ref>International Journal of Soft Computing and Engineering (IJSCE)
  ISSN: 2231-2307, Volume-3, Issue-4, September 2013,pp.124-131</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on two main issues; first one is the impact of Similarity
Search to learning the training sample in metric space, and searching based on
supervised learning classi-fication. In particular, four metrics space
searching are based on spatial information that are introduced as the
following; Cheby-shev Distance (CD); Bray Curtis Distance (BCD); Manhattan
Distance (MD) and Euclidean Distance(ED) classifiers. The second issue
investigates the performance of combination of mul-ti-sensor images on the
supervised learning classification accura-cy. QuickBird multispectral data (MS)
and panchromatic data (PAN) have been used in this study to demonstrate the
enhance-ment and accuracy assessment of fused image over the original images.
The supervised classification results of fusion image generated better than the
MS did. QuickBird and the best results with ED classifier than the other did.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3007</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3007</id><created>2013-09-11</created><authors><author><keyname>Sen</keyname><forenames>Pradeep</forenames></author></authors><title>On the Relationship Between Dual Photography and Classical Ghost Imaging</title><categories>physics.optics cs.GR quant-ph</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical ghost imaging has received considerable attention in recent years
because of its remarkable ability to image a scene without direct observation
by a light-detecting imaging device. In this article, we show that this imaging
process is actually a realization of a paradigm known as dual photography,
which has been shown to produce full-color dual (ghost) images of 3D objects
with complex materials without using a traditional imaging device.
Specifically, we demonstrate mathematically that the cross-correlation based
methods used to recover ghost images are equivalent to the light transport
measurement process of dual photography. Because of this, we are able to
provide a new explanation for ghost imaging using only classical optics by
leveraging the principle of reciprocity in classical electromagnetics. This
observation also shows how to leverage previous work on light transport
acquisition and dual photography to improve ghost imaging systems in the
future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3014</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3014</id><created>2013-09-11</created><authors><author><keyname>Polyanskiy</keyname><forenames>Yury</forenames></author></authors><title>Hypercontractivity of spherical averages in Hamming space</title><categories>math.PR cs.IT math.CO math.FA math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a linear space of functions on the binary hypercube and a linear
operator $T_\delta$ acting by averaging a function over a Hamming sphere of
radius $\delta n$. It is shown that such an operator has a dimension
independent bound on the norm $L_p \to L_2$ with $p = 1+(1-2\delta)^2$. This
result evidently parallels a classical estimate of Bonami and Gross for $L_p
\to L_q$ norms for the operator of convolution with a Bernoulli noise. The
estimate for $T_\delta$ is harder to obtain since the latter is neither a part
of a semigroup, nor a tensor power. The result is shown by a detailed study of
the eigenvalues of $T_\delta$ and $L_p\to L_2$ norms of the Fourier multiplier
operators $\Pi_a$ with symbol equal to a characterstic function of the Hamming
sphere of radius $a$.
  An application of the result to additive combinatorics is given: Any set
$A\subset \FF_2^n$ with the property that $A+A$ contains a large portion of
some Hamming sphere (counted with multiplicity) must have cardinality a
constant multiple of $2^n$. It is also demonstrated that this result does not
follow from standard spectral gap and semi-definite (Lov\'asz-Delsarte)
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3029</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3029</id><created>2013-09-12</created><updated>2013-09-17</updated><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Nock</keyname><forenames>Richard</forenames></author></authors><title>On the Chi square and higher-order Chi distances for approximating
  f-divergences</title><categories>cs.IT math.IT</categories><comments>11 pages, two tables, no figure. Java(TM) code available online at
  http://www.informationgeometry.org/fDivergence/</comments><doi>10.1109/LSP.2013.2288355</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report closed-form formula for calculating the Chi square and higher-order
Chi distances between statistical distributions belonging to the same
exponential family with affine natural space, and instantiate those formula for
the Poisson and isotropic Gaussian families. We then describe an analytic
formula for the $f$-divergences based on Taylor expansions and relying on an
extended class of Chi-type distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3039</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3039</id><created>2013-09-12</created><authors><author><keyname>Iqbal</keyname><forenames>Azlan</forenames></author></authors><title>How Relevant Are Chess Composition Conventions?</title><categories>cs.AI</categories><comments>10 pages, 3 tables, 2 figures. Accepted to the 23rd International
  Joint Conference on Artificial Intelligence (IJCAI) Workshop on Computer
  Games, Beijing, China, 3-5 August. Accepted papers were published online at
  the official workshop's website but have since been taken down. No printed
  proceedings or page numbers were issued</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Composition conventions are guidelines used by human composers in composing
chess problems. They are particularly significant in composition tournaments.
Examples include, not having any check in the first move of the solution and
not dressing up the board with unnecessary pieces. Conventions are often
associated or even directly conflated with the overall aesthetics or beauty of
a composition. Using an existing experimentally-validated computational
aesthetics model for three-move mate problems, we analyzed sets of
computer-generated compositions adhering to at least 2, 3 and 4 comparable
conventions to test if simply conforming to more conventions had a positive
effect on their aesthetics, as is generally believed by human composers. We
found slight but statistically significant evidence that it does, but only to a
point. We also analyzed human judge scores of 145 three-move mate problems
composed by humans to see if they had any positive correlation with the
computational aesthetic scores of those problems. We found that they did not.
These seemingly conflicting findings suggest two main things. First, the right
amount of adherence to composition conventions in a composition has a positive
effect on its perceived aesthetics. Second, human judges either do not look at
the same conventions related to aesthetics in the model used or emphasize
others that have less to do with beauty as perceived by the majority of
players, even though they may mistakenly consider their judgements beautiful in
the traditional, non-esoteric sense. Human judges may also be relying
significantly on personal tastes as we found no correlation between their
individual scores either.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3052</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3052</id><created>2013-09-12</created><authors><author><keyname>Cao</keyname><forenames>Ping</forenames></author><author><keyname>Dong</keyname><forenames>Zhao</forenames></author><author><keyname>Liu</keyname><forenames>Ke</forenames></author><author><keyname>Cai</keyname><forenames>Kai-Yuan</forenames></author></authors><title>Robust Dynamic Selection of Tested Modules in Software Testing for
  Maximizing Delivered Reliability</title><categories>cs.SE</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software testing is aimed to improve the delivered reliability of the users.
Delivered reliability is the reliability of using the software after it is
delivered to the users. Usually the software consists of many modules. Thus,
the delivered reliability is dependent on the operational profile which
specifies how the users will use these modules as well as the defect number
remaining in each module. Therefore, a good testing policy should take the
operational profile into account and dynamically select tested modules
according to the current state of the software during the testing process. This
paper discusses how to dynamically select tested modules in order to maximize
delivered reliability by formulating the selection problem as a dynamic
programming problem. As the testing process is performed only once, risk must
be considered during the testing process, which is described by the tester's
utility function in this paper. Besides, since usually the tester has no
accurate estimate of the operational profile, by employing robust optimization
technique, we analysis the selection problem in the worst case, given the
uncertainty set of operational profile. By numerical examples, we show the
necessity of maximizing delivered reliability directly and using robust
optimization technique when the tester has no clear idea of the operational
profile. Moreover, it is shown that the risk averse behavior of the tester has
a major influence on the delivered reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3060</identifier>
 <datestamp>2014-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3060</id><created>2013-09-12</created><updated>2013-12-18</updated><authors><author><keyname>Gwynne</keyname><forenames>Matthew</forenames></author><author><keyname>Kullmann</keyname><forenames>Oliver</forenames></author></authors><title>On SAT representations of XOR constraints</title><categories>cs.CC cs.AI</categories><comments>39 pages; 2nd v. improved handling of acyclic systems, free-standing
  proof of the transformation from AC-representations to monotone circuits,
  improved wording and literature review; 3rd v. updated literature,
  strengthened treatment of monotonisation, improved discussions; 4th v. update
  of literature, discussions and formulations, more details and examples;
  conference v. to appear LATA 2014</comments><acm-class>F.4.1; I.2.4</acm-class><journal-ref>LATA 2014: Language and Automata Theory and Applications, LNCS
  8370, pages 409-420</journal-ref><doi>10.1007/978-3-319-04921-2_33</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the representation of systems S of linear equations over the
two-element field (aka xor- or parity-constraints) via conjunctive normal forms
F (boolean clause-sets). First we consider the problem of finding an
&quot;arc-consistent&quot; representation (&quot;AC&quot;), meaning that unit-clause propagation
will fix all forced assignments for all possible instantiations of the
xor-variables. Our main negative result is that there is no polysize
AC-representation in general. On the positive side we show that finding such an
AC-representation is fixed-parameter tractable (fpt) in the number of
equations. Then we turn to a stronger criterion of representation, namely
propagation completeness (&quot;PC&quot;) --- while AC only covers the variables of S,
now all the variables in F (the variables in S plus auxiliary variables) are
considered for PC. We show that the standard translation actually yields a PC
representation for one equation, but fails so for two equations (in fact
arbitrarily badly). We show that with a more intelligent translation we can
also easily compute a translation to PC for two equations. We conjecture that
computing a representation in PC is fpt in the number of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3096</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3096</id><created>2013-09-12</created><authors><author><keyname>Goel</keyname><forenames>Neetu</forenames></author><author><keyname>Garg</keyname><forenames>R. B.</forenames></author></authors><title>Simulation of an Optimum Multilevel Dynamic Round Robin Scheduling
  Algorithm</title><categories>cs.OS</categories><comments>International Journal of Computer Applications, Aug 2013</comments><doi>10.5120/13263-0743</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CPU scheduling has valiant effect on resource utilization as well as overall
quality of the system. Round Robin algorithm performs optimally in time shared
systems, but it performs more number of context switches, larger waiting time
and larger response time. In order to simulate the behavior of various CPU
scheduling algorithms and to improve Round Robin scheduling algorithm using
dynamic time slice concept, in this paper we produce the implementation of new
CPU scheduling algorithm called An Optimum Multilevel Dynamic Round Robin
Scheduling (OMDRRS), which calculates intelligent time slice and warps after
every round of execution. The results display the robustness of this software,
especially for academic, research and experimental use, as well as proving the
desirability and efficiency of the probabilistic algorithm over the other
existing techniques and it is observed that this OMDRRS projects good
performance as compared to the other existing CPU scheduling algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3103</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3103</id><created>2013-09-12</created><authors><author><keyname>H&#xe4;usler</keyname><forenames>Chris</forenames></author><author><keyname>Susemihl</keyname><forenames>Alex</forenames></author><author><keyname>Nawrot</keyname><forenames>Martin P</forenames></author><author><keyname>Opper</keyname><forenames>Manfred</forenames></author></authors><title>Temporal Autoencoding Improves Generative Models of Time Series</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restricted Boltzmann Machines (RBMs) are generative models which can learn
useful representations from samples of a dataset in an unsupervised fashion.
They have been widely employed as an unsupervised pre-training method in
machine learning. RBMs have been modified to model time series in two main
ways: The Temporal RBM stacks a number of RBMs laterally and introduces
temporal dependencies between the hidden layer units; The Conditional RBM, on
the other hand, considers past samples of the dataset as a conditional bias and
learns a representation which takes these into account. Here we propose a new
training method for both the TRBM and the CRBM, which enforces the dynamic
structure of temporal datasets. We do so by treating the temporal models as
denoising autoencoders, considering past frames of the dataset as corrupted
versions of the present frame and minimizing the reconstruction error of the
present data by the model. We call this approach Temporal Autoencoding. This
leads to a significant improvement in the performance of both models in a
filling-in-frames task across a number of datasets. The error reduction for
motion capture data is 56\% for the CRBM and 80\% for the TRBM. Taking the
posterior mean prediction instead of single samples further improves the
model's estimates, decreasing the error by as much as 91\% for the CRBM on
motion capture data. We also trained the model to perform forecasting on a
large number of datasets and have found TA pretraining to consistently improve
the performance of the forecasts. Furthermore, by looking at the prediction
error across time, we can see that this improvement reflects a better
representation of the dynamics of the data as opposed to a bias towards
reconstructing the observed data on a short time scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3117</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3117</id><created>2013-09-12</created><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA Paris - Rocquencourt, LIENS</affiliation></author></authors><title>Convex relaxations of structured matrix factorizations</title><categories>cs.LG math.OC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the factorization of a rectangular matrix $X $ into a positive
linear combination of rank-one factors of the form $u v^\top$, where $u$ and
$v$ belongs to certain sets $\mathcal{U}$ and $\mathcal{V}$, that may encode
specific structures regarding the factors, such as positivity or sparsity. In
this paper, we show that computing the optimal decomposition is equivalent to
computing a certain gauge function of $X$ and we provide a detailed analysis of
these gauge functions and their polars. Since these gauge functions are
typically hard to compute, we present semi-definite relaxations and several
algorithms that may recover approximate decompositions with approximation
guarantees. We illustrate our results with simulations on finding
decompositions with elements in $\{0,1\}$. As side contributions, we present a
detailed analysis of variational quadratic representations of norms as well as
a new iterative basis pursuit algorithm that can deal with inexact first-order
oracles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3126</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3126</id><created>2013-09-12</created><updated>2014-05-18</updated><authors><author><keyname>Kotremba</keyname><forenames>J.</forenames></author><author><keyname>Ra&#xdf;</keyname><forenames>S.</forenames></author><author><keyname>Singer</keyname><forenames>R.</forenames></author></authors><title>Distributed Business Processes - A Framework for Modeling and Execution</title><categories>cs.MA cs.SE</categories><msc-class>D.2.12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commercially available business process management systems (BPMS) still
suffer to support organizations to enact their business processes in an
effective and efficient way. Current BPMS, in general, are based on BPMN 2.0
and/or BPEL. It is well known, that these approaches have some restrictions
according modeling and immediate transfer of the model into executable code.
Recently, a method for modeling and execution of business processes, named
subject-oriented business process management (S-BPM), gained attention. This
methodology facilitates modeling of any business process using only five
symbols and allows direct execution based on such models. Further on, this
methodology has a strong theoretical and formal basis realizing distributed
systems; any process is defined as a network of independent and distributed
agents - i.e. instances of subjects - which coordinate work through the
exchange of messages. In this work, we present a framework and a prototype
based on off-the-shelf technologies as a possible realization of the S-BPM
methodology. We can prove and demonstrate the principal architecture concept;
these results should also stimulate a discussion about actual BPMS and its
underlying concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3128</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3128</id><created>2013-09-12</created><authors><author><keyname>Le</keyname><forenames>Ton Chanh</forenames></author></authors><title>Preliminary Notes on Termination and Non-Termination Reasoning</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this preliminary note, we will illustrate our ideas on automated
mechanisms for termination and non-termination reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3132</identifier>
 <datestamp>2014-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3132</id><created>2013-09-12</created><updated>2014-06-25</updated><authors><author><keyname>Jin</keyname><forenames>Xiao-Bo</forenames></author><author><keyname>Geng</keyname><forenames>Guang-Gang</forenames></author><author><keyname>Zhang</keyname><forenames>Dexian</forenames></author></authors><title>Combination of Multiple Bipartite Ranking for Web Content Quality
  Evaluation</title><categories>cs.IR</categories><comments>17 pages, 8 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web content quality estimation is crucial to various web content processing
applications. Our previous work applied Bagging + C4.5 to achive the best
results on the ECML/PKDD Discovery Challenge 2010, which is the comibination of
many point-wise rankinig models. In this paper, we combine multiple pair-wise
bipartite ranking learner to solve the multi-partite ranking problems for the
web quality estimation. In encoding stage, we present the ternary encoding and
the binary coding extending each rank value to $L - 1$ (L is the number of the
different ranking value). For the decoding, we discuss the combination of
multiple ranking results from multiple bipartite ranking models with the
predefined weighting and the adaptive weighting. The experiments on ECML/PKDD
2010 Discovery Challenge datasets show that \textit{binary coding} +
\textit{predefined weighting} yields the highest performance in all four
combinations and furthermore it is better than the best results reported in
ECML/PKDD 2010 Discovery Challenge competition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3139</identifier>
 <datestamp>2014-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3139</id><created>2013-09-12</created><updated>2014-09-03</updated><authors><author><keyname>Limmer</keyname><forenames>Steffen</forenames></author><author><keyname>Stanczak</keyname><forenames>Slawomir</forenames></author><author><keyname>Goldenbaum</keyname><forenames>Mario</forenames></author><author><keyname>Cavalcante</keyname><forenames>Renato L. G.</forenames></author></authors><title>Exploiting Interference for Efficient Distributed Computation in
  Cluster-based Wireless Sensor Networks</title><categories>cs.DC cs.IT math.IT</categories><comments>Accepted for publication at IEEE Global Conference on Signal and
  Information Processing (GlobalSIP 2013)</comments><doi>10.1109/GlobalSIP.2013.6737045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This invited paper presents some novel ideas on how to enhance the
performance of consensus algorithms in distributed wireless sensor networks,
when communication costs are considered. Of particular interest are consensus
algorithms that exploit the broadcast property of the wireless channel to boost
the performance in terms of convergence speeds. To this end, we propose a novel
clustering based consensus algorithm that exploits interference for
computation, while reducing the energy consumption in the network. The
resulting optimization problem is a semidefinite program, which can be solved
offline prior to system startup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3147</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3147</id><created>2013-09-12</created><authors><author><keyname>Saadeh</keyname><forenames>Mahmood</forenames></author><author><keyname>McCann</keyname><forenames>Roy</forenames></author></authors><title>Improved Stability Design of Interconnected Distributed Generation
  Resources</title><categories>cs.SY</categories><comments>6 pages, 12 figures, IEEE North American Power Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work provides a design method for achieving a specified level of
stability for inverter-based interconnected distributed generation. The
stability of parallel connected distributed energy resources determined from a
linearized state-space model of the inverter dynamics that includes the
admittance matrix of the interconnecting distribution lines. Each inverter uses
a localized droop control scheme with the associated voltage and frequency
measurements obtained through the application of an enhanced phase locked loop.
Previous work on this topic has focused on single inverters connected to an
infinite bus without modeling of delays from a phase locked loop
implementation. This proposed method overcomes both of these limitations of
previous research. A detailed large-signal simulation of a three-bus
interconnected power system is analyzed under two different network admittance
values. Results confirm the effectiveness of the proposed stability design
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3150</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3150</id><created>2013-09-12</created><updated>2013-10-04</updated><authors><author><keyname>Borokhovich</keyname><forenames>Michael</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>How (Not) to Shoot in Your Foot with SDN Local Fast Failover: A
  Load-Connectivity Tradeoff</title><categories>cs.NI cs.DC</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the resilient routing and (in-band) fast failover
mechanisms supported in Software-Defined Networks (SDN). We analyze the
potential benefits and limitations of such failover mechanisms, and focus on
two main metrics: (1) correctness (in terms of connectivity and loop-freeness)
and (2) load-balancing. We make the following contributions. First, we show
that in the worst-case (i.e., under adversarial link failures), the usefulness
of local failover is rather limited: already a small number of failures will
violate connectivity properties under any fast failover policy, even though the
underlying substrate network remains highly connected. We then present
randomized and deterministic algorithms to compute resilient forwarding sets;
these algorithms achieve an almost optimal tradeoff. Our worst-case analysis is
complemented with a simulation study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3151</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3151</id><created>2013-09-10</created><authors><author><keyname>Garin</keyname><forenames>Federica</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / Gipsa-lab, GIPSA-lab</affiliation></author><author><keyname>Yuan</keyname><forenames>Ye</forenames></author></authors><title>Distributed privacy-preserving network size computation: A
  system-identification based method</title><categories>math.OC cs.DC cs.SY math.DS</categories><comments>52nd IEEE Conference on Decision and Control (CDC 2013) (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we propose an algorithm for computing the network size of
communicating agents. The algorithm is distributed: a) it does not require a
leader selection; b) it only requires local exchange of information, and; c)
its design can be implemented using local information only, without any global
information about the network. It is privacy-preserving, namely it does not
require to propagate identifying labels. This algorithm is based on system
identification, and more precisely on the identification of the order of a
suitably-constructed discrete-time linear time-invariant system over some
finite field. We provide a probabilistic guarantee for any randomly picked node
to correctly compute the number of nodes in the network. Moreover, numerical
implementation has been taken into account to make the algorithm applicable to
networks of hundreds of nodes, and therefore make the algorithm applicable in
real-world sensor or robotic networks. We finally illustrate our results in
simulation and conclude the paper with discussions on how our technique differs
from a previously-known strategy based on statistical inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3173</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3173</id><created>2013-09-12</created><authors><author><keyname>Cao</keyname><forenames>Congzhe</forenames></author><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Low Complexity List Successive Cancellation Decoding of Polar Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a low complexity list successive cancellation (LCLSC) decoding
algorithm to reduce complexity of traditional list successive cancellation
(LSC) decoding of polar codes while trying to maintain the LSC decoding
performance at the same time. By defining two thresholds, namely &quot;likelihood
ratio (LR) threshold&quot; and &quot;Bhattacharyya parameter threshold&quot;, we classify the
reliability of each received information bit and the quality of each bit
channel. Based on this classification, we implement successive cancellation
(SC) decoding instead of LSC decoding when the information bits from &quot;bad&quot;
subchannels are received reliably and further attempt to skip LSC decoding for
the rest information bits in order to achieve a lower complexity compared to
full LSC decoding. Simulation results show that the complexity of LCLSC
decoding is much lower than LSC decoding and can be close to that of SC
decoding, especially in low code rate regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3187</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3187</id><created>2013-09-12</created><authors><author><keyname>As&#xed;n</keyname><forenames>Roberto</forenames></author><author><keyname>Olate</keyname><forenames>Juan</forenames></author><author><keyname>Ferres</keyname><forenames>Leo</forenames></author></authors><title>Cache Performance Study of Portfolio-Based Parallel CDCL SAT Solvers</title><categories>cs.DC cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel SAT solvers are becoming mainstream. Their performance has made them
win the past two SAT competitions consecutively and are in the limelight of
research and industry. The problem is that it is not known exactly what is
needed to make them perform even better; that is, how to make them solve more
problems in less time. Also, it is also not know how well they scale in massive
multi-core environments which, predictably, is the scenario of comming new
hardware. In this paper we show that cache contention is a main culprit of a
slowing down in scalability, and provide empirical results that for some type
of searches, physically sharing the clause Database between threads is
beneficial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3193</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3193</id><created>2013-09-12</created><authors><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Cohen</keyname><forenames>Asaf</forenames></author><author><keyname>Haddad</keyname><forenames>Yoram</forenames></author><author><keyname>Kantor</keyname><forenames>Erez</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author><author><keyname>Parter</keyname><forenames>Merav</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author></authors><title>SINR Diagram with Interference Cancellation</title><categories>cs.CG cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the reception zones of a wireless network in the SINR
model with receivers that employ \emph{interference cancellation} (IC), a
technique that allows a receiver to decode interfering signals, and
\emph{cancel} them from the received signal in order to decode its intended
message. We first derive some important topological properties of the diagram
describing the reception zones and their connections to \emph{high-order
Voronoi diagrams} and other related geometric objects. We then discuss the
computational issues that arise when seeking an efficient description of the
zones. Our main fundamental result states that although potentially there are
exponentially many possible cancellation orderings (and consequently reception
cells), in fact there are much fewer nonempty such cells. We prove a (tight)
linear bound on the number of cells and provide a polynomial time algorithm to
describe the diagram. Moreover, we introduce a novel measure, referred to as
the \emph{Compactness Parameter}, which influences the tightness of our bounds.
We then utilize the properties established for reception diagrams to devise a
logarithmic time algorithm for answering \emph{point-location} queries for
networks with IC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3195</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3195</id><created>2013-09-12</created><authors><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Cao</keyname><forenames>Congzhe</forenames></author><author><keyname>Xiao</keyname><forenames>Ming</forenames></author><author><keyname>Hussain</keyname><forenames>Iqbal</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Improved LT Codes in Low Overhead Regions for Binary Erasure Channels</title><categories>cs.IT math.IT</categories><comments>8 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study improved degree distribution for Luby Transform (LT) codes which
exhibits improved bit error rate performance particularly in low overhead
regions. We construct the degree distribution by modifying Robust Soliton
distribution. The performance of our proposed LT codes is evaluated and
compared to the conventional LT codes via And-Or tree analysis. Then we propose
a transmission scheme based on the proposed degree distribution to improve its
frame error rate in full recovery regions. Furthermore, the improved degree
distribution is applied to distributed multi-source relay networks and unequal
error protection. It is shown that our schemes achieve better performance and
reduced complexity especially in low overhead regions, compared with
conventional schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3197</identifier>
 <datestamp>2013-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3197</id><created>2013-09-12</created><updated>2013-10-22</updated><authors><author><keyname>Carvalho</keyname><forenames>Arthur</forenames></author><author><keyname>Dimitrov</keyname><forenames>Stanko</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author></authors><title>Inducing Honest Reporting Without Observing Outcomes: An Application to
  the Peer-Review Process</title><categories>cs.MA cs.AI cs.DL math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When eliciting opinions from a group of experts, traditional devices used to
promote honest reporting assume that there is an observable future outcome. In
practice, however, this assumption is not always reasonable. In this paper, we
propose a scoring method built on strictly proper scoring rules to induce
honest reporting without assuming observable outcomes. Our method provides
scores based on pairwise comparisons between the reports made by each pair of
experts in the group. For ease of exposition, we introduce our scoring method
by illustrating its application to the peer-review process. In order to do so,
we start by modeling the peer-review process using a Bayesian model where the
uncertainty regarding the quality of the manuscript is taken into account.
Thereafter, we introduce our scoring method to evaluate the reported reviews.
Under the assumptions that reviewers are Bayesian decision-makers and that they
cannot influence the reviews of other reviewers, we show that risk-neutral
reviewers strictly maximize their expected scores by honestly disclosing their
reviews. We also show how the group's scores can be used to find a consensual
review. Experimental results show that encouraging honest reporting through the
proposed scoring method creates more accurate reviews than the traditional
peer-review process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3200</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3200</id><created>2013-09-12</created><updated>2014-09-03</updated><authors><author><keyname>Di Lorenzo</keyname><forenames>Paolo</forenames></author><author><keyname>Barbarossa</keyname><forenames>Sergio</forenames></author></authors><title>Distributed Estimation and Control of Algebraic Connectivity over Random
  Graphs</title><categories>cs.DC</categories><comments>To appear in IEEE Transactions on Signal Processing</comments><journal-ref>IEEE Taransactions on Signal Processing vol. 62, no. 21, pp.
  5615-5628, Nov. 2014</journal-ref><doi>10.1109/TSP.2014.2355778</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a distributed algorithm for the estimation and
control of the connectivity of ad-hoc networks in the presence of a random
topology. First, given a generic random graph, we introduce a novel stochastic
power iteration method that allows each node to estimate and track the
algebraic connectivity of the underlying expected graph. Using results from
stochastic approximation theory, we prove that the proposed method converges
almost surely (a.s.) to the desired value of connectivity even in the presence
of imperfect communication scenarios. The estimation strategy is then used as a
basic tool to adapt the power transmitted by each node of a wireless network,
in order to maximize the network connectivity in the presence of realistic
Medium Access Control (MAC) protocols or simply to drive the connectivity
toward a desired target value. Numerical results corroborate our theoretical
findings, thus illustrating the main features of the algorithm and its
robustness to fluctuations of the network graph due to the presence of random
link failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3201</identifier>
 <datestamp>2015-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3201</id><created>2013-09-12</created><authors><author><keyname>Bokowski</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Pilaud</keyname><forenames>Vincent</forenames></author></authors><title>On topological and geometric $(19_4)$ configurations</title><categories>cs.CG math.CO</categories><comments>13 pages, 7 figures</comments><msc-class>52C30, 68-04</msc-class><journal-ref>European J. Combin., 50:4-17, 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $(n_k)$ configuration is a set of $n$ points and $n$ lines such that each
point lies on $k$ lines while each line contains $k$ points. The configuration
is geometric, topological, or combinatorial depending on whether lines are
considered to be straight lines, pseudolines, or just combinatorial lines. The
existence and enumeration of $(n_k)$ configurations for a given $k$ has been
subject to active research. A current front of research concerns geometric
$(n_4)$ configurations: it is now known that geometric $(n_4)$ configurations
exist for all $n \ge 18$, apart from sporadic exceptional cases. In this paper,
we settle by computational techniques the first open case of $(19_4)$
configurations: we obtain all topological $(19_4)$ configurations among which
none are geometrically realizable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3210</identifier>
 <datestamp>2015-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3210</id><created>2013-09-12</created><updated>2015-11-08</updated><authors><author><keyname>Rutanen</keyname><forenames>Kalle</forenames></author><author><keyname>G&#xf3;mez-Herrero</keyname><forenames>Germ&#xe1;n</forenames></author><author><keyname>Eriksson</keyname><forenames>Sirkka-Liisa</forenames></author><author><keyname>Egiazarian</keyname><forenames>Karen</forenames></author></authors><title>A general definition of the O-notation for algorithm analysis</title><categories>cs.DS</categories><comments>Added missing reference</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an extensive list of desirable properties for an O-notation --- as
used in algorithm analysis --- and reduce them to 8 primitive properties. We
prove that the primitive properties are equivalent to the definition of the
O-notation as linear dominance. We abstract the existing definitions of the
O-notation under local linear dominance, and show that it has a
characterization by limits over filters for positive functions. We define the
O-mappings as a general tool for manipulating the O-notation, and show that
Master theorems hold under linear dominance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3214</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3214</id><created>2013-09-12</created><authors><author><keyname>Wang</keyname><forenames>Li</forenames></author><author><keyname>Shao</keyname><forenames>Jie</forenames></author><author><keyname>Zhong</keyname><forenames>Yaqin</forenames></author><author><keyname>Zhao</keyname><forenames>Weisong</forenames></author><author><keyname>Malekian</keyname><forenames>Reza</forenames></author></authors><title>Modeling Based on Elman Wavelet Neural Network for Class-D Power
  Amplifiers</title><categories>cs.NE</categories><journal-ref>Applied Mathematics &amp; Information Sciences, Volume 7, No. 6 (Nov.
  2013), PP:2445-2453</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Class-D Power Amplifiers (CDPAs), the power supply noise can intermodulate
with the input signal, manifesting into power-supply induced intermodulation
distortion (PS-IMD) and due to the memory effects of the system, there exist
asymmetries in the PS-IMDs. In this paper, a new behavioral modeling based on
the Elman Wavelet Neural Network (EWNN) is proposed to study the nonlinear
distortion of the CDPAs. In EWNN model, the Morlet wavelet functions are
employed as the activation function and there is a normalized operation in the
hidden layer, the modification of the scale factor and translation factor in
the wavelet functions are ignored to avoid the fluctuations of the error
curves. When there are 30 neurons in the hidden layer, to achieve the same
square sum error (SSE) $\epsilon_{min}=10^{-3}$, EWNN needs 31 iteration steps,
while the basic Elman neural network (BENN) model needs 86 steps. The
Volterra-Laguerre model has 605 parameters to be estimated but still can't
achieve the same magnitude accuracy of EWNN. Simulation results show that the
proposed approach of EWNN model has fewer parameters and higher accuracy than
the Volterra-Laguerre model and its convergence rate is much faster than the
BENN model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3223</identifier>
 <datestamp>2013-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3223</id><created>2013-09-12</created><updated>2013-12-06</updated><authors><author><keyname>Gharan</keyname><forenames>Shayan Oveis</forenames></author><author><keyname>Trevisan</keyname><forenames>Luca</forenames></author></authors><title>Partitioning into Expanders</title><categories>cs.DS math.SP stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E) be an undirected graph, lambda_k be the k-th smallest eigenvalue
of the normalized laplacian matrix of G. There is a basic fact in algebraic
graph theory that lambda_k &gt; 0 if and only if G has at most k-1 connected
components. We prove a robust version of this fact. If lambda_k&gt;0, then for
some 1\leq \ell\leq k-1, V can be {\em partitioned} into l sets P_1,\ldots,P_l
such that each P_i is a low-conductance set in G and induces a high conductance
induced subgraph. In particular, \phi(P_i)=O(l^3\sqrt{\lambda_l}) and
\phi(G[P_i]) &gt;= \lambda_k/k^2).
  We make our results algorithmic by designing a simple polynomial time
spectral algorithm to find such partitioning of G with a quadratic loss in the
inside conductance of P_i's. Unlike the recent results on higher order
Cheeger's inequality [LOT12,LRTV12], our algorithmic results do not use higher
order eigenfunctions of G. If there is a sufficiently large gap between
lambda_k and lambda_{k+1}, more precisely, if \lambda_{k+1} &gt;= \poly(k)
lambda_{k}^{1/4} then our algorithm finds a k partitioning of V into sets
P_1,...,P_k such that the induced subgraph G[P_i] has a significantly larger
conductance than the conductance of P_i in G. Such a partitioning may represent
the best k clustering of G. Our algorithm is a simple local search that only
uses the Spectral Partitioning algorithm as a subroutine. We expect to see
further applications of this simple algorithm in clustering applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3228</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3228</id><created>2013-09-12</created><updated>2014-09-27</updated><authors><author><keyname>Mosonyi</keyname><forenames>Milan</forenames></author><author><keyname>Ogawa</keyname><forenames>Tomohiro</forenames></author></authors><title>Quantum hypothesis testing and the operational interpretation of the
  quantum Renyi relative entropies</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>v5: Added Appendix A on monotonicity and attainability properties</comments><journal-ref>Communications in Mathematical Physics: Volume 334, Issue 3
  (2015), Page 1617-1648</journal-ref><doi>10.1007/s00220-014-2248-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the new quantum extension of Renyi's \alpha-relative entropies,
introduced recently by Muller-Lennert, Dupuis, Szehr, Fehr and Tomamichel, J.
Math. Phys. 54, 122203, (2013), and Wilde, Winter, Yang, Commun. Math. Phys.
331, (2014), have an operational interpretation in the strong converse problem
of quantum hypothesis testing. Together with related results for the direct
part of quantum hypothesis testing, known as the quantum Hoeffding bound, our
result suggests that the operationally relevant definition of the quantum Renyi
relative entropies depends on the parameter \alpha: for \alpha&lt;1, the right
choice seems to be the traditional definition, whereas for \alpha&gt;1 the right
choice is the newly introduced version.
  As a sideresult, we show that the new Renyi \alpha-relative entropies are
asymptotically attainable by measurements for \alpha&gt;1, and give a new simple
proof for their monotonicity under completely positive trace-preserving maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3233</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3233</id><created>2013-09-12</created><authors><author><keyname>Kir&#xe1;ly</keyname><forenames>Franz J.</forenames></author></authors><title>Efficient Orthogonal Tensor Decomposition, with an Application to Latent
  Variable Model Learning</title><categories>stat.ML cs.LG math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decomposing tensors into orthogonal factors is a well-known task in
statistics, machine learning, and signal processing. We study orthogonal outer
product decompositions where the factors in the summands in the decomposition
are required to be orthogonal across summands, by relating this orthogonal
decomposition to the singular value decompositions of the flattenings. We show
that it is a non-trivial assumption for a tensor to have such an orthogonal
decomposition, and we show that it is unique (up to natural symmetries) in case
it exists, in which case we also demonstrate how it can be efficiently and
reliably obtained by a sequence of singular value decompositions. We
demonstrate how the factoring algorithm can be applied for parameter
identification in latent variable and mixture models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3235</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3235</id><created>2013-09-12</created><authors><author><keyname>Ajouli</keyname><forenames>Akram</forenames><affiliation>LINA, INRIA - EMN</affiliation></author><author><keyname>Cohen</keyname><forenames>Julien</forenames><affiliation>LINA</affiliation></author><author><keyname>Royer</keyname><forenames>Jean-Claude</forenames><affiliation>LINA, INRIA - EMN</affiliation></author></authors><title>Transformations between Composite and Visitor implementations in Java</title><categories>cs.SE</categories><comments>39th Euromicro Conference on Software Engineering and Advanced
  Applications (SEAA 2013), Santander : Spain (2013). arXiv admin note:
  substantial text overlap with arXiv:1112.4271</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Basic automated refactoring operations can be chained to perform complex
structure transformations. This is useful for recovering the initial
architecture of a source code which has been degenerated with successive
evolutions during its maintenance lifetime. This is also useful for changing
the structure of a program so that a maintenance task at hand becomes modular
when it would be initially crosscutting. We focus on programs structured
according to Composite and Visitor design patterns, which have dual properties
with respect to modularity. We consider a refactoring-based round-trip
transformation between these two structures and we study how that
transformation is impacted by four variations in the implementation of these
patterns. We validate that study by computing the smallest preconditions for
the resulting transformations. We also automate the transformation and apply it
to JHotDraw, where the studied variations occur.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3242</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3242</id><created>2013-09-12</created><authors><author><keyname>Afrakoti</keyname><forenames>Iman Esmaili Paeen</forenames></author><author><keyname>Shouraki</keyname><forenames>Saeed Bagheri</forenames></author><author><keyname>Merrikhbayat</keyname><forenames>Farnood</forenames></author></authors><title>Using memristor crossbar structure to implement a novel adaptive real
  time fuzzy modeling algorithm</title><categories>cs.AI</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although fuzzy techniques promise fast meanwhile accurate modeling and
control abilities for complicated systems, di?erent di?culties have been
re-vealed in real situation implementations. Usually there is no escape of
it-erative optimization based on crisp domain algorithms. Recently memristor
structures appeared promising to implement neural network structures and fuzzy
algorithms. In this paper a novel adaptive real-time fuzzy modeling algorithm
is proposed which uses active learning method concept to mimic recent
understandings of right brain processing techniques. The developed method is
based on processing fuzzy numbers to provide the ability of being sensitive to
each training data point to expand the knowledge tree leading to plasticity
while used defuzzi?cation technique guaranties enough stability. An outstanding
characteristic of the proposed algorithm is its consistency to memristor
crossbar hardware processing concepts. An analog implemen-tation of the
proposed algorithm on memristor crossbars structure is also introduced in this
paper. The e?ectiveness of the proposed algorithm in modeling and pattern
recognition tasks is veri?ed by means of computer simulations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3256</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3256</id><created>2013-09-12</created><updated>2014-02-02</updated><authors><author><keyname>Nellore</keyname><forenames>Abhinav</forenames></author><author><keyname>Ward</keyname><forenames>Rachel</forenames></author></authors><title>Recovery guarantees for exemplar-based clustering</title><categories>stat.ML cs.CV cs.LG</categories><comments>24 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a certain class of distributions, we prove that the linear programming
relaxation of $k$-medoids clustering---a variant of $k$-means clustering where
means are replaced by exemplars from within the dataset---distinguishes points
drawn from nonoverlapping balls with high probability once the number of points
drawn and the separation distance between any two balls are sufficiently large.
Our results hold in the nontrivial regime where the separation distance is
small enough that points drawn from different balls may be closer to each other
than points drawn from the same ball; in this case, clustering by thresholding
pairwise distances between points can fail. We also exhibit numerical evidence
of high-probability recovery in a substantially more permissive regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3260</identifier>
 <datestamp>2013-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3260</id><created>2013-09-12</created><authors><author><keyname>Chu</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Sethu</keyname><forenames>Harish</forenames></author></authors><title>Cooperative Topology Control with Adaptation for Improved Lifetime in
  Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Topology control algorithms allow each node in a wireless multi-hop network
to adjust the power at which it makes its transmissions and choose the set of
neighbors with which it communicates directly, while preserving global goals
such as connectivity or coverage. This allows each node to conserve energy and
contribute to increasing the lifetime of the network. In this paper, in
contrast to most previous work, we consider (i) both the energy costs of
communication as well as the amount of available energy at each node, (ii) the
realistic situation of varying rates of energy consumption at different nodes,
and (iii) the fact that co-operation between nodes, where some nodes make a
sacrifice by increasing energy consumption to help other nodes reduce their
consumption, can be used to extend network lifetime. This paper introduces a
new distributed topology control algorithm, called the Cooperative Topology
Control with Adaptation (CTCA), based on a game-theoretic approach that maps
the problem of maximizing the network's lifetime into an ordinal potential
game. We prove the existence of a Nash equilibrium for the game. Our simulation
results indicate that the CTCA algorithm extends the life of a network by more
than 50% compared to the best previously-known algorithm. We also study the
performance of the distributed CTCA algorithm in comparison to an optimal
centralized algorithm as a function of the communication ranges of nodes and
node density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3284</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3284</id><created>2013-09-12</created><authors><author><keyname>Chu</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Sethu</keyname><forenames>Harish</forenames></author></authors><title>An Energy Balanced Dynamic Topology Control Algorithm for Improved
  Network Lifetime</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless sensor networks, a few sensor nodes end up being vulnerable to
potentially rapid depletion of the battery reserves due to either their central
location or just the traffic patterns generated by the application. Traditional
energy management strategies, such as those which use topology control
algorithms, reduce the energy consumed at each node to the minimum necessary.
In this paper, we use a different approach that balances the energy consumption
at each of the nodes, thus increasing the functional lifetime of the network.
We propose a new distributed dynamic topology control algorithm called Energy
Balanced Topology Control (EBTC) which considers the actual energy consumed for
each transmission and reception to achieve the goal of an increased functional
lifetime. We analyze the algorithm's computational and communication complexity
and show that it is equivalent or lower in complexity to other dynamic topology
control algorithms. Using an empirical model of energy consumption, we show
that the EBTC algorithm increases the lifetime of a wireless sensor network by
over 40% compared to the best of previously known algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3285</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3285</id><created>2013-09-12</created><authors><author><keyname>Hooshmand</keyname><forenames>Salman</forenames></author><author><keyname>Behshameh</keyname><forenames>Mehdi</forenames></author><author><keyname>Hamidi</keyname><forenames>Omid</forenames></author></authors><title>A tabu search algorithm with efficient diversification strategy for high
  school timetabling problem</title><categories>cs.AI</categories><doi>10.5121/ijcsit.2013.5402</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The school timetabling problem can be described as scheduling a set of
lessons (combination of classes, teachers, subjects and rooms) in a weekly
timetable. This paper presents a novel way to generate timetables for high
schools. The algorithm has three phases. Pre-scheduling, initial phase and
optimization through tabu search. In the first phase, a graph based algorithm
used to create groups of lessons to be scheduled simultaneously; then an
initial solution is built by a sequential greedy heuristic. Finally, the
solution is optimized using tabu search algorithm based on frequency based
diversification. The algorithm has been tested on a set of real problems
gathered from Iranian high schools. Experiments show that the proposed
algorithm can effectively build acceptable timetables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3292</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3292</id><created>2013-09-12</created><authors><author><keyname>Greferath</keyname><forenames>Marcus</forenames></author><author><keyname>Honold</keyname><forenames>Thomas</forenames></author><author><keyname>Fadden</keyname><forenames>Cathy Mc</forenames></author><author><keyname>Wood</keyname><forenames>Jay A.</forenames></author><author><keyname>Zumbr&#xe4;gel</keyname><forenames>Jens</forenames></author></authors><title>MacWilliams' Extension Theorem for Bi-Invariant Weights over Finite
  Principal Ideal Rings</title><categories>math.RA cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A finite ring R and a weight w on R satisfy the Extension Property if every
R-linear w-isometry between two R-linear codes in R^n extends to a monomial
transformation of R^n that preserves w. MacWilliams proved that finite fields
with the Hamming weight satisfy the Extension Property. It is known that finite
Frobenius rings with either the Hamming weight or the homogeneous weight
satisfy the Extension Property. Conversely, if a finite ring with the Hamming
or homogeneous weight satisfies the Extension Property, then the ring is
Frobenius.
  This paper addresses the question of a characterization of all bi-invariant
weights on a finite ring that satisfy the Extension Property. Having solved
this question in previous papers for all direct products of finite chain rings
and for matrix rings, we have now arrived at a characterization of these
weights for finite principal ideal rings, which form a large subclass of the
finite Frobenius rings. We do not assume commutativity of the rings in
question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3297</identifier>
 <datestamp>2013-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3297</id><created>2013-09-12</created><updated>2013-10-30</updated><authors><author><keyname>Bruhn</keyname><forenames>Henning</forenames></author><author><keyname>Schaudt</keyname><forenames>Oliver</forenames></author></authors><title>The journey of the union-closed sets conjecture</title><categories>math.CO cs.DM</categories><comments>Some errors fixed and updated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey the state of the union-closed sets conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3303</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3303</id><created>2013-09-12</created><authors><author><keyname>Sharad</keyname><forenames>Mrigank</forenames></author><author><keyname>Fan</keyname><forenames>D.</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>Spin Neurons: A Possible Path to Energy-Efficient Neuromorphic Computers</title><categories>cond-mat.dis-nn cs.ET q-bio.NC</categories><doi>10.1063/1.4838096</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed growing interest in the field of brain-inspired
computing based on neural-network architectures. In order to translate the
related algorithmic models into powerful, yet energy-efficient
cognitive-computing hardware, computing-devices beyond CMOS may need to be
explored. The suitability of such devices to this field of computing would
strongly depend upon how closely their physical characteristics match with the
essential computing primitives employed in such models. In this work we discuss
the rationale of applying emerging spin-torque devices for bio-inspired
computing. Recent spin-torque experiments have shown the path to low-current,
low-voltage and high-speed magnetization switching in nano-scale magnetic
devices. Such magneto-metallic, current-mode spin-torque switches can mimic the
analog summing and thresholding operation of an artificial neuron with high
energy-efficiency. Comparison with CMOS-based analog circuit-model of neuron
shows that spin neurons can achieve more than two orders of magnitude lower
energy and beyond three orders of magnitude reduction in energy-delay product.
The application of spin neurons can therefore be an attractive option for
neuromorphic computers of future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3307</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3307</id><created>2013-09-12</created><authors><author><keyname>Hamidi-Sepehr</keyname><forenames>Fatemeh</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Chamberland</keyname><forenames>Jean-Francois</forenames></author></authors><title>Delay-Sensitive Communication over Fading Channel: Queueing Behavior and
  Code Parameter Selection</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article examines the queueing performance of communication systems that
transmit encoded data over unreliable channels. A fading formulation suitable
for wireless environments is considered where errors are caused by a discrete
channel with correlated behavior over time. Random codes and BCH codes are
employed as means to study the relationship between code-rate selection and the
queueing performance of point-to-point data links. For carefully selected
channel models and arrival processes, a tractable Markov structure composed of
queue length and channel state is identified. This facilitates the analysis of
the stationary behavior of the system, leading to evaluation criteria such as
bounds on the probability of the queue exceeding a threshold. Specifically,
this article focuses on system models with scalable arrival profiles, which are
based on Poisson processes, and finite-state channels with memory. These
assumptions permit the rigorous comparison of system performance for codes with
arbitrary block lengths and code rates. Based on the resulting
characterizations, it is possible to select the best code parameters for
delay-sensitive applications over various channels. The methodology introduced
herein offers a new perspective on the joint queueing-coding analysis of
finitestate channels with memory, and it is supported by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3314</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3314</id><created>2013-09-12</created><authors><author><keyname>Abderrahim</keyname><forenames>Zeineb</forenames></author><author><keyname>Techini</keyname><forenames>Elhem</forenames></author><author><keyname>Bouhlel</keyname><forenames>Mohamed Salim</forenames></author></authors><title>Progressive Compression of 3D Objects with an Adaptive Quantization</title><categories>cs.GR cs.CG cs.MM</categories><comments>8 pages, 5 figures</comments><journal-ref>IJCSI Volume 10, Issue 2,No 1, March 2013 , Pages 504-511</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new progressive compression method for triangular
meshes. This method, in fact, is based on a schema of irregular
multi-resolution analysis and is centered on the optimization of the
rate-distortion trade-off. The quantization precision is adapted to each vertex
during the encoding / decoding process to optimize the rate-distortion
compromise. The Optimization of the treated mesh geometry improves the
approximation quality and the compression ratio at each level of resolution.
The experimental results show that the proposed algorithm gives competitive
results compared to the previous works dealing with the rate-distortion
compromise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3317</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3317</id><created>2013-09-12</created><authors><author><keyname>Hern&#xe1;ndez</keyname><forenames>Debbie</forenames></author><author><keyname>Casta&#xf1;os</keyname><forenames>Fernando</forenames></author><author><keyname>Fridman</keyname><forenames>Leonid</forenames></author></authors><title>Pole-placement in higher-order sliding-mode control</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the well-known formula by Ackermann and Utkin can be generalized
to the case of higher-order sliding modes. By interpreting the eigenvalue
assignment of the sliding dynamics as a zero-placement problem, the
generalization becomes straightforward and the proof is greatly simplified. The
generalized formula retains the simplicity of the original one while allowing
to construct the sliding variable of a single-input linear time-invariant
system in such a way that it has desired relative degree and desired
sliding-mode dynamics. The formula can be used as part of a higher-order
sliding-mode control design methodology, achieving high accuracy and robustness
at the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3319</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3319</id><created>2013-09-12</created><authors><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Borokhovich</keyname><forenames>Michael</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>OBST: A Self-Adjusting Peer-to-Peer Overlay Based on Multiple BSTs</title><categories>cs.NI</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of scalable and robust overlay topologies has been a main research
subject since the very origins of peer-to-peer (p2p) computing. Today, the
corresponding optimization tradeoffs are fairly well-understood, at least in
the static case and from a worst-case perspective.
  This paper revisits the peer-to-peer topology design problem from a
self-organization perspective. We initiate the study of topologies which are
optimized to serve the communication demand, or even self-adjusting as demand
changes. The appeal of this new paradigm lies in the opportunity to be able to
go beyond the lower bounds and limitations imposed by a static,
communication-oblivious, topology. For example, the goal of having short
routing paths (in terms of hop count) does no longer conflict with the
requirement of having low peer degrees.
  We propose a simple overlay topology Obst(k) which is composed of k (rooted
and directed) Binary Search Trees (BSTs), where k is a parameter. We first
prove some fundamental bounds on what can and cannot be achieved optimizing a
topology towards a static communication pattern (a static Obst(k)). In
particular, we show that the number of BSTs that constitute the overlay can
have a large impact on the routing costs, and that a single additional BST may
reduce the amortized communication costs from Omega(log(n)) to O(1), where n is
the number of peers. Subsequently, we discuss a natural self-adjusting
extension of Obst(k), in which frequently communicating partners are &quot;splayed
together&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3321</identifier>
 <datestamp>2014-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3321</id><created>2013-09-12</created><updated>2014-01-14</updated><authors><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author><author><keyname>Kolda</keyname><forenames>Tamara G.</forenames></author></authors><title>Wedge Sampling for Computing Clustering Coefficients and Triangle Counts
  on Large Graphs</title><categories>cs.SI cs.DS</categories><comments>Full version of SDM 2013 paper &quot;Triadic Measures on Graphs: The Power
  of Wedge Sampling&quot; (arxiv:1202.5230)</comments><journal-ref>Statistical Analysis and Data Mining, Vol. 7, No. 4, pp. 294-307,
  August 2014</journal-ref><doi>10.1002/sam.11224</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphs are used to model interactions in a variety of contexts, and there is
a growing need to quickly assess the structure of such graphs. Some of the most
useful graph metrics are based on triangles, such as those measuring social
cohesion. Algorithms to compute them can be extremely expensive, even for
moderately-sized graphs with only millions of edges. Previous work has
considered node and edge sampling; in contrast, we consider wedge sampling,
which provides faster and more accurate approximations than competing
techniques. Additionally, wedge sampling enables estimation local clustering
coefficients, degree-wise clustering coefficients, uniform triangle sampling,
and directed triangle counts. Our methods come with provable and practical
probabilistic error estimates for all computations. We provide extensive
results that show our methods are both more accurate and faster than
state-of-the-art alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3323</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3323</id><created>2013-09-12</created><updated>2013-09-18</updated><authors><author><keyname>Underwood</keyname><forenames>Ted</forenames></author><author><keyname>Black</keyname><forenames>Michael L.</forenames></author><author><keyname>Auvil</keyname><forenames>Loretta</forenames></author><author><keyname>Capitanu</keyname><forenames>Boris</forenames></author></authors><title>Mapping Mutable Genres in Structurally Complex Volumes</title><categories>cs.CL cs.DL</categories><comments>Preprint accepted for the 2013 IEEE International Conference on Big
  Data. Revised to include corroborating evidence from a smaller workset</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To mine large digital libraries in humanistically meaningful ways, scholars
need to divide them by genre. This is a task that classification algorithms are
well suited to assist, but they need adjustment to address the specific
challenges of this domain. Digital libraries pose two problems of scale not
usually found in the article datasets used to test these algorithms. 1) Because
libraries span several centuries, the genres being identified may change
gradually across the time axis. 2) Because volumes are much longer than
articles, they tend to be internally heterogeneous, and the classification task
needs to begin with segmentation. We describe a multi-layered solution that
trains hidden Markov models to segment volumes, and uses ensembles of
overlapping classifiers to address historical change. We test this approach on
a collection of 469,200 volumes drawn from HathiTrust Digital Library. To
demonstrate the humanistic value of these methods, we extract 32,209 volumes of
fiction from the digital library, and trace the changing proportions of first-
and third-person narration in the corpus. We note that narrative points of view
seem to have strong associations with particular themes and genres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3324</identifier>
 <datestamp>2013-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3324</id><created>2013-09-12</created><updated>2013-11-28</updated><authors><author><keyname>Alvaro</keyname><forenames>Peter</forenames></author><author><keyname>Conway</keyname><forenames>Neil</forenames></author><author><keyname>Hellerstein</keyname><forenames>Joseph M.</forenames></author><author><keyname>Maier</keyname><forenames>David</forenames></author></authors><title>Blazes: Coordination Analysis for Distributed Programs</title><categories>cs.DC</categories><comments>Updated to include additional materials from the original technical
  report: derivation rules, output stream labels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed consistency is perhaps the most discussed topic in distributed
systems today. Coordination protocols can ensure consistency, but in practice
they cause undesirable performance unless used judiciously. Scalable
distributed architectures avoid coordination whenever possible, but
under-coordinated systems can exhibit behavioral anomalies under fault, which
are often extremely difficult to debug. This raises significant challenges for
distributed system architects and developers. In this paper we present Blazes,
a cross-platform program analysis framework that (a) identifies program
locations that require coordination to ensure consistent executions, and (b)
automatically synthesizes application-specific coordination code that can
significantly outperform general-purpose techniques. We present two case
studies, one using annotated programs in the Twitter Storm system, and another
using the Bloom declarative language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3330</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3330</id><created>2013-09-12</created><updated>2014-01-22</updated><authors><author><keyname>Vempaty</keyname><forenames>Aditya</forenames></author><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Reliable Crowdsourcing for Multi-Class Labeling using Coding Theory</title><categories>cs.IT cs.SI math.IT</categories><comments>20 pages, 11 figures, under revision, IEEE Journal of Selected Topics
  in Signal Processing</comments><doi>10.1109/JSTSP.2014.2316116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourcing systems often have crowd workers that perform unreliable work
on the task they are assigned. In this paper, we propose the use of
error-control codes and decoding algorithms to design crowdsourcing systems for
reliable classification despite unreliable crowd workers. Coding-theory based
techniques also allow us to pose easy-to-answer binary questions to the crowd
workers. We consider three different crowdsourcing models: systems with
independent crowd workers, systems with peer-dependent reward schemes, and
systems where workers have common sources of information. For each of these
models, we analyze classification performance with the proposed coding-based
scheme. We develop an ordering principle for the quality of crowds and describe
how system performance changes with the quality of the crowd. We also show that
pairing among workers and diversification of the questions help in improving
system performance. We demonstrate the effectiveness of the proposed
coding-based scheme using both simulated data and real datasets from Amazon
Mechanical Turk, a crowdsourcing microtask platform. Results suggest that use
of good codes may improve the performance of the crowdsourcing task over
typical majority-voting approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3418</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3418</id><created>2013-09-13</created><authors><author><keyname>Bagchi</keyname><forenames>Parama</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>A Novel Approach in detecting pose orientation of a 3D face required for
  face</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we present a novel approach that takes as input a 3D image and
gives as output its pose i.e. it tells whether the face is oriented with
respect the X, Y or Z axes with angles of rotation up to 40 degree. All the
experiments have been performed on the FRAV3D Database. After applying the
proposed algorithm to the 3D facial surface we have obtained i.e. on 848 3D
face images our method detected the pose correctly for 566 face images,thus
giving an approximately 67 % of correct pose detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3421</identifier>
 <datestamp>2014-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3421</id><created>2013-09-13</created><updated>2014-12-11</updated><authors><author><keyname>Wang</keyname><forenames>Yanshan</forenames></author><author><keyname>Lee</keyname><forenames>Jae-Sung</forenames></author><author><keyname>Choi</keyname><forenames>In-Chan</forenames></author></authors><title>Indexing by Latent Dirichlet Allocation and Ensemble Model</title><categories>cs.IR</categories><comments>Accepted by the Journal of American Society for Information Science
  and Technology (JASIST)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The contribution of this paper is two-fold. First, we present Indexing by
Latent Dirichlet Allocation (LDI), an automatic document indexing method. The
probability distributions in LDI utilize those in Latent Dirichlet Allocation
(LDA), a generative topic model that has been previously used in applications
for document retrieval tasks. However, the ad hoc applications, or their
variants with smoothing techniques as prompted by previous studies in LDA-based
language modeling, result in unsatisfactory performance as the document
representations do not accurately reflect concept space. To improve
performance, we introduce a new definition of document probability vectors in
the context of LDA and present a novel scheme for automatic document indexing
based on LDA. Second, we propose an Ensemble Model (EnM) for document
retrieval. The EnM combines basis indexing models by assigning different
weights and attempts to uncover the optimal weights to maximize the Mean
Average Precision (MAP). To solve the optimization problem, we propose an
algorithm, EnM.B, which is derived based on the boosting method. The results of
our computational experiments on benchmark data sets indicate that both the
proposed approaches are viable options for document retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3425</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3425</id><created>2013-09-13</created><authors><author><keyname>Bagchi</keyname><forenames>Parama</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak kr.</forenames></author></authors><title>A method for nose-tip based 3D face registration using maximum intensity
  algorithm</title><categories>cs.CV</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we present a novel technique of registering 3D images across
pose. In this context, we have taken into account the images which are aligned
across X, Y and Z axes. We have first determined the angle across which the
image is rotated with respect to X, Y and Z axes and then translation is
performed on the images. After testing the proposed method on 472 images from
the FRAV3D database, the method correctly registers 358 images thus giving a
performance rate of 75.84%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3439</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3439</id><created>2013-09-12</created><authors><author><keyname>Wang</keyname><forenames>Zhong-qin</forenames></author><author><keyname>Ye</keyname><forenames>Ning</forenames></author><author><keyname>Reza</keyname><forenames>Malekian</forenames></author><author><keyname>Zhao</keyname><forenames>Ting-ting</forenames></author><author><keyname>Wang</keyname><forenames>Ru-chuan</forenames></author></authors><title>Measuring the similarity of PML documents with RFID-based sensors</title><categories>cs.DB cs.NI</categories><comments>International Journal of Ad Hoc and Ubiquitous Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Electronic Product Code (EPC) Network is an important part of the
Internet of Things. The Physical Mark-Up Language (PML) is to represent and
de-scribe data related to objects in EPC Network. The PML documents of each
component to exchange data in EPC Network system are XML documents based on PML
Core schema. For managing theses huge amount of PML documents of tags captured
by Radio frequency identification (RFID) readers, it is inevitable to develop
the high-performance technol-ogy, such as filtering and integrating these tag
data. So in this paper, we propose an approach for meas-uring the similarity of
PML documents based on Bayesian Network of several sensors. With respect to the
features of PML, while measuring the similarity, we firstly reduce the
redundancy data except information of EPC. On the basis of this, the Bayesian
Network model derived from the structure of the PML documents being compared is
constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3441</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3441</id><created>2013-09-13</created><updated>2014-09-13</updated><authors><author><keyname>Vogel</keyname><forenames>Hannah</forenames></author></authors><title>On the shape of subword complexity sequences of finite words</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subword complexity of a word $w$ over a finite alphabet $\mathcal{A}$ is
a function that assigns for each positive integer $n$, the number of distinct
subwords of length $n$ in $w$. The subword complexity of a word is a good
measure of the randomness of the word and gives insight to what the word itself
looks like. In this paper, we discuss the properties of subword complexity
sequences, and consider different variables that influence their shape. We also
compute the number of distinct subword complexity sequences for certain lengths
of words over different alphabets, and state some conjectures about the growth
of these numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3445</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3445</id><created>2013-09-12</created><updated>2016-02-12</updated><authors><author><keyname>Bond</keyname><forenames>Benjamin</forenames></author><author><keyname>Levine</keyname><forenames>Lionel</forenames></author></authors><title>Abelian networks I. Foundations and examples</title><categories>cs.FL cond-mat.stat-mech math.CO</categories><comments>To appear in SIAM J. Discrete Math. The original v1 has been split
  into three parts, of which this is the first. This part covers the least
  action principle, halting dichotomy, local abelianness implies global
  abelianness, and monotone integer programming. The other parts are
  arXiv:1409.0169 (Abelian networks II. Halting on all inputs) and
  arXiv:1409.0170 (Abelian networks III. The critical group)</comments><msc-class>68Q10, 37B15, 90C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Deepak Dhar's model of abelian distributed processors, automata occupy the
vertices of a graph and communicate via the edges. We show that two simple
axioms ensure that the final output does not depend on the order in which the
automata process their inputs. A collection of automata obeying these axioms is
called an &quot;abelian network&quot;. We prove a least action principle for abelian
networks. As an application, we show how abelian networks can solve certain
linear and nonlinear integer programs asynchronously.
  In most previously studied abelian networks, the input alphabet of each
automaton consists of a single letter; in contrast, we propose two non-unary
examples of abelian networks: &quot;oil and water&quot; and &quot;abelian mobile agents&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3446</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3446</id><created>2013-09-13</created><authors><author><keyname>Frank</keyname><forenames>Daniel</forenames></author><author><keyname>Ochs</keyname><forenames>Karlheinz</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>A Systematic Approach for Interference Alignment in CSIT-less
  Relay-Aided X-Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degrees of freedom (DoF) of an X-network with M transmit and N receive
nodes utilizing interference alignment with the support of $J$ relays each
equipped with $L_j$ antennas operating in a half-duplex non-regenerative mode
is investigated. Conditions on the feasibility of interference alignment are
derived using a proper transmit strategy and a structured approach based on a
Kronecker-product representation. The advantages of this approach are twofold:
First, it extends existing results on the achievable DoF to generalized antenna
configurations. Second, it unifies the analysis for time-varying and constant
channels and provides valuable insights and interconnections between the two
channel models. It turns out that a DoF of $\nicefrac{NM}{M+N-1}$ is feasible
whenever the sum of the $L_j^2 \geq [N-1][M-1]$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3458</identifier>
 <datestamp>2014-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3458</id><created>2013-09-13</created><updated>2014-07-24</updated><authors><author><keyname>Marzolla</keyname><forenames>Moreno</forenames></author><author><keyname>D'Angelo</keyname><forenames>Gabriele</forenames></author><author><keyname>Mandrioli</keyname><forenames>Marco</forenames></author></authors><title>A Parallel Data Distribution Management Algorithm</title><categories>cs.DS cs.DC</categories><comments>In proc. of the IEEE/ACM International Symposium on Distributed
  Simulation and Real Time Applications (DS-RT 2013), oct 30-nov 1, 2013,
  Delft, the Netherlands</comments><acm-class>F.2.2</acm-class><doi>10.1109/DS-RT.2013.23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying intersections among a set of d-dimensional rectangular regions
(d-rectangles) is a common problem in many simulation and modeling
applications. Since algorithms for computing intersections over a large number
of regions can be computationally demanding, an obvious solution is to take
advantage of the multiprocessing capabilities of modern multicore processors.
Unfortunately, many solutions employed for the Data Distribution Management
service of the High Level Architecture are either inefficient, or can only
partially be parallelized. In this paper we propose the Interval Tree Matching
(ITM) algorithm for computing intersections among d-rectangles. ITM is based on
a simple Interval Tree data structure, and exhibits an embarrassingly parallel
structure. We implement the ITM algorithm, and compare its sequential
performance with two widely used solutions (brute force and sort-based
matching). We also analyze the scalability of ITM on shared-memory multicore
processors. The results show that the sequential implementation of ITM is
competitive with sort-based matching; moreover, the parallel implementation
provides good speedup on multicore processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3467</identifier>
 <datestamp>2013-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3467</id><created>2013-09-13</created><updated>2013-10-16</updated><authors><author><keyname>Muralidharan</keyname><forenames>Vijayvaradharaj T.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Wireless Bidirectional Relaying, Latin Squares and Graph Vertex Coloring</title><categories>cs.IT math.IT</categories><comments>18 pages, 19 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of obtaining network coding maps for the physical layer network
coded two-way relay channel is considered, using the denoise-and-forward
forward protocol. It is known that network coding maps used at the relay node
which ensure unique decodability at the end nodes form a Latin Square. Also, it
is known that minimum distance of the effective constellation at the relay node
becomes zero, when the ratio of the fade coefficients from the end node to the
relay node, belongs to a finite set of complex numbers determined by the signal
set used, called the singular fade states. Furthermore, it has been shown
recently that the problem of obtaining network coding maps which remove the
harmful effects of singular fade states, reduces to the one of obtaining Latin
Squares, which satisfy certain constraints called \textit{singularity removal
constraints}. In this paper, it is shown that the singularity removal
constraints along with the row and column exclusion conditions of a Latin
Square, can be compactly represented by a graph called the \textit{singularity
removal graph} determined by the singular fade state and the signal set used.
It is shown that a Latin Square which removes a singular fade state can be
obtained from a proper vertex coloring of the corresponding singularity removal
graph. The minimum number of symbols used to fill in a Latin Square which
removes a singular fade state is equal to the chromatic number of the
singularity removal graph. It is shown that for any square $M$-QAM signal set,
there exists singularity removal graphs whose chromatic numbers exceed $M$ and
hence require more than $M$ colors for vertex coloring. Also, it is shown that
for any $2^{\lambda}$-PSK signal set, $\lambda \geq 3,$ all the singularity
removal graphs can be colored using $2^{\lambda}$ colors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3511</identifier>
 <datestamp>2014-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3511</id><created>2013-09-13</created><updated>2014-09-19</updated><authors><author><keyname>Shoukry</keyname><forenames>Yasser</forenames></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>Event-Triggered State Observers for Sparse Sensor Noise/Attacks</title><categories>math.OC cs.CR cs.IT cs.SY math.IT</categories><comments>30 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes two algorithms for state reconstruction from sensor
measurements that are corrupted with sparse, but otherwise arbitrary, &quot;noise&quot;.
These results are motivated by the need to secure cyber-physical systems
against a malicious adversary that can arbitrarily corrupt sensor measurements.
The first algorithm reconstructs the state from a batch of sensor measurements
while the second algorithm is able to incorporate new measurements as they
become available, in the spirit of a Luenberger observer. A distinguishing
point of these algorithms is the use of event-triggered techniques to improve
the computational performance of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3512</identifier>
 <datestamp>2014-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3512</id><created>2013-09-13</created><authors><author><keyname>Zebenaya</keyname><forenames>M.</forenames></author><author><keyname>Boge</keyname><forenames>T.</forenames></author><author><keyname>Krenn</keyname><forenames>R.</forenames></author><author><keyname>Choukroun</keyname><forenames>D.</forenames></author></authors><title>Analytical and experimental stability investigation of a
  hardware-in-the-loop satellite docking simulator</title><categories>cs.OH</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The European Proximity Operation Simulator (EPOS) of the DLR-German Aerospace
Center is a robotics-based simulator that aims at validating and verifying a
satellite docking phase. The generic concept features a robotics tracking
system working in closed loop with a force/torque feedback signal. Inherent
delays in the tracking system combined with typical high stiffness at contact
challenge the stability of the closed-loop system. The proposed concept of
operations is hybrid: the feedback signal is a superposition of a measured
value and of a virtual value that can be tuned in order to guarantee a desired
behavior. This paper is concerned with an analytical study of the system's
closed-loop stability, and with an experimental validation of the hybrid
concept of operations in one dimension (1D). The robotics simulator is modeled
as a second-order loop-delay system and closed-form expressions for the
critical delay and associated frequency are derived as a function of the
satellites' mass and the contact dynamics stiffness and damping parameters. A
numerical illustration sheds light on the impact of the parameters on the
stability regions. A first-order Pade approximation provides additional means
of stability investigation. Experiments were performed and tests results are
described for varying values of the mass and the damping coefficients. The
empirical determination of instability is based on the coefficient of
restitution and on the observed energy. There is a very good agreement between
the critical damping values predicted by the analysis and observed during the
tests...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3513</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3513</id><created>2013-08-22</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Sabyasachi</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Paritosh</forenames></author><author><keyname>Ghosh</keyname><forenames>B. B.</forenames></author></authors><title>Application of Vertex coloring in a particular triangular closed path
  structure and in Krafts inequality</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A good deal of research has been done and published on coloring of the
vertices of graphs for several years while studying of the excellent work of
those maestros, we get inspire to work on the vertex coloring of graphs in case
of a particular triangular closed path structure what we achieve from the front
view of a pyramidal structure. From here we achieve a repetitive nature of
vertex coloring in case of odd and even number of horizontal lines within this
triangular structure. In order to apply this repetitive nature of vertex
coloring in case of a binary tree, we get a success in Krafts Inequality.
Actually our work mainly deals with a particular triangular closed path vertex
coloring and repetition of the vertex coloring nature in case of the Krafts
inequality in the field of Information Theory and Coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3515</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3515</id><created>2013-09-13</created><authors><author><keyname>Brown</keyname><forenames>Joshua</forenames></author><author><keyname>Ohrimenko</keyname><forenames>Olga</forenames></author><author><keyname>Tamassia</keyname><forenames>Roberto</forenames></author></authors><title>Haze: Privacy-Preserving Real-Time Traffic Statistics</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider traffic-update mobile applications that let users learn traffic
conditions based on reports from other users. These applications are becoming
increasingly popular (e.g., Waze reported 30 million users in 2013) since they
aggregate real-time road traffic updates from actual users traveling on the
roads. However, the providers of these mobile services have access to such
sensitive information as timestamped locations and movements of its users. In
this paper, we describe Haze, a protocol for traffic-update applications that
supports the creation of traffic statistics from user reports while protecting
the privacy of the users. Haze relies on a small subset of users to jointly
aggregate encrypted speed and alert data and report the result to the service
provider. We use jury-voting protocols based on threshold cryptosystem and
differential privacy techniques to hide user data from anyone participating in
the protocol while allowing only aggregate information to be extracted and sent
to the service provider. We show that Haze is effective in practice by
developing a prototype implementation and performing experiments on a
real-world dataset of car trajectories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3522</identifier>
 <datestamp>2014-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3522</id><created>2013-09-13</created><updated>2014-03-24</updated><authors><author><keyname>Dirksen</keyname><forenames>Sjoerd</forenames></author></authors><title>Tail bounds via generic chaining</title><categories>math.PR cs.IT math.IT</categories><comments>Added detailed proof of Theorem 3.5; Application to dimensionality
  reduction expanded and moved to separate note arXiv:1402.3973</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We modify Talagrand's generic chaining method to obtain upper bounds for all
p-th moments of the supremum of a stochastic process. These bounds lead to an
estimate for the upper tail of the supremum with optimal deviation parameters.
We apply our procedure to improve and extend some known deviation inequalities
for suprema of unbounded empirical processes and chaos processes. As an
application we give a significantly simplified proof of the restricted isometry
property of the subsampled discrete Fourier transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3533</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3533</id><created>2013-09-13</created><authors><author><keyname>Fox</keyname><forenames>Emily B.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>Mixed Membership Models for Time Series</title><categories>stat.ME cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we discuss some of the consequences of the mixed membership
perspective on time series analysis. In its most abstract form, a mixed
membership model aims to associate an individual entity with some set of
attributes based on a collection of observed data. Although much of the
literature on mixed membership models considers the setting in which
exchangeable collections of data are associated with each member of a set of
entities, it is equally natural to consider problems in which an entire time
series is viewed as an entity and the goal is to characterize the time series
in terms of a set of underlying dynamic attributes or &quot;dynamic regimes&quot;.
Indeed, this perspective is already present in the classical hidden Markov
model, where the dynamic regimes are referred to as &quot;states&quot;, and the
collection of states realized in a sample path of the underlying process can be
viewed as a mixed membership characterization of the observed time series. Our
goal here is to review some of the richer modeling possibilities for time
series that are provided by recent developments in the mixed membership
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3541</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3541</id><created>2013-09-13</created><updated>2013-10-01</updated><authors><author><keyname>Vay</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Geddes</keyname><forenames>Cameron G. R.</forenames></author><author><keyname>Koniges</keyname><forenames>Alice</forenames></author><author><keyname>Friedman</keyname><forenames>Alex</forenames></author><author><keyname>Grote</keyname><forenames>David P.</forenames></author><author><keyname>Bruhwiler</keyname><forenames>David L.</forenames></author><author><keyname>Verboncoeur</keyname><forenames>John P.</forenames></author></authors><title>White Paper on DOE-HEP Accelerator Modeling Science Activities</title><categories>physics.acc-ph cs.DC</categories><comments>4 pages, 0 figures, originally presented at the US Department of
  Energy workshop: Community Summer Study</comments><acm-class>J.2</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Toward the goal of maximizing the impact of computer modeling on the design
of future particle accelerators and the development of new accelerator
techniques &amp; technologies, this white paper presents the rationale for: (a)
strengthening and expanding programmatic activities in accelerator modeling
science within the Department of Energy (DOE) Office of High Energy Physics
(HEP) and (b) increasing the community-wide coordination and integration of
code development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3545</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3545</id><created>2013-09-13</created><updated>2015-06-23</updated><authors><author><keyname>Miller</keyname><forenames>Gary L.</forenames></author><author><keyname>Peng</keyname><forenames>Richard</forenames></author><author><keyname>Vladu</keyname><forenames>Adrian</forenames></author><author><keyname>Xu</keyname><forenames>Shen Chen</forenames></author></authors><title>Improved Parallel Algorithms for Spanners and Hopsets</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use exponential start time clustering to design faster and more
work-efficient parallel graph algorithms involving distances. Previous
algorithms usually rely on graph decomposition routines with strict
restrictions on the diameters of the decomposed pieces. We weaken these bounds
in favor of stronger local probabilistic guarantees. This allows more direct
analyses of the overall process, giving: * Linear work parallel algorithms that
construct spanners with $O(k)$ stretch and size $O(n^{1+1/k})$ in unweighted
graphs, and size $O(n^{1+1/k} \log k)$ in weighted graphs. * Hopsets that lead
to the first parallel algorithm for approximating shortest paths in undirected
graphs with $O(m\;\mathrm{polylog}\;n)$ work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3546</identifier>
 <datestamp>2013-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3546</id><created>2013-09-13</created><updated>2013-12-16</updated><authors><author><keyname>Cheng</keyname><forenames>Qi</forenames></author><author><keyname>Li</keyname><forenames>Jiyou</forenames></author><author><keyname>Zhuang</keyname><forenames>Jincheng</forenames></author></authors><title>On Determining Deep Holes of Generalized Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a linear code, deep holes are defined to be vectors that are further away
from codewords than all other vectors. The problem of deciding whether a
received word is a deep hole for generalized Reed-Solomon codes is proved to be
co-NP-complete. For the extended Reed-Solomon codes $RS_q(\F_q,k)$, a
conjecture was made to classify deep holes by Cheng and Murray in 2007. Since
then a lot of effort has been made to prove the conjecture, or its various
forms. In this paper, we classify deep holes completely for generalized
Reed-Solomon codes $RS_p (D,k)$, where $p$ is a prime, $|D| &gt; k \geqslant
\frac{p-1}{2}$. Our techniques are built on the idea of deep hole trees, and
several results concerning the Erd{\&quot;o}s-Heilbronn conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3582</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3582</id><created>2013-09-13</created><authors><author><keyname>Torrieri</keyname><forenames>Don</forenames></author><author><keyname>Talarico</keyname><forenames>Salvatore</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author></authors><title>Multihop Routing in Ad Hoc Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages, 6 figures, to appear in IEEE Military Commun. Conf.
  (MILCOM), 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a dual method of closed-form analysis and lightweight
simulation that enables an evaluation of the performance of mobile ad hoc
networks that is more realistic, efficient, and accurate than those found in
existing publications. Some features accommodated by the new analysis are
shadowing, exclusion and guard zones, and distance-dependent fading. Three
routing protocols are examined: least-delay, nearest-neighbor, and
maximum-progress routing. The tradeoffs among the path reliabilities, average
conditional delays, average conditional number of hops, and area spectral
efficiencies are examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3583</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3583</id><created>2013-09-13</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Physarum wires: Self-growing self-repairing smart wires made from slime
  mould</title><categories>physics.bio-ph cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report experimental laboratory studies on developing conductive pathways,
or wires, using protoplasmic tubes of plasmodium of acellular slime mould
Physarum polycephalum. Given two pins to be connected by a wire, we place a
piece of slime mould on one pin and an attractant on another pin. Physarum
propagates towards the attract and thus connects the pins with a protoplasmic
tube. A protoplasmic tube is conductive, can survive substantial over-voltage
and can be used to transfer electrical current to lightning and actuating
devices. In experiments we show how to route Physarum wires with
chemoattractants and electrical fields. We demonstrate that Physarum wire can
be grown on almost bare breadboards and on top of electronic circuits. The
Physarum wires can be insulated with a silicon oil without loss of
functionality. We show that a Physarum wire self-heals: end of a cut wire merge
together and restore the conductive pathway in several hours after being cut.
Results presented will be used in future designs of self-growing wetware
circuits and devices, and integration of slime mould electronics into
unconventional bio-hybrid systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3591</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3591</id><created>2013-09-13</created><updated>2014-01-19</updated><authors><author><keyname>Jiang</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Optimal Power Allocation for Parameter Tracking in a Distributed
  Amplify-and-Forward Sensor Network</title><categories>cs.IT math.IT</categories><comments>28 pages, 6 figures, accepted by IEEE Transactions on Signal
  Processing, Jan. 2014</comments><doi>10.1109/TSP.2014.2304434</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of optimal power allocation in a sensor network where
the sensors observe a dynamic parameter in noise and coherently amplify and
forward their observations to a fusion center (FC). The FC uses the
observations in a Kalman filter to track the parameter, and we show how to find
the optimal gain and phase of the sensor transmissions under both global and
individual power constraints in order to minimize the mean squared error (MSE)
of the parameter estimate. For the case of a global power constraint, a
closed-form solution can be obtained. A numerical optimization is required for
individual power constraints, but the problem can be relaxed to a semidefinite
programming problem (SDP), and we show that the optimal result can be
constructed from the SDP solution. We also study the dual problem of minimizing
global and individual power consumption under a constraint on the MSE. As
before, a closed-form solution can be found when minimizing total power, while
the optimal solution is constructed from the output of an SDP when minimizing
the maximum individual sensor power. For purposes of comparison, we derive an
exact expression for the outage probability on the MSE for equal-power
transmission, which can serve as an upper bound for the case of optimal power
control. Finally, we present the results of several simulations to show that
the use of optimal power control provides a significant reduction in either MSE
or transmit power compared with a non-optimized approach (i.e., equal power
transmission).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3597</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3597</id><created>2013-09-13</created><authors><author><keyname>Ibrahim</keyname><forenames>Abdelrahman M.</forenames></author><author><keyname>ElBatt</keyname><forenames>Tamer</forenames></author><author><keyname>El-Keyi</keyname><forenames>Amr</forenames></author></authors><title>Coverage Probability Analysis for Wireless Networks Using Repulsive
  Point Processes</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent witnessed evolution of cellular networks from a carefully planned
deployment to more irregular, heterogeneous deployments of Macro, Pico and
Femto-BSs motivates new analysis and design approaches. In this paper, we
analyze the coverage probability in cellular networks assuming repulsive point
processes for the base station deployment. In particular, we characterize,
analytically using stochastic geometry, the downlink probability of coverage
under a Matern hardcore point process to ensure minimum distance between the
randomly located base stations. Assuming a mobile user connects to the nearest
base station and Rayleigh fading, we derive two lower bounds expressions on the
downlink probability of coverage that is within 4% from the simulated scenario.
To validate our model, we compare the probability of coverage of the Matern
hardcore topology against an actual base station deployment obtained from a
public database. The comparison shows that the actual base station deployment
can be fitted by setting the appropriate Matern point process density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3611</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3611</id><created>2013-09-13</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Ultrametric Component Analysis with Application to Analysis of Text and
  of Emotion</title><categories>cs.AI</categories><comments>49 pages, 15 figures, 52 citations</comments><msc-class>62H30, 68T10</msc-class><acm-class>I.2.0; H.3.3; I.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the theory and practice of determining what parts of a data set are
ultrametric. It is assumed that the data set, to begin with, is endowed with a
metric, and we include discussion of how this can be brought about if a
dissimilarity, only, holds. The basis for part of the metric-endowed data set
being ultrametric is to consider triplets of the observables (vectors). We
develop a novel consensus of hierarchical clusterings. We do this in order to
have a framework (including visualization and supporting interpretation) for
the parts of the data that are determined to be ultrametric. Furthermore a
major objective is to determine locally ultrametric relationships as opposed to
non-local ultrametric relationships. As part of this work, we also study a
particular property of our ultrametricity coefficient, namely, it being a
function of the difference of angles of the base angles of the isosceles
triangle. This work is completed by a review of related work, on consensus
hierarchies, and of a major new application, namely quantifying and
interpreting the emotional content of narrative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3618</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3618</id><created>2013-09-13</created><authors><author><keyname>Perera</keyname><forenames>Charith</forenames></author><author><keyname>Zaslavsky</keyname><forenames>Arkady</forenames></author><author><keyname>Liu</keyname><forenames>Chi Harold</forenames></author><author><keyname>Compton</keyname><forenames>Michael</forenames></author><author><keyname>Christen</keyname><forenames>Peter</forenames></author><author><keyname>Georgakopoulos</keyname><forenames>Dimitrios</forenames></author></authors><title>Sensor Search Techniques for Sensing as a Service Architecture for The
  Internet of Things</title><categories>cs.NI</categories><comments>IEEE sensors Journal, 2013. arXiv admin note: text overlap with
  arXiv:1303.2447</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Things (IoT) is part of the Internet of the future and will
comprise billions of intelligent communicating &quot;things&quot; or Internet Connected
Objects (ICO) which will have sensing, actuating, and data processing
capabilities. Each ICO will have one or more embedded sensors that will capture
potentially enormous amounts of data. The sensors and related data streams can
be clustered physically or virtually, which raises the challenge of searching
and selecting the right sensors for a query in an efficient and effective way.
This paper proposes a context-aware sensor search, selection and ranking model,
called CASSARAM, to address the challenge of efficiently selecting a subset of
relevant sensors out of a large set of sensors with similar functionality and
capabilities. CASSARAM takes into account user preferences and considers a
broad range of sensor characteristics, such as reliability, accuracy, location,
battery life, and many more. The paper highlights the importance of sensor
search, selection and ranking for the IoT, identifies important characteristics
of both sensors and data capture processes, and discusses how semantic and
quantitative reasoning can be combined together. This work also addresses
challenges such as efficient distributed sensor search and
relational-expression based filtering. CASSARAM testing and performance
evaluation results are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3623</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3623</id><created>2013-09-13</created><authors><author><keyname>Kim</keyname><forenames>Hyunjun</forenames></author><author><keyname>Tepedelenlio&#x11f;lu</keyname><forenames>Cihan</forenames></author></authors><title>Unified Sum-BER Performance Analysis of AF MIMO Beamforming in Two-Way
  Relay Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unified performance analysis is carried out for amplify-and-forward (AF)
multiple-input-multiple-output (MIMO) beamforming (BF) two-way relay networks
in Rayleigh fading with five different relaying protocols including two novel
protocols for better performance. As a result, a novel closed-form sum-bit
error rate (BER) expression is presented in a unified expression for all
protocols. A new closed-form high signal-to-noise-ratio (SNR) performance is
also obtained in a single expression, and an analytical high-SNR gap expression
between the five protocols is provided. We compare the performance of the five
relaying protocols with respect to sum-BER with appropriately normalized rate
and power, and show that the proposed protocol with four time slots outperforms
other protocols when transmit powers from two sources are sufficiently
different, and the one with three time slots dominates other protocols when
multiple relay antennas are used, at high-SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3628</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3628</id><created>2013-09-14</created><authors><author><keyname>Singh</keyname><forenames>Ashutosh</forenames></author><author><keyname>Singh</keyname><forenames>Yatindra Nath</forenames></author></authors><title>Multipath Approach for Reliability in Query Network based Overlaid
  Multicasting</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Application layer multicast (ALM) also called Overlay Multicast,
multicast-related functionalities are moved to end-hosts. The key advantages,
overlays offers, are flexibility, adaptability and ease of deployment [1].
Application layer multicast builds a peer-to-peer (P2P) overlay multicast tree
topology consisting of end-to-end unicast connections between end-hosts. End
users self organize themselves into logical overlay networks for efficient data
delivery. Major concern in designing ALM protocol is how to build and maintain
a topology, to route data efficiently and reliably. We propose here a scheme in
which the topology is built incrementally while maintaining dual feeds of the
media stream to any node from the source with minimum differential delay in
receiving packets from both alternatives. We have made the assumption of
availability of a P2P query search network. This enables building of multicast
tree directly as an overlay. There is no need of maintaining an overlaid mesh
and running multicast routing protocol to maintain a multicast tree in this
mesh. Thus the scheme is much more simplified than in the earlier work on
multicast overlay mesh creation and management and then creation and management
of multicast trees using this mesh.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3642</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3642</id><created>2013-09-14</created><updated>2013-09-22</updated><authors><author><keyname>Ram</keyname><forenames>Athma. M.</forenames></author><author><keyname>Rama</keyname><forenames>R.</forenames></author></authors><title>An Alternate method to find the chromatic number of a Finite, Connected
  Graph</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm to obtain the chromatic number of a finite, connected graph
is proposed in this paper. The algorithm is based on contraction of non
adjacent vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3647</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3647</id><created>2013-09-14</created><authors><author><keyname>Armknecht</keyname><forenames>Frederik</forenames></author><author><keyname>Hauptmann</keyname><forenames>Manuel</forenames></author><author><keyname>Roos</keyname><forenames>Stefanie</forenames></author><author><keyname>Strufe</keyname><forenames>Thorsten</forenames></author></authors><title>Protecting Public OSN Posts from Unintended Access</title><categories>cs.SI cs.CR</categories><comments>12 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of secure and usable access schemes to personal data represent a
major challenge of online social networks (OSNs). State of the art requires
prior interaction to grant access. Sharing with users who are not subscribed or
previously have not been accepted as contacts in any case is only possible via
public posts, which can easily be abused by automatic harvesting for user
profiling, targeted spear-phishing, or spamming. Moreover, users are restricted
to the access rules defined by the provider, which may be overly restrictive,
cumbersome to define, or insufficiently fine-grained.
  We suggest a complementary approach that can be easily deployed in addition
to existing access control schemes, does not require any interaction, and
includes even public, unsubscribed users. It exploits the fact that different
social circles of a user share different experiences and hence encrypts
arbitrary posts. Hence arbitrary posts are encrypted, such that only users with
sufficient knowledge about the owner can decrypt.
  Assembling only well-established cryptographic primitives, we prove that the
security of our scheme is determined by the entropy of the required knowledge.
We consequently analyze the efficiency of an informed dictionary attack and
assess the entropy to be on par with common passwords. A fully functional
implementation is used for performance evaluations, and available for download
on the Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3655</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3655</id><created>2013-09-14</created><updated>2013-09-22</updated><authors><author><keyname>Karmoose</keyname><forenames>Mohammed</forenames></author><author><keyname>Habak</keyname><forenames>Karim</forenames></author><author><keyname>El-Nainay</keyname><forenames>Mustafa</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Dead Zone Penetration Protocol for Cognitive Radio Networks</title><categories>cs.NI</categories><comments>The paper has been withdrawn for copyright issues</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current routing protocols for cognitive radio networks are severely affected
by the frequent activity of primary users. Nodes that are in the interference
range of an appearing primary user are not allowed to transmit, and therefore
existing routes which utilize such nodes are obliged to undergo a route
maintenance phase. This naturally provides other routes to the destination that
may incur extra delay or increase packet queuing overhead. In this work, a
novel route maintenance protocol is proposed that allows existing routes to
endure the event of primary user presence by forming cooperative links between
neighboring nodes and nulling out transmission at the primary receiver using
cooperative beamforming. Our proposed protocol can be used in conjunction with
any of the existing routing protocols, thus achieving modularity. Extensive
simulations are done which prove that our proposed protocol outperforms
existing route maintenance techniques in terms of end-to-end delay and loss
ratio, with minimal incurred overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3660</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3660</id><created>2013-09-14</created><authors><author><keyname>Eger</keyname><forenames>Steffen</forenames></author></authors><title>(Failure of the) Wisdom of the crowds in an endogenous opinion dynamics
  model with multiply biased agents</title><categories>cs.SI cs.MA nlin.AO physics.soc-ph</categories><comments>56 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study an endogenous opinion (or, belief) dynamics model where we
endogenize the social network that models the link (`trust') weights between
agents. Our network adjustment mechanism is simple: an agent increases her
weight for another agent if that agent has been close to truth (whence, our
adjustment criterion is `past performance'). Moreover, we consider multiply
biased agents that do not learn in a fully rational manner but are subject to
persuasion bias - they learn in a DeGroot manner, via a simple `rule of thumb'
- and that have biased initial beliefs. In addition, we also study this setup
under conformity, opposition, and homophily - which are recently suggested
variants of DeGroot learning in social networks - thereby taking into account
further biases agents are susceptible to. Our main focus is on crowd wisdom,
that is, on the question whether the so biased agents can adequately aggregate
dispersed information and, consequently, learn the true states of the topics
they communicate about. In particular, we present several conditions under
which wisdom fails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3665</identifier>
 <datestamp>2013-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3665</id><created>2013-09-14</created><updated>2013-10-11</updated><authors><author><keyname>&#xc1;brego</keyname><forenames>Bernardo M.</forenames></author><author><keyname>Aichholzer</keyname><forenames>Oswin</forenames></author><author><keyname>Fern&#xe1;ndez-Merchant</keyname><forenames>Silvia</forenames></author><author><keyname>Ramos</keyname><forenames>Pedro</forenames></author><author><keyname>Salazar</keyname><forenames>Gelasio</forenames></author></authors><title>Shellable drawings and the cylindrical crossing number of $K_n$</title><categories>math.CO cs.CG</categories><comments>9 pages, 4 figures</comments><msc-class>05C10, 05C62, 52C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Harary-Hill Conjecture States that the number of crossings in any drawing
of the complete graph $ K_n $ in the plane is at least
$Z(n):=\frac{1}{4}\left\lfloor \frac{n}{2}\right\rfloor
\left\lfloor\frac{n-1}{2}\right\rfloor \left\lfloor
\frac{n-2}{2}\right\rfloor\left\lfloor \frac{n-3}{2}\right\rfloor$. In this
paper, we settle the Harary-Hill conjecture for {\em shellable drawings}. We
say that a drawing $D$ of $ K_n $ is {\em $ s $-shellable} if there exist a
subset $ S = \{v_1,v_2,\ldots,v_ s\}$ of the vertices and a region $R$ of $D$
with the following property: For all $1 \leq i &lt; j \leq s$, if $D_{ij}$ is the
drawing obtained from $D$ by removing $v_1,v_2,\ldots
v_{i-1},v_{j+1},\ldots,v_{s}$, then $v_i$ and $v_j$ are on the boundary of the
region of $D_{ij}$ that contains $R$. For $ s\geq n/2 $, we prove that the
number of crossings of any $ s $-shellable drawing of $ K_n $ is at least the
long-conjectured value Z(n). Furthermore, we prove that all cylindrical, $ x
$-bounded, monotone, and 2-page drawings of $ K_n $ are $ s $-shellable for
some $ s\geq n/2 $ and thus they all have at least $ Z(n) $ crossings. The
techniques developed provide a unified proof of the Harary-Hill conjecture for
these classes of drawings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3674</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3674</id><created>2013-09-14</created><authors><author><keyname>Fanaei</keyname><forenames>Mohammad</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author><author><keyname>Schmid</keyname><forenames>Natalia A.</forenames></author></authors><title>Power Allocation for Distributed BLUE Estimation with Full and Limited
  Feedback of CSI</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, to appear at the IEEE Military Communications
  Conference (MILCOM) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of adaptive power allocation for
distributed best linear unbiased estimation (BLUE) of a random parameter at the
fusion center (FC) of a wireless sensor network (WSN). An optimal
power-allocation scheme is proposed that minimizes the $L^2$-norm of the vector
of local transmit powers, given a maximum variance for the BLUE estimator. This
scheme results in the increased lifetime of the WSN compared to similar
approaches that are based on the minimization of the sum of the local transmit
powers. The limitation of the proposed optimal power-allocation scheme is that
it requires the feedback of the instantaneous channel state information (CSI)
from the FC to local sensors, which is not practical in most applications of
large-scale WSNs. In this paper, a limited-feedback strategy is proposed that
eliminates this requirement by designing an optimal codebook for the FC using
the generalized Lloyd algorithm with modified distortion metrics. Each sensor
amplifies its analog noisy observation using a quantized version of its optimal
amplification gain, which is received by the FC and used to estimate the
unknown parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3675</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3675</id><created>2013-09-14</created><authors><author><keyname>Im</keyname><forenames>Sungjin</forenames></author><author><keyname>Sviridenko</keyname><forenames>Maxim</forenames></author></authors><title>Optimizing Maximum Flow Time and Maximum Throughput in Broadcast
  Scheduling</title><categories>cs.DS</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the pull-based broadcast scheduling model. In this model, there
are n unit-sized pages of information available at the server. Requests arrive
over time at the server asking for a specific page. When the server transmits a
page, all outstanding requests for the page are simultaneously satisfied, and
this is what distinguishes broadcast scheduling from the standard scheduling
setting where each job must be processed separately by the server. Broadcast
scheduling has received a considerable amount of attention due to the
algorithmic challenges that it gives in addition to its applications in
multicast systems and wireless and LAN networks. In this paper, we give the
following new approximation results for two popular objectives:
  - For the objective of minimizing the maximum flow time, we give the first
PTAS. Previously, it was known that the algorithm First-In-First-Out (FIFO) is
a 2-approximation, and it is tight. It has been suggested as an open problem to
obtain a better approximation.
  - For the objective of maximizing the throughput, we give a
0.7759-approximation which improves upon the previous best known
0.75-approximation.
  Our improved results are enabled by our novel rounding schemes and linear
programming which can effectively reduce congestion in schedule which is often
the main bottleneck in designing scheduling algorithms based on linear
programming. We believe that our algorithmic ideas and techniques could be of
potential use for other scheduling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3676</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3676</id><created>2013-09-14</created><authors><author><keyname>Cleju</keyname><forenames>Nicolae</forenames></author></authors><title>Optimized projections for compressed sensing via rank-constrained
  nearest correlation matrix</title><categories>cs.IT cs.LG math.IT stat.ML</categories><comments>25 pages, 13 figures, to appear in Applied and Computational Harmonic
  Analysis</comments><doi>10.1016/j.acha.2013.08.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimizing the acquisition matrix is useful for compressed sensing of signals
that are sparse in overcomplete dictionaries, because the acquisition matrix
can be adapted to the particular correlations of the dictionary atoms. In this
paper a novel formulation of the optimization problem is proposed, in the form
of a rank-constrained nearest correlation matrix problem. Furthermore,
improvements for three existing optimization algorithms are introduced, which
are shown to be particular instances of the proposed formulation. Simulation
results show notable improvements and superior robustness in sparse signal
recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3685</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3685</id><created>2013-09-14</created><authors><author><keyname>Mitrevski</keyname><forenames>Pece</forenames></author><author><keyname>Gusev</keyname><forenames>Marjan</forenames></author></authors><title>On the Performance Potential of Speculative Execution based on Branch
  and Value Prediction</title><categories>cs.AR</categories><journal-ref>International Scientific Journal Facta Universitatis, Series:
  Electronics and Energetics, Vol. 16, No. 1, ISSN: 0353-3670, pp. 83-91, 2003</journal-ref><doi>10.2298/FUEE0301083M</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fluid Stochastic Petri Nets are used to capture the dynamic behavior of an
ILP processor, and discrete-event simulation is applied to assess the
performance potential of predictions and speculative execution in boosting the
performance of ILP processors that fetch, issue, execute and commit a large
number of instructions per cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3686</identifier>
 <datestamp>2015-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3686</id><created>2013-09-14</created><updated>2014-11-16</updated><authors><author><keyname>B&#xe9;daride</keyname><forenames>Nicolas</forenames></author><author><keyname>Fernique</keyname><forenames>Thomas</forenames></author></authors><title>When periodicities enforce aperiodicity</title><categories>math.DS cs.DM math-ph math.MP</categories><comments>27 pages, 12 figures</comments><msc-class>37B50, 52C23</msc-class><journal-ref>Communications in Mathematical Physics 335 (2015), pp. 1099--1120</journal-ref><doi>10.1007/s00220-015-2334-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aperiodic tilings are non-periodic tilings defined by local rules. They are
widely used to model quasicrystals, and a central question is to understand
which of the non-periodic tilings are actually aperiodic. Among tilings, those
by rhombi can be easily seen as approximations of surfaces in higher
dimensional spaces. In particular, those which approximate irrational planes
are non-periodic. But which ones are also aperiodic? This paper introduces the
notion of subperiod, which links algebraic properties of a plane with geometric
properties of the tilings that approximate it. A necessary and sufficient
condition is obtained for tilings that can be seen in the four dimensional
Euclidean space. This result is then applied to some examples in higher
codimensions, notably tilings with n-fold rotational symmetry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3688</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3688</id><created>2013-09-14</created><authors><author><keyname>Kostoska</keyname><forenames>Olivera</forenames></author><author><keyname>Mitrevski</keyname><forenames>Pece</forenames></author><author><keyname>Hristoski</keyname><forenames>Ilija</forenames></author></authors><title>ICT and Competitiveness of the Macedonian Economy</title><categories>cs.CY</categories><journal-ref>Annals of the University &quot;Constantin Brancusi&quot; of Tg-Jiu, No.
  1/2008, Volume 1, Editura Academica Brancusi, Tg-Jiu, ISSN: 1842-4856</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ongoing process of liberalization, as well as the intensive technological
breakthrough have a great impact either on the macroeconomic policy creators,
or the dissimilarity of conventional approach to found a strategy of a certain
company. Bearing in mind the very notation, core characteristics of the concept
of competitiveness are needed to be explored, but also the necessity to
establish a national competitiveness strategy. However, the main attention
should be paid on the technological changes that affect the economic growth,
but the life standard increase, as well. Nevertheless, developing and
transitional economies are being down-sided with respect to the technological
and innovative capability that measurably implies the necessity to redefine the
conception of competitiveness. Taking into account the above clarifications,
the paper will set a comparative analysis of the key factors that pressure the
competitiveness of Balkans region countries, mainly by the composition of the
Growth Competitiveness Index. In addition, the major accent will be put on the
composite Technology index and its impact on the mainstream of the respective
total index. Finally, the paper will examine the possible change of Growth
Competitiveness Index ranking of the Macedonian economy, principally by the
variation of the Technology index rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3689</identifier>
 <datestamp>2014-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3689</id><created>2013-09-14</created><updated>2014-07-15</updated><authors><author><keyname>Hristoski</keyname><forenames>Ilija</forenames></author><author><keyname>Mitrevski</keyname><forenames>Pece</forenames></author></authors><title>Simulating e-Commerce Client-Server Interaction for Capacity Planning</title><categories>cs.CY</categories><comments>10 pages, 5 figures, 5 tables</comments><acm-class>K.4.4; J.1</acm-class><journal-ref>e-Society Journal: Research and Applications, Vol. 3, No. 2, pp.
  85-94, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contemporary ways of doing business are heavily dependent on the
e-Commerce/e-Business paradigm. The highest priority of an e-Commerce Web
site's management is to assure pertinent Quality-of-Service (QoS) levels of
their Web services continually, in order to keep the potential e-Customers
satisfied. Otherwise, it faces an immense possibility of losing both
e-Customers and revenues, along with a big possibility of gaining bad
reputation due to either poor performance or unavailability of the e-Commerce
Web site. In order to avoid numerous unpleasant consequences, by designing and
implementing e-Commerce Web sites that will always meet e-Customer's high
expectations, a relevant performance models have to be utilized to obtain
appropriate performance metrics. A continuous assessment of current
performances and especially predicting future needs are the subjects of
capacity planning methodologies. Within this paper, such a predictive model has
been described and evaluated by using discrete-event simulation of both the
client-side and server-side processes involved. In addition, the paper
discusses the performance metrics obtained as a function of the intensity and
quality of the workload parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3690</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3690</id><created>2013-09-14</created><authors><author><keyname>Beame</keyname><forenames>Paul</forenames></author><author><keyname>Clifford</keyname><forenames>Raphael</forenames></author><author><keyname>Machmouchi</keyname><forenames>Widad</forenames></author></authors><title>Element Distinctness, Frequency Moments, and Sliding Windows</title><categories>cs.CC</categories><comments>arXiv admin note: substantial text overlap with arXiv:1212.4372</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive new time-space tradeoff lower bounds and algorithms for exactly
computing statistics of input data, including frequency moments, element
distinctness, and order statistics, that are simple to calculate for sorted
data. We develop a randomized algorithm for the element distinctness problem
whose time T and space S satisfy T in O (n^{3/2}/S^{1/2}), smaller than
previous lower bounds for comparison-based algorithms, showing that element
distinctness is strictly easier than sorting for randomized branching programs.
This algorithm is based on a new time and space efficient algorithm for finding
all collisions of a function f from a finite set to itself that are reachable
by iterating f from a given set of starting points. We further show that our
element distinctness algorithm can be extended at only a polylogarithmic factor
cost to solve the element distinctness problem over sliding windows, where the
task is to take an input of length 2n-1 and produce an output for each window
of length n, giving n outputs in total. In contrast, we show a time-space
tradeoff lower bound of T in Omega(n^2/S) for randomized branching programs to
compute the number of distinct elements over sliding windows. The same lower
bound holds for computing the low-order bit of F_0 and computing any frequency
moment F_k, k neq 1. This shows that those frequency moments and the decision
problem F_0 mod 2 are strictly harder than element distinctness. We complement
this lower bound with a T in O(n^2/S) comparison-based deterministic RAM
algorithm for exactly computing F_k over sliding windows, nearly matching both
our lower bound for the sliding-window version and the comparison-based lower
bounds for the single-window version. We further exhibit a quantum algorithm
for F_0 over sliding windows with T in O(n^{3/2}/S^{1/2}). Finally, we consider
the computations of order statistics over sliding windows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3692</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3692</id><created>2013-09-14</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author><author><keyname>Ahmad</keyname><forenames>Sahand Haji Ali</forenames></author></authors><title>Sufficient Conditions on the Optimality of Myopic Sensing in
  Opportunistic Channel Access: A Unifying Framework</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a widely studied stochastic control problem arising from
opportunistic spectrum access (OSA) in a multi-channel system, with the goal of
providing a unifying analytical framework whereby a number of prior results may
be viewed as special cases. Specifically, we consider a single wireless
transceiver/user with access to $N$ channels, each modeled as an iid
discrete-time two-state Markov chain. In each time step the user is allowed to
sense $k\leq N$ channels, and subsequently use up to $m\leq k$ channels out of
those sensed to be available. Channel sensing is assumed to be perfect, and for
each channel use in each time step the user gets a unit reward. The user's
objective is to maximize its total discounted or average reward over a finite
or infinite horizon. This problem has previously been studied in various
special cases including $k=1$ and $m=k\leq N$, often cast as a restless bandit
problem, with optimality results derived for a myopic policy that seeks to
maximize the immediate one-step reward when the two-state Markov chain model is
positively correlated. In this paper we study the general problem with $1\leq
m\leq k\leq N$, and derive sufficient conditions under which the myopic policy
is optimal for the finite and infinite horizon reward criteria, respectively.
It is shown that these results reduce to those derived in prior studies under
the corresponding special cases, and thus may be viewed as a set of unifying
optimality conditions. Numerical examples are also presented to highlight how
and why an optimal policy may deviate from the otherwise-optimal myopic sensing
given additional exploration opportunities, i.e., when $m&lt;k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3696</identifier>
 <datestamp>2014-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3696</id><created>2013-09-14</created><updated>2014-01-03</updated><authors><author><keyname>Caraballo</keyname><forenames>L. E.</forenames></author><author><keyname>Ochoa</keyname><forenames>C.</forenames></author><author><keyname>P&#xe9;rez-Lantero</keyname><forenames>P.</forenames></author><author><keyname>Rojas-Ledesma</keyname><forenames>J.</forenames></author></authors><title>Matching colored points with rectangles</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $S$ be a point set in the plane such that each of its elements is colored
either red or blue. A matching of $S$ with rectangles is any set of
pairwise-disjoint axis-aligned rectangles such that each rectangle contains
exactly two points of $S$. Such a matching is monochromatic if every rectangle
contains points of the same color, and is bichromatic if every rectangle
contains points of different colors. In this paper we study the following two
problems:
  1. Find a maximum monochromatic matching of $S$ with rectangles.
  2. Find a maximum bichromatic matching of $S$ with rectangles.
  For each problem we provide a polynomial-time approximation algorithm that
constructs a matching with at least $1/4$ of the number of rectangles of an
optimal matching. We show that the first problem is $\mathsf{NP}$-hard even if
either the matching rectangles are restricted to axis-aligned segments or $S$
is in general position, that is, no two points of $S$ share the same $x$ or $y$
coordinate. We further show that the second problem is also $\mathsf{NP}$-hard,
even if $S$ is in general position. These $\mathsf{NP}$-hardness results follow
by showing that deciding the existence of a perfect matching is
$\mathsf{NP}$-complete in each case. The approximation results are based on a
relation of our problem with the problem of finding a maximum independent set
in a family of axis-aligned rectangles. With this paper we extend previous ones
on matching one-colored points with rectangles and squares, and matching
two-colored points with segments. Furthermore, using our techniques, we prove
that it is $\mathsf{NP}$-complete to decide a perfect matching with rectangles
in the case where all points have the same color, solving an open problem of
Bereg, Mutsanas, and Wolff [CGTA (2009)].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3697</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3697</id><created>2013-09-14</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Group Learning and Opinion Diffusion in a Broadcast Network</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the following group learning problem in the context of opinion
diffusion: Consider a network with $M$ users, each facing $N$ options. In a
discrete time setting, at each time step, each user chooses $K$ out of the $N$
options, and receive randomly generated rewards, whose statistics depend on the
options chosen as well as the user itself, and are unknown to the users. Each
user aims to maximize their expected total rewards over a certain time horizon
through an online learning process, i.e., a sequence of exploration (sampling
the return of each option) and exploitation (selecting empirically good
options) steps.
  Within this context we consider two group learning scenarios, (1) users with
uniform preferences and (2) users with diverse preferences, and examine how a
user should construct its learning process to best extract information from
other's decisions and experiences so as to maximize its own reward. Performance
is measured in {\em weak regret}, the difference between the user's total
reward and the reward from a user-specific best single-action policy (i.e.,
always selecting the set of options generating the highest mean rewards for
this user). Within each scenario we also consider two cases: (i) when users
exchange full information, meaning they share the actual rewards they obtained
from their choices, and (ii) when users exchange limited information, e.g.,
only their choices but not rewards obtained from these choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3701</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3701</id><created>2013-09-14</created><authors><author><keyname>Cseh</keyname><forenames>&#xc1;gnes</forenames></author></authors><title>Stable flows with restricted edges</title><categories>cs.DM cs.DS math.CO</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stable marriage problem with its extensions is a widely studied subject.
In this paper, we combine two topics related to it, setting up new and
generalizing known results in both. The stable flow problem extends the
well-known stable matching problem to network flows. Restricted edges have some
special properties: forced edges must be in the stable solution, while
forbidden edges may not be in it. Free edges are not able to block matchings.
  Here we describe a polynomial algorithm that finds a stable flow with forced
and forbidden edges or proves its nonexistence. In contrast to this, we also
show that determining whether a stable flow with free edges exists, is
NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3704</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3704</id><created>2013-09-14</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>To Stay Or To Switch: Multiuser Dynamic Channel Access</title><categories>cs.SY cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study opportunistic spectrum access (OSA) policies in a
multiuser multichannel random access cognitive radio network, where users
perform channel probing and switching in order to obtain better channel
condition or higher instantaneous transmission quality. However, unlikely many
prior works in this area, including those on channel probing and switching
policies for a single user to exploit spectral diversity, and on probing and
access policies for multiple users over a single channel to exploit temporal
and multiuser diversity, in this study we consider the collective switching of
multiple users over multiple channels. In addition, we consider finite
arrivals, i.e., users are not assumed to always have data to send and demand
for channel follow a certain arrival process. Under such a scenario, the users'
ability to opportunistically exploit temporal diversity (the temporal variation
in channel quality over a single channel) and spectral diversity (quality
variation across multiple channels at a given time) is greatly affected by the
level of congestion in the system. We investigate the optimal decision process
in this case, and evaluate the extent to which congestion affects potential
gains from opportunistic dynamic channel switching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3716</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3716</id><created>2013-09-14</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author><author><keyname>Deng</keyname><forenames>Jing</forenames></author></authors><title>Revisiting Optimal Power Control: its Dual Effect on SNR and Contention</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a transmission power tune problem with densely
deployed 802.11 Wireless Local Area Networks (WLANs). While previous papers
emphasize on tuning transmission power with either PHY or MAC layer separately,
optimally setting each Access Point's (AP's) transmission power of a densely
deployed 802.11 network considering its dual effects on both layers remains an
open problem. In this work, we design a measure by evaluating impacts of
transmission power on network performance on both PHY and MAC layers. We show
that such an optimization problem is intractable and then we investigate and
develop an analytical framework to allow simple yet efficient solutions.
Through simulations and numerical results, we observe clear benefits of the
dual-effect model compared to solutions optimizing solely on a single layer;
therefore, we conclude that tuning transmission power from a dual layer
(PHY-MAC) point of view is essential and necessary for dense WLANs. We further
form a game theoretical framework and investigate above power-tune problem in a
strategic network. We show that with decentralized and strategic users, the
Nash Equilibrium (N.E.) of the corresponding game is in-efficient and
thereafter we propose a punishment based mechanism to enforce users to adopt
the social optimal strategy profile under both perfect and imperfect sensing
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3719</identifier>
 <datestamp>2015-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3719</id><created>2013-09-14</created><updated>2015-11-11</updated><authors><author><keyname>Skliar</keyname><forenames>Osvaldo</forenames></author><author><keyname>Monge</keyname><forenames>Ricardo E.</forenames></author><author><keyname>Oviedo</keyname><forenames>Guillermo</forenames></author><author><keyname>Gapper</keyname><forenames>Sherry</forenames></author></authors><title>A New Method for the Analysis of Signals: The Square Wave Transform
  (SWT)</title><categories>cs.NA</categories><comments>25 pages, 23 figures</comments><msc-class>94A12, 65F99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The results obtained by analyzing signals with the Square Wave Method (SWM)
introduced previously can be presented in the frequency domain clearly and
precisely by using the Square Wave Transform (SWT) described here. As an
example, the SWT is used to analyze a sequence of samples (that is, of measured
values) taken from an electroencephalographic recording.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3720</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3720</id><created>2013-09-14</created><authors><author><keyname>Fish</keyname><forenames>Alexander</forenames></author><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames></author></authors><title>The Incidence and Cross Methods for Efficient Radar Detection</title><categories>cs.IT math.IT</categories><comments>8 pages. Accepted for publication in Proceedings of Allerton
  Conference on Communication, Control, and Computing, October, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The designation of the radar system is to detect the position and velocity of
targets around us. The radar transmits a waveform, which is reflected back from
the targets, and echo waveform is received. In a commonly used model, the echo
is a sum of a superposition of several delay-Doppler shifts of the transmitted
waveform, and a noise component. The delay and Doppler parameters encode,
respectively, the distances, and relative velocities, between the targets and
the radar. Using standard digital-to-analog and sampling techniques, the
estimation task of the delay-Doppler parameters, which involves waveforms, is
reduced to a problem for complex sequences of finite length N. In these notes
we introduce the Incidence and Cross methods for radar detection. One of their
advantages, is robustness to inhomogeneous radar scene, i.e., for sensing small
targets in the vicinity of large objects. The arithmetic complexity of the
incidence and cross methods is O(NlogN + r^3) and O(NlogN + r^2), for r
targets, respectively. In the case of noisy environment, these are the fastest
radar detection techniques. Both methods employ chirp sequences, which are
commonly used by radar systems, and hence are attractive for real world
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3730</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3730</id><created>2013-09-15</created><authors><author><keyname>Martinez</keyname><forenames>Matias</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Duchien</keyname><forenames>Laurence</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Monperrus</keyname><forenames>Martin</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>Automatically Extracting Instances of Code Change Patterns with AST
  Analysis</title><categories>cs.SE</categories><comments>ICSM - 29th IEEE International Conference on Software Maintenance
  (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A code change pattern represents a kind of recurrent modification in
software. For instance, a known code change pattern consists of the change of
the conditional expression of an if statement. Previous work has identified
different change patterns. Complementary to the identification and definition
of change patterns, the automatic extraction of pattern instances is essential
to measure their empirical importance. For example, it enables one to count and
compare the number of conditional expression changes in the history of
different projects. In this paper we present a novel approach for search
patterns instances from software history. Our technique is based on the
analysis of Abstract Syntax Trees (AST) files within a given commit. We
validate our approach by counting instances of 18 change patterns in 6
open-source Java projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3733</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3733</id><created>2013-09-15</created><authors><author><keyname>Liu</keyname><forenames>Jixue</forenames></author><author><keyname>Kwashie</keyname><forenames>Selasi</forenames></author><author><keyname>Li</keyname><forenames>Jiuyong</forenames></author><author><keyname>Ye</keyname><forenames>Feiyue</forenames></author><author><keyname>Vincent</keyname><forenames>Millist</forenames></author></authors><title>Discovery of Approximate Differential Dependencies</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential dependencies (DDs) capture the relationships between data
columns of relations. They are more general than functional dependencies (FDs)
and and the difference is that DDs are defined on the distances between values
of two tuples, not directly on the values. Because of this difference, the
algorithms for discovering FDs from data find only special DDs, not all DDs and
therefore are not applicable to DD discovery. In this paper, we propose an
algorithm to discover DDs from data following the way of fixing the left hand
side of a candidate DD to determine the right hand side. We also show some
properties of DDs and conduct a comprehensive analysis on how sampling affects
the DDs discovered from data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3745</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3745</id><created>2013-09-15</created><authors><author><keyname>Kulkarni</keyname><forenames>Ankur A.</forenames></author><author><keyname>Coleman</keyname><forenames>Todd P.</forenames></author></authors><title>An Optimizer's Approach to Stochastic Control Problems with Nonclassical
  Information Structures</title><categories>math.OC cs.IT math.IT</categories><comments>Under review with the IEEE Transactions on Automatic Control</comments><msc-class>93E20, 91A12, 49N10, 93C41, 94A34, 94A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an optimization-based approach to stochastic control problems with
nonclassical information structures. We cast these problems equivalently as
optimization prob- lems on joint distributions. The resulting problems are
necessarily nonconvex. Our approach to solving them is through convex
relaxation. We solve the instance solved by Bansal and Basar with a particular
application of this approach that uses the data processing inequality for
constructing the convex relaxation. Using certain f-divergences, we obtain a
new, larger set of inverse optimal cost functions for such problems. Insights
are obtained on the relation between the structure of cost functions and of
convex relaxations for inverse optimal control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3752</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3752</id><created>2013-09-15</created><authors><author><keyname>Lin</keyname><forenames>Sian-Jheng</forenames></author><author><keyname>Chung</keyname><forenames>Wei-Ho</forenames></author></authors><title>Novel Repair-by-Transfer Codes and Systematic Exact-MBR Codes with Lower
  Complexities and Smaller Field Sizes</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The $(n,k,d)$ regenerating code is a class of $(n,k)$ erasure codes with the
capability to recover a lost code fragment from other $d$ existing code
fragments. This paper concentrates on the design of exact regenerating codes at
Minimum Bandwidth Regenerating (MBR) points. For $d=n-1$, a class of
$(n,k,d=n-1)$ Exact-MBR codes, termed as repair-by-transfer codes, have been
developed in prior work to avoid arithmetic operations in node repairing
process. The first result of this paper presents a new class of
repair-by-transfer codes via congruent transformations. As compared with the
prior works, the advantages of the proposed codes include: i) The minimum of
the finite field size is significantly reduced from $n \choose 2$ to $n$. ii)
The encoding complexity is decreased from $n^4$ to $n^3$. As shown in
simulations, the proposed repair-by-transfer codes have lower computational
overhead when $n$ is greater than a specific constant. The second result of
this paper presents a new form of coding matrix for product-matrix Exact-MBR
codes. The proposed coding matrix includes a number of advantages: i). The
minimum of the finite field size is reduced from $n-k+d$ to $n$. ii). The fast
Reed-Solomon erasure coding algorithms can be applied on the Exact-MBR codes to
reduce the time complexities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3775</identifier>
 <datestamp>2014-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3775</id><created>2013-09-15</created><updated>2014-04-04</updated><authors><author><keyname>de Barros</keyname><forenames>J. Acacio</forenames></author></authors><title>Beyond the quantum formalism: consequences of a neural-oscillator model
  to quantum cognition</title><categories>physics.bio-ph cs.AI q-bio.NC quant-ph</categories><comments>4 pages; to appear in the Advances in Cognitive Neurodynamics,
  Proceedings of the 4th International Conference on Cognitive Neurodynamics -
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a neural oscillator model of stimulus response
theory that exhibits quantum-like behavior. We then show that without adding
any additional assumptions, a quantum model constructed to fit observable
pairwise correlations has no predictive power over the unknown triple moment,
obtainable through the activation of multiple oscillators. We compare this with
the results obtained in de Barros (2013), where a criteria of rationality gives
optimal ranges for the triple moment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3783</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3783</id><created>2013-09-15</created><authors><author><keyname>Gonnet</keyname><forenames>Pedro</forenames></author><author><keyname>Schaller</keyname><forenames>Matthieu</forenames></author><author><keyname>Theuns</keyname><forenames>Tom</forenames></author><author><keyname>Chalk</keyname><forenames>Aidan B. G.</forenames></author></authors><title>SWIFT: Fast algorithms for multi-resolution SPH on multi-core
  architectures</title><categories>astro-ph.IM astro-ph.CO cs.DC</categories><comments>8th International SPHERIC Workshop, Trondheim, Norway, June 3--6,
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a novel approach to neighbour-finding in Smoothed
Particle Hydrodynamics (SPH) simulations with large dynamic range in smoothing
length. This approach is based on hierarchical cell decompositions, sorted
interactions, and a task-based formulation. It is shown to be faster than
traditional tree-based codes, and to scale better than domain
decomposition-based approaches on shared-memory parallel architectures such as
multi-cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3785</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3785</id><created>2013-09-15</created><authors><author><keyname>Mittal</keyname><forenames>Sparsh</forenames></author></authors><title>Energy Saving Techniques for Phase Change Memory (PCM)</title><categories>cs.AR</categories><comments>Survey, phase change RAM (PCRAM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the energy consumption of computing systems has increased
and a large fraction of this energy is consumed in main memory. Towards this,
researchers have proposed use of non-volatile memory, such as phase change
memory (PCM), which has low read latency and power; and nearly zero leakage
power. However, the write latency and power of PCM are very high and this,
along with limited write endurance of PCM present significant challenges in
enabling wide-spread adoption of PCM. To address this, several
architecture-level techniques have been proposed. In this report, we review
several techniques to manage power consumption of PCM. We also classify these
techniques based on their characteristics to provide insights into them. The
aim of this work is encourage researchers to propose even better techniques for
improving energy efficiency of PCM based main memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3792</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3792</id><created>2013-09-15</created><authors><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author><author><keyname>Riechers</keyname><forenames>Paul M.</forenames></author></authors><title>Exact Complexity: The Spectral Decomposition of Intrinsic Computation</title><categories>cond-mat.stat-mech cs.IT math.IT nlin.CD nlin.CG</categories><comments>5 pages; Supplementary 13 pages, 12 figures, 2 tables;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/ec.htm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give exact formulae for a wide family of complexity measures that capture
the organization of hidden nonlinear processes. The spectral decomposition of
operator-valued functions leads to closed-form expressions involving the full
eigenvalue spectrum of the mixed-state presentation of a process's
epsilon-machine causal-state dynamic. Measures include correlation functions,
power spectra, past-future mutual information, transient and synchronization
informations, and many others. As a result, a direct and complete analysis of
intrinsic computation is now available for the temporal organization of
finitary hidden Markov models and nonlinear dynamical systems with generating
partitions and for the spatial organization in one-dimensional systems,
including spin systems, cellular automata, and complex materials via chaotic
crystallography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3797</identifier>
 <datestamp>2014-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3797</id><created>2013-09-15</created><authors><author><keyname>Shekhtman</keyname><forenames>Louis M.</forenames></author><author><keyname>Bagrow</keyname><forenames>James P.</forenames></author><author><keyname>Brockmann</keyname><forenames>Dirk</forenames></author></authors><title>Robustness of skeletons and salient features in networks</title><categories>physics.soc-ph cs.SI</categories><doi>10.1093/comnet/cnt019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real world network datasets often contain a wealth of complex topological
information. In the face of these data, researchers often employ methods to
extract reduced networks containing the most important structures or pathways,
sometimes known as `skeletons' or `backbones'. Numerous such methods have been
developed. Yet data are often noisy or incomplete, with unknown numbers of
missing or spurious links. Relatively little effort has gone into understanding
how salient network extraction methods perform in the face of noisy or
incomplete networks. We study this problem by comparing how the salient
features extracted by two popular methods change when networks are perturbed,
either by deleting nodes or links, or by randomly rewiring links. Our results
indicate that simple, global statistics for skeletons can be accurately
inferred even for noisy and incomplete network data, but it is crucial to have
complete, reliable data to use the exact topologies of skeletons or backbones.
These results also help us understand how skeletons respond to damage to the
network itself, as in an attack scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3798</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3798</id><created>2013-09-15</created><authors><author><keyname>Singh</keyname><forenames>Rahul</forenames></author><author><keyname>Hou</keyname><forenames>I-Hong</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Pathwise Performance of Debt Based Policies for Wireless Networks with
  Hard Delay Constraints</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hou et al have introduced a framework to serve clients over wireless channels
when there are hard deadline constraints along with a minimum delivery ratio
for each client's flow. Policies based on &quot;debt,&quot; called maximum debt first
policies (MDF) were introduced, and shown to be throughput optimal. By
&quot;throughput optimality&quot; it is meant that if there exists a policy that fulfils
a set of clients with a given vector of delivery ratios and a vector of channel
reliabilities, then the MDF policy will also fulfill them. The debt of a user
is the difference between the number of packets that should have been delivered
so as to meet the delivery ratio and the number of packets that have been
delivered for that client. The maximum debt first (MDF) prioritizes the clients
in decreasing order of debts at the beginning of every period. Note that a
throughput optimal policy only guarantees that \begin{small} $\liminf_{T \to
\infty} \frac{1}{T}\sum_{t=1}^{T} \mathbbm{1}\{\{client $n$'s packet is
delivered in frame $t$} \} \geq q_{i}$ \end{small}, where the right hand side
is the required delivery ratio for client $i$. Thus, it only guarantees that
the debts of each user are $o(T)$, and can be otherwise arbitrarily large. This
raises the interesting question about what is the growth rate of the debts
under the MDF policy. We show the optimality of MDF policy in the case when the
channel reliabilities of all users are same, and obtain performance bounds for
the general case. For the performance bound we obtain the almost sure bounds on
$\limsup_{t\to\infty}\frac{d_{i}(t)}{\phi(t)}$ for all $i$, where $\phi(t) =
\sqrt{2t\log\log t}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3808</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3808</id><created>2013-09-15</created><authors><author><keyname>Zu</keyname><forenames>K.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author><author><keyname>Haardt</keyname><forenames>M.</forenames></author></authors><title>Low-Complexity Design of Generalized Block Diagonalization Precoding
  Algorithms for Multiuser MIMO Systems</title><categories>cs.IT math.IT</categories><comments>7 figures, 10 pages. IEEE Transactions on Communications, 2013. arXiv
  admin note: text overlap with arXiv:1304.6470</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Block diagonalization (BD) based precoding techniques are well-known linear
transmit strategies for multiuser MIMO (MU-MIMO) systems. By employing BD-type
precoding algorithms at the transmit side, the MU-MIMO broadcast channel is
decomposed into multiple independent parallel single user MIMO (SU-MIMO)
channels and achieves the maximum diversity order at high data rates. The main
computational complexity of BD-type precoding algorithms comes from two
singular value decomposition (SVD) operations, which depend on the number of
users and the dimensions of each user's channel matrix. In this work,
low-complexity precoding algorithms are proposed to reduce the computational
complexity and improve the performance of BD-type precoding algorithms. We
devise a strategy based on a common channel inversion technique, QR
decompositions, and lattice reductions to decouple the MU-MIMO channel into
equivalent SU-MIMO channels. Analytical and simulation results show that the
proposed precoding algorithms can achieve a comparable sum-rate performance as
BD-type precoding algorithms, substantial bit error rate (BER) performance
gains, and a simplified receiver structure, while requiring a much lower
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3809</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3809</id><created>2013-09-15</created><authors><author><keyname>Chakraborty</keyname><forenames>Ishani</forenames></author><author><keyname>Elgammal</keyname><forenames>Ahmed</forenames></author></authors><title>Visual-Semantic Scene Understanding by Sharing Labels in a Context
  Network</title><categories>cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of naming objects in complex, natural scenes
containing widely varying object appearance and subtly different names.
Informed by cognitive research, we propose an approach based on sharing context
based object hypotheses between visual and lexical spaces. To this end, we
present the Visual Semantic Integration Model (VSIM) that represents object
labels as entities shared between semantic and visual contexts and infers a new
image by updating labels through context switching. At the core of VSIM is a
semantic Pachinko Allocation Model and a visual nearest neighbor Latent
Dirichlet Allocation Model. For inference, we derive an iterative Data
Augmentation algorithm that pools the label probabilities and maximizes the
joint label posterior of an image. Our model surpasses the performance of
state-of-art methods in several visual tasks on the challenging SUN09 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3816</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3816</id><created>2013-09-15</created><authors><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author><author><keyname>Thyssen</keyname><forenames>Christian</forenames></author></authors><title>Multiplicative Approximations, Optimal Hypervolume Distributions, and
  the Choice of the Reference Point</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many optimization problems arising in applications have to consider several
objective functions at the same time. Evolutionary algorithms seem to be a very
natural choice for dealing with multi-objective problems as the population of
such an algorithm can be used to represent the trade-offs with respect to the
given objective functions. In this paper, we contribute to the theoretical
understanding of evolutionary algorithms for multi-objective problems. We
consider indicator-based algorithms whose goal is to maximize the hypervolume
for a given problem by distributing {\mu} points on the Pareto front. To gain
new theoretical insights into the behavior of hypervolume-based algorithms we
compare their optimization goal to the goal of achieving an optimal
multiplicative approximation ratio. Our studies are carried out for different
Pareto front shapes of bi-objective problems. For the class of linear fronts
and a class of convex fronts, we prove that maximizing the hypervolume gives
the best possible approximation ratio when assuming that the extreme points
have to be included in both distributions of the points on the Pareto front.
Furthermore, we investigate the choice of the reference point on the
approximation behavior of hypervolume-based approaches and examine Pareto
fronts of different shapes by numerical calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3830</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3830</id><created>2013-09-16</created><authors><author><keyname>Qian</keyname><forenames>Haiyang</forenames></author><author><keyname>Li</keyname><forenames>Fu</forenames></author><author><keyname>Ravindran</keyname><forenames>Ravishankar</forenames></author><author><keyname>Medhi</keyname><forenames>Deep</forenames></author></authors><title>Energy-Aware Aggregation of Dynamic Temporal Workload in Data Centers</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data center providers seek to minimize their total cost of ownership (TCO),
while power consumption has become a social concern. We present formulations to
minimize server energy consumption and server cost under three different data
center server setups (homogeneous, heterogeneous, and hybrid hetero-homogeneous
clusters) with dynamic temporal workload. Our studies show that the homogeneous
model significantly differs from the heterogeneous model in computational time
(by an order of magnitude). To be able to compute optimal configurations in
near real-time for large scale data centers, we propose two modes, aggregation
by maximum and aggregation by mean. In addition, we propose two aggregation
methods, static (periodic) aggregation and dynamic (aperiodic) aggregation. We
found that in the aggregation by maximum mode, the dynamic aggregation resulted
in cost savings of up to approximately 18% over the static aggregation. In the
aggregation by mean mode, the dynamic aggregation by mean could save up to
approximately 50% workload rearrangement compared to the static aggregation by
mean mode. Overall, our methodology helps to understand the trade-off in
energy-aware aggregation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3841</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3841</id><created>2013-09-16</created><updated>2013-11-15</updated><authors><author><keyname>Chakraborty</keyname><forenames>Arpita</forenames></author><author><keyname>Ganguly</keyname><forenames>Srinjoy</forenames></author><author><keyname>Naskar</keyname><forenames>Mrinal Kanti</forenames></author><author><keyname>Karmakar</keyname><forenames>Anupam</forenames></author></authors><title>A Trust Based Fuzzy Algorithm for Congestion Control in Wireless
  Multimedia Sensor Networks (TFCC)</title><categories>cs.NI</categories><comments>6 pages, 5 figures, conference paper</comments><journal-ref>Procs. of the IEEE 2013 International Conference on Informatics,
  Electronics and Vision (ICIEV 2013), pp.XX-XX, Dhaka, Bangladesh, May 17-18,
  (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network congestion has become a critical issue for resource constrained
Wireless Sensor Networks (WSNs), especially for Wireless Multimedia Sensor
Networks (WMSNs)where large volume of multimedia data is transmitted through
the network. If the traffic load is greater than the available capacity of the
sensor network, congestion occurs and it causes buffer overflow, packet drop,
deterioration of network throughput and quality of service (QoS). Again, the
faulty nodes of the network also aggravate congestion by diffusing useless
packets or retransmitting the same packet several times. This results in the
wastage of energy and decrease in network lifetime. To address this challenge,
a new congestion control algorithm is proposed in which the faulty nodes are
identified and blocked from data communication by using the concept of trust.
The trust metric of all the nodes in the WMSN is derived by using a two-stage
Fuzzy inferencing scheme. The traffic flow from source to sink is optimized by
implementing the Link State Routing Protocol. The congestion of the sensor
nodes is controlled by regulating the rate of traffic flow on the basis of the
priority of the traffic. Finally we compare our protocol with other existing
congestion control protocols to show the merit of the work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3842</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3842</id><created>2013-09-16</created><authors><author><keyname>Svane</keyname><forenames>Anne Marie</forenames></author></authors><title>Estimation of intrinsic volumes from digital grey-scale images</title><categories>math.ST cs.CV stat.TH</categories><comments>33 pages</comments><msc-class>62H35</msc-class><doi>10.1007/s10851-013-0469-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Local algorithms are common tools for estimating intrinsic volumes from
black-and-white digital images. However, these algorithms are typically biased
in the design based setting, even when the resolution tends to infinity.
Moreover, images recorded in practice are most often blurred grey-scale images
rather than black-and-white. In this paper, an extended definition of local
algorithms, applying directly to grey-scale images without thresholding, is
suggested. We investigate the asymptotics of these new algorithms when the
resolution tends to infinity and apply this to construct estimators for surface
area and integrated mean curvature that are asymptotically unbiased in certain
natural settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3848</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3848</id><created>2013-09-16</created><authors><author><keyname>Bergh</keyname><forenames>Michael Van den</forenames></author><author><keyname>Boix</keyname><forenames>Xavier</forenames></author><author><keyname>Roig</keyname><forenames>Gemma</forenames></author><author><keyname>Van Gool</keyname><forenames>Luc</forenames></author></authors><title>SEEDS: Superpixels Extracted via Energy-Driven Sampling</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Superpixel algorithms aim to over-segment the image by grouping pixels that
belong to the same object. Many state-of-the-art superpixel algorithms rely on
minimizing objective functions to enforce color ho- mogeneity. The optimization
is accomplished by sophis- ticated methods that progressively build the
superpix- els, typically by adding cuts or growing superpixels. As a result,
they are computationally too expensive for real-time applications. We introduce
a new approach based on a simple hill-climbing optimization. Starting from an
initial superpixel partitioning, it continuously refines the superpixels by
modifying the boundaries. We define a robust and fast to evaluate energy
function, based on enforcing color similarity between the bound- aries and the
superpixel color histogram. In a series of experiments, we show that we achieve
an excellent com- promise between accuracy and efficiency. We are able to
achieve a performance comparable to the state-of- the-art, but in real-time on
a single Intel i7 CPU at 2.8GHz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3849</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3849</id><created>2013-09-16</created><authors><author><keyname>Shinn</keyname><forenames>Tong-Wook</forenames></author><author><keyname>Takaoka</keyname><forenames>Tadao</forenames></author></authors><title>Efficient Graph Algorithms for Network Analysis</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The GC problem is to identify a pre-determined number of center vertices such
that the distances or costs from (or to) the centers to (or from) other
vertices is minimized. The bottleneck of a path is the minimum capacity of
edges on the path. The Bottleneck Paths (BP) problem is to compute the paths
that give us the maximum bottleneck values between pairs of vertices. The Graph
Bottleneck (GB) problem is to find the minimum bottleneck value out of
bottleneck paths for all possible pairs of vertices. We give two similar
algorithms that are based on binary search to solve the 1-center GC problem and
the GB problem on directed graphs with unit edge costs. We achieve
$\tilde{O}(n^{2.373})$ worst case time complexity for both the 1-center GC
problem and the GB problem, where $n$ is the number of vertices in the graph.
This is better than the straightforward methods of solving the two problems in
$O(n^{2.575})$ and $O(n^{2.688})$ time bounds, respectively.
  We then combine the Bottleneck Paths (BP) problem with the well known
Shortest Paths (SP) problem to compute the shortest paths for all possible flow
values. We call this problem the Shortest Paths for All Flows (SP-AF) problem.
We show that if the flow demand is uncertain, but between two consecutive
capacity values, the unique shortest path can be computed to push that flow. If
the uncertainty stretches over two intervals, we need to prepare two shortest
paths to accommodate the uncertainty, etc. In introducing this new problem, we
define a new semi-ring called the distance/flow semi-ring, and show that the
well known algorithm by Floyd can be used over the distance/flow semi-ring to
solve the All Pairs Shortest Paths for All Flows (APSP-AF) problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3858</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3858</id><created>2013-09-16</created><authors><author><keyname>Aichholzer</keyname><forenames>Oswin</forenames></author><author><keyname>Hackl</keyname><forenames>Thomas</forenames></author><author><keyname>Korman</keyname><forenames>Matias</forenames></author><author><keyname>Pilz</keyname><forenames>Alexander</forenames></author><author><keyname>Vogtenhuber</keyname><forenames>Birgit</forenames></author></authors><title>Geodesic-Preserving Polygon Simplification</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polygons are a paramount data structure in computational geometry. While the
complexity of many algorithms on simple polygons or polygons with holes depends
on the size of the input polygon, the intrinsic complexity of the problems
these algorithms solve is often related to the reflex vertices of the polygon.
In this paper, we give an easy-to-describe linear-time method to replace an
input polygon $\mathcal{P}$ by a polygon $\mathcal{P}'$ such that (1)
$\mathcal{P}'$ contains $\mathcal{P}$, (2) $\mathcal{P}'$ has its reflex
vertices at the same positions as $\mathcal{P}$, and (3) the number of vertices
of $\mathcal{P}'$ is linear in the number of reflex vertices. Since the
solutions of numerous problems on polygons (including shortest paths, geodesic
hulls, separating point sets, and Voronoi diagrams) are equivalent for both
$\mathcal{P}$ and $\mathcal{P}'$, our algorithm can be used as a preprocessing
step for several algorithms and makes their running time dependent on the
number of reflex vertices rather than on the size of $\mathcal{P}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3864</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3864</id><created>2013-09-16</created><authors><author><keyname>Huang</keyname><forenames>Kechao</forenames></author><author><keyname>Liang</keyname><forenames>Chulong</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author></authors><title>Unequal Error Protection by Partial Superposition Transmission Using
  LDPC Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider designing low-density parity-check (LDPC) coded
modulation systems to achieve unequal error protection (UEP). We propose a new
UEP approach by partial superposition transmission called UEP-by-PST. In the
UEP-by-PST system, the information sequence is distinguished as two parts, the
more important data (MID) and the less important data (LID), both of which are
coded with LDPC codes. The codeword that corresponds to the MID is superimposed
on the codeword that corresponds to the LID. The system performance can be
analyzed by using discretized density evolution. Also proposed in this paper is
a criterion from a practical point of view to compare the efficiencies of
different UEP approaches. Numerical results show that, over both additive white
Gaussian noise (AWGN) channels and uncorrelated Rayleigh fading channels, 1)
UEP-by-PST provides higher coding gain for the MID compared with the
traditional equal error protection (EEP) approach, but with negligible
performance loss for the LID; 2) UEP-by-PST is more efficient with the proposed
practical criterion than the UEP approach in the digital video broadcasting
(DVB) system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3870</identifier>
 <datestamp>2014-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3870</id><created>2013-09-16</created><updated>2014-01-07</updated><authors><author><keyname>Markstr&#xf6;m</keyname><forenames>Klas</forenames></author></authors><title>Improved bounds for the shortness coefficient of cyclically 4-edge
  connected cubic graphs and snarks</title><categories>math.CO cs.DM</categories><comments>V2: Corrected the statement of Observation 4.1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a construction which shows that there is an infinite set of
cyclically 4-edge connected cubic graphs on $n$ vertices with no cycle longer
than $c_4 n$ for $c_4=\frac{12}{13}$, and at the same time prove that a certain
natural family of cubic graphs cannot be used to lower the shortness
coefficient $c_4$ to 0.
  The graphs we construct are snarks so we get the same upper bound for the
shortness coefficient of snarks, and we prove that the constructed graphs have
an oddness growing linearly with the number of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3874</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3874</id><created>2013-09-16</created><authors><author><keyname>Luo</keyname><forenames>Wuqiong</forenames></author><author><keyname>Tay</keyname><forenames>Wee Peng</forenames></author></authors><title>Finding an infection source under the SIS model</title><categories>cs.SI q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of identifying an infection source based only on an
observed set of infected nodes in a network, assuming that the infection
process follows a Susceptible-Infected-Susceptible (SIS) model. We derive an
estimator based on estimating the most likely infection source associated with
the most likely infection path. Simulation results on regular trees suggest
that our estimator performs consistently better than the minimum distance
centrality based heuristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3877</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3877</id><created>2013-09-16</created><authors><author><keyname>Do</keyname><forenames>Huyen</forenames></author><author><keyname>Kalousis</keyname><forenames>Alexandros</forenames></author></authors><title>A Metric-learning based framework for Support Vector Machines and
  Multiple Kernel Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most metric learning algorithms, as well as Fisher's Discriminant Analysis
(FDA), optimize some cost function of different measures of within-and
between-class distances. On the other hand, Support Vector Machines(SVMs) and
several Multiple Kernel Learning (MKL) algorithms are based on the SVM large
margin theory. Recently, SVMs have been analyzed from SVM and metric learning,
and to develop new algorithms that build on the strengths of each. Inspired by
the metric learning interpretation of SVM, we develop here a new
metric-learning based SVM framework in which we incorporate metric learning
concepts within SVM. We extend the optimization problem of SVM to include some
measure of the within-class distance and along the way we develop a new
within-class distance measure which is appropriate for SVM. In addition, we
adopt the same approach for MKL and show that it can be also formulated as a
Mahalanobis metric learning problem. Our end result is a number of SVM/MKL
algorithms that incorporate metric learning concepts. We experiment with them
on a set of benchmark datasets and observe important predictive performance
improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3883</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3883</id><created>2013-09-16</created><updated>2013-09-20</updated><authors><author><keyname>van Glabbeek</keyname><forenames>Rob J.</forenames><affiliation>NICTA</affiliation></author><author><keyname>Goltz</keyname><forenames>Ursula</forenames><affiliation>TU Braunschweig</affiliation></author><author><keyname>Schicke-Uffmann</keyname><forenames>Jens-Wolfhard</forenames><affiliation>TU Braunschweig</affiliation></author></authors><title>On Characterising Distributability</title><categories>cs.LO</categories><comments>arXiv admin note: substantial text overlap with arXiv:1207.3597</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  17, 2013) lmcs:910</journal-ref><doi>10.2168/LMCS-9(3:17)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formalise a general concept of distributed systems as sequential
components interacting asynchronously. We define a corresponding class of Petri
nets, called LSGA nets, and precisely characterise those system specifications
which can be implemented as LSGA nets up to branching ST-bisimilarity with
explicit divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3888</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3888</id><created>2013-09-16</created><authors><author><keyname>Mitzlaff</keyname><forenames>Folke</forenames></author><author><keyname>Atzmueller</keyname><forenames>Martin</forenames></author><author><keyname>Benz</keyname><forenames>Dominik</forenames></author><author><keyname>Hotho</keyname><forenames>Andreas</forenames></author><author><keyname>Stumme</keyname><forenames>Gerd</forenames></author></authors><title>User-Relatedness and Community Structure in Social Interaction Networks</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With social media and the according social and ubiquitous applications
finding their way into everyday life, there is a rapidly growing amount of user
generated content yielding explicit and implicit network structures. We
consider social activities and phenomena as proxies for user relatedness. Such
activities are represented in so-called social interaction networks or evidence
networks, with different degrees of explicitness. We focus on evidence networks
containing relations on users, which are represented by connections between
individual nodes. Explicit interaction networks are then created by specific
user actions, for example, when building a friend network. On the other hand,
more implicit networks capture user traces or evidences of user actions as
observed in Web portals, blogs, resource sharing systems, and many other social
services. These implicit networks can be applied for a broad range of analysis
methods instead of using expensive gold-standard information.
  In this paper, we analyze different properties of a set of networks in social
media. We show that there are dependencies and correlations between the
networks. These allow for drawing reciprocal conclusions concerning pairs of
networks, based on the assessment of structural correlations and ranking
interchangeability. Additionally, we show how these inter-network correlations
can be used for assessing the results of structural analysis techniques, e.g.,
community mining methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3901</identifier>
 <datestamp>2014-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3901</id><created>2013-09-16</created><updated>2014-03-25</updated><authors><author><keyname>Luzzi</keyname><forenames>Laura</forenames></author><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author></authors><title>A new design criterion for spherically-shaped division algebra-based
  space-time codes</title><categories>cs.IT math.IT</categories><comments>Conference (presented at ITW 2013, Sevilla, Spain) 5 pages. Version
  2, march 2014: a mistake was corrected in Sections IV.A (including Example
  4.1) and V.A</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers normalized inverse determinant sums as a tool for
analyzing the performance of division algebra based space-time codes for
multiple antenna wireless systems. A general union bound based code design
criterion is obtained as a main result. In our previous work, the behavior of
inverse determinant sums was analyzed using point counting techniques for Lie
groups; it was shown that the asymptotic growth exponents of these sums
correctly describe the diversity-multiplexing gain trade-off of the space-time
code for some multiplexing gain ranges. This paper focuses on the constant
terms of the inverse determinant sums, which capture the coding gain behavior.
Pursuing the Lie group approach, a tighter asymptotic bound is derived,
allowing to compute the constant terms for several classes of space-time codes
appearing in the literature. The resulting design criterion suggests that the
performance of division algebra based codes depends on several fundamental
algebraic invariants of the underlying algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3908</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3908</id><created>2013-09-16</created><authors><author><keyname>Guerini</keyname><forenames>Marco</forenames></author><author><keyname>Staiano</keyname><forenames>Jacopo</forenames></author><author><keyname>Albanese</keyname><forenames>Davide</forenames></author></authors><title>Exploring Image Virality in Google Plus</title><categories>cs.SI cs.CY cs.MM physics.soc-ph</categories><comments>8 pages, 8 figures. IEEE/ASE SocialCom 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reactions to posts in an online social network show different dynamics
depending on several textual features of the corresponding content. Do similar
dynamics exist when images are posted? Exploiting a novel dataset of posts,
gathered from the most popular Google+ users, we try to give an answer to such
a question. We describe several virality phenomena that emerge when taking into
account visual characteristics of images (such as orientation, mean saturation,
etc.). We also provide hypotheses and potential explanations for the dynamics
behind them, and include cases for which common-sense expectations do not hold
true in our experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3910</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3910</id><created>2013-09-16</created><authors><author><keyname>Goubault</keyname><forenames>Eric</forenames></author><author><keyname>Putot</keyname><forenames>Sylvie</forenames></author></authors><title>Robustness analysis of finite precision implementations</title><categories>cs.SE cs.SY</categories><comments>16 pages, extended version of APLAS 2013 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A desirable property of control systems is to be robust to inputs, that is
small perturbations of the inputs of a system will cause only small
perturbations on its outputs. But it is not clear whether this property is
maintained at the implementation level, when two close inputs can lead to very
different execution paths. The problem becomes particularly crucial when
considering finite precision implementations, where any elementary computation
can be affected by a small error. In this context, almost every test is
potentially unstable, that is, for a given input, the computed (finite
precision) path may differ from the ideal (same computation in real numbers)
path. Still, state-of-the-art error analyses do not consider this possibility
and rely on the stable test hypothesis, that control flows are identical. If
there is a discontinuity between the treatments in the two branches, that is
the conditional block is not robust to uncertainties, the error bounds can be
unsound.
  We propose here a new abstract-interpretation based error analysis of finite
precision implementations, which is sound in presence of unstable tests. It
automatically bounds the discontinuity error coming from the difference between
the float and real values when there is a path divergence, and introduces a new
error term labeled by the test that introduced this potential discontinuity.
This gives a tractable error analysis, implemented in our static analyzer
FLUCTUAT: we present results on representative extracts of control programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3914</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3914</id><created>2013-09-16</created><authors><author><keyname>Cassou</keyname><forenames>Damien</forenames><affiliation>INRIA Lille - Nord Europe, LIFL</affiliation></author><author><keyname>Ducasse</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Petton</keyname><forenames>Nicolas</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>SafeJS: Hermetic Sandboxing for JavaScript</title><categories>cs.PL cs.CR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Isolating programs is an important mechanism to support more secure
applications. Isolating program in dynamic languages such as JavaScript is even
more challenging since reflective operations can circumvent simple mechanisms
that could protect program parts. In this article we present SafeJS, an
approach and implementation that offers isolation based on separate sandboxes
and control of information exchanged between them. In SafeJS, sandboxes based
on web workers do not share any data. Data exchanged between sandboxes is
solely based on strings. Using different policies, this infrastructure supports
the isolation of the different scripts that usually populate web pages. A
foreign component cannot modify the main DOM tree in unexpected manner. Our
SafeJS implementation is currently being used in an industrial setting in the
context of the Resilience FUI 12 project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3917</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3917</id><created>2013-09-16</created><authors><author><keyname>Marceau</keyname><forenames>Ga&#xe9;tan</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Sav&#xe9;ant</keyname><forenames>Pierre</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author></authors><title>Strategic Planning in Air Traffic Control as a Multi-objective
  Stochastic Optimization Problem</title><categories>cs.AI</categories><comments>ATM Seminar 2013 (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the objective of handling the airspace sector congestion subject to
continuously growing air traffic, we suggest to create a collaborative working
plan during the strategic phase of air traffic control. The plan obtained via a
new decision support tool presented in this article consists in a schedule for
controllers, which specifies time of overflight on the different waypoints of
the flight plans. In order to do it, we believe that the decision-support tool
shall model directly the uncertainty at a trajectory level in order to
propagate the uncertainty to the sector level. Then, the probability of
congestion for any sector in the airspace can be computed. Since air traffic
regulations and sector congestion are antagonist, we designed and implemented a
multi-objective optimization algorithm for determining the best trade-off
between these two criteria. The solution comes up as a set of alternatives for
the multi-sector planner where the severity of the congestion cost is
adjustable. In this paper, the Non-dominated Sorting Genetic Algorithm
(NSGA-II) was used to solve an artificial benchmark problem involving 24
aircraft and 11 sectors, and is able to provide a good approximation of the
Pareto front.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3919</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3919</id><created>2013-09-16</created><authors><author><keyname>Biernacki</keyname><forenames>Dariusz</forenames><affiliation>INRIA Nancy - Grand Est / LORIA</affiliation></author><author><keyname>Lenglet</keyname><forenames>Sergue&#xef;</forenames><affiliation>INRIA Nancy - Grand Est / LORIA</affiliation></author></authors><title>Environmental Bisimulations for Delimited-Control Operators</title><categories>cs.PL cs.FL</categories><comments>Long version of the corresponding APLAS13 paper</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theory of environmental bisimilarity for the delimited-control
operators {\it shift} and {\it reset}. We consider two different notions of
contextual equivalence: one that does not require the presence of a top-level
control delimiter when executing tested terms, and another one, fully
compatible with the original CPS semantics of shift and reset, that does. For
each of them, we develop sound and complete environmental bisimilarities, and
we discuss up-to techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3921</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3921</id><created>2013-09-16</created><authors><author><keyname>Marceau</keyname><forenames>Ga&#xe9;tan</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Sav&#xe9;ant</keyname><forenames>Pierre</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author></authors><title>Computational Methods for Probabilistic Inference of Sector Congestion
  in Air Traffic Management</title><categories>cs.AI</categories><comments>Interdisciplinary Science for Innovative Air Traffic Management
  (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article addresses the issue of computing the expected cost functions
from a probabilistic model of the air traffic flow and capacity management. The
Clenshaw-Curtis quadrature is compared to Monte-Carlo algorithms defined
specifically for this problem. By tailoring the algorithms to this model, we
reduce the computational burden in order to simulate real instances. The study
shows that the Monte-Carlo algorithm is more sensible to the amount of
uncertainty in the system, but has the advantage to return a result with the
associated accuracy on demand. The performances for both approaches are
comparable for the computation of the expected cost of delay and the expected
cost of congestion. Finally, this study shows some evidences that the
simulation of the proposed probabilistic model is tractable for realistic
instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3923</identifier>
 <datestamp>2014-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3923</id><created>2013-09-16</created><authors><author><keyname>Ciurana</keyname><forenames>Alex</forenames></author><author><keyname>Martinez-Mateo</keyname><forenames>Jesus</forenames></author><author><keyname>Peev</keyname><forenames>Momtchil</forenames></author><author><keyname>Poppe</keyname><forenames>Andreas</forenames></author><author><keyname>Walenta</keyname><forenames>Nino</forenames></author><author><keyname>Zbinden</keyname><forenames>Hugo</forenames></author><author><keyname>Martin</keyname><forenames>Vicente</forenames></author></authors><title>Quantum Metropolitan Optical Network based on Wavelength Division
  Multiplexing</title><categories>quant-ph cs.CR cs.NI</categories><comments>23 pages, 8 figures</comments><journal-ref>Optics Express, Vol. 22, Issue 2, pp. 1576-1593 (2014)</journal-ref><doi>10.1364/OE.22.001576</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum Key Distribution (QKD) is maturing quickly. However, the current
approaches to its application in optical networks make it an expensive
technology. QKD networks deployed to date are designed as a collection of
point-to-point, dedicated QKD links where non-neighboring nodes communicate
using the trusted repeater paradigm. We propose a novel optical network model
in which QKD systems share the communication infrastructure by wavelength
multiplexing their quantum and classical signals. The routing is done using
optical components within a metropolitan area which allows for a dynamically
any-to-any communication scheme. Moreover, it resembles a commercial telecom
network, takes advantage of existing infrastructure and utilizes commercial
components, allowing for an easy, cost-effective and reliable deployment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3944</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3944</id><created>2013-09-16</created><authors><author><keyname>Sharma</keyname><forenames>Anuj</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prabin Kumar</forenames></author></authors><title>A Review of Financial Accounting Fraud Detection based on Data Mining
  Techniques</title><categories>cs.CY</categories><comments>11 Pages. International Journal of Computer Applications February
  2012</comments><doi>10.5120/4787-7016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With an upsurge in financial accounting fraud in the current economic
scenario experienced, financial accounting fraud detection (FAFD) has become an
emerging topic of great importance for academic, research and industries. The
failure of internal auditing system of the organization in identifying the
accounting frauds has lead to use of specialized procedures to detect financial
accounting fraud, collective known as forensic accounting. Data mining
techniques are providing great aid in financial accounting fraud detection,
since dealing with the large data volumes and complexities of financial data
are big challenges for forensic accounting. This paper presents a comprehensive
review of the literature on the application of data mining techniques for the
detection of financial accounting fraud and proposes a framework for data
mining techniques based accounting fraud detection. The systematic and
comprehensive literature review of the data mining techniques applicable to
financial accounting fraud detection may provide a foundation to future
research in this field. The findings of this review show that data mining
techniques like logistic models, neural networks, Bayesian belief network, and
decision trees have been applied most extensively to provide primary solutions
to the problems inherent in the detection and classification of fraudulent
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3945</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3945</id><created>2013-09-16</created><authors><author><keyname>Sharma</keyname><forenames>Anuj</forenames></author><author><keyname>Panigrahi</keyname><forenames>Dr. Prabin Kumar</forenames></author></authors><title>A Neural Network based Approach for Predicting Customer Churn in
  Cellular Network Services</title><categories>cs.NE cs.CE</categories><comments>6 Pages. International Journal of Computer Applications August 2011</comments><doi>10.5120/3344-4605 10.5120/3344-4605 10.5120/3344-4605 10.5120/3344-4605
  10.5120/3344-4605</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Marketing literature states that it is more costly to engage a new customer
than to retain an existing loyal customer. Churn prediction models are
developed by academics and practitioners to effectively manage and control
customer churn in order to retain existing customers. As churn management is an
important activity for companies to retain loyal customers, the ability to
correctly predict customer churn is necessary. As the cellular network services
market becoming more competitive, customer churn management has become a
crucial task for mobile communication operators. This paper proposes a neural
network based approach to predict customer churn in subscription of cellular
wireless services. The results of experiments indicate that neural network
based approach can predict customer churn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3946</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3946</id><created>2013-09-16</created><authors><author><keyname>Sharma</keyname><forenames>Anuj</forenames></author><author><keyname>Dey</keyname><forenames>Shubhamoy</forenames></author></authors><title>Using Self-Organizing Maps for Sentiment Analysis</title><categories>cs.IR cs.CL cs.NE</categories><comments>13 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web 2.0 services have enabled people to express their opinions, experience
and feelings in the form of user-generated content. Sentiment analysis or
opinion mining involves identifying, classifying and aggregating opinions as
per their positive or negative polarity. This paper investigates the efficacy
of different implementations of Self-Organizing Maps (SOM) for sentiment based
visualization and classification of online reviews. Specifically, this paper
implements the SOM algorithm for both supervised and unsupervised learning from
text documents. The unsupervised SOM algorithm is implemented for sentiment
based visualization and classification tasks. For supervised sentiment
analysis, a competitive learning algorithm known as Learning Vector
Quantization is used. Both algorithms are also compared with their respective
multi-pass implementations where a quick rough ordering pass is followed by a
fine tuning pass. The experimental results on the online movie review data set
show that SOMs are well suited for sentiment based classification and sentiment
polarity visualization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3949</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3949</id><created>2013-09-16</created><authors><author><keyname>sharma</keyname><forenames>Anuj</forenames></author><author><keyname>Dey</keyname><forenames>Shubhamoy</forenames></author></authors><title>Performance Investigation of Feature Selection Methods</title><categories>cs.IR cs.CL cs.LG</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sentiment analysis or opinion mining has become an open research domain after
proliferation of Internet and Web 2.0 social media. People express their
attitudes and opinions on social media including blogs, discussion forums,
tweets, etc. and, sentiment analysis concerns about detecting and extracting
sentiment or opinion from online text. Sentiment based text classification is
different from topical text classification since it involves discrimination
based on expressed opinion on a topic. Feature selection is significant for
sentiment analysis as the opinionated text may have high dimensions, which can
adversely affect the performance of sentiment analysis classifier. This paper
explores applicability of feature selection methods for sentiment analysis and
investigates their performance for classification in term of recall, precision
and accuracy. Five feature selection methods (Document Frequency, Information
Gain, Gain Ratio, Chi Squared, and Relief-F) and three popular sentiment
feature lexicons (HM, GI and Opinion Lexicon) are investigated on movie reviews
corpus with a size of 2000 documents. The experimental results show that
Information Gain gave consistent results and Gain Ratio performs overall best
for sentimental feature selection while sentiment lexicons gave poor
performance. Furthermore, we found that performance of the classifier depends
on appropriate number of representative feature selected from text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3953</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3953</id><created>2013-09-16</created><authors><author><keyname>Mivule</keyname><forenames>Kato</forenames></author><author><keyname>Turner</keyname><forenames>Claude</forenames></author></authors><title>A Review of Privacy Essentials for Confidential Mobile Data Transactions</title><categories>cs.CR</categories><comments>7 Pages, 7 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasingly rapid use of mobile devices for data transaction around the
world has consequently led to a new problem, and that is, how to engage in
mobile data transactions while maintaining an acceptable level of data privacy
and security. While most mobile devices engage in data transactions through a
data cloud or a set of data servers, it is still possible to apply data
confidentiality across data servers, and, as such, preserving privacy in any
mobile data transaction. Yet still, it is essential that a review of data
privacy, data utility, the techniques, and methodologies employed in the data
privacy process, is done, as the underlying data privacy principles remain the
same. In this paper, as a contribution, we present a review of data privacy
essentials that are fundamental in delivering any appropriate analysis and
specific methodology implementation for various data privacy needs in mobile
data transactions and computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3957</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3957</id><created>2013-09-16</created><updated>2014-08-06</updated><authors><author><keyname>Deshpande</keyname><forenames>Abhishek</forenames></author><author><keyname>Gopalkrishnan</keyname><forenames>Manoj</forenames></author></authors><title>Autocatalysis in Reaction Networks</title><categories>math.DS cs.CE q-bio.MN</categories><comments>v4: 29 pages, 1 figure, Theorem 5.3.3 strengthened to all consistent
  reaction networks; v3: 28 pages, 1 figure, minor revisions; v2: 27 pages, 1
  figure, new introduction and related work sections replacing sections in v1;
  v1:27 pages, 1 figure</comments><journal-ref>Bull. Math Biol. 2014</journal-ref><doi>10.1007/s11538-014-0024-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The persistence conjecture is a long-standing open problem in chemical
reaction network theory. It concerns the behavior of solutions to coupled ODE
systems that arise from applying mass-action kinetics to a network of chemical
reactions. The idea is that if all reactions are reversible in a weak sense,
then no species can go extinct. A notion that has been found useful in thinking
about persistence is that of &quot;critical siphon.&quot; We explore the combinatorics of
critical siphons, with a view towards the persistence conjecture. We introduce
the notions of &quot;drainable&quot; and &quot;self-replicable&quot; (or autocatalytic) siphons. We
show that: every minimal critical siphon is either drainable or
self-replicable; reaction networks without drainable siphons are persistent;
and non-autocatalytic weakly-reversible networks are persistent. Our results
clarify that the difficulties in proving the persistence conjecture are
essentially due to competition between drainable and self-replicable siphons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3958</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3958</id><created>2013-09-16</created><authors><author><keyname>Mivule</keyname><forenames>Kato</forenames></author></authors><title>Utilizing Noise Addition for Data Privacy, an Overview</title><categories>cs.CR</categories><comments>6 pages, 3 Figures</comments><journal-ref>Proceedings of the International Conference on Information and
  Knowledge Engineering (IKE 2012), Pages 65-71</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The internet is increasingly becoming a standard for both the production and
consumption of data while at the same time cyber-crime involving the theft of
private data is growing. Therefore in efforts to securely transact in data,
privacy and security concerns must be taken into account to ensure that the
confidentiality of individuals and entities involved is not compromised, and
that the data published is compliant to privacy laws. In this paper, we take a
look at noise addition as one of the data privacy providing techniques. Our
endeavor in this overview is to give a foundational perspective on noise
addition data privacy techniques, provide statistical consideration for noise
addition techniques and look at the current state of the art in the field,
while outlining future areas of research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3959</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3959</id><created>2013-09-16</created><authors><author><keyname>Varshney</keyname><forenames>Kush R.</forenames></author></authors><title>Bounded Confidence Opinion Dynamics in a Social Network of Bayesian
  Decision Makers</title><categories>cs.SI physics.soc-ph</categories><doi>10.1109/JSTSP.2014.2309945</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bounded confidence opinion dynamics model the propagation of information in
social networks. However in the existing literature, opinions are only viewed
as abstract quantities without semantics rather than as part of a
decision-making system. In this work, opinion dynamics are examined when agents
are Bayesian decision makers that perform hypothesis testing or signal
detection, and the dynamics are applied to prior probabilities of hypotheses.
Bounded confidence is defined on prior probabilities through Bayes risk error
divergence, the appropriate measure between priors in hypothesis testing. This
definition contrasts with the measure used between opinions in standard models:
absolute error. It is shown that the rapid convergence of prior probabilities
to a small number of limiting values is similar to that seen in the standard
Krause-Hegselmann model. The most interesting finding in this work is that the
number of these limiting values and the time to convergence changes with the
signal-to-noise ratio in the detection task. The number of final values or
clusters is maximal at intermediate signal-to-noise ratios, suggesting that the
most contentious issues lead to the largest number of factions. It is at these
same intermediate signal-to-noise ratios at which the degradation in detection
performance of the aggregate vote of the decision makers is greatest in
comparison to the Bayes optimal detection performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3963</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3963</id><created>2013-09-16</created><authors><author><keyname>Gemsa</keyname><forenames>Andreas</forenames></author><author><keyname>Niedermann</keyname><forenames>Benjamin</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author></authors><title>Trajectory-Based Dynamic Map Labeling</title><categories>cs.CG</categories><comments>19 pages, 7 figures, extended version of a paper to appear at ISAAC
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce trajectory-based labeling, a new variant of
dynamic map labeling, where a movement trajectory for the map viewport is
given. We define a general labeling model and study the active range
maximization problem in this model. The problem is NP-complete and W[1]-hard.
In the restricted, yet practically relevant case that no more than k labels can
be active at any time, we give polynomial-time algorithms. For the general case
we present a practical ILP formulation with an experimental evaluation as well
as approximation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3964</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3964</id><created>2013-09-16</created><authors><author><keyname>Mivule</keyname><forenames>Kato</forenames></author><author><keyname>Turner</keyname><forenames>Claude</forenames></author></authors><title>An Investigation of Data Privacy and Utility Preservation using KNN
  Classification as a Gauge</title><categories>cs.CR cs.DB</categories><comments>2 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is obligatory that organizations by law safeguard the privacy of
individuals when handling data sets containing personal identifiable
information (PII). Nevertheless, during the process of data privatization, the
utility or usefulness of the privatized data diminishes. Yet achieving the
optimal balance between data privacy and utility needs has been documented as
an NP-hard challenge. In this study, we investigate data privacy and utility
preservation using KNN machine learning classification as a gauge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3975</identifier>
 <datestamp>2014-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3975</id><created>2013-09-16</created><authors><author><keyname>Pan</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Heng-liang</forenames></author><author><keyname>Jie</keyname><forenames>Qi</forenames></author></authors><title>Problem Complexity Research from Energy Perspective</title><categories>cs.CC cs.IT math.IT physics.pop-ph</categories><comments>10 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Computational complexity is a particularly important objective. The idea of
Landauer principle was extended through mapping three classic problems
(sorting,ordered searching and max of N unordered numbers) into Maxwell demon
thought experiment in this paper. The problems'complexity is defined on the
entropy basis and the minimum energy required to solve them are rigorous
deduced from the perspective of energy (entropy) and the second law of
thermodynamics. Then the theoretical energy consumed by real program and basic
operators of classical computer are both analyzed, the time complexity lower
bounds of three problems'all possible algorithms are derived in this way. The
lower bound is also deduced for the two n*n matrix multiplication problem. In
the end, the reason why reversible computation is impossible and the
possibility of super-linear energy consumption capacity which may be the power
behind quantum computation are discussed, a conjecture is proposed which may
prove NP!=P. The study will bring fresh and profound understanding of
computation complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3984</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3984</id><created>2013-09-16</created><authors><author><keyname>Altarelli</keyname><forenames>F.</forenames></author><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Chiasserini</keyname><forenames>C. F.</forenames></author><author><keyname>Dall'Asta</keyname><forenames>L.</forenames></author><author><keyname>Giaccone</keyname><forenames>P.</forenames></author><author><keyname>Leonardi</keyname><forenames>E.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Stochastic Optimization of Service Provision with Selfish Users</title><categories>cs.GT cond-mat.dis-nn physics.soc-ph</categories><comments>paper presented at NETSTAT Workshop, Budapest - June 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a computationally efficient technique to solve a fairly general
distributed service provision problem with selfish users and imperfect
information. In particular, in a context in which the service capacity of the
existing infrastructure can be partially adapted to the user load by activating
just some of the service units, we aim at finding the configuration of active
service units that achieves the best trade-off between maintenance (e.g.\
energetic) costs for the provider and user satisfaction. The core of our
technique resides in the implementation of a belief-propagation (BP) algorithm
to evaluate the cost configurations. Numerical results confirm the
effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3985</identifier>
 <datestamp>2014-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3985</id><created>2013-09-16</created><updated>2014-02-12</updated><authors><author><keyname>Wolf</keyname><forenames>Thomas</forenames></author><author><keyname>Panzer</keyname><forenames>Heiko K. F.</forenames></author></authors><title>The ADI iteration for Lyapunov equations implicitly performs H2
  pseudo-optimal model order reduction</title><categories>math.NA cs.SY math.DS</categories><comments>15 pages</comments><msc-class>65F10, 93A15, 93C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two approaches for approximating the solution of large-scale Lyapunov
equations are considered: the alternating direction implicit (ADI) iteration
and projective methods by Krylov subspaces. A link between them is presented by
showing that the ADI iteration can always be identified by a Petrov-Galerkin
projection with rational block Krylov subspaces. Then a unique Krylov-projected
dynamical system can be associated with the ADI iteration, which is proven to
be an H2 pseudo-optimal approximation. This includes the generalization of
previous results on H2 pseudo-optimality to the multivariable case.
Additionally, a low-rank formulation of the residual in the Lyapunov equation
is presented, which is well-suited for implementation, and which yields a
measure of the &quot;obliqueness&quot; that the ADI iteration is associated with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3993</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3993</id><created>2013-09-02</created><authors><author><keyname>Das</keyname><forenames>Debesh K.</forenames></author><author><keyname>Chowdhury</keyname><forenames>Debabani</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Bhargab B.</forenames></author><author><keyname>Sasao</keyname><forenames>Tsutomu</forenames></author></authors><title>Inadmissible Class of Boolean Functions under Stuck-at Faults</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many underlying structural and functional factors that determine the fault
behavior of a combinational network, are not yet fully understood. In this
paper, we show that there exists a large class of Boolean functions, called
root functions, which can never appear as faulty response in irredundant
two-level circuits even when any arbitrary multiple stuck-at faults are
injected. Conversely, we show that any other Boolean function can appear as a
faulty response from an irredundant realization of some root function under
certain stuck-at faults. We characterize this new class of functions and show
that for n variables, their number is exactly equal to the number of
independent dominating sets (Harary and Livingston, Appl. Math. Lett., 1993) in
a Boolean n-cube. We report some bounds and enumerate the total number of root
functions up to 6 variables. Finally, we point out several open problems and
possible applications of root functions in logic design and testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.3997</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.3997</id><created>2013-08-19</created><authors><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author><author><keyname>Khanzadi</keyname><forenames>M. Reza</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author><author><keyname>Sayeed</keyname><forenames>Akbar M.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Hua</keyname><forenames>Yingbo</forenames></author></authors><title>Improving Bandwidth Efficiency in E-band Communication Systems</title><categories>cs.NI</categories><comments>16 pages, 6 Figures, Journal paper. IEEE Communication Magazine 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The allocation of a large amount of bandwidth by regulating bodies in the
70/80 GHz band, i.e., the E-band, has opened up new potentials and challenges
for providing affordable and reliable Gigabit per second wireless
point-to-point links. This article first reviews the available bandwidth and
licensing regulations in the E-band. Subsequently, different propagation
models, e.g., the ITU-R and Cane models, are compared against measurement
results and it is concluded that to meet specific availability requirements,
E-band wireless systems may need to be designed with larger fade margins
compared to microwave systems. A similar comparison is carried out between
measurements and models for oscillator phase noise. It is confirmed that phase
noise characteristics, that are neglected by the models used for narrowband
systems, need to be taken into account for the wideband systems deployed in the
E-band. Next, a new multi-input multi-output (MIMO) transceiver design, termed
continuous aperture phased (CAP)-MIMO, is presented. Simulations show that
CAP-MIMO enables E-band systems to achieve fiber-optic like throughputs.
Finally, it is argued that full-duplex relaying can be used to greatly enhance
the coverage of E-band systems without sacrificing throughput, thus,
facilitating their application in establishing the backhaul of heterogeneous
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4008</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4008</id><created>2013-09-16</created><authors><author><keyname>AlSum</keyname><forenames>Ahmed</forenames></author><author><keyname>Weigle</keyname><forenames>Michele C.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Profiling Web Archive Coverage for Top-Level Domain and Content Language</title><categories>cs.DL</categories><comments>Appeared in TPDL 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Memento aggregator currently polls every known public web archive when
serving a request for an archived web page, even though some web archives focus
on only specific domains and ignore the others. Similar to query routing in
distributed search, we investigate the impact on aggregated Memento TimeMaps
(lists of when and where a web page was archived) by only sending queries to
archives likely to hold the archived page. We profile twelve public web
archives using data from a variety of sources (the web, archives' access logs,
and full-text queries to archives) and discover that only sending queries to
the top three web archives (i.e., a 75% reduction in the number of queries) for
any request produces the full TimeMaps on 84% of the cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4009</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4009</id><created>2013-09-16</created><authors><author><keyname>AlNoamany</keyname><forenames>Yasmin</forenames></author><author><keyname>Weigle</keyname><forenames>Michele C.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Access Patterns for Robots and Humans in Web Archives</title><categories>cs.DL cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although user access patterns on the live web are well-understood, there has
been no corresponding study of how users, both humans and robots, access web
archives. Based on samples from the Internet Archive's public Wayback Machine,
we propose a set of basic usage patterns: Dip (a single access), Slide (the
same page at different archive times), Dive (different pages at approximately
the same archive time), and Skim (lists of what pages are archived, i.e.,
TimeMaps). Robots are limited almost exclusively to Dips and Skims, but human
accesses are more varied between all four types. Robots outnumber humans 10:1
in terms of sessions, 5:4 in terms of raw HTTP accesses, and 4:1 in terms of
megabytes transferred. Robots almost always access TimeMaps (95% of accesses),
but humans predominately access the archived web pages themselves (82% of
accesses). In terms of unique archived web pages, there is no overall
preference for a particular time, but the recent past (within the last year)
shows significant repeat accesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4016</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4016</id><created>2013-09-16</created><authors><author><keyname>AlNoamany</keyname><forenames>Yasmin</forenames></author><author><keyname>AlSum</keyname><forenames>Ahmed</forenames></author><author><keyname>Weigle</keyname><forenames>Michele C.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Who and What Links to the Internet Archive</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet Archive's (IA) Wayback Machine is the largest and oldest public
web archive and has become a significant repository of our recent history and
cultural heritage. Despite its importance, there has been little research about
how it is discovered and used. Based on web access logs, we analyze what users
are looking for, why they come to IA, where they come from, and how pages link
to IA. We find that users request English pages the most, followed by the
European languages. Most human users come to web archives because they do not
find the requested pages on the live web. About 65% of the requested archived
pages no longer exist on the live web. We find that more than 82% of human
sessions connect to the Wayback Machine via referrals from other web sites,
while only 15% of robots have referrers. Most of the links (86%) from websites
are to individual archived pages at specific points in time, and of those 83%
no longer exist on the live web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4022</identifier>
 <datestamp>2014-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4022</id><created>2013-09-16</created><updated>2014-05-13</updated><authors><author><keyname>Drange</keyname><forenames>P&#xe5;l Gr&#xf8;n&#xe5;s</forenames></author><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>Exploring Subexponential Parameterized Complexity of Completion Problems</title><categories>cs.DS</categories><comments>32 pages, 16 figures, A preliminary version of this paper appeared in
  the proceedings of STACS'14</comments><msc-class>05C85, 68R10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let ${\cal F}$ be a family of graphs. In the ${\cal F}$-Completion problem,
we are given a graph $G$ and an integer $k$ as input, and asked whether at most
$k$ edges can be added to $G$ so that the resulting graph does not contain a
graph from ${\cal F}$ as an induced subgraph. It appeared recently that special
cases of ${\cal F}$-Completion, the problem of completing into a chordal graph
known as Minimum Fill-in, corresponding to the case of ${\cal
F}=\{C_4,C_5,C_6,\ldots\}$, and the problem of completing into a split graph,
i.e., the case of ${\cal F}=\{C_4, 2K_2, C_5\}$, are solvable in parameterized
subexponential time $2^{O(\sqrt{k}\log{k})}n^{O(1)}$. The exploration of this
phenomenon is the main motivation for our research on ${\cal F}$-Completion.
  In this paper we prove that completions into several well studied classes of
graphs without long induced cycles also admit parameterized subexponential time
algorithms by showing that:
  - The problem Trivially Perfect Completion is solvable in parameterized
subexponential time $2^{O(\sqrt{k}\log{k})}n^{O(1)}$, that is ${\cal
F}$-Completion for ${\cal F} =\{C_4, P_4\}$, a cycle and a path on four
vertices.
  - The problems known in the literature as Pseudosplit Completion, the case
where ${\cal F} = \{2K_2, C_4\}$, and Threshold Completion, where ${\cal F} =
\{2K_2, P_4, C_4\}$, are also solvable in time $2^{O(\sqrt{k}\log{k})}
n^{O(1)}$.
  We complement our algorithms for ${\cal F}$-Completion with the following
lower bounds:
  - For ${\cal F} = \{2K_2\}$, ${\cal F} = \{C_4\}$, ${\cal F} = \{P_4\}$, and
${\cal F} = \{2K_2, P_4\}$, ${\cal F}$-Completion cannot be solved in time
$2^{o(k)} n^{O(1)}$ unless the Exponential Time Hypothesis (ETH) fails.
  Our upper and lower bounds provide a complete picture of the subexponential
parameterized complexity of ${\cal F}$-Completion problems for ${\cal
F}\subseteq\{2K_2, C_4, P_4\}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4024</identifier>
 <datestamp>2014-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4024</id><created>2013-09-16</created><authors><author><keyname>McGuire</keyname><forenames>P. C.</forenames></author><author><keyname>Bonnici</keyname><forenames>A.</forenames></author><author><keyname>Bruner</keyname><forenames>K. R.</forenames></author><author><keyname>Gross</keyname><forenames>C.</forenames></author><author><keyname>Orm&#xf6;</keyname><forenames>J.</forenames></author><author><keyname>Smosna</keyname><forenames>R. A.</forenames></author><author><keyname>Walter</keyname><forenames>S.</forenames></author><author><keyname>Wendt</keyname><forenames>L.</forenames></author></authors><title>The Cyborg Astrobiologist: Matching of Prior Textures by Image
  Compression for Geological Mapping and Novelty Detection</title><categories>cs.CV astro-ph.EP astro-ph.IM cs.LG</categories><comments>27 pages, 3 figures, 2 tables, accepted for publication in the
  International Journal of Astrobiology</comments><journal-ref>International Journal of Astrobiology, 13(03), pp. 191-202 (2014)</journal-ref><doi>10.1017/S1473550413000372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (abridged) We describe an image-comparison technique of Heidemann and Ritter
that uses image compression, and is capable of: (i) detecting novel textures in
a series of images, as well as of: (ii) alerting the user to the similarity of
a new image to a previously-observed texture. This image-comparison technique
has been implemented and tested using our Astrobiology Phone-cam system, which
employs Bluetooth communication to send images to a local laptop server in the
field for the image-compression analysis. We tested the system in a field site
displaying a heterogeneous suite of sandstones, limestones, mudstones and
coalbeds. Some of the rocks are partly covered with lichen. The image-matching
procedure of this system performed very well with data obtained through our
field test, grouping all images of yellow lichens together and grouping all
images of a coal bed together, and giving a 91% accuracy for similarity
detection. Such similarity detection could be employed to make maps of
different geological units. The novelty-detection performance of our system was
also rather good (a 64% accuracy). Such novelty detection may become valuable
in searching for new geological units, which could be of astrobiological
interest. The image-comparison technique is an unsupervised technique that is
not capable of directly classifying an image as containing a particular
geological feature; labeling of such geological features is done post facto by
human geologists associated with this study, for the purpose of analyzing the
system's performance. By providing more advanced capabilities for similarity
detection and novelty detection, this image-compression technique could be
useful in giving more scientific autonomy to robotic planetary rovers, and in
assisting human astronauts in their geological exploration and assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4026</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4026</id><created>2013-09-16</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames><affiliation>Shitz</affiliation></author><author><keyname>Awan</keyname><forenames>Zohaib Hassan</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Secure Degrees of Freedom of MIMO X-Channels with Output Feedback and
  Delayed CSIT</title><categories>cs.IT math.IT</categories><comments>To Appear in IEEE Transactions on Information Forensics and Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of secure transmission over a two-user multi-input
multi-output (MIMO) X-channel in which channel state information is provided
with one-unit delay to both transmitters (CSIT), and each receiver feeds back
its channel output to a different transmitter. We refer to this model as MIMO
X-channel with asymmetric output feedback and delayed CSIT. The transmitters
are equipped with M-antennas each, and the receivers are equipped with
N-antennas each. For this model, accounting for both messages at each receiver,
we characterize the optimal sum secure degrees of freedom (SDoF) region. We
show that, in presence of asymmetric output feedback and delayed CSIT, the sum
SDoF region of the MIMO X-channel is same as the SDoF region of a two-user MIMO
BC with 2M-antennas at the transmitter, N-antennas at each receiver and delayed
CSIT. This result shows that, upon availability of asymmetric output feedback
and delayed CSIT, there is no performance loss in terms of sum SDoF due to the
distributed nature of the transmitters. Next, we show that this result also
holds if only output feedback is conveyed to the transmitters, but in a
symmetric manner, i.e., each receiver feeds back its output to both
transmitters and no CSIT. We also study the case in which only asymmetric
output feedback is provided to the transmitters, i.e., without CSIT, and derive
a lower bound on the sum SDoF for this model. Furthermore, we specialize our
results to the case in which there are no security constraints. In particular,
similar to the setting with security constraints, we show that the optimal sum
DoF region of the (M,M,N,N)--MIMO X-channel with asymmetric output feedback and
delayed CSIT is same as the DoF region of a two-user MIMO BC with 2M-antennas
at the transmitter, N-antennas at each receiver, and delayed CSIT. We
illustrate our results with some numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4033</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4033</id><created>2013-09-16</created><authors><author><keyname>Faben</keyname><forenames>John</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>The complexity of parity graph homomorphism: an initial investigation</title><categories>cs.CC math.CO</categories><comments>22 pages</comments><msc-class>68Q17 (Primary) 05C15, 68T20 (Secondary)</msc-class><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph G, we investigate the question of determining the parity of the
number of homomorphisms from G to some other fixed graph H. We conjecture that
this problem exhibits a complexity dichotomy, such that all parity graph
homomorphism problems are either polynomial-time solvable or parityP-complete,
and provide a conjectured characterisation of the easy cases.
  We show that the conjecture is true for the restricted case in which the
graph H is a tree, and provide some tools that may be useful in further
investigation into the parity graph homomorphism problem, and the problem of
counting homomorphisms for other moduli.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4034</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4034</id><created>2013-09-16</created><authors><author><keyname>Chen</keyname><forenames>Lijun</forenames></author><author><keyname>You</keyname><forenames>Seungil</forenames></author></authors><title>The Weighted Sum Rate Maximization in MIMO Interference Networks: The
  Minimax Lagrangian Duality and Algorithm</title><categories>cs.IT math.IT</categories><comments>10 pages, 6 figures, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We take a new perspective on the weighted sum-rate maximization in
multiple-input multiple-output (MIMO) interference networks, by formulating an
equivalent max-min problem. This seemingly trivial reformulation has
significant implications: the Lagrangian duality of the equivalent max-min
problem provides an elegant way to establish the sum-rate duality between an
interference network and its reciprocal when such a duality exists, and more
importantly, suggests a novel iterative minimax algorithm for the weighted
sum-rate maximization. Moreover, the design and convergence proof of the
algorithm use only general convex analysis. They apply and extend to any
max-min problems with similar structure, and thus provide a general class of
algorithms for such optimization problems. This paper presents a promising step
and lends hope for establishing a general framework based on the minimax
Lagrangian duality for characterizing the weighted sum-rate and developing
efficient algorithms for general MIMO interference networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4035</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4035</id><created>2013-09-16</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames></author></authors><title>Domain and Function: A Dual-Space Model of Semantic Relations and
  Compositions</title><categories>cs.CL cs.AI cs.LG</categories><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Journal of Artificial Intelligence Research (JAIR), (2012), 44,
  533-585</journal-ref><doi>10.1613/jair.3640</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given appropriate representations of the semantic relations between carpenter
and wood and between mason and stone (for example, vectors in a vector space
model), a suitable algorithm should be able to recognize that these relations
are highly similar (carpenter is to wood as mason is to stone; the relations
are analogous). Likewise, with representations of dog, house, and kennel, an
algorithm should be able to recognize that the semantic composition of dog and
house, dog house, is highly similar to kennel (dog house and kennel are
synonymous). It seems that these two tasks, recognizing relations and
compositions, are closely connected. However, up to now, the best models for
relations are significantly different from the best models for compositions. In
this paper, we introduce a dual-space model that unifies these two tasks. This
model matches the performance of the best previous models for relations and
compositions. The dual-space model consists of a space for measuring domain
similarity and a space for measuring function similarity. Carpenter and wood
share the same domain, the domain of carpentry. Mason and stone share the same
domain, the domain of masonry. Carpenter and mason share the same function, the
function of artisans. Wood and stone share the same function, the function of
materials. In the composition dog house, kennel has some domain overlap with
both dog and house (the domains of pets and buildings). The function of kennel
is similar to the function of house (the function of shelters). By combining
domain and function similarities in various ways, we can model relations,
compositions, and other aspects of semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4044</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4044</id><created>2013-09-16</created><updated>2013-11-18</updated><authors><author><keyname>Parisse</keyname><forenames>Bernard</forenames><affiliation>IF</affiliation></author></authors><title>A probabilistic and deterministic modular algorithm for computing
  Groebner basis over $\Q$</title><categories>cs.SC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modular algorithm are widely used in computer algebra systems (CAS), for
example to compute efficiently the gcd of multivariate polynomials. It is known
to work to compute Groebner basis over $\Q$, but it does not seem to be popular
among CAS implementers. In this paper, I will show how to check a candidate
Groebner basis (obtained by reconstruction of several Groebner basis modulo
distinct prime numbers) with a given error probability, that may be 0 if a
certified Groebner basis is desired. This algorithm is now the default
algorithm used by the Giac/Xcas computer algebra system with competitive
timings, thanks to a trick that can accelerate computing Groebner basis modulo
a prime once the computation has been done modulo another prime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4050</identifier>
 <datestamp>2014-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4050</id><created>2013-09-16</created><updated>2014-10-16</updated><authors><author><keyname>Krej&#x10d;&#xed;</keyname><forenames>Pavel</forenames></author><author><keyname>Lamba</keyname><forenames>Harbir</forenames></author><author><keyname>Melnik</keyname><forenames>Sergey</forenames></author><author><keyname>Rachinskii</keyname><forenames>Dmitrii</forenames></author></authors><title>Analytical solution for a class of network dynamics with mechanical and
  financial applications</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.SI physics.soc-ph q-fin.ST</categories><comments>12 pages, 9 figures, 1 table</comments><journal-ref>Phys. Rev. E 90, 032822 (2014)</journal-ref><doi>10.1103/PhysRevE.90.032822</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for a certain class of dynamics at the nodes the response of a
network of any topology to arbitrary inputs is defined in a simple way by its
response to a monotone input. The nodes may have either a discrete or
continuous set of states and there is no limit on the complexity of the
network. The results provide both an efficient numerical method and the
potential for accurate analytic approximation of the dynamics on such networks.
As illustrative applications, we introduce a quasistatic mechanical model with
objects interacting via frictional forces, and a financial market model with
avalanches and critical behavior that are generated by momentum trading
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4055</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4055</id><created>2013-09-16</created><updated>2013-09-29</updated><authors><author><keyname>Kolpakov</keyname><forenames>Roman</forenames></author><author><keyname>Podolskiy</keyname><forenames>Mikhail</forenames></author><author><keyname>Posypkin</keyname><forenames>Mikhail</forenames></author><author><keyname>Khrapov</keyname><forenames>Nickolay</forenames></author></authors><title>Searching of gapped repeats and subrepetitions in a word</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A gapped repeat is a factor of the form $uvu$ where $u$ and $v$ are nonempty
words. The period of the gapped repeat is defined as $|u|+|v|$. The gapped
repeat is maximal if it cannot be extended to the left or to the right by at
least one letter with preserving its period. The gapped repeat is called
$\alpha$-gapped if its period is not greater than $\alpha |v|$. A
$\delta$-subrepetition is a factor which exponent is less than 2 but is not
less than $1+\delta$ (the exponent of the factor is the quotient of the length
and the minimal period of the factor). The $\delta$-subrepetition is maximal if
it cannot be extended to the left or to the right by at least one letter with
preserving its minimal period. We reveal a close relation between maximal
gapped repeats and maximal subrepetitions. Moreover, we show that in a word of
length $n$ the number of maximal $\alpha$-gapped repeats is bounded by
$O(\alpha^2n)$ and the number of maximal $\delta$-subrepetitions is bounded by
$O(n/\delta^2)$. Using the obtained upper bounds, we propose algorithms for
finding all maximal $\alpha$-gapped repeats and all maximal
$\delta$-subrepetitions in a word of length $n$. The algorithm for finding all
maximal $\alpha$-gapped repeats has $O(\alpha^2n)$ time complexity for the case
of constant alphabet size and $O(n\log n + \alpha^2n)$ time complexity for the
general case. For finding all maximal $\delta$-subrepetitions we propose two
algorithms. The first algorithm has $O(\frac{n\log\log n}{\delta^2})$ time
complexity for the case of constant alphabet size and $O(n\log n
+\frac{n\log\log n}{\delta^2})$ time complexity for the general case. The
second algorithm has $O(n\log n+\frac{n}{\delta^2}\log \frac{1}{\delta})$
expected time complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4058</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4058</id><created>2013-09-16</created><authors><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author></authors><title>Why SOV might be initially preferred and then lost or recovered? A
  theoretical framework</title><categories>cs.CL nlin.AO physics.soc-ph q-bio.NC</categories><journal-ref>Proceedings of Evolang 2014, Cartmill, E. A., Roberts, S., Lyn, H.
  &amp; Cornish, H. (eds.), pp. 66-73 (2014)</journal-ref><doi>10.1142/9789814603638_0007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Little is known about why SOV order is initially preferred and then discarded
or recovered. Here we present a framework for understanding these and many
related word order phenomena: the diversity of dominant orders, the existence
of free words orders, the need of alternative word orders and word order
reversions and cycles in evolution. Under that framework, word order is
regarded as a multiconstraint satisfaction problem in which at least two
constraints are in conflict: online memory minimization and maximum
predictability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4061</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4061</id><created>2013-09-16</created><authors><author><keyname>Mueller</keyname><forenames>Andreas Christian</forenames></author><author><keyname>Behnke</keyname><forenames>Sven</forenames></author></authors><title>Learning a Loopy Model For Semantic Segmentation Exactly</title><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning structured models using maximum margin techniques has become an
indispensable tool for com- puter vision researchers, as many computer vision
applications can be cast naturally as an image labeling problem. Pixel-based or
superpixel-based conditional random fields are particularly popular examples.
Typ- ically, neighborhood graphs, which contain a large number of cycles, are
used. As exact inference in loopy graphs is NP-hard in general, learning these
models without approximations is usually deemed infeasible. In this work we
show that, despite the theoretical hardness, it is possible to learn loopy
models exactly in practical applications. To this end, we analyze the use of
multiple approximate inference techniques together with cutting plane training
of structural SVMs. We show that our proposed method yields exact solutions
with an optimality guarantees in a computer vision application, for little
additional computational cost. We also propose a dynamic caching scheme to
accelerate training further, yielding runtimes that are comparable with
approximate methods. We hope that this insight can lead to a reconsideration of
the tractability of loopy models in computer vision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4062</identifier>
 <datestamp>2014-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4062</id><created>2013-09-16</created><updated>2014-05-07</updated><authors><author><keyname>Ye</keyname><forenames>Qiaoyang</forenames></author><author><keyname>Al-Shalash</keyname><forenames>Mazin</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Resource Optimization in Device-to-Device Cellular Systems Using
  Time-Frequency Hopping</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a flexible and accurate framework for device-to-device (D2D)
communication in the context of a conventional cellular network, which allows
for time-frequency resources to be either shared or orthogonally partitioned
between the two networks. Using stochastic geometry, we provide accurate
expressions for SINR distributions and average rates, under an assumption of
interference randomization via time and/or frequency hopping, for both
dedicated and shared spectrum approaches. We obtain analytical results in
closed or semi-closed form in high SNR regime, that allow us to easily explore
the impact of key parameters (e.g., the load and hopping probabilities) on the
network performance. In particular, unlike other models, the expressions we
obtain are tractable, i.e., they can be efficiently optimized without extensive
simulation. Using these, we optimize the hopping probabilities for the D2D
links, i.e., how often they should request a time or frequency slot. This can
be viewed as an optimized lower bound to other more sophisticated scheduling
schemes. We also investigate the optimal resource partitions between D2D and
cellular networks when they use orthogonal resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4067</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4067</id><created>2013-09-16</created><authors><author><keyname>Kagan</keyname><forenames>Dima</forenames></author><author><keyname>Fire</keyname><forenames>Michael</forenames></author><author><keyname>Elyashar</keyname><forenames>Aviad</forenames></author><author><keyname>Elovici</keyname><forenames>Yuval</forenames></author></authors><title>Facebook Applications' Installation and Removal: A Temporal Analysis</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facebook applications are one of the reasons for Facebook attractiveness.
Unfortunately, numerous users are not aware of the fact that many malicious
Facebook applications exist. To educate users, to raise users' awareness and to
improve Facebook users' security and privacy, we developed a Firefox add-on
that alerts users to the number of installed applications on their Facebook
profiles. In this study, we present the temporal analysis of the Facebook
applications' installation and removal dataset collected by our add-on. This
dataset consists of information from 2,945 users, collected during a period of
over a year. We used linear regression to analyze our dataset and discovered
the linear connection between the average percentage change of newly installed
Facebook applications and the number of days passed since the user initially
installed our add-on. Additionally, we found out that users who used our
Firefox add-on become more aware of their security and privacy installing on
average fewer new applications. Finally, we discovered that on average 86.4% of
Facebook users install an additional application every 4.2 days.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4085</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4085</id><created>2013-09-16</created><authors><author><keyname>Marceau</keyname><forenames>Ga&#xe9;tan</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Sav&#xe9;ant</keyname><forenames>Pierre</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author></authors><title>Multiobjective Tactical Planning under Uncertainty for Air Traffic Flow
  and Capacity Management</title><categories>cs.AI</categories><comments>IEEE Congress on Evolutionary Computation (2013). arXiv admin note:
  substantial text overlap with arXiv:1309.3917</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a method to deal with congestion of sectors and delays in the
tactical phase of air traffic flow and capacity management. It relies on
temporal objectives given for every point of the flight plans and shared among
the controllers in order to create a collaborative environment. This would
enhance the transition from the network view of the flow management to the
local view of air traffic control. Uncertainty is modeled at the trajectory
level with temporal information on the boundary points of the crossed sectors
and then, we infer the probabilistic occupancy count. Therefore, we can model
the accuracy of the trajectory prediction in the optimization process in order
to fix some safety margins. On the one hand, more accurate is our prediction;
more efficient will be the proposed solutions, because of the tighter safety
margins. On the other hand, when uncertainty is not negligible, the proposed
solutions will be more robust to disruptions. Furthermore, a multiobjective
algorithm is used to find the tradeoff between the delays and congestion, which
are antagonist in airspace with high traffic density. The flow management
position can choose manually, or automatically with a preference-based
algorithm, the adequate solution. This method is tested against two instances,
one with 10 flights and 5 sectors and one with 300 flights and 16 sectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4109</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4109</id><created>2013-08-09</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author></authors><title>Algorithms for Computing Topological Invariants in 2D and 3D Digital
  Spaces</title><categories>cs.CG cs.DM</categories><comments>keywords: Digital space, Number of holes, Genus of surfaces,
  Algorithm, Time and space complexity. arXiv admin note: text overlap with
  arXiv:1211.3812</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Based on previous results of digital topology, this paper focuses on
algorithms of topological invariants of objects in 2D and 3D Digital Spaces. We
specifically interest in solving hole counting of 2D objects and genus of
closed surface in 3D. We first prove a new formula for hole counting in 2D. The
number of of holes is $h=1 + (|C_4|-|C_2|)/4$ where $C_4$ and $C_2$ are sets of
inward and outward corner points, respectively.
  This paper mainly deals with algorithm design and implementation of practical
computation of topological invariants in digital space. The algorithms relating
to data structures, and pathological case detection and original data
modification are main issues.
  This paper designed fast algorithms for topological invariants such as
connected components, hole counting in 2D and boundary surface genus for 3D.
For 2D images, we designed a linear time algorithm to solve hole counting
problem. In 3D, we designed also O(n) time algorithm to get genus of the closed
surface. These two algorithms are both in $O(\log n)$ space complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4111</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4111</id><created>2013-09-16</created><authors><author><keyname>Qin</keyname><forenames>Tai</forenames></author><author><keyname>Rohe</keyname><forenames>Karl</forenames></author></authors><title>Regularized Spectral Clustering under the Degree-Corrected Stochastic
  Blockmodel</title><categories>stat.ML cs.LG math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral clustering is a fast and popular algorithm for finding clusters in
networks. Recently, Chaudhuri et al. (2012) and Amini et al.(2012) proposed
inspired variations on the algorithm that artificially inflate the node degrees
for improved statistical performance. The current paper extends the previous
statistical estimation results to the more canonical spectral clustering
algorithm in a way that removes any assumption on the minimum degree and
provides guidance on the choice of the tuning parameter. Moreover, our results
show how the &quot;star shape&quot; in the eigenvectors--a common feature of empirical
networks--can be explained by the Degree-Corrected Stochastic Blockmodel and
the Extended Planted Partition model, two statistical models that allow for
highly heterogeneous degrees. Throughout, the paper characterizes and justifies
several of the variations of the spectral clustering algorithm in terms of
these models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4112</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4112</id><created>2013-09-16</created><authors><author><keyname>Kish</keyname><forenames>L. B.</forenames></author><author><keyname>Granqvist</keyname><forenames>C. G.</forenames></author></authors><title>On the security of the Kirchhoff-law-Johnson-noise (KLJN) communicator</title><categories>cs.CR cs.ET</categories><comments>4 pages</comments><journal-ref>Quantum Information Processing, Volume 13, (2014), pp 2213-2219</journal-ref><doi>10.1007/s11128-014-0729-7</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A simple and general proof is given for the information theoretic
(unconditional) security of the Kirchhoff-law-Johnson-noise (KLJN) key exchange
system under practical conditions. The unconditional security for ideal
circumstances, which is based on the Second Law of Thermodynamics, is found to
prevail even under slightly non-ideal conditions. This security level is
guaranteed by the continuity of functions describing classical physical linear,
as well as stable non-linear, systems. Even without privacy amplification,
Eve's probability for successful bit-guessing is found to converge towards 0.5
- i.e., the perfect security level - when ideal conditions are approached.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4132</identifier>
 <datestamp>2014-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4132</id><created>2013-09-16</created><updated>2014-04-03</updated><authors><author><keyname>Angelino</keyname><forenames>Elaine</forenames></author><author><keyname>Kanade</keyname><forenames>Varun</forenames></author></authors><title>Attribute-Efficient Evolvability of Linear Functions</title><categories>cs.LG q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a seminal paper, Valiant (2006) introduced a computational model for
evolution to address the question of complexity that can arise through
Darwinian mechanisms. Valiant views evolution as a restricted form of
computational learning, where the goal is to evolve a hypothesis that is close
to the ideal function. Feldman (2008) showed that (correlational) statistical
query learning algorithms could be framed as evolutionary mechanisms in
Valiant's model. P. Valiant (2012) considered evolvability of real-valued
functions and also showed that weak-optimization algorithms that use
weak-evaluation oracles could be converted to evolutionary mechanisms.
  In this work, we focus on the complexity of representations of evolutionary
mechanisms. In general, the reductions of Feldman and P. Valiant may result in
intermediate representations that are arbitrarily complex (polynomial-sized
circuits). We argue that biological constraints often dictate that the
representations have low complexity, such as constant depth and fan-in
circuits. We give mechanisms for evolving sparse linear functions under a large
class of smooth distributions. These evolutionary algorithms are
attribute-efficient in the sense that the size of the representations and the
number of generations required depend only on the sparsity of the target
function and the accuracy parameter, but have no dependence on the total number
of attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4136</identifier>
 <datestamp>2013-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4136</id><created>2013-09-16</created><updated>2013-11-16</updated><authors><author><keyname>Liu</keyname><forenames>Benyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhilin</forenames></author><author><keyname>Fan</keyname><forenames>Hongqi</forenames></author><author><keyname>Fu</keyname><forenames>Qiang</forenames></author></authors><title>Compression via Compressive Sensing : A Low-Power Framework for the
  Telemonitoring of Multi-Channel Physiological Signals</title><categories>cs.IT math.IT</categories><comments>2013 International Workshop on Biomedical and Health Informatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Telehealth and wearable equipment can deliver personal healthcare and
necessary treatment remotely. One major challenge is transmitting large amount
of biosignals through wireless networks. The limited battery life calls for
low-power data compressors. Compressive Sensing (CS) has proved to be a
low-power compressor. In this study, we apply CS on the compression of
multichannel biosignals. We firstly develop an efficient CS algorithm from the
Block Sparse Bayesian Learning (BSBL) framework. It is based on a combination
of the block sparse model and multiple measurement vector model. Experiments on
real-life Fetal ECGs showed that the proposed algorithm has high fidelity and
efficiency. Implemented in hardware, the proposed algorithm was compared to a
Discrete Wavelet Transform (DWT) based algorithm, verifying the proposed one
has low power consumption and occupies less computational resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4138</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4138</id><created>2013-09-16</created><authors><author><keyname>Liao</keyname><forenames>Wei-Cheng</forenames></author><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Liu</keyname><forenames>Ya-Feng</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author></authors><title>Base Station Activation and Linear Transceiver Design for Optimal
  Resource Management in Heterogeneous Networks</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2014.2331611</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a densely deployed heterogeneous network (HetNet), the number of
pico/micro base stations (BS) can be comparable with the number of the users.
To reduce the operational overhead of the HetNet, proper identification of the
set of serving BSs becomes an important design issue. In this work, we show
that by jointly optimizing the transceivers and determining the active set of
BSs, high system resource utilization can be achieved with only a small number
of BSs. In particular, we provide formulations and efficient algorithms for
such joint optimization problem, under the following two common design
criteria: i) minimization of the total power consumption at the BSs, and ii)
maximization of the system spectrum efficiency. In both cases, we introduce a
nonsmooth regularizer to facilitate the activation of the most appropriate BSs.
We illustrate the efficiency and the efficacy of the proposed algorithms via
extensive numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4140</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4140</id><created>2013-09-16</created><authors><author><keyname>Goyal</keyname><forenames>Navin</forenames></author><author><keyname>Olver</keyname><forenames>Neil</forenames></author><author><keyname>Shepherd</keyname><forenames>F. Bruce</forenames></author></authors><title>Dynamic vs Oblivious Routing in Network Design</title><categories>cs.CC cs.DS cs.NI</categories><journal-ref>Algorithmica, Vol 61, Issue 1, Sept 2011, pp 161-173</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the robust network design problem of finding a minimum cost network
with enough capacity to route all traffic demand matrices in a given polytope.
We investigate the impact of different routing models in this robust setting:
in particular, we compare \emph{oblivious} routing, where the routing between
each terminal pair must be fixed in advance, to \emph{dynamic} routing, where
routings may depend arbitrarily on the current demand. Our main result is a
construction that shows that the optimal cost of such a network based on
oblivious routing (fractional or integral) may be a factor of
$\BigOmega(\log{n})$ more than the cost required when using dynamic routing.
This is true even in the important special case of the asymmetric hose model.
This answers a question in \cite{chekurisurvey07}, and is tight up to constant
factors. Our proof technique builds on a connection between expander graphs and
robust design for single-sink traffic patterns \cite{ChekuriHardness07}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4141</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4141</id><created>2013-09-16</created><authors><author><keyname>Bai</keyname><forenames>Tianyang</forenames></author><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Analysis of Blockage Effects on Urban Cellular Networks</title><categories>cs.IT math.IT</categories><comments>31 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale blockages like buildings affect the performance of urban cellular
networks, especially at higher frequencies. Unfortunately, such blockage
effects are either neglected or characterized by oversimplified models in the
analysis of cellular networks. Leveraging concepts from random shape theory,
this paper proposes a mathematical framework to model random blockages and
analyze their impact on cellular network performance. Random buildings are
modeled as a process of rectangles with random sizes and orientations whose
centers form a Poisson point process on the plane. The distribution of the
number of blockages in a link is proven to be Poisson random variable with
parameter dependent on the length of the link. A path loss model that
incorporates the blockage effects is proposed, which matches experimental
trends observed in prior work. The model is applied to analyze the performance
of cellular networks in urban areas with the presence of buildings, in terms of
connectivity, coverage probability, and average rate. Analytic results show
while buildings may block the desired signal, they may still have a positive
impact on network performance since they can block significantly more
interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4151</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4151</id><created>2013-09-16</created><authors><author><keyname>Jin</keyname><forenames>Qiyu</forenames></author><author><keyname>Grama</keyname><forenames>Ion</forenames></author><author><keyname>Liu</keyname><forenames>Quansheng</forenames></author></authors><title>A Non-Local Means Filter for Removing the Poisson Noise</title><categories>stat.AP cs.CV</categories><comments>24pages,6figures. arXiv admin note: text overlap with
  arXiv:1211.6143, arXiv:1201.5968</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new image denoising algorithm to deal with the Poisson noise model is
given, which is based on the idea of Non-Local Mean. By using the &quot;Oracle&quot;
concept, we establish a theorem to show that the Non-Local Means Filter can
effectively deal with Poisson noise with some modification. Under the
theoretical result, we construct our new algorithm called Non-Local Means
Poisson Filter and demonstrate in theory that the filter converges at the usual
optimal rate. The filter is as simple as the classic Non-Local Means and the
simulation results show that our filter is very competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4156</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4156</id><created>2013-09-16</created><authors><author><keyname>Krings</keyname><forenames>Gautier M.</forenames></author><author><keyname>Carpantier</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Delvenne</keyname><forenames>Jean-Charles</forenames></author></authors><title>Trade integration and trade imbalances in the European Union: a network
  perspective</title><categories>physics.soc-ph cs.CE physics.data-an q-fin.GN</categories><comments>12 pages + 11 pictures</comments><doi>10.1371/journal.pone.0083448</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the ever more integrated and ever more unbalanced trade
relationships between European countries. To better capture the complexity of
economic networks, we propose two global measures that assess the trade
integration and the trade imbalances of the European countries. These measures
are the network (or indirect) counterparts to traditional (or direct) measures
such as the trade-to-GDP (Gross Domestic Product) and trade deficit-to-GDP
ratios. Our indirect tools account for the European inter-country trade
structure and follow (i) a decomposition of the global trade flow into
elementary flows that highlight the long-range dependencies between exporting
and importing economies and (ii) the commute-time distance for trade
integration,which measures the impact of a perturbation in the economy of a
country on another country, possibly through intermediate partners by domino
effect. Our application addresses the impact of the launch of the Euro. We find
that the indirect imbalance measures better identify the countries ultimately
bearing deficits and surpluses, by neutralizing the impact of trade transit
countries, such as the Netherlands. Among others, we find that ultimate
surpluses of Germany are quite concentrated in only three partners. We also
show that for some countries, the direct and indirect measures of trade
integration diverge, thereby revealing that these countries (e.g. Greece and
Portugal) trade to a smaller extent with countries considered as central in the
European Union network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4157</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4157</id><created>2013-09-16</created><authors><author><keyname>Li</keyname><forenames>Rui</forenames></author><author><keyname>Chang</keyname><forenames>Kevin Chen-Chuan</forenames></author></authors><title>EgoNet-UIUC: A Dataset For Ego Network Research</title><categories>cs.SI physics.soc-ph</categories><comments>DataSet Description</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we introduce the version one of EgoNet-UIUC, which is a
dataset for ego network research. The dataset contains about 230 ego networks
in Linkedin, which have about 33K users (with their attributes) and 283K
relationships (with their relationship types) in total. We name this dataset as
EgoNet-UIUC, which stands for Ego Network Dataset from University of Illinois
at Urbana-Champaign.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4161</identifier>
 <datestamp>2014-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4161</id><created>2013-09-16</created><updated>2014-04-01</updated><authors><author><keyname>Luo</keyname><forenames>Wuqiong</forenames></author><author><keyname>Tay</keyname><forenames>Wee Peng</forenames></author><author><keyname>Leng</keyname><forenames>Mei</forenames></author></authors><title>How to Identify an Infection Source with Limited Observations</title><categories>cs.SI physics.soc-ph</categories><doi>10.1109/JSTSP.2014.2315533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rumor spreading in a social network or a disease propagating in a community
can be modeled as an infection spreading in a network. Finding the infection
source is a challenging problem, which is made more difficult in many
applications where we have access only to a limited set of observations. We
consider the problem of estimating an infection source for a
Susceptible-Infected model, in which not all infected nodes can be observed.
When the network is a tree, we show that an estimator for the source node
associated with the most likely infection path that yields the limited
observations is given by a Jordan center, i.e., a node with minimum distance to
the set of observed infected nodes. We also propose approximate source
estimators for general networks. Simulation results on various synthetic
networks and real world networks suggest that our estimators perform better
than distance, closeness, and betweenness centrality based heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4164</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4164</id><created>2013-09-16</created><authors><author><keyname>Peng-Fei</keyname><forenames>Wang</forenames></author><author><keyname>Jian-She</keyname><forenames>Cao</forenames></author><author><keyname>Qiang</keyname><forenames>Ye</forenames></author></authors><title>The Development of ADS Virtual Accelerator Based on XAL</title><categories>physics.acc-ph cs.SY</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  XAL is a high level accelerator application framework originally developed by
the Spallation Neutron Source (SNS), Oak Ridge National Laboratory. It has
advanced design concept and adopted by many international accelerator
laboratories. Adopting XAL for ADS is a key subject in the long term. This
paper will present the modifications to the original XAL applications for ADS.
The work includes proper relational database schema modification in order to
better suit ADS configuration data requirement, redesigning and re-implementing
db2xal application and modifying the virtual accelerator application. In
addition, the new device types and new device attributes for ADS online
modeling purpose is also described here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4166</identifier>
 <datestamp>2014-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4166</id><created>2013-09-16</created><updated>2014-04-22</updated><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author></authors><title>A New Class of Index Coding Instances Where Linear Coding is Optimal</title><categories>cs.IT math.IT</categories><comments>accepted and to be presented at the 2014 International Symposium on
  Network Coding (NetCod)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study index-coding problems (one sender broadcasting messages to multiple
receivers) where each message is requested by one receiver, and each receiver
may know some messages a priori. This type of index-coding problems can be
fully described by directed graphs. The aim is to find the minimum codelength
that the sender needs to transmit in order to simultaneously satisfy all
receivers' requests. For any directed graph, we show that if a maximum acyclic
induced subgraph (MAIS) is obtained by removing two or fewer vertices from the
graph, then the minimum codelength (i.e., the solution to the index-coding
problem) equals the number of vertices in the MAIS, and linear codes are
optimal for this index-coding problem. Our result increases the set of
index-coding problems for which linear index codes are proven to be optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4168</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4168</id><created>2013-09-16</created><authors><author><keyname>Mikolov</keyname><forenames>Tomas</forenames></author><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author></authors><title>Exploiting Similarities among Languages for Machine Translation</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dictionaries and phrase tables are the basis of modern statistical machine
translation systems. This paper develops a method that can automate the process
of generating and extending dictionaries and phrase tables. Our method can
translate missing word and phrase entries by learning language structures based
on large monolingual data and mapping between languages from small bilingual
data. It uses distributed representation of words and learns a linear mapping
between vector spaces of languages. Despite its simplicity, our method is
surprisingly effective: we can achieve almost 90% precision@5 for translation
of words between English and Spanish. This method makes little assumption about
the languages, so it can be used to extend and refine dictionaries and
translation tables for any language pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4203</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4203</id><created>2013-09-17</created><authors><author><keyname>Kibria</keyname><forenames>Mirza Golam</forenames></author><author><keyname>Murata</keyname><forenames>Hidekazu</forenames></author></authors><title>An efficient algorithm for weighted sum-rate maximization in multicell
  downlink beamforming</title><categories>cs.IT math.IT</categories><doi>10.1587/transfun.E97.A.69</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers coordinated linear precoding for rate optimization in
downlink multicell, multiuser orthogonal frequency- division multiple access
networks. We focus on two different design criteria. In the first, the weighted
sum-rate is maximized under transmit power constraints per base station. In the
second, we minimize the total transmit power satisfying the
signal-to-interference-plus-noise-ratio constraints of the subcarriers per
cell. Both problems are solved using standard conic optimization packages. A
less complex, fast, and provably convergent algorithm that maximizes the
weighted sum-rate with per-cell transmit power constraints is formulated. We
approximate the nonconvex weighted sum- rate maximization (WSRM) problem with a
solvable convex form by means of a sequential parametric convex approximation
approach. The second- order cone formulations of an objective function and the
constraints of the optimization problem are derived through a proper change of
variables, first-order linear approximation, and hyperbolic constraints
transformation. This algorithm converges to the suboptimal solution while
taking fewer it- erations in comparison to other known iterative WSRM
algorithms. Numerical results are presented to demonstrate the effectiveness
and superiority of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4251</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4251</id><created>2013-09-17</created><authors><author><keyname>Feyzmahdavian</keyname><forenames>Hamid Reza</forenames></author><author><keyname>Alam</keyname><forenames>Assad</forenames></author><author><keyname>Gattami</keyname><forenames>Ather</forenames></author></authors><title>Optimal Distributed Controller Design with Communication Delays:
  Application to Vehicle Formations</title><categories>cs.SY</categories><comments>Submitted to the 51nd IEEE Conference on Decision and Control, 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper develops a controller synthesis algorithm for distributed LQG
control problems under output feedback. We consider a system consisting of
three interconnected linear subsystems with a delayed information sharing
structure. While the state-feedback case of this problem has previously been
solved, the extension to output-feedback is nontrivial, as the classical
separation principle fails. To find the optimal solution, the controller is
decomposed into two independent components. One is delayed centralized LQR, and
the other is the sum of correction terms based on additional local information.
Explicit discrete-time equations are derived whose solutions are the gains of
the optimal controller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4259</identifier>
 <datestamp>2014-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4259</id><created>2013-09-17</created><authors><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author><author><keyname>Ahnert</keyname><forenames>Sebastian E.</forenames></author><author><keyname>Fink</keyname><forenames>Thomas M. A.</forenames></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author></authors><title>Optimal scales in weighted networks</title><categories>physics.data-an cond-mat.dis-nn cond-mat.stat-mech cs.SI</categories><comments>Accepted for presentation at SocInfo 2013, Kyoto, 25-27 November 2013
  (http://www.socinfo2013.org)</comments><journal-ref>Lecture Notes in Computer Science 8238, 346-359 (2013)</journal-ref><doi>10.1007/978-3-319-03260-3_30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of networks characterized by links with heterogeneous intensity
or weight suffers from two long-standing problems of arbitrariness. On one
hand, the definitions of topological properties introduced for binary graphs
can be generalized in non-unique ways to weighted networks. On the other hand,
even when a definition is given, there is no natural choice of the (optimal)
scale of link intensities (e.g. the money unit in economic networks). Here we
show that these two seemingly independent problems can be regarded as
intimately related, and propose a common solution to both. Using a formalism
that we recently proposed in order to map a weighted network to an ensemble of
binary graphs, we introduce an information-theoretic approach leading to the
least biased generalization of binary properties to weighted networks, and at
the same time fixing the optimal scale of link intensities. We illustrate our
method on various social and economic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4266</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4266</id><created>2013-09-17</created><authors><author><keyname>Hartman</keyname><forenames>David</forenames></author><author><keyname>Hubicka</keyname><forenames>Jan</forenames></author><author><keyname>Nesetril</keyname><forenames>Jaroslav</forenames></author></authors><title>Complexities of relational structures</title><categories>math.CO cs.CC</categories><comments>18 pages, submitted to Mathematica Slovaca</comments><msc-class>05C75</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relational complexity, introduced by G. Cherlin, G. Martin, and D.
Saracino, is a measure of ultrahomogeneity of a relational structure. It
provides an information on minimal arity of additional invariant relations
needed to turn given structure into an ultrahomogeneous one. The original
motivation was group theory. This work focuses more on structures and provides
an alternative approach. Our study is motivated by related concept of lift
complexity studied by Hubicka and Nesetril.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4275</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4275</id><created>2013-09-17</created><updated>2013-09-18</updated><authors><author><keyname>J&#xe4;rpe</keyname><forenames>Eric</forenames></author><author><keyname>Weckst&#xe9;n</keyname><forenames>Mattias</forenames></author></authors><title>Detecting Encrypted code</title><categories>cs.CR stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a computer hard drive is confiscated in the conduct of a police
investigation the information contained is commonly encrypted at such a level
that brute force thechniques have to be used. This is too time consuming if the
hard drive is large, thus demanding methods to make a smart distinction between
likely encrypted and non-encrypted code in order to use the cracking resources
efficiently. The methods are stopping rules according to the cutting edge of
on-line change-point detection. The performance of the methods is evaluated in
terms of conditional expected delay and predictive value having calibrated the
methods so that they all have the same expected time till false alarm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4291</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4291</id><created>2013-09-17</created><updated>2013-11-08</updated><authors><author><keyname>Collins</keyname><forenames>E. J.</forenames></author></authors><title>Models and algorithms for skip-free Markov decision processes on trees</title><categories>math.OC cs.AI math.PR</categories><comments>v1: 20 pages Accepted for publication subject to minor changes by the
  Journal of the Operational Research Society (JORS); v2: 22 pages, 1 figure,
  revised title, example added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a class of models for multidimensional control problems which we
call skip-free Markov decision processes on trees. We describe and analyse an
algorithm applicable to Markov decision processes of this type that are
skip-free in the negative direction. Starting with the finite average cost
case, we show that the algorithm combines the advantages of both value
iteration and policy iteration -- it is guaranteed to converge to an optimal
policy and optimal value function after a finite number of iterations but the
computational effort required for each iteration step is comparable with that
for value iteration. We show that the algorithm can also be used to solve
discounted cost models and continuous time models, and that a suitably modified
algorithm can be used to solve communicating models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4306</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4306</id><created>2013-09-17</created><updated>2014-10-14</updated><authors><author><keyname>Giryes</keyname><forenames>Raja</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author></authors><title>Sparsity Based Poisson Denoising with Dictionary Learning</title><categories>cs.CV stat.ML</categories><comments>13 pages, 9 figures</comments><doi>10.1109/TIP.2014.2362057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of Poisson denoising appears in various imaging applications,
such as low-light photography, medical imaging and microscopy. In cases of high
SNR, several transformations exist so as to convert the Poisson noise into an
additive i.i.d. Gaussian noise, for which many effective algorithms are
available. However, in a low SNR regime, these transformations are
significantly less accurate, and a strategy that relies directly on the true
noise statistics is required. A recent work by Salmon et al. took this route,
proposing a patch-based exponential image representation model based on GMM
(Gaussian mixture model), leading to state-of-the-art results. In this paper,
we propose to harness sparse-representation modeling to the image patches,
adopting the same exponential idea. Our scheme uses a greedy pursuit with
boot-strapping based stopping condition and dictionary learning within the
denoising process. The reconstruction performance of the proposed scheme is
competitive with leading methods in high SNR, and achieving state-of-the-art
results in cases of low SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4323</identifier>
 <datestamp>2014-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4323</id><created>2013-09-17</created><updated>2014-12-01</updated><authors><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author><author><keyname>Matos</keyname><forenames>In&#xea;s</forenames></author><author><keyname>Sacrist&#xe1;n</keyname><forenames>Vera</forenames></author><author><keyname>Saumell</keyname><forenames>Maria</forenames></author><author><keyname>Silveira</keyname><forenames>Rodrigo I.</forenames></author><author><keyname>Staals</keyname><forenames>Frank</forenames></author></authors><title>Terrain visibility with multiple viewpoints</title><categories>cs.CG</categories><comments>Manuscript accompanying shorter version in ISAAC 2013; some
  algorithms and bounds have improved with respect to the ISAAC version. The
  journal version will appear in IJCGA (without Section 4)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of visibility in polyhedral terrains in the presence of
multiple viewpoints. We consider a triangulated terrain with $m&gt;1$ viewpoints
(or guards) located on the terrain surface. A point on the terrain is
considered \emph{visible} if it has an unobstructed line of sight to at least
one viewpoint. We study several natural and fundamental visibility structures:
(1) the visibility map, which is a partition of the terrain into visible and
invisible regions; (2) the \emph{colored} visibility map, which is a partition
of the terrain into regions whose points have exactly the same visible
viewpoints; and (3) the Voronoi visibility map, which is a partition of the
terrain into regions whose points have the same closest visible viewpoint. We
study the complexity of each structure for both 1.5D and 2.5D terrains, and
provide efficient algorithms to construct them. Our algorithm for the
visibility map in 2.5D terrains improves on the only existing algorithm in this
setting. To the best of our knowledge, the other structures have not been
studied before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4334</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4334</id><created>2013-09-17</created><authors><author><keyname>Dias</keyname><forenames>Martin</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Cassou</keyname><forenames>Damien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Ducasse</keyname><forenames>St&#xe9;phane</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>Representing Code History with Development Environment Events</title><categories>cs.PL</categories><proxy>ccsd</proxy><journal-ref>IWST-2013 - 5th International Workshop on Smalltalk Technologies
  (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern development environments handle information about the intent of the
programmer: for example, they use abstract syntax trees for providing
high-level code manipulation such as refactorings; nevertheless, they do not
keep track of this information in a way that would simplify code sharing and
change understanding. In most Smalltalk systems, source code modifications are
immediately registered in a transaction log often called a ChangeSet. Such
mechanism has proven reliability, but it has several limitations. In this paper
we analyse such limitations and describe scenarios and requirements for
tracking fine-grained code history with a semantic representation. We present
Epicea, an early prototype implementation. We want to enrich code sharing with
extra information from the IDE, which will help understanding the intention of
the changes and let a new generation of tools act in consequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4345</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4345</id><created>2013-09-17</created><authors><author><keyname>Brzezi&#x144;ski-Spiczak</keyname><forenames>M.</forenames></author><author><keyname>Dobosz</keyname><forenames>K.</forenames></author><author><keyname>Lis</keyname><forenames>M.</forenames></author><author><keyname>Pintal</keyname><forenames>M.</forenames></author></authors><title>Music Files Search System</title><categories>cs.IR</categories><journal-ref>Information systems architecture and technology : information
  systems and computer communication networks / eds Adam Grzech [i in.].
  Wroc{\l}aw : Oficyna Wydawnicza Politechniki Wroc{\l}awskiej, 2008. s.
  201-211</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper introduces a project of advanced system of music retrieval from
the Internet. The system uses combination of text search (by author, title and
other information about the music file included in id3 tag description or
similar for other file types) with more intuitive and novel method of melody
search using query by humming. The patterns for storing text and melody
information as well as improved clustering algorithm for the pattern space were
proposed. The search engine is planned to optimise the query due to the data
input by user, thanks to the structure of text and melody index database. The
system is planned to be a plug-in for popular digital music players or an
independent player. An advanced system of recommendation based on information
gathered from user's profile and search history is an integral part of the
system. The recommendation mechanism uses scrobbling methods and is responsible
for making suggestions of songs unknown to the user but similar to his
preferred music styles and positioning search results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4349</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4349</id><created>2013-09-17</created><authors><author><keyname>Lis</keyname><forenames>M.</forenames></author><author><keyname>Pintal</keyname><forenames>L.</forenames></author></authors><title>Report: GPU Based Massive Parallel Kawasaki Kinetics In Monte Carlo
  Modelling of Lipid Microdomains</title><categories>cs.DC</categories><report-no>PRE 5/2012</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper introduces novel method of simulation of lipid biomembranes based
on Metropolis Hastings algorithm and Graphic Processing Unit computational
power. Method gives up to 55 times computational boost in comparison to
classical computations. Extensive study of algorithm correctness is provided.
Analysis of simulation results and results obtained with classical simulation
methodologies are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4355</identifier>
 <datestamp>2015-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4355</id><created>2013-09-17</created><updated>2015-04-29</updated><authors><author><keyname>Lameiro</keyname><forenames>Christian</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>&#xd3;scar</forenames></author><author><keyname>Garc&#xed;a-Naya</keyname><forenames>Jos&#xe9; A.</forenames></author><author><keyname>Santamar&#xed;a</keyname><forenames>Ignacio</forenames></author><author><keyname>Castedo</keyname><forenames>Luis</forenames></author></authors><title>Experimental Evaluation of Interference Alignment for Broadband WLAN
  Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an experimental study on the performance of spatial
Interference Alignment (IA) in indoor wireless local area network scenarios
that use Orthogonal Frequency Division Multiplexing (OFDM) according to the
physical-layer specifications of the IEEE 802.11a standard. Experiments have
been carried out using a wireless network testbed capable of implementing a
3-user MIMO interference channel. We have implemented IA decoding schemes that
can be designed according to distinct criteria (e.g. zero-forcing or MaxSINR).
The measurement methodology has been validated considering practical issues
like the number of OFDM training symbols used for channel estimation or
feedback time. In case of asynchronous users, a time-domain IA decoding filter
is also compared to its frequency-domain counterpart. We also evaluated the
performance of IA from bit error rate measurement-based results in comparison
to different time-division multiple access transmission schemes. The comparison
includes single- and multiple-antenna systems transmitting over the dominant
mode of the MIMO channel. Our results indicate that spatial IA is suitable for
practical indoor scenarios in which wireless channels often exhibit relatively
large coherence times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4356</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4356</id><created>2013-09-17</created><authors><author><keyname>Manzoor</keyname><forenames>B.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Rehman</keyname><forenames>O.</forenames></author><author><keyname>Bouk</keyname><forenames>S. H.</forenames></author><author><keyname>Ahmed</keyname><forenames>S. H.</forenames></author><author><keyname>Kim</keyname><forenames>D.</forenames></author></authors><title>Energy Aware Error Control in Cooperative Communication in Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>ACM Research in Adaptive and Convergent Systems (RACS 2013),
  Montreal, Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to small size of sensor nodes deployed in Wireless Sensor Networks
(WSNs), energy utilization is a key issue. Poor channel conditions lead to
retransmissions and hence, result in energy wastage. Error control strategies
are usually utilized to accommodate channel impairments like noise and fading
in order to optimize energy consumption for network lifetime enhancement.
Meanwhile, cooperative communication also emerges to be an appropriate
candidate to combat the effects of channel fading. Energy efficiency of
cooperative scheme when applied with Automatic Repeat Request (ARQ), Hybrid-ARQ
(HARQ) and Forward Error Correction (FEC) is investigated in this work.
Moreover, the expressions for energy efficiency of Direct Transmission, Single
Relay Cooperation and Multi Relay Cooperation are also derived. In all, our
work is focused towards energy optimal communication in WSNs. Our results show
that error control strategies with cooperative schemes can significantly
enhance system performance in form of energy optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4367</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4367</id><created>2013-09-17</created><authors><author><keyname>Bouroubi</keyname><forenames>Sadek</forenames></author><author><keyname>Charchali</keyname><forenames>Fella</forenames></author><author><keyname>Tani</keyname><forenames>Nesrine Benyanhia</forenames></author></authors><title>The Set Partitions: Solution for the sharing secret keys</title><categories>cs.CR math.CO</categories><msc-class>11P82, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Confidentiality was and will always remain a critical need in the exchanges
either between persons or the official parties. Recently, cryptology has made a
jump, from classical form to the quantum one, we talk about quantum
cryptography. This theory, although is perfectly safe, there are still binding
limits of implementation. In this paper, we developed a new cryptographic
protocol, called BCB12 protocol, which will be used to provide random keys
shared via a classical channel, using the set partitions. Each key can be long
enough that the plain text in question, in purpose, for instance, to hide then
to transmit the secret information using the Vernam cipher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4372</identifier>
 <datestamp>2015-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4372</id><created>2013-09-17</created><updated>2015-09-30</updated><authors><author><keyname>Tanaka</keyname><forenames>Takashi</forenames></author><author><keyname>Farokhi</keyname><forenames>Farhad</forenames></author><author><keyname>Langbort</keyname><forenames>C&#xe9;dric</forenames></author></authors><title>Faithful Implementations of Distributed Algorithms and Control Laws</title><categories>cs.GT math.OC</categories><comments>This manuscript is the extended version of arXiv:1304.3063, which was
  presented at the 52nd IEEE Conference on Decision and Control. In addition to
  the previously covered material, this contains a complete discussion
  including proofs and new results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a distributed algorithm must be executed by strategic agents with
misaligned interests, a social leader needs to introduce an appropriate
tax/subsidy mechanism to incentivize agents to faithfully implement the
intended algorithm so that a correct outcome is obtained. We discuss the
incentive issues of implementing economically efficient distributed algorithms
using the framework of indirect mechanism design theory. In particular, we show
that indirect Groves mechanisms are not only sufficient but also necessary to
achieve incentive compatibility. This result can be viewed as a generalization
of the Green-Laffont theorem to indirect mechanisms. Then we introduce the
notion of asymptotic incentive compatibility as an appropriate solution concept
to faithfully implement distributed and iterative optimization algorithms. We
consider two special types of optimization algorithms: dual decomposition
algorithms for resource allocation and average consensus algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4373</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4373</id><created>2013-09-17</created><authors><author><keyname>Aslam</keyname><forenames>M.</forenames></author><author><keyname>Rasheed</keyname><forenames>M. B.</forenames></author><author><keyname>Shah</keyname><forenames>T.</forenames></author><author><keyname>Rahim</keyname><forenames>A.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Qasim</keyname><forenames>M. W.</forenames></author><author><keyname>Hassan</keyname><forenames>A.</forenames></author><author><keyname>Khan</keyname><forenames>A.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author></authors><title>Energy optimization and Performance Analysis of Cluster Based Routing
  Protocols Extended from LEACH for WSNs</title><categories>cs.NI</categories><comments>Journal of Basic and Applied Scientific Research, 2013. arXiv admin
  note: text overlap with arXiv:1207.2609</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An energy efficient routing protocol is the major attentiveness for
researcher in field of Wireless Sensor Networks (WSNs). In this paper, we
present some energy efficient hierarchal routing protocols, prosper from
conventional Low Energy Adaptive Clustering Hierarchy (LEACH) routing protocol.
Fundamental objective of our consideration is to analyze, how these ex- tended
routing protocols work in order to optimize lifetime of network nodes and how
quality of routing protocols is improved for WSNs. Furthermore, this paper also
emphasizes on some issues experienced by LEACH and also explains how these
issues are tackled by other enhanced routing protocols from classi- cal LEACH.
We analytically compare the features and performance issues of each hierarchal
routing protocol. We also simulate selected clustering routing protocols for
our study in order to elaborate the enhancement achieved by ameliorate routing
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4374</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4374</id><created>2013-09-17</created><authors><author><keyname>Rehman</keyname><forenames>O.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Haider</keyname><forenames>A.</forenames></author><author><keyname>Amjad</keyname><forenames>N.</forenames></author><author><keyname>Awan</keyname><forenames>A. A.</forenames></author><author><keyname>Qamar</keyname><forenames>M.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author></authors><title>An Energy Efficient Decoding Scheme for Wireless Body Area Sensor
  Networks</title><categories>cs.NI</categories><comments>Journal of Basic and Applied Scientific Research. 2013. arXiv admin
  note: substantial text overlap with arXiv:1309.0752</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major challenges in Wireless Body Area Networks (WBANs) is to
prolong the lifetime of network. Traditional research work focuses on
minimizing transmit power; however, in the case of short range communication
the consumption power in decoding is significantly larger than transmit power.
This paper investigates the minimization of total power consumption by reducing
the decoding power consumption. For achieving a desired Bit Error Rate (BER),
we introduce some fundamental results on the basis of iterative message-passing
algorithms for Low Density Parity Check Code (LDPC). To reduce energy
dissipation in decoder, LDPC based coded communications between sensors are
considered. Moreover, we evaluate the performance of LDPC at different code
rates and introduce Adaptive Iterative Decoding (AID) by exploiting threshold
on the number of iterations for a certain BER (0.0004). In iterative LDPC
decoding, the total energy consumption of network is reduced by 20 to 25%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4379</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4379</id><created>2013-09-17</created><authors><author><keyname>Ahmed</keyname><forenames>S.</forenames></author><author><keyname>Sandhu</keyname><forenames>M. M.</forenames></author><author><keyname>Amjad</keyname><forenames>N.</forenames></author><author><keyname>Haider</keyname><forenames>A.</forenames></author><author><keyname>Akbar</keyname><forenames>M.</forenames></author><author><keyname>Ahmad</keyname><forenames>A.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author></authors><title>iMOD LEACH: improved MODified LEACH Protocol for Wireless Sensor
  Networks</title><categories>cs.NI</categories><comments>Journal of Basic and Applied Scientific Research, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increased use of Wireless sensor Networks (WSNs) in variety of applications
has enabled the designers to create autonomous sensors, which can be deployed
randomly, without human supervision, for the purpose of sensing and
communicating valuable data. Many energy-efficient routing protocols are
designed for WSNs based on clustering structure. In this paper, we have
proposed iMODLEACH protocol which is an extension to the MODLEACH protocol.
Simulation results indicate that iMODLEACH outperforms MODLEACH in terms of
network life-time and packets transferred to base station. The mathematical
analysis helps to select such values of these parameters which can suit a
particular wireless sensor network application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4385</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4385</id><created>2013-09-17</created><authors><author><keyname>Howland</keyname><forenames>Gregory A.</forenames></author><author><keyname>Lum</keyname><forenames>Daniel J.</forenames></author><author><keyname>Ware</keyname><forenames>Matthew R.</forenames></author><author><keyname>Howell</keyname><forenames>John C.</forenames></author></authors><title>Photon counting compressive depth mapping</title><categories>physics.optics cs.CV</categories><comments>16 pages, 8 figures</comments><doi>10.1364/OE.21.023822</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate a compressed sensing, photon counting lidar system based on
the single-pixel camera. Our technique recovers both depth and intensity maps
from a single under-sampled set of incoherent, linear projections of a scene of
interest at ultra-low light levels around 0.5 picowatts. Only two-dimensional
reconstructions are required to image a three-dimensional scene. We demonstrate
intensity imaging and depth mapping at 256 x 256 pixel transverse resolution
with acquisition times as short as 3 seconds. We also show novelty filtering,
reconstructing only the difference between two instances of a scene. Finally,
we acquire 32 x 32 pixel real-time video for three-dimensional object tracking
at 14 frames-per-second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4386</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4386</id><created>2013-09-17</created><authors><author><keyname>Mahmood</keyname><forenames>D.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Khan</keyname><forenames>A.</forenames></author><author><keyname>Qurashi</keyname><forenames>S.</forenames></author><author><keyname>Memon</keyname><forenames>A.</forenames></author></authors><title>Modeling and Evaluating Performance of Routing Operations in Reactive
  Routing Protocols</title><categories>cs.NI</categories><comments>Journal of Basic and Applied Scientific Research, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reactive routing protocols are gaining popularity due to their event driven
nature day by day. In this vary paper, reactive routing is studied precisely.
Route request, route reply and route maintenance phases are modeled with
respect to control overhead. Control overhead varies with respect to change in
various parameters. Our model calculates these variations as well. Besides
modeling, we chose three most favored reactive routing protocols as Ad-Hoc on
Demand Distance Vector (AODV), Dynamic Source Routing (DSR) and Dynamic MANET
on Demand (DYMO) for our experiments. We simulated these protocols using ns-2
for a detailed comparison and performance analysis with respect to mobility and
scalability issues keeping metrics of throughput, route delay and control over
head. Their performances and comparisons are extensively presented in last part
of our work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4389</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4389</id><created>2013-09-17</created><authors><author><keyname>Mahmood</keyname><forenames>D.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Qasim</keyname><forenames>U.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Khan</keyname><forenames>A.</forenames></author><author><keyname>Qurashi</keyname><forenames>S.</forenames></author><author><keyname>Memon</keyname><forenames>A.</forenames></author></authors><title>Modeling and Evaluating Performance of Routing Operations in Proactive
  Routing Protocols</title><categories>cs.NI</categories><comments>Journal of Basic and Applied Scientific Research, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To ensure seamless communication in wireless multi-hop networks, certain
classes of routing protocols are defined. This vary paper, is based upon
proactive routing protocols for Wireless multihop networks. Initially, we
discuss Destination Sequence Distance Vector (DSDV), Fish-eye State Routing
(FSR) and Optimized Link State Routing (OLSR), precisely followed by
mathematical frame work of control overhead regarding proactive natured routing
protocols. Finally, extensive simulations are done using NS 2 respecting above
mentioned routing protocols covering mobility and scalability issues. Said
protocols are compared under mobile and dense environments to conclude our
performance analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4396</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4396</id><created>2013-09-17</created><authors><author><keyname>Sacharidis</keyname><forenames>Dimitris</forenames></author><author><keyname>Bouros</keyname><forenames>Panagiotis</forenames></author></authors><title>Routing Directions: Keeping it Fast and Simple</title><categories>cs.DS cs.DB</categories><comments>Full version of the SIGSPATIAL'13 paper</comments><acm-class>H.2.8</acm-class><journal-ref>21st ACM SIGSPATIAL International Conference on Advances in
  Geographic Information Systems (ACM SIGSPATIAL GIS 2013), Orlando, Florida,
  USA, November 5-8, 2013</journal-ref><doi>10.1145/2525314.2525362</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of providing meaningful routing directions over road networks is
of great importance. In many real-life cases, the fastest route may not be the
ideal choice for providing directions in written, spoken text, or for an
unfamiliar neighborhood, or in cases of emergency. Rather, it is often more
preferable to offer &quot;simple&quot; directions that are easy to memorize, explain,
understand or follow. However, there exist cases where the simplest route is
considerably longer than the fastest. This paper tries to address this issue,
by finding near-simplest routes which are as short as possible and near-fastest
routes which are as simple as possible. Particularly, we focus on efficiency,
and propose novel algorithms, which are theoretically and experimentally shown
to be significantly faster than existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4405</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4405</id><created>2013-09-17</created><authors><author><keyname>Skowron</keyname><forenames>Piotr</forenames></author><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author></authors><title>Approximating the MaxCover Problem with Bounded Frequencies in FPT Time</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study approximation algorithms for several variants of the MaxCover
problem, with the focus on algorithms that run in FPT time. In the MaxCover
problem we are given a set N of elements, a family S of subsets of N, and an
integer K. The goal is to find up to K sets from S that jointly cover (i.e.,
include) as many elements as possible. This problem is well-known to be NP-hard
and, under standard complexity-theoretic assumptions, the best possible
polynomial-time approximation algorithm has approximation ratio (1 - 1/e). We
first consider a variant of MaxCover with bounded element frequencies, i.e., a
variant where there is a constant p such that each element belongs to at most p
sets in S. For this case we show that there is an FPT approximation scheme
(i.e., for each B there is a B-approximation algorithm running in FPT time) for
the problem of maximizing the number of covered elements, and a randomized FPT
approximation scheme for the problem of minimizing the number of elements left
uncovered (we take K to be the parameter). Then, for the case where there is a
constant p such that each element belongs to at least p sets from S, we show
that the standard greedy approximation algorithm achieves approximation ratio
exactly (1-e^{-max(pK/|S|, 1)}). We conclude by considering an unrestricted
variant of MaxCover, and show approximation algorithms that run in exponential
time and combine an exact algorithm with a greedy approximation. Some of our
results improve currently known results for MaxVertexCover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4408</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4408</id><created>2013-09-17</created><updated>2013-09-17</updated><authors><author><keyname>Liang</keyname><forenames>Percy</forenames></author></authors><title>Lambda Dependency-Based Compositional Semantics</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note presents a new formal language, lambda dependency-based
compositional semantics (lambda DCS) for representing logical forms in semantic
parsing. By eliminating variables and making existential quantification
implicit, lambda DCS logical forms are generally more compact than those in
lambda calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4411</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4411</id><created>2013-09-17</created><updated>2015-04-29</updated><authors><author><keyname>Halu</keyname><forenames>Arda</forenames></author><author><keyname>Mukherjee</keyname><forenames>Satyam</forenames></author><author><keyname>Bianconi</keyname><forenames>Ginestra</forenames></author></authors><title>Emergence of overlap in ensembles of spatial multiplexes and statistical
  mechanics of spatial interacting networks ensembles</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>(12 pages, 4 figures) for downloading data see URL
  http://sites.google.com/site/satyammukherjee/pubs</comments><journal-ref>Phys. Rev. E 89, 012806 (2014)</journal-ref><doi>10.1103/PhysRevE.89.012806</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial networks range from the brain networks, to transportation networks
and infrastructures. Recently interacting and multiplex networks are attracting
great attention because their dynamics and robustness cannot be understood
without treating at the same time several networks. Here we present maximal
entropy ensembles of spatial multiplex and spatial interacting networks that
can be used in order to model spatial multilayer network structures and to
build null models of real datasets. We show that spatial multiplex naturally
develop a significant overlap of the links, a noticeable property of many
multiplexes that can affect significantly the dynamics taking place on them.
Additionally, we characterize ensembles of spatial interacting networks and we
analyse the structure of interacting airport and railway networks in India,
showing the effect of space in determining the link probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4413</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4413</id><created>2013-09-17</created><updated>2013-09-17</updated><authors><author><keyname>Huang</keyname><forenames>Zhanpeng</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Peylo</keyname><forenames>Christoph</forenames></author><author><keyname>Chatzopoulos</keyname><forenames>Dimitris</forenames></author></authors><title>Mobile augmented reality survey: a bottom-up approach</title><categories>cs.GR cs.HC</categories><comments>35 pages</comments><acm-class>H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Augmented Reality (AR) is becoming mobile. Mobile devices have many
constraints but also rich new features that traditional desktop computers do
not have. There are several survey papers on AR, but none is dedicated to
Mobile Augmented Reality (MAR). Our work serves the purpose of closing this
gap. The contents are organized with a bottom-up approach. We first present the
state-of-the-art in system components including hardware platforms, software
frameworks and display devices, follows with enabling technologies such as
tracking and data management. We then survey the latest technologies and
methods to improve run-time performance and energy efficiency for practical
implementation. On top of these, we further introduce the application fields
and several typical MAR applications. Finally we conclude the survey with
several challenge problems, which are under exploration and require great
research efforts in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4416</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4416</id><created>2013-09-13</created><authors><author><keyname>McCabe-Dansted</keyname><forenames>John C.</forenames></author><author><keyname>French</keyname><forenames>Tim</forenames></author><author><keyname>Reynolds</keyname><forenames>Mark</forenames></author><author><keyname>Pinchinat</keyname><forenames>Sophie</forenames></author></authors><title>Specifying Robustness</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new logic RoCTL* to model robustness in concurrent
systems. RoCTL* extends CTL* with the addition of Obligatory and Robustly
operators, which quantify over failure-free paths and paths with one more
failure respectively. We present a number of examples of problems to which
RoCTL* can be applied. The core result of this paper is to show that RoCTL* is
expressively equivalent to CTL* but is non-elementarily more succinct. We
present a translation from RoCTL* into CTL* that preserves truth but may result
in non-elementary growth in the length of the translated formula as each nested
Robustly operator may result in an extra exponential blowup. However, we show
that this translation is optimal in the sense that any equivalence preserving
translation will require an extra exponential growth per nested Robustly. We
also compare RoCTL* to Quantified CTL* (QCTL*) and hybrid logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4426</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4426</id><created>2013-09-17</created><authors><author><keyname>Widmer</keyname><forenames>Christian</forenames></author><author><keyname>Drewe</keyname><forenames>Philipp</forenames></author><author><keyname>Lou</keyname><forenames>Xinghua</forenames></author><author><keyname>Umrania</keyname><forenames>Shefali</forenames></author><author><keyname>Heinrich</keyname><forenames>Stephanie</forenames></author><author><keyname>R&#xe4;tsch</keyname><forenames>Gunnar</forenames></author></authors><title>GRED: Graph-Regularized 3D Shape Reconstruction from Highly Anisotropic
  and Noisy Images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of microscopy images can provide insight into many biological
processes. One particularly challenging problem is cell nuclear segmentation in
highly anisotropic and noisy 3D image data. Manually localizing and segmenting
each and every cell nuclei is very time consuming, which remains a bottleneck
in large scale biological experiments. In this work we present a tool for
automated segmentation of cell nuclei from 3D fluorescent microscopic data. Our
tool is based on state-of-the-art image processing and machine learning
techniques and supports a friendly graphical user interface (GUI). We show that
our tool is as accurate as manual annotation but greatly reduces the time for
the registration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4429</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4429</id><created>2013-09-17</created><authors><author><keyname>Vermeltfoort</keyname><forenames>A. T.</forenames></author><author><keyname>Van Schijndel</keyname><forenames>A. W. M.</forenames></author></authors><title>Comsol Simulations of Cracking in Point Loaded Masonry with Randomly
  Distributed Material Properties</title><categories>cs.CE</categories><comments>Conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes COMSOL simulations of the stress and crack development
in the area where a masonry wall supports a floor. In these simulations one of
the main material properties of calcium silicate, its E-value, was assigned
randomly to the finite elements of the modeled specimen. Calcium silicate is a
frequently used building material with a relatively brittle fracture
characteristic. Its initial E-value varies, as well as tensile strength and
post peak behavior. Therefore, in the simulation, initial E-values were
randomly assigned to the elements of the model and a step function used for
describing the descending branch. The method also allows for variation in
strength to be taken into account in future research. The performed non-linear
simulation results are compared with experimental findings. They show the
stress distribution and cracking behavior in point loaded masonry when varying
material properties are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4496</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4496</id><created>2013-09-17</created><authors><author><keyname>Gutierrez</keyname><forenames>Thoralf</forenames></author><author><keyname>Krings</keyname><forenames>Gautier</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author></authors><title>Evaluating socio-economic state of a country analyzing airtime credit
  and mobile phone datasets</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable statistical information is important to make political decisions on
a sound basis and to help measure the impact of policies. Unfortunately,
statistics offices in developing countries have scarce resources and
statistical censuses are therefore conducted sporadically. Based on mobile
phone communications and history of airtime credit purchases, we estimate the
relative income of individuals, the diversity and inequality of income, and an
indicator for socioeconomic segregation for fine-grained regions of an African
country. Our study shows how to use mobile phone datasets as a starting point
to understand the socio-economic state of a country, which can be especially
useful in countries with few resources to conduct large surveys.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4499</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4499</id><created>2013-09-17</created><authors><author><keyname>Razaque</keyname><forenames>Abdul</forenames></author><author><keyname>Elleithy</keyname><forenames>Khald. M.</forenames></author></authors><title>Restoring the privacy and confidentiality of users over Mobile
  collaborative learning (MCL) environment</title><categories>cs.CR cs.CY</categories><comments>13 pages, 13 figuers. arXiv admin note: substantial text overlap with
  arXiv:1208.2073, arXiv:1210.2030</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile collaborative learning (MCL) is extensively recognized field all over
the world. It demonstrates the cerebral approach combining the several
technology to handle the problem of learning. MCL motivates the social and
educational activities for creating healthier environment. To advance and
promote the baseline of MCL, different frameworks have been introduced for MCL.
From other side, there is no highly acceptable security mechanism has been
implemented to protect MCL environment. This paper introduces the issue of
rogue DHCP server, which highly affects the performance of users who
communicate with each other through MCL. The rogue DHCP is unofficial server
that gives incorrect IP address to user in order to use the legal sources of
different servers by sniffing the traffic. The contribution focuses to maintain
the privacy of users and enhances the confidentiality. The paper introduces
multi-frame signature-cum anomaly-based intrusion detection systems (MSAIDS)
supported with innovative algorithms, modification in the existing rules of IDS
and use of mathematical model. The major objectives of research are to identify
the malicious attacks created by rogue DHCP server. This innovative mechanism
emphasizes the security for users in order to communicate freely. It also
protects network from illegitimate involvement of intruders. Finally, the paper
validates the mechanism using three types of simulations: testbed, discrete
simulation in C++ and ns2. On the basis of findings, the efficiency of proposed
mechanism has been compared with other well-known techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4501</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4501</id><created>2013-09-17</created><authors><author><keyname>Ganesalingam</keyname><forenames>M.</forenames></author><author><keyname>Gowers</keyname><forenames>W. T.</forenames></author></authors><title>A fully automatic problem solver with human-style output</title><categories>cs.AI</categories><comments>41 pages</comments><acm-class>I.2.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper describes a program that solves elementary mathematical problems,
mostly in metric space theory, and presents solutions that are hard to
distinguish from solutions that might be written by human mathematicians. The
program is part of a more general project, which we also discuss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4504</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4504</id><created>2013-09-17</created><authors><author><keyname>Razaque</keyname><forenames>Abdul</forenames></author><author><keyname>Elleithy</keyname><forenames>Khaled</forenames></author></authors><title>Automatic energy saving (AES) modelto boost ubiquitous wireless sensor
  networks (WSNs)</title><categories>cs.NI</categories><comments>11 pages, 7 figures, International Journal of computers and
  technology 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deploy BT node (sensor) that offers passive and active sensing capability
to save energy. BT node works in passive mode for outdoor communication and
active for indoor communication. The BT node is supported with novel automatic
energy saving (AES) mathematical model to decide either modes. It provides
robust and faster communication with less energy consumption. To validate this
approach, network simulator-2 (ns2) simulation is used to simulate the behavior
of network with the supporting mathematical model. The main objective of this
research is to remotely access different types of servers, laptops, desktops
and other static and moving objects. This prototype is initially deployed to
control MSCS [13] &amp; [14] from remote place through mobile devices. The
prototype can further be enhanced to handle several objects simultaneously
consuming less energy and resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4507</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4507</id><created>2013-09-17</created><authors><author><keyname>Popov</keyname><forenames>Vlad</forenames></author><author><keyname>Mazonka</keyname><forenames>Oleg</forenames></author></authors><title>Faster Fair Solution for the Reader-Writer Problem</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fast fair solution for Reader-Writer Problem is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4508</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4508</id><created>2013-09-17</created><authors><author><keyname>Salama</keyname><forenames>Nyembo</forenames></author><author><keyname>Bach</keyname><forenames>Christian</forenames></author></authors><title>Introduction of 6th Generation Smart Phone combining the features of
  both Apple and Android smart phone</title><categories>cs.HC</categories><comments>10 pages, i figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present our novel contribution methodology based on the
results of case study that has been implemented in our research environment to
test with new technique the usability of both intelligent Android and Apple
phones. This analysis of the case study stands for features similar to
applications, operating system, hardware and software structure, battery life,
and online based websites. Multiple interrogations were applied to collect user
answers ongoing features. Users directly react by responding based on their
daily used product experience. Consequently, the estimation is based on the
data that has been unregistered from the user. The most recent results will end
up by introducing a combination of ideal features on both products to build a
wonderful extended product in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4511</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4511</id><created>2013-09-17</created><authors><author><keyname>Khan</keyname><forenames>Muhammad Shoaib</forenames></author><author><keyname>Elleithy</keyname><forenames>Khaled</forenames></author></authors><title>Robust Heterogeneous Network to Support Multitasking</title><categories>cs.NI</categories><comments>10 pages, 06 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to emerging technology, efficient multitasking approach is highly
demanded. But it is hard to accomplish in heterogeneous wireless networks,
where diverse networks have dissimilar geometric features in service and
traffic models. Multitasking loss examination based on Markov chain becomes
inflexible in these networks owing to rigorous computations is obligatory. This
paper emphases on the performance of heterogeneous wireless networks based on
multitasking. A method based on multitasking of the interrelated traffic is
used to attain an approximate performance in heterogeneous wireless networks
with congested traffic. The accuracy of the robust heterogeneous network with
multitasking is verified by using ns2 simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4513</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4513</id><created>2013-09-17</created><authors><author><keyname>Kailkhura</keyname><forenames>Bhavya</forenames></author><author><keyname>Brahma</keyname><forenames>Swastik</forenames></author><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Distributed Detection in Tree Topologies with Byzantines</title><categories>stat.AP cs.CR math.CO</categories><doi>10.1109/TSP.2014.2321735</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of distributed detection in tree
topologies in the presence of Byzantines. The expression for minimum attacking
power required by the Byzantines to blind the fusion center (FC) is obtained.
More specifically, we show that when more than a certain fraction of individual
node decisions are falsified, the decision fusion scheme becomes completely
incapable. We obtain closed form expressions for the optimal attacking
strategies that minimize the detection error exponent at the FC. We also look
at the possible counter-measures from the FC's perspective to protect the
network from these Byzantines. We formulate the robust topology design problem
as a bi-level program and provide an efficient algorithm to solve it. We also
provide some numerical results to gain insights into the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4514</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4514</id><created>2013-09-17</created><authors><author><keyname>Habeeb</keyname><forenames>Maggie</forenames></author><author><keyname>Kahrobaei</keyname><forenames>Delaram</forenames></author></authors><title>On the Dimension of Matrix Representations of Finitely Generated Torsion
  Free Nilpotent Groups</title><categories>math.GR cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that any polycyclic group, and hence any finitely generated
nilpotent group, can be embedded into $GL_{n}(\mathbb{Z})$ for an appropriate
$n\in \mathbb{N}$; that is, each element in the group has a unique matrix
representation. An algorithm to determine this embedding was presented in
Nickel. In this paper, we determine the complexity of the crux of the algorithm
and the dimension of the matrices produced as well as provide a modification of
the algorithm presented by Nickel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4519</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4519</id><created>2013-09-17</created><authors><author><keyname>Anshel</keyname><forenames>Michael</forenames></author><author><keyname>Kahrobaei</keyname><forenames>Delaram</forenames></author></authors><title>Decision and Search in Non-abelian Cramer Shoup Public Key Cryptosystem</title><categories>math.GR cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for non-abelian Cramer-Shoup cryptosystem is presented. The role of
decision and search is explored, and the platform of solvable/polycyclic group
is suggested. In the process we review recent progress in non-abelian
cryptography and post some open problems that naturally arise from this path of
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4531</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4531</id><created>2013-09-17</created><authors><author><keyname>Shen</keyname><forenames>Yuan</forenames></author><author><keyname>Dai</keyname><forenames>Wenhan</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author></authors><title>Power Optimization for Network Localization</title><categories>cs.IT math.IT</categories><comments>15 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable and accurate localization of mobile objects is essential for many
applications in wireless networks. In range-based localization, the position of
the object can be inferred using the distance measurements from wireless
signals exchanged with active objects or reflected by passive ones. Power
allocation for ranging signals is important since it affects not only network
lifetime and throughput but also localization accuracy. In this paper, we
establish a unifying optimization framework for power allocation in both active
and passive localization networks. In particular, we first determine the
functional properties of the localization accuracy metric, which enable us to
transform the power allocation problems into second-order cone programs
(SOCPs). We then propose the robust counterparts of the problems in the
presence of parameter uncertainty and develop asymptotically optimal and
efficient near-optimal SOCP-based algorithms. Our simulation results validate
the efficiency and robustness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4545</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4545</id><created>2013-09-18</created><authors><author><keyname>Wu</keyname><forenames>Yuanxin</forenames></author></authors><title>Further results on &quot;Velocity-position integration formula, part
  I-Application to in-flight alignment&quot;</title><categories>cs.RO</categories><comments>IEEE-TAES, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note improves our above-mentioned recent work by effectively depressing
the adverse effect of the lever arm on attitude estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4550</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4550</id><created>2013-09-18</created><authors><author><keyname>Sandretto</keyname><forenames>Julien Alexandre Dit</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Nicolas</keyname><forenames>Cyprien</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Cable-Driven Robots with Wireless Control Capability for Pedagogical
  Illustration in Science</title><categories>cs.RO</categories><comments>CAR - 8th National Conference on &quot;Control Architecure of Robots&quot;
  (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Science teaching in secondary schools is often abstract for students. Even if
some experiments can be conducted in classrooms, mainly for chemistry or some
physics fields, mathematics is not an experimental science. Teachers have to
convince students that theorems have practical implications. We present
teachers an original and easy-to-use pedagogical tool: a cable-driven robot
with a Web-based remote control interface. The robot implements several
scientific concepts such as 3D-geometry and kinematics. The remote control
enables the teacher to move freely in the classroom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4557</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4557</id><created>2013-09-18</created><authors><author><keyname>Banerjee</keyname><forenames>Anindya</forenames><affiliation>IMDEA Software Institute</affiliation></author><author><keyname>Danvy</keyname><forenames>Olivier</forenames><affiliation>Aarhus University</affiliation></author><author><keyname>Doh</keyname><forenames>Kyung-Goo</forenames><affiliation>Hanyang University</affiliation></author><author><keyname>Hatcliff</keyname><forenames>John</forenames><affiliation>Kansas State University</affiliation></author></authors><title>Semantics, Abstract Interpretation, and Reasoning about Programs: Essays
  Dedicated to David A. Schmidt on the Occasion of his Sixtieth Birthday</title><categories>cs.PL cs.LO cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013</journal-ref><doi>10.4204/EPTCS.129</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Liber Amicorum is a collection of essays ranging from personal memories
to technical contributions. It is a tribute to Dave Schmidt and his career, and
was composed at the occasion of his sixtieth birthday.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4573</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4573</id><created>2013-09-18</created><authors><author><keyname>Bagchi</keyname><forenames>Parama</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>A novel approach for nose tip detection using smoothing by weighted
  median filtering applied to 3D face images in variant poses</title><categories>cs.CV</categories><comments>6 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper is based on an application of smoothing of 3D face images followed
by feature detection i.e. detecting the nose tip. The present method uses a
weighted mesh median filtering technique for smoothing. In this present
smoothing technique we have built the neighborhood surrounding a particular
point in 3D face and replaced that with the weighted value of the surrounding
points in 3D face image. After applying the smoothing technique to the 3D face
images our experimental results show that we have obtained considerable
improvement as compared to the algorithm without smoothing. We have used here
the maximum intensity algorithm for detecting the nose-tip and this method
correctly detects the nose-tip in case of any pose i.e. along X, Y, and Z axes.
The present technique gave us worked successfully on 535 out of 542 3D face
images as compared to the method without smoothing which worked only on 521 3D
face images out of 542 face images. Thus we have obtained a 98.70% performance
rate over 96.12% performance rate of the algorithm without smoothing. All the
experiments have been performed on the FRAV3D database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4576</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4576</id><created>2013-09-18</created><authors><author><keyname>Mirshahvalad</keyname><forenames>Atieh</forenames></author><author><keyname>Viamontes</keyname><forenames>Alcides</forenames></author><author><keyname>Lizana</keyname><forenames>Ludvig</forenames></author><author><keyname>Rosvall</keyname><forenames>Martin</forenames></author></authors><title>Dynamics of interacting information waves in networks</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Phys. Rev. E 89, 012809 (2014)</journal-ref><doi>10.1103/PhysRevE.89.012809</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To better understand the inner workings of information spreading, network
researchers often use simple models to capture the spreading dynamics. But most
models only highlight the effect of local interactions on the global spreading
of a single information wave, and ignore the effects of interactions between
multiple waves. Here we take into account the effect of multiple interacting
waves by using an agent-based model in which the interaction between
information waves is based on their novelty. We analyzed the global effects of
such interactions and found that information that actually reaches nodes
reaches them faster. This effect is caused by selection between information
waves: slow waves die out and only fast waves survive. As a result, and in
contrast to models with non-interacting information dynamics, the access to
information decays with the distance from the source. Moreover, when we
analyzed the model on various synthetic and real spatial road networks, we
found that the decay rate also depends on the path redundancy and the effective
dimension of the system. In general, the decay of the information wave
frequency as a function of distance from the source follows a power law
distribution with an exponent between -0.2 for a two-dimensional system with
high path redundancy and -0.5 for a tree-like system with no path redundancy.
We found that the real spatial networks provide an infrastructure for
information spreading that lies in between these two extremes. Finally, to
better understand the mechanics behind the scaling results, we provide analytic
calculations of the scaling for a one-dimensional system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4577</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4577</id><created>2013-09-18</created><authors><author><keyname>Bagchi</keyname><forenames>Parama</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>Detection of pose orientation across single and multiple axes in case of
  3D face images</title><categories>cs.CV</categories><comments>12 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we propose a new approach that takes as input a 3D face image
across X, Y and Z axes as well as both Y and X axes and gives output as its
pose i.e. it tells whether the face is oriented with respect the X, Y or Z axes
or is it oriented across multiple axes with angles of rotation up to 42 degree.
All the experiments have been performed on the FRAV3D, GAVADB and Bosphorus
database which has two figures of each individual across multiple axes. After
applying the proposed algorithm to the 3D facial surface from FRAV3D on 848 3D
faces, 566 3D faces were correctly recognized for pose thus giving 67% of
correct identification rate. We had experimented on 420 images from the GAVADB
database, and only 336 images were detected for correct pose identification
rate i.e. 80% and from Bosphorus database on 560 images only 448 images were
detected for correct pose identification i.e. 80%.abstract goes here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4582</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4582</id><created>2013-09-18</created><authors><author><keyname>Bagchi</keyname><forenames>Parama</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>A novel approach to nose-tip and eye corners detection using H-K
  Curvature Analysis in case of 3D images</title><categories>cs.CV</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we present a novel method that combines a HK curvature-based
approach for three-dimensional (3D) face detection in different poses (X-axis,
Y-axis and Z-axis). Salient face features, such as the eyes and nose, are
detected through an analysis of the curvature of the entire facial surface. All
the experiments have been performed on the FRAV3D Database. After applying the
proposed algorithm to the 3D facial surface we have obtained considerably good
results i.e. on 752 3D face images our method detected the eye corners for 543
face images, thus giving a 72.20% of eye corners detection and 743 face images
for nose-tip detection thus giving a 98.80% of good nose tip localization
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4602</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4602</id><created>2013-09-18</created><authors><author><keyname>Bhattacharya</keyname><forenames>Sayan</forenames></author><author><keyname>Chalermsook</keyname><forenames>Parinya</forenames></author><author><keyname>Mehlhorn</keyname><forenames>Kurt</forenames></author><author><keyname>Neumann</keyname><forenames>Adrian</forenames></author></authors><title>New Approximability Results for the Robust k-Median Problem</title><categories>cs.DS</categories><comments>19 pages</comments><acm-class>F.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider a robust variant of the classical $k$-median problem, introduced
by Anthony et al. \cite{AnthonyGGN10}. In the \emph{Robust $k$-Median problem},
we are given an $n$-vertex metric space $(V,d)$ and $m$ client sets $\set{S_i
\subseteq V}_{i=1}^m$. The objective is to open a set $F \subseteq V$ of $k$
facilities such that the worst case connection cost over all client sets is
minimized; in other words, minimize $\max_{i} \sum_{v \in S_i} d(F,v)$. Anthony
et al.\ showed an $O(\log m)$ approximation algorithm for any metric and
APX-hardness even in the case of uniform metric. In this paper, we show that
their algorithm is nearly tight by providing $\Omega(\log m/ \log \log m)$
approximation hardness, unless ${\sf NP} \subseteq \bigcap_{\delta &gt;0} {\sf
DTIME}(2^{n^{\delta}})$. This hardness result holds even for uniform and line
metrics. To our knowledge, this is one of the rare cases in which a problem on
a line metric is hard to approximate to within logarithmic factor. We
complement the hardness result by an experimental evaluation of different
heuristics that shows that very simple heuristics achieve good approximations
for realistic classes of instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4616</identifier>
 <datestamp>2014-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4616</id><created>2013-09-18</created><authors><author><keyname>Einkemmer</keyname><forenames>Lukas</forenames></author><author><keyname>Ostermann</keyname><forenames>Alexander</forenames></author></authors><title>Exponential Integrators on Graphic Processing Units</title><categories>cs.NA</categories><comments>To appear in: Proceedings of the 2013 International Conference on
  High Performance Computing Simulation (HPCS 2013), IEEE (2013)</comments><journal-ref>High Performance Computing and Simulation (HPCS), 2013
  International Conference on, pp. 490-496</journal-ref><doi>10.1109/HPCSim.2013.6641458</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we revisit stencil methods on GPUs in the context of
exponential integrators. We further discuss boundary conditions, in the same
context, and show that simple boundary conditions (for example, homogeneous
Dirichlet or homogeneous Neumann boundary conditions) do not affect the
performance if implemented directly into the CUDA kernel. In addition, we show
that stencil methods with position-dependent coefficients can be implemented
efficiently as well.
  As an application, we discuss the implementation of exponential integrators
for different classes of problems in a single and multi GPU setup (up to 4
GPUs). We further show that for stencil based methods such parallelization can
be done very efficiently, while for some unstructured matrices the
parallelization to multiple GPUs is severely limited by the throughput of the
PCIe bus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4628</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4628</id><created>2013-09-18</created><authors><author><keyname>Chrupa&#x142;a</keyname><forenames>Grzegorz</forenames></author></authors><title>Text segmentation with character-level text embeddings</title><categories>cs.CL</categories><comments>Workshop on Deep Learning for Audio, Speech and Language Processing,
  ICML 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning word representations has recently seen much success in computational
linguistics. However, assuming sequences of word tokens as input to linguistic
analysis is often unjustified. For many languages word segmentation is a
non-trivial task and naturally occurring text is sometimes a mixture of natural
language strings and other character data. We propose to learn text
representations directly from raw character sequences by training a Simple
recurrent Network to predict the next character in text. The network uses its
hidden layer to evolve abstract representations of the character sequences it
sees. To demonstrate the usefulness of the learned text embeddings, we use them
as features in a supervised character level text segmentation and labeling
task: recognizing spans of text containing programming language code. By using
the embeddings as features we are able to substantially improve over a baseline
which uses only surface character n-grams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4638</identifier>
 <datestamp>2015-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4638</id><created>2013-09-18</created><updated>2015-09-05</updated><authors><author><keyname>Vituri</keyname><forenames>Shlomi</forenames></author></authors><title>Dispersion Analysis of Infinite Constellations in Ergodic Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>Master's thesis, Tel Aviv Univ (2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis considers infinite constellations in fading channels, without
power constraint and with perfect channel state information available at the
receiver. Infinite constellations are the framework, proposed by Poltyrev, for
analyzing coded modulation codes. The Poltyrev's capacity, is the highest
achievable normalized log density (NLD) of codewords per unit volume, at
possibly large block length, that guarantees a vanishing error probability. For
a given finite block length and a fixed error probability, there is a gap
between the highest achievable NLD and Poltyrev's capacity. The dispersion
analysis quantifies asymptotically this gap.
  The thesis begins by the dispersion analysis of infinite constellations in
scalar fading channels. Later on, we extend the analysis to the case of
multiple input multiple output fading channels. As in other channels, we show
that the gap between the highest achievable NLD and the Poltyrev's capacity,
vanishes asymptotically as the square root of the channel dispersion over the
block length, multiplied by the inverse Q-function of the allowed error
probability.
  Moreover, exact terms for Poltyrev's capacity and channel dispersion, are
derived in the thesis. The relations to the amplitude and to the power
constrained fading channels are also discussed, especially in terms of
capacity, channel dispersion and error exponents. These relations hint that in
typical cases the unconstrained model can be interpreted as the limit of the
constrained model, when the signal to noise ratio tends to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4645</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4645</id><created>2013-09-18</created><authors><author><keyname>Abrahamsson</keyname><forenames>Pekka</forenames></author></authors><title>Measuring the Success of Software Process Improvement: The Dimensions</title><categories>cs.SE</categories><comments>Paper published in the EuroSPI 2000 conference, Copenhagen, Denmark:
  http://www.iscn.com/select_newspaper/measurement/oulu.html. Peer-reviewed,
  final version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality managers, change agents and researchers are often troubled in
defining and demonstrating the level of success achieved in software process
improvement (SPI) initiatives. So far, there exist only few frameworks for
identifying the level of success achieved in SPI. Analysis shows that these
frameworks do not provide a comprehensive view from all relevant stakeholders
involved in SPI. Early results from an ongoing research effort to discover and
operationalise success dimensions are reported. Adapted from the project
management literature it is suggested that five dimensions characterise the
level of success achieved in SPI: (1) project efficiency, (2) impact on the
process user, (3) business success, (4) direct operational success and (5)
process improvement fit. Results from an empirical analysis are reported where
23 change agents evaluated the relative level of importance of each dimension.
Early results indicate that change agents valued the process user satisfaction
the most and the process improvement fit the least. This finding confirms the
need of having various stakeholders and dimensions acknowledged in a framework
that is used to measure the overall success of an SPI initiative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4651</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4651</id><created>2013-09-18</created><authors><author><keyname>Mahdaviani</keyname><forenames>Kaveh</forenames></author><author><keyname>Yazdani</keyname><forenames>Raman</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author></authors><title>Overhead-Optimized Gamma Network Codes</title><categories>cs.IT math.IT</categories><comments>This paper was accepted as a short paper and presented as a poster in
  the 2013 IEEE International Symposium on Network Coding (NetCod'13), Calgary,
  Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a network coding scheme with minimum reception overhead and linear
encoding/decoding complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4662</identifier>
 <datestamp>2015-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4662</id><created>2013-09-18</created><updated>2014-06-01</updated><authors><author><keyname>Ellis-Monaghan</keyname><forenames>Joanna A.</forenames></author><author><keyname>McDowell</keyname><forenames>Andrew</forenames></author><author><keyname>Moffatt</keyname><forenames>Iain</forenames></author><author><keyname>Pangborn</keyname><forenames>Greta</forenames></author></authors><title>DNA origami and the complexity of Eulerian circuits with turning costs</title><categories>math.CO cs.CE cs.DS q-bio.BM</categories><msc-class>92E10, 05C45, 05C85</msc-class><doi>10.1007/s11047-014-9457-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building a structure using self-assembly of DNA molecules by origami folding
requires finding a route for the scaffolding strand through the desired
structure. When the target structure is a 1-complex (or the geometric
realization of a graph), an optimal route corresponds to an Eulerian circuit
through the graph with minimum turning cost. By showing that it leads to a
solution to the 3-SAT problem, we prove that the general problem of finding an
optimal route for a scaffolding strand for such structures is NP-hard. We then
show that the problem may readily be transformed into a Traveling Salesman
Problem (TSP), so that machinery that has been developed for the TSP may be
applied to find optimal routes for the scaffolding strand in a DNA origami
self-assembly process. We give results for a few special cases, showing for
example that the problem remains intractable for graphs with maximum degree 8,
but is polynomial time for 4-regular plane graphs if the circuit is restricted
to following faces. We conclude with some implications of these results for
related problems, such as biomolecular computing and mill routing problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4690</identifier>
 <datestamp>2014-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4690</id><created>2013-09-18</created><updated>2014-05-02</updated><authors><author><keyname>Mishra</keyname><forenames>Dheerendra</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Sourav</forenames></author></authors><title>Security Enhancement of Biometric Authentication Scheme for Telecare
  Medicine Information Systems with Nonce</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author due to a sign of error in
  security analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Telecare medicine information systems (TMIS) present the platform to deliver
clinical service door to door. The technological advances in mobile computing
are enhancing the quality of healthcare and a user can access these services
using its mobile device. Existing authentication schemes for TMIS are either
vulnerable to attacks or they have higher computational cost. We propose a
biometric based efficient authentication scheme for TMIS which only requires
the computation of the hash and XOR functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4693</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4693</id><created>2013-09-18</created><updated>2013-09-24</updated><authors><author><keyname>Cerone</keyname><forenames>Andrea</forenames><affiliation>Trinity College Dublin</affiliation></author><author><keyname>Hennessy</keyname><forenames>Matthew</forenames><affiliation>Trinity College Dublin</affiliation></author></authors><title>Modelling Probabilistic Wireless Networks</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (September
  25, 2013) lmcs:949</journal-ref><doi>10.2168/LMCS-9(3:26)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a process calculus to model high level wireless systems, where the
topology of a network is described by a digraph. The calculus enjoys features
which are proper of wireless networks, namely broadcast communication and
probabilistic behaviour. We first focus on the problem of composing wireless
networks, then we present a compositional theory based on a probabilistic
generalisation of the well known may-testing and must-testing pre- orders.
Also, we define an extensional semantics for our calculus, which will be used
to define both simulation and deadlock simulation preorders for wireless
networks. We prove that our simulation preorder is sound with respect to the
may-testing preorder; similarly, the deadlock simulation pre- order is sound
with respect to the must-testing preorder, for a large class of networks. We
also provide a counterexample showing that completeness of the simulation
preorder, with respect to the may testing one, does not hold. We conclude the
paper with an application of our theory to probabilistic routing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4713</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4713</id><created>2013-09-18</created><authors><author><keyname>Angelini</keyname><forenames>Patrizio</forenames></author><author><keyname>Evans</keyname><forenames>William</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author></authors><title>SEFE with No Mapping via Large Induced Outerplane Graphs in Plane Graphs</title><categories>cs.DS cs.DM math.CO</categories><comments>21 pages, 10 figures, 14 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every $n$-vertex planar graph admits a simultaneous embedding
with no mapping and with fixed edges with any $(n/2)$-vertex planar graph. In
order to achieve this result, we prove that every $n$-vertex plane graph has an
induced outerplane subgraph containing at least $n/2$ vertices. Also, we show
that every $n$-vertex planar graph and every $n$-vertex planar partial 3-tree
admit a simultaneous embedding with no mapping and with fixed edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4714</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4714</id><created>2013-09-18</created><authors><author><keyname>Edwards</keyname><forenames>Ann L.</forenames></author><author><keyname>Kearney</keyname><forenames>Alexandra</forenames></author><author><keyname>Dawson</keyname><forenames>Michael Rory</forenames></author><author><keyname>Sutton</keyname><forenames>Richard S.</forenames></author><author><keyname>Pilarski</keyname><forenames>Patrick M.</forenames></author></authors><title>Temporal-Difference Learning to Assist Human Decision Making during the
  Control of an Artificial Limb</title><categories>cs.AI cs.LG cs.RO</categories><comments>5 pages, 4 figures, This version to appear at The 1st
  Multidisciplinary Conference on Reinforcement Learning and Decision Making,
  Princeton, NJ, USA, Oct. 25-27, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we explore the use of reinforcement learning (RL) to help with
human decision making, combining state-of-the-art RL algorithms with an
application to prosthetics. Managing human-machine interaction is a problem of
considerable scope, and the simplification of human-robot interfaces is
especially important in the domains of biomedical technology and rehabilitation
medicine. For example, amputees who control artificial limbs are often required
to quickly switch between a number of control actions or modes of operation in
order to operate their devices. We suggest that by learning to anticipate
(predict) a user's behaviour, artificial limbs could take on an active role in
a human's control decisions so as to reduce the burden on their users.
Recently, we showed that RL in the form of general value functions (GVFs) could
be used to accurately detect a user's control intent prior to their explicit
control choices. In the present work, we explore the use of temporal-difference
learning and GVFs to predict when users will switch their control influence
between the different motor functions of a robot arm. Experiments were
performed using a multi-function robot arm that was controlled by muscle
signals from a user's body (similar to conventional artificial limb control).
Our approach was able to acquire and maintain forecasts about a user's
switching decisions in real time. It also provides an intuitive and reward-free
way for users to correct or reinforce the decisions made by the machine
learning system. We expect that when a system is certain enough about its
predictions, it can begin to take over switching decisions from the user to
streamline control and potentially decrease the time and effort needed to
complete tasks. This preliminary study therefore suggests a way to naturally
integrate human- and machine-based decision making systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4718</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4718</id><created>2013-09-18</created><updated>2014-04-22</updated><authors><author><keyname>Bonnet</keyname><forenames>Edouard</forenames></author><author><keyname>Paschos</keyname><forenames>Vangelis Th.</forenames></author><author><keyname>Sikora</keyname><forenames>Florian</forenames></author></authors><title>Multiparameterizations for max $k$-set cover and related satisfiability
  problems</title><categories>cs.CC</categories><comments>18 pages</comments><msc-class>68Q17</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of several parameterizations for \textsc{max $k$-set
cover}. Given a family of subsets $\mathcal S=\{S_1,\ldots,S_m\}$ over a set of
elements $X=\{x_1,\ldots,x_n\}$ and an integer $p$, \pSC{} consists of finding
a set $\mathcal T$ of at most $k$ subsets covering at least $p$ elements. This
problem, when parameterized by $k$, is W[2]-hard. Here, we settle the
multiparameterized complexity of \pSC{} under pairs of parameters as
$(k,\Delta)$ and $(k,f)$, where $\Delta=\max_i\{|S_i|\}$ and $f =\max_i|\{j |
x_i \in S_j\}|$. We also study parameterized approximability of the problem
with respect to parameters $k$ and $p$. Then, we investigate some similar
parameterizations of a satisfiability problem \textsc{max sat-$k$} which is
close to \textsc{max $k$-set cover}. Finally, we sketch an enhancement of the
classes of the W[$\cdot$] hierarchy that seems more appropriate for showing
completeness of cardinality constrained W[$\cdot$]-hard problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4720</identifier>
 <datestamp>2014-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4720</id><created>2013-09-18</created><authors><author><keyname>Platig</keyname><forenames>John</forenames></author><author><keyname>Ott</keyname><forenames>Ed</forenames></author><author><keyname>Girvan</keyname><forenames>Michelle</forenames></author></authors><title>Robustness of Network Measures to Link Errors</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.MN</categories><comments>9 pages, 9 figures</comments><journal-ref>Phys. Rev. E 88, 062812 (2013)</journal-ref><doi>10.1103/PhysRevE.88.062812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In various applications involving complex networks, network measures are
employed to assess the relative importance of network nodes. However, the
robustness of such measures in the presence of link inaccuracies has not been
well characterized. Here we present two simple stochastic models of false and
missing links and study the effect of link errors on three commonly used node
centrality measures: degree centrality, betweenness centrality, and dynamical
importance. We perform numerical simulations to assess robustness of these
three centrality measures. We also develop an analytical theory, which we
compare with our simulations, obtaining very good agreement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4741</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4741</id><created>2013-09-18</created><authors><author><keyname>Horan</keyname><forenames>Victoria</forenames></author></authors><title>Overlap Cycles for Permutations: Necessary and Sufficient Conditions</title><categories>math.CO cs.DM</categories><comments>12 pages, 2 figures</comments><msc-class>05A05 (primary) 68R15 (secondary)</msc-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Universal cycles are generalizations of de Bruijn cycles and Gray codes that
were introduced originally by Chung, Diaconis, and Graham in 1992. They have
been developed by many authors since, for various combinatorial objects such as
strings, subsets, permutations, partitions, vector spaces, and designs. One
generalization of universal cycles, which require almost complete overlap of
consecutive words, is $s$-overlap cycles, which relax such a constraint. In
this paper we study permutations and some closely related class of strings,
namely juggling sequences and functions. We prove the existence of $s$-overlap
cycles for these objects, as they do not always lend themselves to the
universal cycle structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4744</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4744</id><created>2013-09-18</created><authors><author><keyname>Mithani</keyname><forenames>Murad A.</forenames></author><author><keyname>Veloz</keyname><forenames>Tomas</forenames></author><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>Modeling the Role of Context Dependency in the Recognition and
  Manifestation of Entrepreneurial Opportunity</title><categories>q-bio.NC cs.AI</categories><comments>8 pages In: P. Bruza, W. Lawless, K. van Rijsbergen, D. Sofge, &amp; D.
  Widdows (Eds.) Proc Assoc Advance Artif Intel Fall Symposium: Quantum
  Informatics for Cognitive, Social, and Semantic Processes. AAAI Press, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper uses the SCOP theory of concepts to model the role of environmental
context on three levels of entrepreneurial opportunity: idea generation, idea
development, and entrepreneurial decision. The role of contextual-fit in the
generation and development of ideas is modeled as the collapse of their
superposition state into one of the potential states that composes this
superposition. The projection of this collapsed state on the socio-economic
basis results in interference of the developed idea with the perceptions of the
supporting community, undergoing an eventual collapse for an entrepreneurial
decision that reflects the shared vision of its stakeholders. The developed
idea may continue to evolve due to continuous or discontinuous changes in the
environment. The model offers unique insights into the effects of external
influences on entrepreneurial decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4747</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4747</id><created>2013-09-18</created><updated>2013-10-26</updated><authors><author><keyname>R&#xf3;th</keyname><forenames>&#xc1;goston</forenames></author><author><keyname>Juh&#xe1;sz</keyname><forenames>Imre</forenames></author><author><keyname>Krist&#xe1;ly</keyname><forenames>Alexandru</forenames></author></authors><title>A constructive approach to triangular trigonometric patches</title><categories>math.NA cs.GR</categories><comments>32 pages, 12 figures</comments><msc-class>65D17, 68U07, 42A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a constrained trivariate extension of the univariate normalized
B-basis of the vector space of trigonometric polynomials of arbitrary (finite)
order n defined on any compact interval [0,\alpha], where \alpha is a fixed
(shape) parameter in (0,\pi). Our triangular extension is a normalized linearly
independent constrained trivariate trigonometric function system of dimension
3n(n+1)+1 that spans the same vector space of functions as the constrained
trivariate extension of the canonical basis of truncated Fourier series of
order n over [0,\alpha]. Although the explicit general basis transformation is
yet unknown, the coincidence of these vector spaces is proved by means of an
appropriate equivalence relation. As a possible application of our triangular
extension, we introduce the notion of (rational) triangular trigonometric
patches of order n and of singularity free parametrization that could be used
as control point based modeling tools in CAGD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4767</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4767</id><created>2013-09-18</created><updated>2013-09-23</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>Log-space counter is useful for unary languages by help of a
  constant-size quantum register</title><categories>cs.CC cs.FL quant-ph</categories><comments>The text is updated by adding a new reference. Technical report. 10
  pages. arXiv admin note: text overlap with arXiv:1207.3880</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum amount of resources to recognize a nonregular language is a
fundamental research topic in theoretical computer science which has been
examined for different kinds of resources and many different models. In this
note, we focus on unary languages and space complexity on counters. Our model
is two-way one-counter automaton with quantum and classical states (2QCCA),
which is a two-way finite automaton with one-counter (2DCA) augmented with a
fixed size quantum register or a two-way finite automaton with quantum and
classical states (2QCFA) augmented with a classical counter. It is known that
any 2DCA using a sublinear space on its counter can recognize only regular
languages \cite{DG82B}. In this note, we show that bounded-error 2QCCAs can
recognize a non-regular unary language by using logarithmic space on its
counters for the members. Note that it is still an open problem whether
bounded-error 2QCFA can recognize a non-regular unary language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4796</identifier>
 <datestamp>2014-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4796</id><created>2013-09-18</created><updated>2014-12-17</updated><authors><author><keyname>Peng</keyname><forenames>Lijun</forenames></author><author><keyname>Carvalho</keyname><forenames>Luis</forenames></author></authors><title>Bayesian Degree-Corrected Stochastic Blockmodels for Community Detection</title><categories>stat.ME cs.SI physics.soc-ph</categories><comments>23 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection in networks has drawn much attention in diverse fields,
especially social sciences. Given its significance, there has been a large body
of literature with approaches from many fields. Here we present a statistical
framework that is representative, extensible, and that yields an estimator with
good properties. Our proposed approach considers a stochastic blockmodel based
on a logistic regression formulation with node correction terms. We follow a
Bayesian approach that explicitly captures the community behavior via prior
specification. We further adopt a data augmentation strategy with latent
Polya-Gamma variables to obtain posterior samples. We conduct inference based
on a principled, canonically mapped centroid estimator that formally addresses
label non-identifiability and captures representative community assignments. We
demonstrate the proposed model and estimation on real-world as well as
simulated benchmark networks and show that the proposed model and estimator are
more flexible, representative, and yield smaller error rates when compared to
the MAP estimator from classical degree-corrected stochastic blockmodels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4810</identifier>
 <datestamp>2015-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4810</id><created>2013-09-18</created><updated>2015-02-15</updated><authors><author><keyname>Turek</keyname><forenames>Ond&#x159;ej</forenames></author></authors><title>Abelian complexity function of the Tribonacci word</title><categories>math.CO cs.FL</categories><comments>Revised version, 29 pages. Text rewritten, new results added
  (including results on the 4-bonacci word)</comments><msc-class>11B85, 68R15</msc-class><journal-ref>J. Integer Seq. 18 (2015), Article 15.3.4</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to a result of Richomme, Saari and Zamboni, the abelian complexity
of the Tribonacci word satisfies $\rho^{\mathrm{ab}}(n)\in\{3,4,5,6,7\}$ for
each $n\in\mathbb{N}$. In this paper we derive an automaton that evaluates the
function $\rho^{\mathrm{ab}}(n)$ explicitly. The automaton takes the Tribonacci
representation of $n$ as its input; therefore,
$(\rho^{\mathrm{ab}}(n))_{n\in\mathbb{N}}$ is an automatic sequence in a
generalized sense. Since our evaluation of $\rho^{\mathrm{ab}}(n)$ uses
$\mathcal{O}(\log n)$ operations, it is fast even for large values of $n$. Our
result also leads to a solution of an open problem proposed by Richomme et al.
concerning the characterization of those $n$ for which
$\rho^{\mathrm{ab}}(n)=c$ with $c$ belonging to $\{4,5,6,7\}$. In addition, we
apply the same approach on the $4$-bonacci word. In this way we find a
description of the abelian complexity of the $4$-bonacci word, too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4843</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4843</id><created>2013-09-18</created><authors><author><keyname>Suksmono</keyname><forenames>Andriyan Bayu</forenames></author></authors><title>A Simple Solution To The Uncertain Delay Problem in USRP Based SDR-Radar
  Systems</title><categories>cs.OH</categories><comments>Presented in MITA 2013, Bali, Indonesia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple solution to the uncertain delay problem in USRP
(Universal Software Radio Peripheral)-based SDR (Software-Defined Radio)-radar
systems. Instead of time-synchronization as employed in (pseudo-) passive radar
configurations, which require at least two synchronized receivers, we use
direct reception signal in a single receiver system as a reference to the exact
location of the target echoes. After finding the reference position, reordering
of the echoes is conducted by circular shift so that the reference moved to the
origin. We demonstrate the effectiveness of the proposed method by simulating
the problem on Matlab and implementing a 128 length random code radar on a
USRP. The random code is constructed from zero padded Barker sequence product.
Experiments on measuring multiple echoes of the targets at precise range bins
confirm the applicability of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4844</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4844</id><created>2013-09-18</created><authors><author><keyname>Wang</keyname><forenames>Jing</forenames></author><author><keyname>Rossell</keyname><forenames>Daniel</forenames></author><author><keyname>Cassandras</keyname><forenames>Christos G.</forenames></author><author><keyname>Paschalidis</keyname><forenames>Ioannis Ch.</forenames></author></authors><title>Network Anomaly Detection: A Survey and Comparative Analysis of
  Stochastic and Deterministic Methods</title><categories>stat.ML cs.LG cs.NI</categories><comments>7 pages. 1 more figure than final CDC 2013 version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present five methods to the problem of network anomaly detection. These
methods cover most of the common techniques in the anomaly detection field,
including Statistical Hypothesis Tests (SHT), Support Vector Machines (SVM) and
clustering analysis. We evaluate all methods in a simulated network that
consists of nominal data, three flow-level anomalies and one packet-level
attack. Through analyzing the results, we point out the advantages and
disadvantages of each method and conclude that combining the results of the
individual methods can yield improved anomaly detection results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4846</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4846</id><created>2013-09-18</created><authors><author><keyname>Zhu</keyname><forenames>Kai</forenames></author><author><keyname>Ying</keyname><forenames>Lei</forenames></author></authors><title>A Robust Information Source Estimator with Sparse Observations</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of locating the information source
with sparse observations. We assume that a piece of information spreads in a
network following a heterogeneous susceptible-infected-recovered (SIR) model
and that a small subset of infected nodes are reported, from which we need to
find the source of the information. We adopt the sample path based estimator
developed in [1], and prove that on infinite trees, the sample path based
estimator is a Jordan infection center with respect to the set of observed
infected nodes. In other words, the sample path based estimator minimizes the
maximum distance to observed infected nodes. We further prove that the distance
between the estimator and the actual source is upper bounded by a constant
independent of the number of infected nodes with a high probability on infinite
trees. Our simulations on tree networks and real world networks show that the
sample path based estimator is closer to the actual source than several other
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4860</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4860</id><created>2013-09-19</created><authors><author><keyname>Chen</keyname><forenames>Yanguang</forenames></author><author><keyname>Xu</keyname><forenames>Feng</forenames></author></authors><title>Modeling complex spatial dynamics of two-population interaction in
  urbanization process</title><categories>physics.soc-ph cs.SI</categories><comments>24 pages, 7 figures, 1 table</comments><journal-ref>Journal of Geography and Geology, 2010, 2(1): 1-17</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper is mainly devoted to lay an empirical foundation for further
research on complex spatial dynamics of two-population interaction. Based on
the US population census data, a rural and urban population interaction model
is developed. Subsequently a logistic equation on percentage urban is derived
from the urbanization model so that spatial interaction can be connected
mathematically with logistic growth. The numerical experiment by using the
discretized urban-rural population interaction model of urbanization shows a
period-doubling bifurcation and chaotic behavior, which is identical in
patterns to those from the simple mathematical models of logistic growth in
ecology. This suggests that the complicated dynamics of logistic growth may
come from some kind of the nonlinear interaction. The results from this study
help to understand urbanization, urban-rural population interaction, chaotic
dynamics, and spatial complexity of geographical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4863</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4863</id><created>2013-09-19</created><updated>2013-09-29</updated><authors><author><keyname>Tashiro</keyname><forenames>Tohru</forenames></author></authors><title>Hierarchical Bass model</title><categories>physics.soc-ph cs.SI</categories><doi>10.1088/1742-6596/490/1/012181</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new model about diffusion of a product which includes a memory
of how many adopters or advertisements a non-adopter met, where (non-)adopters
mean people (not) possessing the product. This effect is lacking in the Bass
model. As an application, we utilize the model to fit the iPod sales data, and
so the better agreement is obtained than the Bass model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4873</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4873</id><created>2013-09-19</created><authors><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Anand</keyname><forenames>Kushal</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Gunawan</keyname><forenames>Erry</forenames></author></authors><title>Sub-Stream Fairness and Numerical Correctness in MIMO Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Wireless Commun</comments><report-no>04c</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stream fairness, fairness between all streams in the system, is a more
restrictive condition than sub-stream fairness, fairness between all streams of
each user. Thus sub-stream fairness alleviates utility loss as well as
complexity and overhead compared to stream fairness. Moreover, depending on
algorithmic parameters, conventional algorithms including distributed
interference alignment (DIA) may not provide sub-stream fairness, and generate
sub-streams with poor signal-to-interference plus noise ratios (SINRs), thus
with poor bit error rates (BERs). To this end, we propose a distributed power
control algorithm to render sub-stream fairness in the system, and establish
initiatory connections between sub-stream SINRs, BERs, and rates. Algorithms
have particular responses to parameters. In the paper, important algorithmic
parameters are analyzed to exhibit numerical correctness in benchmarking. The
distinction between separate filtering schemes that design each stream of a
user separately and group filtering schemes that jointly design the streams of
a user is also underscored in the paper. Finally, the power control law used in
the proposed algorithm is proven to linearly converge to a unique fixed-point,
and the algorithm is shown to achieve feasible SINR targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4882</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4882</id><created>2013-09-19</created><authors><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth</forenames></author></authors><title>Approximation Theory and the Design of Fast Algorithms</title><categories>cs.DS math.CA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey key techniques and results from approximation theory in the context
of uniform approximations to real functions such as e^{-x}, 1/x, and x^k. We
then present a selection of results demonstrating how such approximations can
be used to speed up primitives crucial for the design of fast algorithms for
problems such as simulating random walks, graph partitioning, solving linear
system of equations, computing eigenvalues and combinatorial approaches to
solve semi-definite programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4887</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4887</id><created>2013-09-19</created><authors><author><keyname>Meyer</keyname><forenames>Nils</forenames></author><author><keyname>Ries</keyname><forenames>Manfred</forenames></author><author><keyname>Solbrig</keyname><forenames>Stefan</forenames></author><author><keyname>Wettig</keyname><forenames>Tilo</forenames></author></authors><title>iDataCool: HPC with Hot-Water Cooling and Energy Reuse</title><categories>cs.DC</categories><comments>12 pages, 7 figures, proceedings of ISC 2013</comments><journal-ref>Lecture Notes in Computer Science 7905 (2013) 383</journal-ref><doi>10.1007/978-3-642-38750-0_29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  iDataCool is an HPC architecture jointly developed by the University of
Regensburg and the IBM Research and Development Lab B\&quot;oblingen. It is based on
IBM's iDataPlex platform, whose air-cooling solution was replaced by a custom
water-cooling solution that allows for cooling water temperatures of 70C/158F.
The system is coupled to an adsorption chiller by InvenSor that operates
efficiently at these temperatures. Thus a significant portion of the energy
spent on HPC can be recovered in the form of chilled water, which can then be
used to cool other parts of the computing center. We describe the architecture
of iDataCool and present benchmarks of the cooling performance and the energy
(reuse) efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4907</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4907</id><created>2013-09-19</created><authors><author><keyname>Alamir</keyname><forenames>Mazen</forenames></author></authors><title>On Adaptive Measurement Inclusion Rate In Real-Time Moving-Horizon
  Observers</title><categories>cs.SY math.OC</categories><comments>6 pages. 4 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a self adaptation mechanism regarding the rate with
which new measurements have to be incorporated in Moving-Horizon state
estimation algorithms. This investigation can be viewed as the dual of the one
proposed by the author in the context of real-time model predictive control. An
illustrative example is provided in order to assess the relevance of the
proposed updating rule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4919</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4919</id><created>2013-09-19</created><updated>2013-09-20</updated><authors><author><keyname>Kawahara</keyname><forenames>Jun</forenames></author><author><keyname>Kobayashi</keyname><forenames>Koji M.</forenames></author><author><keyname>Miyazaki</keyname><forenames>Shuichi</forenames></author></authors><title>Better Bounds for Online $k$-Frame Throughput Maximization in Network
  Switches</title><categories>cs.DS</categories><comments>A short version will appear in the proceedings of the 24th
  International Symposium on Algorithms and Computation (ISAAC2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variant of the online buffer management problem in network
switches, called the $k$-frame throughput maximization problem ($k$-FTM). This
problem models the situation where a large frame is fragmented into $k$ packets
and transmitted through the Internet, and the receiver can reconstruct the
frame only if he/she accepts all the $k$ packets. Kesselman et al.\ introduced
this problem and showed that its competitive ratio is unbounded even when
$k=2$. They also introduced an &quot;order-respecting&quot; variant of $k$-FTM, called
$k$-OFTM, where inputs are restricted in some natural way. They proposed an
online algorithm and showed that its competitive ratio is at most
$\frac{2kB}{\lfloor B/k \rfloor} + k$ for any $B \ge k$, where $B$ is the size
of the buffer. They also gave a lower bound of $\frac{B}{\lfloor 2B/k \rfloor}$
for deterministic online algorithms when $2B \geq k$ and $k$ is a power of 2.
In this paper, we improve upper and lower bounds on the competitive ratio of
$k$-OFTM. Our main result is to improve an upper bound of $O(k^{2})$ by
Kesselman et al.\ to $\frac{5B + \lfloor B/k \rfloor - 4}{\lfloor B/2k \rfloor}
= O(k)$ for $B\geq 2k$. Note that this upper bound is tight up to a
multiplicative constant factor since the lower bound given by Kesselman et al.\
is $\Omega(k)$. We also give two lower bounds. First we give a lower bound of
$\frac{2B}{\lfloor {B/(k-1)} \rfloor} + 1$ on the competitive ratio of
deterministic online algorithms for any $k \geq 2$ and any $B \geq k-1$, which
improves the previous lower bound of $\frac{B}{\lfloor 2B/k \rfloor}$ by a
factor of almost four. Next, we present the first nontrivial lower bound on the
competitive ratio of randomized algorithms. Specifically, we give a lower bound
of $k-1$ against an oblivious adversary for any $k \geq 3$ and any $B$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4923</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4923</id><created>2013-09-19</created><authors><author><keyname>Di Molfetta</keyname><forenames>Giuseppe</forenames></author><author><keyname>Brachet</keyname><forenames>Marc</forenames></author><author><keyname>Debbasch</keyname><forenames>Fabrice</forenames></author></authors><title>Quantum Walks in artificial electric and gravitational Fields</title><categories>quant-ph cs.IT gr-qc math-ph math.IT math.MP</categories><comments>13 pages, 3 figures. Submitted to Physica A. arXiv admin note: text
  overlap with arXiv:1212.5821</comments><doi>10.1016/j.physa.2013.11.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The continuous limit of quantum walks (QWs) on the line is revisited through
a recently developed method. In all cases but one, the limit coincides with the
dynamics of a Dirac fermion coupled to an artificial electric and/or
relativistic gravitational field. All results are carefully discussed and
illustrated by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4927</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4927</id><created>2013-09-19</created><updated>2013-09-20</updated><authors><author><keyname>Hannula</keyname><forenames>Miika</forenames></author><author><keyname>Kontinen</keyname><forenames>Juha</forenames></author></authors><title>A finite axiomatization of conditional independence and inclusion
  dependencies</title><categories>math.LO cs.AI cs.DB cs.LO</categories><msc-class>03C80</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a complete finite axiomatization of the unrestricted implication
problem for inclusion and conditional independence atoms in the context of
dependence logic. For databases, our result implies a finite axiomatization of
the unrestricted implication problem for inclusion, functional, and embedded
multivalued dependencies in the unirelational case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4930</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4930</id><created>2013-09-19</created><updated>2014-05-06</updated><authors><author><keyname>Bunte</keyname><forenames>Christoph</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Samorodnitsky</keyname><forenames>Alex</forenames></author></authors><title>The Zero-Undetected-Error Capacity Approaches the Sperner Capacity</title><categories>cs.IT math.IT</categories><comments>8 Pages; added a section on the definition of Sperner capacity;
  accepted for publication in the IEEE Transactions on Information Theory</comments><doi>10.1109/TIT.2014.2322624</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ahlswede, Cai, and Zhang proved that, in the noise-free limit, the
zero-undetected-error capacity is lower bounded by the Sperner capacity of the
channel graph, and they conjectured equality. Here we derive an upper bound
that proves the conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4932</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4932</id><created>2013-09-19</created><authors><author><keyname>Dappert</keyname><forenames>Angela</forenames></author><author><keyname>Jackson</keyname><forenames>Andrew N.</forenames></author><author><keyname>Kimura</keyname><forenames>Akiko</forenames></author></authors><title>Developing a Robust Migration Workflow for Preserving and Curating
  Hand-held Media</title><categories>cs.DL</categories><comments>11 pages, presented at iPres 2011. Also publishing in corresponding
  conference proceedings</comments><acm-class>H.3.2; H.3.6; H.3.7; I.7; J.7</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many memory institutions hold large collections of hand-held media, which can
comprise hundreds of terabytes of data spread over many thousands of
data-carriers. Many of these carriers are at risk of significant physical
degradation over time, depending on their composition. Unfortunately, handling
them manually is enormously time consuming and so a full and frequent
evaluation of their condition is extremely expensive. It is, therefore,
important to develop scalable processes for stabilizing them onto backed-up
online storage where they can be subject to highquality digital preservation
management. This goes hand in hand with the need to establish efficient,
standardized ways of recording metadata and to deal with defective
data-carriers. This paper discusses processing approaches, workflows, technical
set-up, software solutions and touches on staffing needs for the stabilization
process. We have experimented with different disk copying robots, defined our
metadata, and addressed storage issues to scale stabilization to the vast
quantities of digital objects on hand-held data-carriers that need to be
preserved. Working closely with the content curators, we have been able to
build a robust data migration workflow and have stabilized over 16 terabytes of
data in a scalable and economical manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4938</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4938</id><created>2013-09-19</created><authors><author><keyname>Pal</keyname><forenames>Dipasree</forenames></author><author><keyname>Mitra</keyname><forenames>Mandar</forenames></author><author><keyname>Datta</keyname><forenames>Kalyankumar</forenames></author></authors><title>Improving Query Expansion Using WordNet</title><categories>cs.IR</categories><comments>18 pages, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study proposes a new way of using WordNet for Query Expansion (QE). We
choose candidate expansion terms, as usual, from a set of pseudo relevant
documents; however, the usefulness of these terms is measured based on their
definitions provided in a hand-crafted lexical resource like WordNet.
Experiments with a number of standard TREC collections show that this method
outperforms existing WordNet based methods. It also compares favorably with
established QE methods such as KLD and RM3. Leveraging earlier work in which a
combination of QE methods was found to outperform each individual method (as
well as other well-known QE methods), we next propose a combination-based QE
method that takes into account three different aspects of a candidate expansion
term's usefulness: (i) its distribution in the pseudo relevant documents and in
the target corpus, (ii) its statistical association with query terms, and (iii)
its semantic relation with the query, as determined by the overlap between the
WordNet definitions of the term and query terms. This combination of diverse
sources of information appears to work well on a number of test collections,
viz., TREC123, TREC5, TREC678, TREC robust new and TREC910 collections, and
yields significant improvements over competing methods on most of these
collections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4942</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4942</id><created>2013-09-19</created><authors><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author></authors><title>HetNets and Massive MIMO: Modeling, Potential Gains, and Performance
  Analysis</title><categories>cs.IT math.IT</categories><comments>invited paper, presented at IEEE-APS APWC 2013, Special Session on
  Advances in Physical Layer Wireless Communications, Torino, Italy, September
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a heterogeneous cellular network (HetNet) where a macrocell tier
with a large antenna array base station (BS) is overlaid with a dense tier of
small cells (SCs). We investigate the potential benefits of incorporating a
massive MIMO BS in a TDD-based HetNet and we provide analytical expressions for
the coverage probability and the area spectral efficiency using stochastic
geometry. The duplexing mode in which SCs should operate during uplink
macrocell transmissions is optimized. Furthermore, we consider a reverse TDD
scheme, in which the massive MIMO BS can estimate the SC interference
covariance matrix. Our results suggest that significant throughput improvement
can be achieved by exploiting interference nulling and implicit coordination
across the tiers due to flexible and asymmetric TDD operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4944</identifier>
 <datestamp>2014-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4944</id><created>2013-09-19</created><updated>2014-05-02</updated><authors><author><keyname>Mishra</keyname><forenames>Dheerendra</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Sourav</forenames></author></authors><title>Cryptanalysis and Improvement of Yan et al.'s Biometric-based
  authentication scheme for Telecare Medicine Information Systems</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the author due to a inaccuracy in
  analysis section</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote user authentication is desirable for a Telecare medicine information
system (TMIS) to verify the correctness of remote users and server over the
insecure channel. We propose an authentication scheme for TMIS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4953</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4953</id><created>2013-09-19</created><authors><author><keyname>Puthal</keyname><forenames>Deepak</forenames></author></authors><title>A Near Optimal Approximation Algorithm for Vertex-Cover Problem</title><categories>cs.DS</categories><comments>4 pages, 2 figures, 2 theorems, 1 algorithm</comments><msc-class>68</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recently, there has been increasing interest and progress in improvising the
approximation algorithm for well-known NP-Complete problems, particularly the
approximation algorithm for the Vertex-Cover problem. Here we have proposed a
polynomial time efficient algorithm for vertex-cover problem for more
approximate to the optimal solution, which lead to the worst time complexity
?{\theta}(V 2) and space complexity ?{\theta}(V + E). We show that our proposed
method is more approximate with example and theorem proof. Our algorithm also
induces improvement on previous algorithms for the independent set problem on
graphs of small and high degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4958</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4958</id><created>2013-09-19</created><updated>2014-08-23</updated><authors><author><keyname>Je&#x17c;</keyname><forenames>Artur</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author></authors><title>Approximation of smallest linear tree grammar</title><categories>cs.DS cs.FL</categories><comments>43 pages, submitted to a journal. Approximation ratio improved since
  the last version, proofs in the last section simplified. Several figures
  added</comments><acm-class>F.4.2; F.2.2; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple linear-time algorithm for constructing a linear context-free tree
grammar of size O(rg + rg log(n/rg)) for a given input tree T of size n is
presented, where g is the size of a minimal linear context-free tree grammar
for T, and r is the maximal rank of symbols in T (which is a constant in many
applications). This is the first example of a grammar-based tree compression
algorithm with a good approximation ratio. The analysis of the algorithm uses
an extension of the recompression technique (used in the context of
grammar-based string compression) from strings to trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4959</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4959</id><created>2013-09-19</created><authors><author><keyname>Heged&#xfc;s</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Schicho</keyname><forenames>Josef</forenames></author><author><keyname>Schr&#xf6;cker</keyname><forenames>Hans-Peter</forenames></author></authors><title>Four-Pose Synthesis of Angle-Symmetric 6R Linkages</title><categories>cs.RO</categories><msc-class>70B15</msc-class><journal-ref>J. Mech. Robot., 7(4), 2015</journal-ref><doi>10.1115/1.4029186</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the recently introduced factorization theory of motion polynomials
over the dual quaternions for the synthesis of closed kinematic loops with six
revolute joints that visit four prescribed poses. Our approach admits either no
or a one-parametric family of solutions. We suggest strategies for picking good
solutions from this family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4961</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4961</id><created>2013-09-19</created><updated>2014-09-13</updated><authors><author><keyname>Gu</keyname><forenames>Mei-Mei</forenames></author><author><keyname>Hao</keyname><forenames>Rong-Xia</forenames></author><author><keyname>Liu</keyname><forenames>Jian-Bing</forenames></author></authors><title>On 3-extra connectivity of k-ary n-cubes</title><categories>cs.DM</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in the main theorem</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Given a graph G, a non-negative integer h and a set of vertices S, the
h-extra connectivity of G is the cardinality of a minimum set S such that G-S
is disconnected and each component of G-S has at least h+1 vertices. The
2-extra connectivity of k-ary n-cube is gotten by Hsieh et al. in [Theoretical
Computer Science, 443 (2012) 63-69]. In this paper, we obtained the h-extra
connectivity of the k-ary n-cube networks for h=3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4962</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4962</id><created>2013-09-19</created><authors><author><keyname>Kaliszyk</keyname><forenames>Cezary</forenames></author><author><keyname>Urban</keyname><forenames>Josef</forenames></author></authors><title>HOL(y)Hammer: Online ATP Service for HOL Light</title><categories>cs.AI cs.DL cs.LG cs.LO cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  HOL(y)Hammer is an online AI/ATP service for formal (computer-understandable)
mathematics encoded in the HOL Light system. The service allows its users to
upload and automatically process an arbitrary formal development (project)
based on HOL Light, and to attack arbitrary conjectures that use the concepts
defined in some of the uploaded projects. For that, the service uses several
automated reasoning systems combined with several premise selection methods
trained on all the project proofs. The projects that are readily available on
the server for such query answering include the recent versions of the
Flyspeck, Multivariate Analysis and Complex Analysis libraries. The service
runs on a 48-CPU server, currently employing in parallel for each task 7 AI/ATP
combinations and 4 decision procedures that contribute to its overall
performance. The system is also available for local installation by interested
users, who can customize it for their own proof development. An Emacs interface
allowing parallel asynchronous queries to the service is also provided. The
overall structure of the service is outlined, problems that arise and their
solutions are discussed, and an initial account of using the system is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4973</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4973</id><created>2013-09-19</created><updated>2015-04-20</updated><authors><author><keyname>Kontogiannis</keyname><forenames>Spyros</forenames></author><author><keyname>Zaroliagis</keyname><forenames>Christos</forenames></author></authors><title>Distance Oracles for Time-Dependent Networks</title><categories>cs.DS</categories><comments>A preliminary version appeared as Technical Report ECOMPASS-TR-025 of
  EU funded research project eCOMPASS (http://www.ecompass-project.eu/). An
  extended abstract also appeared in the 41st International Colloquium on
  Automata, Languages, and Programming (ICALP 2014, track-A)</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present the first approximate distance oracle for sparse directed networks
with time-dependent arc-travel-times determined by continuous, piecewise
linear, positive functions possessing the FIFO property.
  Our approach precomputes $(1+\epsilon)-$approximate distance summaries from
selected landmark vertices to all other vertices in the network. Our oracle
uses subquadratic space and time preprocessing, and provides two sublinear-time
query algorithms that deliver constant and $(1+\sigma)-$approximate
shortest-travel-times, respectively, for arbitrary origin-destination pairs in
the network, for any constant $\sigma &gt; \epsilon$. Our oracle is based only on
the sparsity of the network, along with two quite natural assumptions about
travel-time functions which allow the smooth transition towards asymmetric and
time-dependent distance metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4978</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4978</id><created>2013-09-19</created><updated>2014-08-18</updated><authors><author><keyname>Wilhelm</keyname><forenames>Matthias</forenames></author><author><keyname>Lenders</keyname><forenames>Vincent</forenames></author><author><keyname>Schmitt</keyname><forenames>Jens B.</forenames></author></authors><title>An Analytical Model of Packet Collisions in IEEE 802.15.4 Wireless
  Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Transactions on Wireless
  Communications under the title &quot;On the Reception of Concurrent Transmissions
  in Wireless Sensor Networks.&quot;</comments><doi>10.1109/TWC.2014.2349896</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous studies showed that concurrent transmissions can boost wireless
network performance despite collisions. While these works provide empirical
evidence that concurrent transmissions may be received reliably, existing
signal capture models only partially explain the root causes of this
phenomenon. We present a comprehensive mathematical model that reveals the
reasons and provides insights on the key parameters affecting the performance
of MSK-modulated transmissions. A major contribution is a closed-form
derivation of the receiver bit decision variable for arbitrary numbers of
colliding signals and constellations of power ratios, timing offsets, and
carrier phase offsets. We systematically explore the root causes for successful
packet delivery under concurrent transmissions across the whole parameter space
of the model. We confirm the capture threshold behavior observed in previous
studies but also reveal new insights relevant for the design of optimal
protocols: We identify capture zones depending not only on the signal power
ratio but also on time and phase offsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4994</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4994</id><created>2013-09-19</created><authors><author><keyname>Cerutti</keyname><forenames>Federico</forenames></author><author><keyname>Toniolo</keyname><forenames>Alice</forenames></author><author><keyname>Oren</keyname><forenames>Nir</forenames></author><author><keyname>Norman</keyname><forenames>Timothy J.</forenames></author></authors><title>Context-dependent Trust Decisions with Subjective Logic</title><categories>cs.OH</categories><comments>19 pages, 4 figures, technical report of the University of Aberdeen
  (preprint version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A decision procedure implemented over a computational trust mechanism aims to
allow for decisions to be made regarding whether some entity or information
should be trusted. As recognised in the literature, trust is contextual, and we
describe how such a context often translates into a confidence level which
should be used to modify an underlying trust value. J{\o}sang's Subjective
Logic has long been used in the trust domain, and we show that its operators
are insufficient to address this problem. We therefore provide a
decision-making approach about trust which also considers the notion of
confidence (based on context) through the introduction of a new operator. In
particular, we introduce general requirements that must be respected when
combining trustworthiness and confidence degree, and demonstrate the soundness
of our new operator with respect to these properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.4999</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.4999</id><created>2013-09-18</created><authors><author><keyname>Voyant</keyname><forenames>Cyril</forenames><affiliation>SPE</affiliation></author><author><keyname>Darras</keyname><forenames>C.</forenames><affiliation>SPE</affiliation></author><author><keyname>Muselli</keyname><forenames>Marc</forenames><affiliation>SPE</affiliation></author><author><keyname>Paoli</keyname><forenames>Christophe</forenames><affiliation>SPE</affiliation></author><author><keyname>Nivet</keyname><forenames>Marie Laure</forenames><affiliation>SPE</affiliation></author><author><keyname>Poggi</keyname><forenames>Philippe</forenames><affiliation>SPE</affiliation></author></authors><title>Bayesian rules and stochastic models for high accuracy prediction of
  solar radiation</title><categories>cs.LG stat.AP</categories><comments>Applied Energy (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is essential to find solar predictive methods to massively insert
renewable energies on the electrical distribution grid. The goal of this study
is to find the best methodology allowing predicting with high accuracy the
hourly global radiation. The knowledge of this quantity is essential for the
grid manager or the private PV producer in order to anticipate fluctuations
related to clouds occurrences and to stabilize the injected PV power. In this
paper, we test both methodologies: single and hybrid predictors. In the first
class, we include the multi-layer perceptron (MLP), auto-regressive and moving
average (ARMA), and persistence models. In the second class, we mix these
predictors with Bayesian rules to obtain ad-hoc models selections, and Bayesian
averages of outputs related to single models. If MLP and ARMA are equivalent
(nRMSE close to 40.5% for the both), this hybridization allows a nRMSE gain
upper than 14 percentage points compared to the persistence estimation
(nRMSE=37% versus 51%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5004</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5004</id><created>2013-09-19</created><authors><author><keyname>Pereg</keyname><forenames>Deborah</forenames></author><author><keyname>Benzvi</keyname><forenames>Doron</forenames></author></authors><title>Blind Deconvolution via Maximum Kurtosis Adaptive Filtering</title><categories>cs.CV</categories><comments>18 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an algorithm for identifying a parametrically
described destructive unknown system based on a non-gaussianity measure. It is
known that under certain conditions the output of a linear system is more
gaussian than the input. Hence, an inverse filter is searched, such that its
output is minimally gaussian. We use the kurtosis as a measure of the
non-gaussianity of the signal. A maximum of the kurtosis as a function of the
deconvolving filter coefficients is searched. The search is done iteratively
using the gradient ascent algorithm, and the coefficients at the maximum point
correspond to the inverse filter coefficients. This filter may be applied to
the distorted signal to obtain the original undistorted signal. While a similar
approach has been used before, it was always directed at a particular kind of a
signal, commonly of impulsive characteristics. In this paper a successful
attempt has been made to apply the algorithm to a wider range of signals, such
as to process distorted audio signals and destructed images. This innovative
implementation required the revelation of a way to preprocess the distorted
signal at hand. The experimental results show very good performance in terms of
recovering audio signals and blurred images, both for an FIR and IIR distorting
filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5009</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5009</id><created>2013-09-19</created><updated>2013-10-07</updated><authors><author><keyname>Creignou</keyname><forenames>Nadia</forenames></author><author><keyname>Ktari</keyname><forenames>Ra&#xef;da</forenames></author><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Julian-Steffen</forenames></author><author><keyname>Olive</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>Parameterized Enumeration with Ordering</title><categories>cs.CC cs.DS</categories><comments>15 pages</comments><msc-class>F.1.3</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classes Delay-FPT and Total-FPT recently have been introduced into
parameterized complexity in order to capture the notion of efficiently solvable
parameterized enumeration problems. In this paper we focus on ordered
enumeration and will show how to obtain Delay-FPT and Total-FPT enumeration
algorithms for several important problems. We propose a generic algorithmic
strategy, combining well-known principles stemming from both parameterized
algorithmics and enumeration, which shows that, under certain preconditions,
the existence of a so-called neighbourhood function among the solutions implies
the existence of a Delay-FPT algorithm which outputs all ordered solutions. In
many cases, the cornerstone to obtain such a neighbourhood function is a
Total-FPT algorithm that outputs all minimal solutions. This strategy is
formalized in the context of graph modification problems, and shown to be
applicable to numerous other kinds of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5014</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5014</id><created>2013-09-19</created><authors><author><keyname>Borondo</keyname><forenames>J.</forenames></author><author><keyname>Morales</keyname><forenames>A. J.</forenames></author><author><keyname>Losada</keyname><forenames>J. C.</forenames></author><author><keyname>Benito</keyname><forenames>R. M.</forenames></author></authors><title>Characterizing and modeling an electoral campaign in the context of
  Twitter: 2011 Spanish Presidential Election as a case study</title><categories>physics.soc-ph cs.CY cs.SI</categories><journal-ref>Chaos 22, 023138 (2012)</journal-ref><doi>10.1063/1.4729139</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmitting messages in the most efficient way as possible has always been
one of politicians main concerns during electoral processes. Due to the rapidly
growing number of users, online social networks have become ideal platforms for
politicians to interact with their potential voters. Exploiting the available
potential of these tools to maximize their influence over voters is one of
politicians actual challenges. To step in this direction, we have analyzed the
user activity in the online social network Twitter, during the 2011 Spanish
Presidential electoral process, and found that such activity is correlated with
the election results. We introduce a new measure to study political support in
Twitter, which we call the Relative Support. We have also characterized user
behavior by analyzing the structural and dynamical patterns of the complex
networks emergent from the mention and retweet networks. Our results suggest
that the collective attention is driven by a very small fraction of users.
Furthermore we have analyzed the interactions taking place among politicians,
observing a lack of debate. Finally we develop a network growth model to
reproduce the interactions taking place among politicians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5018</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5018</id><created>2013-09-19</created><authors><author><keyname>Zamanzadeh</keyname><forenames>Ben</forenames></author><author><keyname>Ashish</keyname><forenames>Naveen</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Cartic</forenames></author><author><keyname>Zimmerman</keyname><forenames>John</forenames></author></authors><title>Semantic Advertising</title><categories>cs.AI cs.CY cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the concept of Semantic Advertising which we see as the future of
online advertising. Semantic Advertising is online advertising powered by
semantic technology which essentially enables us to represent and reason with
concepts and the meaning of things. This paper aims to 1) Define semantic
advertising, 2) Place it in the context of broader and more widely used
concepts such as the Semantic Web and Semantic Search, 3) Provide a survey of
work in related areas such as context matching, and 4) Provide a perspective on
successful emerging technologies and areas of future work. We base our work on
our experience as a company developing semantic technologies aimed at realizing
the full potential of online advertising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5047</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5047</id><created>2013-09-19</created><authors><author><keyname>Whalen</keyname><forenames>Sean</forenames></author><author><keyname>Pandey</keyname><forenames>Gaurav</forenames></author></authors><title>A Comparative Analysis of Ensemble Classifiers: Case Studies in Genomics</title><categories>cs.LG q-bio.GN stat.ML</categories><comments>10 pages, 3 figures, 8 tables, to appear in Proceedings of the 2013
  International Conference on Data Mining</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The combination of multiple classifiers using ensemble methods is
increasingly important for making progress in a variety of difficult prediction
problems. We present a comparative analysis of several ensemble methods through
two case studies in genomics, namely the prediction of genetic interactions and
protein functions, to demonstrate their efficacy on real-world datasets and
draw useful conclusions about their behavior. These methods include simple
aggregation, meta-learning, cluster-based meta-learning, and ensemble selection
using heterogeneous classifiers trained on resampled data to improve the
diversity of their predictions. We present a detailed analysis of these methods
across 4 genomics datasets and find the best of these methods offer
statistically significant improvements over the state of the art in their
respective domains. In addition, we establish a novel connection between
ensemble selection and meta-learning, demonstrating how both of these disparate
methods establish a balance between ensemble diversity and performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5049</identifier>
 <datestamp>2014-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5049</id><created>2013-09-19</created><updated>2014-09-22</updated><authors><author><keyname>Liao</keyname><forenames>Ruizhi</forenames></author><author><keyname>Bellalta</keyname><forenames>Boris</forenames></author><author><keyname>Minh</keyname><forenames>Trang Cao</forenames></author><author><keyname>Barcelo</keyname><forenames>Jaume</forenames></author><author><keyname>Oliver</keyname><forenames>Miquel</forenames></author></authors><title>Uni-MUMAC: A Unified Down/Up-link MU-MIMO MAC Protocol for IEEE 802.11ac
  WLANs</title><categories>cs.NI</categories><comments>27 pages, 16 figures</comments><doi>10.1007/s11276-014-0861-4</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Due to the dominance of the downlink traffic in Wireless Local Area Networks
(WLANs), a large number of previous research efforts have been put to enhance
the transmission from the Access Point (AP) to stations (STAs). The downlink
Multi-User Multiple-Input Multiple-Output (MU-MIMO) technique, supported by the
latest IEEE amendment-802.11ac, is considered as one of the key enhancements
leading WLANs to the Gigabit era. However, as cloud uploading services,
Peer-to-Peer (P2P) and telepresence applications get popular, the need for a
higher uplink capacity becomes inevitable.
  In this paper, a unified down/up-link Medium Access Control (MAC) protocol
called Uni-MUMAC is proposed to enhance the performance of IEEE 802.11ac WLANs
by exploring the multi-user spatial multiplexing technique. Specifically, in
the downlink, we implement an IEEE 802.11ac-compliant MU-MIMO transmission
scheme to allow the AP to simultaneously send frames to a group of STAs. In the
uplink, we extend the traditional one round channel access contention to two
rounds, which coordinate multiple STAs to transmit frames to the AP
simultaneously. 2-nd round Contention Window (CW2nd), a parameter that makes
the length of the 2-nd contention round elastic according to the traffic
condition, is introduced. Uni-MUMAC is evaluated through simulations in
saturated and non-saturated conditions when both downlink and uplink traffic
are present in the system. We also propose an analytic saturation model to
validate the simulation results. By properly setting CW2nd and other
parameters, Uni-MUMAC is compared to a prominent multi-user transmission scheme
in the literature. The results exhibit that Uni-MUMAC not only performs well in
the downlink-dominant scenario, but it is also able to balance both the
downlink and uplink throughput in the emerging uplink bandwidth-hungry
scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5067</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5067</id><created>2013-09-19</created><authors><author><keyname>Tall</keyname><forenames>Abdoulaye</forenames></author><author><keyname>Combes</keyname><forenames>Richard</forenames></author><author><keyname>Altman</keyname><forenames>Zwi</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author></authors><title>Distributed coordination of self-organizing mechanisms in communication
  networks</title><categories>cs.NI cs.SY</categories><comments>submitted to IEEE TCNS. arXiv admin note: substantial text overlap
  with arXiv:1209.1236</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fast development of the Self-Organizing Network (SON) technology in
mobile networks renders the problem of coordinating SON functionalities
operating simultaneously critical. SON functionalities can be viewed as control
loops that may need to be coordinated to guarantee conflict free operation, to
enforce stability of the network and to achieve performance gain. This paper
proposes a distributed solution for coordinating SON functionalities. It uses
Rosen's concave games framework in conjunction with convex optimization. The
SON functionalities are modeled as linear Ordinary Differential Equation
(ODE)s. The stability of the system is first evaluated using a basic control
theory approach. The coordination solution consists in finding a linear map
(called coordination matrix) that stabilizes the system of SON functionalities.
It is proven that the solution remains valid in a noisy environment using
Stochastic Approximation. A practical example involving three different SON
functionalities deployed in Base Stations (BSs) of a Long Term Evolution (LTE)
network demonstrates the usefulness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5069</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5069</id><created>2013-09-19</created><authors><author><keyname>Erskine</keyname><forenames>Samuel</forenames></author><author><keyname>WU</keyname><forenames>Ziengpieng</forenames></author></authors><title>Securing the IEEE 802.16 OFDM WiMAX PHYSICAL AND MAC Layer Using STBC
  Coding and Encryption</title><categories>cs.CR cs.IT cs.NI math.IT</categories><comments>12 pages, 6 figures. International Journal of data network and
  security (IJDNS), 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes model design in securing the IEEE 802.16 WiMAX Physical
and MAC layer, using Orthogonal Frequency Division Multiplexing (OFDM) and STBC
model. Typically, it addresses the physical and MAC layer security concerns,
using a Space Time Block Coding (STBC), link encryption, and Message
Authentication Code (MAC) technique. The model conforms to Multiple Input
Single Output (MISO) fading channels which model two or more transmitters and a
receiver in multiuser environment. The two fading link parameters are assumed
to be same. Channel estimate for each link, in combination to the received
signal is based on Reed Solomon Convolution Coding (RS-CC) algorithm, which
occurs as a result of the Space-Time Diversity Combiner block. In addition the
model explore using communication blocks to measure and display bit error rate
after encryption algorithm and Message Authentication Code (MAC) have been
adapted in Forward Error Correction (FEC) mode. Channel SNR and estimation in
rate ID is applied. The final results shows authentication, and the
Reed-Solomon decoding of the final information or data received.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5075</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5075</id><created>2013-09-19</created><authors><author><keyname>Nakov</keyname><forenames>Svetoslav</forenames></author><author><keyname>Ivanov</keyname><forenames>Tihomir</forenames></author></authors><title>A Calibration Algorithm for Microelectromechanical Systems
  Accelerometers in Inertial Navigation Sensors</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present work we develop an algorithm for calibrating MEMS sensors,
which accounts for the nonorthogonality of the accelerometers' axis, as well as
for the constant bias and scaling errors. We derive an explicit formula for
computing the calibrated acceleration, given data from the sensors. We also
study the error, that is caused by the nonorthogonality of the axis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5083</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5083</id><created>2013-09-19</created><authors><author><keyname>Gu</keyname><forenames>Meimei</forenames></author><author><keyname>Hao</keyname><forenames>Rongxia</forenames></author></authors><title>3-extra connectivity of 3-ary n-cube networks</title><categories>cs.DM math.CO</categories><comments>20 pages,1 figures. arXiv admin note: substantial text overlap with
  arXiv:1309.4961</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Let G be a connected graph and S be a set of vertices. The h-extra
connectivity of G is the cardinality of a minimum set S such that G-S is
disconnected and each component of G-S has at least h+1 vertices. The h-extra
connectivity is an important parameter to measure the reliability and fault
tolerance ability of large interconnection networks. The h-extra connectivity
for h=1,2 of k-ary n-cube are gotten by Hsieh et al. in [Theoretical Computer
Science, 443 (2012) 63-69] for k&gt;=4 and Zhu et al. in [Theory of Computing
Systems, arxiv.org/pdf/1105.0991v1 [cs.DM] 5 May 2011] for k=3. In this paper,
we show that the h-extra connectivity of the 3-ary n-cube networks for h=3 is
equal to 8n-12, where n&gt;=3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5105</identifier>
 <datestamp>2014-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5105</id><created>2013-09-19</created><updated>2014-02-14</updated><authors><author><keyname>Haber</keyname><forenames>Aleksandar</forenames></author><author><keyname>Verhaegen</keyname><forenames>Michel</forenames></author></authors><title>Subspace identification of large-scale interconnected systems</title><categories>cs.SY</categories><comments>revised version, conditionally accepted for publication in IEEE
  Transaction on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a decentralized subspace algorithm for identification of
large-scale, interconnected systems that are described by sparse (multi) banded
state-space matrices. First, we prove that the state of a local subsystem can
be approximated by a linear combination of inputs and outputs of the local
subsystems that are in its neighborhood. Furthermore, we prove that for
interconnected systems with well-conditioned, finite-time observability
Gramians (or observability matrices), the size of this neighborhood is
relatively small. On the basis of these results, we develop a subspace
identification algorithm that identifies a state-space model of a local
subsystem from the local input-output data. Consequently, the developed
algorithm is computationally feasible for interconnected systems with a large
number of local subsystems. Numerical results confirm the effectiveness of the
new identification algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5109</identifier>
 <datestamp>2015-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5109</id><created>2013-09-19</created><updated>2015-12-04</updated><authors><author><keyname>Verdery</keyname><forenames>Ashton M.</forenames></author><author><keyname>Mouw</keyname><forenames>Ted</forenames></author><author><keyname>Bauldry</keyname><forenames>Shawn</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author></authors><title>Network Structure and Biased Variance Estimation in Respondent Driven
  Sampling</title><categories>stat.AP cs.SI stat.ME</categories><comments>56 pages, 5 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores bias in the estimation of sampling variance in Respondent
Driven Sampling (RDS). Prior methodological work on RDS has focused on its
problematic assumptions and the biases and inefficiencies of its estimators of
the population mean. Nonetheless, researchers have given only slight attention
to the topic of estimating sampling variance in RDS, despite the importance of
variance estimation for the construction of confidence intervals and hypothesis
tests. In this paper, we show that the estimators of RDS sampling variance rely
on a critical assumption that the network is First Order Markov (FOM) with
respect to the dependent variable of interest. We demonstrate, through
intuitive examples, mathematical generalizations, and computational experiments
that current RDS variance estimators will always underestimate the population
sampling variance of RDS in empirical networks that do not conform to the FOM
assumption. Analysis of 215 observed university and school networks from
Facebook and Add Health indicates that the FOM assumption is violated in every
empirical network we analyze, and that these violations lead to substantially
biased RDS estimators of sampling variance. We propose and test two alternative
variance estimators that show some promise for reducing biases, but which also
illustrate the limits of estimating sampling variance with only partial
information on the underlying population social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5110</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5110</id><created>2013-09-19</created><authors><author><keyname>Fl&#xf3;rez</keyname><forenames>Edson</forenames></author><author><keyname>G&#xf3;mez</keyname><forenames>Wilfredo</forenames></author><author><keyname>Bautista</keyname><forenames>Lola</forenames></author></authors><title>An ant colony optimization algorithm for job shop scheduling problem</title><categories>cs.AI cs.NE</categories><comments>http://www.airccse.org/journal/ijaia/current2013.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nature has inspired several metaheuristics, outstanding among these is
Ant Colony Optimization (ACO), which have proved to be very effective and
efficient in problems of high complexity (NP-hard) in combinatorial
optimization. This paper describes the implementation of an ACO model algorithm
known as Elitist Ant System (EAS), applied to a combinatorial optimization
problem called Job Shop Scheduling Problem (JSSP). We propose a method that
seeks to reduce delays designating the operation immediately available, but
considering the operations that lack little to be available and have a greater
amount of pheromone. The performance of the algorithm was evaluated for
problems of JSSP reference, comparing the quality of the solutions obtained
regarding the best known solution of the most effective methods. The solutions
were of good quality and obtained with a remarkable efficiency by having to
make a very low number of objective function evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5124</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5124</id><created>2013-09-19</created><updated>2014-05-11</updated><authors><author><keyname>Oselio</keyname><forenames>Brandon</forenames></author><author><keyname>Kulesza</keyname><forenames>Alex</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames><suffix>III</suffix></author></authors><title>Multi-layer graph analysis for dynamic social networks</title><categories>cs.SI physics.soc-ph stat.CO</categories><comments>10 pages, 9 figures</comments><doi>10.1109/JSTSP.2014.2328312</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern social networks frequently encompass multiple distinct types of
connectivity information; for instance, explicitly acknowledged friend
relationships might complement behavioral measures that link users according to
their actions or interests. One way to represent these networks is as
multi-layer graphs, where each layer contains a unique set of edges over the
same underlying vertices (users). Edges in different layers typically have
related but distinct semantics; depending on the application multiple layers
might be used to reduce noise through averaging, to perform multifaceted
analyses, or a combination of the two. However, it is not obvious how to extend
standard graph analysis techniques to the multi-layer setting in a flexible
way. In this paper we develop latent variable models and methods for mining
multi-layer networks for connectivity patterns based on noisy data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5126</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5126</id><created>2013-09-19</created><authors><author><keyname>Altug</keyname><forenames>Yucel</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>The third-order term in the normal approximation for singular channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a singular and symmetric discrete memoryless channel with positive
dispersion, the third-order term in the normal approximation is shown to be
upper bounded by a constant. This finding completes the characterization of the
third-order term for symmetric discrete memoryless channels. The proof method
is extended to asymmetric and singular channels with constant composition
codes, and its connection to existing results, as well as its limitation in the
error exponents regime, are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5128</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5128</id><created>2013-09-19</created><authors><author><keyname>Jones</keyname><forenames>Neil D.</forenames><affiliation>University of Copenhagen</affiliation></author></authors><title>A Swiss Pocket Knife for Computability</title><categories>cs.PL cs.CC</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 1-17</journal-ref><doi>10.4204/EPTCS.129.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This research is about operational- and complexity-oriented aspects of
classical foundations of computability theory. The approach is to re-examine
some classical theorems and constructions, but with new criteria for success
that are natural from a programming language perspective.
  Three cornerstones of computability theory are the S-m-ntheorem; Turing's
&quot;universal machine&quot;; and Kleene's second recursion theorem. In today's
programming language parlance these are respectively partial evaluation,
self-interpretation, and reflection. In retrospect it is fascinating that
Kleene's 1938 proof is constructive; and in essence builds a self-reproducing
program.
  Computability theory originated in the 1930s, long before the invention of
computers and programs. Its emphasis was on delimiting the boundaries of
computability. Some milestones include 1936 (Turing), 1938 (Kleene), 1967
(isomorphism of programming languages), 1985 (partial evaluation), 1989 (theory
implementation), 1993 (efficient self-interpretation) and 2006 (term register
machines).
  The &quot;Swiss pocket knife&quot; of the title is a programming language that allows
efficient computer implementation of all three computability cornerstones,
emphasising the third: Kleene's second recursion theorem. We describe
experiments with a tree-based computational model aiming for both fast program
generation and fast execution of the generated programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5129</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5129</id><created>2013-09-19</created><authors><author><keyname>Stirling</keyname><forenames>Colin</forenames></author></authors><title>A Proof System with Names for Modal Mu-calculus</title><categories>cs.LO</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 18-29</journal-ref><doi>10.4204/EPTCS.129.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fixpoints are an important ingredient in semantics, abstract interpretation
and program logics. Their addition to a logic can add considerable expressive
power. One general issue is how to define proof systems for such logics. Here
we examine proof systems for modal logic with fixpoints. We present a tableau
proof system for checking validity of formulas which uses names to keep track
of unfoldings of fixpoint variables as devised by Jungteerapanich.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5130</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5130</id><created>2013-09-19</created><authors><author><keyname>Mogensen</keyname><forenames>Torben &#xc6;.</forenames><affiliation>DIKU, University of Copenhagen, Denmark</affiliation></author></authors><title>A Comparison of Well-Quasi Orders on Trees</title><categories>cs.PL cs.CC cs.DS</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>E.1; F.2.2; F.3.2</acm-class><journal-ref>EPTCS 129, 2013, pp. 30-40</journal-ref><doi>10.4204/EPTCS.129.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Well-quasi orders such as homeomorphic embedding are commonly used to ensure
termination of program analysis and program transformation, in particular
supercompilation.
  We compare eight well-quasi orders on how discriminative they are and their
computational complexity. The studied well-quasi orders comprise two very
simple examples, two examples from literature on supercompilation and four new
proposed by the author.
  We also discuss combining several well-quasi orders to get well-quasi orders
of higher discriminative power. This adds 19 more well-quasi orders to the
list.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5131</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5131</id><created>2013-09-19</created><authors><author><keyname>Mastroeni</keyname><forenames>Isabella</forenames><affiliation>Computer Science Dept., Univ. of Verona</affiliation></author></authors><title>Abstract interpretation-based approaches to Security - A Survey on
  Abstract Non-Interference and its Challenging Applications</title><categories>cs.PL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 41-65</journal-ref><doi>10.4204/EPTCS.129.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide a survey on the framework of abstract
non-interference. In particular, we describe a general formalization of
abstract non-interference by means of three dimensions (observation, protection
and semantics) that can be instantiated in order to obtain well known or even
new weakened non-interference properties. Then, we show that the notions of
abstract non-interference introduced in language-based security are instances
of this more general framework which allows to better understand the different
components of a non-interference policy. Finally, we consider two challenging
research fields concerning security where abstract non-interference seems a
promising approach providing new perspectives and new solutions to open
problems: Code injection and code obfuscation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5132</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5132</id><created>2013-09-19</created><authors><author><keyname>Mulry</keyname><forenames>Philip</forenames><affiliation>Colgate University</affiliation></author></authors><title>Notions of Monad Strength</title><categories>cs.PL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 67-83</journal-ref><doi>10.4204/EPTCS.129.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past two decades the notion of a strong monad has found wide
applicability in computing. Arising out of a need to interpret products in
computational and semantic settings, different approaches to this concept have
arisen. In this paper we introduce and investigate the connections between
these approaches and also relate the results to monad composition. We also
introduce new methods for checking and using the required laws associated with
such compositions, as well as provide examples illustrating problems and issues
that arise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5133</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5133</id><created>2013-09-19</created><authors><author><keyname>Rosendahl</keyname><forenames>Mads</forenames><affiliation>Roskilde University</affiliation></author></authors><title>Abstract Interpretation as a Programming Language</title><categories>cs.PL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>F.3.2</acm-class><journal-ref>EPTCS 129, 2013, pp. 84-104</journal-ref><doi>10.4204/EPTCS.129.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In David Schmidt's PhD work he explored the use of denotational semantics as
a programming language. It was part of an effort to not only treat formal
semantics as specifications but also as interpreters and input to compiler
generators. The semantics itself can be seen as a program and one may examine
different programming styles and ways to represent states.
  Abstract interpretation is primarily a technique for derivation and
specification of program analysis. As with denotational semantics we may also
view abstract interpretations as programs and examine the implementation. The
main focus in this paper is to show that results from higher-order strictness
analysis may be used more generally as fixpoint operators for higher-order
functions over lattices and thus provide a technique for immediate
implementation of a large class of abstract interpretations. Furthermore, it
may be seen as a programming paradigm and be used to write programs in a
circular style.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5134</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5134</id><created>2013-09-19</created><authors><author><keyname>Denniston</keyname><forenames>Jeffrey T.</forenames></author><author><keyname>Melton</keyname><forenames>Austin</forenames></author><author><keyname>Rodabaugh</keyname><forenames>Stephen E.</forenames></author></authors><title>Formal Contexts, Formal Concept Analysis, and Galois Connections</title><categories>cs.OH</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>06A15</acm-class><journal-ref>EPTCS 129, 2013, pp. 105-120</journal-ref><doi>10.4204/EPTCS.129.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal concept analysis (FCA) is built on a special type of Galois
connections called polarities. We present new results in formal concept
analysis and in Galois connections by presenting new Galois connection results
and then applying these to formal concept analysis. We also approach FCA from
the perspective of collections of formal contexts. Usually, when doing FCA, a
formal context is fixed. We are interested in comparing formal contexts and
asking what criteria should be used when determining when one formal context is
better than another formal context. Interestingly, we address this issue by
studying sets of polarities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5135</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5135</id><created>2013-09-19</created><authors><author><keyname>Launchbury</keyname><forenames>J.</forenames></author><author><keyname>Krstic</keyname><forenames>S.</forenames></author><author><keyname>Sauerwein</keyname><forenames>T. E.</forenames></author></authors><title>Coroutining Folds with Hyperfunctions</title><categories>cs.PL cs.LO</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557. It is a
  privilege to submit a paper for the Festschrift symposium held to honor Dave
  Schmidt's lifetime of contributions on the occasion of his 60th birthday.
  Many years ago, as a fresh PhD student, Dave's excellent book on Denotational
  Semantics opened my eyes to rich possibilities of building functions over
  functions (recursively!) and our continued interactions over the years were
  always insightful. So it seemed appropriate to offer a paper whose
  foundations rely on the same mathematical models that Dave so ably expounded
  all those years ago, constructing recursive function spaces in a way that is
  not possible in traditional set-theoretic models. -- John Launchbury, 2013</comments><proxy>EPTCS</proxy><acm-class>D.1.1</acm-class><journal-ref>EPTCS 129, 2013, pp. 121-135</journal-ref><doi>10.4204/EPTCS.129.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fold functions are a general mechanism for computing over recursive data
structures. First-order folds compute results bottom-up. With higher-order
folds, computations that inherit attributes from above can also be expressed.
In this paper, we explore folds over a form of recursive higher-order function,
called hyperfunctions, and show that hyperfunctions allow fold computations to
coroutine across data structures, as well as compute bottom up and top down. We
use the compiler technique of foldr-build as an exemplar to show how
hyperfunctions can be used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5137</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5137</id><created>2013-09-19</created><authors><author><keyname>Sestoft</keyname><forenames>Peter</forenames><affiliation>IT University of Copenhagen</affiliation></author></authors><title>Online partial evaluation of sheet-defined functions</title><categories>cs.PL cs.SE</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 136-160</journal-ref><doi>10.4204/EPTCS.129.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a spreadsheet implementation, extended with sheet-defined
functions, that allows users to define functions using only standard
spreadsheet concepts such as cells, formulas and references, requiring no new
syntax. This implements an idea proposed by Peyton-Jones and others.
  As the main contribution of this paper, we then show how to add an online
partial evaluator for such sheet-defined functions. The result is a
higher-order functional language that is dynamically typed, in keeping with
spreadsheet traditions, and an interactive platform for function definition and
function specialization.
  We describe an implementation of these ideas, present some performance data
from microbenchmarks, and outline desirable improvements and extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5138</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5138</id><created>2013-09-19</created><authors><author><keyname>Chang</keyname><forenames>Bor-Yuh Evan</forenames><affiliation>University of Colorado Boulder</affiliation></author><author><keyname>Rival</keyname><forenames>Xavier</forenames><affiliation>INRIA, ENS, and CNRS</affiliation></author></authors><title>Modular Construction of Shape-Numeric Analyzers</title><categories>cs.PL cs.LO</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>F.3.1; D.2.4</acm-class><journal-ref>EPTCS 129, 2013, pp. 161-185</journal-ref><doi>10.4204/EPTCS.129.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of static analysis is to infer invariants about programs that are
precise enough to establish semantic properties, such as the absence of
run-time errors. Broadly speaking, there are two major branches of static
analysis for imperative programs. Pointer and shape analyses focus on inferring
properties of pointers, dynamically-allocated memory, and recursive data
structures, while numeric analyses seek to derive invariants on numeric values.
Although simultaneous inference of shape-numeric invariants is often needed,
this case is especially challenging and is not particularly well explored.
Notably, simultaneous shape-numeric inference raises complex issues in the
design of the static analyzer itself.
  In this paper, we study the construction of such shape-numeric, static
analyzers. We set up an abstract interpretation framework that allows us to
reason about simultaneous shape-numeric properties by combining shape and
numeric abstractions into a modular, expressive abstract domain. Such a modular
structure is highly desirable to make its formalization and implementation
easier to do and get correct. To achieve this, we choose a concrete semantics
that can be abstracted step-by-step, while preserving a high level of
expressiveness. The structure of abstract operations (i.e., transfer, join, and
comparison) follows the structure of this semantics. The advantage of this
construction is to divide the analyzer in modules and functors that implement
abstractions of distinct features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5139</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5139</id><created>2013-09-19</created><authors><author><keyname>De Angelis</keyname><forenames>Emanuele</forenames><affiliation>DEC, University `G. D'Annunzio', Pescara, Italy</affiliation></author><author><keyname>Fioravanti</keyname><forenames>Fabio</forenames><affiliation>DEC, University `G. D'Annunzio', Pescara, Italy</affiliation></author><author><keyname>Pettorossi</keyname><forenames>Alberto</forenames><affiliation>DICII, University of Rome Tor Vergata, Rome, Italy</affiliation></author><author><keyname>Proietti</keyname><forenames>Maurizio</forenames><affiliation>IASI-CNR, Rome, Italy</affiliation></author></authors><title>Verification of Imperative Programs by Constraint Logic Program
  Transformation</title><categories>cs.PL cs.LO</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>F.3.1,F.3.2,F.4.1,I.2.2,D.2.4</acm-class><journal-ref>EPTCS 129, 2013, pp. 186-210</journal-ref><doi>10.4204/EPTCS.129.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for verifying partial correctness properties of
imperative programs that manipulate integers and arrays by using techniques
based on the transformation of constraint logic programs (CLP). We use CLP as a
metalanguage for representing imperative programs, their executions, and their
properties. First, we encode the correctness of an imperative program, say
prog, as the negation of a predicate 'incorrect' defined by a CLP program T. By
construction, 'incorrect' holds in the least model of T if and only if the
execution of prog from an initial configuration eventually halts in an error
configuration. Then, we apply to program T a sequence of transformations that
preserve its least model semantics. These transformations are based on
well-known transformation rules, such as unfolding and folding, guided by
suitable transformation strategies, such as specialization and generalization.
The objective of the transformations is to derive a new CLP program TransfT
where the predicate 'incorrect' is defined either by (i) the fact 'incorrect.'
(and in this case prog is not correct), or by (ii) the empty set of clauses
(and in this case prog is correct). In the case where we derive a CLP program
such that neither (i) nor (ii) holds, we iterate the transformation. Since the
problem is undecidable, this process may not terminate. We show through
examples that our method can be applied in a rather systematic way, and is
amenable to automation by transferring to the field of program verification
many techniques developed in the field of program transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5140</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5140</id><created>2013-09-19</created><authors><author><keyname>Giannakopoulou</keyname><forenames>Dimitra</forenames><affiliation>NASA Ames</affiliation></author><author><keyname>P&#x103;s&#x103;reanu</keyname><forenames>Corina S.</forenames><affiliation>Carnegie Mellon Silicon Valley</affiliation></author></authors><title>Abstraction and Learning for Infinite-State Compositional Verification</title><categories>cs.LO cs.FL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 211-228</journal-ref><doi>10.4204/EPTCS.129.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite many advances that enable the application of model checking
techniques to the verification of large systems, the state-explosion problem
remains the main challenge for scalability. Compositional verification
addresses this challenge by decomposing the verification of a large system into
the verification of its components. Recent techniques use learning-based
approaches to automate compositional verification based on the assume-guarantee
style reasoning. However, these techniques are only applicable to finite-state
systems. In this work, we propose a new framework that interleaves abstraction
and learning to perform automated compositional verification of infinite-state
systems. We also discuss the role of learning and abstraction in the related
context of interface generation for infinite-state components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5141</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5141</id><created>2013-09-19</created><authors><author><keyname>Mercadal</keyname><forenames>Julien</forenames></author><author><keyname>Drey</keyname><forenames>Zo&#xe9;</forenames></author><author><keyname>Consel</keyname><forenames>Charles</forenames></author></authors><title>Denotational Semantics of A User-Oriented, Domain-Specific Language</title><categories>cs.PL cs.SE</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 229-249</journal-ref><doi>10.4204/EPTCS.129.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the formal definition of a domain-specific language,
named Pantagruel, following the methodology proposed by David Schmidt for
language development. This language is dedicated to programming applications
that orchestrate networked entities. It targets developers that are
professionals in such domains as building management and assisted living, and
want to leverage networked entities to support daily tasks.
  Pantagruel has a number of features that address the requirements of the
domain of entity orchestration. Furthermore, Pantagruel provides high-level
constructs that make it accessible to developers that do not necessarily have
programming skills. It has been used to develop a number of applications by
non-programmers.
  We show how the user-oriented programming concepts of Pantagruel are
expressed in the denotational semantics of Pantagruel. This formal definition
has been used to derive an interpreter for Pantagruel and to provide a basis to
reason about Pantagruel programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5142</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5142</id><created>2013-09-19</created><authors><author><keyname>Gl&#xfc;ck</keyname><forenames>Robert</forenames><affiliation>DIKU</affiliation></author></authors><title>Simulation of Two-Way Pushdown Automata Revisited</title><categories>cs.PL cs.FL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>D.3.4; F.1.1</acm-class><journal-ref>EPTCS 129, 2013, pp. 250-258</journal-ref><doi>10.4204/EPTCS.129.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear-time simulation of 2-way deterministic pushdown automata (2DPDA)
by the Cook and Jones constructions is revisited. Following the semantics-based
approach by Jones, an interpreter is given which, when extended with
random-access memory, performs a linear-time simulation of 2DPDA. The recursive
interpreter works without the dump list of the original constructions, which
makes Cook's insight into linear-time simulation of exponential-time automata
more intuitive and the complexity argument clearer. The simulation is then
extended to 2-way nondeterministic pushdown automata (2NPDA) to provide for a
cubic-time recognition of context-free languages. The time required to run the
final construction depends on the degree of nondeterminism. The key mechanism
that enables the polynomial-time simulations is the sharing of computations by
memoization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5143</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5143</id><created>2013-09-19</created><authors><author><keyname>Neubauer</keyname><forenames>Johannes</forenames><affiliation>Chair of Programming Systems, TU Dortmund, Germany</affiliation></author><author><keyname>Steffen</keyname><forenames>Bernhard</forenames><affiliation>Chair of Programming Systems, TU Dortmund, Germany</affiliation></author><author><keyname>Margaria</keyname><forenames>Tiziana</forenames><affiliation>Chair of Service and Software Engineering, Universit&#xe4;t Potsdam, Germany</affiliation></author></authors><title>Higher-Order Process Modeling: Product-Lining, Variability Modeling and
  Beyond</title><categories>cs.SE cs.PL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 259-283</journal-ref><doi>10.4204/EPTCS.129.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a graphical and dynamic framework for binding and execution of
business) process models. It is tailored to integrate 1) ad hoc processes
modeled graphically, 2) third party services discovered in the (Inter)net, and
3) (dynamically) synthesized process chains that solve situation-specific
tasks, with the synthesis taking place not only at design time, but also at
runtime. Key to our approach is the introduction of type-safe stacked
second-order execution contexts that allow for higher-order process modeling.
Tamed by our underlying strict service-oriented notion of abstraction, this
approach is tailored also to be used by application experts with little
technical knowledge: users can select, modify, construct and then pass
(component) processes during process execution as if they were data. We
illustrate the impact and essence of our framework along a concrete, realistic
(business) process modeling scenario: the development of Springer's
browser-based Online Conference Service (OCS). The most advanced feature of our
new framework allows one to combine online synthesis with the integration of
the synthesized process into the running application. This ability leads to a
particularly flexible way of implementing self-adaption, and to a particularly
concise and powerful way of achieving variability not only at design time, but
also at runtime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5144</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5144</id><created>2013-09-19</created><authors><author><keyname>Banerjee</keyname><forenames>Anindya</forenames></author><author><keyname>Naumann</keyname><forenames>David A.</forenames></author></authors><title>A Simple Semantics and Static Analysis for Stack Inspection</title><categories>cs.PL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 284-308</journal-ref><doi>10.4204/EPTCS.129.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Java virtual machine and the .NET common language runtime feature an
access control mechanism specified operationally in terms of run-time stack
inspection. We give a denotational semantics in &quot;eager&quot; form, and show that it
is equivalent to the &quot;lazy&quot; semantics using stack inspection. We give a static
analysis of safety, i.e., the absence of security errors, that is simpler than
previous proposals. We identify several program transformations that can be
used to remove run-time checks. We give complete, detailed proofs for safety of
the analysis and for the transformations, exploiting compositionality of the
eager semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5145</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5145</id><created>2013-09-19</created><authors><author><keyname>Talcott</keyname><forenames>Carolyn</forenames></author></authors><title>The Immune System: the ultimate fractionated cyber-physical system</title><categories>cs.CE q-bio.OT</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 309-324</journal-ref><doi>10.4204/EPTCS.129.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this little vision paper we analyze the human immune system from a
computer science point of view with the aim of understanding the architecture
and features that allow robust, effective behavior to emerge from local sensing
and actions. We then recall the notion of fractionated cyber-physical systems,
and compare and contrast this to the immune system. We conclude with some
challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5146</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5146</id><created>2013-09-19</created><authors><author><keyname>Cortesi</keyname><forenames>Agostino</forenames><affiliation>Ca' Foscari University, Venice, Italy</affiliation></author><author><keyname>Costantini</keyname><forenames>Giulia</forenames><affiliation>Ca' Foscari University, Venice, Italy</affiliation></author><author><keyname>Ferrara</keyname><forenames>Pietro</forenames><affiliation>ETH, Zurich, Switzerland</affiliation></author></authors><title>A Survey on Product Operators in Abstract Interpretation</title><categories>cs.LO</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 325-336</journal-ref><doi>10.4204/EPTCS.129.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to provide a general overview of the product
operators introduced in the literature as a tool to enhance the analysis
accuracy in the Abstract Interpretation framework. In particular we focus on
the Cartesian and reduced products, as well as on the reduced cardinal power,
an under-used technique whose features deserve to be stressed for their
potential impact in practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5147</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5147</id><created>2013-09-19</created><authors><author><keyname>Hankin</keyname><forenames>Chris</forenames><affiliation>Imperial College London</affiliation></author></authors><title>A short note on Simulation and Abstraction</title><categories>cs.PL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 337-340</journal-ref><doi>10.4204/EPTCS.129.20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note is written in celebration of David Schmidt's sixtieth
birthday. He has now been active in the program analysis research community for
over thirty years and we have enjoyed many interactions with him. His work on
characterising simulations between Kripke structures using Galois connections
was particularly influential in our own work on using probabilistic abstract
interpretation to study Larsen and Skou's notion of probabilistic bisimulation.
We briefly review this work and discuss some recent applications of these ideas
in a variety of different application areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5148</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5148</id><created>2013-09-19</created><authors><author><keyname>Logozzo</keyname><forenames>Francesco</forenames><affiliation>Microsoft Research, Redmond, USA</affiliation></author><author><keyname>Martel</keyname><forenames>Matthieu</forenames><affiliation>Universit&#xe9; de Perpignan Via Domitia &amp; LIRMM</affiliation></author></authors><title>Automatic Repair of Overflowing Expressions with Abstract Interpretation</title><categories>cs.PL cs.SE</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>B.2.3; D.2.4; I.2.2</acm-class><journal-ref>EPTCS 129, 2013, pp. 341-357</journal-ref><doi>10.4204/EPTCS.129.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of synthesizing provably non-overflowing integer
arithmetic expressions or Boolean relations among integer arithmetic
expressions. First we use a numerical abstract domain to infer numerical
properties among program variables. Then we check if those properties guarantee
that a given expression does not overflow. If this is not the case, we
synthesize an equivalent, yet not-overflowing expression, or we report that
such an expression does not exists.
  The synthesis of a non-overflowing expression depends on three, orthogonal
factors: the input expression (e.g., is it linear, polynomial,... ?), the
output expression (e.g., are case splits allowed?), and the underlying
numerical abstract domain - the more precise the abstract domain is, the more
correct expressions can be synthesized.
  We consider three common cases: (i) linear expressions with integer
coefficients and intervals; (ii) Boolean expressions of linear expressions; and
(iii) linear expressions with templates. In the first case we prove there
exists a complete and polynomial algorithm to solve the problem. In the second
case, we have an incomplete yet polynomial algorithm, whereas in the third we
have a complete yet worst-case exponential algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5149</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5149</id><created>2013-09-19</created><authors><author><keyname>Bodin</keyname><forenames>Martin</forenames><affiliation>ENS Lyon and Inria</affiliation></author><author><keyname>Jensen</keyname><forenames>Thomas</forenames><affiliation>Inria</affiliation></author><author><keyname>Schmitt</keyname><forenames>Alan</forenames><affiliation>Inria</affiliation></author></authors><title>Pretty-big-step-semantics-based Certified Abstract Interpretation
  (Preliminary version)</title><categories>cs.PL cs.LO</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><acm-class>F.3.1; F.3.2</acm-class><journal-ref>EPTCS 129, 2013, pp. 360-383</journal-ref><doi>10.4204/EPTCS.129.23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a technique for deriving semantic program analyses from a natural
semantics specification of the programming language. The technique is based on
a particular kind of semantics called pretty-big-step semantics. We present a
pretty-big-step semantics of a language with simple objects called O'While and
specify a series of instrumentations of the semantics that explicitates the
flows of values in a program. This leads to a semantics-based dependency
analysis, at the core, e.g., of tainting analysis in software security. The
formalization has been realized with the Coq proof assistant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5150</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5150</id><created>2013-09-19</created><authors><author><keyname>Nordhoff</keyname><forenames>Benedikt</forenames><affiliation>Westf&#xe4;lische Wilhelms-Universit&#xe4;t M&#xfc;nster, Germany</affiliation></author><author><keyname>M&#xfc;ller-Olm</keyname><forenames>Markus</forenames><affiliation>Westf&#xe4;lische Wilhelms-Universit&#xe4;t M&#xfc;nster, Germany</affiliation></author><author><keyname>Lammich</keyname><forenames>Peter</forenames><affiliation>Technische Universit&#xe4;t M&#xfc;nchen, Germany</affiliation></author></authors><title>Iterable Forward Reachability Analysis of Monitor-DPNs</title><categories>cs.LO cs.DC cs.PL</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 384-403</journal-ref><doi>10.4204/EPTCS.129.24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a close connection between data-flow analysis and model checking as
observed and studied in the nineties by Steffen and Schmidt. This indicates
that automata-based analysis techniques developed in the realm of
infinite-state model checking can be applied as data-flow analyzers that
interpret complex control structures, which motivates the development of such
analysis techniques for ever more complex models. One approach proposed by
Esparza and Knoop is based on computation of predecessor or successor sets for
sets of automata configurations. Our goal is to adapt and exploit this approach
for analysis of multi-threaded Java programs. Specifically, we consider the
model of Monitor-DPNs for concurrent programs. Monitor-DPNs precisely model
unbounded recursion, dynamic thread creation, and synchronization via
well-nested locks with finite abstractions of procedure- and thread-local
state. Previous work on this model showed how to compute regular predecessor
sets of regular configurations and tree-regular successor sets of a fixed
initial configuration. By combining and extending different previously
developed techniques we show how to compute tree-regular successor sets of
tree-regular sets. Thereby we obtain an iterable, lock-sensitive forward
reachability analysis. We implemented the analysis for Java programs and
applied it to information flow control and data race detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5151</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5151</id><created>2013-09-19</created><authors><author><keyname>Namjoshi</keyname><forenames>Kedar S.</forenames><affiliation>Bell Labs, Alcatel-Lucent</affiliation></author></authors><title>Model Checking in Bits and Pieces</title><categories>cs.LO</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 404-416</journal-ref><doi>10.4204/EPTCS.129.25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully automated verification of concurrent programs is a difficult problem,
primarily because of state explosion: the exponential growth of a program state
space with the number of its concurrently active components. It is natural to
apply a divide and conquer strategy to ameliorate state explosion, by analyzing
only a single component at a time. We show that this strategy leads to the
notion of a &quot;split&quot; invariant, an assertion which is globally inductive, while
being structured as the conjunction of a number of local, per-component
invariants. This formulation is closely connected to the classical Owicki-Gries
method and to Rely-Guarantee reasoning. We show how the division of an
invariant into a number of pieces with limited scope makes it possible to apply
new, localized forms of symmetry and abstraction to drastically simplify its
computation. Split invariance also has interesting connections to parametric
verification. A quantified invariant for a parametric system is a split
invariant for every instance. We show how it is possible, in some cases, to
invert this connection, and to automatically generalize from a split invariant
for a small instance of a system to a quantified invariant which holds for the
entire family of instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5152</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5152</id><created>2013-09-19</created><authors><author><keyname>Yi</keyname><forenames>Jooyong</forenames><affiliation>National University of Singapore</affiliation></author></authors><title>A Case for Dynamic Reverse-code Generation to Debug Non-deterministic
  Programs</title><categories>cs.PL cs.SE</categories><comments>In Proceedings Festschrift for Dave Schmidt, arXiv:1309.4557</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 129, 2013, pp. 419-428</journal-ref><doi>10.4204/EPTCS.129.27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Backtracking (i.e., reverse execution) helps the user of a debugger to
naturally think backwards along the execution path of a program, and thinking
backwards makes it easy to locate the origin of a bug. So far backtracking has
been implemented mostly by state saving or by checkpointing. These
implementations, however, inherently do not scale. Meanwhile, a more recent
backtracking method based on reverse-code generation seems promising because
executing reverse code can restore the previous states of a program without
state saving. In the literature, there can be found two methods that generate
reverse code: (a) static reverse-code generation that pre-generates reverse
code through static analysis before starting a debugging session, and (b)
dynamic reverse-code generation that generates reverse code by applying dynamic
analysis on the fly during a debugging session. In particular, we espoused the
latter one in our previous work to accommodate non-determinism of a program
caused by e.g., multi-threading. To demonstrate the usefulness of our dynamic
reverse-code generation, this article presents a case study of various
backtracking methods including ours. We compare the memory usage of various
backtracking methods in a simple but nontrivial example, a bounded-buffer
program. In the case of non-deterministic programs such as this bounded-buffer
program, our dynamic reverse-code generation outperforms the existing
backtracking methods in terms of memory efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5172</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5172</id><created>2013-09-20</created><authors><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Mathieson</keyname><forenames>Luke</forenames></author></authors><title>Augmenting graphs to minimize the diameter</title><categories>cs.DS</categories><comments>15 pages, 3 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of augmenting a weighted graph by inserting edges of
bounded total cost while minimizing the diameter of the augmented graph. Our
main result is an FPT 4-approximation algorithm for the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5174</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5174</id><created>2013-09-20</created><authors><author><keyname>Barbu</keyname><forenames>Andrei</forenames></author><author><keyname>Siddharth</keyname><forenames>N.</forenames></author><author><keyname>Siskind</keyname><forenames>Jeffrey Mark</forenames></author></authors><title>Saying What You're Looking For: Linguistics Meets Video Search</title><categories>cs.CV cs.CL cs.IR</categories><comments>13 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach to searching large video corpora for video clips which
depict a natural-language query in the form of a sentence. This approach uses
compositional semantics to encode subtle meaning that is lost in other systems,
such as the difference between two sentences which have identical words but
entirely different meaning: &quot;The person rode the horse} vs. \emph{The horse
rode the person&quot;. Given a video-sentence pair and a natural-language parser,
along with a grammar that describes the space of sentential queries, we produce
a score which indicates how well the video depicts the sentence. We produce
such a score for each video clip in a corpus and return a ranked list of clips.
Furthermore, this approach addresses two fundamental problems simultaneously:
detecting and tracking objects, and recognizing whether those tracks depict the
query. Because both tracking and object detection are unreliable, this uses
knowledge about the intended sentential query to focus the tracker on the
relevant participants and ensures that the resulting tracks are described by
the sentential query. While earlier work was limited to single-word queries
which correspond to either verbs or nouns, we show how one can search for
complex queries which contain multiple phrases, such as prepositional phrases,
and modifiers, such as adverbs. We demonstrate this approach by searching for
141 queries involving people and horses interacting with each other in 10
full-length Hollywood movies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5184</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5184</id><created>2013-09-20</created><authors><author><keyname>Achilleos</keyname><forenames>Antonis</forenames></author><author><keyname>Lampis</keyname><forenames>Michael</forenames></author></authors><title>Closing a Gap in the Complexity of Refinement Modal Logic</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Refinement Modal Logic (RML), which was recently introduced by Bozzelli et
al., is an extension of classical modal logic which allows one to reason about
a changing model. In this paper we study computational complexity questions
related to this logic, settling a number of open problems. Specifically, we
study the complexity of satisfiability for the existential fragment of RML, a
problem posed by Bozzelli, van Ditmarsch and Pinchinat. Our main result is a
tight PSPACE upper bound for this problem, which we achieve by introducing a
new tableau system. As a direct consequence, we obtain a tight characterization
of the complexity of RML satisfiability for any fixed number of alternations of
refinement quantifiers. Additionally, through a simple reduction we establish
that the model checking problem for RML is PSPACE-complete, even for formulas
with a single quantifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5201</identifier>
 <datestamp>2014-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5201</id><created>2013-09-20</created><updated>2014-02-11</updated><authors><author><keyname>Noel</keyname><forenames>Adam</forenames></author><author><keyname>Cheung</keyname><forenames>Karen C.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Diffusive Molecular Communication with Disruptive Flows</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 table, 5 figures. Will be presented at the 2014 IEEE
  International Conference on Communications (ICC) in Sydney, Australia, on
  September 12, 2013</comments><doi>10.1109/ICC.2014.6883880</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the performance of detectors in a diffusive molecular
communication environment where steady uniform flow is present. We derive the
expected number of information molecules to be observed in a passive spherical
receiver, and determine the impact of flow on the assumption that the
concentration of molecules throughout the receiver is uniform. Simulation
results show the impact of advection on detector performance as a function of
the flow's magnitude and direction. We highlight that there are disruptive
flows, i.e., flows that are not in the direction of information transmission,
that lead to an improvement in detector performance as long as the disruptive
flow does not dominate diffusion and sufficient samples are taken.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5206</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5206</id><created>2013-09-20</created><authors><author><keyname>Davydow</keyname><forenames>Alex</forenames></author></authors><title>New Algorithms for Solving Tropical Linear Systems</title><categories>cs.CC cs.DS</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of solving tropical linear systems, a natural problem of tropical
mathematics, has already proven to be very interesting from the algorithmic
point of view: it is known to be in $NP\cap coNP$ but no polynomial time
algorithm is known, although counterexamples for existing pseudopolynomial
algorithms are (and have to be) very complex.
  In this work, we continue the study of algorithms for solving tropical linear
systems. First, we present a new reformulation of Grigoriev's algorithm that
brings it closer to the algorithm of Akian, Gaubert, and Guterman; this lets us
formulate a whole family of new algorithms, and we present algorithms from this
family for which no known superpolynomial counterexamples work. Second, we
present a family of algorithms for solving overdetermined tropical systems. We
show that for weakly overdetermined systems, there are polynomial algorithms in
this family. We also present a concrete algorithm from this family that can
solve a tropical linear system defined by an $m\times n$ matrix with maximal
element $M$ in time $\Theta\left({m \choose n} \mathrm{poly}\left(m, n, \log
M\right)\right)$, and this time matches the complexity of the best of
previously known algorithms for feasibility testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5220</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5220</id><created>2013-09-20</created><authors><author><keyname>Roberts</keyname><forenames>James</forenames><affiliation>SystemX, France</affiliation></author><author><keyname>Sbihi</keyname><forenames>Nada</forenames><affiliation>Inria, France</affiliation></author></authors><title>Exploring the Memory-Bandwidth Tradeoff in an Information-Centric
  Network</title><categories>cs.NI</categories><comments>Proceedings of ITC 25 (International Teletraffic Congress), Shanghai,
  September, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An information-centric network should realize significant economies by
exploiting a favourable memory-bandwidth tradeoff: it is cheaper to store
copies of popular content close to users than to fetch them repeatedly over the
Internet. We evaluate this tradeoff for some simple cache network structures
under realistic assumptions concerning the size of the content catalogue and
its popularity distribution. Derived cost formulas reveal the relative impact
of various cost, traffic and capacity parameters, allowing an appraisal of
possible future network architectures. Our results suggest it probably makes
more sense to envisage the future Internet as a loosely interconnected set of
local data centers than a network like today's with routers augmented by
limited capacity content stores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5223</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5223</id><created>2013-09-20</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Ebrahim</keyname><forenames>Mohamed</forenames></author><author><keyname>Turchi</keyname><forenames>Marco</forenames></author></authors><title>JRC EuroVoc Indexer JEX - A freely available multi-label categorisation
  tool</title><categories>cs.CL</categories><acm-class>H.3.1; H.3.6</acm-class><journal-ref>Proceedings of the 8th international conference on Language
  Resources and Evaluation (LREC'2012), pp. 798-805, Istanbul, 21-27 May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EuroVoc (2012) is a highly multilingual thesaurus consisting of over 6,700
hierarchically organised subject domains used by European Institutions and many
authorities in Member States of the European Union (EU) for the classification
and retrieval of official documents. JEX is JRC-developed multi-label
classification software that learns from manually labelled data to
automatically assign EuroVoc descriptors to new documents in a profile-based
category-ranking task. The JEX release consists of trained classifiers for 22
official EU languages, of parallel training data in the same languages, of an
interface that allows viewing and amending the assignment results, and of a
module that allows users to re-train the tool on their own document
collections. JEX allows advanced users to change the document representation so
as to possibly improve the categorisation result through linguistic
pre-processing. JEX can be used as a tool for interactive EuroVoc descriptor
assignment to increase speed and consistency of the human categorisation
process, or it can be used fully automatically. The output of JEX is a
language-independent EuroVoc feature vector lending itself also as input to
various other Language Technology tasks, including cross-lingual clustering and
classification, cross-lingual plagiarism detection, sentence selection and
ranking, and more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5226</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5226</id><created>2013-09-20</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Eisele</keyname><forenames>Andreas</forenames></author><author><keyname>Klocek</keyname><forenames>Szymon</forenames></author><author><keyname>Pilos</keyname><forenames>Spyridon</forenames></author><author><keyname>Schl&#xfc;ter</keyname><forenames>Patrick</forenames></author></authors><title>DGT-TM: A freely Available Translation Memory in 22 Languages</title><categories>cs.CL</categories><acm-class>I.2.7</acm-class><journal-ref>Proceedings of the 8th international conference on Language
  Resources and Evaluation (LREC'2012), pp. 454-459, Istanbul, 21-27 May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The European Commission's (EC) Directorate General for Translation, together
with the EC's Joint Research Centre, is making available a large translation
memory (TM; i.e. sentences and their professionally produced translations)
covering twenty-two official European Union (EU) languages and their 231
language pairs. Such a resource is typically used by translation professionals
in combination with TM software to improve speed and consistency of their
translations. However, this resource has also many uses for translation studies
and for language technology applications, including Statistical Machine
Translation (SMT), terminology extraction, Named Entity Recognition (NER),
multilingual classification and clustering, and many more. In this reference
paper for DGT-TM, we introduce this new resource, provide statistics regarding
its size, and explain how it was produced and how to use it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5247</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5247</id><created>2013-09-20</created><authors><author><keyname>Karpuk</keyname><forenames>David A.</forenames></author><author><keyname>Hollanti</keyname><forenames>Camilla</forenames></author></authors><title>Rotating Non-Uniform and High-Dimensional Constellations Using Geodesic
  Flow on Lie Groups</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use a numerical algorithm on the Lie group of rotation matrices to obtain
rotated constellations for Rayleigh fading channels. Our approach minimizes the
union bound for the pairwise error probability to produce rotations optimized
for a given signal-to-noise ratio. This approach circumvents explicit
parametrization of rotation matrices, which has previously prevented robust
numerical methods from being applied to constellation rotation. Our algorithm
is applicable to arbitrary finite constellations in arbitrary dimensions, and
one can thus apply our method to non-uniform constellations, which are of
interest for practical concerns due to their ability to increase BICM capacity.
We show how our rotations can improve the codeword error performance of
non-uniform constellations, and we also apply our method to reproduce and
improve rotations given by ideal lattices in cyclotomic fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5255</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5255</id><created>2013-09-20</created><authors><author><keyname>Mishra</keyname><forenames>Dheerendra</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Sourav</forenames></author></authors><title>Cryptanalysis of Wu and Xu's authentication scheme for Telecare Medicine
  Information Systems</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote user authentication is desirable for a Telecare medicine information
system (TMIS) to verify the correctness of remote users. In 2013, Jiang et al.
proposed privacy preserving authentication scheme for TMIS. Recently, Wu and Xu
analyzed Jiang's scheme and identify serious security flaws in their scheme,
namely, user impersonation attack, DoS attack and off-line password guessing
attack. In this article, we analyze Wu and Xu's scheme and show that their
scheme is also vulnerable to off-line password guessing attack and does not
protect user anonymity. Moreover, we identify the inefficiency of incorrect
input detection of the login phase in Wu and Xu's scheme, where the smart card
executes the login session in-spite of wrong input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5256</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5256</id><created>2013-09-20</created><authors><author><keyname>Strotmann</keyname><forenames>Andreas</forenames></author><author><keyname>Bleier</keyname><forenames>Arnim</forenames></author></authors><title>Author Name Co-Mention Analysis: Testing a Poor Man's Author Co-Citation
  Analysis Method</title><categories>cs.DL</categories><comments>14th International Society of Scientometrics and Informetrics
  Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a social science information service for the German language countries, we
document research projects, publications, and data in relevant fields. At the
same time, we aim to provide well-founded bibliometric studies of these fields.
Performing a citation analysis on an area of the German social sciences is,
however, a serious challenge given the low and likely significantly biased
coverage of these fields in the standard citation databases. Citations, and
especially author citations, play a highly significant role in that literature,
however. In this work in progress, we report preliminary methods and results
for an author name co-mention analysis of a large fragment of a particularly
interesting corpus of German sociology: a quarter century's worth of the
full-text proceedings of the Deutsche Gesellschaft fuer Soziologie (DGS), which
celebrated its 100th anniversary meeting in 2012. Results are encouraging for
this poor cousin of author co-citation analysis, but considerable refinements,
especially of the underlying computational infrastructure for full-text
analysis, appear advisable for full-scale deployment of this method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5262</identifier>
 <datestamp>2014-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5262</id><created>2013-09-20</created><updated>2014-03-21</updated><authors><author><keyname>Barbero</keyname><forenames>&#xc1;ngela I.</forenames></author><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author><author><keyname>Yang</keyname><forenames>Guang</forenames></author><author><keyname>Ytrehus</keyname><forenames>&#xd8;yvind</forenames></author></authors><title>Near-Field Passive RFID Communication: Channel Model and Code Design</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications. Accepted March 5,
  2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses a new channel model and code design for the
reader-to-tag channel in near-field passive radio frequency identification
(RFID) systems using inductive coupling as a power transfer mechanism. If the
receiver resynchronizes its internal clock each time a bit is detected, the
bit-shift channel used previously in the literature to model the reader-to-tag
channel needs to be modified. In particular, we propose a discretized Gaussian
shift channel as a new channel model in this scenario. We introduce the concept
of quantifiable error avoidance, which is much simpler than error correction.
The capacity is computed numerically, and we also design some new simple codes
for error avoidance on this channel model based on insights gained from the
capacity calculations. Finally, some simulation results are presented to
compare the proposed codes to the Manchester code and two previously proposed
codes for the bit-shift channel model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5275</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5275</id><created>2013-09-20</created><updated>2013-10-01</updated><authors><author><keyname>Stowell</keyname><forenames>Dan</forenames></author><author><keyname>Plumbley</keyname><forenames>Mark D.</forenames></author></authors><title>An open dataset for research on audio field recording archives:
  freefield1010</title><categories>cs.SD cs.DL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We introduce a free and open dataset of 7690 audio clips sampled from the
field-recording tag in the Freesound audio archive. The dataset is designed for
use in research related to data mining in audio archives of field recordings /
soundscapes. Audio is standardised, and audio and metadata are Creative Commons
licensed. We describe the data preparation process, characterise the dataset
descriptively, and illustrate its use through an auto-tagging experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5290</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5290</id><created>2013-09-20</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames></author><author><keyname>van der Goot</keyname><forenames>Erik</forenames></author></authors><title>An introduction to the Europe Media Monitor family of applications</title><categories>cs.CL</categories><acm-class>H.3.1; H.3.3; I.2.7</acm-class><journal-ref>In: Fredric Gey, Noriko Kando &amp; Jussi Karlgren (eds.): Information
  Access in a Multilingual World - Proceedings of the SIGIR 2009 Workshop
  (SIGIR-CLIR'2009), pp. 1-8. Boston, USA. 23 July 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most large organizations have dedicated departments that monitor the media to
keep up-to-date with relevant developments and to keep an eye on how they are
represented in the news. Part of this media monitoring work can be automated.
In the European Union with its 23 official languages, it is particularly
important to cover media reports in many languages in order to capture the
complementary news content published in the different countries. It is also
important to be able to access the news content across languages and to merge
the extracted information. We present here the four publicly accessible systems
of the Europe Media Monitor (EMM) family of applications, which cover between
19 and 50 languages (see http://press.jrc.it/overview.html). We give an
overview of their functionality and discuss some of the implications of the
fact that they cover quite so many languages. We discuss design issues
necessary to be able to achieve this high multilinguality, as well as the
benefits of this multilinguality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5292</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5292</id><created>2013-09-20</created><authors><author><keyname>Horak</keyname><forenames>Peter</forenames></author><author><keyname>Tuza</keyname><forenames>Zsolt</forenames></author></authors><title>Speeding up Deciphering by Hypergraph Ordering</title><categories>cs.CR math.CO</categories><msc-class>94A60 (05C65, 68Q25)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The &quot;Gluing Algorithm&quot; of Semaev [Des.\ Codes Cryptogr.\ 49 (2008), 47--60]
--- that finds all solutions of a sparse system of linear equations over the
Galois field $GF(q)$ --- has average running time $O(mq^{\max \left\vert
\cup_{1}^{k}X_{j}\right\vert -k}), $ where $m$ is the total number of
equations, and $\cup_{1}^{k}X_{j}$ is the set of all unknowns actively
occurring in the first $k$ equations. Our goal here is to minimize the exponent
of $q$ in the case where every equation contains at most three unknowns.
%Applying hypergraph-theoretic methods we prove The main result states that if
the total number $\left\vert \cup_{1}^{m}X_{j}\right\vert$ of unknowns is equal
to $m$, then the best achievable exponent is between $c_1m$ and $c_2m$ for some
positive constants $c_1$ and $c_2.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5301</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5301</id><created>2013-09-20</created><updated>2014-03-04</updated><authors><author><keyname>Herlihy</keyname><forenames>Maurice</forenames></author><author><keyname>Liu</keyname><forenames>Zhiyu</forenames></author></authors><title>Well-Structured Futures and Cache Locality</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In \emph{fork-join parallelism}, a sequential program is split into a
directed acyclic graph of tasks linked by directed dependency edges, and the
tasks are executed, possibly in parallel, in an order consistent with their
dependencies. A popular and effective way to extend fork-join parallelism is to
allow threads to create \emph{futures}. A thread creates a future to hold the
results of a computation, which may or may not be executed in parallel. That
result is returned when some thread \emph{touches} that future, blocking if
necessary until the result is ready.
  Recent research has shown that while futures can, of course, enhance
parallelism in a structured way, they can have a deleterious effect on cache
locality. In the worst case, futures can incur $\Omega(P T_\infty + t
T_\infty)$ deviations, which implies $\Omega(C P T_\infty + C t T_\infty)$
additional cache misses, where $C$ is the number of cache lines, $P$ is the
number of processors, $t$ is the number of touches, and $T_\infty$ is the
\emph{computation span}. Since cache locality has a large impact on software
performance on modern multicores, this result is troubling.
  In this paper, however, we show that if futures are used in a simple,
disciplined way, then the situation is much better: if each future is touched
only once, either by the thread that created it, or by a later descendant of
the thread that created it, then parallel executions with work stealing can
incur at most $O(C P T^2_\infty)$ additional cache misses, a substantial
improvement. This structured use of futures is characteristic of many (but not
all) parallel applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5304</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5304</id><created>2013-09-20</created><authors><author><keyname>Tanaskovic</keyname><forenames>M.</forenames></author><author><keyname>Fagiano</keyname><forenames>L.</forenames></author><author><keyname>Smith</keyname><forenames>R. S.</forenames></author><author><keyname>Morari</keyname><forenames>M.</forenames></author></authors><title>Adaptive model predictive control with exploring property for
  constrained linear systems that uses basis function model parametrization</title><categories>cs.SY math.OC</categories><comments>The material contained in this manuscript is part of a paper
  submitted for possible publication on the Automatica and is subject to IFAC
  Copyright. If accepted, the copy of record will be available at Elsevier</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript contains technical details of recent results developed by the
authors on adaptive model predictive control for constrained linear systems
that exhibits exploring property and uses basis function model parametrization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5310</identifier>
 <datestamp>2015-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5310</id><created>2013-09-20</created><updated>2015-04-28</updated><authors><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Conditioning of Random Block Subdictionaries with Applications to
  Block-Sparse Recovery and Regression</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>38 pages, 3 figures; to appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear model, in which a set of observations is assumed to be given by a
linear combination of columns of a matrix, has long been the mainstay of the
statistics and signal processing literature. One particular challenge for
inference under linear models is understanding the conditions on the dictionary
under which reliable inference is possible. This challenge has attracted
renewed attention in recent years since many modern inference problems deal
with the &quot;underdetermined&quot; setting, in which the number of observations is much
smaller than the number of columns in the dictionary. This paper makes several
contributions for this &quot;block-sparse&quot; setting when the set of observations is
given by a linear combination of a small number of groups of columns of the
dictionary. First, it specifies conditions on the dictionary under which most
block subdictionaries are well conditioned. This result is fundamentally
different from prior work on block-sparse inference because (i) it provides
conditions that can be explicitly computed in polynomial time, (ii) the given
conditions translate into near-optimal scaling of the number of columns of the
block subdictionaries as a function of the number of observations for a large
class of dictionaries, and (iii) it suggests that the spectral norm, rather
than the column/block coherences, of the dictionary fundamentally limits the
scaling of dimensions of the well-conditioned block subdictionaries. Second,
this paper investigates the problems of block-sparse recovery and block-sparse
regression in underdetermined settings. Near-optimal block-sparse recovery and
block-sparse regression is possible for a large class of dictionaries as long
as the dictionary satisfies easily computable conditions and the coefficients
describing the linear combination of groups of columns can be modeled through a
mild statistical prior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5314</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5314</id><created>2013-09-20</created><updated>2013-11-20</updated><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Miasnikov</keyname><forenames>Alexei</forenames></author><author><keyname>Wei&#xdf;</keyname><forenames>Armin</forenames></author></authors><title>Conjugacy in Baumslag's group, generic case complexity, and division in
  power circuits</title><categories>cs.DM math.GR</categories><comments>Section 5 added: We show that an HNN extension G = &lt; H, b | bab^-1 =
  {\phi}(a), a \in A &gt; has a non-amenable Schreier graph with respect to the
  base group H if and only if A \neq H \neq B</comments><acm-class>G.2.1; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conjugacy problem belongs to algorithmic group theory. It is the
following question: given two words x, y over generators of a fixed group G,
decide whether x and y are conjugated, i.e., whether there exists some z such
that zxz^{-1} = y in G. The conjugacy problem is more difficult than the word
problem, in general. We investigate the complexity of the conjugacy problem for
two prominent groups: the Baumslag-Solitar group BS(1,2) and the
Baumslag(-Gersten) group G(1,2). The conjugacy problem in BS(1,2) is
TC^0-complete. To the best of our knowledge BS(1,2) is the first natural
infinite non-commutative group where such a precise and low complexity is
shown. The Baumslag group G(1,2) is an HNN-extension of BS(1,2). We show that
the conjugacy problem is decidable (which has been known before); but our
results go far beyond decidability. In particular, we are able to show that
conjugacy in G(1,2) can be solved in polynomial time in a strongly generic
setting. This means that essentially for all inputs conjugacy in G(1,2) can be
decided efficiently. In contrast, we show that under a plausible assumption the
average case complexity of the same problem is non-elementary. Moreover, we
provide a lower bound for the conjugacy problem in G(1,2) by reducing the
division problem in power circuits to the conjugacy problem in G(1,2). The
complexity of the division problem in power circuits is an open and interesting
problem in integer arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5316</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5316</id><created>2013-09-20</created><authors><author><keyname>Th&#xe9;baut</keyname><forenames>Aur&#xe9;lie</forenames><affiliation>MISTEA</affiliation></author><author><keyname>Scholash</keyname><forenames>Thibault</forenames><affiliation>MISTEA</affiliation></author><author><keyname>Charnomordic</keyname><forenames>Brigitte</forenames><affiliation>MISTEA</affiliation></author><author><keyname>Hilgert</keyname><forenames>Nadine</forenames><affiliation>MISTEA</affiliation></author></authors><title>A modeling approach to design a software sensor and analyze agronomical
  features - Application to sap flow and grape quality relationship</title><categories>cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work proposes a framework using temporal data and domain knowledge in
order to analyze complex agronomical features. The expertise is first
formalized in an ontology, under the form of concepts and relationships between
them, and then used in conjunction with raw data and mathematical models to
design a software sensor. Next the software sensor outputs are put in relation
to product quality, assessed by quantitative measurements. This requires the
use of advanced data analysis methods, such as functional regression. The
methodology is applied to a case study involving an experimental design in
French vineyards. The temporal data consist of sap flow measurements, and the
goal is to explain fruit quality (sugar concentration and weight), using vine's
water courses through the various vine phenological stages. The results are
discussed, as well as the method genericity and robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5319</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5319</id><created>2013-09-20</created><authors><author><keyname>Moulin-Frier</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>INRIA Bordeaux - Sud-Ouest, GIPSA-lab</affiliation></author><author><keyname>Arbib</keyname><forenames>M. A.</forenames><affiliation>USC</affiliation></author></authors><title>Recognizing Speech in a Novel Accent: The Motor Theory of Speech
  Perception Reframed</title><categories>cs.CL cs.LG q-bio.NC</categories><proxy>ccsd</proxy><journal-ref>Biological Cybernetics 107, 4 (2013) 421-447</journal-ref><doi>10.1007/s00422-013-0557-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The motor theory of speech perception holds that we perceive the speech of
another in terms of a motor representation of that speech. However, when we
have learned to recognize a foreign accent, it seems plausible that recognition
of a word rarely involves reconstruction of the speech gestures of the speaker
rather than the listener. To better assess the motor theory and this
observation, we proceed in three stages. Part 1 places the motor theory of
speech perception in a larger framework based on our earlier models of the
adaptive formation of mirror neurons for grasping, and for viewing extensions
of that mirror system as part of a larger system for neuro-linguistic
processing, augmented by the present consideration of recognizing speech in a
novel accent. Part 2 then offers a novel computational model of how a listener
comes to understand the speech of someone speaking the listener's native
language with a foreign accent. The core tenet of the model is that the
listener uses hypotheses about the word the speaker is currently uttering to
update probabilities linking the sound produced by the speaker to phonemes in
the native language repertoire of the listener. This, on average, improves the
recognition of later words. This model is neutral regarding the nature of the
representations it uses (motor vs. auditory). It serve as a reference point for
the discussion in Part 3, which proposes a dual-stream neuro-linguistic
architecture to revisits claims for and against the motor theory of speech
perception and the relevance of mirror neurons, and extracts some implications
for the reframing of the motor theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5333</identifier>
 <datestamp>2013-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5333</id><created>2013-09-20</created><updated>2013-10-14</updated><authors><author><keyname>Zhuang</keyname><forenames>Hao</forenames></author><author><keyname>Weng</keyname><forenames>Shih-Hung</forenames></author><author><keyname>Cheng</keyname><forenames>Chung-Kuan</forenames></author></authors><title>Power Grid Simulation using Matrix Exponential Method with Rational
  Krylov Subspaces</title><categories>cs.CE cs.NA math.DS</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  One well adopted power grid simulation methodology is to factorize matrix
once and perform only backward forward substitution with a deliberately chosen
step size along the simulation. Since the required simulation time is usually
long for the power grid design, the costly factorization is amortized. However,
such fixed step size cannot exploit larger step size for the low frequency
response in the power grid to speedup the simulation. In this work, we utilize
the matrix exponential method with the rational Krylov subspace approximation
to enable adaptive step size in the power grid simulation. The kernel operation
in our method only demands one factorization and backward forward
substitutions. Moreover, the rational Krylov subspace approximation can relax
the stiffness constraint of the previous works. The cheap computation of
adaptivity in our method could exploit the long low frequency response in a
power grid and significantly accelerate the simulation. The experimental
results show that our method achieves up to 18X speedup over the trapezoidal
method with fixed step size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5336</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5336</id><created>2013-09-20</created><authors><author><keyname>Thomas</keyname><forenames>Robin</forenames></author><author><keyname>Whalen</keyname><forenames>Peter</forenames></author></authors><title>Odd K_3,3 subdivisions in bipartite graphs</title><categories>math.CO cs.DM</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that every internally 4-connected non-planar bipartite graph has an
odd K_3,3 subdivision; that is, a subgraph obtained from K_3,3 by replacing its
edges by internally disjoint odd paths with the same ends. The proof gives rise
to a polynomial-time algorithm to find such a subdivision. (A bipartite graph G
is internally 4-connected if it is 3-connected, has at least five vertices, and
there is no partition (A,B,C) of V(G) such that |A|,|B|&gt;1, |C|=3 and G has no
edge with one end in A and the other in B.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5344</identifier>
 <datestamp>2014-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5344</id><created>2013-09-20</created><updated>2014-01-31</updated><authors><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Du</keyname><forenames>Honglu</forenames></author><author><keyname>Freudiger</keyname><forenames>Julien</forenames></author><author><keyname>Norcie</keyname><forenames>Greg</forenames></author></authors><title>A Comparative Usability Study of Two-Factor Authentication</title><categories>cs.CR cs.HC</categories><comments>A preliminary version of this paper appears in USEC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-factor authentication (2F) aims to enhance resilience of password-based
authentication by requiring users to provide an additional authentication
factor, e.g., a code generated by a security token. However, it also introduces
non-negligible costs for service providers and requires users to carry out
additional actions during the authentication process. In this paper, we present
an exploratory comparative study of the usability of 2F technologies. First, we
conduct a pre-study interview to identify popular technologies as well as
contexts and motivations in which they are used. We then present the results of
a quantitative study based on a survey completed by 219 Mechanical Turk users,
aiming to measure the usability of three popular 2F solutions: codes generated
by security tokens, one-time PINs received via email or SMS, and dedicated
smartphone apps (e.g., Google Authenticator). We record contexts and
motivations, and study their impact on perceived usability. We find that 2F
technologies are overall perceived as usable, regardless of motivation and/or
context of use. We also present an exploratory factor analysis, highlighting
that three metrics -- ease-of-use, required cognitive efforts, and
trustworthiness -- are enough to capture key factors affecting 2F usability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5351</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5351</id><created>2013-09-02</created><authors><author><keyname>Navaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Fiaz</keyname><forenames>A. S. Syed</forenames></author><author><keyname>Prabhadevi</keyname><forenames>C.</forenames></author><author><keyname>Sangeetha</keyname><forenames>V.</forenames></author><author><keyname>Gopalakrishnan</keyname><forenames>S.</forenames></author></authors><title>Human Resource Management System</title><categories>cs.OH</categories><comments>10 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper titled HUMAN RESOURCE MANAGEMENT SYSTEM is basically concerned with
managing the Administrator of HUMAN RESOURCE Department in a company. A Human
Resource Management System, refers to the systems and processes at the
intersection between human resource management and information technology. It
merges HRM as a discipline and in particular its basic HR activities and
processes with the information technology field, whereas the programming of
data processing systems evolved into standardized routines and packages of
enterprise resource planning software. The main objective of this paper is to
reduce the effort of Administrator to keep the daily events such as attendance,
projects, works, appointments, etc. This paper deals with the process of
identifying the employees, recording their attendance hourly and calculating
their effective payable hours or days. This paper should maintain the records
of each and every employee and their time spend in to company, which can be
used for performance appraisal. Based on that transfer, removal, promotion can
be done.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5357</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5357</id><created>2013-08-16</created><authors><author><keyname>Dongre</keyname><forenames>Vikas J.</forenames></author><author><keyname>Mankar</keyname><forenames>Vijay H.</forenames></author></authors><title>Development of Comprehensive Devnagari Numeral and Character Database
  for Offline Handwritten Character Recognition</title><categories>cs.CV</categories><comments>5 pages, 8 figures, journal paper</comments><journal-ref>Vikas J. Dongre,Vijay H.Mankar, &quot;Development of Comprehensive
  Devnagari Numeral and Character Database for Offline Handwritten Character
  Recognition&quot;, Applied Computational Intelligence and Soft Computing,Volume
  2012</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In handwritten character recognition, benchmark database plays an important
role in evaluating the performance of various algorithms and the results
obtained by various researchers. In Devnagari script, there is lack of such
official benchmark. This paper focuses on the generation of offline benchmark
database for Devnagari handwritten numerals and characters. The present work
generated 5137 and 20305 isolated samples for numeral and character database,
respectively, from 750 writers of all ages, sex, education, and profession. The
offline sample images are stored in TIFF image format as it occupies less
memory. Also, the data is presented in binary level so that memory requirement
is further reduced. It will facilitate research on handwriting recognition of
Devnagari script through free access to the researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5372</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5372</id><created>2013-08-30</created><authors><author><keyname>Moore</keyname><forenames>Reagan W.</forenames></author></authors><title>Extensible Generic Data Management Software</title><categories>cs.DL cs.SE</categories><comments>4 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Extensibility mechanisms constitute a form of knowledge capture that is
essential for software re-use. The Data Intensive Cyber Environments (DICE)
group has collaborated with twenty-five science and engineering domains on the
application of the iRODS policy-based data management system. Based on these
collaborations, three types of extensibility mechanisms are sufficient to
capture the domain knowledge needed for interaction with domain resources:
computer actionable rules that control management policies; computer executable
micro-services that encapsulate operations or interaction protocols; and
middleware servers that apply standard operations at remote locations. These
mechanisms enable the creation of generic data management software that is
capable of implementing collections, data grids for sharing data, digital
libraries for publishing data, processing pipelines, and archives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5377</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5377</id><created>2013-09-06</created><authors><author><keyname>Girotto</keyname><forenames>Ivan</forenames></author><author><keyname>Kohlmeyer</keyname><forenames>Axel</forenames></author><author><keyname>Grellscheid</keyname><forenames>David</forenames></author><author><keyname>Brown</keyname><forenames>Shawn T.</forenames></author></authors><title>Advanced Techniques for Scientific Programming and Collaborative
  Development of Open Source Software Packages at the International Centre for
  Theoretical Physics (ICTP)</title><categories>cs.SE cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large number of computational scientific research projects make use of open
source software packages. However, the development process of such tools
frequently differs from conventional software development; partly because of
the nature of research, where the problems being addressed are not always fully
understood; partly because the majority of the development is often carried out
by scientists with limited experience and exposure to best practices of
software engineering. Often the software development suffers from the pressure
to publish scientific results and that credit for software development is
limited in comparison. Fundamental components of software engineering like
modular and reusable design, validation, documentation, and software
integration as well as effective maintenance and user support tend to be
disregarded due to lack of resources and qualified specialists. Thus innovative
developments are often hindered by steep learning curves required to master
development for legacy software packages full of ad hoc solutions. The growing
complexity of research, however, requires suitable and maintainable
computational tools, resulting in a widening gap between the potential users
(often growing in number) and contributors to the development of such a
package. In this paper we share our experiences aiming to improve the situation
by training particularly young scientists, through disseminating our own
experiences at contributing to open source software packages and practicing key
components of software engineering adapted for scientists and scientific
software development. Specifically we summarize the outcome of the Workshop in
Advanced Techniques for Scientific Programming and Collaborative Development of
Open Source Software Packages run at the Abdus Salam International Centre for
Theoretical Physics in March 2013, and discuss our conclusions for future
efforts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5390</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5390</id><created>2013-09-20</created><authors><author><keyname>Atanasov</keyname><forenames>Nikolay</forenames></author><author><keyname>Ny</keyname><forenames>Jerome Le</forenames></author><author><keyname>Daniilidis</keyname><forenames>Kostas</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author></authors><title>Information Acquisition with Sensing Robots: Algorithms and Error Bounds</title><categories>cs.SY cs.RO math.DS math.OC</categories><comments>9 pages (two-column); 2 figures; Manuscript submitted to the 2014
  IEEE International Conference on Robotics and Automation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Utilizing the capabilities of configurable sensing systems requires
addressing difficult information gathering problems. Near-optimal approaches
exist for sensing systems without internal states. However, when it comes to
optimizing the trajectories of mobile sensors the solutions are often greedy
and rarely provide performance guarantees. Notably, under linear Gaussian
assumptions, the problem becomes deterministic and can be solved off-line.
Approaches based on submodularity have been applied by ignoring the sensor
dynamics and greedily selecting informative locations in the environment. This
paper presents a non-greedy algorithm with suboptimality guarantees, which does
not rely on submodularity and takes the sensor dynamics into account. Our
method performs provably better than the widely used greedy one. Coupled with
linearization and model predictive control, it can be used to generate adaptive
policies for mobile sensors with non-linear sensing models. Applications in gas
concentration mapping and target tracking are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5391</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5391</id><created>2013-09-20</created><authors><author><keyname>Mohammad</keyname><forenames>Saif M.</forenames></author></authors><title>Even the Abstract have Colour: Consensus in Word-Colour Associations</title><categories>cs.CL</categories><comments>Even the Abstract have Colour: Consensus in Word-Colour Associations,
  Saif Mohammad, In Proceedings of the 49th Annual Meeting of the Association
  for Computational Linguistics: Human Language Technologies, June 2011,
  Portland, OR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colour is a key component in the successful dissemination of information.
Since many real-world concepts are associated with colour, for example danger
with red, linguistic information is often complemented with the use of
appropriate colours in information visualization and product marketing. Yet,
there is no comprehensive resource that captures concept-colour associations.
We present a method to create a large word-colour association lexicon by
crowdsourcing. A word-choice question was used to obtain sense-level
annotations and to ensure data quality. We focus especially on abstract
concepts and emotions to show that even they tend to have strong colour
associations. Thus, using the right colours can not only improve semantic
coherence, but also inspire the desired emotional response.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5393</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5393</id><created>2013-09-13</created><authors><author><keyname>Mishra</keyname><forenames>Umakant</forenames></author></authors><title>How to Implement Access Rights in an MIS Project</title><categories>cs.CR</categories><comments>15 pages, 8 figures, Available at SSRN:
  http://ssrn.com/abstract=2315570</comments><journal-ref>Mishra, Umakant, How to Implement Access Rights in an MIS Project
  (August 24, 2013)</journal-ref><doi>10.2139/ssrn.2315570</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MIS data is critical to an organization and should be protected from
misuse by wrong persons. Although The MIS data is typically meant for the
senior managers each MIS report may not be required by every manager. The
access to MIS data is determined by the role of an individual in the
organization and controlled by the MIS administrator accordingly. The access is
generally determined by the following parameters, (a) the type of user (such as
staff or manager etc.), (b) the type of data (whether general data or
managerial data), (c) level of access (read/ write/ admin access) and (d)
special access allocated by MIS admin. By combining all the above four
parameters, each individual user can be allocated exact specific rights
required to access the MIS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5396</identifier>
 <datestamp>2014-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5396</id><created>2013-09-20</created><updated>2014-07-15</updated><authors><author><keyname>Geng</keyname><forenames>Jun</forenames></author><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Lai</keyname><forenames>Lifeng</forenames></author></authors><title>Bayesian Quickest Change Point Detection with Sampling Right Constraints</title><categories>cs.IT math.IT</categories><comments>18 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Bayesian quickest change detection problems with sampling
right constraints are considered. Specifically, there is a sequence of random
variables whose probability density function will change at an unknown time.
The goal is to detect this change in a way such that a linear combination of
the average detection delay and the false alarm probability is minimized. Two
types of sampling right constrains are discussed. The first one is a limited
sampling right constraint, in which the observer can take at most $N$
observations from this random sequence. Under this setup, we show that the cost
function can be written as a set of iterative functions, which can be solved by
Markov optimal stopping theory. The optimal stopping rule is shown to be a
threshold rule. An asymptotic upper bound of the average detection delay is
developed as the false alarm probability goes to zero. This upper bound
indicates that the performance of the limited sampling right problem is close
to that of the classic Bayesian quickest detection for several scenarios of
practical interest. The second constraint discussed in this paper is a
stochastic sampling right constraint, in which sampling rights are consumed by
taking observations and are replenished randomly. The observer cannot take
observations if there are no sampling rights left. We characterize the optimal
solution, which has a very complex structure. For practical applications, we
propose a low complexity algorithm, in which the sampling rule is to take
observations as long as the observer has sampling rights left and the detection
scheme is a threshold rule. We show that this low complexity scheme is first
order asymptotically optimal as the false alarm probability goes to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5401</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5401</id><created>2013-09-20</created><authors><author><keyname>Atanasov</keyname><forenames>Nikolay</forenames></author><author><keyname>Sankaran</keyname><forenames>Bharath</forenames></author><author><keyname>Ny</keyname><forenames>Jerome Le</forenames></author><author><keyname>Pappas</keyname><forenames>George J.</forenames></author><author><keyname>Daniilidis</keyname><forenames>Kostas</forenames></author></authors><title>Nonmyopic View Planning for Active Object Detection</title><categories>cs.RO cs.CV cs.SY</categories><comments>12 pages (two-column); 7 figures; 2 tables; Manuscript submitted to
  the IEEE Transactions on Robotics (TRO)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the central problems in computer vision is the detection of
semantically important objects and the estimation of their pose. Most of the
work in object detection has been based on single image processing and its
performance is limited by occlusions and ambiguity in appearance and geometry.
This paper proposes an active approach to object detection by controlling the
point of view of a mobile depth camera. When an initial static detection phase
identifies an object of interest, several hypotheses are made about its class
and orientation. The sensor then plans a sequence of views, which balances the
amount of energy used to move with the chance of identifying the correct
hypothesis. We formulate an active hypothesis testing problem, which includes
sensor mobility, and solve it using a point-based approximate POMDP algorithm.
The validity of our approach is verified through simulation and real-world
experiments with the PR2 robot. The results suggest that our approach
outperforms the widely-used greedy view point selection and provides a
significant improvement over static object detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5405</identifier>
 <datestamp>2014-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5405</id><created>2013-09-20</created><updated>2014-12-04</updated><authors><author><keyname>Kinnersley</keyname><forenames>William B.</forenames></author></authors><title>Cops and Robbers is EXPTIME-complete</title><categories>math.CO cs.CC cs.DM</categories><comments>v2: updated figures and slightly clarified some minor points</comments><msc-class>05C57 (Primary), 05C85 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the computational complexity of deciding whether k cops can
capture a robber on a graph G. In 1995, Goldstein and Reingold conjectured that
the problem is EXPTIME-complete when both G and k are part of the input; we
prove this conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5406</identifier>
 <datestamp>2014-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5406</id><created>2013-09-20</created><updated>2014-11-07</updated><authors><author><keyname>Cartis</keyname><forenames>Coralia</forenames></author><author><keyname>Thompson</keyname><forenames>Andrew</forenames></author></authors><title>A new and improved quantitative recovery analysis for iterative hard
  thresholding algorithms in compressed sensing</title><categories>math.NA cs.IT math.IT</categories><msc-class>65K99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new recovery analysis for a standard compressed sensing
algorithm, Iterative Hard Thresholding (IHT) (Blumensath and Davies, 2008),
which considers the fixed points of the algorithm. In the context of arbitrary
measurement matrices, we derive a sufficient condition for convergence of IHT
to a fixed point and a necessary condition for the existence of fixed points.
These conditions allow us to perform a sparse signal recovery analysis in the
deterministic noiseless case by implying that the original sparse signal is the
unique fixed point and limit point of IHT, and in the case of Gaussian
measurement matrices and noise by generating a bound on the approximation error
of the IHT limit as a multiple of the noise level. By generalizing the notion
of fixed points, we extend our analysis to the variable stepsize Normalised IHT
(N-IHT) (Blumensath and Davies, 2010). For both stepsize schemes, we obtain
lower bounds on asymptotic phase transitions in a proportional-dimensional
framework, quantifying the sparsity/undersampling trade-off for which recovery
is guaranteed. Exploiting the reasonable average-case assumption that the
underlying signal and measurement matrix are independent, comparison with
previous results within this framework shows a substantial quantitative
improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5413</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5413</id><created>2013-09-20</created><updated>2015-11-16</updated><authors><author><keyname>Huber</keyname><forenames>Mark</forenames></author></authors><title>An unbiased estimate for the mean of a {0,1} random variable with
  relative error distribution independent of the mean</title><categories>math.ST cs.CC math.PR stat.TH</categories><comments>12 pages; 0 figures</comments><msc-class>62F10, 62F25,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Say $X_1,X_2,\ldots$ are independent identically distributed Bernoulli random
variables with mean $p$. This paper builds a new estimate $\hat p$ of $p$ that
has the property that the relative error, $\hat p /p - 1$, of the estimate does
not depend in any way on the value of $p$. This allows the construction of
exact confidence intervals for $p$ of any desired level without needing any
sort of limit or approximation. In addition, $\hat p$ is unbiased. For
$\epsilon$ and $\delta$ in $(0,1)$, to obtain an estimate where
$\mathbb{P}(|\hat p/p - 1| &gt; \epsilon) \leq \delta$, the new algorithm takes on
average at most $2\epsilon^{-2} p^{-1}\ln(2\delta^{-1})(1 - (14/3)
\epsilon)^{-1}$ samples. It is also shown that any such algorithm that applies
whenever $p \leq 1/2$ requires at least $0.2\epsilon^{-2}
p^{-1}\ln((2-\delta)\delta^{-1})(1 + 2 \epsilon)$ samples. The same algorithm
can also be applied to estimate the mean of any random variable that falls in
$[0,1]$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5414</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5414</id><created>2013-09-20</created><updated>2014-11-21</updated><authors><author><keyname>Lessard</keyname><forenames>Laurent</forenames></author><author><keyname>Lall</keyname><forenames>Sanjay</forenames></author></authors><title>An Algebraic Approach to the Control of Decentralized Systems</title><categories>cs.SY math.OC math.RA</categories><journal-ref>IEEE Transactions on Control of Network Systems, Vol.1(4),
  pp.1-10, Dec. 2014</journal-ref><doi>10.1109/TCNS.2014.2357501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal decentralized controller design is notoriously difficult, but recent
research has identified large subclasses of such problems that may be
convexified and thus are amenable to solution via efficient numerical methods.
One recently discovered sufficient condition for convexity is quadratic
invariance (QI). Despite the simple algebraic characterization of QI, which
relates the plant and controller maps, proving convexity of the set of
achievable closed-loop maps requires tools from functional analysis. In this
work, we present a new formulation of quadratic invariance that is purely
algebraic. While our results are similar in flavor to those from traditional QI
theory, they do not follow from that body of work. Furthermore, they are
applicable to new types of systems that are difficult to treat using functional
analysis. Examples discussed include rational transfer matrices, systems with
delays, and multidimensional systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5422</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5422</id><created>2013-09-20</created><updated>2014-02-02</updated><authors><author><keyname>Caliskan</keyname><forenames>Sina Y.</forenames></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>Compositional Transient Stability Analysis of Multi-Machine Power
  Networks</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the normal operation of a power system all the voltages and currents
are sinusoids with a frequency of 60 Hz in America and parts of Asia, or of
50Hz in the rest of the world. Forcing all the currents and voltages to be
sinusoids with the right frequency is one of the most important problems in
power systems. This problem is known as the transient stability problem in the
power systems literature.
  The classical models used to study transient stability are based on several
implicit assumptions that are violated when transients occur. One such
assumption is the use of phasors to study transients. While phasors require
sinusoidal waveforms to be well defined, there is no guarantee that waveforms
will remain sinusoidal during transients. In this paper, we use energy-based
models derived from first principles that are not subject to hard-to-justify
classical assumptions. In addition to eliminate assumptions that are known not
to hold during transient stages, we derive intuitive conditions ensuring the
transient stability of power systems with lossy transmission lines.
Furthermore, the conditions for transient stability are compositional in the
sense that one infers transient stability of a large power system by checking
simple conditions for individual generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5427</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5427</id><created>2013-09-20</created><authors><author><keyname>Chen</keyname><forenames>Gang</forenames></author></authors><title>Latent Fisher Discriminant Analysis</title><categories>cs.LG cs.CV stat.ML</categories><comments>12 pages</comments><acm-class>I.2.10</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Linear Discriminant Analysis (LDA) is a well-known method for dimensionality
reduction and classification. Previous studies have also extended the
binary-class case into multi-classes. However, many applications, such as
object detection and keyframe extraction cannot provide consistent
instance-label pairs, while LDA requires labels on instance level for training.
Thus it cannot be directly applied for semi-supervised classification problem.
In this paper, we overcome this limitation and propose a latent variable Fisher
discriminant analysis model. We relax the instance-level labeling into
bag-level, is a kind of semi-supervised (video-level labels of event type are
required for semantic frame extraction) and incorporates a data-driven prior
over the latent variables. Hence, our method combines the latent variable
inference and dimension reduction in an unified bayesian framework. We test our
method on MUSK and Corel data sets and yield competitive results compared to
the baseline approach. We also demonstrate its capacity on the challenging
TRECVID MED11 dataset for semantic keyframe extraction and conduct a
human-factors ranking-based experimental evaluation, which clearly demonstrates
our proposed method consistently extracts more semantically meaningful
keyframes than challenging baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5439</identifier>
 <datestamp>2015-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5439</id><created>2013-09-21</created><updated>2015-10-30</updated><authors><author><keyname>Bruy&#xe8;re</keyname><forenames>V&#xe9;ronique</forenames></author><author><keyname>Filiot</keyname><forenames>Emmanuel</forenames></author><author><keyname>Randour</keyname><forenames>Mickael</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Meet Your Expectations With Guarantees: Beyond Worst-Case Synthesis in
  Quantitative Games</title><categories>cs.GT cs.FL cs.LO</categories><comments>Extended version. Journal version published in Information and
  Computation, conference version published in STACS 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the quantitative synthesis framework by going beyond the
worst-case. On the one hand, classical analysis of two-player games involves an
adversary (modeling the environment of the system) which is purely antagonistic
and asks for strict guarantees. On the other hand, stochastic models like
Markov decision processes represent situations where the system is faced to a
purely randomized environment: the aim is then to optimize the expected payoff,
with no guarantee on individual outcomes. We introduce the beyond worst-case
synthesis problem, which is to construct strategies that guarantee some
quantitative requirement in the worst-case while providing an higher expected
value against a particular stochastic model of the environment given as input.
This problem is relevant to produce system controllers that provide nice
expected performance in the everyday situation while ensuring a strict (but
relaxed) performance threshold even in the event of very bad (while unlikely)
circumstances. We study the beyond worst-case synthesis problem for two
important quantitative settings: the mean-payoff and the shortest path. In both
cases, we show how to decide the existence of finite-memory strategies
satisfying the problem and how to synthesize one if one exists. We establish
algorithms and we study complexity bounds and memory requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5440</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5440</id><created>2013-09-21</created><authors><author><keyname>Permuter</keyname><forenames>Haim H.</forenames></author><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Capacity of a POST Channel with and without Feedback</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider finite state channels where the state of the channel is its
previous output. We refer to these as POST (Previous Output is the STate)
channels. We first focus on POST($\alpha$) channels. These channels have binary
inputs and outputs, where the state determines if the channel behaves as a $Z$
or an $S$ channel, both with parameter $\alpha$. %with parameter $\alpha.$ We
show that the non feedback capacity of the POST($\alpha$) channel equals its
feedback capacity, despite the memory of the channel. The proof of this
surprising result is based on showing that the induced output distribution,
when maximizing the directed information in the presence of feedback, can also
be achieved by an input distribution that does not utilize of the feedback. We
show that this is a sufficient condition for the feedback capacity to equal the
non feedback capacity for any finite state channel. We show that the result
carries over from the POST($\alpha$) channel to a binary POST channel where the
previous output determines whether the current channel will be binary with
parameters $(a,b)$ or $(b,a)$. Finally, we show that, in general, feedback may
increase the capacity of a POST channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5442</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5442</id><created>2013-09-21</created><authors><author><keyname>Spillner</keyname><forenames>Josef</forenames></author><author><keyname>Chaichenko</keyname><forenames>Andrii</forenames></author><author><keyname>Brito</keyname><forenames>Andrey</forenames></author><author><keyname>Brasileiro</keyname><forenames>Francisco</forenames></author><author><keyname>Schill</keyname><forenames>Alexander</forenames></author></authors><title>Operating the Cloud from Inside Out</title><categories>cs.DC</categories><comments>5 pages, 9 figures, 1 table. Presented at the HPI Cloud Symposium,
  Potsdam, Germany, September 2013</comments><acm-class>C.2.4; D.4.8; H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual machine images and instances (VMs) in cloud computing centres are
typically designed as isolation containers for applications, databases and
networking functions. In order to build complex distributed applications,
multiple virtual machines must be connected, orchestrated and combined with
platform and infrastructure services from the hosting environment. There are
several reasons why sometimes it is beneficial to introduce a new layer,
Cloud-in-a-VM, which acts as a portable management interface to a cluster of
VMs. We reason about the benefits and present our Cloud-in-a-VM implementation
called Nested Cloud which allows consumers to become light-weight cloud
operators on demand and reap multiple advantages, including fully utilised
resource allocations. The practical usefulness and the performance of the
intermediate cloud stack VM are evaluated in a marketplace scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5450</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5450</id><created>2013-09-21</created><authors><author><keyname>Bialonski</keyname><forenames>Stephan</forenames></author><author><keyname>Lehnertz</keyname><forenames>Klaus</forenames></author></authors><title>Assortative mixing in functional brain networks during epileptic
  seizures</title><categories>physics.data-an cs.SI physics.comp-ph physics.soc-ph</categories><comments>10 pages, 3 figures</comments><journal-ref>Chaos 23, 033139 (2013)</journal-ref><doi>10.1063/1.4821915</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate assortativity of functional brain networks before, during, and
after one-hundred epileptic seizures with different anatomical onset locations.
We construct binary functional networks from multi-channel
electroencephalographic data recorded from 60 epilepsy patients, and from
time-resolved estimates of the assortativity coefficient we conclude that
positive degree-degree correlations are inherent to seizure dynamics. While
seizures evolve, an increasing assortativity indicates a segregation of the
underlying functional network into groups of brain regions that are only
sparsely interconnected, if at all. Interestingly, assortativity decreases
already prior to seizure end. Together with previous observations of
characteristic temporal evolutions of global statistical properties and
synchronizability of epileptic brain networks, our findings may help to gain
deeper insights into the complicated dynamics underlying generation,
propagation, and termination of seizures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5457</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5457</id><created>2013-09-21</created><authors><author><keyname>Gajbhiye</keyname><forenames>Shweta</forenames></author><author><keyname>Karmore</keyname><forenames>S. P.</forenames></author></authors><title>Cable Fault Monitoring and Indication: A Review</title><categories>cs.DC</categories><comments>05 pages, 05 figures, IJCSN Journal, Vol 2, Issue 4, August 2013
  IJCSN - International Journal of Computer Science and Network (August 2013)</comments><report-no>IJCSN-2013-2-4-25</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Underground cable power transmission and distribution system are susceptible
to faults. Accurate fault location for transmission lines is of vital
importance. A quick detection and analysis of faults is necessity of power
retailers and distributors. This paper reviews various fault locating methods
and highly computational methods proposed by research community that are
currently in use. The paper also presents some guidelines for design of fault
location and remote indication, for reducing power outages and reducing heavy
loss of revenue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5459</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5459</id><created>2013-09-21</created><authors><author><keyname>Uddin</keyname><forenames>Irfan</forenames></author></authors><title>Advances in computer architecture</title><categories>cs.AR</categories><comments>12 Pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the past, efforts were taken to improve the performance of a processor via
frequency scaling. However, industry has reached the limits of increasing the
frequency and therefore concurrent execution of instructions on multiple cores
seems the only possible option. It is not enough to provide concurrent
execution by the hardware, software also have to introduce concurrency in order
to exploit the parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5461</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5461</id><created>2013-09-21</created><updated>2014-08-18</updated><authors><author><keyname>Bishnu</keyname><forenames>Arijit</forenames></author><author><keyname>Ghosh</keyname><forenames>Arijit</forenames></author><author><keyname>Paul</keyname><forenames>Subhabrata</forenames></author></authors><title>Linear kernels for k-tuple and liar's domination in bounded genus graphs</title><categories>cs.CC cs.DS</categories><comments>Title changed from &quot;Parameterized complexity of k-tuple and liar's
  domination&quot; to &quot;Linear kernels for k-tuple and liar's domination in bounded
  genus graphs&quot;</comments><msc-class>05C69, 05C85</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A set $D\subseteq V$ is called a $k$-tuple dominating set of a graph
$G=(V,E)$ if $\left| N_G[v] \cap D \right| \geq k$ for all $v \in V$, where
$N_G[v]$ denotes the closed neighborhood of $v$. A set $D \subseteq V$ is
called a liar's dominating set of a graph $G=(V,E)$ if (i) $\left| N_G[v] \cap
D \right| \geq 2$ for all $v\in V$ and (ii) for every pair of distinct vertices
$u, v\in V$, $\left| (N_G[u] \cup N_G[v]) \cap D \right| \geq 3$. Given a graph
$G$, the decision versions of $k$-Tuple Domination Problem and the Liar's
Domination Problem are to check whether there exists a $k$-tuple dominating set
and a liar's dominating set of $G$ of a given cardinality, respectively. These
two problems are known to be NP-complete \cite{LiaoChang2003, Slater2009}. In
this paper, we study the parameterized complexity of these problems. We show
that the $k$-Tuple Domination Problem and the Liar's Domination Problem are
$\mathsf{W}[2]$-hard for general graphs but they admit linear kernels for
graphs with bounded genus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5462</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5462</id><created>2013-09-21</created><updated>2014-07-14</updated><authors><author><keyname>Hunter</keyname><forenames>Paul</forenames></author><author><keyname>P&#xe9;rez</keyname><forenames>Guillermo A.</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Mean-payoff Games with Partial-Observation</title><categories>cs.GT cs.FL cs.LO</categories><comments>Accepted for the 8th International Workshop on Reachability Problems
  (RP2014)</comments><acm-class>F.1.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Mean-payoff games are important quantitative models for open reactive
systems. They have been widely studied as games of perfect information. In this
paper we investigate the algorithmic properties of several subclasses of
mean-payoff games where the players have asymmetric information about the state
of the game. These games are in general undecidable and not determined
according to the classical definition. We show that such games are determined
under a more general notion of winning strategy. We also consider mean-payoff
games where the winner can be determined by the winner of a finite
cycle-forming game. This yields several decidable classes of mean-payoff games
of asymmetric information that require only finite-memory strategies, including
a generalization of perfect information games where positional strategies are
sufficient. We give an exponential time algorithm for determining the winner of
the latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5469</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5469</id><created>2013-09-21</created><authors><author><keyname>Huber</keyname><forenames>Anna</forenames></author><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author></authors><title>Towards Minimizing k-Submodular Functions</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate k-submodular functions. This natural family of
discrete functions includes submodular and bisubmodular functions as the
special cases k = 1 and k = 2 respectively.
  In particular we generalize the known Min-Max-Theorem for submodular and
bisubmodular functions. This theorem asserts that the minimum of the
(bi)submodular function can be found by solving a maximization problem over a
(bi)submodular polyhedron. We define and investigate a k-submodular polyhedron
and prove a Min-Max-Theorem for k-submodular functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5478</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5478</id><created>2013-09-21</created><authors><author><keyname>Komarov</keyname><forenames>Ivan</forenames></author><author><keyname>Dashti</keyname><forenames>Ali</forenames></author><author><keyname>D'Souza</keyname><forenames>Roshan</forenames></author></authors><title>Fast $k$-NNG construction with GPU-based quick multi-select</title><categories>cs.DC</categories><doi>10.1371/journal.pone.0092409</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we describe a new brute force algorithm for building the
$k$-Nearest Neighbor Graph ($k$-NNG). The $k$-NNG algorithm has many
applications in areas such as machine learning, bio-informatics, and clustering
analysis. While there are very efficient algorithms for data of low dimensions,
for high dimensional data the brute force search is the best algorithm. There
are two main parts to the algorithm: the first part is finding the distances
between the input vectors which may be formulated as a matrix multiplication
problem. The second is the selection of the $k$-NNs for each of the query
vectors. For the second part, we describe a novel graphics processing unit
(GPU) -based multi-select algorithm based on quick sort. Our optimization makes
clever use of warp voting functions available on the latest GPUs along with
use-controlled cache. Benchmarks show significant improvement over
state-of-the-art implementations of the $k$-NN search on GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5479</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5479</id><created>2013-09-21</created><authors><author><keyname>Gower</keyname><forenames>Robert M.</forenames></author><author><keyname>Gower</keyname><forenames>Artur L.</forenames></author></authors><title>Higher-order Reverse Automatic Differentiation with emphasis on the
  third-order</title><categories>cs.MS cs.SC math.OC</categories><doi>10.1007/s10107-014-0827-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is commonly assumed that calculating third order information is too
expensive for most applications. But we show that the directional derivative of
the Hessian ($D^3f(x)\cdot d$) can be calculated at a cost proportional to that
of a state-of-the-art method for calculating the Hessian matrix. We do this by
first presenting a simple procedure for designing high order reverse methods
and applying it to deduce several methods including a reverse method that
calculates $D^3f(x)\cdot d$. We have implemented this method taking into
account symmetry and sparsity, and successfully calculated this derivative for
functions with a million variables. These results indicate that the use of
third order information in a general nonlinear solver, such as Halley-Chebyshev
methods, could be a practical alternative to Newton's method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5488</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5488</id><created>2013-09-21</created><authors><author><keyname>Shi</keyname><forenames>Guodong</forenames></author><author><keyname>Proutiere</keyname><forenames>Alexandre</forenames></author><author><keyname>Johansson</keyname><forenames>Mikael</forenames></author><author><keyname>Baras</keyname><forenames>John. S.</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author></authors><title>Emergent Behaviors over Signed Random Networks in Dynamical Environments</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study asymptotic dynamical patterns that emerge among a set of nodes that
interact in a dynamically evolving signed random network. Node interactions
take place at random on a sequence of deterministic signed graphs. Each node
receives positive or negative recommendations from its neighbors depending on
the sign of the interaction arcs, and updates its state accordingly. Positive
recommendations follow the standard consensus update while two types of
negative recommendations, each modeling a different type of antagonistic or
malicious interaction, are considered. Nodes may weigh positive and negative
recommendations differently, and random processes are introduced to model the
time-varying attention that nodes pay to the positive and negative
recommendations. Various conditions for almost sure convergence, divergence,
and clustering of the node states are established. Some fundamental
similarities and differences are established for the two notions of negative
recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5491</identifier>
 <datestamp>2015-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5491</id><created>2013-09-21</created><updated>2014-08-22</updated><authors><author><keyname>Dr&#xe4;xler</keyname><forenames>Martin</forenames></author><author><keyname>Blobel</keyname><forenames>Johannes</forenames></author><author><keyname>Dreimann</keyname><forenames>Philipp</forenames></author><author><keyname>Valentin</keyname><forenames>Stefan</forenames></author><author><keyname>Karl</keyname><forenames>Holger</forenames></author></authors><title>Anticipatory Buffer Control and Quality Selection for Wireless Video
  Streaming</title><categories>cs.NI cs.MM</categories><acm-class>C.2.1; F.2.2; H.5.1</acm-class><doi>10.1109/NetSys.2015.7089073</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video streaming is in high demand by mobile users, as recent studies
indicate. In cellular networks, however, the unreliable wireless channel leads
to two major problems. Poor channel states degrade video quality and interrupt
the playback when a user cannot sufficiently fill its local playout buffer:
buffer underruns occur. In contrast to that, good channel conditions cause
common greedy buffering schemes to pile up very long buffers. Such
over-buffering wastes expensive wireless channel capacity.
  To keep buffering in balance, we employ a novel approach. Assuming that we
can predict data rates, we plan the quality and download time of the video
segments ahead. This anticipatory scheduling avoids buffer underruns by
downloading a large number of segments before a channel outage occurs, without
wasting wireless capacity by excessive buffering. We formalize this approach as
an optimization problem and derive practical heuristics for segmented video
streaming protocols (e.g., HLS or MPEG DASH). Simulation results and testbed
measurements show that our solution essentially eliminates playback
interruptions without significantly decreasing video quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5498</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5498</id><created>2013-09-21</created><authors><author><keyname>Morrison</keyname><forenames>Foster</forenames></author></authors><title>High Precision Arithmetic for Scientific Applications</title><categories>cs.MS</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  All but a few digital computers used for scientific computations have
supported floating-point and digital arithmetic of rather limited numerical
precision. The underlying assumptions were that the systems being studied were
basically deterministic and of limited complexity. The ideal scientific
paradigm was the orbits of the major planets, which could be observed with high
precision, predicted for thousands of years into the future, and extrapolated
for thousands of years into the past. Much the same technology that has made
computers possible has also provided instrumentation that has vastly expanded
the scope and precision of scientific analysis. Complex nonlinear systems
exhibiting so-called chaotic dynamics are now fair game for scientists and
engineers in every discipline. Today it seems that computers need to enhance
the precision of their numerical computations to support the needs of science.
However, there is no need to wait for the necessary updates in both hardware
and software; it is easy enough to monitor numerical precision with a few minor
modifications to existing software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5500</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5500</id><created>2013-09-21</created><authors><author><keyname>Bishop</keyname><forenames>Judith</forenames></author><author><keyname>Tillmann</keyname><forenames>Nikolai</forenames></author><author><keyname>Puder</keyname><forenames>Arno</forenames></author><author><keyname>Naik</keyname><forenames>Vinayak</forenames></author></authors><title>PRoMoTo 2013 proceedings</title><categories>cs.PL</categories><comments>Published in PRoMoTo'13</comments><acm-class>D.2.3; D.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Programming for Mobile and Touch (PRoMoTo'13) was held at the 2013 ACM
SIGPLAN conference on Systems, Programming, Languages and Applications (SPLASH
2013), October 2013 in Indianapolis, USA. Submissions for this event were
invited in the general area of mobile and touch-oriented programming languages
and programming environments, and teaching of programming for mobile devices.
These are proceedings of the PRoMoTo'13.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5502</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5502</id><created>2013-09-21</created><authors><author><keyname>Oliveira</keyname><forenames>Washington A.</forenames></author><author><keyname>Mello</keyname><forenames>Margarida P.</forenames></author><author><keyname>Moretti</keyname><forenames>Ant&#xf4;nio C.</forenames></author><author><keyname>Reis</keyname><forenames>Ednei F.</forenames></author></authors><title>The multi-vehicle covering tour problem: building routes for urban
  patrolling</title><categories>cs.AI cs.DS</categories><comments>19 pages, 6 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study a particular aspect of the urban community policing:
routine patrol route planning. We seek routes that guarantee visibility, as
this has a sizable impact on the community perceived safety, allowing quick
emergency responses and providing surveillance of selected sites (e.g.,
hospitals, schools). The planning is restricted to the availability of vehicles
and strives to achieve balanced and short routes. We study an adaptation of the
model for the multi-vehicle covering tour problem, in which a set of locations
must be visited, whereas another subset must be close enough to the planned
routes. It constitutes an NP-hard integer programming problem. Suboptimal
solutions are obtained with several heuristics, some adapted from literature
and others developed by us. The heuristics aim to construct short routes so
that one could make several rounds during a work shift. We solve randomly
generated problems and a problem with real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5503</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5503</id><created>2013-09-21</created><authors><author><keyname>Ainsworth</keyname><forenames>Scott G.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Evaluating Sliding and Sticky Target Policies by Measuring Temporal
  Drift in Acyclic Walks Through a Web Archive</title><categories>cs.DL</categories><comments>10 pages, JCDL 2013</comments><acm-class>H.3.7</acm-class><doi>10.1145/2467696.2467718</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a user views an archived page using the archive's user interface (UI),
the user selects a datetime to view from a list. The archived web page, if
available, is then displayed. From this display, the web archive UI attempts to
simulate the web browsing experience by smoothly transitioning between archived
pages. During this process, the target datetime changes with each link
followed; drifting away from the datetime originally selected. When browsing
sparsely-archived pages, this nearly-silent drift can be many years in just a
few clicks. We conducted 200,000 acyclic walks of archived pages, following up
to 50 links per walk, comparing the results of two target datetime policies.
The Sliding Target policy allows the target datetime to change as it does in
archive UIs such as the Internet Archive's Wayback Machine. The Sticky Target
policy, represented by the Memento API, keeps the target datetime the same
throughout the walk. We found that the Sliding Target policy drift increases
with the number of walk steps, number of domains visited, and choice (number of
links available). However, the Sticky Target policy controls temporal drift,
holding it to less than 30 days on average regardless of walk length or number
of domains visited. The Sticky Target policy shows some increase as choice
increases, but this may be caused by other factors. We conclude that based on
walk length, the Sticky Target policy generally produces at least 30 days less
drift than the Sliding Target policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5504</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5504</id><created>2013-09-21</created><updated>2013-12-16</updated><authors><author><keyname>James</keyname><forenames>Ryan G.</forenames></author><author><keyname>Burke</keyname><forenames>Korana</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>Chaos Forgets and Remembers: Measuring Information Creation,
  Destruction, and Storage</title><categories>nlin.CD cond-mat.stat-mech cs.IT math.DS math.IT</categories><comments>5 pages, 4 figures; supplemental: 2 pages, 4 figures;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/chaos_anatomy.htm</comments><doi>10.1016/j.physleta.2014.05.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hallmark of deterministic chaos is that it creates information---the rate
being given by the Kolmogorov-Sinai metric entropy. Since its introduction half
a century ago, the metric entropy has been used as a unitary quantity to
measure a system's intrinsic unpredictability. Here, we show that it naturally
decomposes into two structurally meaningful components: A portion of the
created information---the ephemeral information---is forgotten and a
portion---the bound information---is remembered. The bound information is a new
kind of intrinsic computation that differs fundamentally from information
creation: it measures the rate of active information storage. We show that it
can be directly and accurately calculated via symbolic dynamics, revealing a
hitherto unknown richness in how dynamical systems compute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5507</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5507</id><created>2013-09-21</created><authors><author><keyname>Uddin</keyname><forenames>Irfan</forenames></author></authors><title>Microgrid - The microthreaded many-core architecture</title><categories>cs.AR</categories><comments>30 pages, 16 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Traditional processors use the von Neumann execution model, some other
processors in the past have used the dataflow execution model. A combination of
von Neuman model and dataflow model is also tried in the past and the resultant
model is referred as hybrid dataflow execution model. We describe a hybrid
dataflow model known as the microthreading. It provides constructs for
creation, synchronization and communication between threads in an intermediate
language. The microthreading model is an abstract programming and machine model
for many-core architecture. A particular instance of this model is named as the
microthreaded architecture or the Microgrid. This architecture implements all
the concurrency constructs of the microthreading model in the hardware with the
management of these constructs in the hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5511</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5511</id><created>2013-09-21</created><authors><author><keyname>De la Sen</keyname><forenames>M.</forenames></author><author><keyname>Ibeas</keyname><forenames>A.</forenames></author><author><keyname>Alonso-Quesada</keyname><forenames>S.</forenames></author></authors><title>On the asymptotic hyperstability of switched systems</title><categories>cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymptotic hyperstability is achievable under certain switching laws if at
least one of the feed-forward parameterization: 1) possesses a strictly
positive real transfer function, 2) a minimum residence time interval is
respected for each activation time interval of such a parameterization, and 3)
a maximum allowable residence time interval is guaranteed for all active
parameterization which is not positive real.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5522</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5522</id><created>2013-09-21</created><authors><author><keyname>Golab</keyname><forenames>Wojciech</forenames><affiliation>Steve</affiliation></author><author><keyname>Hurwitz</keyname><forenames>Jeremy</forenames><affiliation>Steve</affiliation></author><author><keyname>Xiaozhou</keyname><affiliation>Steve</affiliation></author><author><keyname>Li</keyname></author></authors><title>On the k-Atomicity-Verification Problem</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern Internet-scale storage systems often provide weak consistency in
exchange for better performance and resilience. An important weak consistency
property is k-atomicity, which bounds the staleness of values returned by read
operations. The k-atomicity-verification problem (or k-AV for short) is the
problem of deciding whether a given history of operations is k-atomic. The 1-AV
problem is equivalent to verifying atomicity/linearizability, a well-known and
solved problem. However, for k &gt; 2, no polynomial-time k-AV algorithm is known.
  This paper makes the following contributions towards solving the k-AV
problem. First, we present a simple 2- AV algorithm called LBT, which is likely
to be efficient (quasilinear) for histories that arise in practice, although it
is less efficient (quadratic) in the worst case. Second, we present a more
involved 2-AV algorithm called FZF, which runs efficiently (quasilinear) even
in the worst case. To our knowledge, these are the first algorithms that solve
the 2-AV problem fully. Third, we show that the weighted k-AV problem, a
natural extension of the k-AV problem, is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5540</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5540</id><created>2013-09-21</created><updated>2014-08-13</updated><authors><author><keyname>Rahimian</keyname><forenames>M. Amin</forenames></author><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author></authors><title>Detection and Isolation of Failures in Linear Multi-Agent Networks</title><categories>cs.SY cs.DM math.OC</categories><comments>There is an improved version of this work in another of our papers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the focus is on the relationship between the occurrence of
failures in a (directed or undirected) network of linear single integrator
agents and the presence of jump discontinuities in the derivatives of the
network output. Based on this relationship, an algorithm for sensor placement
is proposed, which enables the designer to detect and isolate any link failures
across the network, based on the jump discontinuities observed by the sensor
nodes. These results are explained through elaborative examples and computer
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5544</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5544</id><created>2013-09-21</created><updated>2013-09-29</updated><authors><author><keyname>Leivant</keyname><forenames>Daniel M</forenames><affiliation>Indiana University</affiliation></author></authors><title>Alternating Turing machines for inductive languages</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 3 (October 1,
  2013) lmcs:1115</journal-ref><doi>10.2168/LMCS-9(3:29)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that alternating Turing machines, with a novel and natural definition
of acceptance, accept precisely the inductive (Pi-1-1) languages. Total
alternating machines, that either accept or reject each input, accept precisely
the hyper-elementary (Delta-1-1) languages. Moreover, bounding the permissible
number of alternations yields a characterization of the levels of the
arithmetical hierarchy. Notably, these results use simple finite computing
devices, with finitary and discrete operational semantics, and neither the
results nor their proofs make any use of transfinite ordinals. Our
characterizations elucidate the analogy between the polynomial-time hierarchy
and the arithmetical hierarchy, as well as between their respective limits,
namely polynomial-space and Pi-1-1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5546</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5546</id><created>2013-09-21</created><authors><author><keyname>Choi</keyname><forenames>Yang-Seok</forenames></author><author><keyname>Shirani-Mehr</keyname><forenames>Hooman</forenames></author></authors><title>Simultaneous Transmission and Reception: Algorithm, Design and System
  Level Performance</title><categories>cs.NI</categories><comments>20 pages. This manuscript will appear in the IEEE Transactions on
  Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full Duplex or Simultaneous transmission and reception (STR) in the same
frequency at the same time can potentially double the physical layer capacity.
However, high power transmit signal will appear at receive chain as echoes with
powers much higher than the desired received signal. Therefore, in order to
achieve the potential gain, it is imperative to cancel these echoes. As these
high power echoes can saturate low noise amplifier (LNA) and also digital
domain echo cancellation requires unrealistically high resolution
analog-to-digital converter (ADC), the echoes should be cancelled or suppressed
sufficiently before LNA. In this paper we present a closed-loop echo
cancellation technique which can be implemented purely in analogue domain. The
advantages of our method are multiple-fold: it is robust to phase noise, does
not require additional set of antennas, can be applied to wideband signals and
the performance is irrelevant to radio frequency (RF) impairments in transmit
chain. Next, we study a few protocols for STR systems in carrier sense multiple
access (CSMA) network and investigate MAC level throughput with realistic
assumptions in both single cell and multiple cells. We show that STR can reduce
hidden node problem in CSMA network and produce gains of up to 279% in maximum
throughput in such networks. Finally, we investigate the application of STR in
cellular systems and study two new unique interferences introduced to the
system due to STR, namely BS-BS interference and UE-UE interference. We show
that these two new interferences will hugely degrade system performance if not
treated appropriately. We propose novel methods to reduce both interferences
and investigate the performances in system level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5549</identifier>
 <datestamp>2015-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5549</id><created>2013-09-21</created><authors><author><keyname>Ghadimi</keyname><forenames>Saeed</forenames></author><author><keyname>Lan</keyname><forenames>Guanghui</forenames></author></authors><title>Stochastic First- and Zeroth-order Methods for Nonconvex Stochastic
  Programming</title><categories>math.OC cs.CC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a new stochastic approximation (SA) type
algorithm, namely the randomized stochastic gradient (RSG) method, for solving
an important class of nonlinear (possibly nonconvex) stochastic programming
(SP) problems. We establish the complexity of this method for computing an
approximate stationary point of a nonlinear programming problem. We also show
that this method possesses a nearly optimal rate of convergence if the problem
is convex. We discuss a variant of the algorithm which consists of applying a
post-optimization phase to evaluate a short list of solutions generated by
several independent runs of the RSG method, and show that such modification
allows to improve significantly the large-deviation properties of the
algorithm. These methods are then specialized for solving a class of
simulation-based optimization problems in which only stochastic zeroth-order
information is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5551</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5551</id><created>2013-09-21</created><authors><author><keyname>Uddin</keyname><forenames>Irfan</forenames></author></authors><title>Design space exploration in the microthreaded many-core architecture</title><categories>cs.AR</categories><comments>12 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Design space exploration is commonly performed in embedded system, where the
architecture is a complicated piece of engineering. With the current trend of
many-core systems, design space exploration in general-purpose computers can no
longer be avoided. Microgrid is a complicated architecture, and therefor we
need to perform design space exploration. Generally, simulators are used for
the design space exploration of an architecture. Different simulators with
different levels of complexity, simulation time and accuracy are used.
Simulators with little complexity, low simulation time and reasonable accuracy
are desirable for the design space exploration of an architecture. These
simulators are referred as high-level simulators and are commonly used in the
design of embedded systems. However, the use of high-level simulation for
design space exploration in general-purpose computers is a relatively new area
of research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5552</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5552</id><created>2013-09-21</created><updated>2014-05-18</updated><authors><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author></authors><title>The co-evolution of brand effect and competitiveness in evolving
  networks</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages, 6 figures. arXiv admin note: text overlap with
  arXiv:1101.1638; and with arXiv:cond-mat/0406238 by other authors</comments><journal-ref>Chin. Phys. B Vol. 23, No. 7 (2014) 070206</journal-ref><doi>10.1088/1674-1056/23/7/070206</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The principle that 'the brand effect is attractive' underlies preferential
attachment. Here we show that the brand effect is just one dimension of
attractiveness. Another dimension is competitiveness. We firstly develop a
general framework that allows us to investigate the competitive aspect of real
networks, instead of simply preferring popular nodes. Our model accurately
describes the evolution of social and technological networks. The phenomenon
which more competitive nodes become richer links can help us to understand the
evolution of many competitive systems in nature and society. In general, the
paper provides an explicit analytical expression of degree distributions of the
network. In particular, the model yields a nontrivial time evolution of nodes'
properties and scale-free behavior with exponents depending on the microscopic
parameters characterizing the competition rules. Secondly, through theoretical
analysis and numerical simulations, it reveals that our model has not only the
universality for the homogeneous weighted network, but also the character for
the heterogeneous weighted network. Thirdly, the paper also develops a model
based on a profit-driven mechanism. It can better describe the observed
phenomenon in enterprise cooperation networks. We show that standard
preferential attachment, the growing random graph, the initial attractiveness
model, the fitness model and weighted networks, can all be seen as degenerate
cases of our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5568</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5568</id><created>2013-09-22</created><authors><author><keyname>Coleman</keyname><forenames>Martin A.</forenames></author></authors><title>Integrating Communications and Merging Messaging via the eXtensible
  Messaging and Presence Protocol</title><categories>cs.NI</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common problems affecting modern email usage include spam, lack of sender
verification, lack of built-in security and lack of message integrity. This
paper looks at how we can utilise the extensible messaging and presence
protocol also known as XMPP to, in time, replace email facilities. We present
several methods for initiating a transition away from SMTP for email to rely
upon the inherent benefits of XMPP with minimal disruption to existing networks
and email infrastructure. We look at how a program might be used to open an
existing POP3/IMAP account, scan for messages that can be sent to a XMPP
network user, extract the message and then deliver it the XMPP user's client.
We show that the system can be implemented and then deployed with a minimum of
hassle and network disruption to demonstrate XMPP as a reliable and fast
replacement for email as we know it today.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5574</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5574</id><created>2013-09-22</created><authors><author><keyname>Egger</keyname><forenames>Jan</forenames></author></authors><title>Image-guided therapy system for interstitial gynecologic brachytherapy
  in a multimodality operating suite</title><categories>cs.CE physics.med-ph</categories><comments>7 pages, 3 figures</comments><journal-ref>SpringerPlus 2013 2:395</journal-ref><doi>10.1186/2193-1801-2-395</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, an image-guided therapy system supporting gynecologic
radiation therapy is introduced. The overall workflow of the presented system
starts with the arrival of the patient and ends with follow-up examinations by
imaging and a superimposed visualization of the modeled device from a PACS
system. Thereby, the system covers all treatments stages (pre-, intra- and
postoperative) and has been designed and constructed by a computer scientist
with feedback from an interdisciplinary team of physicians and engineers. This
integrated medical system enables dispatch of diagnostic images directly after
acquisition to a processing workstation that has an on-board 3D Computer Aided
Design model of a medical device. Thus, allowing precise identification of
catheter location in the 3D imaging model which later provides rapid feedback
to the clinician regarding device location. Moreover, the system enables the
ability to perform patient-specific pre-implant evaluation by assessing the
placement of interstitial needles prior to an intervention via virtual template
matching with a diagnostic scan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5582</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5582</id><created>2013-09-22</created><updated>2014-01-06</updated><authors><author><keyname>Steinberger</keyname><forenames>John P</forenames></author></authors><title>The sum-capture problem for abelian groups</title><categories>cs.DM math.CO</categories><msc-class>11B05, 11B30</msc-class><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a finite abelian group, let $0 &lt; \alpha &lt; 1$, and let $A \subseteq
G$ be a random set of size $|G|^\alpha$. We let $$ \mu(A) =
\max_{B,C:|B|=|C|=|A|}|\{(a,b,c) \in A \times B \times C : a = b + c \}|. $$
The issue is to determine upper bounds on $\mu(A)$ that hold with high
probability over the random choice of $A$. Mennink and Preneel \cite{BM}
conjecture that $\mu(A)$ should be close to $|A|$ (up to possible logarithmic
factors in $|G|$) for $\alpha \leq 1/2$ and that $\mu(A)$ should not much
exceed $|A|^{3/2}$ for $\alpha \leq 2/3$. We prove the second half of this
conjecture by showing that $$ \mu(A) \leq |A|^3/|G| + 4|A|^{3/2}\ln(|G|)^{1/2}
$$ with high probability, for all $0 &lt; \alpha &lt; 1$. We note that $3\alpha - 1
\leq (3/2)\alpha$ for $\alpha \leq 2/3$.
  In previous work, Alon et al$.$ have shown that $\mu(A) \leq O(1)|A|^3/|G|$
with high probability for $\alpha \geq 2/3$ while Kiltz, Pietrzak and Szegedy
show that $\mu(A) \leq |A|^{1 + 2\alpha}$ with high probability for $\alpha
\leq 1/4$. Current bounds on $\mu(A)$ are essentially sharp for the range $2/3
\leq \alpha \leq 1$. Finding better bounds remains an open problem for the
range $0 &lt; \alpha &lt; 2/3$ and especially for the range $1/4 &lt; \alpha &lt; 2/3$ in
which the bound of Kiltz et al$.$ doesn't improve on the bound given in this
paper (even if that bound applied). Moreover the conjecture of Mennink and
Preneel for $\alpha \leq 1/2$ remains open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5587</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5587</id><created>2013-09-22</created><updated>2015-03-14</updated><authors><author><keyname>Fujiwara</keyname><forenames>Yuichiro</forenames></author><author><keyname>Gruner</keyname><forenames>Alexander</forenames></author><author><keyname>Vandendriessche</keyname><forenames>Peter</forenames></author></authors><title>High-rate quantum low-density parity-check codes assisted by reliable
  qubits</title><categories>quant-ph cs.IT math.IT</categories><comments>18 pages, 5 figures, 1 table</comments><journal-ref>IEEE Transactions on Information Theory, 61 (2015) 1860-1878</journal-ref><doi>10.1109/TIT.2015.2398436</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum error correction is an important building block for reliable quantum
information processing. A challenging hurdle in the theory of quantum error
correction is that it is significantly more difficult to design
error-correcting codes with desirable properties for quantum information
processing than for traditional digital communications and computation. A
typical obstacle to constructing a variety of strong quantum error-correcting
codes is the complicated restrictions imposed on the structure of a code.
Recently, promising solutions to this problem have been proposed in quantum
information science, where in principle any binary linear code can be turned
into a quantum error-correcting code by assuming a small number of reliable
quantum bits. This paper studies how best to take advantage of these latest
ideas to construct desirable quantum error-correcting codes of very high
information rate. Our methods exploit structured high-rate low-density
parity-check codes available in the classical domain and provide quantum
analogues that inherit their characteristic low decoding complexity and high
error correction performance even at moderate code lengths. Our approach to
designing high-rate quantum error-correcting codes also allows for making
direct use of other major syndrome decoding methods for linear codes, making it
possible to deal with a situation where promising quantum analogues of
low-density parity-check codes are difficult to find.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5594</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5594</id><created>2013-09-22</created><updated>2013-09-29</updated><authors><author><keyname>Shen</keyname><forenames>Fumin</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author></authors><title>Generic Image Classification Approaches Excel on Face Recognition</title><categories>cs.CV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main finding of this work is that the standard image classification
pipeline, which consists of dictionary learning, feature encoding, spatial
pyramid pooling and linear classification, outperforms all state-of-the-art
face recognition methods on the tested benchmark datasets (we have tested on
AR, Extended Yale B, the challenging FERET, and LFW-a datasets). This
surprising and prominent result suggests that those advances in generic image
classification can be directly applied to improve face recognition systems. In
other words, face recognition may not need to be viewed as a separate object
classification problem.
  While recently a large body of residual based face recognition methods focus
on developing complex dictionary learning algorithms, in this work we show that
a dictionary of randomly extracted patches (even from non-face images) can
achieve very promising results using the image classification pipeline. That
means, the choice of dictionary learning methods may not be important. Instead,
we find that learning multiple dictionaries using different low-level image
features often improve the final classification accuracy. Our proposed face
recognition approach offers the best reported results on the widely-used face
recognition benchmark datasets. In particular, on the challenging FERET and
LFW-a datasets, we improve the best reported accuracies in the literature by
about 20% and 30% respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5598</identifier>
 <datestamp>2013-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5598</id><created>2013-09-22</created><authors><author><keyname>Wang</keyname><forenames>Yun-Jiang</forenames></author><author><keyname>Zeng</keyname><forenames>Bei</forenames></author><author><keyname>Grassl</keyname><forenames>Markus</forenames></author><author><keyname>Sanders</keyname><forenames>Barry C.</forenames></author></authors><title>Stabilizer formalism for generalized concatenated quantum codes</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 2 figures, International Symposium on Information Theory, 7
  July - 12 July 2013, Istanbul, Turkey</comments><journal-ref>Proceedings 2013 IEEE International Symposium on Information
  Theory (ISIT 2013), Istanbul, Turkey, pp. 529-533</journal-ref><doi>10.1109/ISIT.2013.6620282</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of generalized concatenated quantum codes (GCQC) provides a
systematic way for constructing good quantum codes from short component codes.
We introduce a stabilizer formalism for GCQCs, which is achieved by defining
quantum coset codes. This formalism offers a new perspective for GCQCs and
enables us to derive a lower bound on the code distance of stabilizer GCQCs
from component codes parameters,for both non-degenerate and degenerate
component codes. Our formalism also shows how to exploit the error-correcting
capacity of component codes to design good GCQCs efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5601</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5601</id><created>2013-09-22</created><authors><author><keyname>T</keyname><forenames>Lata B</forenames></author><author><keyname>R</keyname><forenames>Jansi P K</forenames></author><author><keyname>K</keyname><forenames>Shaila</forenames></author><author><keyname>Sujatha</keyname><forenames>D N</forenames></author><author><keyname>R</keyname><forenames>Venugopal K</forenames></author><author><keyname>Patnaik</keyname><forenames>L M</forenames></author></authors><title>Multiple Domain Secure Routing for Wireless Sensor Networks</title><categories>cs.CR cs.NI</categories><comments>10 pages</comments><journal-ref>International Journal of Information Processing, 7(2), 59-68, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure Transmission of data packets in Wireless Sensor Networks is an
important area of Research. There is a possibility of an attacker creating
security holes in the network. Hence, network security and reliability can be
achieved by discovering random multiple paths using multiple domains, and
forwarding data packets from the source node to the destination node. We have
designed, Multiple Domain Routing with Overlap of Nodes (MDRON) and Multiple
Domain Routing Without Overlap of Nodes (MDRWON) algorithms, in which packets
follow multiple optimized paths simultaneously. The Special node algorithm
searches the node which has maximum power and these nodes are used for
transferring the packet from one domain to another domain. Simulation results
using MATLAB shows that performance is better than Purely Random Propagation
(PRP) and Non Repetitive Random Propagation(NRRP) Algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5605</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5605</id><created>2013-09-22</created><authors><author><keyname>Choromanska</keyname><forenames>Anna</forenames></author><author><keyname>Jebara</keyname><forenames>Tony</forenames></author></authors><title>Stochastic Bound Majorization</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently a majorization method for optimizing partition functions of
log-linear models was proposed alongside a novel quadratic variational
upper-bound. In the batch setting, it outperformed state-of-the-art first- and
second-order optimization methods on various learning tasks. We propose a
stochastic version of this bound majorization method as well as a low-rank
modification for high-dimensional data-sets. The resulting stochastic
second-order method outperforms stochastic gradient descent (across variations
and various tunings) both in terms of the number of iterations and computation
time till convergence while finding a better quality parameter setting. The
proposed method bridges first- and second-order stochastic optimization methods
by maintaining a computational complexity that is linear in the data dimension
and while exploiting second order information about the pseudo-global curvature
of the objective function (as opposed to the local curvature in the Hessian).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5618</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5618</id><created>2013-09-22</created><authors><author><keyname>Babenko</keyname><forenames>Maxim</forenames></author><author><keyname>Gawrychowski</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Kociumaka</keyname><forenames>Tomasz</forenames></author><author><keyname>Starikovskaya</keyname><forenames>Tatiana</forenames></author></authors><title>Substring Suffix Selection</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the following substring suffix selection problem: given a substring
of a string T of length n, compute its k-th lexicographically smallest suffix.
This a natural generalization of the well-known question of computing the
maximal suffix of a string, which is a basic ingredient in many other problems.
We first revisit two special cases of the problem, introduced by Babenko,
Kolesnichenko and Starikovskaya [CPM'13], in which we are asked to compute the
minimal non-empty and the maximal suffixes of a substring. For the maximal
suffixes problem, we give a linear-space structure with O(1) query time and
linear preprocessing time, i.e., we manage to achieve optimal construction and
optimal query time simultaneously. For the minimal suffix problem, we give a
linear-space data structure with O(\tau) query time and O(n log n / \tau)
preprocessing time, where 1 &lt;= \tau &lt;= log n is a parameter of the data
structure. As a sample application, we show that this data structure can be
used to compute the Lyndon decomposition of any substring of T in O(k \tau)
time, where k is the number of distinct factors in the decomposition.
  Finally, we move to the general case of the substring suffix selection
problem, where using any combinatorial properties seems more difficult.
Nevertheless, we develop a linear-space data structure with O(log^{2+\epsilon}
n) query time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5643</identifier>
 <datestamp>2014-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5643</id><created>2013-09-22</created><updated>2014-08-12</updated><authors><author><keyname>Cheplygina</keyname><forenames>Veronika</forenames></author><author><keyname>Tax</keyname><forenames>David M. J.</forenames></author><author><keyname>Loog</keyname><forenames>Marco</forenames></author></authors><title>Multiple Instance Learning with Bag Dissimilarities</title><categories>stat.ML cs.LG</categories><comments>Pattern Recognition, in press</comments><journal-ref>Pattern Recognition 48.1 (2015): 264-275</journal-ref><doi>10.1016/j.patcog.2014.07.022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple instance learning (MIL) is concerned with learning from sets (bags)
of objects (instances), where the individual instance labels are ambiguous. In
this setting, supervised learning cannot be applied directly. Often,
specialized MIL methods learn by making additional assumptions about the
relationship of the bag labels and instance labels. Such assumptions may fit a
particular dataset, but do not generalize to the whole range of MIL problems.
Other MIL methods shift the focus of assumptions from the labels to the overall
(dis)similarity of bags, and therefore learn from bags directly. We propose to
represent each bag by a vector of its dissimilarities to other bags in the
training set, and treat these dissimilarities as a feature representation. We
show several alternatives to define a dissimilarity between bags and discuss
which definitions are more suitable for particular MIL problems. The
experimental results show that the proposed approach is computationally
inexpensive, yet very competitive with state-of-the-art algorithms on a wide
range of MIL datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5647</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5647</id><created>2013-09-22</created><authors><author><keyname>Mittal</keyname><forenames>Sparsh</forenames></author></authors><title>A Cache-Coloring Based Technique for Saving Leakage Energy In
  Multitasking Systems</title><categories>cs.AR</categories><comments>Cache leakage energy saving technique</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a significant increase in leakage energy dissipation of CMOS
circuits with each technology generation. Further, due to their large size,
last level caches (LLCs) spend a large fraction of their energy in the form of
leakage energy and hence, addressing this has become extremely important to
meet the challenges of chip power budget. For addressing this, several
techniques have been proposed. However, most of these techniques require
offline profiling and hence cannot be used for real-life systems which usually
run multitasking programs, with possible pre-emptions. In this paper, we
propose a dynamic profiling based technique for saving cache leakage energy in
multitasking systems. Our technique uses a small coloring-based profiling
cache, to estimate performance and energy consumption of multiple cache
configurations and then selects the best (least-energy) configuration among
them. Our technique uses non-intrusive profiling and saves energy despite
intra-task and inter-task variations; thus, it is suitable for multitasking
systems. Simulations performed using workloads from SPEC2006 suite show the
superiority of our technique over an existing cache energy saving technique.
With a 2MB baseline cache, the average saving in memory sub-system energy is
22.8%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5652</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5652</id><created>2013-09-22</created><authors><author><keyname>Diab</keyname><forenames>Mona</forenames></author><author><keyname>Habash</keyname><forenames>Nizar</forenames></author><author><keyname>Rambow</keyname><forenames>Owen</forenames></author><author><keyname>Roth</keyname><forenames>Ryan</forenames></author></authors><title>LDC Arabic Treebanks and Associated Corpora: Data Divisions Manual</title><categories>cs.CL</categories><comments>14 pages; one cover</comments><report-no>CLCSL-0S7--1031-02</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Linguistic Data Consortium (LDC) has developed hundreds of data corpora
for natural language processing (NLP) research. Among these are a number of
annotated treebank corpora for Arabic. Typically, these corpora consist of a
single collection of annotated documents. NLP research, however, usually
requires multiple data sets for the purposes of training models, developing
techniques, and final evaluation. Therefore it becomes necessary to divide the
corpora used into the required data sets (divisions). This document details a
set of rules that have been defined to enable consistent divisions for old and
new Arabic treebanks (ATB) and related corpora.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5655</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5655</id><created>2013-09-22</created><updated>2014-01-16</updated><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author></authors><title>Reweighted message passing revisited</title><categories>cs.AI cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new family of message passing techniques for MAP estimation in
graphical models which we call {\em Sequential Reweighted Message Passing}
(SRMP). Special cases include well-known techniques such as {\em Min-Sum
Diffusion} (MSD) and a faster {\em Sequential Tree-Reweighted Message Passing}
(TRW-S). Importantly, our derivation is simpler than the original derivation of
TRW-S, and does not involve a decomposition into trees. This allows easy
generalizations. We present such a generalization for the case of higher-order
graphical models, and test it on several real-world problems with promising
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5657</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5657</id><created>2013-09-22</created><authors><author><keyname>El-Shishtawy</keyname><forenames>T.</forenames></author></authors><title>A Hybrid Algorithm for Matching Arabic Names</title><categories>cs.CL</categories><journal-ref>International Journal of Computational Linguistics Research Volume
  4 Number 2 June 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new hybrid algorithm which combines both of token-based and
character-based approaches is presented. The basic Levenshtein approach has
been extended to token-based distance metric. The distance metric is enhanced
to set the proper granularity level behavior of the algorithm. It smoothly maps
a threshold of misspellings differences at the character level, and the
importance of token level errors in terms of token's position and frequency.
Using a large Arabic dataset, the experimental results show that the proposed
algorithm overcomes successfully many types of errors such as: typographical
errors, omission or insertion of middle name components, omission of
non-significant popular name components, and different writing styles character
variations. When compared the results with other classical algorithms, using
the same dataset, the proposed algorithm was found to increase the minimum
success level of best tested algorithms, while achieving higher upper limits .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5660</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5660</id><created>2013-09-22</created><authors><author><keyname>Harter</keyname><forenames>Derek</forenames></author></authors><title>Spike Synchronization Dynamics of Small-World Networks</title><categories>cs.NE nlin.AO q-bio.NC</categories><comments>22 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research report, we examine the effects of small-world network
organization on spike synchronization dynamics in networks of Izhikevich
spiking units. We interpolate network organizations from regular ring lattices,
through the small-world region, to random networks, and measure global spike
synchronization dynamics. We examine how average path length and clustering
effect the dynamics of global and neighborhood clique spike organization and
propagation. We show that the emergence of global synchronization undergoes a
phase transition in the small-world region, between the clustering and path
length phase transitions that are known to exist. We add additional realistic
constraints on the dynamics by introducing propagation delays of spiking
signals proportional to wiring length. The addition of delays interferes with
the ability of random networks to sustain global synchronization, in relation
to the breakdown of clustering in the networks. The addition of delays further
enhances the finding that small-world organization is beneficial for balancing
neighborhood synchronized waves of organization with global synchronization
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5668</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5668</id><created>2013-09-22</created><authors><author><keyname>Forbes</keyname><forenames>Michael A.</forenames></author><author><keyname>Saptharishi</keyname><forenames>Ramprasad</forenames></author><author><keyname>Shpilka</keyname><forenames>Amir</forenames></author></authors><title>Pseudorandomness for Multilinear Read-Once Algebraic Branching Programs,
  in any Order</title><categories>cs.CC</categories><comments>38 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give deterministic black-box polynomial identity testing algorithms for
multilinear read-once oblivious algebraic branching programs (ROABPs), in
n^(lg^2 n) time. Further, our algorithm is oblivious to the order of the
variables. This is the first sub-exponential time algorithm for this model.
Furthermore, our result has no known analogue in the model of read-once
oblivious boolean branching programs with unknown order, as despite recent work
there is no known pseudorandom generator for this model with sub-polynomial
seed-length (for unbounded-width branching programs).
  This result extends and generalizes the result of Forbes and Shpilka that
obtained a n^(lg n)-time algorithm when given the order. We also extend and
strengthen the work of Agrawal, Saha and Saxena that gave a black-box algorithm
running in time exp((lg n)^d) for set-multilinear formulas of depth d. We note
that the model of multilinear ROABPs contains the model of set-multilinear
algebraic branching programs, which itself contains the model of
set-multilinear formulas of arbitrary depth. We obtain our results by
recasting, and improving upon, the ideas of Agrawal, Saha and Saxena. We phrase
the ideas in terms of rank condensers and Wronskians, and show that our results
improve upon the classical multivariate Wronskian, which may be of independent
interest.
  In addition, we give the first n^(lglg n) black-box polynomial identity
testing algorithm for the so called model of diagonal circuits. This model,
introduced by Saxena has recently found applications in the work of Mulmuley,
as well as in the work of Gupta, Kamath, Kayal, Saptharishi. Previously work
had given n^(lg n)-time algorithms for this class. More generally, our result
holds for any model computing polynomials whose partial derivatives (of all
orders) span a low dimensional linear space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5671</identifier>
 <datestamp>2014-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5671</id><created>2013-09-22</created><updated>2014-02-27</updated><authors><author><keyname>Van Renesse</keyname><forenames>Robbert</forenames></author><author><keyname>Schiper</keyname><forenames>Nicolas</forenames></author><author><keyname>Schneider</keyname><forenames>Fred B.</forenames></author></authors><title>Vive la Diff\'erence: Paxos vs. Viewstamped Replication vs. Zab</title><categories>cs.DC</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paxos, Viewstamped Replication, and Zab are replication protocols that ensure
high-availability in asynchronous environments with crash failures. Various
claims have been made about similarities and differences between these
protocols. But how does one determine whether two protocols are the same, and
if not, how significant the differences are?
  We propose to address these questions using refinement mappings, where
protocols are expressed as succinct specifications that are progressively
refined to executable implementations. Doing so enables a principled
understanding of the correctness of the different design decisions that went
into implementing the various protocols. Additionally, it allowed us to
identify key differences that have a significant impact on performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5674</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5674</id><created>2013-09-22</created><updated>2013-10-07</updated><authors><author><keyname>Liu</keyname><forenames>Xiaogang</forenames></author><author><keyname>Harrison</keyname><forenames>Michael</forenames></author><author><keyname>Luo</keyname><forenames>Yuan</forenames></author></authors><title>A note on the five valued conjectures of Johansen and Helleseth and zeta
  functions</title><categories>cs.IT math.IT</categories><comments>14 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  For the complete five-valued cross-correlation distribution between two
$m$-sequences ${s_t}$ and ${s_{dt}}$ of period $2^m-1$ that differ by the
decimation $d={{2^{2k}+1}\over {2^k+1}}$ where $m$ is odd and
$\mbox{gcd}(k,m)=1$, Johansen and Hellseth expressed it in terms of some
exponential sums. And two conjectures are presented that are of interest in
their own right. In this correspondence we study these conjectures for the
particular case where $k=3$, and the cases $k=1,2$ can also be analyzed in a
similar process. When $k&gt;3$, the degrees of the relevant polynomials will
become higher.
  Here the multiplicity of the biggest absolute value of the cross-correlation
is no more than one-sixth of the multiplicity corresponding the smallest
absolute value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5676</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5676</id><created>2013-09-22</created><updated>2014-08-03</updated><authors><author><keyname>Grossu</keyname><forenames>I. V.</forenames><affiliation>Neagu</affiliation></author><author><keyname>Ciuluvica</keyname><forenames>C. I.</forenames><affiliation>Neagu</affiliation></author></authors><title>Implementation of a language driven Backpropagation algorithm</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the importance of both communication and feedback on errors in
human learning, our main goal was to implement a similar mechanism in
supervised learning of artificial neural networks. The starting point in our
study was the observation that words should accompany the input vectors
included in the training set, thus extending the ANN input space. This had as
consequence the necessity to take into consideration a modified sigmoid
activation function for neurons in the first hidden layer (in agreement with a
specific MLP apartment structure), and also a modified version of the
Backpropagation algorithm, which allows using of unspecified (null) desired
output components. Following the belief that basic concepts should be tested on
simple examples, the previous mentioned mechanism was applied on both the XOR
problem and a didactic color case study. In this context, we noticed the
interesting fact that the ANN was capable to categorize all desired input
vectors in the absence of their corresponding words, even though the training
set included only word accompanied inputs, in both positive and negative
examples. Further analysis along applying this approach to more complex
scenarios is currently in progress, as we consider the proposed language-driven
algorithm might contribute to a better understanding of learning in humans,
opening as well the possibility to create a specific category of artificial
neural networks, with abstraction capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5677</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5677</id><created>2013-09-22</created><authors><author><keyname>Koga</keyname><forenames>Jun-ichi</forenames></author><author><keyname>Koga</keyname><forenames>Jiro</forenames></author><author><keyname>Homma</keyname><forenames>Shunji</forenames></author></authors><title>Checkerboard Problem to Topology Optimization of Continuum Structures</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The area of topology optimization of continuum structures of which is allowed
to change in order to improve the performance is now dominated by methods that
employ the material distribution concept. The typical methods of the topology
optimization based on the structural optimization of two phase composites are
the so-called variable density ones, like the SIMP (Solid Isotropic Material
with Penalization) and the BESO (Bi-directional Evolutional Structure
Optimization). The topology optimization problem refers to the saddle-point
variation one as well as the so-called Stokes flow problem of the compressive
fluid. The checkerboard patterns often appear in the results computed by the
SIMP and the BESO in which the Q1-P0 element is used for FEM (Finite Element
Method), since these patterns are more favourable than uniform density regions.
Computational experiments of SIMP and BESO have shown that filtering of
sensitivity information of the optimization problem is a highly efficient way
that the checkerboard patterns disappeared and to ensure mesh-independency. SIn
this paper, we discuss the theoretical basis for the filtering method of the
SIMP and the BESO and as a result, the filtering method can be understood by
the theorem of partition of unity and the convolution operator of low-pass
filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5680</identifier>
 <datestamp>2014-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5680</id><created>2013-09-22</created><updated>2014-05-08</updated><authors><author><keyname>Yao</keyname><forenames>Zheng</forenames></author><author><keyname>Peng</keyname><forenames>Xiao-Long</forenames></author><author><keyname>Zhang</keyname><forenames>Li-Jie</forenames></author><author><keyname>Xu</keyname><forenames>Xin-Jian</forenames></author></authors><title>Modeling nonuniversal citation distributions: the role of scientific
  journals</title><categories>physics.soc-ph cond-mat.stat-mech cs.DL</categories><comments>14 pages, 6 figures, Latex</comments><journal-ref>J. Stat. Mech. (2014) P04029</journal-ref><doi>10.1088/1742-5468/2014/04/P04029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whether a scientific paper is cited is related not only to the influence of
its author(s) but also to the journal publishing it. Scientists, either
proficient or tender, usually submit their most important work to prestigious
journals which receives higher citations than the ordinary. How to model the
role of scientific journals in citation dynamics is of great importance. In
this paper we address this issue through two folds. One is the intrinsic
heterogeneity of a paper determined by the impact factor of the journal
publishing it. The other is the mechanism of a paper being cited which depends
on its citations and prestige. We develop a model for citation networks via an
intrinsic nodal weight function and an intuitive ageing mechanism. The node's
weight is drawn from the distribution of impact factors of journals and the
ageing transition is a function of the citation and the prestige. The
node-degree distribution of resulting networks shows nonuniversal scaling: the
distribution decays exponentially for small degree and has a power-law tail for
large degree, hence the dual behaviour. The higher the impact factor of the
journal, the larger the tipping point and the smaller the power exponent that
are obtained. With the increase of the journal rank, this phenomenon will fade
and evolve to pure power laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5686</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5686</id><created>2013-09-22</created><authors><author><keyname>S.</keyname><forenames>Vineeth B.</forenames></author><author><keyname>Mukherji</keyname><forenames>Utpal</forenames></author></authors><title>On the tradeoff of average delay and average power for fading
  point-to-point links with monotone policies</title><categories>cs.NI cs.IT cs.PF math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a fading point-to-point link with packets arriving randomly at
rate $\lambda$ per slot to the transmitter queue. We assume that the
transmitter can control the number of packets served in a slot by varying the
transmit power for the slot. We restrict to transmitter scheduling policies
that are monotone and stationary, i.e., the number of packets served is a
non-decreasing function of the queue length at the beginning of the slot for
every slot fade state. For such policies, we obtain asymptotic lower bounds for
the minimum average delay of the packets, when average transmitter power is a
small positive quantity $V$ more than the minimum average power required for
transmitter queue stability. We show that the minimum average delay grows
either to a finite value or as $\Omega\brap{\log(1/V)}$ or $\Omega\brap{1/V}$
when $V \downarrow 0$, for certain sets of values of $\lambda$. These sets are
determined by the distribution of fading gain, the maximum number of packets
which can be transmitted in a slot, and the transmit power function of the
fading gain and the number of packets transmitted that is assumed. We identify
a case where the above behaviour of the tradeoff differs from that obtained
from a previously considered approximate model, in which the random queue
length process is assumed to evolve on the non-negative real line, and the
transmit power function is strictly convex. We also consider a fading
point-to-point link, where the transmitter, in addition to controlling the
number of packets served, can also control the number of packets admitted in
every slot. Our approach, which uses bounds on the stationary probability
distribution of the queue length, also leads to an intuitive explanation of the
asymptotic behaviour of average delay in the regime where $V \downarrow 0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5687</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5687</id><created>2013-09-22</created><authors><author><keyname>Shinn</keyname><forenames>Tong-Wook</forenames></author><author><keyname>Takaoka</keyname><forenames>Tadao</forenames></author></authors><title>Combining All Pairs Shortest Paths and All Pairs Bottleneck Paths
  Problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new problem that combines the well known All Pairs Shortest
Paths (APSP) problem and the All Pairs Bottleneck Paths (APBP) problem to
compute the shortest paths for all pairs of vertices for all possible flow
amounts. We call this new problem the All Pairs Shortest Paths for All Flows
(APSP-AF) problem. We firstly solve the APSP-AF problem on directed graphs with
unit edge costs and real edge capacities in
$\tilde{O}(\sqrt{t}n^{(\omega+9)/4}) = \tilde{O}(\sqrt{t}n^{2.843})$ time,
where $n$ is the number of vertices, $t$ is the number of distinct edge
capacities (flow amounts) and $O(n^{\omega}) &lt; O(n^{2.373})$ is the time taken
to multiply two $n$-by-$n$ matrices over a ring. Secondly we extend the problem
to graphs with positive integer edge costs and present an algorithm with
$\tilde{O}(\sqrt{t}c^{(\omega+5)/4}n^{(\omega+9)/4}) =
\tilde{O}(\sqrt{t}c^{1.843}n^{2.843})$ worst case time complexity, where $c$ is
the upper bound on edge costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5688</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5688</id><created>2013-09-22</created><authors><author><keyname>Emanuel</keyname><forenames>Andi Wahju Rahardjo</forenames></author><author><keyname>Surjawan</keyname><forenames>Daniel Jahja</forenames></author></authors><title>Revised Modularity Index to Measure Modularity of OSS Projects with Case
  Study of Freemind</title><categories>cs.SE</categories><comments>6 pages, 9 figures, Published with International Journal of Computer
  Applications (IJCA)</comments><journal-ref>IJCA 59(12):28-33, December 2012. Published by Foundation of
  Computer Science, New York, USA</journal-ref><doi>10.5120/9602-4227</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open Source Software (OSS) Projects are gaining popularity worldwide. Studies
by many researchers show that the important key success factor is modularity of
the source code. This paper presents the revised Modularity Index which is a
software metrics to measure the modularity level of a javabased OSS Projects.
To show its effectiveness in analyzing OSS Project, the Modularity Index and
its supporting software metrics are then used to analyze the evolution of
Freemind mind mapping OSS Project. The analysis using Modularity Index and its
supporting metrics shows the strength and weaknesses of the Freemind OSS
Projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5689</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5689</id><created>2013-09-22</created><authors><author><keyname>Emanuel</keyname><forenames>Andi Wahju Rahardjo</forenames></author><author><keyname>Wardoyo</keyname><forenames>Retantyo</forenames></author><author><keyname>Istiyanto</keyname><forenames>Jazi Eko</forenames></author><author><keyname>Mustofa</keyname><forenames>Khabib</forenames></author></authors><title>Modularity Index Metrics for Java-Based Open Source Software Projects</title><categories>cs.SE</categories><comments>7 pages, 5 figures. Published in (IJACSA) International Journal of
  Advanced Computer Science and Applications, Vol. 2, No. 11, 2011</comments><journal-ref>IJACSA Vol. 2 No. 11, 2011. The Science and Information
  Organization</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open Source Software (OSS) Projects are gaining popularity these days, and
they become alternatives in building software system. Despite many failures in
these projects, there are some success stories with one of the identified
success factors is modularity. This paper presents the first quantitative
software metrics to measure modularity level of Java-based OSS Projects called
Modularity Index. This software metrics is formulated by analyzing modularity
traits such as size, complexity, cohesion, and coupling of 59 Java-based OSS
Projects from sourceforge.net using SONAR tool. These OSS Projects are selected
since they have been downloaded more than 100K times and believed to have the
required modularity trait to be successful. The software metrics related to
modularity in class, package and system level of these projects are extracted
and analyzed. The similarities found are then analyzed to determine the class
quality, package quality, and then combined with system architecture measure to
formulate the Modularity Index. The case study of measuring Modularity Index
during the evolution of JFreeChart project has shown that this software metrics
is able to identify strengths and potential problems of the project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5697</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5697</id><created>2013-09-23</created><authors><author><keyname>Kao</keyname><forenames>Mong-Jen</forenames></author><author><keyname>Chen</keyname><forenames>Jian-Jia</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author><author><keyname>Wagner</keyname><forenames>Dorothea</forenames></author></authors><title>Competitive Design and Analysis for Machine-Minimizing Job Scheduling
  Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the machine-minimizing job scheduling problem, which has a rich
history in the line of research, under an online setting. We consider systems
with arbitrary job arrival times, arbitrary job deadlines, and unit job
execution time. For this problem, we present a lower bound 2.09 on the
competitive factor of \emph{any} online algorithms, followed by designing a
5.2-competitive online algorithm. We also point out a false claim made in an
existing paper of Shi and Ye regarding a further restricted case of the
considered problem. To the best of our knowledge, what we present is the first
concrete result concerning online machine-minimizing job scheduling with
arbitrary job arrival times and deadlines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5702</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5702</id><created>2013-09-23</created><authors><author><keyname>Hatanaka</keyname><forenames>Takeshi</forenames></author><author><keyname>Funada</keyname><forenames>Riku</forenames></author><author><keyname>Fujita</keyname><forenames>Masayuki</forenames></author></authors><title>3-D Visual Coverage Based on Gradient Descent Techniques on Matrix
  Manifold and Its Application to Moving Objects Monitoring</title><categories>cs.SY</categories><comments>10 pages, 27 figures, submitted to 2014 ACC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates coverage control for visual sensor networks based on
gradient descent techniques on matrix manifolds. We consider the scenario that
networked vision sensors with controllable orientations are distributed over
3-D space to monitor 2-D environment. Then, the decision variable must be
constrained on the Lie group SO(3). The contribution of this paper is two
folds. The first one is technical, namely we formulate the coverage problem as
an optimization problem on SO(3) without introducing local parameterization
like Eular angles and directly apply the gradient descent algorithm on the
manifold. The second technological contribution is to present not only the
coverage control scheme but also the density estimation process including image
processing and curve fitting while exemplifying its effectiveness through
simulation of moving objects monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5706</identifier>
 <datestamp>2013-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5706</id><created>2013-09-23</created><updated>2013-11-21</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Marx</keyname><forenames>Werner</forenames></author><author><keyname>Milojevi&#x107;</keyname><forenames>Sta&#x161;a</forenames></author></authors><title>Referenced Publication Years Spectroscopy applied to iMetrics:
  Scientometrics, Journal of Informetrics, and a relevant subset of JASIST</title><categories>cs.DL cs.CY</categories><comments>Journal of Informetrics, accepted for publication (20 Nov. 2013)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed a (freeware) routine for &quot;referenced publication years
spectroscopy&quot; (RPYS) and apply this method to the historiography of &quot;iMetrics,&quot;
that is, the junction of the journals Scientometrics, Informetrics, and the
relevant subset of JASIST (approx. 20%) that shapes the intellectual space for
the development of information metrics (bibliometrics, scientometrics,
informetrics, and webometrics). The application to information metrics (our own
field of research) provides us with the opportunity to validate this
methodology, and to add a reflection about using citations for the historical
reconstruction. The results show that the field is rooted in individual
contributions of the 1920s-1950s (e.g., Alfred J. Lotka), and was then shaped
intellectually in the early 1960s by a confluence of the history of science
(Derek de Solla Price), documentation (e.g., Michael M. Kessler's
&quot;bibliographic coupling&quot;), and &quot;citation indexing&quot; (Eugene Garfield).
Institutional development at the interfaces between science studies and
information science has been reinforced by the new journal Informetrics since
2007. In a concluding reflection, we return to the question of how the
historiography of science using algorithmic means--in terms of citation
practices--can be different from an intellectual history of the field based,
for example, on reading source materials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5724</identifier>
 <datestamp>2015-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5724</id><created>2013-09-23</created><updated>2015-10-08</updated><authors><author><keyname>Albenque</keyname><forenames>Marie</forenames></author><author><keyname>Knauer</keyname><forenames>Kolja</forenames></author></authors><title>Convexity in partial cubes: the hull number</title><categories>math.CO cs.DM</categories><comments>19 pages, 4 figures</comments><msc-class>05C85, 05C62</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the combinatorial optimization problem of determining the hull
number of a partial cube is NP-complete. This makes partial cubes the minimal
graph class for which NP-completeness of this problem is known and improves
some earlier results in the literature.
  On the other hand we provide a polynomial-time algorithm to determine the
hull number of planar partial cube quadrangulations.
  Instances of the hull number problem for partial cubes described include
poset dimension and hitting sets for interiors of curves in the plane.
  To obtain the above results, we investigate convexity in partial cubes and
characterize these graphs in terms of their lattice of convex subgraphs,
improving a theorem of Handa. Furthermore we provide a topological
representation theorem for planar partial cubes, generalizing a result of
Fukuda and Handa about rank three oriented matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5725</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5725</id><created>2013-09-23</created><authors><author><keyname>Tengviel</keyname><forenames>John</forenames></author><author><keyname>Diawuo</keyname><forenames>K.</forenames></author></authors><title>Comparing the impact of mobile nodes arrival patterns in mobile ad hoc
  networks using poisson and pareto models</title><categories>cs.NI</categories><comments>8 pages, 3 figures</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  5, No. 4, August 2013 International Journal of Wireless &amp; Mobile Networks
  (IJWMN) Vol. 5, No. 4, August 2013</journal-ref><doi>10.5121/ijwmn.2013.5410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad hoc Networks (MANETs) are dynamic networks populated by mobile
stations, or mobile nodes (MNs). Mobility model is a hot topic in many areas,
for example, protocol evaluation, network performance analysis and so on.How to
simulate MNs mobility is the problem we should consider if we want to build an
accurate mobility model. When new nodes can join and other nodes can leave the
network and therefore the topology is dynamic.Specifically, Mobile Ad hoc
Networks consist of a collection of nodes randomly placed in a line (not
necessarily straight). Mobile Ad hoc Networks do appear in many real-world
network applications such as a vehicular Mobile Ad hoc Networks built along a
highway in a city environment or people in a particular location. Mobile Nodes
in Mobile Ad hoc Networks are usually laptops, Personal Digital Assistants or
mobile phones. This paper presents comparative results that have been carried
out via Matrix lab software simulation. The study investigates the impact of
mobility predictive models on mobile nodes parameters such as, the arrival rate
and the size of mobile nodes in a given area using Pareto and Poisson
distributions. The results have indicated that mobile nodes arrival rates may
have influence on Mobile Nodes population (as a larger number) in a location.
The Pareto distribution is more reflective of the modeling mobility for Mobile
Ad hoc Networks than the Poisson distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5735</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5735</id><created>2013-09-23</created><authors><author><keyname>Alahuhta</keyname><forenames>Petteri</forenames></author><author><keyname>Abrahamsson</keyname><forenames>Pekka</forenames></author><author><keyname>Nummiaho</keyname><forenames>Antti</forenames></author></authors><title>On Exploring Consumers' Technology Foresight Capabilities - An Analysis
  of 4000 Mobile Service Ideas</title><categories>cs.HC</categories><comments>Published in ICE-B 2008 - Proceedings of the International Conference
  on e-Business, Porto, Portugal, July 26-29, 2008. INSTICC Press 2008 ISBN
  978-989-8111-58-6</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lead user driven innovation and open innovation paradigms seek to involve
consumers and common people to innovative product development projects. In
order to help developers choose ideas that meet the end users' needs, we
undertook a massive collaborative research effort and collected 40000 ideas
from 2150 common people about future mobile services that they would like to
use. We inspired each people to produce tens of mobile service ideas. In this
paper we carry out an analysis for 4000 ideas from the idea database. We had a
particular interest in whether peoples' ideas can be used in foreseeing the
technology development needs. The results show that end users produce ideas
that are conservative more than novel. Therefore, we claim that consumers'
technology foresight horizon is limited by the existing technological base. The
second finding, linked to the previous one, is that the great majority of the
ideas that consumers expressed could be realised utilizing existing
technologies. The implication of this finding is that the idea database should
be an interesting source of ideas for service developers. The third finding of
the study, related to the methodology, is that a vast number of ideas can be
collected fairly easily but analyzing them cost effectively is a challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5742</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5742</id><created>2013-09-23</created><authors><author><keyname>Melham</keyname><forenames>Tom</forenames></author><author><keyname>Cohn</keyname><forenames>Raphael</forenames></author><author><keyname>Childs</keyname><forenames>Ian</forenames></author></authors><title>On the Semantics of ReFLect as a Basis for a Reflective Theorem Prover</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the semantics of a combinatory fragment of reFLect, the
lambda-calculus underlying a functional language used by Intel Corporation for
hardware design and verification. ReFLect is similar to ML, but has a primitive
data type whose elements are the abstract syntax trees of reFLect expressions
themselves. Following the LCF paradigm, this is intended to serve as the object
language of a higher-order logic theorem prover for specification and reasoning
- but one in which object- and meta-languages are unified. The aim is to
intermix program evaluation and logical deduction through reflection
mechanisms. We identify some difficulties with the semantics of reFLect as
currently defined, and propose a minimal modification of the type system that
avoids these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5749</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5749</id><created>2013-09-23</created><authors><author><keyname>Stankovic</keyname><forenames>Ljubisa</forenames></author><author><keyname>Dakovic</keyname><forenames>Milos</forenames></author><author><keyname>Vujovic</keyname><forenames>Stefan</forenames></author></authors><title>Adaptive Variable Step Algorithm for Missing Samples Recovery in Sparse
  Signals</title><categories>cs.IT math.IT</categories><comments>12 pages, 11 figures, Submitted to IET Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovery of arbitrarily positioned samples that are missing in sparse signals
recently attracted significant research interest. Sparse signals with heavily
corrupted arbitrary positioned samples could be analyzed in the same way as
compressive sensed signals by omitting the corrupted samples and considering
them as unavailable during the recovery process. The reconstruction of missing
samples is done by using one of the well known reconstruction algorithms. In
this paper we will propose a very simple and efficient adaptive variable step
algorithm, applied directly to the concentration measures, without
reformulating the reconstruction problem within the standard linear programming
form. Direct application of the gradient approach to the nondifferentiable
forms of measures lead us to introduce a variable step size algorithm. A
criterion for changing adaptive algorithm parameters is presented. The results
are illustrated on the examples with sparse signals, including approximately
sparse signals and noisy sparse signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5762</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5762</id><created>2013-09-23</created><updated>2016-02-24</updated><authors><author><keyname>Deepak</keyname><forenames>Talasila Sai</forenames></author><author><keyname>Adhya</keyname><forenames>Hindol</forenames></author><author><keyname>Kejriwal</keyname><forenames>Shyamal</forenames></author><author><keyname>Gullapalli</keyname><forenames>Bhanuteja</forenames></author><author><keyname>Shannigrahi</keyname><forenames>Saswata</forenames></author></authors><title>A new hierarchical clustering algorithm to identify non-overlapping
  like-minded communities</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network has a non-overlapping community structure if the nodes of the
network can be partitioned into disjoint sets such that each node in a set is
densely connected to other nodes inside the set and sparsely connected to the
nodes out- side it. There are many metrics to validate the efficacy of such a
structure, such as clustering coefficient, betweenness, centrality, modularity
and like-mindedness. Many methods have been proposed to optimize some of these
metrics, but none of these works well on the recently introduced metric
like-mindedness. To solve this problem, we propose a be- havioral property
based algorithm to identify communities that optimize the like-mindedness
metric and compare its performance on this metric with other behavioral data
based methodologies as well as community detection methods that rely only on
structural data. We execute these algorithms on real-life datasets of
Filmtipset and Twitter and show that our algorithm performs better than the
existing algorithms with respect to the like-mindedness metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5767</identifier>
 <datestamp>2014-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5767</id><created>2013-09-23</created><updated>2014-06-13</updated><authors><author><keyname>Herbelin</keyname><forenames>Hugo</forenames></author><author><keyname>Spiwack</keyname><forenames>Arnaud</forenames></author></authors><title>The Rooster and the Syntactic Bracket</title><categories>cs.LO</categories><comments>To appear in the proceedings of the 19th International Conference on
  Types for Proofs and Programs</comments><acm-class>F.3.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose an extension of pure type systems with an algebraic presentation
of inductive and co-inductive type families with proper indices. This type
theory supports coercions toward from smaller sorts to bigger sorts via
explicit type construction, as well as impredicative sorts. Type families in
impredicative sorts are constructed with a bracketing operation. The necessary
restrictions of pattern-matching from impredicative sorts to types are confined
to the bracketing construct. This type theory gives an alternative presentation
to the calculus of inductive constructions on which the Coq proof assistant is
an implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5769</identifier>
 <datestamp>2015-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5769</id><created>2013-09-23</created><updated>2015-02-18</updated><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author><author><keyname>Lockwood</keyname><forenames>Joseph</forenames></author></authors><title>Creative Gardens</title><categories>cs.CY</categories><comments>4 pages, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can we move beyond simply networking creative individuals to establishing
diverse communities of practice for innovation through discursive methods.
Furthermore, can we digitise their creativity activities within an integrative
socio-cultural collaborative technology platform that could then support
distributed innovation. First, we consider the complexity of creative cultures
from the perspective of design innovation, including how to nurture creativity
activities in what we call Creative Gardens. Specifically, how they could grow,
diverge, and combine, be- ing cultivated to nurture emergent, disruptive,
collaborative innovation. Then, we consider the digitisation of Creative
Gardens from the perspective of digital culture. Specifically, the tenets of
Creative Gardens as dynamic and innovative communities. This includes
considering the challenges and opportunities around digitisation, the
influences around the connectivity with knowledge cultivation, and the
potential for distributed innovation as collective intelligence to utilise
diverse expertise. We conclude be considering the importance of the issues and
questions raised, and their potential for the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5781</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5781</id><created>2013-09-23</created><authors><author><keyname>Fichtenberger</keyname><forenames>Hendrik</forenames></author><author><keyname>Schmidt</keyname><forenames>Melanie</forenames></author></authors><title>PROBI: A Heuristic for the probabilistic k-median problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop the heuristic PROBI for the probabilistic Euclidean k-median
problem based on a coreset construction by Lammersen et al. Our algorithm
computes a summary of the data and then uses an adapted version of k-means++
(Arthur and Vassilvitskii, 2007) to compute a good solution on the summary. The
summary is maintained in a data stream, so PROBI can be used in a data stream
setting on very large data sets. We experimentally evaluate the quality of the
summary and of the computed solution and compare the running time to state of
the art data stream clustering algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5787</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5787</id><created>2013-09-23</created><authors><author><keyname>Berry</keyname><forenames>Anne</forenames></author><author><keyname>Brandst&#xe4;dt</keyname><forenames>Andreas</forenames></author><author><keyname>Engel</keyname><forenames>Konrad</forenames></author></authors><title>The Dilworth Number of Auto-Chordal-Bipartite Graphs</title><categories>cs.DM math.CO</categories><msc-class>05C75, 05C85, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mirror (or bipartite complement) mir(B) of a bipartite graph B=(X,Y,E)
has the same color classes X and Y as B, and two vertices x in X and y in Y are
adjacent in mir(B) if and only if xy is not in E. A bipartite graph is chordal
bipartite if none of its induced subgraphs is a chordless cycle with at least
six vertices. In this paper, we deal with chordal bipartite graphs whose mirror
is chordal bipartite as well; we call these graphs auto-chordal bipartite
graphs (ACB graphs for short). We describe the relationship to some known graph
classes such as interval and strongly chordal graphs and we present several
characterizations of ACB graphs. We show that ACB graphs have unbounded
Dilworth number, and we characterize ACB graphs with Dilworth number k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5802</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5802</id><created>2013-09-18</created><updated>2013-09-24</updated><authors><author><keyname>Kaddoum</keyname><forenames>Georges</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author></authors><title>Lower Bound on the BER of a Decode-and-Forward Relay Network Under Chaos
  Shift Keying Communication System</title><categories>cs.IT cs.PF math.IT</categories><comments>This paper has been accepted for publication and will soon appear in
  the IET Communications Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper carries out the first-ever investigation of the analysis of a
cooperative Decode-and-Forward (DF) relay network with Chaos Shift Keying (CSK)
modulation. The performance analysis of DF-CSK in this paper takes into account
the dynamical nature of chaotic signal, which is not similar to a conventional
binary modulation performance computation methodology. The expression of a
lower bound bit error rate (BER) is derived in order to investigate the
performance of the cooperative system under independently and identically
distributed (i.i.d.) Gaussian fading wireless environments. The effect of the
non-periodic nature of chaotic sequence leading to a non constant bit energy of
the considered modulation is also investigated. A computation approach of the
BER expression based on the probability density function of the bit energy of
the chaotic sequence, channel distribution, and number of relays is presented.
Simulation results prove the accuracy of our BER computation methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5803</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5803</id><created>2013-09-20</created><authors><author><keyname>Ohlsson</keyname><forenames>Henrik</forenames></author><author><keyname>Chen</keyname><forenames>Tianshi</forenames></author><author><keyname>Pakazad</keyname><forenames>Sina Khoshfetrat</forenames></author><author><keyname>Ljung</keyname><forenames>Lennart</forenames></author><author><keyname>Sastry</keyname><forenames>S. Shankar</forenames></author></authors><title>Scalable Anomaly Detection in Large Homogenous Populations</title><categories>cs.LG cs.DC cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anomaly detection in large populations is a challenging but highly relevant
problem. The problem is essentially a multi-hypothesis problem, with a
hypothesis for every division of the systems into normal and anomal systems.
The number of hypothesis grows rapidly with the number of systems and
approximate solutions become a necessity for any problems of practical
interests. In the current paper we take an optimization approach to this
multi-hypothesis problem. We first observe that the problem is equivalent to a
non-convex combinatorial optimization problem. We then relax the problem to a
convex problem that can be solved distributively on the systems and that stays
computationally tractable as the number of systems increase. An interesting
property of the proposed method is that it can under certain conditions be
shown to give exactly the same result as the combinatorial multi-hypothesis
problem and the relaxation is hence tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5821</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5821</id><created>2013-09-20</created><authors><author><keyname>Ward</keyname><forenames>Jonathan Stuart</forenames></author><author><keyname>Barker</keyname><forenames>Adam</forenames></author></authors><title>Undefined By Data: A Survey of Big Data Definitions</title><categories>cs.DB</categories><comments>Big data definition paper, 2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The term big data has become ubiquitous. Owing to a shared origin between
academia, industry and the media there is no single unified definition, and
various stakeholders provide diverse and often contradictory definitions. The
lack of a consistent definition introduces ambiguity and hampers discourse
relating to big data. This short paper attempts to collate the various
definitions which have gained some degree of traction and to furnish a clear
and concise definition of an otherwise ambiguous term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5822</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5822</id><created>2013-09-23</created><updated>2014-05-20</updated><authors><author><keyname>B&#xe1;r&#xe1;ny</keyname><forenames>Vince</forenames><affiliation>University of Warsaw</affiliation></author><author><keyname>Gottlob</keyname><forenames>Georg</forenames><affiliation>Oxford University Computing Laboratory</affiliation></author><author><keyname>Otto</keyname><forenames>Martin</forenames><affiliation>Technische Universit&#xe4;t Darmstadt</affiliation></author></authors><title>Querying the Guarded Fragment</title><categories>cs.LO cs.DB</categories><comments>This is an improved and extended version of the paper of the same
  title presented at LICS 2010</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 2 (May 21,
  2014) lmcs:675</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evaluating a Boolean conjunctive query Q against a guarded first-order theory
F is equivalent to checking whether &quot;F and not Q&quot; is unsatisfiable. This
problem is relevant to the areas of database theory and description logic.
Since Q may not be guarded, well known results about the decidability,
complexity, and finite-model property of the guarded fragment do not obviously
carry over to conjunctive query answering over guarded theories, and had been
left open in general. By investigating finite guarded bisimilar covers of
hypergraphs and relational structures, and by substantially generalising
Rosati's finite chase, we prove for guarded theories F and (unions of)
conjunctive queries Q that (i) Q is true in each model of F iff Q is true in
each finite model of F and (ii) determining whether F implies Q is
2EXPTIME-complete. We further show the following results: (iii) the existence
of polynomial-size conformal covers of arbitrary hypergraphs; (iv) a new proof
of the finite model property of the clique-guarded fragment; (v) the small
model property of the guarded fragment with optimal bounds; (vi) a
polynomial-time solution to the canonisation problem modulo guarded
bisimulation, which yields (vii) a capturing result for guarded bisimulation
invariant PTIME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5823</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5823</id><created>2013-09-23</created><authors><author><keyname>Wang</keyname><forenames>Faqiang</forenames></author><author><keyname>Zuo</keyname><forenames>Wangmeng</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Meng</keyname><forenames>Deyu</forenames></author><author><keyname>Zhang</keyname><forenames>David</forenames></author></authors><title>A Kernel Classification Framework for Metric Learning</title><categories>cs.LG</categories><comments>11 pages, 7 figures</comments><acm-class>I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning a distance metric from the given training samples plays a crucial
role in many machine learning tasks, and various models and optimization
algorithms have been proposed in the past decade. In this paper, we generalize
several state-of-the-art metric learning methods, such as large margin nearest
neighbor (LMNN) and information theoretic metric learning (ITML), into a kernel
classification framework. First, doublets and triplets are constructed from the
training samples, and a family of degree-2 polynomial kernel functions are
proposed for pairs of doublets or triplets. Then, a kernel classification
framework is established, which can not only generalize many popular metric
learning methods such as LMNN and ITML, but also suggest new metric learning
methods, which can be efficiently implemented, interestingly, by using the
standard support vector machine (SVM) solvers. Two novel metric learning
methods, namely doublet-SVM and triplet-SVM, are then developed under the
proposed framework. Experimental results show that doublet-SVM and triplet-SVM
achieve competitive classification accuracies with state-of-the-art metric
learning methods such as ITML and LMNN but with significantly less training
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5826</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5826</id><created>2013-09-23</created><authors><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Dunay</keyname><forenames>Omer</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>Simple Destination-Swap Strategies for Adaptive Intra- and Inter-Tenant
  VM Migration</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the opportunities and limitations of adaptive virtual
machine (VM) migration to reduce communication costs in a virtualized
environment. We introduce a new formal model for the problem of online VM
migration in two scenarios: (1) VMs can be migrated arbitrarily in the
substrate network; e.g., a private cloud provider may have an incentive to
reduce the overall communication cost in the network. (2) VMs can only be
migrated within a given tenant; e.g., a user that was assigned a set of
physical machines may exchange the functionality of the VMs on these machines.
  We propose a simple class of Destination-Swap algorithms which are based on
an aggressive collocation strategy (inspired by splay datastructures) and which
maintain a minimal and local amount of per-node (amortized cost) information to
decide where to migrate a VM and how; thus, the algorithms react quickly to
changes in the load. The algorithms come in two main flavors, an indirect and
distributed variant which keeps existing VM placements local, and a direct
variant which keeps the number of affected VMs small.
  We show that naturally, inter-tenant optimizations yield a larger potential
for optimization, but generally also a tenant itself can improve its embedding.
Moreover, there exists an interesting tradeoff between direct and indirect
strategies: indirect variants are preferable under skewed and sparse
communication patterns due to their locality properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5836</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5836</id><created>2013-09-23</created><authors><author><keyname>Ozyurt</keyname><forenames>Serdar</forenames></author><author><keyname>Torlak</keyname><forenames>Murat</forenames></author></authors><title>Exact Joint Distribution Analysis of Zero-Forcing V-BLAST Gains with
  Greedy Ordering</title><categories>cs.IT math.IT</categories><comments>9 pages, 6 figures, IEEE Transactions on Wireless Communications, to
  appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive the joint probability distribution of zero-forcing (ZF) V-BLAST
gains under a greedy selection of decoding order and no error propagation.
Unlike the previous approximated analyses, a mathematical framework is built by
applying order statistics rules and an exact closed-form joint probability
density function expression for squared layer gains is obtained. Our analysis
relies on the fact that all orderings are equiprobable under independent and
identical Rayleigh fading. Based on this idea, we determine the joint
distribution of the ordered gains from the joint distribution of the unordered
gains. Our results are applicable for any number of transmit and receive
antennas. Although we present our analysis in a ZF V-BLAST setting, our
analytical results can be directly applied for the dual cases of ZF V-BLAST.
Under the assumption of a low rate feedback of decoding order to the
transmitter, a benefit of having exact expressions is illustrated by the
calculation of the cutoff value under optimal power allocation that maximizes
the sum of the substream outage capacities under a given sum power constraint.
We provide numerical results and verify our analysis by means of simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5843</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5843</id><created>2013-09-23</created><authors><author><keyname>Guerini</keyname><forenames>Marco</forenames></author><author><keyname>Gatti</keyname><forenames>Lorenzo</forenames></author><author><keyname>Turchi</keyname><forenames>Marco</forenames></author></authors><title>Sentiment Analysis: How to Derive Prior Polarities from SentiWordNet</title><categories>cs.CL</categories><comments>To appear in Proceedings of EMNLP 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assigning a positive or negative score to a word out of context (i.e. a
word's prior polarity) is a challenging task for sentiment analysis. In the
literature, various approaches based on SentiWordNet have been proposed. In
this paper, we compare the most often used techniques together with newly
proposed ones and incorporate all of them in a learning framework to see
whether blending them can further improve the estimation of prior polarity
scores. Using two different versions of SentiWordNet and testing regression and
classification models across tasks and datasets, our learning approach
consistently outperforms the single metrics, providing a new state-of-the-art
approach in computing words' prior polarity for sentiment analysis. We conclude
our investigation showing interesting biases in calculated prior polarity
scores when word Part of Speech and annotator gender are considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5854</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5854</id><created>2013-09-01</created><authors><author><keyname>Hosseini</keyname><forenames>Seyed Hossein</forenames></author><author><keyname>Shayesteh</keyname><forenames>Mahrokh G.</forenames></author><author><keyname>Amirani</keyname><forenames>Mehdi Chehel</forenames></author></authors><title>Demodulation of Sparse PPM Signals with Low Samples Using Trained RIP
  Matrix</title><categories>cs.OH cs.IT cs.LG math.IT</categories><comments>4 pages, 6 figures, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) theory considers the restricted isometry property
(RIP) as a sufficient condition for measurement matrix which guarantees the
recovery of any sparse signal from its compressed measurements. The RIP
condition also preserves enough information for classification of sparse
symbols, even with fewer measurements. In this work, we utilize RIP bound as
the cost function for training a simple neural network in order to exploit the
near optimal measurements or equivalently near optimal features for
classification of a known set of sparse symbols. As an example, we consider
demodulation of pulse position modulation (PPM) signals. The results indicate
that the proposed method has much better performance than the random
measurements and requires less samples than the optimum matched filter
demodulator, at the expense of some performance loss. Further, the proposed
approach does not need equalizer for multipath channels in contrast to the
conventional receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5862</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5862</id><created>2013-09-23</created><authors><author><keyname>Hemmerling</keyname><forenames>Armin</forenames></author></authors><title>On Regular Sets of Bounds and Determinism versus Nondeterminism</title><categories>cs.CC</categories><comments>29 pages</comments><msc-class>68Q15, 03D15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper illustrates the richness of the concept of regular sets of time
bounds and demonstrates its application to problems of computational
complexity. There is a universe of bounds whose regular subsets allow to
represent several time complexity classes of common interest and are linearly
ordered with respect to the confinality relation which implies the inclusion
between the corresponding complexity classes. By means of classical results of
complexity theory, the separation of determinism from nondeterminism is
possible for a variety of sets of bounds below $n\cdot\log^*(n)$. The system of
all regular bound sets ordered by confinality allows the order-isomorphic
embedding of, e.g., the ordered set of real numbers or the Cantor discontinuum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5866</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5866</id><created>2013-09-23</created><authors><author><keyname>Cai</keyname><forenames>Xing Shi</forenames></author><author><keyname>Devroye</keyname><forenames>Luc</forenames></author></authors><title>A Probabilistic Analysis of Kademlia Networks</title><categories>cs.NI cs.DS</categories><comments>ISAAC 2013</comments><doi>10.1007/978-3-642-45030-3_66</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kademlia is currently the most widely used searching algorithm in P2P
(peer-to-peer) networks. This work studies an essential question about Kademlia
from a mathematical perspective: how long does it take to locate a node in the
network? To answer it, we introduce a random graph K and study how many steps
are needed to locate a given vertex in K using Kademlia's algorithm, which we
call the routing time. Two slightly different versions of K are studied. In the
first one, vertices of K are labelled with fixed IDs. In the second one,
vertices are assumed to have randomly selected IDs. In both cases, we show that
the routing time is about c*log(n), where n is the number of nodes in the
network and c is an explicitly described constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5868</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5868</id><created>2013-09-23</created><updated>2014-09-21</updated><authors><author><keyname>Pequito</keyname><forenames>Sergio</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Aguiar</keyname><forenames>A. Pedro</forenames></author></authors><title>A Framework for Structural Input/Output and Control Configuration
  Selection in Large-Scale Systems</title><categories>math.OC cs.SY</categories><comments>Software for implementing the input-output and control configuration
  selection algorithms presented in the paper can be downloaded from
  http://www.mathworks.com/matlabcentral/fileexchange/46848-a-framework-for-structural-input-output-and-control-configuration-selection-in-large-scale-systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses problems on the structural design of control systems
taking explicitly into consideration the possible application to large-scale
systems. We provide an efficient and unified framework to solve the following
major minimization problems: (i) selection of the minimum number of
manipulated/measured variables to achieve structural
controllability/observability of the system, and (ii) selection of the minimum
number of feedback interconnections between measured and manipulated variables
such that the closed-loop system has no structurally fixed modes. Contrary to
what would be expected, we show that it is possible to obtain a global solution
for each of the aforementioned minimization problems using polynomial
complexity algorithms in the number of the state variables of the system. In
addition, we provide several new graph-theoretic characterizations of
structural systems concepts, which, in turn, enable us to characterize all
possible solutions to the above problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5885</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5885</id><created>2013-09-23</created><authors><author><keyname>Fercoq</keyname><forenames>Olivier</forenames></author><author><keyname>Richt&#xe1;rik</keyname><forenames>Peter</forenames></author></authors><title>Smooth minimization of nonsmooth functions with parallel coordinate
  descent methods</title><categories>cs.DC math.OC stat.ML</categories><comments>39 pages, 1 algorithm, 3 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of a family of randomized parallel coordinate
descent methods for minimizing the sum of a nonsmooth and separable convex
functions. The problem class includes as a special case L1-regularized L1
regression and the minimization of the exponential loss (&quot;AdaBoost problem&quot;).
We assume the input data defining the loss function is contained in a sparse
$m\times n$ matrix $A$ with at most $\omega$ nonzeros in each row. Our methods
need $O(n \beta/\tau)$ iterations to find an approximate solution with high
probability, where $\tau$ is the number of processors and $\beta = 1 +
(\omega-1)(\tau-1)/(n-1)$ for the fastest variant. The notation hides
dependence on quantities such as the required accuracy and confidence levels
and the distance of the starting iterate from an optimal point. Since
$\beta/\tau$ is a decreasing function of $\tau$, the method needs fewer
iterations when more processors are used. Certain variants of our algorithms
perform on average only $O(\nnz(A)/n)$ arithmetic operations during a single
iteration per processor and, because $\beta$ decreases when $\omega$ does,
fewer iterations are needed for sparser problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5896</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5896</id><created>2013-09-23</created><authors><author><keyname>Kronberger</keyname><forenames>Gabriel</forenames></author><author><keyname>Winkler</keyname><forenames>Stephan</forenames></author><author><keyname>Affenzeller</keyname><forenames>Michael</forenames></author><author><keyname>Beham</keyname><forenames>Andreas</forenames></author><author><keyname>Wagner</keyname><forenames>Stefan</forenames></author></authors><title>On the Success Rate of Crossover Operators for Genetic Programming with
  Offspring Selection</title><categories>cs.NE</categories><comments>The final publication is available at
  http://link.springer.com/chapter/10.1007/978-3-642-04772-5_102</comments><journal-ref>Computer Aided Systems Theory - EUROCAST 2009, Lecture Notes in
  Computer Science Volume 5717, 2009, pp 793-800, Springer</journal-ref><doi>10.1007/978-3-642-04772-5_102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genetic programming is a powerful heuristic search technique that is used for
a number of real world applications to solve among others regression,
classification, and time-series forecasting problems. A lot of progress towards
a theoretic description of genetic programming in form of schema theorems has
been made, but the internal dynamics and success factors of genetic programming
are still not fully understood. In particular, the effects of different
crossover operators in combination with offspring selection are largely
unknown.
  This contribution sheds light on the ability of well-known GP crossover
operators to create better offspring when applied to benchmark problems. We
conclude that standard (sub-tree swapping) crossover is a good default choice
in combination with offspring selection, and that GP with offspring selection
and random selection of crossover operators can improve the performance of the
algorithm in terms of best solution quality when no solution size constraints
are applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5904</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5904</id><created>2013-09-23</created><authors><author><keyname>Bera</keyname><forenames>Suman K</forenames></author><author><keyname>Choudhury</keyname><forenames>Anamitra R</forenames></author><author><keyname>Das</keyname><forenames>Syamantak</forenames></author><author><keyname>Roy</keyname><forenames>Sambuddha</forenames></author><author><keyname>Thatchachar</keyname><forenames>Jayram S.</forenames></author></authors><title>Fenchel Duals for Drifting Adversaries</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a primal-dual framework for the design and analysis of online
convex optimization algorithms for {\em drifting regret}. Existing literature
shows (nearly) optimal drifting regret bounds only for the $\ell_2$ and the
$\ell_1$-norms. Our work provides a connection between these algorithms and the
Online Mirror Descent ($\omd$) updates; one key insight that results from our
work is that in order for these algorithms to succeed, it suffices to have the
gradient of the regularizer to be bounded (in an appropriate norm). For
situations (like for the $\ell_1$ norm) where the vanilla regularizer does not
have this property, we have to {\em shift} the regularizer to ensure this.
Thus, this helps explain the various updates presented in \cite{bansal10,
buchbinder12}. We also consider the online variant of the problem with
1-lookahead, and with movement costs in the $\ell_2$-norm. Our primal dual
approach yields nearly optimal competitive ratios for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5905</identifier>
 <datestamp>2014-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5905</id><created>2013-09-23</created><updated>2014-09-30</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author></authors><title>A complexity theory of constructible functions and sheaves</title><categories>math.AG cs.CC math.LO</categories><comments>71 pages, 1 figure. Minor typos corrected. Final version to appear in
  Foundations of Computational Mathematics</comments><msc-class>Primary 14P10, 14P25, Secondary 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce constructible analogs of the discrete complexity
classes $\mathbf{VP}$ and $\mathbf{VNP}$ of sequences of functions. The
functions in the new definitions are constructible functions on $\mathbb{R}^n$
or $\mathbb{C}^n$. We define a class of sequences of constructible functions
that play a role analogous to that of $\mathbf{VP}$ in the more classical
theory. The class analogous to $\mathbf{VNP}$ is defined using Euler
integration. We discuss several examples, develop a theory of completeness, and
pose a conjecture analogous to the $\mathbf{VP}$ vs. $\mathbf{VNP}$ conjecture
in the classical case. In the second part of the paper we extend the notions of
complexity classes to sequences of constructible sheaves over $\mathbb{R}^n$
(or its one point compactification). We introduce a class of sequences of
simple constructible sheaves, that could be seen as the sheaf-theoretic analog
of the Blum-Shub-Smale class $\mathbf{P}_{\mathbb{R}}$. We also define a
hierarchy of complexity classes of sheaves mirroring the polynomial hierarchy,
$\mathbf{PH}_{\mathbb{R}}$, in the B-S-S theory. We prove a singly exponential
upper bound on the topological complexity of the sheaves in this hierarchy
mirroring a similar result in the B-S-S setting. We obtain as a result an
algorithm with singly exponential complexity for a sheaf-theoretic variant of
the real quantifier elimination problem. We pose the natural sheaf-theoretic
analogs of the classical $\mathbf{P}$ vs. $\mathbf{NP}$ question, and also
discuss a connection with Toda's theorem from discrete complexity theory in the
context of constructible sheaves. We also discuss possible generalizations of
the questions in complexity theory related to separation of complexity classes
to more general categories via sequences of adjoint pairs of functors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5909</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5909</id><created>2013-09-23</created><authors><author><keyname>Mohammad</keyname><forenames>Saif</forenames></author></authors><title>From Once Upon a Time to Happily Ever After: Tracking Emotions in Novels
  and Fairy Tales</title><categories>cs.CL</categories><journal-ref>In Proceedings of the ACL Workshop on Language Technology for
  Cultural Heritage, Social Sciences, and Humanities (LaTeCH), 2011, Portland,
  OR</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today we have access to unprecedented amounts of literary texts. However,
search still relies heavily on key words. In this paper, we show how sentiment
analysis can be used in tandem with effective visualizations to quantify and
track emotions in both individual books and across very large collections. We
introduce the concept of emotion word density, and using the Brothers Grimm
fairy tales as example, we show how collections of text can be organized for
better search. Using the Google Books Corpus we show how to determine an
entity's emotion associations from co-occurring words. Finally, we compare
emotion words in fairy tales and novels, to show that fairy tales have a much
wider range of emotion word densities than novels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5914</identifier>
 <datestamp>2015-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5914</id><created>2013-09-23</created><updated>2015-06-03</updated><authors><author><keyname>Ma</keyname><forenames>Zongming</forenames></author><author><keyname>Wu</keyname><forenames>Yihong</forenames></author></authors><title>Computational barriers in minimax submatrix detection</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Published at http://dx.doi.org/10.1214/14-AOS1300 in the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS1300</report-no><journal-ref>Annals of Statistics 2015, Vol. 43, No. 3, 1089-1116</journal-ref><doi>10.1214/14-AOS1300</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the minimax detection of a small submatrix of elevated
mean in a large matrix contaminated by additive Gaussian noise. To investigate
the tradeoff between statistical performance and computational cost from a
complexity-theoretic perspective, we consider a sequence of discretized models
which are asymptotically equivalent to the Gaussian model. Under the hypothesis
that the planted clique detection problem cannot be solved in randomized
polynomial time when the clique size is of smaller order than the square root
of the graph size, the following phase transition phenomenon is established:
when the size of the large matrix $p\to\infty$, if the submatrix size
$k=\Theta(p^{\alpha})$ for any $\alpha\in(0,{2}/{3})$, computational complexity
constraints can incur a severe penalty on the statistical performance in the
sense that any randomized polynomial-time test is minimax suboptimal by a
polynomial factor in $p$; if $k=\Theta(p^{\alpha})$ for any
$\alpha\in({2}/{3},1)$, minimax optimal detection can be attained within
constant factors in linear time. Using Schatten norm loss as a representative
example, we show that the hardness of attaining the minimax estimation rate can
crucially depend on the loss function. Implications on the hardness of support
recovery are also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5927</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5927</id><created>2013-09-23</created><authors><author><keyname>Bousquet-Melou</keyname><forenames>Mireille</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author><author><keyname>Noeth</keyname><forenames>Eric</forenames></author></authors><title>XML Compression via DAGs</title><categories>cs.DS cs.DB</categories><comments>A short version of this paper appeared in the Proceedings of ICDT
  2013</comments><msc-class>68P30, 68P15, 68R05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unranked trees can be represented using their minimal dag (directed acyclic
graph). For XML this achieves high compression ratios due to their repetitive
mark up. Unranked trees are often represented through first child/next sibling
(fcns) encoded binary trees. We study the difference in size (= number of
edges) of minimal dag versus minimal dag of the fcns encoded binary tree. One
main finding is that the size of the dag of the binary tree can never be
smaller than the square root of the size of the minimal dag, and that there are
examples that match this bound. We introduce a new combined structure, the
hybrid dag, which is guaranteed to be smaller than (or equal in size to) both
dags. Interestingly, we find through experiments that last child/previous
sibling encodings are much better for XML compression via dags, than fcns
encodings. We determine the average sizes of unranked and binary dags over a
given set of labels (under uniform distribution) in terms of their exact
generating functions, and in terms of their asymptotical behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5931</identifier>
 <datestamp>2013-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5931</id><created>2013-09-23</created><authors><author><keyname>Kommenda</keyname><forenames>Michael</forenames></author><author><keyname>Kronberger</keyname><forenames>Gabriel</forenames></author><author><keyname>Feilmayr</keyname><forenames>Christoph</forenames></author><author><keyname>Affenzeller</keyname><forenames>Michael</forenames></author></authors><title>Data Mining using Unguided Symbolic Regression on a Blast Furnace
  Dataset</title><categories>cs.NE</categories><comments>Presented at Workshop for Heuristic Problem Solving, Computer Aided
  Systems Theory - EUROCAST 2011. The final publication is available at
  http://link.springer.com/chapter/10.1007/978-3-642-27549-4_51</comments><journal-ref>Computer Aided Systems Theory - EUROCAST 2011, Lecture Notes in
  Computer Science Volume 6927, 2012, pp 400-407</journal-ref><doi>10.1007/978-3-642-27549-4_51</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a data mining approach for variable selection and knowledge
extraction from datasets is presented. The approach is based on unguided
symbolic regression (every variable present in the dataset is treated as the
target variable in multiple regression runs) and a novel variable relevance
metric for genetic programming. The relevance of each input variable is
calculated and a model approximating the target variable is created. The
genetic programming configurations with different target variables are executed
multiple times to reduce stochastic effects and the aggregated results are
displayed as a variable interaction network. This interaction network
highlights important system components and implicit relations between the
variables. The whole approach is tested on a blast furnace dataset, because of
the complexity of the blast furnace and the many interrelations between the
variables. Finally the achieved results are discussed with respect to existing
knowledge about the blast furnace process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5942</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5942</id><created>2013-09-20</created><authors><author><keyname>Mohammad</keyname><forenames>Saif</forenames></author></authors><title>Colourful Language: Measuring Word-Colour Associations</title><categories>cs.CL</categories><comments>arXiv admin note: substantial text overlap with arXiv:1309.5391</comments><journal-ref>Colourful Language: Measuring Word-Colour Associations, Saif
  Mohammad, In Proceedings of the ACL 2011 Workshop on Cognitive Modeling and
  Computational Linguistics (CMCL), June 2011, Portland, OR</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since many real-world concepts are associated with colour, for example danger
with red, linguistic information is often complimented with the use of
appropriate colours in information visualization and product marketing. Yet,
there is no comprehensive resource that captures concept-colour associations.
We present a method to create a large word-colour association lexicon by
crowdsourcing. We focus especially on abstract concepts and emotions to show
that even though they cannot be physically visualized, they too tend to have
strong colour associations. Finally, we show how word-colour associations
manifest themselves in language, and quantify usefulness of co-occurrence and
polarity cues in automatically detecting colour associations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5944</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5944</id><created>2013-09-23</created><authors><author><keyname>Tengviel</keyname><forenames>John</forenames></author><author><keyname>Dotche</keyname><forenames>Koffi A.</forenames></author><author><keyname>Diawuo</keyname><forenames>K.</forenames></author></authors><title>The impact of mobile nodes arrival patterns in mobile ad hoc networks
  using poisson models</title><categories>cs.NI</categories><comments>17 pages, 9 pages. arXiv admin note: substantial text overlap with
  arXiv:1309.5725</comments><journal-ref>International Journal of Managing Information Technology (IJMIT)
  Vol.4, No.3, August 2012</journal-ref><doi>10.5121/ijmit.2012.4305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad hoc Networks (MANETs) are dynamic networks populated by mobile
stations, or mobile nodes (MNs). Specifically, MANETs consist of a collection
of nodes randomly placed in a line (not necessarily straight). Mobile Ad hoc
Networks do appear in many real-world network applications such as a vehicular
Mobile Ad hoc Networks built along a highway in a city environment or people in
a particular location. Mobile Nodes in Mobile Ad hoc Networks are usually
laptops, Personal Digital Assistants or mobile phones. These devices may use
Blue-tooth and/or IEEE 802.11 network interfaces and communicate in a
decentralized manner. Mobility is a key feature of Mobile Ad hoc Networks. Each
node may work as a router and the network can dynamically change with time;
when new nodes can join, and other nodes can leave the network. This paper
presents comparative results that have been carried out via Matrix lab software
simulation. The study investigates the impact of mobile nodes parameters such
as the speed, the arrival rate and the size of mobile nodes in a given area
using Poisson distribution. The results have indicated that mobile nodes
arrival rates may have influence on Mobile Nodes population (as a larger
number) in a location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5946</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5946</id><created>2013-09-23</created><authors><author><keyname>Beling</keyname><forenames>Piotr</forenames></author></authors><title>A Complexity of double dummy bridge</title><categories>cs.GT</categories><comments>10 pages, in Polish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analysis of complexity of double dummy bridge. Values
of both, a state-space (search-space) complexity and a game tree complexity
have been estimated.
  -----
  Oszacowanie z{\l}o\.zono\'sci problemu rozgrywki w otwarte karty w bryd\.zu
  Artyku{\l} zawiera analiz{\ke} z{\l}o\.zono\'sci problemu rozgrywki w otwarte
karty w bryd\.zu, przy u\.zyciu miar zaproponowanych przez Louisa Victora
Allisa. Oszacowane s{\ka} w nim z{\l}o\.zono\'sci przestrzeni stan\'ow i drzewa
wspomnianej gry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5979</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5979</id><created>2013-09-23</created><authors><author><keyname>Mousavi</keyname><forenames>Ali</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Asymptotic Analysis of LASSOs Solution Path with Implications for
  Approximate Message Passing</title><categories>math.ST cs.IT math.IT stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the performance of the LASSO (also knows as basis pursuit
denoising) for recovering sparse signals from undersampled, randomized, noisy
measurements. We consider the recovery of the signal $x_o \in \mathbb{R}^N$
from $n$ random and noisy linear observations $y= Ax_o + w$, where $A$ is the
measurement matrix and $w$ is the noise. The LASSO estimate is given by the
solution to the optimization problem $x_o$ with $\hat{x}_{\lambda} = \arg
\min_x \frac{1}{2} \|y-Ax\|_2^2 + \lambda \|x\|_1$. Despite major progress in
the theoretical analysis of the LASSO solution, little is known about its
behavior as a function of the regularization parameter $\lambda$. In this paper
we study two questions in the asymptotic setting (i.e., where $N \rightarrow
\infty$, $n \rightarrow \infty$ while the ratio $n/N$ converges to a fixed
number in $(0,1)$): (i) How does the size of the active set
$\|\hat{x}_\lambda\|_0/N$ behave as a function of $\lambda$, and (ii) How does
the mean square error $\|\hat{x}_{\lambda} - x_o\|_2^2/N$ behave as a function
of $\lambda$? We then employ these results in a new, reliable algorithm for
solving LASSO based on approximate message passing (AMP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5984</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5984</id><created>2013-09-23</created><authors><author><keyname>Lord</keyname><forenames>Phillip</forenames></author></authors><title>An evolutionary approach to Function</title><categories>cs.AI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Background: Understanding the distinction between function and role is vexing
and difficult. While it appears to be useful, in practice this distinction is
hard to apply, particularly within biology.
  Results: I take an evolutionary approach, considering a series of examples,
to develop and generate definitions for these concepts. I test them in practice
against the Ontology for Biomedical Investigations (OBI). Finally, I give an
axiomatisation and discuss methods for applying these definitions in practice.
  Conclusions: The definitions in this paper are applicable, formalizing
current practice. As such, they make a significant contribution to the use of
these concepts within biomedical ontologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5991</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5991</id><created>2013-09-23</created><authors><author><keyname>Burr</keyname><forenames>Michael A.</forenames></author></authors><title>Applications of Continuous Amortization to Bisection-based Root
  Isolation</title><categories>cs.DS cs.SC</categories><msc-class>68W40, 68W30, 14Q20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous amortization is a technique for computing the complexity of
algorithms, and it was first presented by the author in Burr, Krahmer, &amp; Yap
(2009). Continuous amortization can result in simpler and more straight-forward
complexity analyses, and it was used in Burr, Krahmer, &amp; Yap (2009), Burr &amp;
Krahmer (2012), and Sharma &amp; Yap (2012) to provide complexity bounds for simple
root isolation algorithms. This paper greatly extends the reach of continuous
amortization to serve as an overarching technique which can be used to compute
complexity of many root isolation techniques in a straight-forward manner.
Additionally, the technique of continuous amortization is extended to higher
dimensions and to the computation of the bit-complexity of algorithms. In this
paper, six continuous amortization calculations are performed to compute
complexity bounds (on either the size of the subdivision tree or the bit
complexity) for several algorithms (including algorithms based on Sturm
sequences, Descartes' rule of signs, and polynomial evaluation); in each case,
continuous amortization achieves an optimal complexity bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5993</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5993</id><created>2013-09-23</created><authors><author><keyname>Long</keyname><forenames>Ying</forenames></author><author><keyname>Thill</keyname><forenames>Jean-Claude</forenames></author></authors><title>Combining smart card data and household travel survey to analyze
  jobs-housing relationships in Beijing</title><categories>cs.SI physics.soc-ph</categories><comments>35 pages, 13 figures</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location Based Services (LBS) provide a new perspective for spatiotemporally
analyzing dynamic urban systems. Research has investigated urban dynamics using
GSM (Global System for Mobile Communications), GPS (Global Positioning System),
SNS (Social Networking Services) and Wi-Fi techniques. However, less attention
has been paid to the analysis of urban structure (especially commuting pattern)
using smart card data (SCD), which are widely available in most cities.
Additionally, ubiquitous LBS data, although providing rich spatial and temporal
information, lacks rich information on the social dimension, which limits its
in-depth application. To bridge this gap, this paper combines bus SCD for a
one-week period with a one-day household travel survey, as well as a
parcel-level land use map to identify job-housing locations and commuting trip
routes in Beijing. Two data forms (TRIP and PTD) are proposed, with PTD used
for jobs-housing identification and TRIP used for commuting trip route
identification. The results of the identification are aggregated in the bus
stop and traffic analysis zone (TAZ) scales, respectively. Particularly,
commuting trips from three typical residential communities to six main business
zones are mapped and compared to analyze commuting patterns in Beijing. The
identified commuting trips are validated on three levels by comparison with
those from the survey in terms of commuting time and distance, and the positive
validation results prove the applicability of our approach. Our experiment, as
a first step toward enriching LBS data using conventional survey and urban GIS
data, can obtain solid identification results based on rules extracted from
existing surveys or censuses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.5997</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.5997</id><created>2013-09-23</created><authors><author><keyname>Kharitonov</keyname><forenames>Daniel</forenames></author><author><keyname>Ibatullin</keyname><forenames>Oscar</forenames></author></authors><title>Extended Security Risks in IP Networks</title><categories>cs.NI</categories><comments>preprint submitted to ICC 2014</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Exploitation techniques targeting intermediate (transit) network nodes in
public and private networks have been theoretically known and empirically
proven to work for quite some time. However, very little effort has been made
to look into the network-specific risks of compromising the Internet
infrastructure to this date. In this publication, we describe several methods
of hijacking live network traffic following a successful attack on a router or
switch. We demonstrate that modern network platforms are capable of targeted
traffic replication and redirection for online and offline analysis and
modification, which can be a threat far greater than loss of service or other
risks frequently associated with such exploits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6000</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6000</id><created>2013-09-23</created><authors><author><keyname>Diongue</keyname><forenames>Dame</forenames></author><author><keyname>Thiare</keyname><forenames>Ousmane</forenames></author></authors><title>A New Sentinel Approach for Energy Efficient and Hole Aware Wireless
  Sensor Networks</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recent advances in micro-sensor and communication technology have enabled the
emergence of a new technology, Wireless Sensor Networks (WSN). WSN have
emerging recently as a key solution to monitor remote or hostile environments
and concern a wide range of applications. These networks are faced with many
challenges such as energy efficiency usage, topology maintenance, network
lifetime maximization, etc. Experience shows that sensing and communications
tasks consume energy, therefore judicious power management can effectively
extend network lifetime. Moreover, the low cost of sensor devices will allows
deployment of huge number nodes that can permit a high redundancy degree. In
this paper, we focus on the problem of energy efficiency and topology
maintenance in a densely deployed network context. Hence we propose an energy
aware sleep scheduling and rapid topology healing scheme for long life wireless
sensor networks. Our scheme is a strong node scheduling based mechanism for
lifetime maximization in wireless sensor networks and has a fast maintenance
method to cover nodes failure. Our sentinel scheme is based on a probabilistic
model which provides a distributed sleep scheduling and topology control
algorithm. Simulations and experimental results are presented to verify our
approach and the performance of our mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6001</identifier>
 <datestamp>2015-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6001</id><created>2013-09-23</created><updated>2014-02-01</updated><authors><author><keyname>Antoniades</keyname><forenames>Demetris</forenames></author><author><keyname>Dovrolis</keyname><forenames>Constantine</forenames></author></authors><title>Co-evolutionary dynamics in social networks: A case study of Twitter</title><categories>cs.SI physics.soc-ph</categories><comments>11 pages, 7 figures</comments><doi>10.1186/s40649-015-0023-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks often exhibit co-evolutionary dynamics, meaning that the
network topology and the state of nodes or links are coupled, affecting each
other in overlapping time scales. We focus on the co-evolutionary dynamics of
online social networks, and on Twitter in particular. Monitoring the activity
of thousands of Twitter users in real-time, and tracking their followers and
tweets/retweets, we propose a method to infer new retweet-driven follower
relations. The formation of such relations is much more likely than the
exogenous creation of new followers in the absence of any retweets. We identify
the most significant factors (reciprocity and the number of retweets that a
potential new follower receives) and propose a simple probabilistic model of
this effect. We also discuss the implications of such co-evolutionary dynamics
on the topology and function of a social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6027</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6027</id><created>2013-09-23</created><authors><author><keyname>Chen</keyname><forenames>Xiaoming</forenames></author><author><keyname>Wang</keyname><forenames>Xiumin</forenames></author><author><keyname>Chen</keyname><forenames>Xianfu</forenames></author></authors><title>Energy-Efficient Optimization for Wireless Information and Power
  Transfer in Large-Scale MIMO Systems Employing Energy Beamforming</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures. IEEE Wireless Communications Letters 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider a large-scale multiple-input multiple-output
(MIMO) system where the receiver should harvest energy from the transmitter by
wireless power transfer to support its wireless information transmission. The
energy beamforming in the large-scale MIMO system is utilized to address the
challenging problem of long-distance wireless power transfer. Furthermore,
considering the limitation of the power in such a system, this letter focuses
on the maximization of the energy efficiency of information transmission (bit
per Joule) while satisfying the quality-of-service (QoS) requirement, i.e.
delay constraint, by jointly optimizing transfer duration and transmit power.
By solving the optimization problem, we derive an energy-efficient resource
allocation scheme. Numerical results validate the effectiveness of the proposed
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6036</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6036</id><created>2013-09-23</created><authors><author><keyname>Fish</keyname><forenames>Alexander</forenames></author><author><keyname>Gurevich</keyname><forenames>Shamgar</forenames></author></authors><title>Almost Linear Complexity Methods for Delay-Doppler Channel Estimation</title><categories>cs.IT math.IT</categories><comments>4 double column pages. arXiv admin note: substantial text overlap
  with arXiv:1309.3720</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental task in wireless communication is channel estimation: Compute
the channel parameters a signal undergoes while traveling from a transmitter to
a receiver. In the case of delay-Doppler channel, i.e., a signal undergoes only
delay and Doppler shifts, a widely used method to compute delay-Doppler
parameters is the pseudo-random method. It uses a pseudo-random sequence of
length N; and, in case of non-trivial relative velocity between transmitter and
receiver, its computational complexity is O(N^2logN) arithmetic operations. In
[1] the flag method was introduced to provide a faster algorithm for
delay-Doppler channel estimation. It uses specially designed flag sequences and
its complexity is O(rNlogN) for channels of sparsity r. In these notes, we
introduce the incidence and cross methods for channel estimation. They use
triple-chirp and double-chirp sequences of length N, correspondingly. These
sequences are closely related to chirp sequences widely used in radar systems.
The arithmetic complexity of the incidence and cross methods is O(NlogN + r^3),
and O(NlogN + r^2), respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6041</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6041</id><created>2013-09-24</created><updated>2014-09-13</updated><authors><author><keyname>Yu</keyname><forenames>Jingjin</forenames></author><author><keyname>Karaman</keyname><forenames>Sertac</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>Persistent Monitoring of Events with Stochastic Arrivals at Multiple
  Stations</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new mobile sensor scheduling problem, involving a
single robot tasked with monitoring several events of interest that occur at
different locations. Of particular interest is the monitoring of transient
events that can not be easily forecast. Application areas range from natural
phenomena ({\em e.g.}, monitoring abnormal seismic activity around a volcano
using a ground robot) to urban activities ({\em e.g.}, monitoring early
formations of traffic congestion using an aerial robot). Motivated by those and
many other examples, this paper focuses on problems in which the precise
occurrence times of the events are unknown {\em a priori}, but statistics for
their inter-arrival times are available. The robot's task is to monitor the
events to optimize the following two objectives: {\em (i)} maximize the number
of events observed and {\em (ii)} minimize the delay between two consecutive
observations of events occurring at the same location. The paper considers the
case when a robot is tasked with optimizing the event observations in a
balanced manner, following a cyclic patrolling route. First, assuming the
cyclic ordering of stations is known, we prove the existence and uniqueness of
the optimal solution, and show that the optimal solution has desirable
convergence and robustness properties. Our constructive proof also produces an
efficient algorithm for computing the unique optimal solution with $O(n)$ time
complexity, in which $n$ is the number of stations, with $O(\log n)$ time
complexity for incrementally adding or removing stations. Except for the
algorithm, most of the analysis remains valid when the cyclic order is unknown.
We then provide a polynomial-time approximation scheme that gives a
$(1+\epsilon)$-optimal solution for this more general, NP-hard problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6047</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6047</id><created>2013-09-24</created><authors><author><keyname>Lyubimov</keyname><forenames>Nikolay</forenames></author><author><keyname>Kotov</keyname><forenames>Mikhail</forenames></author></authors><title>Non-negative Matrix Factorization with Linear Constraints for
  Single-Channel Speech Enhancement</title><categories>cs.SD cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a non-negative matrix factorization (NMF)-based
approach to the semi-supervised single-channel speech enhancement problem where
only non-stationary additive noise signals are given. The proposed method
relies on sinusoidal model of speech production which is integrated inside NMF
framework using linear constraints on dictionary atoms. This method is further
developed to regularize harmonic amplitudes. Simple multiplicative algorithms
are presented. The experimental evaluation was made on TIMIT corpus mixed with
various types of noise. It has been shown that the proposed method outperforms
some of the state-of-the-art noise suppression techniques in terms of
signal-to-noise ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6064</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6064</id><created>2013-09-24</created><authors><author><keyname>Islam</keyname><forenames>Md. Shafiqul</forenames></author><author><keyname>Shirin</keyname><forenames>Afroza</forenames></author></authors><title>Numerical solutions of a class of second order boundary value problems
  on using Bernoulli Polynomials</title><categories>cs.NA math.NA</categories><comments>6 tables</comments><doi>10.4236/am.2011.29147</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to find the numerical solutions of the second order
linear and nonlinear differential equations with Dirichlet, Neumann and Robin
boundary conditions. We use the Bernoulli polynomials as linear combination to
the approximate solutions of 2nd order boundary value problems. Here the
Bernoulli polynomials over the interval [0, 1] are chosen as trial functions so
that care has been taken to satisfy the corresponding homogeneous form of the
Dirichlet boundary conditions in the Galerkin weighted residual method. In
addition to that the given differential equation over arbitrary finite domain
[a, b] and the boundary conditions are converted into its equivalent form over
the interval [0, 1]. All the formulas are verified by considering numerical
examples. The approximate solutions are compared with the exact solutions, and
also with the solutions of the existing methods. A reliable good accuracy is
obtained in all cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6069</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6069</id><created>2013-09-24</created><authors><author><keyname>Farnik</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Kowalik</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Soca&#x142;a</keyname><forenames>Arkadiusz</forenames></author></authors><title>Beyond the Shannon's Bound</title><categories>cs.DS cs.DM math.CO</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G=(V,E)$ be a multigraph of maximum degree $\Delta$. The edges of $G$
can be colored with at most $\frac{3}{2}\Delta$ colors by Shannon's theorem. We
study lower bounds on the size of subgraphs of $G$ that can be colored with
$\Delta$ colors.
  Shannon's Theorem gives a bound of
$\frac{\Delta}{\lfloor\frac{3}{2}\Delta\rfloor}|E|$. However, for $\Delta=3$,
Kami\'{n}ski and Kowalik [SWAT'10] showed that there is a 3-edge-colorable
subgraph of size at least $\frac{7}{9}|E|$, unless $G$ has a connected
component isomorphic to $K_3+e$ (a $K_3$ with an arbitrary edge doubled). Here
we extend this line of research by showing that $G$ has a $\Delta$-edge
colorable subgraph with at least
$\frac{\Delta}{\lfloor\frac{3}{2}\Delta\rfloor-1}|E|$ edges, unless $\Delta$ is
even and $G$ contains $\frac{\Delta}{2}K_3$ or $\Delta$ is odd and $G$ contains
$\frac{\Delta-1}{2}K_3+e$. Moreover, the subgraph and its coloring can be found
in polynomial time.
  Our results have applications in approximation algorithms for the Maximum
$k$-Edge-Colorable Subgraph problem, where given a graph $G$ (without any bound
on its maximum degree or other restrictions) one has to find a
$k$-edge-colorable subgraph with maximum number of edges. In particular, for
every even $k \ge 4$ we obtain a $\frac{2k+2}{3k+2}$-approximation and for
every odd $k\ge 5$ we get a $\frac{2k+1}{3k}$-approximation. When $4\le k \le
13$ this improves over earlier algorithms due to Feige et al. [APPROX'02]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6073</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6073</id><created>2013-09-24</created><authors><author><keyname>Song</keyname><forenames>Chao-Bing</forenames></author><author><keyname>Xia</keyname><forenames>Shu-Tao</forenames></author><author><keyname>Liu</keyname><forenames>Xin-ji</forenames></author></authors><title>Improved Analyses for SP and CoSaMP Algorithms in Terms of Restricted
  Isometry Constants</title><categories>cs.IT math.IT</categories><doi>10.1109/LSP.2014.2336733</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of compressed sensing (CS), both Subspace Pursuit (SP) and
Compressive Sampling Matching Pursuit (CoSaMP) are very important iterative
greedy recovery algorithms which could reduce the recovery complexity greatly
comparing with the well-known $\ell_1$-minimization. Restricted isometry
property (RIP) and restricted isometry constant (RIC) of measurement matrices
which ensure the convergency of iterative algorithms play key roles for the
guarantee of successful reconstructions. In this paper, we show that for the
$s$-sparse recovery, the RICs are enlarged to $\delta_{3s}&lt;0.4859$ for SP and
$\delta_{4s}&lt;0.5$ for CoSaMP, which improve the known results significantly.
The proposed results also apply to almost sparse signal and corrupted
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6078</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6078</id><created>2013-09-24</created><authors><author><keyname>Romanov</keyname><forenames>V. F.</forenames></author></authors><title>Discordant Compact Logic-Arithmetic Structures in Discrete Optimization
  Problems</title><categories>cs.DS</categories><comments>17 pages; typeset in LaTeX. arXiv admin note: substantial text
  overlap with arXiv:1011.3944</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In sphere of research of discrete optimization algorithms efficiency the
important place occupies a method of polynomial reducibility of some problems
to others with use of special purpose components. In this paper a novel method
of compact representation for sets of binary sequences in the form of &quot;compact
triplets structures&quot; (CTS) and &quot;compact couples structures&quot; (CCS) is stated,
supposing both logic and arithmetic interpretation of data. It is shown that
any non-empty CTS in dual interpretation represents some unique Boolean formula
in 3-CNF and the tabular CTS contains all satisfyig sets of the formula as
concatenations of the triplets chosen from the neighbouring tiers. In general,
any 3-CNF formula is transformed by decomposition to a system of discordant
CTS's, each being associated with an individual permutation of variables
constructed by a polynomial algorithm. As a result the problem of the formula
satisfiability is reduced to the following one: ascertain the fact of existence
(or absence) of a &quot;joint satisfying set&quot; (JSS) for all discordant structures,
based on the different permutations. Further transformation of each CTS to CCS
is used; correctness of preservation of the allowed sets is reached by simple
algorithmic restrictions on triplets concatenation. Then the procedure of
&quot;inverting of the same name columns&quot; in the various structures is entered for
the purpose of reducing the problem of JSS revealing to elementary detection of
n-tuples of zeros in the CCS system. The formula is synthesized, being on the
structure a variation of 2-CNF, associated with the calculation procedure
realizing adaptation of the polynomial algorithm of constraints distribution
(well-known in the optimization theory) to the efficient resolving Boolean
formula coded by means of discordant compact structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6109</identifier>
 <datestamp>2015-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6109</id><created>2013-09-24</created><updated>2015-06-22</updated><authors><author><keyname>Garc&#xed;a</keyname><forenames>&#xc1;lvaro L&#xf3;pez</forenames></author><author><keyname>del Castillo</keyname><forenames>Enol Fern&#xe1;ndez</forenames></author></authors><title>Analysis of Scientific Cloud Computing requirements</title><categories>cs.DC cs.CE</categories><journal-ref>7th Iberian Grid Infrastructure Conference (IBERGRID 2013)
  proceedings, pp 147-158</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the requirements of enterprise and web applications have driven the
development of Cloud computing, some of its key features, such as customized
environments and rapid elasticity, could also benefit scientific applications.
However, neither virtualization techniques nor Cloud-like access to resources
is common in scientific computing centers due to the negative perception of the
impact that virtualization techniques introduce.
  In this paper we discuss the feasibility of the IaaS cloud model to satisfy
some of the computational science requirements and the main drawbacks that need
to be addressed by cloud resource providers so that the maximum benefit can be
obtained from a given cloud infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6115</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6115</id><created>2013-09-24</created><updated>2013-12-25</updated><authors><author><keyname>Lin</keyname><forenames>Chengyu</forenames></author><author><keyname>Liu</keyname><forenames>Jingcheng</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author></authors><title>A Simple FPTAS for Counting Edge Covers</title><categories>cs.DS</categories><comments>To appear in SODA 2014</comments><doi>10.1137/1.9781611973402.25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An edge cover of a graph is a set of edges such that every vertex has at
least an adjacent edge in it. Previously, approximation algorithm for counting
edge covers is only known for 3 regular graphs and it is randomized. We design
a very simple deterministic fully polynomial-time approximation scheme (FPTAS)
for counting the number of edge covers for any graph. Our main technique is
correlation decay, which is a powerful tool to design FPTAS for counting
problems. In order to get FPTAS for general graphs without degree bound, we
make use of a stronger notion called computationally efficient correlation
decay, which is introduced in [Li, Lu, Yin SODA 2012].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6116</identifier>
 <datestamp>2015-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6116</id><created>2013-09-24</created><updated>2015-02-20</updated><authors><author><keyname>Jeffery</keyname><forenames>Stacey</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Magniez</keyname><forenames>Frederic</forenames><affiliation>Universite Paris Diderot</affiliation></author><author><keyname>de Wolf</keyname><forenames>Ronald</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>Optimal parallel quantum query algorithms</title><categories>quant-ph cs.CC</categories><comments>19 pages LaTeX</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of quantum query algorithms that make p queries in
parallel in each timestep. This model is in part motivated by the fact that
decoherence times of qubits are typically small, so it makes sense to
parallelize quantum algorithms as much as possible. We show tight bounds for a
number of problems, specifically Theta((n/p)^{2/3}) p-parallel queries for
element distinctness and Theta((n/p)^{k/(k+1)} for k-sum. Our upper bounds are
obtained by parallelized quantum walk algorithms, and our lower bounds are
based on a relatively small modification of the adversary lower bound method,
combined with recent results of Belovs et al. on learning graphs. We also prove
some general bounds, in particular that quantum and classical p-parallel
complexity are polynomially related for all total functions f when p is small
compared to f's block sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6123</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6123</id><created>2013-09-24</created><authors><author><keyname>P&#xe4;&#xe4;kk&#xf6;nen</keyname><forenames>J.</forenames></author><author><keyname>Hollanti</keyname><forenames>C.</forenames></author><author><keyname>Tirkkonen</keyname><forenames>O.</forenames></author></authors><title>Device-to-Device Data Storage for Mobile Cellular Systems</title><categories>cs.NI</categories><comments>6 pages, 9 figures. Accepted, will appear in the proceedings of
  Globecom 2013 (Device-to-Device (D2D) Communication With and Without
  Infrastructure)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an alternative to downloading content from a cellular access network,
mobile devices could be used to store data files and distribute them through
device-to-device (D2D) communication. We consider a D2D-based storage community
that is comprised of mobile users. Assuming that transmitting data from a base
station to a mobile user consumes more energy than transmitting data between
two mobile users, we show that it can be beneficial to use redundant storage to
ensure that data files stay available to the community even if some of the
storing users leave the network. We derive a tractable closed-form equation
stating when redundancy should be used in order to minimize the expected energy
consumption of data retrieval. We find that replication is the preferred method
of adding redundancy as opposed to regenerating codes. Our findings are
verified by computer simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6124</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6124</id><created>2013-09-24</created><authors><author><keyname>Boja&#x144;czyk</keyname><forenames>Miko&#x142;aj</forenames></author></authors><title>Transducers with origin information</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Call a string-to-string transducer regular if it can be realised by one of
the following equivalent models: mso transductions, two-way deterministic
automata with output, and streaming transducers with registers. This paper
proposes to treat origin information as part of the semantics of a regular
string-to-string transducer. With such semantics, the model admits a
machine-independent characterisation, Angluin-style learning in polynomial
time, as well as effective characterisations of natural subclasses such as
one-way transducers or first-order definable transducers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6129</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6129</id><created>2013-09-24</created><authors><author><keyname>Blondel</keyname><forenames>Vincent</forenames></author><author><keyname>Jung</keyname><forenames>Kyomin</forenames></author><author><keyname>Kohli</keyname><forenames>Pushmeet</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>Partition-Merge: Distributed Inference and Modularity Optimization</title><categories>cs.DS cs.AI cs.SI</categories><comments>19 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel meta algorithm, Partition-Merge (PM), which takes
existing centralized algorithms for graph computation and makes them
distributed and faster. In a nutshell, PM divides the graph into small
subgraphs using our novel randomized partitioning scheme, runs the centralized
algorithm on each partition separately, and then stitches the resulting
solutions to produce a global solution. We demonstrate the efficiency of the PM
algorithm on two popular problems: computation of Maximum A Posteriori (MAP)
assignment in an arbitrary pairwise Markov Random Field (MRF), and modularity
optimization for community detection. We show that the resulting distributed
algorithms for these problems essentially run in time linear in the number of
nodes in the graph, and perform as well -- or even better -- than the original
centralized algorithm as long as the graph has geometric structures. Here we
say a graph has geometric structures, or polynomial growth property, when the
number of nodes within distance r of any given node grows no faster than a
polynomial function of r. More precisely, if the centralized algorithm is a
C-factor approximation with constant C \ge 1, the resulting distributed
algorithm is a (C+\delta)-factor approximation for any small \delta&gt;0; but if
the centralized algorithm is a non-constant (e.g. logarithmic) factor
approximation, then the resulting distributed algorithm becomes a constant
factor approximation. For general graphs, we compute explicit bounds on the
loss of performance of the resulting distributed algorithm with respect to the
centralized algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6131</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6131</id><created>2013-09-24</created><updated>2015-02-13</updated><authors><author><keyname>Ahmed</keyname><forenames>Mahmuda</forenames></author><author><keyname>Fasy</keyname><forenames>Brittany Terese</forenames></author><author><keyname>Hickmann</keyname><forenames>Kyle S.</forenames></author><author><keyname>Wenk</keyname><forenames>Carola</forenames></author></authors><title>Path-Based Distance for Street Map Comparison</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comparing two geometric graphs embedded in space is important in the field of
transportation network analysis. Given street maps of the same city collected
from different sources, researchers often need to know how and where they
differ. However, the majority of current graph comparison algorithms are based
on structural properties of graphs, such as their degree distribution or their
local connectivity properties, and do not consider their spatial embedding.
This ignores a key property of road networks since similarity of travel over
two road networks is intimately tied to the specific spatial embedding.
Likewise, many current street map comparison algorithms focus on the spatial
embeddings only and do not take structural properties into account, which makes
these algorithms insensitive to local connectivity properties and shortest path
similarities. We propose a new path-based distance measure to compare two
planar geometric graphs embedded in the plane. Our distance measure takes
structural as well as spatial properties into account by imposing a distance
measure between two road networks based on the Hausdorff distance between the
two sets of travel paths they represent. We show that this distance can be
approximated in polynomial time and that it preserves structural and spatial
properties of the graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6132</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6132</id><created>2013-09-24</created><authors><author><keyname>Minsky</keyname><forenames>Naftaly</forenames></author></authors><title>An Approach to Modularization of Distributed Systems</title><categories>cs.DC cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modularization is an important architectural principle underlying many types
of complex systems. It tends to tame the complexity of systems, to facilitate
their management, and to enhance their flexibility with respect to evolution.
In software, modularization has been practiced and studied thoroughly in local,
i.e. non-distributed systems. But very little attention has been paid so far to
modularization in distributed systems. This is, in part, because distributed
systems are inherently modularized, in the sense that the internals of each
component of such a system is inaccessible to other components, thus satisfying
the Parnas hiding principle. It is, however, the thesis of this paper that
there is much to be gained by being able to treat groups of distributed
components as modules, called here distributed modules. And that besides the
conventional hiding principle, distributed modularization should provide
additional capabilities, which rarely, if ever, figure in conventional
modularized systems. These capabilities include, but are not limited to: the
ability to impose constraints on which kind of messages can be sent from a
given distributed-module to its outside; and the ability to create AOP-like
crosscutting modules. This paper introduces a model of modular distributed
system, orMDS, which satisfies such capabilities, and which is implemented via
the LGI middleware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6134</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6134</id><created>2013-09-24</created><authors><author><keyname>Mac Carron</keyname><forenames>P.</forenames></author><author><keyname>Kenna</keyname><forenames>R.</forenames></author></authors><title>Network analysis of the \'{I}slendinga s\&quot;{o}gur - the Sagas of
  Icelanders</title><categories>physics.soc-ph cs.SI</categories><comments>9 pages, 9 figures, 3 Tables</comments><journal-ref>Eur. Phys. J. B, 86 10 (2013) 407</journal-ref><doi>10.1140/epjb/e2013-40583-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \'{I}slendinga s\&quot;{o}gur - or Sagas of Icelanders - constitute a
collection of medieval literature set in Iceland around the late 9th to early
11th centuries, the so-called Saga Age. They purport to describe events during
the period around the settlement of Iceland and the generations immediately
following and constitute an important element of world literature thanks to
their unique narrative style. Although their historicity is a matter of
scholarly debate, the narratives contain interwoven and overlapping plots
involving thousands of characters and interactions between them. Here we
perform a network analysis of the \'{I}slendinga s\&quot;{o}gur in an attempt to
gather quantitative information on interrelationships between characters and to
compare saga society to other social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6144</identifier>
 <datestamp>2013-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6144</id><created>2013-09-24</created><updated>2013-10-10</updated><authors><author><keyname>Bourgeois</keyname><forenames>Nicolas</forenames></author><author><keyname>Dabrowski</keyname><forenames>Konrad K.</forenames></author><author><keyname>Demange</keyname><forenames>Marc</forenames></author><author><keyname>Paschos</keyname><forenames>Vangelis Th.</forenames></author></authors><title>Playing with parameters: structural parameterization in graphs</title><categories>cs.CC cs.DS</categories><comments>17 pages</comments><msc-class>05C85</msc-class><acm-class>F.2.2; F.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When considering a graph problem from a parameterized point of view, the
parameter chosen is often the size of an optimal solution of this problem (the
&quot;standard&quot; parameter). A natural subject for investigation is what happens when
we parameterize such a problem by various other parameters, some of which may
be the values of optimal solutions to different problems. Such research is
known as parameterized ecology. In this paper, we investigate seven natural
vertex problems, along with their respective parameters: the size of a maximum
independent set, the size of a minimum vertex cover, the size of a maximum
clique, the chromatic number, the size of a minimum dominating set, the size of
a minimum independent dominating set and the size of a minimum feedback vertex
set. We study the parameterized complexity of each of these problems with
respect to the standard parameter of the others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6148</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6148</id><created>2013-09-24</created><authors><author><keyname>Brito</keyname><forenames>Jose Andre de Moura</forenames></author><author><keyname>Semaan</keyname><forenames>Gustavo Silva</forenames></author><author><keyname>Silva</keyname><forenames>Pedro Luis do Nascimento</forenames></author><author><keyname>Maculan</keyname><forenames>Nelson</forenames></author></authors><title>An Integer Programming Formulation Applied to Optimum Allocation in
  Multivariate Stratified Sampling</title><categories>cs.DM stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of optimal allocation of samples in surveys using a stratified
sampling plan was first discussed by Neyman in 1934. Since then, many
researchers have studied the problem of the sample allocation in multivariate
surveys and several methods have been proposed. Basically, these methods are
divided into two class: The first involves forming a weighted average of the
stratum variances and finding the optimal allocation for the average variance.
The second class is associated with methods that require that an acceptable
coefficient of variation for each of the variables on which the allocation is
to be done. Particularly, this paper proposes a new optimization approach to
the second problem. This approach is based on an integer programming
formulation. Several experiments showed that the proposed approach is efficient
way to solve this problem, considering a comparison of this approach with the
other approach from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6149</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6149</id><created>2013-09-24</created><authors><author><keyname>Ennahbaoui</keyname><forenames>Mohammed</forenames><affiliation>LabMIA</affiliation></author><author><keyname>Elhajji</keyname><forenames>Said</forenames><affiliation>LabMIA</affiliation></author></authors><title>Mutation Analysis for Security</title><categories>cs.CR</categories><proxy>ccsd</proxy><journal-ref>International Journal of Advenced Research in Computer Science and
  Software Engineering 3, 3 (2013) 1-13</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security has become, nowadays, a major concern for the organizations as the
majority of its applications are exposed to Internet, which increases the
threats of security considerably. Thus, the solution is to improve tools and
mechanisms to strengthen the protection of applications against attacks and
ensure the different security objectives. Among solutions we will talking
about, in this paper, there is Mutation Analysis which is a technique of test
that evaluates the quality of software tests and their ability to detect
errors, It also compares the criteria and test generation strategies. In this
study we will use the Mutation Analysis as a mean to qualify the penetration
tests, and then, apply this technique in the security mechanisms and exactly on
the mechanisms of access control. At the end we will propose a method for the
elimination of hidden mechanisms for access control that will allow the access
control policy to evolve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6151</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6151</id><created>2013-09-24</created><authors><author><keyname>Callegari</keyname><forenames>Sergio</forenames></author><author><keyname>Bizzarri</keyname><forenames>Federico</forenames></author></authors><title>Noise Weighting in the Design of {\Delta}{\Sigma} Modulators (with a
  Psychoacoustic Coder as an Example)</title><categories>cs.IT math.IT</categories><comments>5 pages, 18 figures, journal. Code accompanying the paper is
  available at http://pydsm.googlecode.com</comments><doi>10.1109/TCSII.2013.2281892</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A design flow for {\Delta}{\Sigma} modulators is illustrated, allowing
quantization noise to be shaped according to an arbitrary weighting profile.
Being based on FIR NTFs, possibly with high order, the flow is best suited for
digital architectures. The work builds on a recent proposal where the modulator
is matched to the reconstruction filter, showing that this type of optimization
can benefit a wide range of applications where noise (including in-band noise)
is known to have a different impact at different frequencies. The design of a
multiband modulator, a modulator avoiding DC noise, and an audio modulator
capable of distributing quantization artifacts according to a psychoacoustic
model are discussed as examples. A software toolbox is provided as a general
design aid and to replicate the proposed results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6162</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6162</id><created>2013-09-24</created><authors><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames></author><author><keyname>Kabadjov</keyname><forenames>Mijail</forenames></author><author><keyname>van der Goot</keyname><forenames>Erik</forenames></author></authors><title>JRC-Names: A freely available, highly multilingual named entity resource</title><categories>cs.CL</categories><acm-class>H.3.1; H.3.3; I.2.7; I.5</acm-class><journal-ref>Proceedings of the 8th International Conference Recent Advances in
  Natural Language Processing (RANLP'2011), pp. 104-110. Hissar, Bulgaria,
  12-14 September 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new, freely available, highly multilingual named
entity resource for person and organisation names that has been compiled over
seven years of large-scale multilingual news analysis combined with Wikipedia
mining, resulting in 205,000 per-son and organisation names plus about the same
number of spelling variants written in over 20 different scripts and in many
more languages. This resource, produced as part of the Europe Media Monitor
activity (EMM, http://emm.newsbrief.eu/overview.html), can be used for a number
of purposes. These include improving name search in databases or on the
internet, seeding machine learning systems to learn named entity recognition
rules, improve machine translation results, and more. We describe here how this
resource was created; we give statistics on its current size; we address the
issue of morphological inflection; and we give details regarding its
functionality. Updates to this resource will be made available daily.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6176</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6176</id><created>2013-09-23</created><authors><author><keyname>Zheng</keyname><forenames>Xin</forenames></author><author><keyname>Wu</keyname><forenames>Zhiyong</forenames></author><author><keyname>Meng</keyname><forenames>Helen</forenames></author><author><keyname>Li</keyname><forenames>Weifeng</forenames></author><author><keyname>Cai</keyname><forenames>Lianhong</forenames></author></authors><title>Feature Learning with Gaussian Restricted Boltzmann Machine for Robust
  Speech Recognition</title><categories>cs.CL cs.LG cs.SD</categories><comments>4 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we first present a new variant of Gaussian restricted
Boltzmann machine (GRBM) called multivariate Gaussian restricted Boltzmann
machine (MGRBM), with its definition and learning algorithm. Then we propose
using a learned GRBM or MGRBM to extract better features for robust speech
recognition. Our experiments on Aurora2 show that both GRBM-extracted and
MGRBM-extracted feature performs much better than Mel-frequency cepstral
coefficient (MFCC) with either HMM-GMM or hybrid HMM-deep neural network (DNN)
acoustic model, and MGRBM-extracted feature is slightly better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6185</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6185</id><created>2013-09-24</created><authors><author><keyname>Ehrmann</keyname><forenames>Maud</forenames></author><author><keyname>della Rocca</keyname><forenames>Leonida</forenames></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Tanev</keyname><forenames>Hristo</forenames></author></authors><title>Acronym recognition and processing in 22 languages</title><categories>cs.CL</categories><acm-class>H.3.1; H.3.3; I.2.7; I.5.4</acm-class><journal-ref>Proceedings of the 9th Conference 'Recent Advances in Natural
  Language Processing' (RANLP), pp. 237-244. Hissar, Bulgaria, 7-13 September
  2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are presenting work on recognising acronyms of the form Long-Form
(Short-Form) such as &quot;International Monetary Fund (IMF)&quot; in millions of news
articles in twenty-two languages, as part of our more general effort to
recognise entities and their variants in news text and to use them for the
automatic analysis of the news, including the linking of related news across
languages. We show how the acronym recognition patterns, initially developed
for medical terms, needed to be adapted to the more general news domain and we
present evaluation results. We describe our effort to automatically merge the
numerous long-form variants referring to the same short-form, while keeping
non-related long-forms separate. Finally, we provide extensive statistics on
the frequency and the distribution of short-form/long-form pairs across
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6195</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6195</id><created>2013-09-20</created><authors><author><keyname>Liu</keyname><forenames>Benyuan</forenames></author><author><keyname>Fan</keyname><forenames>Hongqi</forenames></author><author><keyname>Lu</keyname><forenames>Zaiqi</forenames></author><author><keyname>Fu</keyname><forenames>Qiang</forenames></author></authors><title>Scan-based Compressed Terahertz Imaging and Real-Time Reconstruction via
  the Complex-valued Fast Block Sparse Bayesian Learning Algorithm</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Sensing based Terahertz imaging (CS-THz) is a computational
imaging technique. It uses only one THz receiver to accumulate the random
modulated image measurements where the original THz image is reconstruct from
these measurements using compressed sensing solvers. The advantage of the
CS-THz is its reduced acquisition time compared with the raster scan mode.
However, when it applied to large-scale two-dimensional (2D) imaging, the
increased dimension resulted in both high computational complexity and
excessive memory usage. In this paper, we introduced a novel CS-based THz
imaging system that progressively compressed the THz image column by column.
Therefore, the CS-THz system could be simplified with a much smaller sized
modulator and reduced dimension. In order to utilize the block structure and
the correlation of adjacent columns of the THz image, a complex-valued block
sparse Bayesian learning algorithm was proposed. We conducted systematic
evaluation of state-of-the-art CS algorithms under the scan based CS-THz
architecture. The compression ratios and the choices of the sensing matrices
were analyzed in detail using both synthetic and real-life THz images.
Simulation results showed that both the scan based architecture and the
proposed recovery algorithm were superior and efficient for large scale CS-THz
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6200</identifier>
 <datestamp>2013-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6200</id><created>2013-09-24</created><updated>2013-11-12</updated><authors><author><keyname>Scarlett</keyname><forenames>Jonathan</forenames></author></authors><title>On the Dispersions of the Gel'fand-Pinsker Channel and Dirty Paper
  Coding</title><categories>cs.IT math.IT</categories><comments>(v2) Added dirty paper coding, changed title (v3) Generalized dirty
  paper coding to non-Gaussian state, submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies second-order coding rates for memoryless channels with a
state sequence known non-causally at the encoder. In the case of finite
alphabets, an achievability result is obtained using constant-composition
random coding, and by using a small fraction of the block to transmit the type
of the state sequence. For error probabilities less than 1/2, it is shown that
the second-order rate improves on an existing one based on i.i.d. random
coding. In the Gaussian case (dirty paper coding) with an almost-sure power
constraint, an achievability result is obtained used using random coding over
the surface of a sphere, and using a small fraction of the block to transmit a
quantized description of the state power. It is shown that the second-order
asymptotics are identical to the single-user Gaussian channel of the same input
power without a state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6202</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6202</id><created>2013-09-24</created><authors><author><keyname>Balahur</keyname><forenames>Alexandra</forenames></author><author><keyname>Steinberger</keyname><forenames>Ralf</forenames></author><author><keyname>Kabadjov</keyname><forenames>Mijail</forenames></author><author><keyname>Zavarella</keyname><forenames>Vanni</forenames></author><author><keyname>van der Goot</keyname><forenames>Erik</forenames></author><author><keyname>Halkia</keyname><forenames>Matina</forenames></author><author><keyname>Pouliquen</keyname><forenames>Bruno</forenames></author><author><keyname>Belyaeva</keyname><forenames>Jenya</forenames></author></authors><title>Sentiment Analysis in the News</title><categories>cs.CL</categories><acm-class>H.3.1; H.3.3; I.2.7; J.4</acm-class><journal-ref>Proceedings of the 7th International Conference on Language
  Resources and Evaluation (LREC'2010), pp. 2216-2220. Valletta, Malta, 19-21
  May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have brought a significant growth in the volume of research in
sentiment analysis, mostly on highly subjective text types (movie or product
reviews). The main difference these texts have with news articles is that their
target is clearly defined and unique across the text. Following different
annotation efforts and the analysis of the issues encountered, we realised that
news opinion mining is different from that of other text types. We identified
three subtasks that need to be addressed: definition of the target; separation
of the good and bad news content from the good and bad sentiment expressed on
the target; and analysis of clearly marked opinion that is expressed
explicitly, not needing interpretation or the use of world knowledge.
Furthermore, we distinguish three different possible views on newspaper
articles - author, reader and text, which have to be addressed differently at
the time of analysing sentiment. Given these definitions, we present work on
mining opinions about entities in English language news, in which (a) we test
the relative suitability of various sentiment dictionaries and (b) we attempt
to separate positive or negative opinion from good or bad news. In the
experiments described here, we tested whether or not subject domain-defining
vocabulary should be ignored. Results showed that this idea is more appropriate
in the context of news opinion mining and that the approaches taking this into
consideration produce a better performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6204</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6204</id><created>2013-09-24</created><updated>2013-12-01</updated><authors><author><keyname>Jin</keyname><forenames>Lei</forenames></author><author><keyname>Long</keyname><forenames>Xuelian</forenames></author><author><keyname>Joshi</keyname><forenames>James</forenames></author></authors><title>A Friendship Privacy Attack on Friends and 2-Distant Neighbors in Social
  Networks</title><categories>cs.SI cs.CR physics.soc-ph</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an undirected social graph, a friendship link involves two users and the
friendship is visible in both the users' friend lists. Such a dual visibility
of the friendship may raise privacy threats. This is because both users can
separately control the visibility of a friendship link to other users and their
privacy policies for the link may not be consistent. Even if one of them
conceals the link from a third user, the third user may find such a friendship
link from another user's friend list. In addition, as most users allow their
friends to see their friend lists in most social network systems, an adversary
can exploit the inconsistent policies to launch privacy attacks to identify and
infer many of a targeted user's friends. In this paper, we propose, analyze and
evaluate such an attack which is called Friendship Identification and Inference
(FII) attack. In a FII attack scenario, we assume that an adversary can only
see his friend list and the friend lists of his friends who do not hide the
friend lists from him. Then, a FII attack contains two attack steps: 1) friend
identification and 2) friend inference. In the friend identification step, the
adversary tries to identify a target's friends based on his friend list and
those of his friends. In the friend inference step, the adversary attempts to
infer the target's friends by using the proposed random walk with restart
approach. We present experimental results using three real social network
datasets and show that FII attacks are generally efficient and effective when
adversaries and targets are friends or 2-distant neighbors. We also
comprehensively analyze the attack results in order to find what values of
parameters and network features could promote FII attacks. Currently, most
popular social network systems with an undirected friendship graph, such as
Facebook, LinkedIn and Foursquare, are susceptible to FII attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6225</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6225</id><created>2013-09-24</created><authors><author><keyname>Colman</keyname><forenames>E. R.</forenames></author><author><keyname>Rodgers</keyname><forenames>G. J.</forenames></author></authors><title>Kinetics of node splitting in evolving complex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><doi>10.1016/j.physa.2012.07.034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a collection of complex networks generated by a combination of
preferential attachment and a previously unexamined process of &quot;splitting&quot;
nodes of degree $k$ into $k$ nodes of degree 1. Four networks are considered,
each evolves at each time step by either preferential attachment, with
probability $p$, or splitting with probability $1-p$. Two methods of attachment
are considered; first, attachment of an edge between a newly created node and
existing node in the network, and secondly by attachment of an edge between two
existing nodes. Splitting is also considered in two separate ways; first by
selecting each node with equal probability and secondly, selecting the node
with probability proportional to its degree. Exact solutions for the degree
distributions are found and scale-free structure is exhibited in those networks
where the candidates for splitting are chosen with uniform probability, those
that are chosen preferentially are distributed with a power law with
exponential cut-off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6226</identifier>
 <datestamp>2014-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6226</id><created>2013-09-24</created><updated>2014-07-28</updated><authors><author><keyname>Moore</keyname><forenames>J Strother</forenames></author><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>Automation of Mathematical Induction as part of the History of Logic</title><categories>cs.AI</categories><comments>ii+107 pages</comments><report-no>SEKI-Report SR-2013-02. ISSN 1437--4447</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the history of the automation of mathematical induction
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6243</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6243</id><created>2013-09-24</created><authors><author><keyname>Chen</keyname><forenames>Guangye</forenames></author><author><keyname>Chacon</keyname><forenames>Luis</forenames></author><author><keyname>Leibs</keyname><forenames>Christopher A</forenames></author><author><keyname>Knoll</keyname><forenames>Dana A</forenames></author><author><keyname>Taitano</keyname><forenames>William</forenames></author></authors><title>Fluid preconditioning for Newton-Krylov-based, fully implicit,
  electrostatic particle-in-cell simulations</title><categories>physics.plasm-ph cs.NA physics.comp-ph</categories><comments>21 pages, 8 figures</comments><doi>10.1016/j.jcp.2013.10.052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent proof-of-principle study proposes an energy- and charge-conserving,
nonlinearly implicit electrostatic particle-in-cell (PIC) algorithm in one
dimension [Chen et al, J. Comput. Phys., 230 (2011) 7018]. The algorithm in the
reference employs an unpreconditioned Jacobian-free Newton-Krylov method, which
ensures nonlinear convergence at every timestep (resolving the dynamical
timescale of interest). Kinetic enslavement, which is one key component of the
algorithm, not only enables fully implicit PIC a practical approach, but also
allows preconditioning the kinetic solver with a fluid approximation. This
study proposes such a preconditioner, in which the linearized moment equations
are closed with moments computed from particles. Effective acceleration of the
linear GMRES solve is demonstrated, on both uniform and non-uniform meshes. The
algorithm performance is largely insensitive to the electron-ion mass ratio.
Numerical experiments are performed on a 1D multi-scale ion acoustic wave test
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6270</identifier>
 <datestamp>2015-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6270</id><created>2013-09-24</created><updated>2014-05-11</updated><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Zargham</keyname><forenames>Michael</forenames></author><author><keyname>Enyioha</keyname><forenames>Chinwendu</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author><author><keyname>Pappas</keyname><forenames>George</forenames></author></authors><title>Optimal Resource Allocation for Network Protection Against Spreading
  Processes</title><categories>math.OC cs.SY physics.soc-ph</categories><journal-ref>IEEE Transaction on Control of Network Systems, vol.1, no.1, pp.
  99-108, March 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of containing spreading processes in arbitrary directed
networks by distributing protection resources throughout the nodes of the
network. We consider two types of protection resources are available: (i)
Preventive resources able to defend nodes against the spreading (such as
vaccines in a viral infection process), and (ii) corrective resources able to
neutralize the spreading after it has reached a node (such as antidotes). We
assume that both preventive and corrective resources have an associated cost
and study the problem of finding the cost-optimal distribution of resources
throughout the nodes of the network. We analyze these questions in the context
of viral spreading processes in directed networks. We study the following two
problems: (i) Given a fixed budget, find the optimal allocation of preventive
and corrective resources in the network to achieve the highest level of
containment, and (ii) when a budget is not specified, find the minimum budget
required to control the spreading process. We show that both resource
allocation problems can be solved in polynomial time using Geometric
Programming (GP) for arbitrary directed graphs of nonidentical nodes and a wide
class of cost functions. Furthermore, our approach allows to optimize
simultaneously over both preventive and corrective resources, even in the case
of cost functions being node-dependent. We illustrate our approach by designing
optimal protection strategies to contain an epidemic outbreak that propagates
through an air transportation network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6280</identifier>
 <datestamp>2015-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6280</id><created>2013-09-24</created><updated>2015-07-13</updated><authors><author><keyname>Franek</keyname><forenames>Peter</forenames></author><author><keyname>Ratschan</keyname><forenames>Stefan</forenames></author><author><keyname>Zgliczynski</keyname><forenames>Piotr</forenames></author></authors><title>Quasi-decidability of a Fragment of the First-order Theory of Real
  Numbers</title><categories>cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a fragment of the first-order theory of the real
numbers that includes systems of equations of continuous functions in bounded
domains, and for which all functions are computable in the sense that it is
possible to compute arbitrarily close piece-wise interval approximations. Even
though this fragment is undecidable, we prove that there is a (possibly
non-terminating) algorithm for checking satisfiability such that (1) whenever
it terminates, it computes a correct answer, and (2) it always terminates when
the input is robust. A formula is robust, if its satisfiability does not change
under small perturbations. As a basic tool for our algorithm we use the notion
of degree from the field of (differential) topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6289</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6289</id><created>2013-09-24</created><authors><author><keyname>Ballier</keyname><forenames>Alexis</forenames></author><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames></author></authors><title>Structuring multi-dimensional subshifts</title><categories>math.DS cs.DM</categories><msc-class>37B50, 37B10, 68R05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two relations on multi-dimensional subshifts: A pre-order based on
the patterns configurations contain and the Cantor-Bendixson rank. We exhibit
several structural properties of two-dimensional subshifts: We characterize the
simplest aperiodic configurations in countable SFTs, we give a combinatorial
characterization of uncountable subshifts, we prove that there always exists
configurations without any periodicity but that have the simplest possible
combinatorics in countable SFTs. Finally, we prove that some Cantor-Bendixson
ranks are impossible for countable SFTs, leaving only a few unknown cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6290</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6290</id><created>2013-09-23</created><updated>2014-02-10</updated><authors><author><keyname>Krishnamoorthy</keyname><forenames>Aravindh</forenames></author></authors><title>Coefficient Matrices Computation of Structural Vector Autoregressive
  Model</title><categories>cs.NA stat.CO</categories><comments>2pp; pre-publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the Large Inverse Cholesky (LIC) method, an
efficient method for computing the coefficient matrices of a Structural Vector
Autoregressive (SVAR) model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6297</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6297</id><created>2013-09-24</created><authors><author><keyname>Erdem</keyname><forenames>Esra</forenames></author><author><keyname>Oztok</keyname><forenames>Umut</forenames></author></authors><title>Generating Explanations for Biomedical Queries</title><categories>cs.AI cs.LO</categories><comments>42 pages, 14 figures, 4 tables, online appendix (proofs, 24 pages)</comments><doi>10.1017/S1471068413000598</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce novel mathematical models and algorithms to generate (shortest
or k different) explanations for biomedical queries, using answer set
programming. We implement these algorithms and integrate them in BIOQUERY-ASP.
We illustrate the usefulness of these methods with some complex biomedical
queries related to drug discovery, over the biomedical knowledge resources
PHARMGKB, DRUGBANK, BIOGRID, CTD, SIDER, DISEASE ONTOLOGY and ORPHADATA. To
appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6301</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6301</id><created>2013-09-24</created><updated>2013-09-27</updated><authors><author><keyname>Zeng</keyname><forenames>Xiangrong</forenames></author><author><keyname>Figueiredo</keyname><forenames>M&#xe1;rio A. T.</forenames></author></authors><title>Solving OSCAR regularization problems by proximal splitting algorithms</title><categories>cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The OSCAR (octagonal selection and clustering algorithm for regression)
regularizer consists of a L_1 norm plus a pair-wise L_inf norm (responsible for
its grouping behavior) and was proposed to encourage group sparsity in
scenarios where the groups are a priori unknown. The OSCAR regularizer has a
non-trivial proximity operator, which limits its applicability. We reformulate
this regularizer as a weighted sorted L_1 norm, and propose its grouping
proximity operator (GPO) and approximate proximity operator (APO), thus making
state-of-the-art proximal splitting algorithms (PSAs) available to solve
inverse problems with OSCAR regularization. The GPO is in fact the APO followed
by additional grouping and averaging operations, which are costly in time and
storage, explaining the reason why algorithms with APO are much faster than
that with GPO. The convergences of PSAs with GPO are guaranteed since GPO is an
exact proximity operator. Although convergence of PSAs with APO is may not be
guaranteed, we have experimentally found that APO behaves similarly to GPO when
the regularization parameter of the pair-wise L_inf norm is set to an
appropriately small value. Experiments on recovery of group-sparse signals
(with unknown groups) show that PSAs with APO are very fast and accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6307</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6307</id><created>2013-09-21</created><authors><author><keyname>Arapostathis</keyname><forenames>Ari</forenames></author></authors><title>On the Non-Uniqueness of Solutions to the Average Cost HJB for
  Controlled Diffusions with Near-Monotone Costs</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theorem for verification of optimality of controlled diffusions
under the average cost criterion with near-monotone running cost, without
invoking any blanket stability assumptions. The implications of this result to
the policy iteration algorithm are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6311</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6311</id><created>2013-09-24</created><authors><author><keyname>Shirin</keyname><forenames>Afroza</forenames></author><author><keyname>Islam</keyname><forenames>Md. Shafiqul</forenames></author></authors><title>Numerical Solutions of Fredholm Integral Equations Using Bernstein
  Polynomials</title><categories>cs.NA math.NA</categories><comments>9 pages. arXiv admin note: substantial text overlap with
  arXiv:1309.6064</comments><doi>10.3329/jsr.v2i2.4483</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Bernstein piecewise polynomials are used to solve the integral
equations numerically. A matrix formulation is given for a non-singular linear
Fredholm Integral Equation by the technique of Galerkin method. In the Galerkin
method, the Bernstein polynomials are used as the approximation of basis
functions. Examples are considered to verify the effectiveness of the proposed
derivations, and the numerical solutions guarantee the desired accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6347</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6347</id><created>2013-09-24</created><authors><author><keyname>Mohammad</keyname><forenames>Saif M.</forenames><affiliation>Wenda</affiliation></author><author><keyname>Tony</keyname><affiliation>Wenda</affiliation></author><author><keyname>Yang</keyname></author></authors><title>Tracking Sentiment in Mail: How Genders Differ on Emotional Axes</title><categories>cs.CL</categories><comments>In Proceedings of the ACL 2011 Workshop on ACL 2011 Workshop on
  Computational Approaches to Subjectivity and Sentiment Analysis (WASSA), June
  2011, Portland, OR. arXiv admin note: text overlap with arXiv:1309.5909</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the widespread use of email, we now have access to unprecedented amounts
of text that we ourselves have written. In this paper, we show how sentiment
analysis can be used in tandem with effective visualizations to quantify and
track emotions in many types of mail. We create a large word--emotion
association lexicon by crowdsourcing, and use it to compare emotions in love
letters, hate mail, and suicide notes. We show that there are marked
differences across genders in how they use emotion words in work-place email.
For example, women use many words from the joy--sadness axis, whereas men
prefer terms from the fear--trust axis. Finally, we show visualizations that
can help people track emotions in their emails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6348</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6348</id><created>2013-09-24</created><authors><author><keyname>Bezzo</keyname><forenames>Nicola</forenames></author><author><keyname>Davalos</keyname><forenames>Patricio J. Cruz</forenames></author><author><keyname>Sorrentino</keyname><forenames>Francesco</forenames></author><author><keyname>Fierro</keyname><forenames>Rafael</forenames></author></authors><title>Decentralized identification and control of networks of coupled mobile
  platforms through adaptive synchronization of chaos</title><categories>nlin.AO cs.RO</categories><comments>17 pages, 10 figures, accepted for publication in Physica D</comments><doi>10.1016/j.physd.2013.08.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an application of adaptive synchronization of chaos
to detect changes in the topology of a mobile robotic network. We assume that
the network may evolve in time due to the relative motion of the mobile robots
and due to unknown environmental conditions, such as the presence of obstacles
in the environment. We consider that each robotic agent is equipped with a
chaotic oscillator whose state is propagated to the other robots through
wireless communication, with the goal of synchronizing the oscillators. We
introduce an adaptive strategy that each agent independently implements to: (i)
estimate the net coupling of all the oscillators in its neighborhood and (ii)
synchronize the state of the oscillators onto the same time evolution. We show
that by using this strategy, synchronization can be attained and changes in the
network topology can be detected. We go one step forward and consider the
possibility of using this information to control the mobile network. We show
the potential applicability of our technique to the problem of maintaining a
formation between a set of mobile platforms, which operate in an inhomogeneous
and uncertain environment. We discuss the importance of using chaotic
oscillators and validate our methodology by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6352</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6352</id><created>2013-09-24</created><authors><author><keyname>Mohammad</keyname><forenames>Saif M.</forenames></author><author><keyname>Kiritchenko</keyname><forenames>Svetlana</forenames></author></authors><title>Using Nuances of Emotion to Identify Personality</title><categories>cs.CL</categories><comments>In Proceedings of the ICWSM Workshop on Computational Personality
  Recognition, July 2013, Boston, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Past work on personality detection has shown that frequency of lexical
categories such as first person pronouns, past tense verbs, and sentiment words
have significant correlations with personality traits. In this paper, for the
first time, we show that fine affect (emotion) categories such as that of
excitement, guilt, yearning, and admiration are significant indicators of
personality. Additionally, we perform experiments to show that the gains
provided by the fine affect categories are not obtained by using coarse affect
categories alone or with specificity features alone. We employ these features
in five SVM classifiers for detecting five personality traits through essays.
We find that the use of fine emotion features leads to statistically
significant improvement over a competitive baseline, whereas the use of coarse
affect and specificity features does not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6369</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6369</id><created>2013-09-24</created><authors><author><keyname>Fang</keyname><forenames>Xiao</forenames></author><author><keyname>Hu</keyname><forenames>Paul J.</forenames></author><author><keyname>Li</keyname><forenames>Zhepeng</forenames></author><author><keyname>Tsai</keyname><forenames>Weiyu</forenames></author></authors><title>Predicting Adoption Probabilities in Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>56 pages</comments><msc-class>Adoption probability, Social network, Bayesian learning, Social
  influence, Structural equivalence, Entity similarity, Confounding factor</msc-class><journal-ref>Information Systems Research 24(1) 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a social network, adoption probability refers to the probability that a
social entity will adopt a product, service, or opinion in the foreseeable
future. Such probabilities are central to fundamental issues in social network
analysis, including the influence maximization problem. In practice, adoption
probabilities have significant implications for applications ranging from
social network-based target marketing to political campaigns; yet, predicting
adoption probabilities has not received sufficient research attention. Building
on relevant social network theories, we identify and operationalize key factors
that affect adoption decisions: social influence, structural equivalence,
entity similarity, and confounding factors. We then develop the
locally-weighted expectation-maximization method for Na\&quot;ive Bayesian learning
to predict adoption probabilities on the basis of these factors. The principal
challenge addressed in this study is how to predict adoption probabilities in
the presence of confounding factors that are generally unobserved. Using data
from two large-scale social networks, we demonstrate the effectiveness of the
proposed method. The empirical results also suggest that cascade methods
primarily using social influence to predict adoption probabilities offer
limited predictive power, and that confounding factors are critical to adoption
probability predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6379</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6379</id><created>2013-09-24</created><authors><author><keyname>Du</keyname><forenames>Jia</forenames></author><author><keyname>Hosseinbor</keyname><forenames>A. Pasha</forenames></author><author><keyname>Chung</keyname><forenames>Moo K.</forenames></author><author><keyname>Bendlin</keyname><forenames>Barbara B.</forenames></author><author><keyname>Suryawanshi</keyname><forenames>Gaurav</forenames></author><author><keyname>Alexander</keyname><forenames>Andrew L.</forenames></author><author><keyname>Qiu</keyname><forenames>Anqi</forenames></author></authors><title>Diffeomorphic Metric Mapping and Probabilistic Atlas Generation of
  Hybrid Diffusion Imaging based on BFOR Signal Basis</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a large deformation diffeomorphic metric mapping algorithm to
align multiple b-value diffusion weighted imaging (mDWI) data, specifically
acquired via hybrid diffusion imaging (HYDI), denoted as LDDMM-HYDI. We then
propose a Bayesian model for estimating the white matter atlas from HYDIs. We
adopt the work given in Hosseinbor et al. (2012) and represent the q-space
diffusion signal with the Bessel Fourier orientation reconstruction (BFOR)
signal basis. The BFOR framework provides the representation of mDWI in the
q-space and thus reduces memory requirement. In addition, since the BFOR signal
basis is orthonormal, the L2 norm that quantifies the differences in the
q-space signals of any two mDWI datasets can be easily computed as the sum of
the squared differences in the BFOR expansion coefficients. In this work, we
show that the reorientation of the $q$-space signal due to spatial
transformation can be easily defined on the BFOR signal basis. We incorporate
the BFOR signal basis into the LDDMM framework and derive the gradient descent
algorithm for LDDMM-HYDI with explicit orientation optimization. Additionally,
we extend the previous Bayesian atlas estimation framework for scalar-valued
images to HYDIs and derive the expectation-maximization algorithm for solving
the HYDI atlas estimation problem. Using real HYDI datasets, we show the
Bayesian model generates the white matter atlas with anatomical details.
Moreover, we show that it is important to consider the variation of mDWI
reorientation due to a small change in diffeomorphic transformation in the
LDDMM-HYDI optimization and to incorporate the full information of HYDI for
aligning mDWI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6390</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6390</id><created>2013-09-24</created><authors><author><keyname>Arandjelovi&#x107;</keyname><forenames>Ognjen</forenames></author></authors><title>Contextually learnt detection of unusual motion-based behaviour in
  crowded public spaces</title><categories>cs.CV</categories><journal-ref>Computer and Information Sciences II Computer and Information
  Sciences II, pp 403-410, 2012</journal-ref><doi>10.1007/978-1-4471-2155-8_51</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are interested in analyzing behaviour in crowded public
places at the level of holistic motion. Our aim is to learn, without user
input, strong scene priors or labelled data, the scope of &quot;normal behaviour&quot;
for a particular scene and thus alert to novelty in unseen footage. The first
contribution is a low-level motion model based on what we term tracklet
primitives, which are scene-specific elementary motions. We propose a
clustering-based algorithm for tracklet estimation from local approximations to
tracks of appearance features. This is followed by two methods for motion
novelty inference from tracklet primitives: (a) we describe an approach based
on a non-hierarchial ensemble of Markov chains as a means of capturing
behavioural characteristics at different scales, and (b) a more flexible
alternative which exhibits a higher generalizing power by accounting for
constraints introduced by intentionality and goal-oriented planning of human
motion in a particular scene. Evaluated on a 2h long video of a busy city
marketplace, both algorithms are shown to be successful at inferring unusual
behaviour, the latter model achieving better performance for novelties at a
larger spatial scale.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6391</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6391</id><created>2013-09-24</created><authors><author><keyname>Martin</keyname><forenames>Rhys</forenames></author><author><keyname>Arandjelovi&#x107;</keyname><forenames>Ognjen</forenames></author></authors><title>Multiple-object tracking in cluttered and crowded public spaces</title><categories>cs.CV</categories><journal-ref>Lecture Notes in Computer Science, volume 6455, pp 89-98, 2010</journal-ref><doi>10.1007/978-3-642-17277-9_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of tracking moving objects of variable
appearance in challenging scenes rich with features and texture. Reliable
tracking is of pivotal importance in surveillance applications. It is made
particularly difficult by the nature of objects encountered in such scenes:
these too change in appearance and scale, and are often articulated (e.g.
humans). We propose a method which uses fast motion detection and segmentation
as a constraint for both building appearance models and their robust
propagation (matching) in time. The appearance model is based on sets of local
appearances automatically clustered using spatio-kinetic similarity, and is
updated with each new appearance seen. This integration of all seen appearances
of a tracked object makes it extremely resilient to errors caused by occlusion
and the lack of permanence of due to low data quality, appearance change or
background clutter. These theoretical strengths of our algorithm are
empirically demonstrated on two hour long video footage of a busy city
marketplace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6395</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6395</id><created>2013-09-24</created><authors><author><keyname>Shafie</keyname><forenames>Ahmed El</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author></authors><title>Optimal Selection of Spectrum Sensing Duration for an Energy Harvesting
  Cognitive Radio</title><categories>cs.NI cs.IT math.IT</categories><comments>Accepted in GLOBECOM 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a time-slotted cognitive radio (CR) setting with
buffered and energy harvesting primary and CR users. At the beginning of each
time slot, the CR user probabilistically chooses the spectrum sensing duration
from a predefined set. If the primary user (PU) is sensed to be inactive, the
CR user accesses the channel immediately. The CR user optimizes the sensing
duration probabilities in order to maximize its mean data service rate with
constraints on the stability of the primary and cognitive queues. The
optimization problem is split into two subproblems. The first is a
linear-fractional program, and the other is a linear program. Both subproblems
can be solved efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6422</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6422</id><created>2013-09-25</created><authors><author><keyname>Xu</keyname><forenames>Hong</forenames></author><author><keyname>Li</keyname><forenames>Baochun</forenames></author></authors><title>Spot Transit: Cheaper Internet Transit for Elastic Traffic</title><categories>cs.NI</categories><comments>14 pages</comments><acm-class>C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We advocate to create a \emph{spot} Internet transit market, where transit is
sold using the under-utilized backbone capacity at a lower price. The providers
can improve profit by capitalizing the perishable capacity, and customers can
buy transit on-demand without a minimum commitment level for elastic traffic,
and as a result improve its surplus (i.e. utility gains). We conduct a
systematic study of the economical benefits of spot transit both theoretically
and empirically. We propose a simple analytical framework with a general demand
function, and solve the pricing problem of maximizing the expected profit,
taking into account the revenue loss of regular transit when spot transit
traffic hikes. We rigorously prove the price advantage of spot transit, as well
as profit and surplus improvements for tier-1 ISPs and customers, respectively.
Using real-world price data and traffic statistics of 6 IXPs with more than
1000 ISPs, we quantitatively evaluate spot transit and show that significant
financial benefits can be achieved in both absolute and relative terms, robust
to parameter values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6433</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6433</id><created>2013-09-25</created><authors><author><keyname>Bazmara</keyname><forenames>Mohammad</forenames></author><author><keyname>Jafari</keyname><forenames>Shahram</forenames></author><author><keyname>Pasand</keyname><forenames>Fatemeh</forenames></author></authors><title>A Fuzzy expert system for goalkeeper quality recognition</title><categories>cs.AI</categories><comments>5 pages</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 5, No 1, September 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goalkeeper (GK) is an expert in soccer and goalkeeping is a complete
professional job. In fact, achieving success seems impossible without a
reliable GK. His effect in successes and failures is more dominant than other
players. The most visible mistakes in a game are those of goalkeeper's. In this
paper the expert fuzzy system is used as a suitable tool to study the quality
of a goalkeeper and compare it with others. Previously done researches are used
to find the goalkeepers' indexes in soccer. Soccer experts have found that a
successful GK should have some qualifications. A new pattern is offered here
which is called &quot;Soccer goalkeeper quality recognition using fuzzy expert
systems&quot;. This pattern has some important capabilities. Firstly, among some
goalkeepers the one with the best quality for the main team arrange can be
chosen. Secondly, the need to expert coaches for choosing a GK using their
senses and experiences decreases a lot. Thirdly, in the survey of a GK,
quantitative criteria can be included, and finally this pattern is simple and
easy to understand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6449</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6449</id><created>2013-09-25</created><authors><author><keyname>Terrazas</keyname><forenames>German</forenames></author><author><keyname>Zenil</keyname><forenames>Hector</forenames></author><author><keyname>Krasnogor</keyname><forenames>Natalio</forenames></author></authors><title>Exploring Programmable Self-Assembly in Non-DNA based Molecular
  Computing</title><categories>cs.CC cs.AI cs.CE physics.comp-ph physics.data-an</categories><doi>10.1007/s11047-013-9397-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-assembly is a phenomenon observed in nature at all scales where
autonomous entities build complex structures, without external influences nor
centralised master plan. Modelling such entities and programming correct
interactions among them is crucial for controlling the manufacture of desired
complex structures at the molecular and supramolecular scale. This work focuses
on a programmability model for non DNA-based molecules and complex behaviour
analysis of their self-assembled conformations. In particular, we look into
modelling, programming and simulation of porphyrin molecules self-assembly and
apply Kolgomorov complexity-based techniques to classify and assess simulation
results in terms of information content. The analysis focuses on phase
transition, clustering, variability and parameter discovery which as a whole
pave the way to the notion of complex systems programmability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6450</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6450</id><created>2013-09-25</created><authors><author><keyname>Shakarian</keyname><forenames>Paulo</forenames></author><author><keyname>Shakarian</keyname><forenames>Jana</forenames></author><author><keyname>Ruef</keyname><forenames>Andrew</forenames></author></authors><title>The Dragon and the Computer: Why Intellectual Property Theft is
  Compatible with Chinese Cyber-Warfare Doctrine</title><categories>cs.CR cs.CY</categories><comments>This is an excerpt from the upcoming book Introduction to
  Cyber-Warfare: A Multidisciplinary Approach published by Syngress (ISBN:
  978-0124078147)</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Along with the USA and Russia, China is often considered one of the leading
cyber-powers in the world. In this excerpt, we explore how Chinese military
thought, developed in the 1990s, influenced their cyber-operations in the early
2000s. In particular, we examine the ideas of &quot;Unrestricted Warfare&quot; and
&quot;Active Offense&quot; and discuss how they can permit for the theft of intellectual
property. We then specifically look at how the case study of Operation Aurora,
a cyber-operation directed against many major U.S. technology and defense
firms, reflects some of these ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6452</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6452</id><created>2013-09-25</created><updated>2014-02-03</updated><authors><author><keyname>Luckeneder</keyname><forenames>Michael</forenames></author><author><keyname>Barker</keyname><forenames>Adam</forenames></author></authors><title>Location, Location, Location: Data-Intensive Distributed Computing in
  the Cloud</title><categories>cs.DC</categories><comments>Preprint of paper to appear in IEEE CloudCom 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When orchestrating highly distributed and data-intensive Web service
workflows the geographical placement of the orchestration engine can greatly
affect the overall performance of a workflow. Orchestration engines are
typically run from within an organisations' network, and may have to transfer
data across long geographical distances, which in turn increases execution time
and degrades the overall performance of a workflow. In this paper we present
CloudForecast: a Web service framework and analysis tool which given a workflow
specification, computes the optimal Amazon EC2 Cloud region to automatically
deploy the orchestration engine and execute the workflow. We use geographical
distance of the workflow, network latency and HTTP round-trip time between
Amazon Cloud regions and the workflow nodes to find a ranking of Cloud regions.
This combined set of simple metrics effectively predicts where the workflow
orchestration engine should be deployed in order to reduce overall execution
time.
  We evaluate our approach by executing randomly generated data-intensive
workflows deployed on the PlanetLab platform in order to rank Amazon EC2 Cloud
regions. Our experimental results show that our proposed optimisation strategy,
depending on the particular workflow, can speed up execution time on average by
82.25% compared to local execution. We also show that the standard deviation of
execution time is reduced by an average of almost 65% using the optimisation
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6453</identifier>
 <datestamp>2014-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6453</id><created>2013-09-25</created><updated>2014-03-05</updated><authors><author><keyname>Gawrychowski</keyname><forenames>Pawel</forenames></author><author><keyname>Uznanski</keyname><forenames>Przemyslaw</forenames></author></authors><title>Order-preserving pattern matching with k mismatches</title><categories>cs.DS</categories><comments>This is the full version of an extended abstract to appear in CPM'14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a generalization of the recently introduced order-preserving pattern
matching, where instead of looking for an exact copy of the pattern, we only
require that the relative order between the elements is the same. In our
variant, we additionally allow up to k mismatches between the pattern and the
text, and the goal is to construct an efficient algorithm for small values of
k. For a pattern of length m and a text of length n, our algorithm detects an
order-preserving occurrence with up to k mismatches in O(n(loglogm + kloglogk))
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6455</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6455</id><created>2013-09-25</created><authors><author><keyname>Spencer</keyname><forenames>Gwen</forenames></author><author><keyname>Howarth</keyname><forenames>Richard</forenames></author></authors><title>Maximizing the Spread of Stable Influence: Leveraging Norm-driven
  Moral-Motivation for Green Behavior Change in Networks</title><categories>cs.SI physics.soc-ph</categories><msc-class>68, 90, 91</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an effort to understand why individuals choose to participate in
personally-expensive pro-environmental behaviors, environmental and behavioral
economists have examined a moral-motivation model in which the decision to
adopt a pro-environmental behavior depends on the society-wide market share of
that behavior. An increasing body of practical research on adoption of
pro-environmental behavior emphasizes the importance of encouragement from
local social contacts and messaging about locally-embraced norms: we respond by
extending the moral-motivation model to a social networks setting. We obtain a
new decision rule: an individual adopts a pro-environmental behavior if he or
she observes a certain threshold of adoption within their local social
neighborhood. This gives rise to a concurrent update process which describes
adoption of a pro-environmental behavior spreading through a network. The
original moral-motivation model corresponds to the special case of our network
version in a complete graph.
  By improving convergence results, we formulate modest-size Integer Programs
that accurately (but not efficiently) find minimum-size sets of nodes that
convert the entire network, or alternately that maximize long-term adoption in
the network given a limited number of nodes which may be temporarily converted.
Issues of stability in determining long-term adoption are key. We give hardness
of approximation results for these optimization problems. We demonstrate that
there exist classes of networks which qualitatively have severely different
behavior than the non-networked version, and provide preliminary computational
results in in modestly-sized highly-clustered small-world networks related to
the famous small-world networks of Watts and Strogatz.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6466</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6466</id><created>2013-09-25</created><authors><author><keyname>Dardaillon</keyname><forenames>Micka&#xeb;l</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Marquet</keyname><forenames>Kevin</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Risset</keyname><forenames>Tanguy</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Scherrer</keyname><forenames>Antoine</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Software Defined Radio Architecture Survey for Cognitive Testbeds</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>Wireless Communications and Mobile Computing Conference (IWCMC),
  2012 8th International (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a survey of existing prototypes dedicated to
software defined radio. We propose a classification related to the
architectural organization of the pro- totypes and provide some conclusions
about the most promising architectures. This study should be useful for
cognitive radio testbed designers who have to choose between many possible
computing platforms. We also introduce a new cognitive radio testbed currently
under construction and explain how this study have influenced the test-bed
designers choices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6468</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6468</id><created>2013-09-25</created><authors><author><keyname>Dardaillon</keyname><forenames>Micka&#xeb;l</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Lauradoux</keyname><forenames>C&#xe9;dric</forenames><affiliation>CITI</affiliation></author><author><keyname>Risset</keyname><forenames>Tanguy</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Hardware Implementation of the GPS authentication</title><categories>cs.CR</categories><comments>ReConFig - International Conference on ReConFigurable Computing and
  FPGAs (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we explore new area/throughput trade- offs for the Girault,
Poupard and Stern authentication protocol (GPS). This authentication protocol
was selected in the NESSIE competition and is even part of the standard ISO/IEC
9798. The originality of our work comes from the fact that we exploit a fixed
key to increase the throughput. It leads us to implement GPS using the Chapman
constant multiplier. This parallel implementation is 40 times faster but 10
times bigger than the reference serial one. We propose to serialize this
multiplier to reduce its area at the cost of lower throughput. Our hybrid
Chapman's multiplier is 8 times faster but only twice bigger than the
reference. Results presented here allow designers to adapt the performance of
GPS authentication to their hardware resources. The complete GPS prover side is
also integrated in the network stack of the PowWow sensor which contains an
Actel IGLOO AGL250 FPGA as a proof of concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6471</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6471</id><created>2013-09-25</created><authors><author><keyname>Boyac&#x131;</keyname><forenames>Arman</forenames></author><author><keyname>Ekim</keyname><forenames>T\inaz</forenames></author><author><keyname>Shalom</keyname><forenames>Mordechai</forenames></author><author><keyname>Zaks</keyname><forenames>Shmuel</forenames></author></authors><title>Graphs of Edge-Intersecting Non-Splitting Paths in a Tree:
  Representations of Holes-Part II</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a tree and a set P of non-trivial simple paths on it, VPT(P) is the VPT
graph (i.e. the vertex intersection graph) of the paths P, and EPT(P) is the
EPT graph (i.e. the edge intersection graph) of P. These graphs have been
extensively studied in the literature. Given two (edge) intersecting paths in a
graph, their split vertices is the set of vertices having degree at least 3 in
their union. A pair of (edge) intersecting paths is termed non-splitting if
they do not have split vertices (namely if their union is a path). We define
the graph ENPT(P) of edge intersecting non-splitting paths of a tree, termed
the ENPT graph, as the graph having a vertex for each path in P, and an edge
between every pair of vertices representing two paths that are both
edge-intersecting and non-splitting. A graph G is an ENPT graph if there is a
tree T and a set of paths P of T such that G=ENPT(P), and we say that &lt;T,P&gt; is
a representation of G.
  Our goal is to characterize the representation of chordless ENPT cycles
(holes). To achieve this goal, we first assume that the EPT graph induced by
the vertices of an ENPT hole is given. In [2] we introduce three assumptions
(P1), (P2), (P3) defined on EPT, ENPT pairs of graphs. In the same study, we
define two problems HamiltonianPairRec, P3-HamiltonianPairRec and characterize
the representations of ENPT holes that satisfy (P1), (P2), (P3).
  In this work, we continue our work by relaxing these three assumptions one by
one. We characterize the representations of ENPT holes satisfying (P3) by
providing a polynomial-time algorithm to solve P3-HamiltonianPairRec. We also
show that there does not exist a polynomial-time algorithm to solve
HamiltonianPairRec, unless P=NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6474</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6474</id><created>2013-09-25</created><updated>2013-09-26</updated><authors><author><keyname>Diaz</keyname><forenames>Josep</forenames></author><author><keyname>Giotis</keyname><forenames>Ioannis</forenames></author><author><keyname>Kirousis</keyname><forenames>Lefteris</forenames></author><author><keyname>Markakis</keyname><forenames>Evangelos</forenames></author><author><keyname>Serna</keyname><forenames>Maria</forenames></author></authors><title>On the Stability of Generalized Second Price Auctions with Budgets</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Generalized Second Price (GSP) auction used typically to model sponsored
search auctions does not include the notion of budget constraints, which is
present in practice. Motivated by this, we introduce the different variants of
GSP auctions that take budgets into account in natural ways. We examine their
stability by focusing on the existence of Nash equilibria and envy-free
assignments. We highlight the differences between these mechanisms and find
that only some of them exhibit both notions of stability. This shows the
importance of carefully picking the right mechanism to ensure stable outcomes
in the presence of budgets
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6477</identifier>
 <datestamp>2014-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6477</id><created>2013-09-25</created><updated>2014-02-27</updated><authors><author><keyname>Christ</keyname><forenames>Marie G.</forenames></author><author><keyname>Favrholdt</keyname><forenames>Lene M.</forenames></author><author><keyname>Larsen</keyname><forenames>Kim S.</forenames></author></authors><title>Online Bin Covering: Expectations vs. Guarantees</title><categories>cs.DS</categories><comments>IMADA-preprint-cs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bin covering is a dual version of classic bin packing. Thus, the goal is to
cover as many bins as possible, where covering a bin means packing items of
total size at least one in the bin.
  For online bin covering, competitive analysis fails to distinguish between
most algorithms of interest; all &quot;reasonable&quot; algorithms have a competitive
ratio of 1/2. Thus, in order to get a better understanding of the combinatorial
difficulties in solving this problem, we turn to other performance measures,
namely relative worst order, random order, and max/max analysis, as well as
analyzing input with restricted or uniformly distributed item sizes. In this
way, our study also supplements the ongoing systematic studies of the relative
strengths of various performance measures.
  Two classic algorithms for online bin packing that have natural dual versions
are Harmonic and Next-Fit. Even though the algorithms are quite different in
nature, the dual versions are not separated by competitive analysis. We make
the case that when guarantees are needed, even under restricted input
sequences, dual Harmonic is preferable. In addition, we establish quite robust
theoretical results showing that if items come from a uniform distribution or
even if just the ordering of items is uniformly random, then dual Next-Fit is
the right choice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6484</identifier>
 <datestamp>2014-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6484</id><created>2013-09-25</created><updated>2014-04-22</updated><authors><author><keyname>Gregoire</keyname><forenames>Jean</forenames></author><author><keyname>Qian</keyname><forenames>Xiangjun</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author><author><keyname>de La Fortelle</keyname><forenames>Arnaud</forenames></author><author><keyname>Wongpiromsarn</keyname><forenames>Tichakorn</forenames></author></authors><title>Capacity-aware back-pressure traffic signal control</title><categories>cs.SY</categories><comments>9 pages, submitted to IEEE TCNS</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The control of a network of signalized intersections is considered. Previous
work demonstrates that the so-called back-pressure control provides stability
guarantees, assuming infinite queues capacities. In this paper, we highlight
the failing of current back-pressure control under finite capacities by
identifying sources of non work-conservation and congestion propagation. We
propose the use of a normalized pressure which guarantees work conservation and
mitigates congestion propagation, while ensuring fairness at low traffic
densities, and recovering original back-pressure as capacities grow to
infinity. This capacity-aware back-pressure control allows to improve
performance as congestion increases, as indicated by simulation results, and
keeps the key benefits of back-pressure: ability to be distributed over
intersections and O(1) complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6487</identifier>
 <datestamp>2015-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6487</id><created>2013-09-25</created><updated>2015-10-30</updated><authors><author><keyname>Peng</keyname><forenames>Xi</forenames></author><author><keyname>Tang</keyname><forenames>Huajin</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author><author><keyname>Yi</keyname><forenames>Zhang</forenames></author><author><keyname>Xiao</keyname><forenames>Shijie</forenames></author></authors><title>A Unified Framework for Representation-based Subspace Clustering of
  Out-of-sample and Large-scale Data</title><categories>cs.LG cs.CV stat.ML</categories><comments>in IEEE Trans. on Neural Networks and Learning Systems, 2015</comments><doi>10.1109/TNNLS.2015.2490080</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under the framework of spectral clustering, the key of subspace clustering is
building a similarity graph which describes the neighborhood relations among
data points. Some recent works build the graph using sparse, low-rank, and
$\ell_2$-norm-based representation, and have achieved state-of-the-art
performance. However, these methods have suffered from the following two
limitations. First, the time complexities of these methods are at least
proportional to the cube of the data size, which make those methods inefficient
for solving large-scale problems. Second, they cannot cope with out-of-sample
data that are not used to construct the similarity graph. To cluster each
out-of-sample datum, the methods have to recalculate the similarity graph and
the cluster membership of the whole data set. In this paper, we propose a
unified framework which makes representation-based subspace clustering
algorithms feasible to cluster both out-of-sample and large-scale data. Under
our framework, the large-scale problem is tackled by converting it as
out-of-sample problem in the manner of &quot;sampling, clustering, coding, and
classifying&quot;. Furthermore, we give an estimation for the error bounds by
treating each subspace as a point in a hyperspace. Extensive experimental
results on various benchmark data sets show that our methods outperform several
recently-proposed scalable methods in clustering large-scale data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6504</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6504</id><created>2013-09-25</created><authors><author><keyname>Lampis</keyname><forenames>Michael</forenames></author><author><keyname>Mitsou</keyname><forenames>Valia</forenames></author></authors><title>The Computational Complexity of the Game of Set and its Theoretical
  Applications</title><categories>cs.CC cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The game of SET is a popular card game in which the objective is to form Sets
using cards from a special deck. In this paper we study single- and multi-round
variations of this game from the computational complexity point of view and
establish interesting connections with other classical computational problems.
Specifically, we first show that a natural generalization of the problem of
finding a single Set, parameterized by the size of the sought Set is W-hard;
our reduction applies also to a natural parameterization of Perfect
Multi-Dimensional Matching, a result which may be of independent interest.
Second, we observe that a version of the game where one seeks to find the
largest possible number of disjoint Sets from a given set of cards is a special
case of 3-Set Packing; we establish that this restriction remains NP-complete.
Similarly, the version where one seeks to find the smallest number of disjoint
Sets that overlap all possible Sets is shown to be NP-complete, through a close
connection to the Independent Edge Dominating Set problem. Finally, we study a
2-player version of the game, for which we show a close connection to Arc
Kayles, as well as fixed-parameter tractability when parameterized by the
number of rounds played.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6527</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6527</id><created>2013-09-25</created><authors><author><keyname>Kalmukov</keyname><forenames>Yordan</forenames></author></authors><title>Describing Papers and Reviewers' Competences by Taxonomy of Keywords</title><categories>cs.IR cs.DL</categories><journal-ref>Computer Science and Information Systems, Vol. 9(2), pp. 763-789,
  2012, ISSN 1820-0214</journal-ref><doi>10.2298/CSIS110906012K</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article focuses on the importance of the precise calculation of
similarity factors between papers and reviewers for performing a fair and
accurate automatic assignment of reviewers to papers. It suggests that papers
and reviewers' competences should be described by taxonomy of keywords so that
the implied hierarchical structure allows similarity measures to take into
account not only the number of exactly matching keywords, but in case of
non-matching ones to calculate how semantically close they are. The paper also
suggests a similarity measure derived from the well-known and widely-used
Dice's coefficient, but adapted in a way it could be also applied between sets
whose elements are semantically related to each other (as concepts in taxonomy
are). It allows a non-zero similarity factor to be accurately calculated
between a paper and a reviewer even if they do not share any keyword in common.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6545</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6545</id><created>2013-09-25</created><authors><author><keyname>Milling</keyname><forenames>Chris</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author><author><keyname>Shakkottai</keyname><forenames>Sanjay</forenames></author></authors><title>Distinguishing Infections on Different Graph Topologies</title><categories>cs.SI q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The history of infections and epidemics holds famous examples where
understanding, containing and ultimately treating an outbreak began with
understanding its mode of spread. Influenza, HIV and most computer viruses,
spread person to person, device to device, through contact networks; Cholera,
Cancer, and seasonal allergies, on the other hand, do not. In this paper we
study two fundamental questions of detection: first, given a snapshot view of a
(perhaps vanishingly small) fraction of those infected, under what conditions
is an epidemic spreading via contact (e.g., Influenza), distinguishable from a
&quot;random illness&quot; operating independently of any contact network (e.g., seasonal
allergies); second, if we do have an epidemic, under what conditions is it
possible to determine which network of interactions is the main cause of the
spread -- the causative network -- without any knowledge of the epidemic, other
than the identity of a minuscule subsample of infected nodes?
  The core, therefore, of this paper, is to obtain an understanding of the
diagnostic power of network information. We derive sufficient conditions
networks must satisfy for these problems to be identifiable, and produce
efficient, highly scalable algorithms that solve these problems. We show that
the identifiability condition we give is fairly mild, and in particular, is
satisfied by two common graph topologies: the grid, and the Erdos-Renyi graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6550</identifier>
 <datestamp>2014-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6550</id><created>2013-09-25</created><updated>2014-12-19</updated><authors><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author></authors><title>Loop Calculus for Non-Binary Alphabets using Concepts from Information
  Geometry</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>18 pages, 4 figures, submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Bethe approximation is a well-known approximation of the partition
function used in statistical physics. Recently, an equality relating the
partition function and its Bethe approximation was obtained for graphical
models with binary variables by Chertkov and Chernyak. In this equality, the
multiplicative error in the Bethe approximation is represented as a weighted
sum over all generalized loops in the graphical model. In this paper, the
equality is generalized to graphical models with non-binary alphabet using
concepts from information geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6576</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6576</id><created>2013-09-25</created><authors><author><keyname>Mivule</keyname><forenames>Kato</forenames></author></authors><title>SIED, a Data Privacy Engineering Framework</title><categories>cs.CR</categories><comments>2 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While a number of data privacy techniques have been proposed in the recent
years, a few frameworks have been suggested for the implementation of the data
privacy process. Most of the proposed approaches are tailored towards
implementing a specific data privacy algorithm but not the overall data privacy
engineering and design process. Therefore, as a contribution, this study
proposes SIED (Specification, Implementation, Evaluation, and Dissemination), a
conceptual framework that takes a holistic approach to the data privacy
engineering procedure by looking at the specifications, implementation,
evaluation, and finally, dissemination of the privatized data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6584</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6584</id><created>2013-09-25</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>Should I Stay or Should I Go: Coordinating Biological Needs with
  Continuously-updated Assessments of the Environment</title><categories>cs.NE cs.LG q-bio.NC</categories><journal-ref>Gabora, L. (1992). In (S. Wilson, J. A. Mayer &amp; H. Roitblat, Eds.)
  Proceedings of the Second International Conference on the Simulation of
  Adaptive Behavior (pp. 156-162), Cambridge MA: MIT Press</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents Wanderer, a model of how autonomous adaptive systems
coordinate internal biological needs with moment-by-moment assessments of the
probabilities of events in the external world. The extent to which Wanderer
moves about or explores its environment reflects the relative activations of
two competing motivational sub-systems: one represents the need to acquire
energy and it excites exploration, and the other represents the need to avoid
predators and it inhibits exploration. The environment contains food,
predators, and neutral stimuli. Wanderer responds to these events in a way that
is adaptive in the short turn, and reassesses the probabilities of these events
so that it can modify its long term behaviour appropriately. When food appears,
Wanderer be-comes satiated and exploration temporarily decreases. When a
predator appears, Wanderer both decreases exploration in the short term, and
becomes more &quot;cautious&quot; about exploring in the future. Wanderer also forms
associations between neutral features and salient ones (food and predators)
when they are present at the same time, and uses these associations to guide
its behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6603</identifier>
 <datestamp>2015-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6603</id><created>2013-09-25</created><updated>2015-02-24</updated><authors><author><keyname>Bramas</keyname><forenames>Quentin</forenames><affiliation>LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, LINCS, IUF</affiliation></author></authors><title>The Random Bit Complexity of Mobile Robots Scattering</title><categories>cs.DS cs.CC cs.DC cs.MA cs.RO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of scattering $n$ robots in a two dimensional
continuous space. As this problem is impossible to solve in a deterministic
manner, all solutions must be probabilistic. We investigate the amount of
randomness (that is, the number of random bits used by the robots) that is
required to achieve scattering. We first prove that $n \log n$ random bits are
necessary to scatter $n$ robots in any setting. Also, we give a sufficient
condition for a scattering algorithm to be random bit optimal. As it turns out
that previous solutions for scattering satisfy our condition, they are hence
proved random bit optimal for the scattering problem. Then, we investigate the
time complexity of scattering when strong multiplicity detection is not
available. We prove that such algorithms cannot converge in constant time in
the general case and in $o(\log \log n)$ rounds for random bits optimal
scattering algorithms. However, we present a family of scattering algorithms
that converge as fast as needed without using multiplicity detection. Also, we
put forward a specific protocol of this family that is random bit optimal ($n
\log n$ random bits are used) and time optimal ($\log \log n$ rounds are used).
This improves the time complexity of previous results in the same setting by a
$\log n$ factor. Aside from characterizing the random bit complexity of mobile
robot scattering, our study also closes its time complexity gap with and
without strong multiplicity detection (that is, $O(1)$ time complexity is only
achievable when strong multiplicity detection is available, and it is possible
to approach it as needed otherwise).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6608</identifier>
 <datestamp>2013-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6608</id><created>2013-09-25</created><authors><author><keyname>Sehra</keyname><forenames>Sukhjit Singh</forenames></author><author><keyname>Singh</keyname><forenames>Jaiteg</forenames></author><author><keyname>Rai</keyname><forenames>Hardeep Singh</forenames></author></authors><title>Assessment of OpenStreetMap Data - A Review</title><categories>cs.CY cs.DB cs.SI</categories><comments>Review paper</comments><journal-ref>International Journal of Computer Applications, 76(16):17-20,
  August 2013</journal-ref><doi>10.5120/13331-0888 10.5120/13331-0888</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The meaning and purposes of web has been changing and evolving day by day.
Web 2. 0 encouraged more contribution by the end users. This movement provided
revolutionary methods of sharing and computing data by crowdsourcing such as
OpenStreetmap, also called &quot;the wikification of maps&quot; by some researchers. When
crowdsourcing collects huge data with help of general public with varying level
of mapping experience, the focus of researcher should be on analysing the data
rather than collecting it. Researchers have assessed the quality of
OpenStreetMap data by comparing it with proprietary data or data of
governmental map agencies. This study reviews the research work for assessment
of Open- StreetMap Data and also discusses about the future directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6610</identifier>
 <datestamp>2014-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6610</id><created>2013-09-25</created><updated>2014-09-16</updated><authors><author><keyname>Anantharamu</keyname><forenames>Lakshmi</forenames></author><author><keyname>Chlebus</keyname><forenames>Bogdan S.</forenames></author><author><keyname>Rokicki</keyname><forenames>Mariusz A.</forenames></author></authors><title>Adversarial Multiple Access Channels with Individual Injection Rates</title><categories>cs.DC cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study deterministic distributed broadcasting in synchronous
multiple-access channels. Packets are injected into $n$ nodes by a window-type
adversary that is constrained by a window $w$ and injection rates individually
assigned to all nodes. We investigate what queue size and packet latency can be
achieved with the maximum aggregate injection rate of one packet per round,
depending on properties of channels and algorithms. We give a non-adaptive
algorithm for channels with collision detection and an adaptive algorithm for
channels without collision detection that achieve $O(\min(n+w,w\log n))$ packet
latency. We show that packet latency has to be either $\Omega(w \max (1,\log_w
n))$, when $w\le n$, or $\Omega(w+n)$, when $w&gt;n$, as a matching lower bound to
these algorithms. We develop a non-adaptive algorithm for channels without
collision detection that achieves $O(n+w)$ queue size and $O(nw)$ packet
latency. This is in contrast with the adversarial model of global injection
rates, in which non-adaptive algorithms with bounded packet latency do not
exist [18]. Our algorithm avoids collisions produced by simultaneous
transmissions; we show that any algorithm with this property must have
$\Omega(nw)$ packet latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6613</identifier>
 <datestamp>2014-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6613</id><created>2013-09-25</created><updated>2014-02-18</updated><authors><author><keyname>Droge</keyname><forenames>Greg</forenames></author><author><keyname>Kawashima</keyname><forenames>Hiroaki</forenames></author><author><keyname>Egerstedt</keyname><forenames>Magnus</forenames></author></authors><title>Continuous-time Proportional-Integral Distributed Optimization for
  Networked Systems</title><categories>cs.SY math.OC</categories><comments>23 Pages, submission to Journal of Control and Decision, under
  review. Takes comments from previous review process into account. Reasons for
  a continuous approach are given and minor technical details are remedied.
  Largest revision is reformatting for the Journal of Control and Decision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore the relationship between dual decomposition and the
consensus-based method for distributed optimization. The relationship is
developed by examining the similarities between the two approaches and their
relationship to gradient-based constrained optimization. By formulating each
algorithm in continuous-time, it is seen that both approaches use a gradient
method for optimization with one using a proportional control term and the
other using an integral control term to drive the system to the constraint set.
Therefore, a significant contribution of this paper is to combine these methods
to develop a continuous-time proportional-integral distributed optimization
method. Furthermore, we establish convergence using Lyapunov stability
techniques and utilizing properties from the network structure of the
multi-agent system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6627</identifier>
 <datestamp>2014-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6627</id><created>2013-09-25</created><updated>2014-06-15</updated><authors><author><keyname>Yong</keyname><forenames>Sze Zheng</forenames></author><author><keyname>Zhu</keyname><forenames>Minghui</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>A Unified Filter for Simultaneous Input and State Estimation of Linear
  Discrete-time Stochastic Systems</title><categories>math.OC cs.SY math.DS</categories><comments>Preprint for Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a unified optimal and exponentially stable filter
for linear discrete-time stochastic systems that simultaneously estimates the
states and unknown inputs in an unbiased minimum-variance sense, without making
any assumptions on the direct feedthrough matrix. We also derive input and
state observability/detectability conditions, and analyze their connection to
the convergence and stability of the estimator. We discuss two variations of
the filter and their optimality and stability properties, and show that filters
in the literature, including the Kalman filter, are special cases of the filter
derived in this paper. Finally, illustrative examples are given to demonstrate
the performance of the unified unbiased minimum-variance filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6628</identifier>
 <datestamp>2014-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6628</id><created>2013-09-25</created><authors><author><keyname>Blumberg</keyname><forenames>Andrew J.</forenames></author><author><keyname>Mandell</keyname><forenames>Michael A.</forenames></author></authors><title>Quantitative Homotopy Theory in Topological Data Analysis</title><categories>cs.CG</categories><msc-class>55U10, 68U05</msc-class><journal-ref>Found. Comput. Math. 13 (2013), no. 6, 885-911</journal-ref><doi>10.1007/s10208-013-9177-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper lays the foundations of an approach to applying Gromov's ideas on
quantitative topology to topological data analysis. We introduce the
&quot;contiguity complex&quot;, a simplicial complex of maps between simplicial complexes
defined in terms of the combinatorial notion of contiguity. We generalize the
Simplicial Approximation Theorem to show that the contiguity complex
approximates the homotopy type of the mapping space as we subdivide the domain.
We describe algorithms for approximating the rate of growth of the components
of the contiguity complex under subdivision of the domain; this procedure
allows us to computationally distinguish spaces with isomorphic homology but
different homotopy types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6629</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6629</id><created>2013-09-25</created><authors><author><keyname>Wen</keyname><forenames>Chuan</forenames></author><author><keyname>Loe</keyname></author><author><keyname>Jensen</keyname><forenames>Henrik Jeldtoft</forenames></author></authors><title>Stability of the Centrality of Unions of Networks on the Same Vertex Set</title><categories>nlin.AO cs.SI math.CO</categories><comments>12 pages with 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G^1(V,E_1)$ and $G^2(V,E_2)$ be two networks on the same vertex set $V$
and consider the union of edges $G(V, E_1 \cup E_2)$. This paper studies the
stability of the Degree, Betweenness and Eigenvector Centrality of the
resultant network, $G(V, E_1 \cup E_2)$. Specifically assume $v^1_{max}$ and
$v^c_{max}$ are the highest centrality vertices of $G^1(V,E_1)$ and $G(V, E_1
\cup E_2)$ respectively, we want to find $Pr(v^1_{max} = v^c_{max})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6650</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6650</id><created>2013-09-25</created><authors><author><keyname>Al-Feel</keyname><forenames>Haytham</forenames></author><author><keyname>Schafermeier</keyname><forenames>Ralph</forenames></author><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>An Inter-lingual Reference Approach For Multi-Lingual Ontology Matching</title><categories>cs.CL cs.DL</categories><comments>http://www.ijcsi.org/papers/IJCSI-10-2-1-497-503.pdf</comments><acm-class>I.2.4; I.2.7; I.2</acm-class><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 10,
  Issue 2, No 1, March 2013 ISSN (Print): 1694-0814 | ISSN (Online): 1694-0784</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontologies are considered as the backbone of the Semantic Web. With the
rising success of the Semantic Web, the number of participating communities
from different countries is constantly increasing. The growing number of
ontologies available in different natural languages leads to an
interoperability problem. In this paper, we discuss several approaches for
ontology matching; examine similarities and differences, identify weaknesses,
and compare the existing automated approaches with the manual approaches for
integrating multilingual ontologies. In addition to that, we propose a new
architecture for a multilingual ontology matching service. As a case study we
used an example of two multilingual enterprise ontologies - the university
ontology of Freie Universitaet Berlin and the ontology for Fayoum University in
Egypt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6651</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6651</id><created>2013-09-19</created><authors><author><keyname>Gao</keyname><forenames>Pu</forenames></author><author><keyname>Molloy</keyname><forenames>Michael</forenames></author></authors><title>Inside the clustering threshold for random linear equations</title><categories>cs.DM math.CO math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a random system of $cn$ linear equations over $n$ variables in
GF(2), where each equation contains exactly $r$ variables; this is equivalent
to $r$-XORSAT. \cite{ikkm,amxor} determined the clustering threshold, $c^*_r$:
if $c=c^*_r+\e$ for any constant $\e&gt;0$, then \aas the solutions partition into
well-connected, well-separated {\em clusters} (with probability tending to 1 as
$n\rightarrow\infty$). This is part of a general clustering phenomenon which is
hypothesized to arise in most of the commonly studied models of random
constraint satisfaction problems, via sophisticated but mostly non-rigorous
techniques from statistical physics. We extend that study to the range
$c=c^*_r+o(1)$, showing that if $c=c^*_r+n^{-\d}, \d&gt;0$, then the connectivity
parameter of each $r$-XORSAT cluster is $n^{\Theta(\d)}$, as compared to
$O(\log n)$ when $c=c^*_r+\e$. This means that one can move between any two
solutions in the same cluster via a sequence of solutions where consecutive
solutions differ on at most $n^{\Theta(\d)}$ variables; this is tight up to the
implicit constant. In contrast, moving to a solution in another cluster
requires that some pair of consecutive solutions differ in at least
$n^{1-O(\d)}$ variables.
  Along the way, we prove that in a random $r$-uniform hypergraph with
edge-density $n^{-\d}$ above the $k$-core threshold, \aas every vertex not in
the $k$-core can be removed by a sequence of $n^{\Theta(\d)}$ vertex-deletions
in which the deleted vertex has degree less than $k$; again, this is tight up
to the implicit constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6655</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6655</id><created>2013-09-23</created><authors><author><keyname>Mao</keyname><forenames>Weiguang</forenames></author></authors><title>Introduction to the Symbolic Integration System</title><categories>cs.SC</categories><comments>273 pages in Chinese</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Symbolic integration is an important module of a typical Computer Algebra
System. As for now, Mathematica, Matlab, Maple and Sage are all mainstream CAS.
They share the same framework for symbolic integration at some points. In this
book first we review the state of the art in the field of CAS. Then we focus on
typical frameworks of the current symbolic integration systems and summarize
the main mathematical theories behind these frameworks. Based on the
open-source computer algebra system maTHmU developed by our team in our
university, we propose a potential framework to improve the performance of the
current symbolic integration system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6659</identifier>
 <datestamp>2014-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6659</id><created>2013-09-25</created><updated>2014-01-03</updated><authors><author><keyname>Correa</keyname><forenames>Jos&#xe9; R.</forenames></author><author><keyname>Feuilloley</keyname><forenames>Laurent</forenames></author><author><keyname>P&#xe9;rez-Lantero</keyname><forenames>Pablo</forenames></author><author><keyname>Soto</keyname><forenames>Jos&#xe9; A.</forenames></author></authors><title>Independent and Hitting Sets of Rectangles Intersecting a Diagonal Line
  : Algorithms and Complexity</title><categories>cs.CG</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding a maximum independent set (MIS) of a given fam- ily of axis-parallel
rectangles is a basic problem in computational geom- etry and combinatorics.
This problem has attracted signi?cant atten- tion since the sixties, when
Wegner conjectured that the corresponding duality gap, i.e., the maximum
possible ratio between the maximum independent set and the minimum hitting set
(MHS), is bounded by a universal constant. An interesting special case, that
may prove use- ful to tackling the general problem, is the
diagonal-intersecting case, in which the given family of rectangles is
intersected by a diagonal. Indeed, Chepoi and Felsner recently gave a factor 6
approximation algorithm for MHS in this setting, and showed that the duality
gap is between 3/2 and 6. In this paper we improve upon these results. First we
show that MIS in diagonal-intersecting families is NP-complete, providing one
smallest subclass for which MIS is provably hard. Then, we derive an
$O(n^2)$-time algorithm for the maximum weight independent set when, in
addition the rectangles intersect below the diagonal. This improves and extends
a classic result of Lubiw, and amounts to obtain a 2-approximation algo- rithm
for the maximum weight independent set of rectangles intersecting a diagonal.
Finally, we prove that for diagonal-intersecting families the duality gap is
between 2 and 4. The upper bound, which implies an approximation algorithm of
the same factor, follows from a simple com- binatorial argument, while the
lower bound represents the best known lower bound on the duality gap, even in
the general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6683</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6683</id><created>2013-09-25</created><updated>2013-09-26</updated><authors><author><keyname>Baingana</keyname><forenames>Brian</forenames></author><author><keyname>Mateos</keyname><forenames>Gonzalo</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Dynamic Structural Equation Models for Social Network Topology Inference</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world processes evolve in cascades over complex networks, whose
topologies are often unobservable and change over time. However, the so-termed
adoption times when blogs mention popular news items, individuals in a
community catch an infectious disease, or consumers adopt a trendy electronics
product are typically known, and are implicitly dependent on the underlying
network. To infer the network topology, a \textit{dynamic} structural equation
model is adopted to capture the relationship between observed adoption times
and the unknown edge weights. Assuming a slowly time-varying topology and
leveraging the sparse connectivity inherent to social networks, edge weights
are estimated by minimizing a sparsity-regularized exponentially-weighted
least-squares criterion. To this end, solvers with complementary strengths are
developed by leveraging (pseudo) real-time sparsity-promoting proximal gradient
iterations, the improved convergence rate of accelerated variants, or reduced
computational complexity of stochastic gradient descent. Numerical tests with
both synthetic and real data demonstrate the effectiveness of the novel
algorithms in unveiling sparse dynamically-evolving topologies, while
accounting for external influences in the adoption times. Key events in the
recent succession of political leadership in North Korea, explain connectivity
changes observed in the associated network inferred from global cascades of
online media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6687</identifier>
 <datestamp>2013-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6687</id><created>2013-09-25</created><updated>2013-11-04</updated><authors><author><keyname>Hamdi</keyname><forenames>Maziyar</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Vikram</forenames></author></authors><title>Removal of Data Incest in Multi-agent Social Learning in Social Networks</title><categories>cs.SI physics.soc-ph</categories><comments>32 pages, 12 figures, submitted to IEEE Journal of Selected Topics in
  Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by online reputation systems, we investigate social learning in a
network where agents interact on a time dependent graph to estimate an
underlying state of nature. Agents record their own private observations, then
update their private beliefs about the state of nature using Bayes' rule. Based
on their belief, each agent then chooses an action (rating) from a finite set
and transmits this action over the social network. An important consequence of
such social learning over a network is the ruinous multiple re-use of
information known as data incest (or mis-information propagation). In this
paper, the data incest management problem in social learning context is
formulated on a directed acyclic graph. We give necessary and sufficient
conditions on the graph topology of social interactions to eliminate data
incest. A data incest removal algorithm is proposed such that the public belief
of social learning (and hence the actions of agents) is not affected by data
incest propagation. This results in an online reputation system with a higher
trust rating. Numerical examples are provided to illustrate the performance of
the proposed optimal data incest removal algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6689</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6689</id><created>2013-09-25</created><authors><author><keyname>Duan</keyname><forenames>Qi</forenames></author><author><keyname>Xu</keyname><forenames>Jinhui</forenames></author></authors><title>On the Connectivity Preserving Minimum Cut Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study a generalization of the classical minimum cut prob-
lem, called Connectivity Preserving Minimum Cut (CPMC) problem, which seeks a
minimum cut to separate a pair (or pairs) of source and destination nodes and
meanwhile ensure the connectivity between the source and its partner node(s).
The CPMC problem is a rather powerful formulation for a set of problems and
finds applications in many other areas, such as network security, image
processing, data mining, pattern recognition, and machine learning. For this
important problem, we consider two variants, connectiv- ity preserving minimum
node cut (CPMNC) and connectivity preserving minimum edge cut (CPMEC). For
CPMNC, we show that it cannot be ap- proximated within {\alpha}logn for some
constant {\alpha} unless P=NP, and cannot be approximated within any poly(logn)
unless NP has quasi-polynomial time algorithms. The hardness results hold even
for graphs with unit weight and bipartite graphs. Particularly, we show that
polynomial time solutions exist for CPMEC in planar graphs and for CPMNC in
some special planar graphs. The hardness of CPMEC in general graphs remains
open, but the polynomial time algorithm in planar graphs still has important
practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6690</identifier>
 <datestamp>2014-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6690</id><created>2013-09-25</created><updated>2014-03-19</updated><authors><author><keyname>Nasir</keyname><forenames>Ali Arshad</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author><author><keyname>Blostein</keyname><forenames>Steven D.</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author></authors><title>Training-Based Synchronization and Channel Estimation in AF Two-Way
  Relaying Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE SPAWC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-way relaying networks (TWRNs) allow for more bandwidth efficient use of
the available spectrum since they allow for simultaneous information exchange
between two users with the assistance of an intermediate relay node. However,
due to superposition of signals at the relay node, the received signal at the
user terminals is affected by \emph{multiple impairments}, i.e., channel gains,
timing offsets, and carrier frequency offsets, that need to be jointly
estimated and compensated. This paper presents a training-based system model
for amplify-and-forward (AF) TWRNs in the presence of multiple impairments and
proposes maximum likelihood and differential evolution based algorithms for
joint estimation of these impairments. The Cramer-Rao lower bounds (CRLBs) for
the joint estimation of multiple impairments are derived. A minimum mean-square
error based receiver is then proposed to compensate the effect of multiple
impairments and decode each user's signal. Simulation results show that the
performance of the proposed estimators is very close to the derived CRLBs at
moderate-to-high signal-to-noise-ratios. It is also shown that the bit-error
rate performance of the overall AF TWRN is close to a TWRN that is based on
assumption of perfect knowledge of the synchronization parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6691</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6691</id><created>2013-09-25</created><authors><author><keyname>Li</keyname><forenames>Yao</forenames></author><author><keyname>Jia</keyname><forenames>Wenjing</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author></authors><title>Characterness: An Indicator of Text in the Wild</title><categories>cs.CV</categories><comments>11 pages; Appearing in IEEE Trans. on Image Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text in an image provides vital information for interpreting its contents,
and text in a scene can aide with a variety of tasks from navigation, to
obstacle avoidance, and odometry. Despite its value, however, identifying
general text in images remains a challenging research problem. Motivated by the
need to consider the widely varying forms of natural text, we propose a
bottom-up approach to the problem which reflects the `characterness' of an
image region. In this sense our approach mirrors the move from saliency
detection methods to measures of `objectness'. In order to measure the
characterness we develop three novel cues that are tailored for character
detection, and a Bayesian method for their integration. Because text is made up
of sets of characters, we then design a Markov random field (MRF) model so as
to exploit the inherent dependencies between characters.
  We experimentally demonstrate the effectiveness of our characterness cues as
well as the advantage of Bayesian multi-cue integration. The proposed text
detector outperforms state-of-the-art methods on a few benchmark scene text
detection datasets. We also show that our measurement of `characterness' is
superior than state-of-the-art saliency detection models when applied to the
same task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6693</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6693</id><created>2013-09-25</created><authors><author><keyname>Yucelen</keyname><forenames>Tansel</forenames></author><author><keyname>De La Torre</keyname><forenames>Gerardo</forenames></author><author><keyname>Johnson</keyname><forenames>Eric N.</forenames></author></authors><title>Improving Transient Performance of Adaptive Control Architectures using
  Frequency-Limited System Error Dynamics</title><categories>math.DS cs.SY</categories><comments>27 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an adaptive control architecture to achieve stabilization and
command following of uncertain dynamical systems with improved transient
performance. Our framework consists of a new reference system and an adaptive
controller. The proposed reference system captures a desired closed-loop
dynamical system behavior modified by a mismatch term representing the
high-frequency content between the uncertain dynamical system and this
reference system, i.e., the system error. In particular, this mismatch term
allows to limit the frequency content of the system error dynamics, which is
used to drive the adaptive controller. It is shown that this key feature of our
framework yields fast adaptation with- out incurring high-frequency
oscillations in the transient performance. We further show the effects of
design parameters on the system performance, analyze closeness of the uncertain
dynamical system to the unmodified (ideal) reference system, discuss robustness
of the proposed approach with respect to time-varying uncertainties and
disturbances, and make connections to gradient minimization and classical
control theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6701</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6701</id><created>2013-09-25</created><authors><author><keyname>Kurihara</keyname><forenames>Masazumi</forenames></author><author><keyname>Kuwakado</keyname><forenames>Hidenori</forenames></author></authors><title>Generalization of Rashmi-Shah-Kumar Minimum-Storage-Regenerating Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a generalized version of the Rashmi-Shah-Kumar
Minimum-Storage-Regenerating(RSK-MSR) codes based on the product-matrix
framework. For any $(n,k,d)$ such that $d \geq 2k-2$ and $d \leq n-1$, we can
directly construct an $(n,k,d)$ MSR code without constructing a larger MSR code
and shortening of the larger MSR code. As a result, the size of a finite field
over which the proposed code is defined is smaller than or equal to the size of
a finite field over which the RSK-MSR code is defined. In addition, the
$\{\ell,\ell'\}$ secure codes based on the generalized RSK-MSR codes can be
obtained by applying the construction method of $\{\ell,\ell'\}$ secure codes
proposed by Shah, Rashmi and Kumar. Furthermore, the message matrix of the
$(n,k,d)$ generalized RSK-MSR code is derived from that of the RSK-MSR code by
using the construction method of the $\{\ell=k,\ell'=0\}$ secure code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6707</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6707</id><created>2013-09-25</created><updated>2014-01-21</updated><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Zhang</keyname><forenames>Simpson</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Distributed Online Learning in Social Recommender Systems</title><categories>cs.SI cs.LG stat.ML</categories><journal-ref>Selected Topics in Signal Processing, IEEE Journal of , vol.8,
  no.4, pp.638,652, Aug. 2014</journal-ref><doi>10.1109/JSTSP.2014.2299517</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider decentralized sequential decision making in
distributed online recommender systems, where items are recommended to users
based on their search query as well as their specific background including
history of bought items, gender and age, all of which comprise the context
information of the user. In contrast to centralized recommender systems, in
which there is a single centralized seller who has access to the complete
inventory of items as well as the complete record of sales and user
information, in decentralized recommender systems each seller/learner only has
access to the inventory of items and user information for its own products and
not the products and user information of other sellers, but can get commission
if it sells an item of another seller. Therefore the sellers must distributedly
find out for an incoming user which items to recommend (from the set of own
items or items of another seller), in order to maximize the revenue from own
sales and commissions. We formulate this problem as a cooperative contextual
bandit problem, analytically bound the performance of the sellers compared to
the best recommendation strategy given the complete realization of user
arrivals and the inventory of items, as well as the context-dependent purchase
probabilities of each item, and verify our results via numerical examples on a
distributed data set adapted based on Amazon data. We evaluate the dependence
of the performance of a seller on the inventory of items the seller has, the
number of connections it has with the other sellers, and the commissions which
the seller gets by selling items of other sellers to its users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6715</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6715</id><created>2013-09-25</created><updated>2014-06-13</updated><authors><author><keyname>Zhang</keyname><forenames>Qiang</forenames></author><author><keyname>Qi</keyname><forenames>Tianxiao</forenames></author><author><keyname>Li</keyname><forenames>Keqiang</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author><author><keyname>Wu</keyname><forenames>Jinshan</forenames></author></authors><title>Games on graphs: A minor modification of payoff scheme makes a big
  difference</title><categories>physics.soc-ph cs.GT</categories><comments>23 pages,171 figures</comments><doi>10.1209/0295-5075/107/10002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various social dilemma games that follow different strategy updating rules
have been studied on many networks.The reported results span the entire
spectrum, from significantly boosting,to marginally affecting,to seriously
decreasing the level of cooperation.Experimental results that are qualitatively
different from theoretical prediction have also been reported.It is widely
believed that the results are largely determined by three elements,including
payoff matrices of the underlying 2*2 games,the way that the strategic states
of the players are updated and the structure of the networks.Here we discuss
the impact of a seemly non-essential mechanism -- what we refer to as a &quot;payoff
scheme&quot;. Specifically, in each round after the states of all of the players are
determined,the payoff scheme is how each player's payoff is calculated.In
addition to the two conventions in which either the accumulated or the averaged
payoff is calculated from playing with all of the neighboring players,we here
study the effects of calculating the payoff from pairing up with one random
player from among the neighboring players. Based on probability theory, in a
situation of uncorrelated events, the average payoff that involves all of the
neighbors should,in principal,be equivalent to the payoff from pairing up with
one neighbor.However,our simulation of games on graphs shows that, in many
cases,the two payoff schemes lead to qualitatively different levels of
cooperation.This finding appears to provide a possible explanation for a wide
spectrum of observed behaviors in the literature.We have also observed that
results from the randomly-pairing-one mechanism are more robust than the
involving-all-neighbours mechanism because,in the former case, neither the
other three main elements nor the initial states of the players have a large
impact on the final level of cooperation compared with in the latter case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6722</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6722</id><created>2013-09-26</created><authors><author><keyname>Duyu</keyname><forenames>Tang</forenames></author><author><keyname>Bing</keyname><forenames>Qin</forenames></author><author><keyname>LanJun</keyname><forenames>Zhou</forenames></author><author><keyname>KamFai</keyname><forenames>Wong</forenames></author><author><keyname>Yanyan</keyname><forenames>Zhao</forenames></author><author><keyname>Ting</keyname><forenames>Liu</forenames></author></authors><title>Domain-Specific Sentiment Word Extraction by Seed Expansion and Pattern
  Generation</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the automatic extraction of domain-specific sentiment
word (DSSW), which is a fundamental subtask of sentiment analysis. Most
previous work utilizes manual patterns for this task. However, the performance
of those methods highly relies on the labelled patterns or selected seeds. In
order to overcome the above problem, this paper presents an automatic framework
to detect large-scale domain-specific patterns for DSSW extraction. To this
end, sentiment seeds are extracted from massive dataset of user comments.
Subsequently, these sentiment seeds are expanded by synonyms using a
bootstrapping mechanism. Simultaneously, a synonymy graph is built and the
graph propagation algorithm is applied on the built synonymy graph. Afterwards,
syntactic and sequential relations between target words and high-ranked
sentiment words are extracted automatically to construct large-scale patterns,
which are further used to extracte DSSWs. The experimental results in three
domains reveal the effectiveness of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6723</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6723</id><created>2013-09-26</created><authors><author><keyname>Dayyani</keyname><forenames>Sheida</forenames></author><author><keyname>Khayyambashi</keyname><forenames>Mohammad Reza</forenames></author></authors><title>A Comparative Study of Replication Techniques in Grid Computing Systems</title><categories>cs.DC</categories><comments>10 pages, 3 figures, 4 table</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 11, No. 9, September 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grid Computing is a type of parallel and distributed systems that is designed
to provide reliable access to data and computational resources in wide area
networks. These resources are distributed in different geographical locations,
however are organized to provide an integrated service. Effective data
management in today`s enterprise environment is an important issue. Also,
Performance is one of the challenges of using these environments. For improving
the performance of file access and easing the sharing amongst distributed
systems, replication techniques are used. Data replication is a common method
used in distributed environments, where essential data is stored in multiple
locations, so that a user can access the data from a site in his area. In this
paper, we present a survey on basic and new replication techniques that have
been proposed by other researchers. After that, we have a full comparative
study on these replication strategies. Also, at the end of the paper, we
summarize the results and points of these replication techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6727</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6727</id><created>2013-09-26</created><authors><author><keyname>Liu</keyname><forenames>Tingting</forenames></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames></author></authors><title>Genie Chain and Degrees of Freedom of Symmetric MIMO Interference
  Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the information theoretic degrees of freedom (DoF)
for symmetric multi-input-multi-output interference broadcast channel
(MIMO-IBC) with arbitrary configuration. We find the maximal DoF achieved by
linear interference alignment (IA), and prove when linear IA can achieve the
information theoretic maximal DoF. Specifically, we find that the information
theoretic DoF can be divided into two regions according to the ratio of the
number of antennas at each base station (BS) to that at each user. In Region I,
the sum DoF of the system linearly increases with the number of cells, which
can be achieved by asymptotic IA but not by linear IA, where infinite
time/frequency extension is necessary. In Region II, the DoF is a piecewise
linear function, depending on the number of antennas at each BS or that at each
user alternately, which can be achieved by linear IA without the need of
infinite time/frequency extension, and the sum DoF cannot exceed the sum number
of antennas at each BS and each user. We propose and prove the information
theoretic DoF upper-bound for general MIMO-IBC including the system settings in
Regions I and II, by constructing a useful and smart genie chain. We prove the
achievability of the upper-bound in Region II by proposing a unified way to
design closed-form linear IA. From the proof we reveal when proper systems are
feasible or infeasible and explain why. The approach of the proof can be
extended to more general asymmetric MIMO-IBC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6730</identifier>
 <datestamp>2015-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6730</id><created>2013-09-26</created><updated>2015-06-22</updated><authors><author><keyname>Boyer</keyname><forenames>Laurent</forenames><affiliation>SAMM</affiliation></author><author><keyname>Delacourt</keyname><forenames>Martin</forenames><affiliation>CMM</affiliation></author><author><keyname>Poupet</keyname><forenames>Victor</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Sablik</keyname><forenames>Mathieu</forenames><affiliation>LATP</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>$\mu$-Limit Sets of Cellular Automata from a Computational Complexity
  Perspective</title><categories>cs.DM cs.FL nlin.CG</categories><comments>41 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns $\mu$-limit sets of cellular automata: sets of
configurations made of words whose probability to appear does not vanish with
time, starting from an initial $\mu$-random configuration. More precisely, we
investigate the computational complexity of these sets and of related decision
problems. Main results: first, $\mu$-limit sets can have a $\Sigma\_3^0$-hard
language, second, they can contain only $\alpha$-complex configurations, third,
any non-trivial property concerning them is at least $\Pi\_3^0$-hard. We prove
complexity upper bounds, study restrictions of these questions to particular
classes of CA, and different types of (non-)convergence of the measure of a
word during the evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6732</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6732</id><created>2013-09-26</created><authors><author><keyname>Samarasinghe</keyname><forenames>Tharaka</forenames></author><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Outage Capacity of Opportunistic Beamforming with Random User Locations</title><categories>cs.IT math.IT</categories><comments>To appear in Globecom 2013, Atlanta, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the outage capacity of a network consisting of a multitude
of heterogenous mobile users, and operating according to the classical
opportunistic beamforming framework. The base station is located at the center
of the cell, which is modeled as a disk of finite radius. The random user
locations are modeled using a homogenous spatial Poisson point process. The
received signals are impaired by both fading and location dependent path loss.
For this system, we first derive an expression for the beam outage probability.
This expression holds for all path loss models that satisfy some mild
conditions. Then, we focus on two specific path loss models (i.e., an unbounded
model and a more realistic bounded one) to illustrate the applications of our
results. In the large system limit where the cell radius tends to infinity, the
beam outage capacity and its scaling behavior are derived for the selected
specific path loss models. It is shown that the beam outage capacity scales
logarithmically for the unbounded model. On the other hand, this scaling
behavior becomes double logarithmic for the bounded model. Intuitive
explanations are provided as to why we observe different scaling behavior for
different path loss models. Numerical evaluations are performed to give further
insights, and to illustrate the applicability of the outage capacity results
even to a cell having a small finite radius.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6740</identifier>
 <datestamp>2014-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6740</id><created>2013-09-26</created><updated>2014-12-22</updated><authors><author><keyname>Corominas-Murtra</keyname><forenames>Bernat</forenames></author><author><keyname>Fuchs</keyname><forenames>Benedikt</forenames></author><author><keyname>Thurner</keyname><forenames>Stefan</forenames></author></authors><title>Detection of the elite structure in a virtual multiplex social system by
  means of a generalized $K$-core</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>13 figures, 3 tables, 19 pages. Accepted for publication in PLoS ONE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Elites are subgroups of individuals within a society that have the ability
and means to influence, lead, govern, and shape societies. Members of elites
are often well connected individuals, which enables them to impose their
influence to many and to quickly gather, process, and spread information. Here
we argue that elites are not only composed of highly connected individuals, but
also of intermediaries connecting hubs to form a cohesive and structured
elite-subgroup at the core of a social network. For this purpose we present a
generalization of the $K$-core algorithm that allows to identify a social core
that is composed of well-connected hubs together with their `connectors'. We
show the validity of the idea in the framework of a virtual world defined by a
massive multiplayer online game, on which we have complete information of
various social networks. Exploiting this multiplex structure, we find that the
hubs of the generalized $K$-core identify those individuals that are high
social performers in terms of a series of indicators that are available in the
game. In addition, using a combined strategy which involves the generalized
$K$-core and the recently introduced $M$-core, the elites of the different
'nations' present in the game are perfectly identified as modules of the
generalized $K$-core. Interesting sudden shifts in the composition of the elite
cores are observed at deep levels. We show that elite detection with the
traditional $K$-core is not possible in a reliable way. The proposed method
might be useful in a series of more general applications, such as community
detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6772</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6772</id><created>2013-09-26</created><authors><author><keyname>Fountoulakis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Khosla</keyname><forenames>Megha</forenames></author><author><keyname>Panagiotou</keyname><forenames>Konstantinos</forenames></author></authors><title>The Multiple-orientability Thresholds for Random Hypergraphs</title><categories>cs.DM math.CO</categories><comments>An extended abstract appeared in the proceedings of SODA 2011</comments><msc-class>68Q25, 05C80, 68Q87, 68W20, 05C65</msc-class><acm-class>G.2.1; G.2.2; F.1.2; F.2.2</acm-class><doi>10.1017/S0963548315000334</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $k$-uniform hypergraph $H = (V, E)$ is called $\ell$-orientable, if there
is an assignment of each edge $e\in E$ to one of its vertices $v\in e$ such
that no vertex is assigned more than $\ell$ edges. Let $H_{n,m,k}$ be a
hypergraph, drawn uniformly at random from the set of all $k$-uniform
hypergraphs with $n$ vertices and $m$ edges. In this paper we establish the
threshold for the $\ell$-orientability of $H_{n,m,k}$ for all $k\ge 3$ and
$\ell \ge 2$, i.e., we determine a critical quantity $c_{k, \ell}^*$ such that
with probability $1-o(1)$ the graph $H_{n,cn,k}$ has an $\ell$-orientation if
$c &lt; c_{k, \ell}^*$, but fails doing so if $c &gt; c_{k, \ell}^*$.
  Our result has various applications including sharp load thresholds for
cuckoo hashing, load balancing with guaranteed maximum load, and massive
parallel access to hard disk arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6786</identifier>
 <datestamp>2014-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6786</id><created>2013-09-26</created><updated>2014-09-24</updated><authors><author><keyname>Paquet</keyname><forenames>Ulrich</forenames></author><author><keyname>Koenigstein</keyname><forenames>Noam</forenames></author></authors><title>One-class Collaborative Filtering with Random Graphs: Annotated Version</title><categories>stat.ML cs.LG</categories><comments>11 pages, 7 figures. Detailed, annotated and expanded version of
  conference paper &quot;One-class Collaborative Filtering with Random Graphs&quot; (WWW
  2013)</comments><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bane of one-class collaborative filtering is interpreting and modelling
the latent signal from the missing class. In this paper we present a novel
Bayesian generative model for implicit collaborative filtering. It forms a core
component of the Xbox Live architecture, and unlike previous approaches,
delineates the odds of a user disliking an item from simply not considering it.
The latent signal is treated as an unobserved random graph connecting users
with items they might have encountered. We demonstrate how large-scale
distributed learning can be achieved through a combination of stochastic
gradient descent and mean field variational inference over random graph
samples. A fine-grained comparison is done against a state of the art baseline
on real world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6788</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6788</id><created>2013-09-26</created><authors><author><keyname>Wildemeersch</keyname><forenames>Matthias</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Rabbachin</keyname><forenames>Alberto</forenames></author><author><keyname>Slump</keyname><forenames>Cornelis H.</forenames></author></authors><title>Successive Interference Cancellation in Heterogeneous Cellular Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>submitted for journal publication, 13 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present, operators address the explosive growth of mobile data demand by
densification of the cellular network so as to reduce the transmitter-receiver
distance and to achieve higher spectral efficiency. Due to such network
densification and the intense proliferation of wireless devices, modern
wireless networks are interference-limited, which motivates the use of
interference mitigation and coordination techniques. In this work, we develop a
statistical framework to evaluate the performance of multi-tier heterogeneous
networks with successive interference cancellation (SIC) capabilities,
accounting for the computational complexity of the cancellation scheme and
relevant network related parameters such as random location of the access
points (APs) and mobile users, and the characteristics of the wireless
propagation channel. We explicitly model the consecutive events of canceling
interferers and we derive the success probability to cancel the n-th strongest
signal and to decode the signal of interest after n cancellations. When users
are connected to the AP which provides the maximum average received signal
power, the analysis indicates that the performance gains of SIC diminish
quickly with n and the benefits are modest for realistic values of the
signal-to-interference ratio (SIR). We extend the statistical model to include
several association policies where distinct gains of SIC are expected: (i)
minimum load association, (ii) maxi- mum instantaneous SIR association, and
(iii) range expansion. Numerical results show the effectiveness of SIC for the
considered association policies. This work deepens the understanding of SIC by
defining the achievable gains for different association policies in multi-tier
heterogeneous networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6797</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6797</id><created>2013-09-26</created><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Golovach</keyname><forenames>Petr A.</forenames></author><author><keyname>Nederlof</keyname><forenames>Jesper</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Minimizing Rosenthal Potential in Multicast Games</title><categories>cs.GT cs.DS</categories><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multicast game is a network design game modelling how selfish
non-cooperative agents build and maintain one-to-many network communication.
There is a special source node and a collection of agents located at
corresponding terminals. Each agent is interested in selecting a route from the
special source to its terminal minimizing the cost. The mutual influence of the
agents is determined by a cost sharing mechanism, which evenly splits the cost
of an edge among all the agents using it for routing. In this paper we provide
several algorithmic and complexity results on finding a Nash equilibrium
minimizing the value of Rosenthal potential. Let n be the number of agents and
G be the communication network. We show that
  - For a given strategy profile s and integer k&gt;=1, there is a local search
algorithm which in time n^{O(k)}|G|^{O(1)} finds a better strategy profile, if
there is any, in a k-exchange neighbourhood of s. In other words, the algorithm
decides if Rosenthal potential can be decreased by changing strategies of at
most k agents;
  - The running time of our local search algorithm is essentially tight: unless
FPT= W[1], for any function f(k), searching of the k-neighbourhood cannot be
done in time f(k)|G|^{O(1)}.
  The key ingredient of our algorithmic result is a subroutine that finds an
equilibrium with minimum potential in 3^n|G|^{O(1)} time. In other words,
finding an equilibrium with minimum potential is fixed-parameter tractable when
parameterized by the number of agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6806</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6806</id><created>2013-09-26</created><updated>2014-02-18</updated><authors><author><keyname>M&#xfc;ller</keyname><forenames>Ralf</forenames></author><author><keyname>Cottatellucci</keyname><forenames>Laura</forenames></author><author><keyname>Vehkaper&#xe4;</keyname><forenames>Mikko</forenames></author></authors><title>Blind pilot decontamination</title><categories>cs.IT math.IT</categories><comments>The condition that the coherence time C must be greater that the
  number of receive antennas R was removed. Some Figures were updated. Now
  showing both cases with R&lt;C and R&gt;C</comments><journal-ref>IEEE J. Sel. Topics Signal Process., vol.8, no.5, pp. 773-786,
  2014</journal-ref><doi>10.1109/JSTSP.2014.2310053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subspace projection to improve channel estimation in massive multi-antenna
systems is proposed and analyzed. Together with power-controlled hand-off, it
can mitigate the pilot contamination problem without the need for coordination
among cells. The proposed method is blind in the sense that it does not require
pilot data to find the appropriate subspace. It is based on the theory of large
random matrices that predicts that the eigenvalue spectra of large sample
covariance matrices can asymptotically decompose into disjoint bulks as the
matrix size grows large. Random matrix and free probability theory are utilized
to predict under which system parameters such a bulk decomposition takes place.
Simulation results are provided to confirm that the proposed method outperforms
conventional linear channel estimation if bulk separation occurs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6811</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6811</id><created>2013-09-26</created><authors><author><keyname>Adel</keyname><forenames>Tameem</forenames></author><author><keyname>Smith</keyname><forenames>Benn</forenames></author><author><keyname>Urner</keyname><forenames>Ruth</forenames></author><author><keyname>Stashuk</keyname><forenames>Daniel</forenames></author><author><keyname>Lizotte</keyname><forenames>Daniel J.</forenames></author></authors><title>Generative Multiple-Instance Learning Models For Quantitative
  Electromyography</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-2-11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a comprehensive study of the use of generative modeling approaches
for Multiple-Instance Learning (MIL) problems. In MIL a learner receives
training instances grouped together into bags with labels for the bags only
(which might not be correct for the comprised instances). Our work was
motivated by the task of facilitating the diagnosis of neuromuscular disorders
using sets of motor unit potential trains (MUPTs) detected within a muscle
which can be cast as a MIL problem. Our approach leads to a state-of-the-art
solution to the problem of muscle classification. By introducing and analyzing
generative models for MIL in a general framework and examining a variety of
model structures and components, our work also serves as a methodological guide
to modelling MIL tasks. We evaluate our proposed methods both on MUPT datasets
and on the MUSK1 dataset, one of the most widely used benchmarks for MIL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6812</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6812</id><created>2013-09-26</created><authors><author><keyname>Amizadeh</keyname><forenames>Saeed</forenames></author><author><keyname>Thiesson</keyname><forenames>Bo</forenames></author><author><keyname>Hauskrecht</keyname><forenames>Milos</forenames></author></authors><title>The Bregman Variational Dual-Tree Framework</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-22-31</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph-based methods provide a powerful tool set for many non-parametric
frameworks in Machine Learning. In general, the memory and computational
complexity of these methods is quadratic in the number of examples in the data
which makes them quickly infeasible for moderate to large scale datasets. A
significant effort to find more efficient solutions to the problem has been
made in the literature. One of the state-of-the-art methods that has been
recently introduced is the Variational Dual-Tree (VDT) framework. Despite some
of its unique features, VDT is currently restricted only to Euclidean spaces
where the Euclidean distance quantifies the similarity. In this paper, we
extend the VDT framework beyond the Euclidean distance to more general Bregman
divergences that include the Euclidean distance as a special case. By
exploiting the properties of the general Bregman divergence, we show how the
new framework can maintain all the pivotal features of the VDT framework and
yet significantly improve its performance in non-Euclidean domains. We apply
the proposed framework to different text categorization problems and
demonstrate its benefits over the original VDT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6813</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6813</id><created>2013-09-26</created><authors><author><keyname>Bach</keyname><forenames>Stephen</forenames></author><author><keyname>Huang</keyname><forenames>Bert</forenames></author><author><keyname>London</keyname><forenames>Ben</forenames></author><author><keyname>Getoor</keyname><forenames>Lise</forenames></author></authors><title>Hinge-loss Markov Random Fields: Convex Inference for Structured
  Prediction</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-32-41</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical models for structured domains are powerful tools, but the
computational complexities of combinatorial prediction spaces can force
restrictions on models, or require approximate inference in order to be
tractable. Instead of working in a combinatorial space, we use hinge-loss
Markov random fields (HL-MRFs), an expressive class of graphical models with
log-concave density functions over continuous variables, which can represent
confidences in discrete predictions. This paper demonstrates that HL-MRFs are
general tools for fast and accurate structured prediction. We introduce the
first inference algorithm that is both scalable and applicable to the full
class of HL-MRFs, and show how to train HL-MRFs with several learning
algorithms. Our experiments show that HL-MRFs match or surpass the predictive
performance of state-of-the-art methods, including discrete models, in four
application domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6814</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6814</id><created>2013-09-26</created><authors><author><keyname>Balasubramanian</keyname><forenames>Krishnakumar</forenames></author><author><keyname>Yu</keyname><forenames>Kai</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>High-dimensional Joint Sparsity Random Effects Model for Multi-task
  Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-42-51</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint sparsity regularization in multi-task learning has attracted much
attention in recent years. The traditional convex formulation employs the group
Lasso relaxation to achieve joint sparsity across tasks. Although this approach
leads to a simple convex formulation, it suffers from several issues due to the
looseness of the relaxation. To remedy this problem, we view jointly sparse
multi-task learning as a specialized random effects model, and derive a convex
relaxation approach that involves two steps. The first step learns the
covariance matrix of the coefficients using a convex formulation which we refer
to as sparse covariance coding; the second step solves a ridge regression
problem with a sparse quadratic regularizer based on the covariance matrix
obtained in the first step. It is shown that this approach produces an
asymptotically optimal quadratic regularizer in the multitask learning setting
when the number of tasks approaches infinity. Experimental results demonstrate
that the convex formulation obtained via the proposed model significantly
outperforms group Lasso (and related multi-stage formulations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6815</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6815</id><created>2013-09-26</created><authors><author><keyname>Beame</keyname><forenames>Paul</forenames></author><author><keyname>Li</keyname><forenames>Jerry</forenames></author><author><keyname>Roy</keyname><forenames>Sudeepa</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Lower Bounds for Exact Model Counting and Applications in Probabilistic
  Databases</title><categories>cs.DB cs.AI cs.CC</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-52-61</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The best current methods for exactly computing the number of satisfying
assignments, or the satisfying probability, of Boolean formulas can be seen,
either directly or indirectly, as building 'decision-DNNF' (decision
decomposable negation normal form) representations of the input Boolean
formulas. Decision-DNNFs are a special case of 'd-DNNF's where 'd' stands for
'deterministic'. We show that any decision-DNNF can be converted into an
equivalent 'FBDD' (free binary decision diagram) -- also known as a 'read-once
branching program' (ROBP or 1-BP) -- with only a quasipolynomial increase in
representation size in general, and with only a polynomial increase in size in
the special case of monotone k-DNF formulas. Leveraging known exponential lower
bounds for FBDDs, we then obtain similar exponential lower bounds for
decision-DNNFs which provide lower bounds for the recent algorithms. We also
separate the power of decision-DNNFs from d-DNNFs and a generalization of
decision-DNNFs known as AND-FBDDs. Finally we show how these imply exponential
lower bounds for natural problems associated with probabilistic databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6816</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6816</id><created>2013-09-26</created><authors><author><keyname>Belle</keyname><forenames>Vaishak</forenames></author><author><keyname>Levesque</keyname><forenames>Hector</forenames></author></authors><title>Reasoning about Probabilities in Dynamic Systems using Goal Regression</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-62-71</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reasoning about degrees of belief in uncertain dynamic worlds is fundamental
to many applications, such as robotics and planning, where actions modify state
properties and sensors provide measurements, both of which are prone to noise.
With the exception of limited cases such as Gaussian processes over linear
phenomena, belief state evolution can be complex and hard to reason with in a
general way. This paper proposes a framework with new results that allows the
reduction of subjective probabilities after sensing and acting to questions
about the initial state only. We build on an expressive probabilistic
first-order logical account by Bacchus, Halpern and Levesque, resulting in a
methodology that, in principle, can be coupled with a variety of existing
inference solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6817</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6817</id><created>2013-09-26</created><authors><author><keyname>Bigot</keyname><forenames>Damien</forenames></author><author><keyname>Zanuttini</keyname><forenames>Bruno</forenames></author><author><keyname>Fargier</keyname><forenames>Helene</forenames></author><author><keyname>Mengin</keyname><forenames>Jerome</forenames></author></authors><title>Probabilistic Conditional Preference Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-72-81</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to represent the preferences of a group of individuals, we introduce
Probabilistic CP-nets (PCP-nets). PCP-nets provide a compact language for
representing probability distributions over preference orderings. We argue that
they are useful for aggregating preferences or modelling noisy preferences.
Then we give efficient algorithms for the main reasoning problems, namely for
computing the probability that a given outcome is preferred to another one, and
the probability that a given outcome is optimal. As a by-product, we obtain an
unexpected linear-time algorithm for checking dominance in a standard,
tree-structured CP-net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6818</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6818</id><created>2013-09-26</created><authors><author><keyname>Bootkrajang</keyname><forenames>Jakramate</forenames></author><author><keyname>Kaban</keyname><forenames>Ata</forenames></author></authors><title>Boosting in the presence of label noise</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-82-91</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting is known to be sensitive to label noise. We studied two approaches
to improve AdaBoost's robustness against labelling errors. One is to employ a
label-noise robust classifier as a base learner, while the other is to modify
the AdaBoost algorithm to be more robust. Empirical evaluation shows that a
committee of robust classifiers, although converges faster than non label-noise
aware AdaBoost, is still susceptible to label noise. However, pairing it with
the new robust Boosting algorithm we propose here results in a more resilient
algorithm under mislabelling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6819</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6819</id><created>2013-09-26</created><authors><author><keyname>Boots</keyname><forenames>Byron</forenames></author><author><keyname>Gordon</keyname><forenames>Geoffrey</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author></authors><title>Hilbert Space Embeddings of Predictive State Representations</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-92-101</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predictive State Representations (PSRs) are an expressive class of models for
controlled stochastic processes. PSRs represent state as a set of predictions
of future observable events. Because PSRs are defined entirely in terms of
observable data, statistically consistent estimates of PSR parameters can be
learned efficiently by manipulating moments of observed training data. Most
learning algorithms for PSRs have assumed that actions and observations are
finite with low cardinality. In this paper, we generalize PSRs to infinite sets
of observations and actions, using the recent concept of Hilbert space
embeddings of distributions. The essence is to represent the state as a
nonparametric conditional embedding operator in a Reproducing Kernel Hilbert
Space (RKHS) and leverage recent work in kernel methods to estimate, predict,
and update the representation. We show that these Hilbert space embeddings of
PSRs are able to gracefully handle continuous actions and observations, and
that our learned models outperform competing system identification algorithms
on several prediction benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6820</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6820</id><created>2013-09-26</created><authors><author><keyname>Brenner</keyname><forenames>Eliot</forenames></author><author><keyname>Sontag</keyname><forenames>David</forenames></author></authors><title>SparsityBoost: A New Scoring Function for Learning Bayesian Network
  Structure</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-112-121</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new consistent scoring function for structure learning of Bayesian
networks. In contrast to traditional approaches to scorebased structure
learning, such as BDeu or MDL, the complexity penalty that we propose is
data-dependent and is given by the probability that a conditional independence
test correctly shows that an edge cannot exist. What really distinguishes this
new scoring function from earlier work is that it has the property of becoming
computationally easier to maximize as the amount of data increases. We prove a
polynomial sample complexity result, showing that maximizing this score is
guaranteed to correctly learn a structure with no false edges and a
distribution close to the generating distribution, whenever there exists a
Bayesian network which is a perfect map for the data generating distribution.
Although the new score can be used with any search algorithm, we give empirical
results showing that it is particularly effective when used together with a
linear programming relaxation approach to Bayesian network structure learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6821</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6821</id><created>2013-09-26</created><authors><author><keyname>Brunskill</keyname><forenames>Emma</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author></authors><title>Sample Complexity of Multi-task Reinforcement Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-122-131</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transferring knowledge across a sequence of reinforcement-learning tasks is
challenging, and has a number of important applications. Though there is
encouraging empirical evidence that transfer can improve performance in
subsequent reinforcement-learning tasks, there has been very little theoretical
analysis. In this paper, we introduce a new multi-task algorithm for a sequence
of reinforcement-learning tasks when each task is sampled independently from
(an unknown) distribution over a finite set of Markov decision processes whose
parameters are initially unknown. For this setting, we prove under certain
assumptions that the per-task sample complexity of exploration is reduced
significantly due to transfer compared to standard single-task algorithms. Our
multi-task algorithm also has the desired characteristic that it is guaranteed
not to exhibit negative transfer: in the worst case its per-task sample
complexity is comparable to the corresponding single-task algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6822</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6822</id><created>2013-09-26</created><authors><author><keyname>Bui</keyname><forenames>Hung</forenames></author><author><keyname>Huynh</keyname><forenames>Tuyen</forenames></author><author><keyname>Riedel</keyname><forenames>Sebastian</forenames></author></authors><title>Automorphism Groups of Graphical Models and Lifted Variational Inference</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-132-141</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the theory of group action, we first introduce the concept of the
automorphism group of an exponential family or a graphical model, thus
formalizing the general notion of symmetry of a probabilistic model. This
automorphism group provides a precise mathematical framework for lifted
inference in the general exponential family. Its group action partitions the
set of random variables and feature functions into equivalent classes (called
orbits) having identical marginals and expectations. Then the inference problem
is effectively reduced to that of computing marginals or expectations for each
class, thus avoiding the need to deal with each individual variable or feature.
We demonstrate the usefulness of this general framework in lifting two classes
of variational approximation for maximum a posteriori (MAP) inference: local
linear programming (LP) relaxation and local LP relaxation with cycle
constraints; the latter yields the first lifted variational inference algorithm
that operates on a bound tighter than the local constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6823</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6823</id><created>2013-09-26</created><authors><author><keyname>Cheng</keyname><forenames>Hao</forenames></author><author><keyname>Zhang</keyname><forenames>Xinhua</forenames></author><author><keyname>Schuurmans</keyname><forenames>Dale</forenames></author></authors><title>Convex Relaxations of Bregman Divergence Clustering</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-162-171</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although many convex relaxations of clustering have been proposed in the past
decade, current formulations remain restricted to spherical Gaussian or
discriminative models and are susceptible to imbalanced clusters. To address
these shortcomings, we propose a new class of convex relaxations that can be
flexibly applied to more general forms of Bregman divergence clustering. By
basing these new formulations on normalized equivalence relations we retain
additional control on relaxation quality, which allows improvement in
clustering quality. We furthermore develop optimization methods that improve
scalability by exploiting recent implicit matrix norm methods. In practice, we
find that the new formulations are able to efficiently produce tighter
clusterings that improve the accuracy of state of the art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6824</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6824</id><created>2013-09-26</created><authors><author><keyname>Claassen</keyname><forenames>Tom</forenames></author><author><keyname>Mooij</keyname><forenames>Joris</forenames></author><author><keyname>Heskes</keyname><forenames>Tom</forenames></author></authors><title>Learning Sparse Causal Models is not NP-hard</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-172-181</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows that causal model discovery is not an NP-hard problem, in
the sense that for sparse graphs bounded by node degree k the sound and
complete causal model can be obtained in worst case order N^{2(k+2)}
independence tests, even when latent variables and selection bias may be
present. We present a modification of the well-known FCI algorithm that
implements the method for an independence oracle, and suggest improvements for
sample/real-world data versions. It does not contradict any known hardness
results, and does not solve an NP-hard problem: it just proves that sparse
causal discovery is perhaps more complicated, but not as hard as learning
minimal Bayesian networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6825</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6825</id><created>2013-09-26</created><updated>2015-03-23</updated><authors><author><keyname>Bartlett</keyname><forenames>Mark</forenames></author><author><keyname>Cussens</keyname><forenames>James</forenames></author></authors><title>Advances in Bayesian Network Learning using Integer Programming</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-182-191</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning Bayesian networks (BNs) from complete
discrete data. This problem of discrete optimisation is formulated as an
integer program (IP). We describe the various steps we have taken to allow
efficient solving of this IP. These are (i) efficient search for cutting
planes, (ii) a fast greedy algorithm to find high-scoring (perhaps not optimal)
BNs and (iii) tightening the linear relaxation of the IP. After relating this
BN learning problem to set covering and the multidimensional 0-1 knapsack
problem, we present our empirical results. These show improvements, sometimes
dramatic, over earlier results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6826</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6826</id><created>2013-09-26</created><authors><author><keyname>Drougard</keyname><forenames>Nicolas</forenames></author><author><keyname>Teichteil-Konigsbuch</keyname><forenames>Florent</forenames></author><author><keyname>Farges</keyname><forenames>Jean-Loup</forenames></author><author><keyname>Dubois</keyname><forenames>Didier</forenames></author></authors><title>Qualitative Possibilistic Mixed-Observable MDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-192-201</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Possibilistic and qualitative POMDPs (pi-POMDPs) are counterparts of POMDPs
used to model situations where the agent's initial belief or observation
probabilities are imprecise due to lack of past experiences or insufficient
data collection. However, like probabilistic POMDPs, optimally solving
pi-POMDPs is intractable: the finite belief state space exponentially grows
with the number of system's states. In this paper, a possibilistic version of
Mixed-Observable MDPs is presented to get around this issue: the complexity of
solving pi-POMDPs, some state variables of which are fully observable, can be
then dramatically reduced. A value iteration algorithm for this new formulation
under infinite horizon is next proposed and the optimality of the returned
policy (for a specified criterion) is shown assuming the existence of a &quot;stay&quot;
action in some goal states. Experimental work finally shows that this
possibilistic model outperforms probabilistic POMDPs commonly used in robotics,
for a target recognition problem where the agent's observations are imprecise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6827</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6827</id><created>2013-09-26</created><authors><author><keyname>Ermon</keyname><forenames>Stefano</forenames></author><author><keyname>Gomes</keyname><forenames>Carla P.</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashish</forenames></author><author><keyname>Selman</keyname><forenames>Bart</forenames></author></authors><title>Optimization With Parity Constraints: From Binary Codes to Discrete
  Integration</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-202-211</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many probabilistic inference tasks involve summations over exponentially
large sets. Recently, it has been shown that these problems can be reduced to
solving a polynomial number of MAP inference queries for a model augmented with
randomly generated parity constraints. By exploiting a connection with
max-likelihood decoding of binary codes, we show that these optimizations are
computationally hard. Inspired by iterative message passing decoding
algorithms, we propose an Integer Linear Programming (ILP) formulation for the
problem, enhanced with new sparsification techniques to improve decoding
performance. By solving the ILP through a sequence of LP relaxations, we get
both lower and upper bounds on the partition function, which hold with high
probability and are much tighter than those obtained with variational methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6828</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6828</id><created>2013-09-26</created><authors><author><keyname>Feldman</keyname><forenames>Zohar</forenames></author><author><keyname>Domshlak</keyname><forenames>Carmel</forenames></author></authors><title>Monte-Carlo Planning: Theoretically Fast Convergence Meets Practical
  Efficiency</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-212-221</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popular Monte-Carlo tree search (MCTS) algorithms for online planning, such
as epsilon-greedy tree search and UCT, aim at rapidly identifying a reasonably
good action, but provide rather poor worst-case guarantees on performance
improvement over time. In contrast, a recently introduced MCTS algorithm BRUE
guarantees exponential-rate improvement over time, yet it is not geared towards
identifying reasonably good choices right at the go. We take a stand on the
individual strengths of these two classes of algorithms, and show how they can
be effectively connected. We then rationalize a principle of &quot;selective tree
expansion&quot;, and suggest a concrete implementation of this principle within
MCTS. The resulting algorithm,s favorably compete with other MCTS algorithms
under short planning times, while preserving the attractive convergence
properties of BRUE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6829</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6829</id><created>2013-09-26</created><authors><author><keyname>Fu</keyname><forenames>Qiang</forenames></author><author><keyname>Wang</keyname><forenames>Huahua</forenames></author><author><keyname>Banerjee</keyname><forenames>Arindam</forenames></author></authors><title>Bethe-ADMM for Tree Decomposition based Parallel MAP Inference</title><categories>cs.AI cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-222-231</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximum a posteriori (MAP) inference in discrete
graphical models. We present a parallel MAP inference algorithm called
Bethe-ADMM based on two ideas: tree-decomposition of the graph and the
alternating direction method of multipliers (ADMM). However, unlike the
standard ADMM, we use an inexact ADMM augmented with a Bethe-divergence based
proximal function, which makes each subproblem in ADMM easy to solve in
parallel using the sum-product algorithm. We rigorously prove global
convergence of Bethe-ADMM. The proposed algorithm is extensively evaluated on
both synthetic and real datasets to illustrate its effectiveness. Further, the
parallel Bethe-ADMM is shown to scale almost linearly with increasing number of
cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6830</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6830</id><created>2013-09-26</created><authors><author><keyname>Ganti</keyname><forenames>Ravi</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author></authors><title>Building Bridges: Viewing Active Learning from the Multi-Armed Bandit
  Lens</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-232-241</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a multi-armed bandit inspired, pool based active
learning algorithm for the problem of binary classification. By carefully
constructing an analogy between active learning and multi-armed bandits, we
utilize ideas such as lower confidence bounds, and self-concordant
regularization from the multi-armed bandit literature to design our proposed
algorithm. Our algorithm is a sequential algorithm, which in each round assigns
a sampling distribution on the pool, samples one point from this distribution,
and queries the oracle for the label of this sampled point. The design of this
sampling distribution is also inspired by the analogy between active learning
and multi-armed bandits. We show how to derive lower confidence bounds required
by our algorithm. Experimental comparisons to previously proposed active
learning algorithms show superior performance on some standard UCI datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6831</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6831</id><created>2013-09-26</created><authors><author><keyname>Geramifard</keyname><forenames>Alborz</forenames></author><author><keyname>Walsh</keyname><forenames>Thomas J.</forenames></author><author><keyname>Roy</keyname><forenames>Nicholas</forenames></author><author><keyname>How</keyname><forenames>Jonathan</forenames></author></authors><title>Batch-iFDD for Representation Expansion in Large MDPs</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-242-251</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching pursuit (MP) methods are a promising class of feature construction
algorithms for value function approximation. Yet existing MP methods require
creating a pool of potential features, mandating expert knowledge or
enumeration of a large feature pool, both of which hinder scalability. This
paper introduces batch incremental feature dependency discovery (Batch-iFDD) as
an MP method that inherits a provable convergence property. Additionally,
Batch-iFDD does not require a large pool of features, leading to lower
computational complexity. Empirical policy evaluation results across three
domains with up to one million states highlight the scalability of Batch-iFDD
over the previous state of the art MP algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6832</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6832</id><created>2013-09-26</created><authors><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author><author><keyname>Domingos</keyname><forenames>Pedro</forenames></author></authors><title>Structured Message Passing</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-252-261</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present structured message passing (SMP), a unifying
framework for approximate inference algorithms that take advantage of
structured representations such as algebraic decision diagrams and sparse hash
tables. These representations can yield significant time and space savings over
the conventional tabular representation when the message has several identical
values (context-specific independence) or zeros (determinism) or both in its
range. Therefore, in order to fully exploit the power of structured
representations, we propose to artificially introduce context-specific
independence and determinism in the messages. This yields a new class of
powerful approximate inference algorithms which includes popular algorithms
such as cluster-graph Belief propagation (BP), expectation propagation and
particle BP as special cases. We show that our new algorithms introduce several
interesting bias-variance trade-offs. We evaluate these trade-offs empirically
and demonstrate that our new algorithms are more accurate and scalable than
state-of-the-art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6833</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6833</id><created>2013-09-26</created><authors><author><keyname>Hajimirsadeghi</keyname><forenames>Hossein</forenames></author><author><keyname>Li</keyname><forenames>Jinling</forenames></author><author><keyname>Mori</keyname><forenames>Greg</forenames></author><author><keyname>Zaki</keyname><forenames>Mohammad</forenames></author><author><keyname>Sayed</keyname><forenames>Tarek</forenames></author></authors><title>Multiple Instance Learning by Discriminative Training of Markov Networks</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-262-271</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a graphical framework for multiple instance learning (MIL) based
on Markov networks. This framework can be used to model the traditional MIL
definition as well as more general MIL definitions. Different levels of
ambiguity -- the portion of positive instances in a bag -- can be explored in
weakly supervised data. To train these models, we propose a discriminative
max-margin learning algorithm leveraging efficient inference for
cardinality-based cliques. The efficacy of the proposed framework is evaluated
on a variety of data sets. Experimental results verify that encoding or
learning the degree of ambiguity can improve classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6834</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6834</id><created>2013-09-26</created><authors><author><keyname>Halpern</keyname><forenames>Yonatan</forenames></author><author><keyname>Sontag</keyname><forenames>David</forenames></author></authors><title>Unsupervised Learning of Noisy-Or Bayesian Networks</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-272-281</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of learning the parameters in Bayesian
networks of discrete variables with known structure and hidden variables.
Previous approaches in these settings typically use expectation maximization;
when the network has high treewidth, the required expectations might be
approximated using Monte Carlo or variational methods. We show how to avoid
inference altogether during learning by giving a polynomial-time algorithm
based on the method-of-moments, building upon recent work on learning
discrete-valued mixture models. In particular, we show how to learn the
parameters for a family of bipartite noisy-or Bayesian networks. In our
experimental results, we demonstrate an application of our algorithm to
learning QMR-DT, a large Bayesian network used for medical diagnosis. We show
that it is possible to fully learn the parameters of QMR-DT even when only the
findings are observed in the training data (ground truth diseases unknown).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6835</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6835</id><created>2013-09-26</created><authors><author><keyname>Hensman</keyname><forenames>James</forenames></author><author><keyname>Fusi</keyname><forenames>Nicolo</forenames></author><author><keyname>Lawrence</keyname><forenames>Neil D.</forenames></author></authors><title>Gaussian Processes for Big Data</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-282-290</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce stochastic variational inference for Gaussian process models.
This enables the application of Gaussian process (GP) models to data sets
containing millions of data points. We show how GPs can be vari- ationally
decomposed to depend on a set of globally relevant inducing variables which
factorize the model in the necessary manner to perform variational inference.
Our ap- proach is readily extended to models with non-Gaussian likelihoods and
latent variable models based around Gaussian processes. We demonstrate the
approach on a simple toy problem and two real world data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6836</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6836</id><created>2013-09-26</created><authors><author><keyname>Hyttinen</keyname><forenames>Antti</forenames></author><author><keyname>Hoyer</keyname><forenames>Patrik O.</forenames></author><author><keyname>Eberhardt</keyname><forenames>Frederick</forenames></author><author><keyname>Jarvisalo</keyname><forenames>Matti</forenames></author></authors><title>Discovering Cyclic Causal Models with Latent Variables: A General
  SAT-Based Procedure</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-301-310</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a very general approach to learning the structure of causal models
based on d-separation constraints, obtained from any given set of overlapping
passive observational or experimental data sets. The procedure allows for both
directed cycles (feedback loops) and the presence of latent variables. Our
approach is based on a logical representation of causal pathways, which permits
the integration of quite general background knowledge, and inference is
performed using a Boolean satisfiability (SAT) solver. The procedure is
complete in that it exhausts the available information on whether any given
edge can be determined to be present or absent, and returns &quot;unknown&quot;
otherwise. Many existing constraint-based causal discovery algorithms can be
seen as special cases, tailored to circumstances in which one or more
restricting assumptions apply. Simulations illustrate the effect of these
assumptions on discovery and how the present algorithm scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6838</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6838</id><created>2013-09-26</created><authors><author><keyname>Honorio</keyname><forenames>Jean</forenames></author><author><keyname>Jaakkola</keyname><forenames>Tommi S.</forenames></author></authors><title>Inverse Covariance Estimation for High-Dimensional Data in Linear Time
  and Space: Spectral Methods for Riccati and Sparse Models</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-291-300</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose maximum likelihood estimation for learning Gaussian graphical
models with a Gaussian (ell_2^2) prior on the parameters. This is in contrast
to the commonly used Laplace (ell_1) prior for encouraging sparseness. We show
that our optimization problem leads to a Riccati matrix equation, which has a
closed form solution. We propose an efficient algorithm that performs a
singular value decomposition of the training data. Our algorithm is
O(NT^2)-time and O(NT)-space for N variables and T samples. Our method is
tailored to high-dimensional problems (N gg T), in which sparseness promoting
methods become intractable. Furthermore, instead of obtaining a single solution
for a specific regularization parameter, our algorithm finds the whole solution
path. We show that the method has logarithmic sample complexity under the
spiked covariance model. We also propose sparsification of the dense solution
with provable performance guarantees. We provide techniques for using our
learnt models, such as removing unimportant variables, computing likelihoods
and conditional distributions. Finally, we show promising results in several
gene expressions datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6839</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6839</id><created>2013-09-26</created><authors><author><keyname>Khaled</keyname><forenames>Arindam</forenames></author><author><keyname>Hansen</keyname><forenames>Eric A.</forenames></author><author><keyname>Yuan</keyname><forenames>Changhe</forenames></author></authors><title>Solving Limited-Memory Influence Diagrams Using Branch-and-Bound Search</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-331-340</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A limited-memory influence diagram (LIMID) generalizes a traditional
influence diagram by relaxing the assumptions of regularity and no-forgetting,
allowing a wider range of decision problems to be modeled. Algorithms for
solving traditional influence diagrams are not easily generalized to solve
LIMIDs, however, and only recently have exact algorithms for solving LIMIDs
been developed. In this paper, we introduce an exact algorithm for solving
LIMIDs that is based on branch-and-bound search. Our approach is related to the
approach of solving an influence diagram by converting it to an equivalent
decision tree, with the difference that the LIMID is converted to a much
smaller decision graph that can be searched more efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6840</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6840</id><created>2013-09-26</created><authors><author><keyname>Koyejo</keyname><forenames>Oluwasanmi</forenames></author><author><keyname>Ghosh</keyname><forenames>Joydeep</forenames></author></authors><title>Constrained Bayesian Inference for Low Rank Multitask Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-341-350</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach for constrained Bayesian inference. Unlike
current methods, our approach does not require convexity of the constraint set.
We reduce the constrained variational inference to a parametric optimization
over the feasible set of densities and propose a general recipe for such
problems. We apply the proposed constrained Bayesian inference approach to
multitask learning subject to rank constraints on the weight matrix. Further,
constrained parameter estimation is applied to recover the sparse conditional
independence structure encoded by prior precision matrices. Our approach is
motivated by reverse inference for high dimensional functional neuroimaging, a
domain where the high dimensionality and small number of examples requires the
use of constraints to ensure meaningful and effective models. For this
application, we propose a model that jointly learns a weight matrix and the
prior inverse covariance structure between different tasks. We present
experimental validation showing that the proposed approach outperforms strong
baseline models in terms of predictive performance and structure recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6841</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6841</id><created>2013-09-26</created><authors><author><keyname>Kumar</keyname><forenames>Akshat</forenames></author><author><keyname>Sheldon</keyname><forenames>Daniel</forenames></author><author><keyname>Srivastava</keyname><forenames>Biplav</forenames></author></authors><title>Collective Diffusion Over Networks: Models and Inference</title><categories>cs.SI physics.soc-ph</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-351-360</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion processes in networks are increasingly used to model the spread of
information and social influence. In several applications in computational
sustainability such as the spread of wildlife, infectious diseases and traffic
mobility pattern, the observed data often consists of only aggregate
information. In this work, we present new models that generalize standard
diffusion processes to such collective settings. We also present optimization
based techniques that can accurately learn the underlying dynamics of the given
contagion process, including the hidden network structure, by only observing
the time a node becomes active and the associated aggregate information.
Empirically, our technique is highly robust and accurately learns network
structure with more than 90% recall and precision. Results on real-world flu
spread data in the US confirm that our technique can also accurately model
infectious disease spread.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6842</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6842</id><created>2013-09-26</created><authors><author><keyname>Lee</keyname><forenames>Sanghack</forenames></author><author><keyname>Honavar</keyname><forenames>Vasant</forenames></author></authors><title>Causal Transportability of Experiments on Controllable Subsets of
  Variables: z-Transportability</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-361-370</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce z-transportability, the problem of estimating the causal effect
of a set of variables X on another set of variables Y in a target domain from
experiments on any subset of controllable variables Z where Z is an arbitrary
subset of observable variables V in a source domain. z-Transportability
generalizes z-identifiability, the problem of estimating in a given domain the
causal effect of X on Y from surrogate experiments on a set of variables Z such
that Z is disjoint from X;. z-Transportability also generalizes
transportability which requires that the causal effect of X on Y in the target
domain be estimable from experiments on any subset of all observable variables
in the source domain. We first generalize z-identifiability to allow cases
where Z is not necessarily disjoint from X. Then, we establish a necessary and
sufficient condition for z-transportability in terms of generalized
z-identifiability and transportability. We provide a correct and complete
algorithm that determines whether a causal effect is z-transportable; and if it
is, produces a transport formula, that is, a recipe for estimating the causal
effect of X on Y in the target domain using information elicited from the
results of experimental manipulations of Z in the source domain and
observational data from the target domain. Our results also show that
do-calculus is complete for z-transportability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6843</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6843</id><created>2013-09-26</created><authors><author><keyname>Maier</keyname><forenames>Marc</forenames></author><author><keyname>Marazopoulou</keyname><forenames>Katerina</forenames></author><author><keyname>Arbour</keyname><forenames>David</forenames></author><author><keyname>Jensen</keyname><forenames>David</forenames></author></authors><title>A Sound and Complete Algorithm for Learning Causal Models from
  Relational Data</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-371-380</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PC algorithm learns maximally oriented causal Bayesian networks. However,
there is no equivalent complete algorithm for learning the structure of
relational models, a more expressive generalization of Bayesian networks.
Recent developments in the theory and representation of relational models
support lifted reasoning about conditional independence. This enables a
powerful constraint for orienting bivariate dependencies and forms the basis of
a new algorithm for learning structure. We present the relational causal
discovery (RCD) algorithm that learns causal relational models. We prove that
RCD is sound and complete, and we present empirical results that demonstrate
effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6844</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6844</id><created>2013-09-26</created><authors><author><keyname>Malone</keyname><forenames>Brandon</forenames></author><author><keyname>Yuan</keyname><forenames>Changhe</forenames></author></authors><title>Evaluating Anytime Algorithms for Learning Optimal Bayesian Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-381-390</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exact algorithms for learning Bayesian networks guarantee to find provably
optimal networks. However, they may fail in difficult learning tasks due to
limited time or memory. In this research we adapt several anytime heuristic
search-based algorithms to learn Bayesian networks. These algorithms find
high-quality solutions quickly, and continually improve the incumbent solution
or prove its optimality before resources are exhausted. Empirical results show
that the anytime window A* algorithm usually finds higher-quality, often
optimal, networks more quickly than other approaches. The results also show
that, surprisingly, while generating networks with few parents per variable are
structurally simpler, they are harder to learn than complex generating networks
with more parents per variable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6845</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6845</id><created>2013-09-26</created><authors><author><keyname>Maua</keyname><forenames>Denis D.</forenames></author><author><keyname>de Campos</keyname><forenames>Cassio Polpo</forenames></author><author><keyname>Benavoli</keyname><forenames>Alessio</forenames></author><author><keyname>Antonucci</keyname><forenames>Alessandro</forenames></author></authors><title>On the Complexity of Strong and Epistemic Credal Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-391-400</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Credal networks are graph-based statistical models whose parameters take
values in a set, instead of being sharply specified as in traditional
statistical models (e.g., Bayesian networks). The computational complexity of
inferences on such models depends on the irrelevance/independence concept
adopted. In this paper, we study inferential complexity under the concepts of
epistemic irrelevance and strong independence. We show that inferences under
strong independence are NP-hard even in trees with ternary variables. We prove
that under epistemic irrelevance the polynomial time complexity of inferences
in credal trees is not likely to extend to more general models (e.g. singly
connected networks). These results clearly distinguish networks that admit
efficient inferences and those where inferences are most likely hard, and
settle several open questions regarding computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6846</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6846</id><created>2013-09-26</created><authors><author><keyname>McInerney</keyname><forenames>James</forenames></author><author><keyname>Rogers</keyname><forenames>Alex</forenames></author><author><keyname>Jennings</keyname><forenames>Nicholas R.</forenames></author></authors><title>Learning Periodic Human Behaviour Models from Sparse Data for
  Crowdsourcing Aid Delivery in Developing Countries</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-401-410</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many developing countries, half the population lives in rural locations,
where access to essentials such as school materials, mosquito nets, and medical
supplies is restricted. We propose an alternative method of distribution (to
standard road delivery) in which the existing mobility habits of a local
population are leveraged to deliver aid, which raises two technical challenges
in the areas optimisation and learning. For optimisation, a standard Markov
decision process applied to this problem is intractable, so we provide an exact
formulation that takes advantage of the periodicities in human location
behaviour. To learn such behaviour models from sparse data (i.e., cell tower
observations), we develop a Bayesian model of human mobility. Using real cell
tower data of the mobility behaviour of 50,000 individuals in Ivory Coast, we
find that our model outperforms the state of the art approaches in mobility
prediction by at least 25% (in held-out data likelihood). Furthermore, when
incorporating mobility prediction with our MDP approach, we find a 81.3%
reduction in total delivery time versus routine planning that minimises just
the number of participants in the solution path.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6847</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6847</id><created>2013-09-26</created><authors><author><keyname>Meshi</keyname><forenames>Ofer</forenames></author><author><keyname>Eban</keyname><forenames>Elad</forenames></author><author><keyname>Elidan</keyname><forenames>Gal</forenames></author><author><keyname>Globerson</keyname><forenames>Amir</forenames></author></authors><title>Learning Max-Margin Tree Predictors</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-411-420</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured prediction is a powerful framework for coping with joint
prediction of interacting outputs. A central difficulty in using this framework
is that often the correct label dependence structure is unknown. At the same
time, we would like to avoid an overly complex structure that will lead to
intractable prediction. In this work we address the challenge of learning tree
structured predictive models that achieve high accuracy while at the same time
facilitate efficient (linear time) inference. We start by proving that this
task is in general NP-hard, and then suggest an approximate alternative.
Briefly, our CRANK approach relies on a novel Circuit-RANK regularizer that
penalizes non-tree structures and that can be optimized using a CCCP procedure.
We demonstrate the effectiveness of our approach on several domains and show
that, despite the relative simplicity of the structure, prediction accuracy is
competitive with a fully connected model that is computationally costly at
prediction time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6848</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6848</id><created>2013-09-26</created><authors><author><keyname>Mezuman</keyname><forenames>Elad</forenames></author><author><keyname>Tarlow</keyname><forenames>Daniel</forenames></author><author><keyname>Globerson</keyname><forenames>Amir</forenames></author><author><keyname>Weiss</keyname><forenames>Yair</forenames></author></authors><title>Tighter Linear Program Relaxations for High Order Graphical Models</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-421-430</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical models with High Order Potentials (HOPs) have received considerable
interest in recent years. While there are a variety of approaches to inference
in these models, nearly all of them amount to solving a linear program (LP)
relaxation with unary consistency constraints between the HOP and the
individual variables. In many cases, the resulting relaxations are loose, and
in these cases the results of inference can be poor. It is thus desirable to
look for more accurate ways of performing inference in these models. In this
work, we study the LP relaxations that result from enforcing additional
consistency constraints between the HOP and the rest of the model. We address
theoretical questions about the strength of the resulting relaxations compared
to the relaxations that arise in standard approaches, and we develop practical
and efficient message passing algorithms for optimizing the LPs. Empirically,
we show that the LPs with additional consistency constraints lead to more
accurate inference on some challenging problems that include a combination of
low order and high order terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6849</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6849</id><created>2013-09-26</created><authors><author><keyname>Mooij</keyname><forenames>Joris</forenames></author><author><keyname>Heskes</keyname><forenames>Tom</forenames></author></authors><title>Cyclic Causal Discovery from Continuous Equilibrium Data</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-431-439</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for learning cyclic causal models from a combination of
observational and interventional equilibrium data. Novel aspects of the
proposed method are its ability to work with continuous data (without assuming
linearity) and to deal with feedback loops. Within the context of biochemical
reactions, we also propose a novel way of modeling interventions that modify
the activity of compounds instead of their abundance. For computational
reasons, we approximate the nonlinear causal mechanisms by (coupled) local
linearizations, one for each experimental condition. We apply the method to
reconstruct a cellular signaling network from the flow cytometry data measured
by Sachs et al. (2005). We show that our method finds evidence in the data for
feedback loops and that it gives a more accurate quantitative description of
the data at comparable model complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6850</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6850</id><created>2013-09-26</created><authors><author><keyname>Nagano</keyname><forenames>Kiyohito</forenames></author><author><keyname>Kawahara</keyname><forenames>Yoshinobu</forenames></author></authors><title>Structured Convex Optimization under Submodular Constraints</title><categories>cs.LG cs.DS stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-459-468</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of discrete and continuous optimization problems in machine learning
are related to convex minimization problems under submodular constraints. In
this paper, we deal with a submodular function with a directed graph structure,
and we show that a wide range of convex optimization problems under submodular
constraints can be solved much more efficiently than general submodular
optimization methods by a reduction to a maximum flow problem. Furthermore, we
give some applications, including sparse optimization methods, in which the
proposed methods are effective. Additionally, we evaluate the performance of
the proposed method through computational experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6851</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6851</id><created>2013-09-26</created><authors><author><keyname>Niinimaki</keyname><forenames>Teppo</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>Treedy: A Heuristic for Counting and Sampling Subsets</title><categories>cs.DS cs.AI cs.LG</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-469-477</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a collection of weighted subsets of a ground set N. Given a query
subset Q of N, how fast can one (1) find the weighted sum over all subsets of
Q, and (2) sample a subset of Q proportionally to the weights? We present a
tree-based greedy heuristic, Treedy, that for a given positive tolerance d
answers such counting and sampling queries to within a guaranteed relative
error d and total variation distance d, respectively. Experimental results on
artificial instances and in application to Bayesian structure discovery in
Bayesian networks show that approximations yield dramatic savings in running
time compared to exact computation, and that Treedy typically outperforms a
previously proposed sorting-based heuristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6852</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6852</id><created>2013-09-26</created><authors><author><keyname>Niu</keyname><forenames>Shuzi</forenames></author><author><keyname>Lan</keyname><forenames>Yanyan</forenames></author><author><keyname>Guo</keyname><forenames>Jiafeng</forenames></author><author><keyname>Cheng</keyname><forenames>Xueqi</forenames></author></authors><title>Stochastic Rank Aggregation</title><categories>cs.LG cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-478-487</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of rank aggregation, which aims to find a
consensus ranking among multiple ranking inputs. Traditional rank aggregation
methods are deterministic, and can be categorized into explicit and implicit
methods depending on whether rank information is explicitly or implicitly
utilized. Surprisingly, experimental results on real data sets show that
explicit rank aggregation methods would not work as well as implicit methods,
although rank information is critical for the task. Our analysis indicates that
the major reason might be the unreliable rank information from incomplete
ranking inputs. To solve this problem, we propose to incorporate uncertainty
into rank aggregation and tackle the problem in both unsupervised and
supervised scenario. We call this novel framework {stochastic rank aggregation}
(St.Agg for short). Specifically, we introduce a prior distribution on ranks,
and transform the ranking functions or objectives in traditional explicit
methods to their expectations over this distribution. Our experiments on
benchmark data sets show that the proposed St.Agg outperforms the baselines in
both unsupervised and supervised scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6854</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6854</id><created>2013-09-26</created><authors><author><keyname>Oren</keyname><forenames>Sigal</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Pay or Play</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-488-497</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the class of pay or play games, which captures scenarios in
which each decision maker is faced with a choice between two actions: one with
a fixed payoff and an- other with a payoff dependent on others' selected
actions. This is, arguably, the simplest setting that models selection among
certain and uncertain outcomes in a multi-agent system. We study the properties
of equilibria in such games from both a game-theoretic perspective and a
computational perspective. Our main positive result establishes the existence
of a semi-strong equilibrium in every such game. We show that although simple,
pay of play games contain a large variety of well-studied environments, e.g.,
vaccination games. We discuss the interesting implications of our results for
these environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6855</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6855</id><created>2013-09-26</created><authors><author><keyname>Pacer</keyname><forenames>Michael</forenames></author><author><keyname>Williams</keyname><forenames>Joseph</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Lombrozo</keyname><forenames>Tania</forenames></author><author><keyname>Griffiths</keyname><forenames>Thomas</forenames></author></authors><title>Evaluating computational models of explanation using human judgments</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-498-507</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We evaluate four computational models of explanation in Bayesian networks by
comparing model predictions to human judgments. In two experiments, we present
human participants with causal structures for which the models make divergent
predictions and either solicit the best explanation for an observed event
(Experiment 1) or have participants rate provided explanations for an observed
event (Experiment 2). Across two versions of two causal structures and across
both experiments, we find that the Causal Explanation Tree and Most Relevant
Explanation models provide better fits to human data than either Most Probable
Explanation or Explanation Tree models. We identify strengths and shortcomings
of these models and what they can reveal about human explanation. We conclude
by suggesting the value of pursuing computational and psychological
investigations of explanation in parallel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6856</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6856</id><created>2013-09-26</created><authors><author><keyname>Perny</keyname><forenames>Patrice</forenames></author><author><keyname>Weng</keyname><forenames>Paul</forenames></author><author><keyname>Goldsmith</keyname><forenames>Judy</forenames></author><author><keyname>Hanna</keyname><forenames>Josiah</forenames></author></authors><title>Approximation of Lorenz-Optimal Solutions in Multiobjective Markov
  Decision Processes</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-508-517</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to fair optimization in Multiobjective Markov Decision
Processes (MOMDPs). A MOMDP is an extension of the MDP model for planning under
uncertainty while trying to optimize several reward functions simultaneously.
This applies to multiagent problems when rewards define individual utility
functions, or in multicriteria problems when rewards refer to different
features. In this setting, we study the determination of policies leading to
Lorenz-non-dominated tradeoffs. Lorenz dominance is a refinement of Pareto
dominance that was introduced in Social Choice for the measurement of
inequalities. In this paper, we introduce methods to efficiently approximate
the sets of Lorenz-non-dominated solutions of infinite-horizon, discounted
MOMDPs. The approximations are polynomial-sized subsets of those solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6857</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6857</id><created>2013-09-26</created><authors><author><keyname>Petrik</keyname><forenames>Marek</forenames></author><author><keyname>Subramanian</keyname><forenames>Dharmashankar</forenames></author><author><keyname>Marecki</keyname><forenames>Janusz</forenames></author></authors><title>Solution Methods for Constrained Markov Decision Process with Continuous
  Probability Modulation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-518-526</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose solution methods for previously-unsolved constrained MDPs in which
actions can continuously modify the transition probabilities within some
acceptable sets. While many methods have been proposed to solve regular MDPs
with large state sets, there are few practical approaches for solving
constrained MDPs with large action sets. In particular, we show that the
continuous action sets can be replaced by their extreme points when the rewards
are linear in the modulation. We also develop a tractable optimization
formulation for concave reward functions and, surprisingly, also extend it to
non- concave reward functions by using their concave envelopes. We evaluate the
effectiveness of the approach on the problem of managing delinquencies in a
portfolio of loans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6858</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6858</id><created>2013-09-26</created><authors><author><keyname>Quadrianto</keyname><forenames>Novi</forenames></author><author><keyname>Sharmanska</keyname><forenames>Viktoriia</forenames></author><author><keyname>Knowles</keyname><forenames>David A.</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>The Supervised IBP: Neighbourhood Preserving Infinite Latent Feature
  Models</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-527-536</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a probabilistic model to infer supervised latent variables in the
Hamming space from observed data. Our model allows simultaneous inference of
the number of binary latent variables, and their values. The latent variables
preserve neighbourhood structure of the data in a sense that objects in the
same semantic concept have similar latent values, and objects in different
concepts have dissimilar latent values. We formulate the supervised infinite
latent variable problem based on an intuitive principle of pulling objects
together if they are of the same type, and pushing them apart if they are not.
We then combine this principle with a flexible Indian Buffet Process prior on
the latent variables. We show that the inferred supervised latent variables can
be directly used to perform a nearest neighbour search for the purpose of
retrieval. We introduce a new application of dynamically extending hash codes,
and show how to effectively couple the structure of the hash codes with
continuously growing structure of the neighbourhood preserving infinite latent
feature space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6859</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6859</id><created>2013-09-26</created><authors><author><keyname>Ruozzi</keyname><forenames>Nicholas</forenames></author></authors><title>Beyond Log-Supermodularity: Lower Bounds and the Bethe Partition
  Function</title><categories>cs.DM math.CO</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-546-555</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent result has demonstrated that the Bethe partition function always
lower bounds the true partition function of binary, log-supermodular graphical
models. We demonstrate that these results can be extended to other interesting
classes of graphical models that are not necessarily binary or
log-supermodular: the ferromagnetic Potts model with a uniform external field
and its generalizations and special classes of weighted graph homomorphism
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6860</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6860</id><created>2013-09-26</created><authors><author><keyname>Sgouritsa</keyname><forenames>Eleni</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Peters</keyname><forenames>Jonas</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Identifying Finite Mixtures of Nonparametric Product Distributions and
  Causal Inference of Confounders</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-556-565</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a kernel method to identify finite mixtures of nonparametric
product distributions. It is based on a Hilbert space embedding of the joint
distribution. The rank of the constructed tensor is equal to the number of
mixture components. We present an algorithm to recover the components by
partitioning the data points into clusters such that the variables are jointly
conditionally independent given the cluster. This method can be used to
identify finite confounders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6862</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6862</id><created>2013-09-26</created><authors><author><keyname>Shah</keyname><forenames>Amar</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Determinantal Clustering Processes - A Nonparametric Bayesian Approach
  to Kernel Based Semi-Supervised Clustering</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-566-575</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-supervised clustering is the task of clustering data points into
clusters where only a fraction of the points are labelled. The true number of
clusters in the data is often unknown and most models require this parameter as
an input. Dirichlet process mixture models are appealing as they can infer the
number of clusters from the data. However, these models do not deal with high
dimensional data well and can encounter difficulties in inference. We present a
novel nonparameteric Bayesian kernel based method to cluster data points
without the need to prespecify the number of clusters or to model complicated
densities from which data points are assumed to be generated from. The key
insight is to use determinants of submatrices of a kernel matrix as a measure
of how close together a set of points are. We explore some theoretical
properties of the model and derive a natural Gibbs based algorithm with MCMC
hyperparameter learning. The model is implemented on a variety of synthetic and
real world data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6863</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6863</id><created>2013-09-26</created><authors><author><keyname>Shpitser</keyname><forenames>Ilya</forenames></author><author><keyname>Evans</keyname><forenames>Robin J.</forenames></author><author><keyname>Richardson</keyname><forenames>Thomas S.</forenames></author><author><keyname>Robins</keyname><forenames>James M.</forenames></author></authors><title>Sparse Nested Markov models with Log-linear Parameters</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-576-585</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden variables are ubiquitous in practical data analysis, and therefore
modeling marginal densities and doing inference with the resulting models is an
important problem in statistics, machine learning, and causal inference.
Recently, a new type of graphical model, called the nested Markov model, was
developed which captures equality constraints found in marginals of directed
acyclic graph (DAG) models. Some of these constraints, such as the so called
`Verma constraint', strictly generalize conditional independence. To make
modeling and inference with nested Markov models practical, it is necessary to
limit the number of parameters in the model, while still correctly capturing
the constraints in the marginal of a DAG model. Placing such limits is similar
in spirit to sparsity methods for undirected graphical models, and regression
models. In this paper, we give a log-linear parameterization which allows
sparse modeling with nested Markov models. We illustrate the advantages of this
parameterization with a simulation study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6864</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6864</id><created>2013-09-26</created><authors><author><keyname>Soufiani</keyname><forenames>Hossein Azari</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author><author><keyname>Xia</keyname><forenames>Lirong</forenames></author></authors><title>Preference Elicitation For General Random Utility Models</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-596-605</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses {General Random Utility Models (GRUMs)}. These are a
class of parametric models that generate partial ranks over alternatives given
attributes of agents and alternatives. We propose two preference elicitation
scheme for GRUMs developed from principles in Bayesian experimental design, one
for social choice and the other for personalized choice. We couple this with a
general Monte-Carlo-Expectation-Maximization (MC-EM) based algorithm for MAP
inference under GRUMs. We also prove uni-modality of the likelihood functions
for a class of GRUMs. We examine the performance of various criteria by
experimental studies, which show that the proposed elicitation scheme increases
the precision of estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6865</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6865</id><created>2013-09-26</created><authors><author><keyname>Srivastava</keyname><forenames>Nitish</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan R</forenames></author><author><keyname>Hinton</keyname><forenames>Geoffrey E.</forenames></author></authors><title>Modeling Documents with Deep Boltzmann Machines</title><categories>cs.LG cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-616-624</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a Deep Boltzmann Machine model suitable for modeling and
extracting latent semantic representations from a large unstructured collection
of documents. We overcome the apparent difficulty of training a DBM with
judicious parameter tying. This parameter tying enables an efficient
pretraining algorithm and a state initialization scheme that aids inference.
The model can be trained just as efficiently as a standard Restricted Boltzmann
Machine. Our experiments show that the model assigns better log probability to
unseen data than the Replicated Softmax model. Features extracted from our
model outperform LDA, Replicated Softmax, and DocNADE models on document
retrieval and document classification tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6867</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6867</id><created>2013-09-26</created><authors><author><keyname>Tenzer</keyname><forenames>Yaniv</forenames></author><author><keyname>Elidan</keyname><forenames>Gal</forenames></author></authors><title>Speedy Model Selection (SMS) for Copula Models</title><categories>cs.LG stat.ME</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-625-634</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the challenge of efficiently learning the structure of expressive
multivariate real-valued densities of copula graphical models. We start by
theoretically substantiating the conjecture that for many copula families the
magnitude of Spearman's rank correlation coefficient is monotone in the
expected contribution of an edge in network, namely the negative copula
entropy. We then build on this theory and suggest a novel Bayesian approach
that makes use of a prior over values of Spearman's rho for learning
copula-based models that involve a mix of copula families. We demonstrate the
generalization effectiveness of our highly efficient approach on sizable and
varied real-life datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6868</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6868</id><created>2013-09-26</created><authors><author><keyname>Tripp</keyname><forenames>Charles</forenames></author><author><keyname>Shachter</keyname><forenames>Ross D.</forenames></author></authors><title>Approximate Kalman Filter Q-Learning for Continuous State-Space MDPs</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-644-653</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We seek to learn an effective policy for a Markov Decision Process (MDP) with
continuous states via Q-Learning. Given a set of basis functions over state
action pairs we search for a corresponding set of linear weights that minimizes
the mean Bellman residual. Our algorithm uses a Kalman filter model to estimate
those weights and we have developed a simpler approximate Kalman filter model
that outperforms the current state of the art projected TD-Learning methods on
several standard benchmark problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6869</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6869</id><created>2013-09-26</created><authors><author><keyname>Valko</keyname><forenames>Michal</forenames></author><author><keyname>Korda</keyname><forenames>Nathaniel</forenames></author><author><keyname>Munos</keyname><forenames>Remi</forenames></author><author><keyname>Flaounas</keyname><forenames>Ilias</forenames></author><author><keyname>Cristianini</keyname><forenames>Nelo</forenames></author></authors><title>Finite-Time Analysis of Kernelised Contextual Bandits</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-654-663</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of online reward maximisation over a large finite set
of actions described by their contexts. We focus on the case when the number of
actions is too big to sample all of them even once. However we assume that we
have access to the similarities between actions' contexts and that the expected
reward is an arbitrary linear function of the contexts' images in the related
reproducing kernel Hilbert space (RKHS). We propose KernelUCB, a kernelised UCB
algorithm, and give a cumulative regret bound through a frequentist analysis.
For contextual bandits, the related algorithm GP-UCB turns out to be a special
case of our algorithm, and our finite-time analysis improves the regret bound
of GP-UCB for the agnostic case, both in the terms of the kernel-dependent
quantity and the RKHS norm of the reward function. Moreover, for the linear
kernel, our regret bound matches the lower bound for contextual linear bandits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6870</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6870</id><created>2013-09-26</created><authors><author><keyname>Venugopal</keyname><forenames>Deepak</forenames></author><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author></authors><title>Dynamic Blocking and Collapsing for Gibbs Sampling</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-664-673</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate combining blocking and collapsing -- two widely
used strategies for improving the accuracy of Gibbs sampling -- in the context
of probabilistic graphical models (PGMs). We show that combining them is not
straight-forward because collapsing (or eliminating variables) introduces new
dependencies in the PGM and in computation-limited settings, this may adversely
affect blocking. We therefore propose a principled approach for tackling this
problem. Specifically, we develop two scoring functions, one each for blocking
and collapsing, and formulate the problem of partitioning the variables in the
PGM into blocked and collapsed subsets as simultaneously maximizing both
scoring functions (i.e., a multi-objective optimization problem). We propose a
dynamic, greedy algorithm for approximately solving this intractable
optimization problem. Our dynamic algorithm periodically updates the
partitioning into blocked and collapsed variables by leveraging correlation
statistics gathered from the generated samples and enables rapid mixing by
blocking together and collapsing highly correlated variables. We demonstrate
experimentally the clear benefit of our dynamic approach: as more samples are
drawn, our dynamic approach significantly outperforms static graph-based
approaches by an order of magnitude in terms of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6871</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6871</id><created>2013-09-26</created><authors><author><keyname>Vianna</keyname><forenames>Luis Gustavo</forenames></author><author><keyname>Sanner</keyname><forenames>Scott</forenames></author><author><keyname>de Barros</keyname><forenames>Leliane Nunes</forenames></author></authors><title>Bounded Approximate Symbolic Dynamic Programming for Hybrid MDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-674-683</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in symbolic dynamic programming (SDP) combined with the
extended algebraic decision diagram (XADD) data structure have provided exact
solutions for mixed discrete and continuous (hybrid) MDPs with piecewise linear
dynamics and continuous actions. Since XADD-based exact solutions may grow
intractably large for many problems, we propose a bounded error compression
technique for XADDs that involves the solution of a constrained bilinear saddle
point problem. Fortuitously, we show that given the special structure of this
problem, it can be expressed as a bilevel linear programming problem and solved
to optimality in finite time via constraint generation, despite having an
infinite set of constraints. This solution permits the use of efficient linear
program solvers for XADD compression and enables a novel class of bounded
approximate SDP algorithms for hybrid MDPs that empirically offers
order-of-magnitude speedups over the exact solution in exchange for a small
approximation error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6872</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6872</id><created>2013-09-26</created><authors><author><keyname>Weller</keyname><forenames>Adrian</forenames></author><author><keyname>Jebara</keyname><forenames>Tony S.</forenames></author></authors><title>On MAP Inference by MWSS on Perfect Graphs</title><categories>cs.AI cs.DS</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-684-693</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the most likely (MAP) configuration of a Markov random field (MRF) is
NP-hard in general. A promising, recent technique is to reduce the problem to
finding a maximum weight stable set (MWSS) on a derived weighted graph, which
if perfect, allows inference in polynomial time. We derive new results for this
approach, including a general decomposition theorem for MRFs of any order and
number of labels, extensions of results for binary pairwise models with
submodular cost functions to higher order, and an exact characterization of
which binary pairwise MRFs can be efficiently solved with this method. This
defines the power of the approach on this class of models, improves our toolbox
and expands the range of tractable models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6874</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6874</id><created>2013-09-26</created><authors><author><keyname>Xie</keyname><forenames>Pengtao</forenames></author><author><keyname>Xing</keyname><forenames>Eric P.</forenames></author></authors><title>Integrating Document Clustering and Topic Modeling</title><categories>cs.LG cs.CL cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-694-703</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Document clustering and topic modeling are two closely related tasks which
can mutually benefit each other. Topic modeling can project documents into a
topic space which facilitates effective document clustering. Cluster labels
discovered by document clustering can be incorporated into topic models to
extract local topics specific to each cluster and global topics shared by all
clusters. In this paper, we propose a multi-grain clustering topic model
(MGCTM) which integrates document clustering and topic modeling into a unified
framework and jointly performs the two tasks to achieve the overall best
performance. Our model tightly couples two components: a mixture component used
for discovering latent groups in document collection and a topic model
component used for mining multi-grain topics including local topics specific to
each cluster and global topics shared across clusters.We employ variational
inference to approximate the posterior of hidden variables and learn model
parameters. Experiments on two datasets demonstrate the effectiveness of our
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6875</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6875</id><created>2013-09-26</created><authors><author><keyname>Zhao</keyname><forenames>Peilin</forenames></author><author><keyname>Hoi</keyname><forenames>Steven</forenames></author><author><keyname>Zhuang</keyname><forenames>Jinfeng</forenames></author></authors><title>Active Learning with Expert Advice</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-704-713</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional learning with expert advice methods assumes a learner is always
receiving the outcome (e.g., class labels) of every incoming training instance
at the end of each trial. In real applications, acquiring the outcome from
oracle can be costly or time consuming. In this paper, we address a new problem
of active learning with expert advice, where the outcome of an instance is
disclosed only when it is requested by the online learner. Our goal is to learn
an accurate prediction model by asking the oracle the number of questions as
small as possible. To address this challenge, we propose a framework of active
forecasters for online active learning with expert advice, which attempts to
extend two regular forecasters, i.e., Exponentially Weighted Average Forecaster
and Greedy Forecaster, to tackle the task of active learning with expert
advice. We prove that the proposed algorithms satisfy the Hannan consistency
under some proper assumptions, and validate the efficacy of our technique by an
extensive set of experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6876</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6876</id><created>2013-09-26</created><authors><author><keyname>Zhang</keyname><forenames>Chao</forenames></author></authors><title>Bennett-type Generalization Bounds: Large-deviation Case and Faster Rate
  of Convergence</title><categories>stat.ML cs.LG</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-714-722</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the Bennett-type generalization bounds of the
learning process for i.i.d. samples, and then show that the generalization
bounds have a faster rate of convergence than the traditional results. In
particular, we first develop two types of Bennett-type deviation inequality for
the i.i.d. learning process: one provides the generalization bounds based on
the uniform entropy number; the other leads to the bounds based on the
Rademacher complexity. We then adopt a new method to obtain the alternative
expressions of the Bennett-type generalization bounds, which imply that the
bounds have a faster rate o(N^{-1/2}) of convergence than the traditional
results O(N^{-1/2}). Additionally, we find that the rate of the bounds will
become faster in the large-deviation case, which refers to a situation where
the empirical risk is far away from (at least not close to) the expected risk.
Finally, we analyze the asymptotical convergence of the learning process and
compare our analysis with the existing results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6883</identifier>
 <datestamp>2015-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6883</id><created>2013-09-26</created><updated>2014-03-28</updated><authors><author><keyname>Bruynooghe</keyname><forenames>Maurice</forenames></author><author><keyname>Blockeel</keyname><forenames>Hendrik</forenames></author><author><keyname>Bogaerts</keyname><forenames>Bart</forenames></author><author><keyname>De Cat</keyname><forenames>Broes</forenames></author><author><keyname>De Pooter</keyname><forenames>Stef</forenames></author><author><keyname>Jansen</keyname><forenames>Joachim</forenames></author><author><keyname>Labarre</keyname><forenames>Anthony</forenames></author><author><keyname>Ramon</keyname><forenames>Jan</forenames></author><author><keyname>Denecker</keyname><forenames>Marc</forenames></author><author><keyname>Verwer</keyname><forenames>Sicco</forenames></author></authors><title>Predicate Logic as a Modeling Language: Modeling and Solving some
  Machine Learning and Data Mining Problems with IDP3</title><categories>cs.LO cs.AI</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><journal-ref>Theory and Practice of Logic Programming 15 (2014) 783-817</journal-ref><doi>10.1017/S147106841400009X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a gentle introduction to problem solving with the IDP3
system. The core of IDP3 is a finite model generator that supports first order
logic enriched with types, inductive definitions, aggregates and partial
functions. It offers its users a modeling language that is a slight extension
of predicate logic and allows them to solve a wide range of search problems.
Apart from a small introductory example, applications are selected from
problems that arose within machine learning and data mining research. These
research areas have recently shown a strong interest in declarative modeling
and constraint solving as opposed to algorithmic approaches. The paper
illustrates that the IDP3 system can be a valuable tool for researchers with
such an interest.
  The first problem is in the domain of stemmatology, a domain of philology
concerned with the relationship between surviving variant versions of text. The
second problem is about a somewhat related problem within biology where
phylogenetic trees are used to represent the evolution of species. The third
and final problem concerns the classical problem of learning a minimal
automaton consistent with a given set of strings. For this last problem, we
show that the performance of our solution comes very close to that of a
state-of-the art solution. For each of these applications, we analyze the
problem, illustrate the development of a logic-based model and explore how
alternatives can affect the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6908</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6908</id><created>2013-09-26</created><authors><author><keyname>Ray</keyname><forenames>Sanjog</forenames></author><author><keyname>Sharma</keyname><forenames>Anuj</forenames></author></authors><title>A Collaborative Filtering Based Approach for Recommending Elective
  Courses</title><categories>cs.IR</categories><comments>10 Pages, Ray, S., &amp; Sharma, A. (2011). A Collaborative Filtering
  Based Approach for Recommending Elective Courses. 5th International
  Conference on Information Systems, Technology and Management (ICISTM-2011).
  Gurgaon, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In management education programmes today, students face a difficult time in
choosing electives as the number of electives available are many. As the range
and diversity of different elective courses available for selection have
increased, course recommendation systems that help students in making choices
about courses have become more relevant. In this paper we extend the concept of
collaborative filtering approach to develop a course recommendation system. The
proposed approach provides student an accurate prediction of the grade they may
get if they choose a particular course, which will be helpful when they decide
on selecting elective courses, as grade is an important parameter for a student
while deciding on an elective course. We experimentally evaluate the
collaborative filtering approach on a real life data set and show that the
proposed system is effective in terms of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6914</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6914</id><created>2013-09-26</created><authors><author><keyname>Buliga</keyname><forenames>Marius</forenames></author></authors><title>Chemical concrete machine</title><categories>cs.FL math.LO q-bio.MN</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The chemical concrete machine is a graph rewriting system which uses only
local moves (rewrites), seen as chemical reactions involving molecules which
are graphs made up by 4 trivalent nodes. It is Turing complete, therefore it
might be used as a model of computation in algorithmic chemistry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6919</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6919</id><created>2013-09-26</created><authors><author><keyname>Zuk</keyname><forenames>Or</forenames></author><author><keyname>Amir</keyname><forenames>Amnon</forenames></author><author><keyname>Zeisel</keyname><forenames>Amit</forenames></author><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author><author><keyname>Shental</keyname><forenames>Noam</forenames></author></authors><title>Accurate Profiling of Microbial Communities from Massively Parallel
  Sequencing using Convex Optimization</title><categories>cs.CE q-bio.GN q-bio.QM stat.AP stat.CO</categories><comments>To appear in SPIRE 13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the Microbial Community Reconstruction ({\bf MCR}) Problem, which
is fundamental for microbiome analysis. In this problem, the goal is to
reconstruct the identity and frequency of species comprising a microbial
community, using short sequence reads from Massively Parallel Sequencing (MPS)
data obtained for specified genomic regions. We formulate the problem
mathematically as a convex optimization problem and provide sufficient
conditions for identifiability, namely the ability to reconstruct species
identity and frequency correctly when the data size (number of reads) grows to
infinity. We discuss different metrics for assessing the quality of the
reconstructed solution, including a novel phylogenetically-aware metric based
on the Mahalanobis distance, and give upper-bounds on the reconstruction error
for a finite number of reads under different metrics. We propose a scalable
divide-and-conquer algorithm for the problem using convex optimization, which
enables us to handle large problems (with $\sim10^6$ species). We show using
numerical simulations that for realistic scenarios, where the microbial
communities are sparse, our algorithm gives solutions with high accuracy, both
in terms of obtaining accurate frequency, and in terms of species phylogenetic
resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6925</identifier>
 <datestamp>2014-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6925</id><created>2013-09-26</created><authors><author><keyname>Takabe</keyname><forenames>Satoshi</forenames></author><author><keyname>Hukushima</keyname><forenames>Koji</forenames></author></authors><title>Typical behavior of the linear programming method for combinatorial
  optimization problems: From a statistical-mechanical perspective</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><journal-ref>J. Phys. Soc. Jpn. 83 (2014) 043801</journal-ref><doi>10.7566/JPSJ.83.043801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typical behavior of the linear programming problem (LP) is studied as a
relaxation of the minimum vertex cover problem, which is a type of the integer
programming problem (IP). To deal with the LP and IP by statistical mechanics,
a lattice-gas model on the Erd\&quot;os-R\'enyi random graphs is analyzed by a
replica method. It is found that the LP optimal solution is typically equal to
that of the IP below the critical average degree c*=e in the thermodynamic
limit. The critical threshold for LP=IP is beyond a mathematical result, c=1,
and coincides with the replica-symmetry-breaking threshold of the IP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6927</identifier>
 <datestamp>2013-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6927</id><created>2013-09-26</created><updated>2013-12-12</updated><authors><author><keyname>Wild</keyname><forenames>Marcel</forenames></author></authors><title>Inclusion-exclusion meets exclusion</title><categories>cs.DM math.CO</categories><comments>Version 2 features various improvements, in particular in Sections 4
  and 5</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some &quot;principle of exclusion&quot; (POE) has been introduced and investigated by
the author in previous publications. In particular the POE often outperforms
the familiar principle of inclusion-exclusion (IE), provided both are
applicable. In the present article we argue that sometimes the two can join
hands. That is, POE doesn't replace IE but rather accelerates the otherwise
infeasible IE calculations. The ideas are applied to count (a) constrained
permutations (constrained in a way more general than by forbidden positions),
(b) integer partitions, and (c) models of a Boolean function given in DNF.
Concerning (c), for several choices of parameters binary decision diagrams are
not competitive, and they never are competitive when only models (=bitstrings)
of fixed weight need to be counted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6928</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6928</id><created>2013-09-24</created><updated>2013-11-30</updated><authors><author><keyname>Csermely</keyname><forenames>Peter</forenames></author><author><keyname>London</keyname><forenames>Andras</forenames></author><author><keyname>Wu</keyname><forenames>Ling-Yun</forenames></author><author><keyname>Uzzi</keyname><forenames>Brian</forenames></author></authors><title>Structure and dynamics of core-periphery networks</title><categories>physics.soc-ph cs.NI cs.SI nlin.AO q-bio.MN</categories><comments>a comprehensive review of 41 pages, 2 figures, 1 table and 182
  references</comments><journal-ref>Journal of Complex Networks 1, 93-123 (2013)</journal-ref><doi>10.1093/comnet/cnt016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies uncovered important core/periphery network structures
characterizing complex sets of cooperative and competitive interactions between
network nodes, be they proteins, cells, species or humans. Better
characterization of the structure, dynamics and function of core/periphery
networks is a key step of our understanding cellular functions, species
adaptation, social and market changes. Here we summarize the current knowledge
of the structure and dynamics of &quot;traditional&quot; core/periphery networks,
rich-clubs, nested, bow-tie and onion networks. Comparing core/periphery
structures with network modules, we discriminate between global and local
cores. The core/periphery network organization lies in the middle of several
extreme properties, such as random/condensed structures, clique/star
configurations, network symmetry/asymmetry, network
assortativity/disassortativity, as well as network hierarchy/anti-hierarchy.
These properties of high complexity together with the large degeneracy of core
pathways ensuring cooperation and providing multiple options of network flow
re-channelling greatly contribute to the high robustness of complex systems.
Core processes enable a coordinated response to various stimuli, decrease
noise, and evolve slowly. The integrative function of network cores is an
important step in the development of a large variety of complex organisms and
organizations. In addition to these important features and several decades of
research interest, studies on core/periphery networks still have a number of
unexplored areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6933</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6933</id><created>2013-09-26</created><authors><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author><author><keyname>Kolar</keyname><forenames>Mladen</forenames></author><author><keyname>Rinaldo</keyname><forenames>Alessandro</forenames></author></authors><title>Estimating Undirected Graphs Under Weak Assumptions</title><categories>math.ST cs.LG stat.ML stat.TH</categories><msc-class>62H12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of providing nonparametric confidence guarantees for
undirected graphs under weak assumptions. In particular, we do not assume
sparsity, incoherence or Normality. We allow the dimension $D$ to increase with
the sample size $n$. First, we prove lower bounds that show that if we want
accurate inferences with low assumptions then there are limitations on the
dimension as a function of sample size. When the dimension increases slowly
with sample size, we show that methods based on Normal approximations and on
the bootstrap lead to valid inferences and we provide Berry-Esseen bounds on
the accuracy of the Normal approximation. When the dimension is large relative
to sample size, accurate inferences for graphs under low assumptions are not
possible. Instead we propose to estimate something less demanding than the
entire partial correlation graph. In particular, we consider: cluster graphs,
restricted partial correlation graphs and correlation graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6947</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6947</id><created>2013-09-26</created><updated>2013-09-30</updated><authors><author><keyname>Lang</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA</affiliation></author><author><keyname>Mateescu</keyname><forenames>Radu</forenames><affiliation>INRIA</affiliation></author></authors><title>Partial Model Checking using Networks of Labelled Transition Systems and
  Boole an Equation Systems</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 4 (October 1,
  2013) lmcs:763</journal-ref><doi>10.2168/LMCS-9(4:1)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partial model checking was proposed by Andersen in 1995 to verify a temporal
logic formula compositionally on a composition of processes. It consists in
incrementally incorporating into the formula the behavioural information taken
from one process - an operation called quotienting - to obtain a new formula
that can be verified on a smaller composition from which the incorporated
process has been removed. Simplifications of the formula must be applied at
each step, so as to maintain the formula at a tractable size. In this paper, we
revisit partial model checking. First, we extend quotienting to the network of
labelled transition systems model, which subsumes most parallel composition
operators, including m-among-n synchronisation and parallel composition using
synchronisation interfaces, available in the ELOTOS standard. Second, we
reformulate quotienting in terms of a simple synchronous product between a
graph representation of the formula (called formula graph) and a process, thus
enabling quotienting to be implemented efficiently and easily, by reusing
existing tools dedicated to graph compositions. Third, we propose
simplifications of the formula as a combination of bisimulations and reductions
using Boolean equation systems applied directly to the formula graph, thus
enabling formula simplifications also to be implemented efficiently. Finally,
we describe an implementation in the CADP (Construction and Analysis of
Distributed Processes) toolbox and present some experimental results in which
partial model checking uses hundreds of times less memory than on-the-fly model
checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6964</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6964</id><created>2013-09-26</created><updated>2015-03-30</updated><authors><author><keyname>Kennedy</keyname><forenames>Ryan</forenames></author><author><keyname>Balzano</keyname><forenames>Laura</forenames></author><author><keyname>Wright</keyname><forenames>Stephen J.</forenames></author><author><keyname>Taylor</keyname><forenames>Camillo J.</forenames></author></authors><title>Online Algorithms for Factorization-Based Structure from Motion</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a family of online algorithms for real-time factorization-based
structure from motion, leveraging a relationship between incremental singular
value decomposition and recently proposed methods for online matrix completion.
Our methods are orders of magnitude faster than previous state of the art, can
handle missing data and a variable number of feature points, and are robust to
noise and sparse outliers. We demonstrate our methods on both real and
synthetic sequences and show that they perform well in both online and batch
settings. We also provide an implementation which is able to produce 3D models
in real time using a laptop with a webcam.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6978</identifier>
 <datestamp>2014-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6978</id><created>2013-09-26</created><updated>2014-07-10</updated><authors><author><keyname>Michail</keyname><forenames>Othon</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>Simple and Efficient Local Codes for Distributed Stable Network
  Construction</title><categories>cs.DC</categories><comments>43 pages, 7 figures</comments><acm-class>C.2.4; C.2.1; F.1.1; F.1.2; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study protocols so that populations of distributed processes
can construct networks. In order to highlight the basic principles of
distributed network construction we keep the model minimal in all respects. In
particular, we assume finite-state processes that all begin from the same
initial state and all execute the same protocol (i.e. the system is
homogeneous). Moreover, we assume pairwise interactions between the processes
that are scheduled by an adversary. The only constraint on the adversary
scheduler is that it must be fair. In order to allow processes to construct
networks, we let them activate and deactivate their pairwise connections. When
two processes interact, the protocol takes as input the states of the processes
and the state of the their connection and updates all of them. Initially all
connections are inactive and the goal is for the processes, after interacting
and activating/deactivating connections for a while, to end up with a desired
stable network. We give protocols (optimal in some cases) and lower bounds for
several basic network construction problems such as spanning line, spanning
ring, spanning star, and regular network. We provide proofs of correctness for
all of our protocols and analyze the expected time to convergence of most of
them under a uniform random scheduler that selects the next pair of interacting
processes uniformly at random from all such pairs. Finally, we prove several
universality results by presenting generic protocols that are capable of
simulating a Turing Machine (TM) and exploiting it in order to construct a
large class of networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.6989</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.6989</id><created>2013-09-26</created><authors><author><keyname>Zahedi</keyname><forenames>Keyan</forenames></author><author><keyname>Martius</keyname><forenames>Georg</forenames></author><author><keyname>Ay</keyname><forenames>Nihat</forenames></author></authors><title>Linear combination of one-step predictive information with an external
  reward in an episodic policy gradient setting: a critical analysis</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main challenges in the field of embodied artificial intelligence
is the open-ended autonomous learning of complex behaviours. Our approach is to
use task-independent, information-driven intrinsic motivation(s) to support
task-dependent learning. The work presented here is a preliminary step in which
we investigate the predictive information (the mutual information of the past
and future of the sensor stream) as an intrinsic drive, ideally supporting any
kind of task acquisition. Previous experiments have shown that the predictive
information (PI) is a good candidate to support autonomous, open-ended learning
of complex behaviours, because a maximisation of the PI corresponds to an
exploration of morphology- and environment-dependent behavioural regularities.
The idea is that these regularities can then be exploited in order to solve any
given task. Three different experiments are presented and their results lead to
the conclusion that the linear combination of the one-step PI with an external
reward function is not generally recommended in an episodic policy gradient
setting. Only for hard tasks a great speed-up can be achieved at the cost of an
asymptotic performance lost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7001</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7001</id><created>2013-09-26</created><updated>2013-09-26</updated><authors><author><keyname>Jamil</keyname><forenames>Noreen</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author><author><keyname>Muller</keyname><forenames>Johannes</forenames></author><author><keyname>Lutteroth</keyname><forenames>Christof</forenames></author><author><keyname>Weber</keyname><forenames>Gerald</forenames></author></authors><title>Kaczmarz Algorithm with Soft Constraints for User Interface Layout</title><categories>cs.NA math.NA</categories><msc-class>65J20, 47J06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kaczmarz method is an iterative method for solving large systems of
equations that projects iterates orthogonally onto the solution space of each
equation. In contrast to direct methods such as Gaussian elimination or
QR-factorization, this algorithm is efficient for problems with sparse
matrices, as they appear in constraint-based user interface (UI) layout
specifications. However, the Kaczmarz method as described in the literature has
its limitations: it considers only equality constraints and does not support
soft constraints, which makes it inapplicable to the UI layout problem.
  In this paper we extend the Kaczmarz method for solving specifications
containing soft constraints, using the prioritized IIS detection algorithm.
Furthermore, the performance and convergence of the proposed algorithms are
evaluated empirically using randomly generated UI layout specifications of
various sizes. The results show that these methods offer improvements in
performance over standard methods like Matlab's LINPROG, a well-known efficient
linear programming solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7004</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7004</id><created>2013-09-17</created><authors><author><keyname>Spirtes</keyname><forenames>Peter L.</forenames></author></authors><title>Calculation of Entailed Rank Constraints in Partially Non-Linear and
  Cyclic Models</title><categories>cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-606-615</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Trek Separation Theorem (Sullivant et al. 2010) states necessary and
sufficient conditions for a linear directed acyclic graphical model to entail
for all possible values of its linear coefficients that the rank of various
sub-matrices of the covariance matrix is less than or equal to n, for any given
n. In this paper, I extend the Trek Separation Theorem in two ways: I prove
that the same necessary and sufficient conditions apply even when the
generating model is partially non-linear and contains some cycles. This
justifies application of constraint-based causal search algorithms such as the
BuildPureClusters algorithm (Silva et al. 2006) for discovering the causal
structure of latent variable models to data generated by a wider class of
causal models that may contain non-linear and cyclic relations among the latent
variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7009</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7009</id><created>2013-09-26</created><authors><author><keyname>Banani</keyname><forenames>S. Alireza</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj</forenames></author></authors><title>Analyzing the Reduced Required BS Density due to CoMP in Cellular
  Networks</title><categories>cs.IT math.IT</categories><comments>Accepted for presentation in IEEE Globecom Conf., to be held in
  Atlanta, USA, Dec. 2013. arXiv admin note: text overlap with arXiv:1302.1592</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the benefit of base station (BS) cooperation in
the uplink of coordinated multi-point (CoMP) networks. Our figure of merit is
the required BS density required to meet a chosen rate coverage. Our model
assumes a 2-D network of BSs on a regular hexagonal lattice in which path loss,
lognormal shadowing and Rayleigh fading affect the signal received from users.
Accurate closed-form expressions are first presented for the sum-rate coverage
probability and ergodic sum-rate at each point of the cooperation region. Then,
for a chosen quality of user rate, the required density of BS is derived based
on the minimum value of rate coverage probability in the cooperation region.
The approach guarantees that the achievable rate in the entire coverage region
is above a target rate with chosen probability. The formulation allows
comparison between different orders of BS cooperation, quantifying the reduced
required BS density from higher orders of cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7031</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7031</id><created>2013-09-26</created><authors><author><keyname>Liu</keyname><forenames>Suyu</forenames></author><author><keyname>Perra</keyname><forenames>Nicola</forenames></author><author><keyname>Karsai</keyname><forenames>Marton</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>Controlling Contagion Processes in Time-Varying Networks</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><doi>10.1103/PhysRevLett.112.118702</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast majority of strategies aimed at controlling contagion processes on
networks considers the connectivity pattern of the system as either quenched or
annealed. However, in the real world many networks are highly dynamical and
evolve in time concurrently to the contagion process. Here, we derive an
analytical framework for the study of control strategies specifically devised
for time-varying networks. We consider the removal/immunization of individual
nodes according the their activity in the network and develop a block variable
mean-field approach that allows the derivation of the equations describing the
evolution of the contagion process concurrently to the network dynamic. We
derive the critical immunization threshold and assess the effectiveness of the
control strategies. Finally, we validate the theoretical picture by simulating
numerically the information spreading process and control strategies in both
synthetic networks and a large-scale, real-world mobile telephone call dataset
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7063</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7063</id><created>2013-09-26</created><authors><author><keyname>Maan</keyname><forenames>Jitendra</forenames></author></authors><title>Social Business Transformation through Gamification</title><categories>cs.CY</categories><comments>8 pages, 6 figures</comments><doi>10.5121/ijmit.2013.5302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Being an emerging business practice, gamification is going to the mainstream
to enable and transform social business initiatives across enterprises. With
the consistent focus on customer behavior and experience, there is a paradigm
shift in thinking about how Gamification and Social initiatives together help
to increase the engagement level of knowledge worker, yielding better business
results. Business scenarios for gamification are wide spread ranging from
customer service and support to communities and collaboration.
  The Paper discusses the characteristics &amp; mechanism to learn from games that
are important for businesses to understand and apply. It also gives insights on
gamification trends, real-world business challenges and also describes on how
game thinking can revolutionize the business and create an engaging experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7066</identifier>
 <datestamp>2014-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7066</id><created>2013-09-26</created><updated>2014-02-12</updated><authors><author><keyname>Singla</keyname><forenames>Ankit</forenames></author><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author><author><keyname>Kolla</keyname><forenames>Alexandra</forenames></author></authors><title>High Throughput Data Center Topology Design</title><categories>cs.NI</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With high throughput networks acquiring a crucial role in supporting
data-intensive applications, a variety of data center network topologies have
been proposed to achieve high capacity at low cost. While this literature
explores a large number of design points, even in the limited case of a network
of identical switches, no proposal has been able to claim any notion of
optimality. The case of heterogeneous networks, incorporating multiple
line-speeds and port-counts as data centers grow over time, introduces even
greater complexity.
  In this paper, we present the first non-trivial upper-bound on network
throughput under uniform traffic patterns for any topology with identical
switches. We then show that random graphs achieve throughput surprisingly close
to this bound, within a few percent at the scale of a few thousand servers.
Apart from demonstrating that homogeneous topology design may be reaching its
limits, this result also motivates our use of random graphs as building blocks
to explore the design of heterogeneous networks. Given a heterogeneous pool of
network switches, through experiments and analysis, we explore how the
distribution of servers across switches and the interconnection of switches
affect network throughput. We apply these insights to a real-world
heterogeneous data center topology, VL2, demonstrating as much as 43% higher
throughput with the same equipment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7068</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7068</id><created>2013-09-25</created><updated>2014-06-15</updated><authors><author><keyname>Jouneghani</keyname><forenames>Farzad Ghafari</forenames></author><author><keyname>Babazadeh</keyname><forenames>Mohammad</forenames></author><author><keyname>Bayramzadeh</keyname><forenames>Rogayeh</forenames></author><author><keyname>Movla</keyname><forenames>Hossein</forenames></author></authors><title>Investigation of commuting Hamiltonian in quantum Markov network</title><categories>cs.AI quant-ph</categories><comments>11 pages, 8 figures</comments><journal-ref>IJTP, V 53, I 8, August 2014, P 2521-2530</journal-ref><doi>10.1007/s10773-014-2042-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical Models have various applications in science and engineering which
include physics, bioinformatics, telecommunication and etc. Usage of graphical
models needs complex computations in order to evaluation of marginal
functions,so there are some powerful methods including mean field
approximation, belief propagation algorithm and etc. Quantum graphical models
have been recently developed in context of quantum information and computation,
and quantum statistical physics, which is possible by generalization of
classical probability theory to quantum theory. The main goal of this paper is
preparing a primary generalization of Markov network, as a type of graphical
models, to quantum case and applying in quantum statistical physics.We have
investigated the Markov network and the role of commuting Hamiltonian terms in
conditional independence with simple examples of quantum statistical physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7082</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7082</id><created>2013-09-26</created><authors><author><keyname>Mittal</keyname><forenames>Sparsh</forenames></author></authors><title>A Cache Reconfiguration Approach for Saving Leakage and Refresh Energy
  in Embedded DRAM Caches</title><categories>cs.AR</categories><comments>Embedded DRAM (eDRAM) caches</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the size and leakage energy consumption of large last level
caches (LLCs) has increased. To address this, embedded DRAM (eDRAM) caches have
been considered which have lower leakage energy consumption; however eDRAM
caches consume a significant amount of energy in the form of refresh energy. In
this paper, we present a technique for saving both leakage and refresh energy
in eDRAM caches. We use dynamic cache reconfiguration approach to intelligently
turn-off part of the cache to save leakage energy and refresh only valid data
of the active (i.e. not turned-off) cache to save refresh energy. We evaluate
our technique using an x86-64 simulator and SPEC2006 benchmarks and compare it
with a recently proposed technique for saving refresh energy, named Refrint.
The experiments have shown that our technique provides better performance and
energy efficiency than Refrint. Using our technique, for a 2MB LLC and 40
micro-seconds eDRAM refresh period, the average saving in energy over eDRAM
baseline (which periodically refreshes all cache lines) is 22.8%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7084</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7084</id><created>2013-09-26</created><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Yannakakis</keyname><forenames>Mihalis</forenames></author></authors><title>How good is the Chord algorithm?</title><categories>cs.DS cs.CG</categories><comments>47 pages, full version of SODA 2010 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Chord algorithm is a popular, simple method for the succinct
approximation of curves, which is widely used, under different names, in a
variety of areas, such as, multiobjective and parametric optimization,
computational geometry, and graphics. We analyze the performance of the Chord
algorithm, as compared to the optimal approximation that achieves a desired
accuracy with the minimum number of points. We prove sharp upper and lower
bounds, both in the worst case and average case setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7099</identifier>
 <datestamp>2013-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7099</id><created>2013-09-26</created><authors><author><keyname>Docampo</keyname><forenames>Domingo</forenames></author><author><keyname>Cram</keyname><forenames>Lawrence</forenames></author></authors><title>On the Internal Dynamics of the Shanghai Ranking</title><categories>cs.DL</categories><msc-class>68P20</msc-class><acm-class>H.1.1; H.2.8; H.3.1</acm-class><doi>10.1007/s11192-013-1143-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Academic Ranking of World Universities (ARWU) published by researchers at
Shanghai Jiao Tong University has become a major source of information for
university administrators, country officials, students and the public at large.
Recent discoveries regarding its internal dynamics allow the inversion of
published ARWU indicator scores to reconstruct raw scores for five hundred
world class universities. This paper explores raw scores in the ARWU and in
other contests to contrast the dynamics of rank-driven and score-driven tables,
and to explain why the ARWU ranking is a score-driven procedure. We show that
the ARWU indicators constitute sub-scales of a single factor accounting for
research performance, and provide an account of the system of gains and
non-linearities used by ARWU. The paper discusses the non-linearities selected
by ARWU, concluding that they are designed to represent the regressive
character of indicators measuring research performance. We propose that the
utility and usability of the ARWU could be greatly improved by replacing the
unwanted dynamical effects of the annual re-scaling based on raw scores of the
best performers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7102</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7102</id><created>2013-09-26</created><authors><author><keyname>Noor-A-Rahim</keyname><forenames>Md.</forenames></author><author><keyname>Nguyen</keyname><forenames>Khoa D.</forenames></author><author><keyname>Lechner</keyname><forenames>Gottfried</forenames></author></authors><title>Finite Length Analysis of LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to WCNC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the performance of finite-length LDPC codes in the
waterfall region. We propose an algorithm to predict the error performance of
finite-length LDPC codes over various binary memoryless channels. Through
numerical results, we find that our technique gives better performance
prediction compared to existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7109</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7109</id><created>2013-09-26</created><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Nock</keyname><forenames>Richard</forenames></author></authors><title>Total Jensen divergences: Definition, Properties and k-Means++
  Clustering</title><categories>cs.IT math.IT</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel class of divergences induced by a smooth convex function
called total Jensen divergences. Those total Jensen divergences are invariant
by construction to rotations, a feature yielding regularization of ordinary
Jensen divergences by a conformal factor. We analyze the relationships between
this novel class of total Jensen divergences and the recently introduced total
Bregman divergences. We then proceed by defining the total Jensen centroids as
average distortion minimizers, and study their robustness performance to
outliers. Finally, we prove that the k-means++ initialization that bypasses
explicit centroid computations is good enough in practice to guarantee
probabilistically a constant approximation factor to the optimal k-means
clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7119</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7119</id><created>2013-09-27</created><authors><author><keyname>Wang</keyname><forenames>Yanshan</forenames></author><author><keyname>Choi</keyname><forenames>In-Chan</forenames></author></authors><title>Market Index and Stock Price Direction Prediction using Machine Learning
  Techniques: An empirical study on the KOSPI and HSI</title><categories>cs.CE cs.LG q-fin.ST</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prediction of a stock market direction may serve as an early
recommendation system for short-term investors and as an early financial
distress warning system for long-term shareholders. In this paper, we propose
an empirical study on the Korean and Hong Kong stock market with an integrated
machine learning framework that employs Principal Component Analysis (PCA) and
Support Vector Machine (SVM). We try to predict the upward or downward
direction of stock market index and stock price. In the proposed framework,
PCA, as a feature selection method, identifies principal components in the
stock market movement and SVM, as a classifier for future stock market
movement, processes them along with other economic factors in training and
forecasting. We present the results of an extensive empirical study of the
proposed method on the Korean composite stock price index (KOSPI) and Hangseng
index (HSI), as well as the individual constituents included in the indices. In
our experiment, ten years data (from January 1st, 2002 to January 1st, 2012)
are collected and schemed by rolling windows to predict one-day-ahead
directions. The experimental results show notably high hit ratios in predicting
the movements of the individual constituents in the KOSPI and HSI. The results
also varify the \textit{co-movement} effect between the Korean (Hong Kong)
stock market and the American stock market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7122</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7122</id><created>2013-09-27</created><authors><author><keyname>Graudenzi</keyname><forenames>Alex</forenames><affiliation>Dept. of Informatics, Systems and Communication, University of Milan Bicocca</affiliation></author><author><keyname>Caravagna</keyname><forenames>Giulio</forenames><affiliation>Dept. of Informatics, Systems and Communication, University of Milan Bicocca</affiliation></author><author><keyname>Mauri</keyname><forenames>Giancarlo</forenames><affiliation>Dept. of Informatics, Systems and Communication, University of Milan Bicocca</affiliation></author><author><keyname>Antoniotti</keyname><forenames>Marco</forenames><affiliation>Dept. of Informatics, Systems and Communication, University of Milan Bicocca</affiliation></author></authors><title>Proceedings Wivace 2013 - Italian Workshop on Artificial Life and
  Evolutionary Computation</title><categories>cs.CE cs.NE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013</journal-ref><doi>10.4204/EPTCS.130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Wivace 2013 Electronic Proceedings in Theoretical Computer Science
(EPTCS) contain some selected long and short articles accepted for the
presentation at Wivace 2013 - Italian Workshop on Artificial Life and
Evolutionary Computation, which was held at the University of Milan-Bicocca,
Milan, on the 1st and 2nd of July, 2013.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7140</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7140</id><created>2013-09-27</created><authors><author><keyname>Felicetti</keyname><forenames>Luca</forenames></author><author><keyname>Femminella</keyname><forenames>Mauro</forenames></author><author><keyname>Reali</keyname><forenames>Gianluca</forenames></author></authors><title>Establishing digital molecular communications in blood vessels</title><categories>cs.NI</categories><comments>First International Black Sea Conference on Communications and
  Networking (BlackSeaCom 2013), Batumi, Georgia, July 3-5, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a solution for transmitting digital information
within the cardiocirculatory system. In particular, we make use of a channel
delivering burst of molecules, emitted by mobile transmitters, which diffuse in
the blood towards fixed receivers, that are attached to the vessel walls. This
communication scheme has been inspired by the real signaling between platelets
and endothelial cells, the behavior of which has been investigated
experimentally. We thus believe that our proposal can be successfully deployed
in living bodies. On the basis of the results achieved through simulations on
the communication system capabilities, we propose a simple but effective
receiver scheme, and we outline the future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7141</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7141</id><created>2013-09-27</created><authors><author><keyname>Belghiti</keyname><forenames>Ismael</forenames></author><author><keyname>Habib</keyname><forenames>Michel</forenames></author></authors><title>A general method for common intervals</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an elementary chain of vertex set V, seen as a labelling of V by the
set {1, ...,n=|V|}, and another discrete structure over $V$, say a graph G, the
problem of common intervals is to compute the induced subgraphs G[I], such that
$I$ is an interval of [1, n] and G[I] satisfies some property Pi (as for
example Pi= &quot;being connected&quot;). This kind of problems comes from comparative
genomic in bioinformatics, mainly when the graph $G$ is a chain or a tree
(Heber and Stoye 2001, Heber and Savage 2005, Bergeron et al 2008).
  When the family of intervals is closed under intersection, we present here
the combination of two approaches, namely the idea of potential beginning
developed in Uno, Yagiura 2000 and Bui-Xuan et al 2005 and the notion of
generator as defined in Bergeron et al 2008. This yields a very simple generic
algorithm to compute all common intervals, which gives optimal algorithms in
various applications. For example in the case where $G$ is a tree, our
framework yields the first linear time algorithms for the two properties:
&quot;being connected&quot; and &quot;being a path&quot;. In the case where $G$ is a chain, the
problem is known as: common intervals of two permutations (Uno and Yagiura
2000), our algorithm provides not only the set of all common intervals but also
with some easy modifications a tree structure that represents this set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7145</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7145</id><created>2013-09-27</created><authors><author><keyname>Beldiceanu</keyname><forenames>Nicolas</forenames></author><author><keyname>Flener</keyname><forenames>Pierre</forenames></author><author><keyname>Pearson</keyname><forenames>Justin</forenames></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames></author></authors><title>Propagating Regular Counting Constraints</title><categories>cs.AI cs.FL</categories><comments>Includes a SICStus Prolog source file with the propagator</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraints over finite sequences of variables are ubiquitous in sequencing
and timetabling. Moreover, the wide variety of such constraints in practical
applications led to general modelling techniques and generic propagation
algorithms, often based on deterministic finite automata (DFA) and their
extensions. We consider counter-DFAs (cDFA), which provide concise models for
regular counting constraints, that is constraints over the number of times a
regular-language pattern occurs in a sequence. We show how to enforce domain
consistency in polynomial time for atmost and atleast regular counting
constraints based on the frequent case of a cDFA with only accepting states and
a single counter that can be incremented by transitions. We also prove that the
satisfaction of exact regular counting constraints is NP-hard and indicate that
an incomplete algorithm for exact regular counting constraints is faster and
provides more pruning than the existing propagator from [3]. Regular counting
constraints are closely related to the CostRegular constraint but contribute
both a natural abstraction and some computational advantages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7163</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7163</id><created>2013-09-27</created><authors><author><keyname>Saha</keyname><forenames>Dipankar</forenames></author><author><keyname>Basak</keyname><forenames>Subhramita</forenames></author><author><keyname>Mukherjee</keyname><forenames>Sagar</forenames></author><author><keyname>Sarkar</keyname><forenames>C. K.</forenames></author></authors><title>A Low-Voltage, Low-Power 4-bit BCD Adder, designed using the Clock Gated
  Power Gating, and the DVT Scheme</title><categories>cs.AR</categories><comments>To appear in the proceedings of 2013 IEEE International Conference on
  Signal Processing, Computing and Control (ISPCC,13)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a Low-Power, Energy Efficient 4-bit Binary Coded Decimal
(BCD) adder design where the conventional 4-bit BCD adder has been modified
with the Clock Gated Power Gating Technique. Moreover, the concept of DVT
(Dual-vth) scheme has been introduced while designing the full adder blocks to
reduce the Leakage Power, as well as, to maintain the overall performance of
the entire circuit. The reported architecture of 4-bit BCD adder is designed
using 45 nm technology and it consumes 1.384 {\mu}Watt of Average Power while
operating with a frequency of 200 MHz, and a Supply Voltage (Vdd) of 1 Volt.
The results obtained from different simulation runs on SPICE, indicate the
superiority of the proposed design compared to the conventional 4-bit BCD
adder. Considering the product of Average Power and Delay, for the operating
frequency of 200 MHz, a fair 47.41 % reduction compared to the conventional
design has been achieved with this proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7170</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7170</id><created>2013-09-27</created><authors><author><keyname>Hajebi</keyname><forenames>Kiana</forenames></author><author><keyname>Zhang</keyname><forenames>Hong</forenames></author></authors><title>An Efficient Index for Visual Search in Appearance-based SLAM</title><categories>cs.CV cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vector-quantization can be a computationally expensive step in visual
bag-of-words (BoW) search when the vocabulary is large. A BoW-based appearance
SLAM needs to tackle this problem for an efficient real-time operation. We
propose an effective method to speed up the vector-quantization process in
BoW-based visual SLAM. We employ a graph-based nearest neighbor search (GNNS)
algorithm to this aim, and experimentally show that it can outperform the
state-of-the-art. The graph-based search structure used in GNNS can efficiently
be integrated into the BoW model and the SLAM framework. The graph-based index,
which is a k-NN graph, is built over the vocabulary words and can be extracted
from the BoW's vocabulary construction procedure, by adding one iteration to
the k-means clustering, which adds small extra cost. Moreover, exploiting the
fact that images acquired for appearance-based SLAM are sequential, GNNS search
can be initiated judiciously which helps increase the speedup of the
quantization process considerably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7173</identifier>
 <datestamp>2014-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7173</id><created>2013-09-27</created><updated>2013-12-25</updated><authors><author><keyname>Manchanda</keyname><forenames>Priyanka</forenames></author></authors><title>Analysis of Optimization Techniques to Improve User Response Time of Web
  Applications and Their Implementation for MOODLE</title><categories>cs.AI cs.PF</categories><comments>The original final publication will be available at
  http://www.springerlink.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of seven optimization techniques grouped under three categories
(hardware, back-end, and front-end) is done to study the reduction in average
user response time for Modular Object Oriented Dynamic Learning Environment
(Moodle), a Learning Management System which is scripted in PHP5, runs on
Apache web server and utilizes MySQL database software. Before the
implementation of these techniques, performance analysis of Moodle is performed
for varying number of concurrent users. The results obtained for each
optimization technique are then reported in a tabular format. The maximum
reduction in end user response time was achieved for hardware optimization
which requires Moodle server and database to be installed on solid state disk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7187</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7187</id><created>2013-09-27</created><authors><author><keyname>Lumbreras</keyname><forenames>Alberto</forenames></author><author><keyname>Lanagan</keyname><forenames>James</forenames></author><author><keyname>Velcin</keyname><forenames>Julien</forenames></author><author><keyname>Jouve</keyname><forenames>Bertrand</forenames></author></authors><title>Analyse des r\^oles dans les communaut\'es virtuelles : d\'efinitions et
  premi\`eres exp\'erimentations sur IMDb</title><categories>cs.SI</categories><comments>MARAMI 2013</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Role analysis in online communities allows us to understand and predict users
behavior. Though several approaches have been followed, there is still lack of
generalization of their methods and their results. In this paper, we discuss
about the ground theory of roles and search for a consistent and computable
definition that allows the automatic detection of roles played by users in
forum threads on the internet. We analyze the web site IMDb to illustrate the
discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7198</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7198</id><created>2013-09-27</created><authors><author><keyname>Fagerberg</keyname><forenames>Rolf</forenames></author><author><keyname>Flamm</keyname><forenames>Christoph</forenames></author><author><keyname>Merkle</keyname><forenames>Daniel</forenames></author><author><keyname>Peters</keyname><forenames>Philipp</forenames></author><author><keyname>Stadler</keyname><forenames>Peter F.</forenames></author></authors><title>On the Complexity of Reconstructing Chemical Reaction Networks</title><categories>cs.CC q-bio.MN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of the structure of chemical reaction networks is crucial for a
better understanding of chemical processes. Such networks are well described as
hypergraphs. However, due to the available methods, analyses regarding network
properties are typically made on standard graphs derived from the full
hypergraph description, e.g.\ on the so-called species and reaction graphs.
However, a reconstruction of the underlying hypergraph from these graphs is not
necessarily unique. In this paper, we address the problem of reconstructing a
hypergraph from its species and reaction graph and show NP-completeness of the
problem in its Boolean formulation. Furthermore we study the problem
empirically on random and real world instances in order to investigate its
computational limits in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7233</identifier>
 <datestamp>2014-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7233</id><created>2013-09-27</created><updated>2014-03-03</updated><authors><author><keyname>Kivel&#xe4;</keyname><forenames>Mikko</forenames></author><author><keyname>Arenas</keyname><forenames>Alexandre</forenames></author><author><keyname>Barthelemy</keyname><forenames>Marc</forenames></author><author><keyname>Gleeson</keyname><forenames>James P.</forenames></author><author><keyname>Moreno</keyname><forenames>Yamir</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author></authors><title>Multilayer Networks</title><categories>physics.soc-ph cs.SI</categories><comments>Working paper; 59 pages, 8 figures</comments><journal-ref>J. Complex Netw. 2(3): 203-271 (2014)</journal-ref><doi>10.1093/comnet/cnu016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most natural and engineered systems, a set of entities interact with each
other in complicated patterns that can encompass multiple types of
relationships, change in time, and include other types of complications. Such
systems include multiple subsystems and layers of connectivity, and it is
important to take such &quot;multilayer&quot; features into account to try to improve our
understanding of complex systems. Consequently, it is necessary to generalize
&quot;traditional&quot; network theory by developing (and validating) a framework and
associated tools to study multilayer systems in a comprehensive fashion. The
origins of such efforts date back several decades and arose in multiple
disciplines, and now the study of multilayer networks has become one of the
most important directions in network science. In this paper, we discuss the
history of multilayer networks (and related concepts) and review the exploding
body of work on such networks. To unify the disparate terminology in the large
body of recent work, we discuss a general framework for multilayer networks,
construct a dictionary of terminology to relate the numerous existing concepts
to each other, and provide a thorough discussion that compares, contrasts, and
translates between related notions such as multilayer networks, multiplex
networks, interdependent networks, networks of networks, and many others. We
also survey and discuss existing data sets that can be represented as
multilayer networks. We review attempts to generalize single-layer-network
diagnostics to multilayer networks. We also discuss the rapidly expanding
research on multilayer-network models and notions like community structure,
connected components, tensor decompositions, and various types of dynamical
processes on multilayer networks. We conclude with a summary and an outlook.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7258</identifier>
 <datestamp>2014-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7258</id><created>2013-09-27</created><updated>2014-03-21</updated><authors><author><keyname>Anbalagan</keyname><forenames>Yogesh</forenames></author><author><keyname>Norin</keyname><forenames>Sergey</forenames></author><author><keyname>Savani</keyname><forenames>Rahul</forenames></author><author><keyname>Vetta</keyname><forenames>Adrian</forenames></author></authors><title>Polylogarithmic Supports are required for Approximate Well-Supported
  Nash Equilibria below 2/3</title><categories>cs.GT</categories><comments>Added details on related work (footnote 7 expanded)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an epsilon-approximate Nash equilibrium, a player can gain at most epsilon
in expectation by unilateral deviation. An epsilon well-supported approximate
Nash equilibrium has the stronger requirement that every pure strategy used
with positive probability must have payoff within epsilon of the best response
payoff. Daskalakis, Mehta and Papadimitriou conjectured that every win-lose
bimatrix game has a 2/3-well-supported Nash equilibrium that uses supports of
cardinality at most three. Indeed, they showed that such an equilibrium will
exist subject to the correctness of a graph-theoretic conjecture. Regardless of
the correctness of this conjecture, we show that the barrier of a 2/3 payoff
guarantee cannot be broken with constant size supports; we construct win-lose
games that require supports of cardinality at least Omega((log n)^(1/3)) in any
epsilon-well supported equilibrium with epsilon &lt; 2/3. The key tool in showing
the validity of the construction is a proof of a bipartite digraph variant of
the well-known Caccetta-Haggkvist conjecture. A probabilistic argument shows
that there exist epsilon-well-supported equilibria with supports of cardinality
O(log n/(epsilon^2)), for any epsilon&gt; 0; thus, the polylogarithmic cardinality
bound presented cannot be greatly improved. We also show that for any delta &gt;
0, there exist win-lose games for which no pair of strategies with support
sizes at most two is a (1-delta)-well-supported Nash equilibrium. In contrast,
every bimatrix game with payoffs in [0,1] has a 1/2-approximate Nash
equilibrium where the supports of the players have cardinality at most two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7261</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7261</id><created>2013-09-27</created><authors><author><keyname>Abbasi</keyname><forenames>Ahmed</forenames></author><author><keyname>Chen</keyname><forenames>Hsinchun</forenames></author></authors><title>Detecting Fake Escrow Websites using Rich Fraud Cues and Kernel Based
  Methods</title><categories>cs.CY cs.LG</categories><journal-ref>Abbasi, A. and Chen, H. &quot;Detecting Fake Escrow Websites using Rich
  Fraud Cues and Kernel Based Methods,&quot; In Proceedings of the 17th Annual
  Workshop on Information Technologies and Systems, Montreal, Canada, December
  8-9, 2007, pp. 55-60</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to automatically detect fraudulent escrow websites is important
in order to alleviate online auction fraud. Despite research on related topics,
fake escrow website categorization has received little attention. In this study
we evaluated the effectiveness of various features and techniques for detecting
fake escrow websites. Our analysis included a rich set of features extracted
from web page text, image, and link information. We also proposed a composite
kernel tailored to represent the properties of fake websites, including content
duplication and structural attributes. Experiments were conducted to assess the
proposed features, techniques, and kernels on a test bed encompassing nearly
90,000 web pages derived from 410 legitimate and fake escrow sites. The
combination of an extended feature set and the composite kernel attained over
98% accuracy when differentiating fake sites from real ones, using the support
vector machines algorithm. The results suggest that automated web-based
information systems for detecting fake escrow sites could be feasible and may
be utilized as authentication mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7262</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7262</id><created>2013-09-27</created><authors><author><keyname>Zahedi</keyname><forenames>F. Mariam</forenames></author><author><keyname>Abbasi</keyname><forenames>Ahmed</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author></authors><title>Design Elements that Promote the use of Fake Website Detection Tools</title><categories>cs.CY</categories><comments>Zahedi, F. M., Abbasi, A., and Chen, Y. &quot;Design Elements that Promote
  the use of Fake Website Detection Tools,&quot; In Proceedings of the 10th Annual
  AIS SIG-HCI Workshop, Shanghai, China, December 4, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fake websites have emerged as a major source of online fraud, accounting for
billions of dollars of loss by Internet users. We explore the process by which
salient design elements could increase the use of protective tools, thus
reducing the success rate of fake websites. Using the protection motivation
theory, we conceptualize a model to investigate how salient design elements of
detection tools could influence user perceptions of the tools, efficacy in
dealing with threats, and use of such tools. The research method was a
controlled lab experiment with a novel and extensive experimental design and
protocol. We found that trust in the detector is the pivotal coping mechanism
in dealing with security threats and is a major conduit for transforming
salient design elements into increased use. We also found that design elements
have profound and unexpected impacts on self-efficacy. The significant
theoretical and empirical implications of findings are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7266</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7266</id><created>2013-09-27</created><authors><author><keyname>Abbasi</keyname><forenames>Ahmed</forenames></author><author><keyname>Kaza</keyname><forenames>Siddharth</forenames></author><author><keyname>Zahedi</keyname><forenames>F. Mariam</forenames></author></authors><title>Evaluating Link-Based Techniques for Detecting Fake Pharmacy Websites</title><categories>cs.CY cs.LG</categories><comments>Abbasi, A., Kaza, S., and Zahedi, F. M. &quot;Evaluating Link-Based
  Techniques for Detecting Fake Pharmacy Websites,&quot; In Proceedings of the 19th
  Annual Workshop on Information Technologies and Systems, Phoenix, Arizona,
  December 14-15, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fake online pharmacies have become increasingly pervasive, constituting over
90% of online pharmacy websites. There is a need for fake website detection
techniques capable of identifying fake online pharmacy websites with a high
degree of accuracy. In this study, we compared several well-known link-based
detection techniques on a large-scale test bed with the hyperlink graph
encompassing over 80 million links between 15.5 million web pages, including
1.2 million known legitimate and fake pharmacy pages. We found that the QoC and
QoL class propagation algorithms achieved an accuracy of over 90% on our
dataset. The results revealed that algorithms that incorporate dual class
propagation as well as inlink and outlink information, on page-level or
site-level graphs, are better suited for detecting fake pharmacy websites. In
addition, site-level analysis yielded significantly better results than
page-level analysis for most algorithms evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7270</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7270</id><created>2013-09-27</created><authors><author><keyname>Fu</keyname><forenames>Tianjun</forenames></author><author><keyname>Abbasi</keyname><forenames>Ahmed</forenames></author><author><keyname>Zeng</keyname><forenames>Daniel</forenames></author><author><keyname>Chen</keyname><forenames>Hsinchun</forenames></author></authors><title>Evaluating the Usefulness of Sentiment Information for Focused Crawlers</title><categories>cs.IR cs.CL</categories><comments>Fu, T., Abbasi, A., Zeng, D., and Chen, H. &quot;Evaluating the Usefulness
  of Sentiment Information for Focused Crawlers,&quot; In Proceedings of the 20th
  Annual Workshop on Information Technologies and Systems, St. Louis, MO,
  December 11-12, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the prevalence of sentiment-related content on the Web, there has
been limited work on focused crawlers capable of effectively collecting such
content. In this study, we evaluated the efficacy of using sentiment-related
information for enhanced focused crawling of opinion-rich web content regarding
a particular topic. We also assessed the impact of using sentiment-labeled web
graphs to further improve collection accuracy. Experimental results on a large
test bed encompassing over half a million web pages revealed that focused
crawlers utilizing sentiment information as well as sentiment-labeled web
graphs are capable of gathering more holistic collections of opinion-related
content regarding a particular topic. The results have important implications
for business and marketing intelligence gathering efforts in the Web 2.0 era.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7276</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7276</id><created>2013-09-26</created><authors><author><keyname>T.</keyname><forenames>Bijeesh</forenames><suffix>V</suffix></author><author><keyname>P</keyname><forenames>Nimmi I.</forenames></author></authors><title>Adopting level set theory based algorithms to segment human ear</title><categories>cs.CV</categories><comments>15 pages</comments><doi>10.5121/ijci.2013.2407</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human identification has always been a topic that interested researchers
around the world. Biometric methods are found to be more effective and much
easier for the users than the traditional identification methods like keys,
smart cards and passwords. Unlike with the traditional methods, with biometric
methods the data acquisition is most of the times passive, which means the
users do not take active part in data acquisition. Data acquisition can be
performed using cameras, scanners or sensors. Human physiological biometrics
such as face, eye and ear are good candidates for uniquely identifying an
individual. However, human ear scores over face and eye because of certain
advantages it has over face. The most challenging phase in human identification
based on ear biometric is the segmentation of the ear image from the captured
image which may contain many unwanted details. In this work, PDE based image
processing techniques are used to segment out the ear image. Level Set Theory
based image processing is employed to obtain the contour of the ear image. A
few Level set algorithms are compared for their efficiency in segmenting test
ear images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7287</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7287</id><created>2013-09-27</created><updated>2014-02-11</updated><authors><author><keyname>Kant</keyname><forenames>Philipp</forenames></author></authors><title>Finding Linear Dependencies in Integration-By-Parts Equations: A Monte
  Carlo Approach</title><categories>hep-ph cs.SC physics.comp-ph</categories><comments>8 pages, 1 figure. Added references. Some minor additions</comments><report-no>HU-EP-13/49, SFB/CPP-13-68</report-no><acm-class>J.2</acm-class><doi>10.1016/j.cpc.2014.01.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reduction of a large number of scalar integrals to a small set of master
integrals via Laporta's algorithm is common practice in multi-loop
calculations. It is also a major bottleneck in terms of running time and memory
consumption. It involves solving a large set of linear equations where many of
the equations are linearly dependent. We propose a simple algorithm that
eliminates all linearly dependent equations from a given system, reducing the
time and space requirements of a subsequent run of Laporta's algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7288</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7288</id><created>2013-09-27</created><authors><author><keyname>Zaitsev</keyname><forenames>Dmitry A.</forenames></author></authors><title>Small Polynomial Time Universal Petri Nets</title><categories>cs.CC</categories><comments>arXiv admin note: text overlap with arXiv:1309.1274</comments><acm-class>F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The time complexity of the presented in 2013 by the author small universal
Petri nets with the pairs of places/transitions numbers (14,42) and (14,29) was
estimated as exponential. In the present paper, it is shown, that their slight
modification and interpretation as timed Petri nets with multichannel
transitions, introduced by the author in 1991, allows obtaining polynomial time
complexity. The modification concerns using only inhibitor arcs to control
transitions' firing in multiple instances and employing an inverse control flow
represented by moving zero. Thus, small universal Petri nets are efficient that
justifies their application as models of high performance computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7289</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7289</id><created>2013-09-27</created><authors><author><keyname>Sotoodeh</keyname><forenames>Hamidreza</forenames></author><author><keyname>Safaei</keyname><forenames>Farshad</forenames></author><author><keyname>Sanei</keyname><forenames>Arghavan</forenames></author><author><keyname>Daei</keyname><forenames>Elahe</forenames></author></authors><title>A General Stochastic Information Diffusion Model in Social Networks
  based on Epidemic Diseases</title><categories>cs.SI physics.soc-ph</categories><doi>10.5121/ijcnc.2013.5512</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Social networks are an important infrastructure for information, viruses and
innovations propagation. Since users behavior has influenced by other users
activity, some groups of people would be made regard to similarity of users
interests. On the other hand, dealing with many events in real worlds, can be
justified in social networks; spreading disease is one instance of them. People
manner and infection severity are more important parameters in dissemination of
diseases. Both of these reasons derive, whether the diffusion leads to an
epidemic or not. SIRS is a hybrid model of SIR and SIS disease models to spread
contamination. A person in this model can be returned to susceptible state
after it removed. According to communities which are established on the social
network, we use the compartmental type of SIRS model. During this paper, a
general compartmental information diffusion model would be proposed and
extracted some of the beneficial parameters to analyze our model. To adapt our
model to realistic behaviors, we use Markovian model, which would be helpful to
create a stochastic manner of the proposed model. In the case of random model,
we can calculate probabilities of transaction between states and predicting
value of each state. The comparison between two mode of the model shows that,
the prediction of population would be verified in each state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7298</identifier>
 <datestamp>2015-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7298</id><created>2013-09-27</created><updated>2015-02-06</updated><authors><author><keyname>Giryes</keyname><forenames>Raja</forenames></author></authors><title>A Greedy Algorithm for the Analysis Transform Domain</title><categories>math.NA cs.IT math.IT</categories><comments>33 Pages</comments><msc-class>41A46, 68Q25, 68W25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many image processing applications benefited remarkably from the theory of
sparsity. One model of sparsity is the cosparse analysis one. It was shown that
using l_1-minimization one might stably recover a cosparse signal from a small
set of random linear measurements if the operator is a frame. Another effort
has provided guarantees for dictionaries that have a near optimal projection
procedure using greedy-like algorithms. However, no claims have been given for
frames. A common drawback of all these existing techniques is their high
computational cost for large dimensional problems.
  In this work we propose a new greedy-like technique with theoretical recovery
guarantees for frames as the analysis operator, closing the gap between greedy
and relaxation techniques. Our results cover both the case of bounded
adversarial noise, where we show that the algorithm provides us with a stable
reconstruction, and the one of random Gaussian noise, for which we prove that
it has a denoising effect, closing another gap in the analysis framework. Our
proposed program, unlike the previous greedy-like ones that solely act in the
signal domain, operates mainly in the analysis operator's transform domain.
Besides the theoretical benefit, the main advantage of this strategy is its
computational efficiency that makes it easily applicable to visually big data.
We demonstrate its performance on several high dimensional images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7311</identifier>
 <datestamp>2014-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7311</id><created>2013-09-27</created><authors><author><keyname>Orchard</keyname><forenames>Peter</forenames></author><author><keyname>Agakov</keyname><forenames>Felix</forenames></author><author><keyname>Storkey</keyname><forenames>Amos</forenames></author></authors><title>Bayesian Inference in Sparse Gaussian Graphical Models</title><categories>stat.ML cs.LG</categories><doi>10.1017/S0956796814000057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental tasks of science is to find explainable relationships
between observed phenomena. One approach to this task that has received
attention in recent years is based on probabilistic graphical modelling with
sparsity constraints on model structures. In this paper, we describe two new
approaches to Bayesian inference of sparse structures of Gaussian graphical
models (GGMs). One is based on a simple modification of the cutting-edge block
Gibbs sampler for sparse GGMs, which results in significant computational gains
in high dimensions. The other method is based on a specific construction of the
Hamiltonian Monte Carlo sampler, which results in further significant
improvements. We compare our fully Bayesian approaches with the popular
regularisation-based graphical LASSO, and demonstrate significant advantages of
the Bayesian treatment under the same computing costs. We apply the methods to
a broad range of simulated data sets, and a real-life financial data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7312</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7312</id><created>2013-09-27</created><authors><author><keyname>Sarma</keyname><forenames>Himangshu</forenames></author><author><keyname>Saharia</keyname><forenames>Navanath</forenames></author><author><keyname>Sharma</keyname><forenames>Utpal</forenames></author><author><keyname>Sinha</keyname><forenames>Smriti Kumar</forenames></author><author><keyname>Malakar</keyname><forenames>Mancha Jyoti</forenames></author></authors><title>Development and Transcription of Assamese Speech Corpus</title><categories>cs.CL</categories><comments>4 page,National Conferance</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A balanced speech corpus is the basic need for any speech processing task. In
this report we describe our effort on development of Assamese speech corpus. We
mainly focused on some issues and challenges faced during development of the
corpus. Being a less computationally aware language, this is the first effort
to develop speech corpus for Assamese. As corpus development is an ongoing
process, in this paper we report only the initial task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7313</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7313</id><created>2013-09-27</created><updated>2014-02-07</updated><authors><author><keyname>Li</keyname><forenames>Jiwei</forenames></author><author><keyname>Cardie</keyname><forenames>Claire</forenames></author></authors><title>Timeline Generation: Tracking individuals on Twitter</title><categories>cs.SI cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a unsupervised framework to reconstruct a person's
life history by creating a chronological list for {\it personal important
events} (PIE) of individuals based on the tweets they published. By analyzing
individual tweet collections, we find that what are suitable for inclusion in
the personal timeline should be tweets talking about personal (as opposed to
public) and time-specific (as opposed to time-general) topics. To further
extract these types of topics, we introduce a non-parametric multi-level
Dirichlet Process model to recognize four types of tweets: personal
time-specific (PersonTS), personal time-general (PersonTG), public
time-specific (PublicTS) and public time-general (PublicTG) topics, which, in
turn, are used for further personal event extraction and timeline generation.
To the best of our knowledge, this is the first work focused on the generation
of timeline for individuals from twitter data. For evaluation, we have built a
new golden standard Timelines based on Twitter and Wikipedia that contain PIE
related events from 20 {\it ordinary twitter users} and 20 {\it celebrities}.
Experiments on real Twitter data quantitatively demonstrate the effectiveness
of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7315</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7315</id><created>2013-09-08</created><authors><author><keyname>Ohlsson</keyname><forenames>Henrik</forenames></author><author><keyname>Verhaegen</keyname><forenames>Michel</forenames></author><author><keyname>Sastry</keyname><forenames>S. Shankar</forenames></author></authors><title>Nonlinear Compressive Particle Filtering</title><categories>cs.SY</categories><comments>Accepted to CDC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many systems for which compressive sensing is used today are dynamical. The
common approach is to neglect the dynamics and see the problem as a sequence of
independent problems. This approach has two disadvantages. Firstly, the
temporal dependency in the state could be used to improve the accuracy of the
state estimates. Secondly, having an estimate for the state and its support
could be used to reduce the computational load of the subsequent step. In the
linear Gaussian setting, compressive sensing was recently combined with the
Kalman filter to mitigate above disadvantages. In the nonlinear dynamical case,
compressive sensing can not be used and, if the state dimension is high, the
particle filter would perform poorly. In this paper we combine one of the most
novel developments in compressive sensing, nonlinear compressive sensing, with
the particle filter. We show that the marriage of the two is essential and that
neither the particle filter or nonlinear compressive sensing alone gives a
satisfying solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7321</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7321</id><created>2013-09-27</created><authors><author><keyname>Nathan</keyname><forenames>Ralph</forenames></author><author><keyname>Anthonio</keyname><forenames>Bryan</forenames></author><author><keyname>Lu</keyname><forenames>Shih-Lien</forenames></author><author><keyname>Naeimi</keyname><forenames>Helia</forenames></author><author><keyname>Sorin</keyname><forenames>Daniel J.</forenames></author><author><keyname>Sun</keyname><forenames>Xiaobai</forenames></author></authors><title>Recycled Error Bits: Energy-Efficient Architectural Support for Higher
  Precision Floating Point</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we provide energy-efficient architectural support for floating
point accuracy. Our goal is to provide accuracy that is far greater than that
provided by the processor's hardware floating point unit (FPU). Specifically,
for each floating point addition performed, we &quot;recycle&quot; that operation's
error: the difference between the finite-precision result produced by the
hardware and the result that would have been produced by an infinite-precision
FPU. We make this error architecturally visible such that it can be used, if
desired, by software. Experimental results on physical hardware show that
software that exploits architecturally recycled error bits can achieve accuracy
comparable to a 2B-bit FPU with performance and energy that are comparable to a
B-bit FPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7334</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7334</id><created>2013-09-26</created><authors><author><keyname>Chadha</keyname><forenames>Ankit</forenames></author><author><keyname>Satam</keyname><forenames>Neha</forenames></author><author><keyname>Ballal</keyname><forenames>Beena</forenames></author></authors><title>Orthogonal Frequency Division Multiplexing and its Applications</title><categories>cs.NI</categories><journal-ref>nternational Journal of Science and Research (IJSR) Online ISSN:
  2319-7064 , January 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal Frequency Division Multiplexing (OFDM) is a multi-carrier
modulation technique which is very much popular in new wireless networks of
IEEE standard, digital television, audio broadcasting and 4G mobile
communications. The main benefit of OFDM over single-carrier schemes is its
ability to cope with severe channel conditions without complex equalization
filters. It has improved the quality of long-distance communication by
eliminating InterSymbol Interference (ISI) and improving Signal-to-Noise ratio
(SNR). The main drawbacks of OFDM are its high peak to average power ratio and
its sensitivity to phase noise and frequency offset. This paper gives an
overview of OFDM, its applications in various systems such as IEEE 802.11a,
Digital Audio Broadcasting (DAB) and Digital Broadcast Services to Handheld
Devices (DVB-H) along with its advantages and disadvantages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7340</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7340</id><created>2013-09-27</created><updated>2013-11-18</updated><authors><author><keyname>Li</keyname><forenames>Jiwei</forenames></author><author><keyname>Cardie</keyname><forenames>Claire</forenames></author></authors><title>Early Stage Influenza Detection from Twitter</title><categories>cs.SI cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Influenza is an acute respiratory illness that occurs virtually every year
and results in substantial disease, death and expense. Detection of Influenza
in its earliest stage would facilitate timely action that could reduce the
spread of the illness. Existing systems such as CDC and EISS which try to
collect diagnosis data, are almost entirely manual, resulting in about two-week
delays for clinical data acquisition. Twitter, a popular microblogging service,
provides us with a perfect source for early-stage flu detection due to its
real- time nature. For example, when a flu breaks out, people that get the flu
may post related tweets which enables the detection of the flu breakout
promptly. In this paper, we investigate the real-time flu detection problem on
Twitter data by proposing Flu Markov Network (Flu-MN): a spatio-temporal
unsupervised Bayesian algorithm based on a 4 phase Markov Network, trying to
identify the flu breakout at the earliest stage. We test our model on real
Twitter datasets from the United States along with baselines in multiple
applications, such as real-time flu breakout detection, future epidemic phase
prediction, or Influenza-like illness (ILI) physician visits. Experimental
results show the robustness and effectiveness of our approach. We build up a
real time flu reporting system based on the proposed approach, and we are
hopeful that it would help government or health organizations in identifying
flu outbreaks and facilitating timely actions to decrease unnecessary
mortality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7341</identifier>
 <datestamp>2013-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7341</id><created>2013-09-27</created><authors><author><keyname>Paschke</keyname><forenames>Adrian</forenames></author></authors><title>OntoMaven: Maven-based Ontology Development and Management of
  Distributed Ontology Repositories</title><categories>cs.SE</categories><comments>Pre-print submission to 9th International Workshop on Semantic Web
  Enabled Software Engineering (SWESE2013). Berlin, Germany, December 2-5, 2013</comments><acm-class>I.2; I.2.4; D.2; D.2.13; D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In collaborative agile ontology development projects support for modular
reuse of ontologies from large existing remote repositories, ontology project
life cycle management, and transitive dependency management are important
needs. The Apache Maven approach has proven its success in distributed
collaborative Software Engineering by its widespread adoption. The contribution
of this paper is a new design artifact called OntoMaven. OntoMaven adopts the
Maven-based development methodology and adapts its concepts to knowledge
engineering for Maven-based ontology development and management of ontology
artifacts in distributed ontology repositories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7366</identifier>
 <datestamp>2014-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7366</id><created>2013-09-27</created><updated>2014-01-08</updated><authors><author><keyname>Corrigan-Gibbs</keyname><forenames>Henry</forenames></author><author><keyname>Mu</keyname><forenames>Wendy</forenames></author><author><keyname>Boneh</keyname><forenames>Dan</forenames></author><author><keyname>Ford</keyname><forenames>Bryan</forenames></author></authors><title>Ensuring High-Quality Randomness in Cryptographic Key Generation</title><categories>cs.CR</categories><comments>This is an extended and corrected version of a paper which appeared
  in the proceedings of the 2013 ACM Conference on Computer and Communications
  Security (CCS). This version corrects an error in the proceedings version of
  the DSA protocol and accompanying security proof. This version also contains
  the full proof of security for the RSA protocol</comments><acm-class>C.2.0; C.2.2; E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The security of any cryptosystem relies on the secrecy of the system's secret
keys. Yet, recent experimental work demonstrates that tens of thousands of
devices on the Internet use RSA and DSA secrets drawn from a small pool of
candidate values. As a result, an adversary can derive the device's secret keys
without breaking the underlying cryptosystem. We introduce a new threat model,
under which there is a systemic solution to such randomness flaws. In our
model, when a device generates a cryptographic key, it incorporates some random
values from an entropy authority into its cryptographic secrets and then proves
to the authority, using zero-knowledge-proof techniques, that it performed this
operation correctly. By presenting an entropy-authority-signed public-key
certificate to a third party (like a certificate authority or SSH client), the
device can demonstrate that its public key incorporates randomness from the
authority and is therefore drawn from a large pool of candidate values. Where
possible, our protocol protects against eavesdroppers, entropy authority
misbehavior, and devices attempting to discredit the entropy authority. To
demonstrate the practicality of our protocol, we have implemented and evaluated
its performance on a commodity wireless home router. When running on a home
router, our protocol incurs a 2.1x slowdown over conventional RSA key
generation and it incurs a 4.4x slowdown over conventional EC-DSA key
generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7367</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7367</id><created>2013-09-27</created><updated>2015-10-27</updated><authors><author><keyname>Talebi</keyname><forenames>M. Sadegh</forenames></author><author><keyname>Zou</keyname><forenames>Zhenhua</forenames></author><author><keyname>Combes</keyname><forenames>Richard</forenames></author><author><keyname>Proutiere</keyname><forenames>Alexandre</forenames></author><author><keyname>Johansson</keyname><forenames>Mikael</forenames></author></authors><title>Stochastic Online Shortest Path Routing: The Value of Feedback</title><categories>cs.NI cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies online shortest path routing over multi-hop networks. Link
costs or delays are time-varying and modeled by independent and identically
distributed random processes, whose parameters are initially unknown. The
parameters, and hence the optimal path, can only be estimated by routing
packets through the network and observing the realized delays. Our aim is to
find a routing policy that minimizes the regret (the cumulative difference of
expected delay) between the path chosen by the policy and the unknown optimal
path. We formulate the problem as a combinatorial bandit optimization problem
and consider several scenarios that differ in where routing decisions are made
and in the information available when making the decisions. For each scenario,
we derive a tight asymptotic lower bound on the regret that has to be satisfied
by any online routing policy. These bounds help us to understand the
performance improvements we can expect when (i) taking routing decisions at
each hop rather than at the source only, and (ii) observing per-link delays
rather than end-to-end path delays. In particular, we show that (i) is of no
use while (ii) can have a spectacular impact. Three algorithms, with a
trade-off between computational complexity and performance, are proposed. The
regret upper bounds of these algorithms improve over those of the existing
algorithms, and they significantly outperform state-of-the-art algorithms in
numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7391</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7391</id><created>2013-09-27</created><authors><author><keyname>Johnson</keyname><forenames>Chris</forenames></author></authors><title>Madeup: A Mobile Development Environment for Programming 3-D Models</title><categories>cs.CY</categories><comments>2 pages, 3 figures, PROMOTO 2013, 1309.5500</comments><report-no>PrMoTo/2013/05</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Constructionism is a learning theory that states that we learn more when we
construct tangible objects. In the process of building and presenting our work,
we make concrete the abstract mental models we've formed, see where they
breakdown through the feedback we receive, and revise the models accordingly.
Computer programming has long been taught under a constructionist approach
using sensory-rich contexts like robots, media, and Logo-style environments.
Now, with affordable 3-D printers in the hands of consumers, we have a new
medium in which learners may realize their computational ideas. In this
demonstration, we share a mobile development environment named Madeup, which
empowers its users to navigate 3-D space using a Logo-like imperative and
functional language. Every stop in space becomes a vertex in a 3-D model. The
generated models may be exported or uploaded to a 3-D printing service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7393</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7393</id><created>2013-09-27</created><authors><author><keyname>Shi</keyname><forenames>Chuan</forenames></author><author><keyname>Kong</keyname><forenames>Xiangnan</forenames></author><author><keyname>Huang</keyname><forenames>Yue</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author><author><keyname>Wu</keyname><forenames>Bin</forenames></author></authors><title>HeteSim: A General Framework for Relevance Measure in Heterogeneous
  Networks</title><categories>cs.IR cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity search is an important function in many applications, which
usually focuses on measuring the similarity between objects with the same type.
However, in many scenarios, we need to measure the relatedness between objects
with different types. With the surge of study on heterogeneous networks, the
relevance measure on objects with different types becomes increasingly
important. In this paper, we study the relevance search problem in
heterogeneous networks, where the task is to measure the relatedness of
heterogeneous objects (including objects with the same type or different
types). A novel measure HeteSim is proposed, which has the following
attributes: (1) a uniform measure: it can measure the relatedness of objects
with the same or different types in a uniform framework; (2) a path-constrained
measure: the relatedness of object pairs are defined based on the search path
that connect two objects through following a sequence of node types; (3) a
semi-metric measure: HeteSim has some good properties (e.g., self-maximum and
symmetric), that are crucial to many data mining tasks. Moreover, we analyze
the computation characteristics of HeteSim and propose the corresponding quick
computation strategies. Empirical studies show that HeteSim can effectively and
efficiently evaluate the relatedness of heterogeneous objects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7405</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7405</id><created>2013-09-27</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author><author><keyname>Colgan</keyname><forenames>Patrick</forenames></author></authors><title>A Model of the Mechanisms Underlying Exploratory Behaviour</title><categories>q-bio.PE cs.AI</categories><comments>17 pages Gabora, L., &amp; Colgan, P. (1990). In (S. Wilson &amp; J. A.
  Mayer, Eds.) Proceedings of the First International Conference on the
  Simulation of Adaptive Behavior (pp. 475-484) Cambridge MA: MIT Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model of the mechanisms underlying exploratory behaviour, based on
empirical research and refined using a computer simulation, is presented. The
behaviour of killifish from two lakes, one with killifish predators and one
without, was compared in the laboratory. Plotting average activity in a novel
environment versus time resulted in an inverted-U-shaped curve for both groups;
however, the curve for killifish from the lake without predators was (1)
steeper, (2) reached a peak value earlier, (S) reached a higher peak value, and
(4) subsumed less area than the curve for killifish from the lake with
predators. We hypothesize that the shape of the exploration curve reflects a
competition between motivational subsystems that excite and inhibit exploratory
behaviour in a way that is tuned to match the affordance probabilities of the
animal's environment. A computer implementation of this model produced curves
which differed along the same four dimensions as differentiate the two
killifish curves. All four differences were reproduced in the model by tuning a
single parameter: the time-dependent component of the decay-rate of the
exploration-inhibiting subsystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7407</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7407</id><created>2013-09-27</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author><author><keyname>Kitto</keyname><forenames>Kirsty</forenames></author></authors><title>Concept Combination and the Origins of Complex Cognition</title><categories>q-bio.NC cs.AI</categories><comments>24 pages. arXiv admin note: substantial text overlap with
  arXiv:1308.5032</comments><journal-ref>In (E. Swan, Ed.) Origins of mind: Biosemiotics Series, Vol. 8
  (pp. 361-382). Berlin: Springer</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the core of our uniquely human cognitive abilities is the capacity to see
things from different perspectives, or to place them in a new context. We
propose that this was made possible by two cognitive transitions. First, the
large brain of Homo erectus facilitated the onset of recursive recall: the
ability to string thoughts together into a stream of potentially abstract or
imaginative thought. This hypothesis is supported by a set of computational
models where an artificial society of agents evolved to generate more diverse
and valuable cultural outputs under conditions of recursive recall. We propose
that the capacity to see things in context arose much later, following the
appearance of anatomically modern humans. This second transition was brought on
by the onset of contextual focus: the capacity to shift between a minimally
contextual analytic mode of thought, and a highly contextual associative mode
of thought, conducive to combining concepts in new ways and 'breaking out of a
rut'. When contextual focus is implemented in an art-generating computer
program, the resulting artworks are seen as more creative and appealing. We
summarize how both transitions can be modeled using a theory of concepts which
highlights the manner in which different contexts can lead to modern humans
attributing very different meanings to the interpretation of one concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7423</identifier>
 <datestamp>2014-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7423</id><created>2013-09-28</created><updated>2014-07-21</updated><authors><author><keyname>Qu</keyname><forenames>Longjiang</forenames></author><author><keyname>Tan</keyname><forenames>Yin</forenames></author><author><keyname>Li</keyname><forenames>Chao</forenames></author><author><keyname>Gong</keyname><forenames>Guang</forenames></author></authors><title>More Constructions of Differentially 4-uniform Permutations on
  $\gf_{2^{2k}}$</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differentially 4-uniform permutations on $\gf_{2^{2k}}$ with high
nonlinearity are often chosen as Substitution boxes in both block and stream
ciphers. Recently, Qu et al. introduced a class of functions, which are called
preferred functions, to construct a lot of infinite families of such
permutations \cite{QTTL}. In this paper, we propose a particular type of
Boolean functions to characterize the preferred functions. On the one hand,
such Boolean functions can be determined by solving linear equations, and they
give rise to a huge number of differentially 4-uniform permutations over
$\gf_{2^{2k}}$. Hence they may provide more choices for the design of
Substitution boxes. On the other hand, by investigating the number of these
Boolean functions, we show that the number of CCZ-inequivalent differentially
4-uniform permutations over $\gf_{2^{2k}}$ grows exponentially when $k$
increases, which gives a positive answer to an open problem proposed in
\cite{QTTL}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7429</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7429</id><created>2013-09-28</created><authors><author><keyname>Sheth</keyname><forenames>Mit</forenames></author><author><keyname>Benerjee</keyname><forenames>Krishna Gopal</forenames></author><author><keyname>Gupta</keyname><forenames>Manish K.</forenames></author></authors><title>Quorum Sensing for Regenerating Codes in Distributed Storage</title><categories>cs.DC cs.IT math.IT</categories><comments>8 pages, 5 figures, submitted to conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed storage systems with replication are well known for storing large
amount of data. A large number of replication is done in order to provide
reliability. This makes the system expensive. Various methods have been
proposed over time to reduce the degree of replication and yet provide same
level of reliability. One recently suggested scheme is of Regenerating codes,
where a file is divided in to parts which are then processed by a coding
mechanism and network coding to provide large number of parts. These are stored
at various nodes with more than one part at each node. These codes can generate
whole file and can repair a failed node by contacting some out of total
existing nodes. This property ensures reliability in case of node failure and
uses clever replication. This also optimizes bandwidth usage. In a practical
scenario, the original file will be read and updated many times. With every
update, we will have to update the data stored at many nodes. Handling multiple
requests at the same time will bring a lot of complexity. Reading and writing
or multiple writing on the same data at the same time should also be prevented.
In this paper, we propose an algorithm that manages and executes all the
requests from the users which reduces the update complexity. We also try to
keep an adequate amount of availability at the same time. We use a voting based
mechanism and form read, write and repair quorums. We have also done
probabilistic analysis of regenerating codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7430</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7430</id><created>2013-09-28</created><updated>2014-01-15</updated><authors><author><keyname>Noh</keyname><forenames>Song</forenames></author><author><keyname>Zoltowski</keyname><forenames>Michael D.</forenames></author><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author></authors><title>Pilot Beam Pattern Design for Channel Estimation in Massive MIMO Systems</title><categories>cs.IT math.IT</categories><comments>15 pages, 12 figures, Practical issues such as channel covariance
  matrix estimation are considered</comments><doi>10.1109/JSTSP.2014.2327572</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of pilot beam pattern design for channel
estimation in massive multiple-input multiple-output systems with a large
number of transmit antennas at the base station is considered, and a new
algorithm for pilot beam pattern design for optimal channel estimation is
proposed under the assumption that the channel is a stationary Gauss-Markov
random process. The proposed algorithm designs the pilot beam pattern
sequentially by exploiting the properties of Kalman filtering and the
associated prediction error covariance matrices and also the channel statistics
such as spatial and temporal channel correlation. The resulting design
generates a sequentially-optimal sequence of pilot beam patterns with low
complexity for a given set of system parameters. Numerical results show the
effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7434</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7434</id><created>2013-09-28</created><authors><author><keyname>Zhang</keyname><forenames>Dong</forenames></author><author><keyname>Oreifej</keyname><forenames>Omar</forenames></author><author><keyname>Shah</keyname><forenames>Mubarak</forenames></author></authors><title>Face Verification Using Boosted Cross-Image Features</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new approach for face verification, where a pair of
images needs to be classified as belonging to the same person or not. This
problem is relatively new and not well-explored in the literature. Current
methods mostly adopt techniques borrowed from face recognition, and process
each of the images in the pair independently, which is counter intuitive. In
contrast, we propose to extract cross-image features, i.e. features across the
pair of images, which, as we demonstrate, is more discriminative to the
similarity and the dissimilarity of faces. Our features are derived from the
popular Haar-like features, however, extended to handle the face verification
problem instead of face detection. We collect a large bank of cross-image
features using filters of different sizes, locations, and orientations.
Consequently, we use AdaBoost to select and weight the most discriminative
features. We carried out extensive experiments on the proposed ideas using
three standard face verification datasets, and obtained promising results
outperforming state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7437</identifier>
 <datestamp>2014-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7437</id><created>2013-09-28</created><updated>2014-06-16</updated><authors><author><keyname>Kim</keyname><forenames>Hyeji</forenames></author><author><keyname>Chia</keyname><forenames>Yeow-Khiang</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>A Note on Broadcast Channels with Stale State Information at the
  Transmitter</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows that the Maddah-Ali--Tse (MAT) scheme which establishes the
symmetric capacity of two example broadcast channels with strictly causal state
information at the transmitter is a simple special case of the
Shayevitz--Wigger scheme for the broadcast channel with generalized feedback,
which involves block Markov coding, compression, superposition coding, Marton
coding, and coded time sharing. Focusing on the class of symmetric broadcast
channels with state, we derive an expression for the maximum achievable
symmetric rate using the Shayevitz--Wigger scheme. We show that the MAT results
can be recovered by evaluating this expression for the special case in which
superposition coding and Marton coding are not used. We then introduce a new
broadcast channel example that shares many features of the MAT examples. We
show that another special case of our maximum symmetric rate expression in
which superposition coding is also used attains a higher symmetric rate than
the MAT scheme. The symmetric capacity of this example is not known, however.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7439</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7439</id><created>2013-09-28</created><authors><author><keyname>Viswanadh</keyname><forenames>K</forenames></author><author><keyname>Murthy</keyname><forenames>Dr. G Rama</forenames></author></authors><title>Optimal Hybrid Channel Allocation:Based On Machine Learning Algorithms</title><categories>cs.NI cs.LG</categories><comments>5 pages, 1 figure</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Recent advances in cellular communication systems resulted in a huge increase
in spectrum demand. To meet the requirements of the ever-growing need for
spectrum, efficient utilization of the existing resources is of utmost
importance. Channel Allocation, has thus become an inevitable research topic in
wireless communications. In this paper, we propose an optimal channel
allocation scheme, Optimal Hybrid Channel Allocation (OHCA) for an effective
allocation of channels. We improvise upon the existing Fixed Channel Allocation
(FCA) technique by imparting intelligence to the existing system by employing
the multilayer perceptron technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7440</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7440</id><created>2013-09-28</created><updated>2014-02-07</updated><authors><author><keyname>Gupta</keyname><forenames>Rishi</forenames></author><author><keyname>Roughgarden</keyname><forenames>Tim</forenames></author><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author></authors><title>Decompositions of Triangle-Dense Graphs</title><categories>cs.DS cs.SI math.CO</categories><comments>20 pages. Version 1-&gt;2: Minor edits. 2-&gt;3: Strengthened {\S}3.5,
  removed appendix</comments><acm-class>F.2.0; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High triangle density -- the graph property stating that a constant fraction
of two-hop paths belong to a triangle -- is a common signature of social
networks. This paper studies triangle-dense graphs from a structural
perspective. We prove constructively that significant portions of a
triangle-dense graph are contained in a disjoint union of dense, radius 2
subgraphs. This result quantifies the extent to which triangle-dense graphs
resemble unions of cliques. We also show that our algorithm recovers planted
clusterings in approximation-stable k-median instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7451</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7451</id><created>2013-09-28</created><authors><author><keyname>Lee</keyname><forenames>Jung Hoon</forenames></author><author><keyname>Choi</keyname><forenames>Wan</forenames></author></authors><title>Multiuser Diversity for Secrecy Communications Using Opportunistic
  Jammer Selection -- Secure DoF and Jammer Scaling Law</title><categories>cs.IT math.IT</categories><comments>Accepted with minor revisions, IEEE Trans. on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose opportunistic jammer selection in a wireless
security system for increasing the secure degrees of freedom (DoF) between a
transmitter and a legitimate receiver (say, Alice and Bob). There is a jammer
group consisting of $S$ jammers among which Bob selects $K$ jammers. The
selected jammers transmit independent and identically distributed Gaussian
signals to hinder the eavesdropper (Eve). Since the channels of Bob and Eve are
independent, we can select the jammers whose jamming channels are aligned at
Bob, but not at Eve. As a result, Eve cannot obtain any DoF unless it has more
than $KN_j$ receive antennas, where $N_j$ is the number of jammer's transmit
antenna each, and hence $KN_j$ can be regarded as defensible dimensions against
Eve. For the jamming signal alignment at Bob, we propose two opportunistic
jammer selection schemes and find the scaling law of the required number of
jammers for target secure DoF by a geometrical interpretation of the received
signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7455</identifier>
 <datestamp>2014-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7455</id><created>2013-09-28</created><updated>2014-04-12</updated><authors><author><keyname>Li</keyname><forenames>Menghui</forenames></author><author><keyname>Guan</keyname><forenames>Shuguang</forenames></author><author><keyname>Wu</keyname><forenames>Chensheng</forenames></author><author><keyname>Gong</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Li</keyname><forenames>Kun</forenames></author><author><keyname>Wu</keyname><forenames>Jinshan</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author><author><keyname>Lai</keyname><forenames>Choy-Heng</forenames></author></authors><title>From sparse to dense and from assortative to disassortative in online
  social networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages, 7 figures and 2 tables</comments><journal-ref>Scientific Reports 4 4861 (2014)</journal-ref><doi>10.1038/srep04861</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by the analysis of several empirical online social networks, we
propose a simple reaction-diffusion-like coevolving model, in which individuals
are activated to create links based on their states, influenced by local
dynamics and their own intention. It is shown that the model can reproduce the
remarkable properties observed in empirical online social networks; in
particular, the assortative coefficients are neutral or negative, and the power
law exponents are smaller than 2. Moreover, we demonstrate that, under
appropriate conditions, the model network naturally makes transition(s) from
assortative to disassortative, and from sparse to dense in their
characteristics. The model is useful in understanding the formation and
evolution of online social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7457</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7457</id><created>2013-09-28</created><authors><author><keyname>Hemmerling</keyname><forenames>Armin</forenames></author></authors><title>On the Tape-Number Problem for Deterministic Time Classes</title><categories>cs.CC</categories><comments>10 pages, 1 figure</comments><msc-class>68Q15, 03Q15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For any time bound f, let H(f) denote the hierarchy conjecture which means
that the restriction of the numbers of work tapes of deterministic Turing
machines to some b generates an infinite hierarchy of proper subclasses
DTIME_b(f) \subset \DTIME(f). We show that H(f) implies separations of
deterministic from nondeterministic time classes. H(f) follows from the gap
property, G(f), which says that there is a time-constructible bound f_2 such
that f \in o(f_2) and DTIME(f)=DTIME(f_2). G(f) implies further separations.
All these relationships relativize.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7460</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7460</id><created>2013-09-28</created><updated>2013-09-30</updated><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Arkhipov</keyname><forenames>Alex</forenames></author></authors><title>BosonSampling Is Far From Uniform</title><categories>quant-ph cs.CC</categories><comments>41 pages, 2 figures, clarified that Brandao's observation is only
  nontrivial if the mockup distribution has large entropy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BosonSampling, which we proposed three years ago, is a scheme for using
linear-optical networks to solve sampling problems that appear to be
intractable for a classical computer. In arXiv:1306.3995, Gogolin et al.
claimed that even an ideal BosonSampling device's output would be
&quot;operationally indistinguishable&quot; from a uniform random outcome, at least
&quot;without detailed a priori knowledge&quot;; or at any rate, that telling the two
apart might itself be a hard problem. We first answer these claims---explaining
why the first is based on a definition of &quot;a priori knowledge&quot; so strange that,
were it adopted, almost no quantum algorithm could be distinguished from a pure
random-number source; while the second is neither new nor a practical obstacle
to interesting BosonSampling experiments. However, we then go further, and
address some interesting research questions inspired by Gogolin et al.'s
mistaken arguments. We prove that, with high probability over a Haar-random
matrix A, the BosonSampling distribution induced by A is far from the uniform
distribution in total variation distance. More surprisingly, and directly
counter to Gogolin et al., we give an efficient algorithm that distinguishes
these two distributions with constant bias. Finally, we offer three &quot;bonus&quot;
results about BosonSampling. First, we report an observation of Fernando
Brandao: that one can efficiently sample a distribution that has large entropy
and that's indistinguishable from a BosonSampling distribution by any circuit
of fixed polynomial size. Second, we show that BosonSampling distributions can
be efficiently distinguished from uniform even with photon losses and for
general initial states. Third, we offer the simplest known proof that
FermionSampling is solvable in classical polynomial time, and we reuse
techniques from our BosonSampling analysis to characterize random
FermionSampling distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7461</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7461</id><created>2013-09-28</created><authors><author><keyname>Garimella</keyname><forenames>Rama Murthy</forenames></author><author><keyname>Singhal</keyname><forenames>Deepti</forenames></author></authors><title>Grid-based Network Architecture for Distributed Computation in Wireless
  Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) are used to perform distributed sensing in
various fields, such as health, military, home etc. In WSNs, sensor nodes
should communicate among themselves and do distributed computation over the
sensed values to identify the occurrence of an event. This paper assumes the no
memory computation model for sensor nodes, i.e. the sensor nodes only have two
registers. This paper presents an optimal architecture for the distributed
computation in WSN and also claims that this architecture is the optimal for
the described computation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7463</identifier>
 <datestamp>2014-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7463</id><created>2013-09-28</created><updated>2014-02-28</updated><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Li</keyname><forenames>Menghui</forenames></author><author><keyname>Gao</keyname><forenames>Liang</forenames></author><author><keyname>Fan</keyname><forenames>Ying</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author></authors><title>Characterizing and Modeling the Dynamics of Activity and Popularity</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>13 pages, 6 figures, 2 tables</comments><journal-ref>PLoS ONE 9(2): e89192 (2014)</journal-ref><doi>10.1371/journal.pone.0089192</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social media, regarded as two-layer networks consisting of users and items,
turn out to be the most important channels for access to massive information in
the era of Web 2.0. The dynamics of human activity and item popularity is a
crucial issue in social media networks. In this paper, by analyzing the growth
of user activity and item popularity in four empirical social media networks,
i.e., Amazon, Flickr, Delicious and Wikipedia, it is found that cross links
between users and items are more likely to be created by active users and to be
acquired by popular items, where user activity and item popularity are measured
by the number of cross links associated with users and items. This indicates
that users generally trace popular items, overall. However, it is found that
the inactive users more severely trace popular items than the active users.
Inspired by empirical analysis, we propose an evolving model for such networks,
in which the evolution is driven only by two-step random walk. Numerical
experiments verified that the model can qualitatively reproduce the
distributions of user activity and item popularity observed in empirical
networks. These results might shed light on the understandings of micro
dynamics of activity and popularity in social media networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7472</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7472</id><created>2013-09-28</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Anirban</forenames></author><author><keyname>Bhandarkar</keyname><forenames>Suchendra M.</forenames></author><author><keyname>Porikli</keyname><forenames>Fatih</forenames></author></authors><title>Detection and Characterization of Intrinsic Symmetry</title><categories>cs.GR</categories><comments>11 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comprehensive framework for detection and characterization of overlapping
intrinsic symmetry over 3D shapes is proposed. To identify prominent symmetric
regions which overlap in space and vary in form, the proposed framework is
decoupled into a Correspondence Space Voting procedure followed by a
Transformation Space Mapping procedure. In the correspondence space voting
procedure, significant symmetries are first detected by identifying surface
point pairs on the input shape that exhibit local similarity in terms of their
intrinsic geometry while simultaneously maintaining an intrinsic distance
structure at a global level. Since different point pairs can share a common
point, the detected symmetric shape regions can potentially overlap. To this
end, a global intrinsic distance-based voting technique is employed to ensure
the inclusion of only those point pairs that exhibit significant symmetry. In
the transformation space mapping procedure, the Functional Map framework is
employed to generate the final map of symmetries between point pairs. The
transformation space mapping procedure ensures the retrieval of the underlying
dense correspondence map throughout the 3D shape that follows a particular
symmetry. Additionally, the formulation of a novel cost matrix enables the
inner product to succesfully indicate the complexity of the underlying symmetry
transformation. The proposed transformation space mapping procedure is shown to
result in the formulation of a semi-metric symmetry space where each point in
the space represents a specific symmetry transformation and the distance
between points represents the complexity between the corresponding
transformations. Experimental results show that the proposed framework can
successfully process complex 3D shapes that possess rich symmetries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7478</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7478</id><created>2013-09-28</created><authors><author><keyname>McCoy</keyname><forenames>Michael B.</forenames></author><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author></authors><title>The achievable performance of convex demixing</title><categories>cs.IT math.IT math.OC</categories><msc-class>94A15, 90C25, 60D05, 94B75</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demixing is the problem of identifying multiple structured signals from a
superimposed, undersampled, and noisy observation. This work analyzes a general
framework, based on convex optimization, for solving demixing problems. When
the constituent signals follow a generic incoherence model, this analysis leads
to precise recovery guarantees. These results admit an attractive
interpretation: each signal possesses an intrinsic degrees-of-freedom
parameter, and demixing can succeed if and only if the dimension of the
observation exceeds the total degrees of freedom present in the observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7484</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7484</id><created>2013-09-28</created><authors><author><keyname>Junzhou</keyname><forenames>Chen</forenames></author><author><keyname>Qing</keyname><forenames>Li</forenames></author><author><keyname>Qiang</keyname><forenames>Peng</forenames></author><author><keyname>Wong</keyname><forenames>Kin Hong</forenames></author></authors><title>CSIFT Based Locality-constrained Linear Coding for Image Classification</title><categories>cs.CV</categories><comments>9 pages, 5 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the past decade, SIFT descriptor has been witnessed as one of the most
robust local invariant feature descriptors and widely used in various vision
tasks. Most traditional image classification systems depend on the
luminance-based SIFT descriptors, which only analyze the gray level variations
of the images. Misclassification may happen since their color contents are
ignored. In this article, we concentrate on improving the performance of
existing image classification algorithms by adding color information. To
achieve this purpose, different kinds of colored SIFT descriptors are
introduced and implemented. Locality-constrained Linear Coding (LLC), a
state-of-the-art sparse coding technology, is employed to construct the image
classification system for the evaluation. The real experiments are carried out
on several benchmarks. With the enhancements of color SIFT, the proposed image
classification system obtains approximate 3% improvement of classification
accuracy on the Caltech-101 dataset and approximate 4% improvement of
classification accuracy on the Caltech-256 dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7495</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7495</id><created>2013-09-28</created><authors><author><keyname>Aharonov</keyname><forenames>Dorit</forenames></author><author><keyname>Arad</keyname><forenames>Itai</forenames></author><author><keyname>Vidick</keyname><forenames>Thomas</forenames></author></authors><title>The Quantum PCP Conjecture</title><categories>quant-ph cs.CC</categories><comments>45 pages, 4 figures, an enhanced version of the SIGACT guest column
  from Volume 44 Issue 2, June 2013</comments><journal-ref>ACM SIGACT News archive Volume 44 Issue 2, June 2013, Pages 47--79</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical PCP theorem is arguably the most important achievement of
classical complexity theory in the past quarter century. In recent years,
researchers in quantum computational complexity have tried to identify
approaches and develop tools that address the question: does a quantum version
of the PCP theorem hold? The story of this study starts with classical
complexity and takes unexpected turns providing fascinating vistas on the
foundations of quantum mechanics, the global nature of entanglement and its
topological properties, quantum error correction, information theory, and much
more; it raises questions that touch upon some of the most fundamental issues
at the heart of our understanding of quantum mechanics. At this point, the jury
is still out as to whether or not such a theorem holds. This survey aims to
provide a snapshot of the status in this ongoing story, tailored to a general
theory-of-CS audience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7498</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7498</id><created>2013-09-28</created><authors><author><keyname>Stepanov</keyname><forenames>Misha</forenames></author><author><keyname>Sundarrajan</keyname><forenames>Aditya</forenames></author></authors><title>Most probable failure scenario in a model power grid with random power
  demand</title><categories>math.OC cs.SY</categories><comments>7 pages, 12 figures</comments><msc-class>60G70, 49M05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a simple system with a local synchronous generator and a load
whose power consumption is a random process. The most probable scenario of
system failure (synchronization loss) is considered, and it is argued that its
knowledge is virtually enough to estimate the probability of failure per unit
time. We discuss two numerical methods to obtain the &quot;optimal&quot; evolution
leading to failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7508</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7508</id><created>2013-09-28</created><authors><author><keyname>Brglez</keyname><forenames>Franc</forenames><affiliation>Computer Science, NC State University</affiliation></author></authors><title>On Self-Avoiding Walks across n-Dimensional Dice and Combinatorial
  Optimization: An Introduction</title><categories>cs.DS</categories><comments>15 pdf pages that include 4 full-page figure composites, 4 smaller
  figure composites, 2 Tables</comments><acm-class>F.2.2; G.1.6; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-avoiding walks (SAWs) were introduced in chemistry to model the
real-life behavior of chain-like entities such as solvents and polymers, whose
physical volume prohibits multiple occupation of the same spatial point. In
mathematics, a SAW lives in the n-dimensional lattices.
  In this paper, SAWs are a metaphor for walks across faces of n-dimensional
dice, or more formally, a hyperhedron family H(Theta, b, n). Each face is
assigned a label {x:Theta(x)}; x represents a unique n-dimensional coordinate
string, Theta(x) is the value of the function. The walk searches Theta(x) for
optima by following five simple rules: (1) select a random coordinate and mark
it as the `initial pivot'; (2) probe all unmarked adjacent coordinates, then
select and mark the coordinate with the 'best value' as the new pivot; (3)
continue the walk until either the 'best value' &lt;= `target value' or the walk
is being blocked by adjacent coordinates that are already pivots; (4) if the
walk is blocked, restart the walk from a randomly selected `new initial pivot';
(5) if needed, manage the memory overflow with a streaming-like buffer of
appropriate size.
  Hard instances from a number of problem domains, including the 2D protein
folding problem, with up to (2^{25})*(3^{24}) coordinates, have been solved
with SAWs in less than 1,000,000 steps -- while also exceeding the quality of
best known solutions to date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7512</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7512</id><created>2013-09-28</created><updated>2013-09-30</updated><authors><author><keyname>Fix</keyname><forenames>Alexander</forenames></author><author><keyname>Joachims</keyname><forenames>Thorsten</forenames></author><author><keyname>Park</keyname><forenames>Sam</forenames></author><author><keyname>Zabih</keyname><forenames>Ramin</forenames></author></authors><title>Structured learning of sum-of-submodular higher order energy functions</title><categories>cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Submodular functions can be exactly minimized in polynomial time, and the
special case that graph cuts solve with max flow \cite{KZ:PAMI04} has had
significant impact in computer vision
\cite{BVZ:PAMI01,Kwatra:SIGGRAPH03,Rother:GrabCut04}. In this paper we address
the important class of sum-of-submodular (SoS) functions
\cite{Arora:ECCV12,Kolmogorov:DAM12}, which can be efficiently minimized via a
variant of max flow called submodular flow \cite{Edmonds:ADM77}. SoS functions
can naturally express higher order priors involving, e.g., local image patches;
however, it is difficult to fully exploit their expressive power because they
have so many parameters. Rather than trying to formulate existing higher order
priors as an SoS function, we take a discriminative learning approach,
effectively searching the space of SoS functions for a higher order prior that
performs well on our training set. We adopt a structural SVM approach
\cite{Joachims/etal/09a,Tsochantaridis/etal/04} and formulate the training
problem in terms of quadratic programming; as a result we can efficiently
search the space of SoS priors via an extended cutting-plane algorithm. We also
show how the state-of-the-art max flow method for vision problems
\cite{Goldberg:ESA11} can be modified to efficiently solve the submodular flow
problem. Experimental comparisons are made against the OpenCV implementation of
the GrabCut interactive segmentation technique \cite{Rother:GrabCut04}, which
uses hand-tuned parameters instead of machine learning. On a standard dataset
\cite{Gulshan:CVPR10} our method learns higher order priors with hundreds of
parameter values, and produces significantly better segmentations. While our
focus is on binary labeling problems, we show that our techniques can be
naturally generalized to handle more than two labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7517</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7517</id><created>2013-09-28</created><authors><author><keyname>Gueye</keyname><forenames>Modou</forenames></author><author><keyname>Abdessalem</keyname><forenames>Talel</forenames></author><author><keyname>Naacke</keyname><forenames>Hubert</forenames></author></authors><title>Improving tag recommendation by folding in more consistency</title><categories>cs.IR</categories><comments>14 pages</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tag recommendation is a major aspect of collaborative tagging systems. It
aims to recommend tags to a user for tagging an item. In this paper we present
a part of our work in progress which is a novel improvement of recommendations
by re-ranking the output of a tag recommender. We mine association rules
between candidates tags in order to determine a more consistent list of tags to
recommend.
  Our method is an add-on one which leads to better recommendations as we show
in this paper. It is easily parallelizable and morever it may be applied to a
lot of tag recommenders. The experiments we did on five datasets with two kinds
of tag recommender demonstrated the efficiency of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7518</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7518</id><created>2013-09-28</created><authors><author><keyname>Carosino</keyname><forenames>Michael</forenames></author><author><keyname>Chen</keyname><forenames>Yiming</forenames></author><author><keyname>Belzer</keyname><forenames>Benjamin J.</forenames></author><author><keyname>Sivakumar</keyname><forenames>Krishnamoorthy</forenames></author><author><keyname>Murray</keyname><forenames>Jacob</forenames></author><author><keyname>Wettin</keyname><forenames>Paul</forenames></author></authors><title>Iterative Detection and Decoding for the Four-Rectangular-Grain TDMR
  Model</title><categories>cs.IT math.IT</categories><comments>7 pages, 7 figures, 2 tables. Accepted paper to appear in proceedings
  of the 2013 Allerton Conference on Communication, Control and Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers detection and error control coding for the
two-dimensional magnetic recording (TDMR) channel modeled by the
two-dimensional (2D) four-rectangular-grain model proposed by Kavcic, Huang et.
al. in 2010. This simple model captures the effects of different 2D grain sizes
and shapes, as well as the TDMR grain overwrite effect: grains large enough to
be written by successive bits retain the polarity of only the last bit written.
We construct a row-by-row BCJR detection algorithm that considers outputs from
two rows at a time over two adjacent columns, thereby enabling consideration of
more grain and data states than previously proposed algorithms that scan only
one row at a time. The proposed algorithm employs soft-decision feedback of
grain states from previous rows to aid the estimation of current data bits and
grain states. Simulation results using the same average coded bit density and
serially concatenated convolutional code (SCCC) as a previous paper by Pan,
Ryan, et. al. show gains in user bits/grain of up to 6.7% over the previous
work when no iteration is performed between the TDMR BCJR and the SCCC, and
gains of up to 13.4% when the detector and the decoder iteratively exchange
soft information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7522</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7522</id><created>2013-09-28</created><authors><author><keyname>Pratiwi</keyname><forenames>Dian</forenames></author><author><keyname>Santika</keyname><forenames>Diaz D.</forenames></author><author><keyname>Pardamean</keyname><forenames>Bens</forenames></author></authors><title>An Application of Backpropagation Artificial Neural Network Method for
  Measuring The Severity of Osteoarthritis</title><categories>cs.NE cs.CE cs.CV</categories><comments>4 pages, 4 figures, 3 tables</comments><journal-ref>International Journal of Engineering &amp; Technology IJET-IJENS Vol.
  11 No.3, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The examination of Osteoarthritis disease through X-ray by rheumatology can
be classified into four grade of severity. This paper discusses about the
application of artificial neural network backpropagation method for measuring
the severity of the disease, where the observed X-ray range from wrist to
fingers. The main procedures of system in this paper is divided into three,
which are image processing, feature extraction, and artificial neural network
process. First, an X-ray image digital (200x150 pixels and greyscale) will be
thresholded, then extracted features based on probabilistic values of the color
intensity of seven bit quantization result, and statistical textures. That
feature values then will be normalizing to interval [0.1, 0.9], and then the
result would be processing on backpropagation artificial neural network system
as input to determine the severity of disease from an X-ray had input before
it. From testing with learning rate 0.3, momentum 0.4, hidden units five pieces
and about 132 feature vectors, this system had had a level of accuracy of 100%
for learning data, 80% for learning and non-learning data, and 66.6% for
non-learning data
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7524</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7524</id><created>2013-09-28</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>Meme and Variations: A Computer Model of Cultural Evolution</title><categories>cs.MA cs.NE</categories><comments>14 pages</comments><journal-ref>Gabora, L. (1995). Meme and Variations: A computer model of
  cultural evolution. In (L. Nadel and D. L. Stein, eds.) 1993 Lectures in
  Complex Systems (pp. 471-486). Boston: Addison Wesley</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Holland's (1975) genetic algorithm is a minimal computer model of natural
selection that made it possible to investigate the effect of manipulating
specific parameters on the evolutionary process. If culture is, like biology, a
form of evolution, it should be possible to similarly abstract the underlying
skeleton of the process and develop a minimal model of it. Meme and Variations,
or MAV, is a computational model, inspired by the genetic algorithm, of how
ideas evolve in a society of interacting individuals (Gabora 1995). The name is
a pun on the classical music form 'theme and variations', because it is based
on the premise that novel ideas are variations of old ones; they result from
tweaking or combining existing ideas in new ways (Holland et al. 1981). MAV
explores the impact of biological phenomena such as over-dominance and
epistasis as well as cognitive and social phenomena such as the ability to
learn generalizations or imitate others on the fitness and diversity of
cultural transmissible actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7527</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7527</id><created>2013-09-28</created><authors><author><keyname>Bao</keyname><forenames>Wei</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>Structured Spectrum Allocation and User Association in Heterogeneous
  Cellular Networks</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study joint spectrum allocation and user association in heterogeneous
cellular networks with multiple tiers of base stations. A stochastic geometric
approach is applied as the basis to derive the average downlink user data rate
in a closed-form expression. Then, the expression is employed as the objective
function in jointly optimizing spectrum allocation and user association, which
is of non-convex programming in nature. A computationally efficient Structured
Spectrum Allocation and User Association (SSAUA) approach is proposed, solving
the optimization problem optimally when the density of users is low, and
near-optimally with a guaranteed performance bound when the density of users is
high. A Surcharge Pricing Scheme (SPS) is also presented, such that the
designed association bias values can be achieved in Nash equilibrium.
Simulations and numerical studies are conducted to validate the accuracy and
efficiency of the proposed SSAUA approach and SPS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7528</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7528</id><created>2013-09-28</created><updated>2015-03-14</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author></authors><title>Non-Asymptotic and Asymptotic Analyses of Information Processing on
  Markov Chains</title><categories>cs.IT math.IT</categories><comments>51 pages; 2 figures; presented at Allerton 2013 and ITA 2014; v2
  fixed a gap in Remark 5; v3 changed the organization and presentation of the
  paper; Sections 2 and 3 in v2 were removed in v3, and extended version of
  them are in separate papers (cf. arXiv:1401.3801 and arXiv:1401.3814); in v4,
  results on random number generation are removed, and will appear in a
  separate paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we derive non-asymptotic achievability and converse bounds on
the source coding with/without side-information, the random number generation
with/without side-information, and the channel coding for the regular channel.
Our bounds are efficiently computable in the sense that the computational
complexity does not depend on the block length. We also characterize the
asymptotic behaviors of the large deviation regime and the moderate deviation
regime by using our bounds, which implies that our bounds are asymptotically
tight in those regimes. We also show the second order rates of those problems,
and derive single letter forms of the variances characterizing the second order
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7540</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7540</id><created>2013-09-29</created><updated>2013-12-28</updated><authors><author><keyname>Liu</keyname><forenames>An</forenames></author><author><keyname>Lau</keyname><forenames>Vincent</forenames></author></authors><title>Joint Power and Antenna Selection Optimization in Large Cloud Radio
  Access Networks</title><categories>cs.IT math.IT</categories><comments>Accepted by IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2014.2298367</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large multiple-input multiple-output (MIMO) networks promise high energy
efficiency, i.e., much less power is required to achieve the same capacity
compared to the conventional MIMO networks if perfect channel state information
(CSI) is available at the transmitter. However, in such networks, huge overhead
is required to obtain full CSI especially for Frequency-Division Duplex (FDD)
systems. To reduce overhead, we propose a downlink antenna selection scheme,
which selects S antennas from M&gt;S transmit antennas based on the large scale
fading to serve K\leq S users in large distributed MIMO networks employing
regularized zero-forcing (RZF) precoding. In particular, we study the joint
optimization of antenna selection, regularization factor, and power allocation
to maximize the average weighted sum-rate. This is a mixed combinatorial and
non-convex problem whose objective and constraints have no closed-form
expressions. We apply random matrix theory to derive asymptotically accurate
expressions for the objective and constraints. As such, the joint optimization
problem is decomposed into subproblems, each of which is solved by an efficient
algorithm. In addition, we derive structural solutions for some special cases
and show that the capacity of very large distributed MIMO networks scales as
O\left(K\textrm{log}M\right) when M\rightarrow\infty with K,S fixed.
Simulations show that the proposed scheme achieves significant performance gain
over various baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7543</identifier>
 <datestamp>2015-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7543</id><created>2013-09-29</created><updated>2014-10-11</updated><authors><author><keyname>Kumar</keyname><forenames>Santhosh</forenames></author><author><keyname>Young</keyname><forenames>Andrew J.</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Threshold Saturation for Spatially-Coupled LDPC and LDGM Codes on BMS
  Channels</title><categories>cs.IT math.IT</categories><comments>(v1) This article supersedes arXiv:1301.6111 (v2) Accepted to the
  IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 60, No. 12, pp.
  7389-7415, Dec. 2014</journal-ref><doi>10.1109/TIT.2014.2360692</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatially-coupled low-density parity-check (LDPC) codes, which were first
introduced as LDPC convolutional codes, have been shown to exhibit excellent
performance under low-complexity belief-propagation decoding. This phenomenon
is now termed threshold saturation via spatial coupling. Spatially-coupled
codes have been successfully applied in numerous areas. In particular, it was
proven that spatially-coupled regular LDPC codes universally achieve capacity
over the class of binary memoryless symmetric (BMS) channels under
belief-propagation decoding.
  Recently, potential functions have been used to simplify threshold saturation
proofs for scalar and vector recursions. In this paper, potential functions are
used to prove threshold saturation for irregular LDPC and low-density
generator-matrix (LDGM) codes on BMS channels, extending the simplified proof
technique to BMS channels. The corresponding potential functions are closely
related to the average Bethe free entropy of the ensembles in the large-system
limit. These functions also appear in statistical physics when the replica
method is used to analyze optimal decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7555</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7555</id><created>2013-09-29</created><authors><author><keyname>Bastian</keyname><forenames>Peter</forenames></author></authors><title>A fully-coupled discontinuous Galerkin method for two-phase flow in
  porous media with discontinuous capillary pressure</title><categories>physics.flu-dyn cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we formulate and test numerically a fully-coupled discontinuous
Galerkin (DG) method for incompressible two-phase flow with discontinuous
capillary pressure. The spatial discretization uses the symmetric interior
penalty DG formulation with weighted averages and is based on a wetting-phase
potential / capillary potential formulation of the two-phase flow system. After
discretizing in time with diagonally implicit Runge-Kutta schemes the resulting
systems of nonlinear algebraic equations are solved with Newton's method and
the arising systems of linear equations are solved efficiently and in parallel
with an algebraic multigrid method. The new scheme is investigated for various
test problems from the literature and is also compared to a cell-centered
finite volume scheme in terms of accuracy and time to solution. We find that
the method is accurate, robust and efficient. In particular no post-processing
of the DG velocity field is necessary in contrast to results reported by
several authors for decoupled schemes. Moreover, the solver scales well in
parallel and three-dimensional problems with up to nearly 100 million degrees
of freedom per time step have been computed on 1000 processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7564</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7564</id><created>2013-09-29</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Hua</keyname><forenames>Yingbo</forenames></author></authors><title>Channel Estimation, Carrier Recovery, and Data Detection in the Presence
  of Phase Noise in OFDM Relay Systems</title><categories>cs.IT math.IT</categories><comments>13 pages, 12 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Due to its time-varying nature, oscillator phase noise can significantly
degrade the performance of channel estimation, carrier recovery, and data
detection blocks in high-speed wireless communication systems. In this paper,
we analyze joint channel, \emph{carrier frequency offset (CFO)}, and phase
noise estimation plus data detection in \emph{orthogonal frequency division
multiplexing (OFDM)} relay systems. To achieve this goal, a detailed
transmission framework involving both training and data symbols is presented.
In the data transmission phase, a comb-type OFDM symbol consisting of both
pilots and data symbols is proposed to track phase noise over an OFDM frame.
Next, a novel algorithm that applies the training symbols to jointly estimate
the channel responses, CFO, and phase noise based on the maximum a posteriori
criterion is proposed. Additionally, a new \emph{hybrid Cram\'{e}r-Rao lower
bound} for evaluating the performance of channel estimation and carrier
recovery algorithms in OFDM relay networks is derived. Finally, an iterative
receiver for joint phase noise estimation and data detection at the destination
node is derived. Extensive simulations demonstrate that the application of the
proposed estimation and receiver blocks significantly improves the performance
of OFDM relay networks in the presence of phase noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7565</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7565</id><created>2013-09-29</created><authors><author><keyname>Magniez</keyname><forenames>Frederic</forenames></author><author><keyname>Nayak</keyname><forenames>Ashwin</forenames></author><author><keyname>Santha</keyname><forenames>Miklos</forenames></author><author><keyname>Sherman</keyname><forenames>Jonah</forenames></author><author><keyname>Tardos</keyname><forenames>Gabor</forenames></author><author><keyname>Xiao</keyname><forenames>David</forenames></author></authors><title>Improved bounds for the randomized decision tree complexity of recursive
  majority</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the randomized decision tree complexity of the recursive
3-majority function. We prove a lower bound of $(1/2-\delta) \cdot 2.57143^h$
for the two-sided-error randomized decision tree complexity of evaluating
height $h$ formulae with error $\delta \in [0,1/2)$. This improves the lower
bound of $(1-2\delta)(7/3)^h$ given by Jayram, Kumar, and Sivakumar (STOC'03),
and the one of $(1-2\delta) \cdot 2.55^h$ given by Leonardos (ICALP'13).
Second, we improve the upper bound by giving a new zero-error randomized
decision tree algorithm that has complexity at most $(1.007) \cdot 2.64944^h$.
The previous best known algorithm achieved complexity $(1.004) \cdot
2.65622^h$. The new lower bound follows from a better analysis of the base case
of the recursion of Jayram et al. The new algorithm uses a novel &quot;interleaving&quot;
of two recursive algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7572</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7572</id><created>2013-09-29</created><updated>2013-11-04</updated><authors><author><keyname>Alsharoa</keyname><forenames>Ahmad</forenames></author><author><keyname>Ghazzai</keyname><forenames>Hakim</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Optimal Transmit Power Allocation for MIMO Two-Way Cognitive Relay
  Networks with Multiple Relays</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider a multiple-input multiple-output two-way
cognitive radio system under a spectrum sharing scenario, where primary and
secondary users operate on the same frequency band. The secondary terminals
aims to exchange different messages with each other using multiple relays where
each relay employs an amplify-and-forward strategy. The main objective of our
work is to maximize the secondary sum rate allowed to share the spectrum with
the primary users by respecting a primary user tolerated interference
threshold. In this context, we derive a closed-form expression of the optimal
power allocated to each antenna of the terminals. We then discuss the impact of
some system parameters on the performance in the numerical result section.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7583</identifier>
 <datestamp>2015-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7583</id><created>2013-09-29</created><authors><author><keyname>H&#xe4;ger</keyname><forenames>Christian</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Br&#xe4;nnstr&#xf6;m</keyname><forenames>Fredrik</forenames></author><author><keyname>Agrell</keyname><forenames>Erik</forenames></author></authors><title>Optimized Bit Mappings for Spatially Coupled LDPC Codes over Parallel
  Binary Erasure Channels</title><categories>cs.IT math.IT</categories><doi>10.1109/ICC.2014.6883627</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many practical communication systems, one binary encoder/decoder pair is
used to communicate over a set of parallel channels. Examples of this setup
include multi-carrier transmission, rate-compatible puncturing of turbo-like
codes, and bit-interleaved coded modulation (BICM). A bit mapper is commonly
employed to determine how the coded bits are allocated to the channels. In this
paper, we study spatially coupled low-density parity check codes over parallel
channels and optimize the bit mapper using BICM as the driving example. For
simplicity, the parallel bit channels that arise in BICM are replaced by
independent binary erasure channels (BECs). For two parallel BECs modeled
according to a 4-PAM constellation labeled by the binary reflected Gray code,
the optimization results show that the decoding threshold can be improved over
a uniform random bit mapper, or, alternatively, the spatial chain length of the
code can be reduced for a given gap to capacity. It is also shown that for
rate-loss free, circular (tail-biting) ensembles, a decoding wave effect can be
initiated using only an optimized bit mapper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7584</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7584</id><created>2013-09-29</created><authors><author><keyname>Breveglieri</keyname><forenames>Luca</forenames></author><author><keyname>Reghizzi</keyname><forenames>Stefano Crespi</forenames></author><author><keyname>Morzenti</keyname><forenames>Angelo</forenames></author></authors><title>Parsing methods streamlined</title><categories>cs.FL cs.PL</categories><comments>64 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has the goals (1) of unifying top-down parsing with shift-reduce
parsing to yield a single simple and consistent framework, and (2) of producing
provably correct parsing methods, deterministic as well as tabular ones, for
extended context-free grammars (EBNF) represented as state-transition networks.
Departing from the traditional way of presenting as independent algorithms the
deterministic bottom-up LR(1), the top-down LL(1) and the general tabular
(Earley) parsers, we unify them in a coherent minimalist framework. We present
a simple general construction method for EBNF ELR(1) parsers, where the new
category of convergence conflicts is added to the classical shift-reduce and
reduce-reduce conflicts; we prove its correctness and show two implementations
by deterministic push-down machines and by vector-stack machines, the latter to
be also used for Earley parsers. Then the Beatty's theoretical characterization
of LL(1) grammars is adapted to derive the extended ELL(1 parsing method, first
by minimizing the ELR(1) parser and then by simplifying its state information.
Through using the same notations in the ELR(1) case, the extended Earley parser
is obtained. Since all the parsers operate on compatible representations, it is
feasible to combine them into mixed mode algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7598</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7598</id><created>2013-09-29</created><authors><author><keyname>Hazan</keyname><forenames>Tamir</forenames></author><author><keyname>Maji</keyname><forenames>Subhransu</forenames></author><author><keyname>Jaakkola</keyname><forenames>Tommi</forenames></author></authors><title>On Sampling from the Gibbs Distribution with Random Maximum A-Posteriori
  Perturbations</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe how MAP inference can be used to sample efficiently
from Gibbs distributions. Specifically, we provide means for drawing either
approximate or unbiased samples from Gibbs' distributions by introducing low
dimensional perturbations and solving the corresponding MAP assignments. Our
approach also leads to new ways to derive lower bounds on partition functions.
We demonstrate empirically that our method excels in the typical &quot;high signal -
high coupling&quot; regime. The setting results in ragged energy landscapes that are
challenging for alternative approaches to sampling and/or lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7609</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7609</id><created>2013-09-29</created><authors><author><keyname>Laura</keyname><forenames>Kevin Rojas</forenames></author><author><keyname>Alvarez</keyname><forenames>Christhian Cardenas</forenames></author></authors><title>Identificaci\'on y Registro Catastral de Cuerpos de Agua mediante
  T\'ecnicas de Procesamiento Digital de Imagenes</title><categories>cs.CV</categories><comments>in Spanish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effects of global climate change on Peruvian glaciers have brought about
several processes of deglaciation during the last few years. The immediate
effect is the change of size of lakes and rivers. Public institutions that
monitor water resources currently have only recent studies which make up less
than 10% of the total. The effects of climate change and the lack of updated
information intensify social-economic problems related to water resources in
Peru. The objective of this research is to develop a software application to
automate the Cadastral Registry of Water Bodies in Peru, using techniques of
digital image processing, which would provide tools for detection, record,
temporal analysis and visualization of water bodies. The images used are from
the satellite Landsat5, which undergo a pre-processing of calibration and
correction of the satellite. Detection results are archived into a file that
contains location vectors and images of the segmentated bodies of water.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7611</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7611</id><created>2013-09-29</created><authors><author><keyname>Hidasi</keyname><forenames>Bal&#xe1;zs</forenames></author><author><keyname>Tikk</keyname><forenames>Domonkos</forenames></author></authors><title>Context-aware recommendations from implicit data via scalable tensor
  factorization</title><categories>cs.LG cs.IR</categories><comments>Extended version of the ECML/PKDD 2012 paper of B. Hidasi &amp; D. Tikk:
  Fast ALS-based tensor factorization for context-aware recommendation from
  implicit feedback [arXiv:1204.1259]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Albeit the implicit feedback based recommendation problem - when only the
user history is available but there are no ratings - is the most typical
setting in real-world applications, it is much less researched than the
explicit feedback case. State-of-the-art algorithms that are efficient on the
explicit case cannot be automatically transformed to the implicit case if
scalability should be maintained. There are few implicit feedback benchmark
data sets, therefore new ideas are usually experimented on explicit benchmarks.
In this paper, we propose a generic context-aware implicit feedback recommender
algorithm, coined iTALS. iTALS applies a fast, ALS-based tensor factorization
learning method that scales linearly with the number of non-zero elements in
the tensor. We also present two approximate and faster variants of iTALS using
coordinate descent and conjugate gradient methods at learning. The method also
allows us to incorporate various contextual information into the model while
maintaining its computational efficiency. We present two context-aware variants
of iTALS incorporating seasonality and item purchase sequentiality into the
model to distinguish user behavior at different time intervals, and product
types with different repetitiveness. Experiments run on six data sets shows
that iTALS clearly outperforms context-unaware models and context aware
baselines, while it is on par with factorization machines (beats 7 times out of
12 cases) both in terms of recall and MAP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7615</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7615</id><created>2013-09-29</created><authors><author><keyname>Jassim</keyname><forenames>Firas A.</forenames></author></authors><title>Correcting Multi-focus Images via Simple Standard Deviation for Image
  Fusion</title><categories>cs.CV</categories><journal-ref>International Journal of Image, Graphics and Signal Processing
  (IJIGSP), Vol. 5, No. 12, pp. 56-61, October 2013</journal-ref><doi>10.5815/ijigsp.2013.12.08</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Image fusion is one of the recent trends in image registration which is an
essential field of image processing. The basic principle of this paper is to
fuse multi-focus images using simple statistical standard deviation. Firstly,
the simple standard deviation for the k-by-k window inside each of the
multi-focus images was computed. The contribution in this paper came from the
idea that the focused part inside an image had high details rather than the
unfocused part. Hence, the dispersion between pixels inside the focused part is
higher than the dispersion inside the unfocused part. Secondly, a simple
comparison between the standard deviation for each k-by-k window in the
multi-focus images could be computed. The highest standard deviation between
all the computed standard deviations for the multi-focus images could be
treated as the optimal that is to be placed in the fused image. The
experimental visual results show that the proposed method produces very
satisfactory results in spite of its simplicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7640</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7640</id><created>2013-09-29</created><authors><author><keyname>El-Hadedy</keyname><forenames>Mohamed</forenames></author><author><keyname>Pitsilis</keyname><forenames>Georgios</forenames></author><author><keyname>Knapskog</keyname><forenames>Svein J.</forenames></author></authors><title>An Efficient Authorship Protection Scheme for Shared Multimedia Content</title><categories>cs.MM cs.DL</categories><comments>Extensive technical report of paper published in Sixth International
  Conference on Image and Graphics (ICIG), pp.914-919, Hefei, Anhui, China,
  August 12-15, 2011. ISBN: 978-0-7695-4541-7</comments><doi>10.1109/ICIG.2011.183</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many electronic content providers today like Flickr and Google, offer space
to users to publish their electronic media (e.g. photos and videos) in their
cloud infrastructures, so that they can be publicly accessed. Features like
including other information, such as keywords or owner information into the
digital material is already offered by existing providers. Despite the useful
features made available to users by such infrastructures, the authorship of the
published content is not protected against various attacks such as compression.
In this paper we propose a robust scheme that uses digital invisible
watermarking and hashing to protect the authorship of the digital content and
provide resistance against malicious manipulation of multimedia content. The
scheme is enhanced by an algorithm called MMBEC, that is an extension of an
established scheme MBEC, towards higher resistance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7643</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7643</id><created>2013-09-29</created><updated>2014-03-17</updated><authors><author><keyname>Zhao</keyname><forenames>Zhizhen</forenames></author><author><keyname>Singer</keyname><forenames>Amit</forenames></author></authors><title>Rotationally Invariant Image Representation for Viewing Direction
  Classification in Cryo-EM</title><categories>q-bio.BM cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new rotationally invariant viewing angle classification method
for identifying, among a large number of Cryo-EM projection images, similar
views without prior knowledge of the molecule. Our rotationally invariant
features are based on the bispectrum. Each image is denoised and compressed
using steerable principal component analysis (PCA) such that rotating an image
is equivalent to phase shifting the expansion coefficients. Thus we are able to
extend the theory of bispectrum of 1D periodic signals to 2D images. The
randomized PCA algorithm is then used to efficiently reduce the dimensionality
of the bispectrum coefficients, enabling fast computation of the similarity
between any pair of images. The nearest neighbors provide an initial
classification of similar viewing angles. In this way, rotational alignment is
only performed for images with their nearest neighbors. The initial nearest
neighbor classification and alignment are further improved by a new
classification method called vector diffusion maps. Our pipeline for viewing
angle classification and alignment is experimentally shown to be faster and
more accurate than reference-free alignment with rotationally invariant K-means
clustering, MSA/MRA 2D classification, and their modern approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7665</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7665</id><created>2013-09-29</created><authors><author><keyname>Brislawn</keyname><forenames>Christopher M.</forenames></author></authors><title>Group-theoretic structure of linear phase multirate filter banks</title><categories>cs.IT math.IT</categories><comments>33 pages, 6 figures; to appear in IEEE Transactions on Information
  Theory</comments><report-no>LA-UR-12-20858</report-no><msc-class>42C40 (Primary), 94A29 (Secondary)</msc-class><acm-class>E.4; G.1.2</acm-class><journal-ref>IEEE Transactions on Information Theory, vol. 59, no. 9, pp.
  5842-5859, Sept. 2013</journal-ref><doi>10.1109/TIT.2013.2259292</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unique lifting factorization results for group lifting structures are used to
characterize the group-theoretic structure of two-channel linear phase FIR
perfect reconstruction filter bank groups. For D-invariant, order-increasing
group lifting structures, it is shown that the associated lifting cascade group
C is isomorphic to the free product of the upper and lower triangular lifting
matrix groups. Under the same hypotheses, the associated scaled lifting group S
is the semidirect product of C by the diagonal gain scaling matrix group D.
These results apply to the group lifting structures for the two principal
classes of linear phase perfect reconstruction filter banks, the whole- and
half-sample symmetric classes. Since the unimodular whole-sample symmetric
class forms a group, W, that is in fact equal to its own scaled lifting group,
W=S_W, the results of this paper characterize the group-theoretic structure of
W up to isomorphism. Although the half-sample symmetric class H does not form a
group, it can be partitioned into cosets of its lifting cascade group, C_H, or,
alternatively, into cosets of its scaled lifting group, S_H. Homomorphic
comparisons reveal that scaled lifting groups covered by the results in this
paper have a structure analogous to a &quot;noncommutative vector space.&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7666</identifier>
 <datestamp>2013-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7666</id><created>2013-09-29</created><updated>2013-10-24</updated><authors><author><keyname>P.</keyname><forenames>Sara Gholipour</forenames></author><author><keyname>Sh</keyname><forenames>Heydar Toosian</forenames></author></authors><title>Dynamic Sliding Mode Control based on Fractional calculus subject to
  uncertain delay based chaotic pneumatic robot</title><categories>cs.RO cs.SY</categories><comments>8 pages, 9 figures, will be submitted in journal</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers the chattering problem of sliding mode control while
delay in robot manipulator caused chaos in such electromechanical systems.
Fractional calculus as a powerful theorem to produce a novel sliding mode;
which has a dynamic essence is used for chattering elimination. To realize the
control of a class of chaotic systems in master-slave configuration this novel
fractional dynamic sliding mode control scheme is presented and examined on
delay based chaotic robot in joint and work space. Also the stability of the
closed-loop system is guaranteed by Lyapunov stability theory. Beside these,
delayed robot motions are sorted out for qualitative and quantification study.
Finally, numerical simulation example illustrates the feasibility of proposed
control method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7669</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7669</id><created>2013-09-29</created><authors><author><keyname>Voroninski</keyname><forenames>Vladislav</forenames></author></authors><title>Quantum Tomography From Few Full-Rank Observables</title><categories>math-ph cs.IT math.IT math.MP math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish that the PhaseLift algorithm recovers pure states from a
constant number of full-rank observables with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7676</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7676</id><created>2013-09-29</created><authors><author><keyname>Christiansen</keyname><forenames>Eric</forenames></author></authors><title>An upper bound on prototype set size for condensed nearest neighbor</title><categories>cs.LG stat.ML</categories><comments>This was submitted to the journal Artificial Intelligence in 2009,
  and while it was considered technically sound, it was also believed to be of
  minor importance. My research has since moved on, so I'm unlikely to attempt
  a resubmission</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The condensed nearest neighbor (CNN) algorithm is a heuristic for reducing
the number of prototypical points stored by a nearest neighbor classifier,
while keeping the classification rule given by the reduced prototypical set
consistent with the full set. I present an upper bound on the number of
prototypical points accumulated by CNN. The bound originates in a bound on the
number of times the decision rule is updated during training in the multiclass
perceptron algorithm, and thus is independent of training set size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7685</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7685</id><created>2013-09-29</created><authors><author><keyname>P</keyname><forenames>Saravana Perumal</forenames></author><author><keyname>Karkare</keyname><forenames>Amey</forenames></author></authors><title>Retargeting GCC: Do We Reinvent the Wheel Every Time?</title><categories>cs.PL cs.SE</categories><comments>4 pages, accepted at The Second Asia-Pacific Programming Languages
  and Compilers Workshop (APPLC), Shenzen, China, Feb 2013</comments><acm-class>D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Porting GCC to new architecture requires writing a Machine Description (MD)
file that contains mapping from GCC's intermediate form to the target assembly
code. Constructing an MD file is a difficult task because it requires the user
to understand both (a) the internals of GCC, and (b) the intricacies of the
target architecture. Instruction sets of different architectures exhibit
significant amount of semantic similarities across a large class (for example,
the instruction sets for RISC architectures) and differ only in syntax.
Therefore, it is expected that MD files of machines with similar architectures
should also have similarities. To confirm our hypothesis, we created
&quot;mdcompare&quot;, a tool to (a) extract RTL patterns (machine independent
abstraction of RTL templates) from MD files of well known architectures and (b)
compare the similarity of patterns across architectures. The results are
encouraging; we found that 28% -- 70% RTL expressions are similar across pairs
of MD files, the similarity percentage being on the higher side for pairs of
similar architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7686</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7686</id><created>2013-09-29</created><authors><author><keyname>Damiani</keyname><forenames>Chiara</forenames><affiliation>Dept. of Informatics, Systems and Communication, University of Milan Bicocca, Italy</affiliation></author><author><keyname>Filisetti</keyname><forenames>Alessandro</forenames><affiliation>European Centre for Living Technology, University Ca' Foscari of Venice, Italy</affiliation></author><author><keyname>Graudenzi</keyname><forenames>Alex</forenames><affiliation>Dept. of Informatics, Systems and Communication, University of Milan Bicocca, Italy</affiliation></author><author><keyname>Villani</keyname><forenames>Marco</forenames><affiliation>Dept. of Physics, Informatics and Mathematics, Modena and Reggio Emilia University</affiliation></author><author><keyname>Serra</keyname><forenames>Roberto</forenames><affiliation>Dept. of Physics, Informatics and Mathematics, Modena and Reggio Emilia University</affiliation></author></authors><title>Recent developments in research on catalytic reaction networks</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 3-13</journal-ref><doi>10.4204/EPTCS.130.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last years, analyses performed on a stochastic model of catalytic
reaction networks have provided some indications about the reasons why wet-lab
experiments hardly ever comply with the phase transition typically predicted by
theoretical models with regard to the emergence of collectively
self-replicating sets of molecule (also defined as autocatalytic sets, ACSs), a
phenomenon that is often observed in nature and that is supposed to have played
a major role in the emergence of the primitive forms of life. The model at
issue has allowed to reveal that the emerging ACSs are characterized by a
general dynamical fragility, which might explain the difficulty to observe them
in lab experiments. In this work, the main results of the various analyses are
reviewed, with particular regard to the factors able to affect the generic
properties of catalytic reactions network, for what concerns, not only the
probability of ACSs to be observed, but also the overall activity of the
system, in terms of production of new species, reactions and matter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7687</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7687</id><created>2013-09-29</created><authors><author><keyname>Rampioni</keyname><forenames>Giordano</forenames><affiliation>Science Dept. University Roma Tre</affiliation></author><author><keyname>Damiano</keyname><forenames>Luisa</forenames><affiliation>Univ. Bergamo</affiliation></author><author><keyname>Messina</keyname><forenames>Marco</forenames><affiliation>Science Dept. University Roma Tre</affiliation></author><author><keyname>D'Angelo</keyname><forenames>Francesca</forenames><affiliation>Science Dept. University Roma Tre</affiliation></author><author><keyname>Leoni</keyname><forenames>Livia</forenames><affiliation>Science Dept. University Roma Tre</affiliation></author><author><keyname>Stano</keyname><forenames>Pasquale</forenames><affiliation>Science Dept. University Roma Tre</affiliation></author></authors><title>Chemical communication between synthetic and natural cells: a possible
  experimental design</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 14-26</journal-ref><doi>10.4204/EPTCS.130.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bottom-up construction of synthetic cells is one of the most intriguing
and interesting research arenas in synthetic biology. Synthetic cells are built
by encapsulating biomolecules inside lipid vesicles (liposomes), allowing the
synthesis of one or more functional proteins. Thanks to the in situ synthesized
proteins, synthetic cells become able to perform several biomolecular
functions, which can be exploited for a large variety of applications. This
paves the way to several advanced uses of synthetic cells in basic science and
biotechnology, thanks to their versatility, modularity, biocompatibility, and
programmability. In the previous WIVACE (2012) we presented the
state-of-the-art of semi-synthetic minimal cell (SSMC) technology and
introduced, for the first time, the idea of chemical communication between
synthetic cells and natural cells. The development of a proper synthetic
communication protocol should be seen as a tool for the nascent field of
bio/chemical-based Information and Communication Technologies (bio-chem-ICTs)
and ultimately aimed at building soft-wet-micro-robots. In this contribution
(WIVACE, 2013) we present a blueprint for realizing this project, and show some
preliminary experimental results. We firstly discuss how our research goal
(based on the natural capabilities of biological systems to manipulate chemical
signals) finds a proper place in the current scientific and technological
contexts. Then, we shortly comment on the experimental approaches from the
viewpoints of (i) synthetic cell construction, and (ii) bioengineering of
microorganisms, providing up-to-date results from our laboratory. Finally, we
shortly discuss how autopoiesis can be used as a theoretical framework for
defining synthetic minimal life, minimal cognition, and as bridge between
synthetic biology and artificial intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7688</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7688</id><created>2013-09-29</created><authors><author><keyname>Fontana</keyname><forenames>Alessandro</forenames><affiliation>Adam Mickiewicz University</affiliation></author><author><keyname>Wr&#xf3;bel</keyname><forenames>Borys</forenames><affiliation>Adam Mickiewicz University</affiliation></author></authors><title>Evolution and development of complex computational systems using the
  paradigm of metabolic computing in Epigenetic Tracking</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 27-34</journal-ref><doi>10.4204/EPTCS.130.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epigenetic Tracking (ET) is an Artificial Embryology system which allows for
the evolution and development of large complex structures built from artificial
cells. In terms of the number of cells, the complexity of the bodies generated
with ET is comparable with the complexity of biological organisms. We have
previously used ET to simulate the growth of multicellular bodies with
arbitrary 3-dimensional shapes which perform computation using the paradigm of
&quot;metabolic computing&quot;. In this paper we investigate the memory capacity of such
computational structures and analyse the trade-off between shape and
computation. We now plan to build on these foundations to create a
biologically-inspired model in which the encoding of the phenotype is efficient
(in terms of the compactness of the genome) and evolvable in tasks involving
non-trivial computation, robust to damage and capable of self-maintenance and
self-repair.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7689</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7689</id><created>2013-09-29</created><authors><author><keyname>Maggiolo-Schettini</keyname><forenames>Andrea</forenames><affiliation>Dipartimento di Informatica - Universit&#xe0; di Pisa</affiliation></author><author><keyname>Milazzo</keyname><forenames>Paolo</forenames><affiliation>Dipartimento di Informatica - Universit&#xe0; di Pisa</affiliation></author><author><keyname>Pardini</keyname><forenames>Giovanni</forenames><affiliation>Dipartimento di Informatica - Universit&#xe0; di Pisa</affiliation></author></authors><title>Application of a Semi-automatic Algorithm for Identification of
  Molecular Components in SBML Models</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 43-52</journal-ref><doi>10.4204/EPTCS.130.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reactions forming a pathway can be rewritten by making explicit the different
molecular components involved in them. A molecular component represents a
biological entity (e.g. a protein) in all its states (free, bound, degraded,
etc.). In this paper we show the application of a component identification
algorithm to a number of real-world models to experimentally validate the
approach. Components identification allows subpathways to be computed to better
understand the pathway functioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7690</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7690</id><created>2013-09-29</created><authors><author><keyname>Citrolo</keyname><forenames>Andrea G.</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>Mauri</keyname><forenames>Giancarlo</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author></authors><title>A Hybrid Monte Carlo Ant Colony Optimization Approach for Protein
  Structure Prediction in the HP Model</title><categories>cs.NE cs.CE</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 61-69</journal-ref><doi>10.4204/EPTCS.130.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hydrophobic-polar (HP) model has been widely studied in the field of
protein structure prediction (PSP) both for theoretical purposes and as a
benchmark for new optimization strategies. In this work we introduce a new
heuristics based on Ant Colony Optimization (ACO) and Markov Chain Monte Carlo
(MCMC) that we called Hybrid Monte Carlo Ant Colony Optimization (HMCACO). We
describe this method and compare results obtained on well known HP instances in
the 3 dimensional cubic lattice to those obtained with standard ACO and
Simulated Annealing (SA). All methods were implemented using an unconstrained
neighborhood and a modified objective function to prevent the creation of
overlapping walks. Results show that our methods perform better than the other
heuristics in all benchmark instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7691</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7691</id><created>2013-09-29</created><authors><author><keyname>Serra</keyname><forenames>Roberto</forenames><affiliation>University of Modena and Reggio Emilia</affiliation></author><author><keyname>Filisetti</keyname><forenames>Alessandro</forenames><affiliation>European Centre for Living Technology</affiliation></author><author><keyname>Graudenzi</keyname><forenames>Alex</forenames><affiliation>Department of Informatics, Systems and Communication University of Milan Bicocca</affiliation></author><author><keyname>Damiani</keyname><forenames>Chiara</forenames><affiliation>Department of Informatics, Systems and Communication University of Milan Bicocca</affiliation></author><author><keyname>Villani</keyname><forenames>Marco</forenames><affiliation>University of Modena and Reggio Emilia</affiliation></author></authors><title>A model of protocell based on the introduction of a semi-permeable
  membrane in a stochastic model of catalytic reaction networks</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 70-73</journal-ref><doi>10.4204/EPTCS.130.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce some preliminary analyses on the role of a
semi-permeable membrane in the dynamics of a stochastic model of catalytic
reaction sets (CRSs) of molecules. The results of the simulations performed on
ensembles of randomly generated reaction schemes highlight remarkable
differences between this very simple protocell description model and the
classical case of the continuous stirred-tank reactor (CSTR). In particular, in
the CSTR case, distinct simulations with the same reaction scheme reach the
same dynamical equilibrium, whereas, in the protocell case, simulations with
identical reaction schemes can reach very different dynamical states, despite
starting from the same initial conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7692</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7692</id><created>2013-09-29</created><authors><author><keyname>Ramazzotti</keyname><forenames>Daniele</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>Maj</keyname><forenames>Carlo</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>Antoniotti</keyname><forenames>Marco</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author></authors><title>A Model of Colonic Crypts using SBML Spatial</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 74-78</journal-ref><doi>10.4204/EPTCS.130.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Spatial Processes package enables an explicit definition of a spatial
environment on top of the normal dynamic modeling SBML capabilities. The
possibility of an explicit representation of spatial dynamics increases the
representation power of SBML. In this work we used those new SBML features to
define an extensive model of colonic crypts composed of the main cellular types
(from stem cells to fully differentiated cells), alongside their spatial
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7693</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7693</id><created>2013-09-29</created><authors><author><keyname>Caravagna</keyname><forenames>Giulio</forenames><affiliation>Dipartimento di Informatica, Sistemistica e Comunicazione, Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>Graudenzi</keyname><forenames>Alex</forenames><affiliation>Dipartimento di Informatica, Sistemistica e Comunicazione, Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>Antoniotti</keyname><forenames>Marco</forenames><affiliation>Dipartimento di Informatica, Sistemistica e Comunicazione, Universit&#xe0; degli Studi di Milano-Bicocca</affiliation></author><author><keyname>de Matteis</keyname><forenames>Giovanni</forenames><affiliation>Department of Mathematics and Information Sciences, Northumbria University, Pandon Building, Camden Street, Newcastle Upon Tyne, England, U.K.</affiliation></author></authors><title>Analysis of the spatial and dynamical properties of a multiscale model
  of intestinal crypts</title><categories>cs.CE cs.CG cs.DM q-bio.CB</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 79-82</journal-ref><doi>10.4204/EPTCS.130.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The preliminary analyses on a multiscale model of intestinal crypt dynamics
are here presented. The model combines a morphological model, based on the
Cellular Potts Model (CPM), and a gene regulatory network model, based on Noisy
Random Boolean Networks (NRBNs). Simulations suggest that the stochastic
differentiation process is itself sufficient to ensure the general homeostasis
in the asymptotic states, as proven by several measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7694</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7694</id><created>2013-09-29</created><authors><author><keyname>Fraccalvieri</keyname><forenames>Domenico</forenames><affiliation>Department of Earth and Environmental Sciences, University of Milano Bicocca, Milano IT</affiliation></author><author><keyname>Bonati</keyname><forenames>Laura</forenames><affiliation>Department of Earth and Environmental Sciences, University of Milano Bicocca, Milano IT</affiliation></author><author><keyname>Stella</keyname><forenames>Fabio</forenames><affiliation>Department of Informatics, Systems and Communication, University of Milano Bicocca, Milano IT</affiliation></author></authors><title>Self Organizing Maps to efficiently cluster and functionally interpret
  protein conformational ensembles</title><categories>cs.CE q-bio.BM</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 83-86</journal-ref><doi>10.4204/EPTCS.130.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approach that combines Self-Organizing maps, hierarchical clustering and
network components is presented, aimed at comparing protein conformational
ensembles obtained from multiple Molecular Dynamic simulations. As a first
result the original ensembles can be summarized by using only the
representative conformations of the clusters obtained. In addition the network
components analysis allows to discover and interpret the dynamic behavior of
the conformations won by each neuron. The results showed the ability of this
approach to efficiently derive a functional interpretation of the protein
dynamics described by the original conformational ensemble, highlighting its
potential as a support for protein engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7695</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7695</id><created>2013-09-29</created><authors><author><keyname>Besozzi</keyname><forenames>Daniela</forenames><affiliation>University of Milano</affiliation></author><author><keyname>Caravagna</keyname><forenames>Giulio</forenames><affiliation>University of Milano Bicocca</affiliation></author><author><keyname>Cazzaniga</keyname><forenames>Paolo</forenames><affiliation>University of Bergamo</affiliation></author><author><keyname>Nobile</keyname><forenames>Marco</forenames><affiliation>University of Milano Bicocca</affiliation></author><author><keyname>Pescini</keyname><forenames>Dario</forenames><affiliation>University of Milano Bicocca</affiliation></author><author><keyname>Re</keyname><forenames>Alessandro</forenames><affiliation>University of Milano Bicocca</affiliation></author></authors><title>GPU-powered Simulation Methodologies for Biological Systems</title><categories>cs.CE cs.DC</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 87-91</journal-ref><doi>10.4204/EPTCS.130.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of biological systems witnessed a pervasive cross-fertilization
between experimental investigation and computational methods. This gave rise to
the development of new methodologies, able to tackle the complexity of
biological systems in a quantitative manner. Computer algorithms allow to
faithfully reproduce the dynamics of the corresponding biological system, and,
at the price of a large number of simulations, it is possible to extensively
investigate the system functioning across a wide spectrum of natural
conditions. To enable multiple analysis in parallel, using cheap, diffused and
highly efficient multi-core devices we developed GPU-powered simulation
algorithms for stochastic, deterministic and hybrid modeling approaches, so
that also users with no knowledge of GPUs hardware and programming can easily
access the computing power of graphics engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7696</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7696</id><created>2013-09-29</created><authors><author><keyname>Damiani</keyname><forenames>Chiara</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Biotecnologie e Bioscienze Piazza della Scienza, Italy</affiliation></author><author><keyname>Colombo</keyname><forenames>Riccardo</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Biotecnologie e Bioscienze Piazza della Scienza, Italy</affiliation></author><author><keyname>Molinari</keyname><forenames>Sara</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Biotecnologie e Bioscienze Piazza della Scienza, Italy</affiliation></author><author><keyname>Pescini</keyname><forenames>Dario</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Statistica e Metodi Quantitativi Via Bicocca degli Arcimboldi, Italy</affiliation></author><author><keyname>Gaglio</keyname><forenames>Daniela</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Biotecnologie e Bioscienze Piazza della Scienza, Italy</affiliation></author><author><keyname>Vanoni</keyname><forenames>Marco</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Biotecnologie e Bioscienze Piazza della Scienza, Italy</affiliation></author><author><keyname>Alberghina</keyname><forenames>Lilia</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Biotecnologie e Bioscienze Piazza della Scienza, Italy</affiliation></author><author><keyname>Mauri</keyname><forenames>Giancarlo</forenames><affiliation>Universit&#xe0; degli Studi di Milano-Bicocca, Dipartimento di Biotecnologie e Bioscienze Piazza della Scienza, Italy</affiliation></author></authors><title>An ensemble approach to the study of the emergence of metabolic and
  proliferative disorders via Flux Balance Analysis</title><categories>cs.CE q-bio.MN</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 92-97</journal-ref><doi>10.4204/EPTCS.130.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An extensive rewiring of cell metabolism supports enhanced proliferation in
cancer cells. We propose a systems level approach to describe this phenomenon
based on Flux Balance Analysis (FBA). The approach does not explicit a cell
biomass formation reaction to be maximized, but takes into account an ensemble
of alternative flux distributions that match the cancer metabolic rewiring
(CMR) phenotype description. The underlying concept is that the analysis the
common/distinguishing properties of the ensemble can provide indications on how
CMR is achieved and sustained and thus on how it can be controlled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7697</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7697</id><created>2013-09-29</created><authors><author><keyname>Colombo</keyname><forenames>Gianluca</forenames><affiliation>Technological Transfer Consortium - C2T, Milan, Italy</affiliation></author><author><keyname>Colombo</keyname><forenames>Ettore</forenames><affiliation>Technological Transfer Consortium - C2T, Milan, Italy</affiliation></author><author><keyname>Bonomi</keyname><forenames>Andrea</forenames><affiliation>Technological Transfer Consortium - C2T, Milan, Italy</affiliation></author><author><keyname>Mosca</keyname><forenames>Alessandro</forenames><affiliation>KRDB Research Centre - Free University of Bozen-Bolzano, Italy</affiliation></author><author><keyname>Bassis</keyname><forenames>Simone</forenames><affiliation>Department of Computer Science - University of Milano, Italy</affiliation></author></authors><title>Semi-structured data extraction and modelling: the WIA Project</title><categories>cs.SE cs.CY cs.NE</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><acm-class>H3; I.2; H.1.2</acm-class><journal-ref>EPTCS 130, 2013, pp. 98-103</journal-ref><doi>10.4204/EPTCS.130.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decades, the amount of data of all kinds available
electronically has increased dramatically. Data are accessible through a range
of interfaces including Web browsers, database query languages,
application-specific interfaces, built on top of a number of different data
exchange formats. All these data span from un-structured to highly structured
data. Very often, some of them have structure even if the structure is
implicit, and not as rigid or regular as that found in standard database
systems. Spreadsheet documents are prototypical in this respect. Spreadsheets
are the lightweight technology able to supply companies with easy to build
business management and business intelligence applications, and business people
largely adopt spreadsheets as smart vehicles for data files generation and
sharing. Actually, the more spreadsheets grow in complexity (e.g., their use in
product development plans and quoting), the more their arrangement,
maintenance, and analysis appear as a knowledge-driven activity. The
algorithmic approach to the problem of automatic data structure extraction from
spreadsheet documents (i.e., grid-structured and free topological-related data)
emerges from the WIA project: Worksheets Intelligent Analyser. The
WIA-algorithm shows how to provide a description of spreadsheet contents in
terms of higher level of abstractions or conceptualisations. In particular, the
WIA-algorithm target is about the extraction of i) the calculus work-flow
implemented in the spreadsheets formulas and ii) the logical role played by the
data which take part into the calculus. The aim of the resulting
conceptualisations is to provide spreadsheets with abstract representations
useful for further model refinements and optimizations through evolutionary
algorithms computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7698</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7698</id><created>2013-09-29</created><authors><author><keyname>Righi</keyname><forenames>Simone</forenames><affiliation>MTA TK &quot;Lend&#xfc;let&quot; Research Center for Educational and Network studies</affiliation></author><author><keyname>Tak&#xe1;cs</keyname><forenames>K&#xe1;roly</forenames><affiliation>MTA TK &quot;Lend&#xfc;let&quot; Research Center for Educational and Network studies</affiliation></author></authors><title>Signed Networks, Triadic Interactions and the Evolution of Cooperation</title><categories>cs.SI cs.GT cs.NE physics.soc-ph</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 104-107</journal-ref><doi>10.4204/EPTCS.130.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We outline a model to study the evolution of cooperation in a population of
agents playing the prisoner's dilemma in signed networks. We highlight that if
only dyadic interactions are taken into account, cooperation never evolves.
However, when triadic considerations are introduced, a window of opportunity
for emergence of cooperation as a stable behaviour emerges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7702</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7702</id><created>2013-09-29</created><authors><author><keyname>Massaro</keyname><forenames>Emanuele</forenames><affiliation>Universit&#xe0; degli studi di Firenze</affiliation></author><author><keyname>Olsson</keyname><forenames>Henrik</forenames><affiliation>Max Planck Institute for Human Development</affiliation></author><author><keyname>Guazzini</keyname><forenames>Andrea</forenames><affiliation>Universit&#xe0; degli studi di Firenze</affiliation></author><author><keyname>Bagnoli</keyname><forenames>Franco</forenames><affiliation>Universit&#xe0; degli studi di Firenze</affiliation></author></authors><title>Impact of local information in growing networks</title><categories>cs.SI physics.soc-ph</categories><comments>In Proceedings Wivace 2013, arXiv:1309.7122</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 130, 2013, pp. 53-60</journal-ref><doi>10.4204/EPTCS.130.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new model of the evolutionary dynamics and the growth of on-line
social networks. The model emulates people's strategies for acquiring
information in social networks, emphasising the local subjective view of an
individual and what kind of information the individual can acquire when
arriving in a new social context. The model proceeds through two phases: (a) a
discovery phase, in which the individual becomes aware of the surrounding world
and (b) an elaboration phase, in which the individual elaborates locally the
information trough a cognitive-inspired algorithm. Model generated networks
reproduce main features of both theoretical and real-world networks, such as
high clustering coefficient, low characteristic path length, strong division in
communities, and variability of degree distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7712</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7712</id><created>2013-09-29</created><updated>2014-03-23</updated><authors><author><keyname>Choi</keyname><forenames>Junil</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Bidigare</keyname><forenames>Patrick</forenames></author></authors><title>Downlink Training Techniques for FDD Massive MIMO Systems: Open-Loop and
  Closed-Loop Training with Memory</title><categories>cs.IT math.IT</categories><comments>13 pages, 16 figures, to appear in IEEE Journal of Selected Topics in
  Signal Processing on Signal Processing for Large-Scale MIMO Communications</comments><doi>10.1109/JSTSP.2014.2313020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of deploying a large number of antennas at the base station,
often called massive multiple-input multiple-output (MIMO), has drawn
considerable interest because of its potential ability to revolutionize current
wireless communication systems. Most literature on massive MIMO systems assumes
time division duplexing (TDD), although frequency division duplexing (FDD)
dominates current cellular systems. Due to the large number of transmit
antennas at the base station, currently standardized approaches would require a
large percentage of the precious downlink and uplink resources in FDD massive
MIMO be used for training signal transmissions and channel state information
(CSI) feedback. To reduce the overhead of the downlink training phase, we
propose practical open-loop and closed-loop training frameworks in this paper.
We assume the base station and the user share a common set of training signals
in advance. In open-loop training, the base station transmits training signals
in a round-robin manner, and the user successively estimates the current
channel using long-term channel statistics such as temporal and spatial
correlations and previous channel estimates. In closed-loop training, the user
feeds back the best training signal to be sent in the future based on channel
prediction and the previously received training signals. With a small amount of
feedback from the user to the base station, closed-loop training offers better
performance in the data communication phase, especially when the
signal-to-noise ratio is low, the number of transmit antennas is large, or
prior channel estimates are not accurate at the beginning of the communication
setup, all of which would be mostly beneficial for massive MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7713</identifier>
 <datestamp>2014-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7713</id><created>2013-09-29</created><updated>2014-03-05</updated><authors><author><keyname>Wang</keyname><forenames>Guoming</forenames></author></authors><title>Span-program-based quantum algorithm for tree detection</title><categories>quant-ph cs.CC cs.DS</categories><comments>24 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Span program is a linear-algebraic model of computation originally proposed
for studying the complexity theory. Recently, it has become a useful tool for
designing quantum algorithms. In this paper, we present a time-efficient
span-program-based quantum algorithm for the following problem. Let $T$ be an
arbitrary tree. Given query access to the adjacency matrix of a graph $G$ with
$n$ vertices, we need to determine whether $G$ contains $T$ as a subgraph, or
$G$ does not contain $T$ as a minor, under the promise that one of these cases
holds. We call this problem the subgraph/not-a-minor problem for $T$. We show
that this problem can be solved by a bounded-error quantum algorithm with
$O(n)$ query complexity and $\tilde{O}(n)$ time complexity. The query
complexity is optimal, and the time complexity is tight up to polylog factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7720</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7720</id><created>2013-09-30</created><authors><author><keyname>Ishikawa</keyname><forenames>Ken-ichiro</forenames></author></authors><title>ASURA: Scalable and Uniform Data Distribution Algorithm for Storage
  Clusters</title><categories>cs.DC</categories><comments>I post this article to IEEE TPDS simultaneously</comments><acm-class>D.4.7; E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale storage cluster systems need to manage a vast amount of
information denoting combinations of data identifiers (IDs) and corresponding
nodes that store the data. Management using data distribution algorithms,
rather than management using tables, has been proposed in recent research. In
algorithm management, data are distributed in accordance with a data
distribution algorithm that is capable of determining, on the basis of the
datum ID, the node in which the required data is being stored. Among the
requirements for a data distribution algorithm are short calculation times, low
memory consumption, uniform data distribution in accordance with the capacity
of each node and the ability to handle the addition or removal of nodes. This
paper presents a data distribution algorithm called ASURA (Advanced Scalable
and Uniform storage by Random number Algorithm), which satisfies these
requirements. It offers roughly 0.6-{\mu}s calculation time, kilobyte-order
memory consumption, less than 1% maximum variability between nodes in data
distribution, data distribution in accordance with the capacity of each node
and optimal data movement to maintain data distribution in accordance with node
capacity when nodes are added or removed. ASURA is contrasted in this paper
qualitatively and quantitatively with representative data distribution
algorithms: Consistent Hashing and Straw Buckets in CRUSH. The comparison
results show that ASURA can achieve the same storage cluster capacity as
Consistent Hashing with dozens fewer nodes by virtue of the uniformity of its
distribution with the same level calculation time. They also show that the
execution time of ASURA is shorter than that of Straw Buckets in CRUSH. The
results reveal that ASURA is the best algorithm for large-scale storage cluster
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7723</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7723</id><created>2013-09-30</created><authors><author><keyname>Ickowicz</keyname><forenames>Adrien</forenames></author><author><keyname>Cadre</keyname><forenames>Jean-Pierre Le</forenames></author></authors><title>On the Effect of Data Contamination on Track Purity</title><categories>cs.IT math.IT</categories><comments>15 pages, dc, 11 figures. To appear in IEEE Transactions on Aerospace
  and Electronic Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with performance analysis for data association, in a
target tracking environment. Effects of misassociation are considered in a
simple (linear) multiscan framework so as to provide closed-form expressions of
the probability of correct association. In this paper, we focus on the
development of explicit approximations of this probability. Via rigorous
calculations the effect of dimensioning parameters (number of scans, false
measurement positions or densities) is analyzed, for various modelings of the
false measurements. Remarkably, it is possible to derive very simple
expressions of the probability of correct association which are independent of
the scenario kinematic parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7724</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7724</id><created>2013-09-30</created><updated>2013-12-15</updated><authors><author><keyname>Chen</keyname><forenames>Alex</forenames></author><author><keyname>Chu</keyname><forenames>Timothy</forenames></author><author><keyname>Pinsker</keyname><forenames>Nathan</forenames></author></authors><title>The Dynamic Longest Increasing Subsequence Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we construct a data structure to efficiently compute the
longest increasing subsequence of a sequence subject to dynamic updates. Our
data structure supports a query for the longest increasing subsequence in
$O(r+\log n)$ worst-case time and supports inserts anywhere in the sequence in
$O \left(r\log{n/r}\right)$ worst-case time (where $r$ is the length of the
longest increasing subsequence). The same data structure with a minor
modification supports $O(\log n)$ worst-case time insertions if the insertions
are performed at the end of the sequence. The data structure presented can also
be augmented to support delete operations in the same worst-case time as
insertions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7731</identifier>
 <datestamp>2013-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7731</id><created>2013-09-30</created><updated>2013-10-25</updated><authors><author><keyname>Dvijotham</keyname><forenames>Krishnamurthy</forenames></author><author><keyname>Todorov</keyname><forenames>Emanuel</forenames></author><author><keyname>Fazel</keyname><forenames>Maryam</forenames></author></authors><title>Convex Structured Controller Design</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of synthesizing optimal linear feedback policies
subject to arbitrary convex constraints on the feedback matrix. This is known
to be a hard problem in the usual formulations ($\Htwo,\Hinf,\LQR$) and
previous works have focused on characterizing classes of structural constraints
that allow efficient solution through convex optimization or dynamic
programming techniques. In this paper, we propose a new control objective and
show that this formulation makes the problem of computing optimal linear
feedback matrices convex under arbitrary convex constraints on the feedback
matrix. This allows us to solve problems in decentralized control (sparsity in
the feedback matrices), control with delays and variable impedance control.
Although the control objective is nonstandard, we present theoretical and
empirical evidence that it agrees well with standard notions of control. We
also present an extension to nonlinear control affine systems. We present
numerical experiments validating our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7734</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7734</id><created>2013-09-30</created><authors><author><keyname>Zhang</keyname><forenames>Tao</forenames></author><author><keyname>Li</keyname><forenames>Shuxing</forenames></author><author><keyname>Feng</keyname><forenames>Tao</forenames></author><author><keyname>Ge</keyname><forenames>Gennian</forenames></author></authors><title>Some New Results on the Cross Correlation of $m$-sequences</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The determination of the cross correlation between an $m$-sequence and its
decimated sequence has been a long-standing research problem. Considering a
ternary $m$-sequence of period $3^{3r}-1$, we determine the cross correlation
distribution for decimations $d=3^{r}+2$ and $d=3^{2r}+2$, where $\gcd(r,3)=1$.
Meanwhile, for a binary $m$-sequence of period $2^{2lm}-1$, we make an initial
investigation for the decimation $d=\frac{2^{2lm}-1}{2^{m}+1}+2^{s}$, where $l
\ge 2$ is even and $0 \le s \le 2m-1$. It is shown that the cross correlation
takes at least four values. Furthermore, we confirm the validity of two famous
conjectures due to Sarwate et al. and Helleseth in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7735</identifier>
 <datestamp>2015-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7735</id><created>2013-09-30</created><updated>2015-05-24</updated><authors><author><keyname>Sun</keyname><forenames>Jiajun</forenames></author></authors><title>Long-Term Profit-Maximizing Incentive for Crowd Sensing in Mobile Social
  Networks</title><categories>cs.SI cs.GT cs.NI</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in Section 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowd sensing is a new paradigm that leverages pervasive sensor-equipped
mobile devices to provide sensing services like forensic analysis, documenting
public spaces, and collaboratively constructing statistical models. Extensive
user participation is indispensable for achieving good service quality.
Nowadays, most of existing mechanisms focus on guaranteeing good service
quality based on instantaneous extensive user participation for crowd sensing
applications. Little attention has been dedicated to maximizing long-term
service quality for crowd sensing applications due to their asymmetric
interests, preferences, selfish behaviors, etc. To fill these gaps, in this
paper, we derive the closed expression of the marginal sensing data quality
based on the monopoly aggregation in economics. Furthermore, we design
marginalquality based incentive mechanisms for long-term crowd sensing
applications, not only to enhance extensive user participation by maximizing
the expected total profits of mobile users, but also to stimulate mobile users
to produce high-quality contents by applying the marginal quality. Finally,
simulation results show that our mechanisms outperform the existing solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7739</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7739</id><created>2013-09-30</created><authors><author><keyname>Gruska</keyname><forenames>Jozef</forenames></author><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Zheng</keyname><forenames>Shenggen</forenames></author></authors><title>Communication complexity of promise problems and their applications to
  finite automata</title><categories>cs.CC cs.FL quant-ph</categories><comments>15 pages. arXiv admin note: text overlap with arXiv:1307.2499</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Equality and disjointness are two of the most studied problems in
communication complexity. They have been studied for both classical and also
quantum communication and for various models and modes of communication.
Buhrman et al. [Buh98] proved that the exact quantum communication complexity
for a promise version of the equality problem is ${\bf O}(\log {n})$ while the
classical deterministic communication complexity is $n+1$ for two-way
communication, which was the first impressively large (exponential) gap between
quantum and classical (deterministic and probabilistic) communication
complexity. If an error is tolerated, both quantum and probabilistic
communication complexities for equality are ${\bf O}(\log {n})$. However, even
if an error is tolerated, the gaps between quantum (probabilistic) and
deterministic complexity are not larger than quadratic for the disjointness
problem. It is therefore interesting to ask whether there are some promise
versions of the disjointness problem for which bigger gaps can be shown. We
give a positive answer to such a question. Namely, we prove that there exists
an exponential gap between quantum (even probabilistic) communication
complexity and classical deterministic communication complexity of some
specific versions of the disjointness problem.
  Klauck [Kla00] proved, for any language, that the state complexity of exact
quantum/classical finite automata, which is a general model of one-way quantum
finite automata, is not less than the state complexity of an equivalent one-way
deterministic finite automata (1DFA). In this paper we show, using a
communication complexity result, that situation may be different for some
promise problems. Namely, we show for certain promise problem that the gap
between the state complexity of exact one-way quantum finite automata and 1DFA
can be exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7747</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7747</id><created>2013-09-30</created><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>Research misconduct: definitions, manifestations and extent</title><categories>cs.CY cs.DL</categories><comments>Accepted for publication in publications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the international scientific community has been rocked by a
number of serious cases of research misconduct. In one of these, Woo Suk Hwang,
a Korean stem cell researcher published two articles on research with
ground-breaking results in Science in 2004 and 2005. Both articles were later
revealed to be fakes. This paper provides an overview of what research
misconduct is generally understood to be, its manifestations and the extent to
which they are thought to exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7750</identifier>
 <datestamp>2014-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7750</id><created>2013-09-30</created><updated>2014-02-11</updated><authors><author><keyname>Ougiaroglou</keyname><forenames>Stefanos</forenames></author><author><keyname>Evangelidis</keyname><forenames>Georgios</forenames></author><author><keyname>Dervos</keyname><forenames>Dimitris A.</forenames></author></authors><title>An Extensive Experimental Study on the Cluster-based Reference Set
  Reduction for speeding-up the k-NN Classifier</title><categories>cs.LG</categories><comments>Proceeding of International Conference on Integrated Information
  (IC-InInfo 2011), pp. 12-15, Kos island, Greece, 2011</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The k-Nearest Neighbor (k-NN) classification algorithm is one of the most
widely-used lazy classifiers because of its simplicity and ease of
implementation. It is considered to be an effective classifier and has many
applications. However, its major drawback is that when sequential search is
used to find the neighbors, it involves high computational cost. Speeding-up
k-NN search is still an active research field. Hwang and Cho have recently
proposed an adaptive cluster-based method for fast Nearest Neighbor searching.
The effectiveness of this method is based on the adjustment of three
parameters. However, the authors evaluated their method by setting specific
parameter values and using only one dataset. In this paper, an extensive
experimental study of this method is presented. The results, which are based on
five real life datasets, illustrate that if the parameters of the method are
carefully defined, one can achieve even better classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7776</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7776</id><created>2013-09-30</created><authors><author><keyname>Caullery</keyname><forenames>Florian</forenames></author></authors><title>A new large class of functions not APN infinitely often</title><categories>cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that there is no vectorial Boolean function of degree
4e, with e satisfaying certain conditions, which is APN over infinitely many
extensions of its field of definition. It is a new step in the proof of the
conjecture of Aubry, McGuire and Rodier
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7803</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7803</id><created>2013-09-30</created><authors><author><keyname>Bygi</keyname><forenames>Mojtaba Nouri</forenames></author><author><keyname>Ghodsi</keyname><forenames>Mohammad</forenames></author></authors><title>Near Optimal Line Segment Weak Visibility Queries in Simple Polygons</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of computing the weak visibility polygon
(WVP) of any query line segment pq (or WVP(pq)) inside a given simple polygon
P. We present an algorithm that preprocesses P and creates a data structure
from which WVP(pq) is efficiently reported in an output sensitive manner.
  Our algorithm needs O(n^2 log n) time and O(n^2) space in the preprocessing
phase to report WVP(pq) of any query line segment pq in time O(log^2 n +
|WVP(pq)|). We improve the preprocessing time and space of current results for
this problem at the expense of more query time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7804</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7804</id><created>2013-09-30</created><authors><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>On statistics, computation and scalability</title><categories>stat.ML cs.LG math.ST stat.TH</categories><comments>Published in at http://dx.doi.org/10.3150/12-BEJSP17 the Bernoulli
  (http://isi.cbs.nl/bernoulli/) by the International Statistical
  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)</comments><proxy>vtex</proxy><report-no>IMS-BEJ-BEJSP17</report-no><journal-ref>Bernoulli 2013, Vol. 19, No. 4, 1378-1390</journal-ref><doi>10.3150/12-BEJSP17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How should statistical procedures be designed so as to be scalable
computationally to the massive datasets that are increasingly the norm? When
coupled with the requirement that an answer to an inferential question be
delivered within a certain time budget, this question has significant
repercussions for the field of statistics. With the goal of identifying
&quot;time-data tradeoffs,&quot; we investigate some of the statistical consequences of
computational perspectives on scability, in particular divide-and-conquer
methodology and hierarchies of convex relaxations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7817</identifier>
 <datestamp>2015-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7817</id><created>2013-09-30</created><updated>2015-07-10</updated><authors><author><keyname>Lim</keyname><forenames>Yeon-Geun</forenames></author><author><keyname>Chae</keyname><forenames>Chan-Byoung</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Performance Analysis of Massive MIMO for Cell-Boundary Users</title><categories>cs.IT math.IT</categories><comments>accepted at IEEE Transaction on Wireless Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider massive multiple-input multiple-output (MIMO)
systems for both downlink and uplink scenarios, where three radio units (RUs)
connected via one digital unit (DU) support multiple user equipments (UEs) at
the cell-boundary through the same radio resource, i.e., the same
time-frequency slot. For downlink transmitter options, the study considers
zero-forcing (ZF) and maximum ratio transmission (MRT), while for uplink
receiver options it considers ZF and maximum ratio combining (MRC). For the sum
rate of each of these, we derive simple closed-form formulas. In the simple but
practically relevant case where uniform power is allocated to all downlink data
streams, we observe that, for the downlink, vector normalization is better for
ZF while matrix normalization is better for MRT. For a given antenna and user
configuration, we also derive analytically the signal-to-noise-ratio (SNR)
level below which MRC should be used instead of ZF. Numerical simulations
confirm our analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7818</identifier>
 <datestamp>2015-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7818</id><created>2013-09-30</created><authors><author><keyname>Berhault</keyname><forenames>Guillaume</forenames></author><author><keyname>Leroux</keyname><forenames>Camille</forenames></author><author><keyname>Jego</keyname><forenames>Christophe</forenames></author><author><keyname>Dallet</keyname><forenames>Dominique</forenames></author></authors><title>Partial Sums Generation Architecture for Successive Cancellation
  Decoding of Polar Codes</title><categories>cs.AR</categories><comments>Submitted to IEEE Workshop on Signal Processing Systems (SiPS)(26
  April 2012). Accepted (28 June 2013)</comments><doi>10.1109/SiPS.2013.6674541</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar codes are a new family of error correction codes for which efficient
hardware architectures have to be defined for the encoder and the decoder.
Polar codes are decoded using the successive cancellation decoding algorithm
that includes partial sums computations. We take advantage of the recursive
structure of polar codes to introduce an efficient partial sums computation
unit that can also implements the encoder. The proposed architecture is
synthesized for several codelengths in 65nm ASIC technology. The area of the
resulting design is reduced up to 26% and the maximum working frequency is
improved by ~25%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7823</identifier>
 <datestamp>2014-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7823</id><created>2013-09-30</created><updated>2014-08-29</updated><authors><author><keyname>Lansky</keyname><forenames>Petr</forenames></author><author><keyname>Polito</keyname><forenames>Federico</forenames></author><author><keyname>Sacerdote</keyname><forenames>Laura</forenames></author></authors><title>The role of detachment of in-links in scale-free networks</title><categories>math.PR cs.IT math.IT</categories><journal-ref>Journal of Physics A: Mathematical and Theoretical, Vol. 37, art.
  345002, 2014</journal-ref><doi>10.1088/1751-8113/47/34/345002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-world networks may exhibit detachment phenomenon determined by the
cancelling of previously existing connections. We discuss a tractable extension
of Yule model to account for this feature. Analytical results are derived and
discussed both asymptotically and for a finite number of links. Comparison with
the original model is performed in the supercritical case. The first-order
asymptotic tail behavior of the two models is similar but differences arise in
the second-order term. We explicitly refer to World Wide Web modeling and we
show the agreement of the proposed model on very recent data. However, other
possible network applications are also mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7824</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7824</id><created>2013-09-30</created><authors><author><keyname>Ioannidis</keyname><forenames>Stratis</forenames></author><author><keyname>Loiseau</keyname><forenames>Patrick</forenames></author></authors><title>Linear Regression as a Non-Cooperative Game</title><categories>cs.GT cs.LG math.ST stat.TH</categories><comments>Full version of WINE 2013 paper with the same title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear regression amounts to estimating a linear model that maps features
(e.g., age or gender) to corresponding data (e.g., the answer to a survey or
the outcome of a medical exam). It is a ubiquitous tool in experimental
sciences. We study a setting in which features are public but the data is
private information. While the estimation of the linear model may be useful to
participating individuals, (if, e.g., it leads to the discovery of a treatment
to a disease), individuals may be reluctant to disclose their data due to
privacy concerns. In this paper, we propose a generic game-theoretic model to
express this trade-off. Users add noise to their data before releasing it. In
particular, they choose the variance of this noise to minimize a cost
comprising two components: (a) a privacy cost, representing the loss of privacy
incurred by the release; and (b) an estimation cost, representing the
inaccuracy in the linear model estimate. We study the Nash equilibria of this
game, establishing the existence of a unique non-trivial equilibrium. We
determine its efficiency for several classes of privacy and estimation costs,
using the concept of the price of stability. Finally, we prove that, for a
specific estimation cost, the generalized least-square estimator is optimal
among all linear unbiased estimators in our non-cooperative setting: this
result extends the famous Aitken/Gauss-Markov theorem in statistics,
establishing that its conclusion persists even in the presence of strategic
individuals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7828</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7828</id><created>2013-09-30</created><updated>2013-10-07</updated><authors><author><keyname>Harase</keyname><forenames>Shin</forenames></author><author><keyname>Ohori</keyname><forenames>Ryuichi</forenames></author></authors><title>A search for extensible low-WAFOM point sets</title><categories>math.NA cs.NA</categories><comments>14 pages</comments><msc-class>65D30, 65D32, 65C05, 11K38</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matsumoto, Saito, and Matoba recently proposed the Walsh figure of merit
(WAFOM), which is a computable criterion of quasi-Monte Carlo point sets
constructed by digital nets. Matsumoto et al. also showed that the
computational complexity is reduced for a special subclass of digital nets, and
obtained concrete examples of low-WAFOM point sets by random search. In their
framework, the number of points is fixed in advance, but extensible point sets
are preferred for some applications. In this paper, we propose a heuristic
search algorithm for extensible low-WAFOM point sets based on general digital
nets and random search. For this, we alternatively propose a method using
lookup tables to compute WAFOM faster. Numerical results show that the obtained
WAFOM-based point sets are competitive with Niederreiter--Xing points for some
low-dimensional and smooth test functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7829</identifier>
 <datestamp>2014-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7829</id><created>2013-09-30</created><updated>2014-12-10</updated><authors><author><keyname>Asaeedi</keyname><forenames>Saeed</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author><author><keyname>Mohades</keyname><forenames>Ali</forenames></author></authors><title>Alpha-Concave Hull, a Generalization of Convex Hull</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bounding hull, such as convex hull, concave hull, alpha shapes etc. has vast
applications in different areas especially in computational geometry. Alpha
shape and concave hull are generalizations of convex hull. Unlike the convex
hull, they construct non-convex enclosure on a set of points. In this paper, we
introduce another generalization of convex hull, named alpha-concave hull, and
compare this concept with convex hull and alpha shape. We show that the
alpha-concave hull is also a generalization of an NP-complete problem named
min-area TSP. We prove that computing the alpha-concave hull is NP-hard on a
set of points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7841</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7841</id><created>2013-09-30</created><updated>2014-01-06</updated><authors><author><keyname>Borkar</keyname><forenames>Vivek S.</forenames></author><author><keyname>Makhijani</keyname><forenames>Rahul</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Asynchronous Gossip for Averaging and Spectral Ranking</title><categories>cs.DC cs.IT cs.SY math.IT math.OC</categories><comments>14 pages, 7 figures. Minor revision</comments><doi>10.1109/JSTSP.2014.2320229</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two variants of the classical gossip algorithm. The first variant
is a version of asynchronous stochastic approximation. We highlight a
fundamental difficulty associated with the classical asynchronous gossip
scheme, viz., that it may not converge to a desired average, and suggest an
alternative scheme based on reinforcement learning that has guaranteed
convergence to the desired average. We then discuss a potential application to
a wireless network setting with simultaneous link activation constraints. The
second variant is a gossip algorithm for distributed computation of the
Perron-Frobenius eigenvector of a nonnegative matrix. While the first variant
draws upon a reinforcement learning algorithm for an average cost controlled
Markov decision problem, the second variant draws upon a reinforcement learning
algorithm for risk-sensitive control. We then discuss potential applications of
the second variant to ranking schemes, reputation networks, and principal
component analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7842</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7842</id><created>2013-09-30</created><authors><author><keyname>Pott</keyname><forenames>Alexander</forenames></author><author><keyname>Wang</keyname><forenames>Qi</forenames></author></authors><title>Difference Balanced Functions and Their Generalized Difference Sets</title><categories>math.CO cs.IT math.IT</categories><comments>17 pages</comments><msc-class>05B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Difference balanced functions from $F_{q^n}^*$ to $F_q$ are closely related
to combinatorial designs and naturally define $p$-ary sequences with the ideal
two-level autocorrelation. In the literature, all existing such functions are
associated with the $d$-homogeneous property, and it was conjectured by Gong
and Song that difference balanced functions must be $d$-homogeneous. First we
characterize difference balanced functions by generalized difference sets with
respect to two exceptional subgroups. We then derive several necessary and
sufficient conditions for $d$-homogeneous difference balanced functions. In
particular, we reveal an unexpected equivalence between the $d$-homogeneous
property and multipliers of generalized difference sets. By determining these
multipliers, we prove the Gong-Song conjecture for $q$ prime. Furthermore, we
show that every difference balanced function must be balanced or an affine
shift of a balanced function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7843</identifier>
 <datestamp>2014-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7843</id><created>2013-09-30</created><updated>2014-03-05</updated><authors><author><keyname>Liu</keyname><forenames>Benyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Zhilin</forenames></author><author><keyname>Xu</keyname><forenames>Gary</forenames></author><author><keyname>Fan</keyname><forenames>Hongqi</forenames></author><author><keyname>Fu</keyname><forenames>Qiang</forenames></author></authors><title>Energy Efficient Telemonitoring of Physiological Signals via Compressed
  Sensing: A Fast Algorithm and Power Consumption Evaluation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless telemonitoring of physiological signals is an important topic in
eHealth. In order to reduce on-chip energy consumption and extend sensor life,
recorded signals are usually compressed before transmission. In this paper, we
adopt compressed sensing (CS) as a low-power compression framework, and propose
a fast block sparse Bayesian learning (BSBL) algorithm to reconstruct original
signals. Experiments on real-world fetal ECG signals and epilepsy EEG signals
showed that the proposed algorithm has good balance between speed and data
reconstruction fidelity when compared to state-of-the-art CS algorithms.
Further, we implemented the CS-based compression procedure and a low-power
compression procedure based on a wavelet transform in Filed Programmable Gate
Array (FPGA), showing that the CS-based compression can largely save energy and
other on-chip computing resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7881</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7881</id><created>2013-09-30</created><authors><author><keyname>Ploumidis</keyname><forenames>Manolis</forenames></author><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Siris</keyname><forenames>Vasilios A.</forenames></author><author><keyname>Traganitis</keyname><forenames>Apostolos</forenames></author></authors><title>On the Performance of Network Coding and Forwarding Schemes with
  Different Degrees of Redundancy for Wireless Mesh Networks</title><categories>cs.NI</categories><comments>Submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study explores the throughput and delay that can be achieved by various
forwarding schemes employing multiple paths and different degrees of redundancy
focusing on linear network coding. The key contribution of the study is an
analytical framework for modeling the throughput and delay for various schemes
considering wireless mesh networks where, unicast traffic is forwarded and
hop-by-hop retransmissions are employed for achieving reliability. The
analytical framework is generalized for an arbitrary number of paths and hops
per path. Another key contribution of the study is the evaluation and extension
of the numerical results drawn from the analysis through NS-2 simulations. Our
results show that in scenarios with significant interference the best
throughput-delay tradeoff is achieved by single path forwarding. Moreover, when
significant interference is present and network coding employs the larger
packet generation size it experiences higher delay than all other schemes due
to the inter-arrival times aggregating over all coded packets required to
decode a packet generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7891</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7891</id><created>2013-09-30</created><authors><author><keyname>Giannopoulou</keyname><forenames>Archontia C.</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Suchy</keyname><forenames>Ondrej</forenames></author></authors><title>Tree Deletion Set has a Polynomial Kernel (but no OPT^O(1)
  approximation)</title><categories>cs.DS cs.DM</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the Tree Deletion Set problem the input is a graph G together with an
integer k. The objective is to determine whether there exists a set S of at
most k vertices such that G-S is a tree. The problem is NP-complete and even
NP-hard to approximate within any factor of OPT^c for any constant c. In this
paper we give a O(k^4) size kernel for the Tree Deletion Set problem. To the
best of our knowledge our result is the first counterexample to the
&quot;conventional wisdom&quot; that kernelization algorithms automatically provide
approximation algorithms with approximation ratio close to the size of the
kernel. An appealing feature of our kernelization algorithm is a new algebraic
reduction rule that we use to handle the instances on which Tree Deletion Set
is hard to approximate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7901</identifier>
 <datestamp>2013-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7901</id><created>2013-09-30</created><updated>2013-10-29</updated><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author></authors><title>Prefactor Reduction of the Guruswami-Sudan Interpolation Step</title><categories>cs.IT math.IT</categories><comments>13 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of prefactors is considered in order to decrease the complexity
of the Guruswami-Sudan interpolation step for generalized Reed-Solomon codes.
It is shown that the well-known re-encoding projection due to Koetter et al.
leads to one type of such prefactors. The new type of Sierpinski prefactors is
introduced. The latter are based on the fact that many binomial coefficients in
the Hasse derivative associated with the Guruswami-Sudan interpolation step are
zero modulo the base field characteristic. It is shown that both types of
prefactors can be combined and how arbitrary prefactors can be used to derive a
reduced Guruswami-Sudan interpolation step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7910</identifier>
 <datestamp>2014-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7910</id><created>2013-09-30</created><updated>2014-09-11</updated><authors><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Jian</keyname><forenames>Yung-Yih</forenames></author><author><keyname>Nguyen</keyname><forenames>Phong S.</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>A Simple Proof of Maxwell Saturation for Coupled Scalar Recursions</title><categories>cs.IT math.IT</categories><comments>This article is an extended journal version of arXiv:1204.5703 and
  has now been accepted to the IEEE Transactions on Information Theory. This
  version adds additional explanation for some details and also corrects a
  number of small typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-density parity-check (LDPC) convolutional codes (or spatially-coupled
codes) were recently shown to approach capacity on the binary erasure channel
(BEC) and binary-input memoryless symmetric channels. The mechanism behind this
spectacular performance is now called threshold saturation via spatial
coupling. This new phenomenon is characterized by the belief-propagation
threshold of the spatially-coupled ensemble increasing to an intrinsic noise
threshold defined by the uncoupled system. In this paper, we present a simple
proof of threshold saturation that applies to a wide class of coupled scalar
recursions. Our approach is based on constructing potential functions for both
the coupled and uncoupled recursions. Our results actually show that the fixed
point of the coupled recursion is essentially determined by the minimum of the
uncoupled potential function and we refer to this phenomenon as Maxwell
saturation. A variety of examples are considered including the
density-evolution equations for: irregular LDPC codes on the BEC, irregular
low-density generator matrix codes on the BEC, a class of generalized LDPC
codes with BCH component codes, the joint iterative decoding of LDPC codes on
intersymbol-interference channels with erasure noise, and the compressed
sensing of random vectors with i.i.d. components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7912</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7912</id><created>2013-09-30</created><authors><author><keyname>de Amorim</keyname><forenames>Mauro</forenames></author><author><keyname>Fabbri</keyname><forenames>Ricardo</forenames></author><author><keyname>Pinto</keyname><forenames>Lucia Maria dos Santos</forenames></author><author><keyname>Neto</keyname><forenames>Francisco Duarte Moura</forenames></author></authors><title>An Image-Based Fluid Surface Pattern Model</title><categories>cs.CV</categories><comments>a reduced version in Portuguese appears in proceedings of the XVI EMC
  - Computational Modeling Meeting (Encontro de Modelagem Computacional), 2013</comments><acm-class>I.2.10; I.4.8; I.5.4; I.6.5; J.2; G.1.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This work aims at generating a model of the ocean surface and its dynamics
from one or more video cameras. The idea is to model wave patterns from video
as a first step towards a larger system of photogrammetric monitoring of marine
conditions for use in offshore oil drilling platforms. The first part of the
proposed approach consists in reducing the dimensionality of sensor data made
up of the many pixels of each frame of the input video streams. This enables
finding a concise number of most relevant parameters to model the temporal
dataset, yielding an efficient data-driven model of the evolution of the
observed surface. The second part proposes stochastic modeling to better
capture the patterns embedded in the data. One can then draw samples from the
final model, which are expected to simulate the behavior of previously observed
flow, in order to determine conditions that match new observations. In this
paper we focus on proposing and discussing the overall approach and on
comparing two different techniques for dimensionality reduction in the first
stage: principal component analysis and diffusion maps. Work is underway on the
second stage of constructing better stochastic models of fluid surface dynamics
as proposed here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7919</identifier>
 <datestamp>2014-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7919</id><created>2013-09-30</created><updated>2014-03-11</updated><authors><author><keyname>Berwald</keyname><forenames>Jesse</forenames></author><author><keyname>Gidea</keyname><forenames>Marian</forenames></author></authors><title>Critical Transitions In a Model of a Genetic Regulatory System</title><categories>nlin.CD cs.CE cs.CG math.AP q-bio.GN q-bio.QM</categories><comments>19 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a model for substrate-depletion oscillations in genetic systems,
based on a stochastic differential equation with a slowly evolving external
signal. We show the existence of critical transitions in the system. We apply
two methods to numerically test the synthetic time series generated by the
system for early indicators of critical transitions: a detrended fluctuation
analysis method, and a novel method based on topological data analysis
(persistence diagrams).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7935</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7935</id><created>2013-09-30</created><authors><author><keyname>Pananjady</keyname><forenames>Ashwin</forenames></author><author><keyname>Bagaria</keyname><forenames>Vivek Kumar</forenames></author><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>Maximizing Utility Among Selfish Users in Social Groups</title><categories>cs.NI cs.DS cs.SI</categories><comments>11 pages, 3 figures; submitted for review to the National Conference
  on Communications (NCC) 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of a social group of users trying to obtain a
&quot;universe&quot; of files, first from a server and then via exchange amongst
themselves. We consider the selfish file-exchange paradigm of give-and-take,
whereby two users can exchange files only if each has something unique to offer
the other. We are interested in maximizing the number of users who can obtain
the universe through a schedule of file-exchanges. We first present a practical
paradigm of file acquisition. We then present an algorithm which ensures that
at least half the users obtain the universe with high probability for $n$ files
and $m=O(\log n)$ users when $n\rightarrow\infty$, thereby showing an
approximation ratio of 2. Extending these ideas, we show a $1+\epsilon_1$ -
approximation algorithm for $m=O(n)$, $\epsilon_1&gt;0$ and a $(1+z)/2
+\epsilon_2$ - approximation algorithm for $m=O(n^z)$, $z&gt;1$, $\epsilon_2&gt;0$.
Finally, we show that for any $m=O(e^{o(n)})$, there exists a schedule of file
exchanges which ensures that at least half the users obtain the universe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7937</identifier>
 <datestamp>2014-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7937</id><created>2013-09-30</created><updated>2014-03-13</updated><authors><author><keyname>Bellman</keyname><forenames>Matthew J.</forenames></author><author><keyname>Cheng</keyname><forenames>Teng-Hu</forenames></author><author><keyname>Downey</keyname><forenames>Ryan J.</forenames></author><author><keyname>Dixon</keyname><forenames>Warren E.</forenames></author></authors><title>Stationary Cycling Induced by Switched Functional Electrical Stimulation
  Control</title><categories>cs.SY</categories><comments>8 pages, 3 figures, submitted to ACC 2014</comments><msc-class>93-06</msc-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Functional electrical stimulation (FES) is used to activate the dysfunctional
lower limb muscles of individuals with neuromuscular disorders to produce
cycling as a means of exercise and rehabilitation. However, FES-cycling is
still metabolically inefficient and yields low power output at the cycle crank
compared to able-bodied cycling. Previous literature suggests that these
problems are symptomatic of poor muscle control and non-physiological muscle
fiber recruitment. The latter is a known problem with FES in general, and the
former motivates investigation of better control methods for FES-cycling.In
this paper, a stimulation pattern for quadriceps femoris-only FES-cycling is
derived based on the effectiveness of knee joint torque in producing forward
pedaling. In addition, a switched sliding-mode controller is designed for the
uncertain, nonlinear cycle-rider system with autonomous state-dependent
switching. The switched controller yields ultimately bounded tracking of a
desired trajectory in the presence of an unknown, time-varying, bounded
disturbance, provided a reverse dwell-time condition is satisfied by
appropriate choice of the control gains and a sufficient desired cadence.
Stability is derived through Lyapunov methods for switched systems, and
experimental results demonstrate the performance of the switched control system
under typical cycling conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7949</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7949</id><created>2013-09-30</created><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author></authors><title>Bibliometric-enhanced Retrieval Models for Big Scholarly Information
  Systems</title><categories>cs.DL</categories><comments>4 pages, IEEE BigData 2013, Workshop on Scholarly Big Data:
  Challenges and Ideas</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bibliometric techniques are not yet widely used to enhance retrieval
processes in digital libraries, although they offer value-added effects for
users. In this paper we will explore how statistical modelling of scholarship,
such as Bradfordizing or network analysis of coauthorship network, can improve
retrieval services for specific communities, as well as for large, cross-domain
large collections. This paper aims to raise awareness of the missing link
between information retrieval (IR) and bibliometrics / scientometrics and to
create a common ground for the incorporation of bibliometric-enhanced services
into retrieval at the digital library interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7950</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7950</id><created>2013-09-30</created><authors><author><keyname>Abdeen</keyname><forenames>Hani</forenames></author><author><keyname>Shata</keyname><forenames>Osama</forenames></author><author><keyname>Erradi</keyname><forenames>Abdelkarim</forenames></author></authors><title>Software Interfaces: On The Impact of Interface Design Anomalies</title><categories>cs.SE</categories><comments>Conference paper, published in IEEE CSIT' 2013</comments><doi>10.1109/CSIT.2013.6588778</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Interfaces are recognized as an important mechanism to define contracts
governing interactions between semi-independent software modules. Well-designed
interfaces significantly reduce software complexity and ease maintainability by
fostering modularization, hiding implementation details and minimizing the
impact caused by changes in the software implementation. However, designing
good interfaces is not a trivial task. The presence of interface design defects
often yield increased development cost, lower code quality and reduced
development productivity. Despite their importance, currently there are only a
few research efforts that investigate the quality of interface design. In this
paper, we identify and characterize common interface design anomalies and
illustrate them via examples taken from well-known open source applications. In
order to quantify the presence of interface design anomalies and estimate their
impact on the interface design quality, as well on the software quality
attributes, such as maintainability, we conduct an empirical study covering 9
open source projects. Building on our empirical results, we develop a set of
recommendations to improve interface design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7955</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7955</id><created>2013-09-30</created><authors><author><keyname>Fernandes</keyname><forenames>Cristina G.</forenames></author><author><keyname>Schouery</keyname><forenames>Rafael C. S.</forenames></author></authors><title>Approximation Algorithms for the Max-Buying Problem with Limited Supply</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Max-Buying Problem with Limited Supply, in which there are
$n$ items, with $C_i$ copies of each item $i$, and $m$ bidders such that every
bidder $b$ has valuation $v_{ib}$ for item $i$. The goal is to find a pricing
$p$ and an allocation of items to bidders that maximizes the profit, where
every item is allocated to at most $C_i$ bidders, every bidder receives at most
one item and if a bidder $b$ receives item $i$ then $p_i \leq v_{ib}$. Briest
and Krysta presented a 2-approximation for this problem and Aggarwal et al.
presented a 4-approximation for the Price Ladder variant where the pricing must
be non-increasing (that is, $p_1 \geq p_2 \geq \cdots \geq p_n$). We present an
$e/(e-1)$-approximation for the Max-Buying Problem with Limited Supply and, for
every $\varepsilon &gt; 0$, a $(2+\varepsilon)$-approximation for the Price Ladder
variant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7958</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7958</id><created>2013-09-27</created><authors><author><keyname>Abbasi</keyname><forenames>Ahmed</forenames></author><author><keyname>Zhang</keyname><forenames>Zhu</forenames></author><author><keyname>Chen</keyname><forenames>Hsinchun</forenames></author></authors><title>A Statistical Learning Based System for Fake Website Detection</title><categories>cs.CY cs.LG</categories><journal-ref>Abbasi, A., Zhang, Z., and Chen, H. &quot;A Statistical Learning Based
  System for Fake Website Detection,&quot; In Proceedings of the Workshop on Secure
  Knowledge Management, Dallas, Texas, November 3-4 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing fake website detection systems are unable to effectively detect fake
websites. In this study, we advocate the development of fake website detection
systems that employ classification methods grounded in statistical learning
theory (SLT). Experimental results reveal that a prototype system developed
using SLT-based methods outperforms seven existing fake website detection
systems on a test bed encompassing 900 real and fake websites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7959</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7959</id><created>2013-09-19</created><authors><author><keyname>Bliek</keyname><forenames>Laurens</forenames></author></authors><title>Exploration and Exploitation in Visuomotor Prediction of Autonomous
  Agents</title><categories>cs.LG cs.CV math.DS</categories><comments>Award-winning paper of the internal conference 'Almende research
  workshop 2013'</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses various techniques to let an agent learn how to predict
the effects of its own actions on its sensor data autonomously, and their
usefulness to apply them to visual sensors. An Extreme Learning Machine is used
for visuomotor prediction, while various autonomous control techniques that can
aid the prediction process by balancing exploration and exploitation are
discussed and tested in a simple system: a camera moving over a 2D greyscale
image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7960</identifier>
 <datestamp>2014-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7960</id><created>2013-09-30</created><updated>2014-08-29</updated><authors><author><keyname>Bhattacharya</keyname><forenames>Subhrajit</forenames></author><author><keyname>Pivtoraiko</keyname><forenames>Mihail</forenames></author></authors><title>A Classification of Configuration Spaces of Planar Robot Arms with
  Application to a Continuous Inverse Kinematics Problem</title><categories>math.DG cs.RO</categories><comments>Revised version from December 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using results on the topology of moduli space of polygons [Jaggi, 92;
Kapovich and Millson, 94], it can be shown that for a planar robot arm with $n$
segments there are some values of the base-length, $z$, at which the
configuration space of the constrained arm (arm with its end effector fixed)
has two disconnected components, while at other values the constrained
configuration space has one connected component. We first review some of these
known results.
  Then the main design problem addressed in this paper is the construction of
pairs of continuous inverse kinematics for arbitrary robot arms, with the
property that the two inverse kinematics agree when the constrained
configuration space has a single connected component, but they give distinct
configurations (one in each connected component) when the configuration space
of the constrained arm has two components. This design is made possible by a
fundamental theoretical contribution in this paper -- a classification of
configuration spaces of robot arms such that the type of path that the system
(robot arm) takes through certain critical values of the forward kinematics
function is completely determined by the class to which the configuration space
of the arm belongs. This classification result makes the aforesaid design
problem tractable, making it sufficient to design a pair of inverse kinematics
for each class of configuration spaces (three of them in total).
  We discuss the motivation for this work, which comes from a more extensive
problem of motion planning for the end effector of a robot arm requiring us to
continuously sample one configuration from each connected component of the
constrained configuration spaces.
  We demonstrate the low complexity of the presented algorithm through a
Javascript + HTML5 based implementation available at
http://hans.math.upenn.edu/~subhrabh/nowiki/robot_arm_JS-HTML5/arm.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7964</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7964</id><created>2013-09-30</created><authors><author><keyname>Somekh-Baruch</keyname><forenames>Anelia</forenames></author></authors><title>A General Formula for the Mismatch Capacity</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental limits of channels with mismatched decoding are addressed. A
general formula is established for the mismatch capacity of a general channel,
defined as a sequence of conditional distributions with a general decoding
metrics sequence. We deduce an identity between the Verd\'{u}-Han general
channel capacity formula, and the mismatch capacity formula applied to Maximum
Likelihood decoding metric. Further, several upper bounds on the capacity are
provided, and a simpler expression for a lower bound is derived for the case of
a non-negative decoding metric. The general formula is specialized to the case
of finite input and output alphabet channels with a type-dependent metric. The
closely related problem of threshold mismatched decoding is also studied, and a
general expression for the threshold mismatch capacity is obtained. As an
example of threshold mismatch capacity, we state a general expression for the
erasures-only capacity of the finite input and output alphabet channel. We
observe that for every channel there exists a (matched) threshold decoder which
is capacity achieving. Additionally, necessary and sufficient conditions are
stated for a channel to have a strong converse. Csisz\'{a}r and Narayan's
conjecture is proved for bounded metrics, providing a positive answer to the
open problem introduced in [1], i.e., that the &quot;product-space&quot; improvement of
the lower random coding bound, $C_q^{(\infty)}(W)$, is indeed the mismatch
capacity of the discrete memoryless channel $W$. We conclude by presenting an
identity between the threshold capacity and $C_q^{(\infty)}(W)$ in the DMC
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7971</identifier>
 <datestamp>2014-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7971</id><created>2013-09-30</created><updated>2014-08-27</updated><authors><author><keyname>Nicholson</keyname><forenames>Ann</forenames></author><author><keyname>Smyth</keyname><forenames>Padhriac</forenames></author></authors><title>Proceedings of the Twenty-Ninth Conference on Uncertainty in Artificial
  Intelligence (2013)</title><categories>cs.AI</categories><proxy>Martijn de Jongh</proxy><report-no>UAI2013</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the Proceedings of the Twenty-Ninth Conference on Uncertainty in
Artificial Intelligence, which was held in Bellevue, WA, August 11-15, 2013
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7979</identifier>
 <datestamp>2014-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7979</id><created>2013-09-30</created><updated>2014-06-16</updated><authors><author><keyname>Horsman</keyname><forenames>Clare</forenames></author><author><keyname>Stepney</keyname><forenames>Susan</forenames></author><author><keyname>Wagner</keyname><forenames>Rob C.</forenames></author><author><keyname>Kendon</keyname><forenames>Viv</forenames></author></authors><title>When does a physical system compute?</title><categories>cs.ET physics.hist-ph quant-ph</categories><comments>22 pages, 10 figures. v3 as accepted by Proc.Roy.Soc.A</comments><journal-ref>Proc. R. Soc. A 2014 470, 20140182</journal-ref><doi>10.1098/rspa.2014.0182</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing is a high-level process of a physical system. Recent interest in
non-standard computing systems, including quantum and biological computers, has
brought this physical basis of computing to the forefront. There has been,
however, no consensus on how to tell if a given physical system is acting as a
computer or not; leading to confusion over novel computational devices, and
even claims that every physical event is a computation. In this paper we
introduce a formal framework that can be used to determine whether or not a
physical system is performing a computation. We demonstrate how the abstract
computational level interacts with the physical device level, drawing the
comparison with the use of mathematical models to represent physical objects in
experimental science. This powerful formulation allows a precise description of
the similarities between experiments, computation, simulation, and technology,
leading to our central conclusion: physical computing is the use of a physical
system to predict the outcome of an abstract evolution. We give conditions that
must be satisfied in order for computation to be occurring, and illustrate
these with a range of non-standard computing scenarios. The framework also
covers broader computing contexts, where there is no obvious human computer
user. We define the critical notion of a 'computational entity', and show the
role this plays in defining when computing is taking place in physical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1309.7982</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1309.7982</id><created>2013-09-26</created><authors><author><keyname>Liao</keyname><forenames>Zhung-Xun</forenames></author><author><keyname>Li</keyname><forenames>Shou-Chung</forenames></author><author><keyname>Peng</keyname><forenames>Wen-Chih</forenames></author><author><keyname>Yu</keyname><forenames>Philip S</forenames></author></authors><title>On the Feature Discovery for App Usage Prediction in Smartphones</title><categories>cs.LG</categories><comments>10 pages, 17 figures, ICDM 2013 short paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing number of mobile Apps developed, they are now closely
integrated into daily life. In this paper, we develop a framework to predict
mobile Apps that are most likely to be used regarding the current device status
of a smartphone. Such an Apps usage prediction framework is a crucial
prerequisite for fast App launching, intelligent user experience, and power
management of smartphones. By analyzing real App usage log data, we discover
two kinds of features: The Explicit Feature (EF) from sensing readings of
built-in sensors, and the Implicit Feature (IF) from App usage relations. The
IF feature is derived by constructing the proposed App Usage Graph (abbreviated
as AUG) that models App usage transitions. In light of AUG, we are able to
discover usage relations among Apps. Since users may have different usage
behaviors on their smartphones, we further propose one personalized feature
selection algorithm. We explore minimum description length (MDL) from the
training data and select those features which need less length to describe the
training data. The personalized feature selection can successfully reduce the
log size and the prediction time. Finally, we adopt the kNN classification
model to predict Apps usage. Note that through the features selected by the
proposed personalized feature selection algorithm, we only need to keep these
features, which in turn reduces the prediction time and avoids the curse of
dimensionality when using the kNN classifier. We conduct a comprehensive
experimental study based on a real mobile App usage dataset. The results
demonstrate the effectiveness of the proposed framework and show the predictive
capability for App usage prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0005</identifier>
 <datestamp>2014-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0005</id><created>2013-09-30</created><updated>2014-01-15</updated><authors><author><keyname>Vassio</keyname><forenames>Luca</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Message passing optimization of Harmonic Influence Centrality</title><categories>math.OC cs.SI cs.SY</categories><comments>11 pages; 10 figures; to appear as a journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new measure of node centrality in social networks, the
Harmonic Influence Centrality, which emerges naturally in the study of social
influence over networks. Using an intuitive analogy between social and
electrical networks, we introduce a distributed message passing algorithm to
compute the Harmonic Influence Centrality of each node. Although its design is
based on theoretical results which assume the network to have no cycle, the
algorithm can also be successfully applied on general graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0036</identifier>
 <datestamp>2013-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0036</id><created>2013-09-30</created><authors><author><keyname>Bhattacharjee</keyname><forenames>Saptarshi</forenames></author><author><keyname>Arunkumar</keyname><forenames>S</forenames></author><author><keyname>Bandyopadhyay</keyname><forenames>Samir Kumar</forenames></author></authors><title>Personal Identification from Lip-Print Features using a Statistical
  Model</title><categories>cs.CV</categories><comments>5 pages, 7 images, Published with International Journal of Computer
  Applications (IJCA)</comments><doi>10.5120/8817-2801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach towards identification of human beings
from the statistical analysis of their lip prints. Lip features are extracted
by studying the spatial orientations of the grooves present in lip prints of
individuals using standard edge detection techniques. Horizontal, vertical and
diagonal groove features are analysed using connected-component analysis to
generate the region-specific edge datasets. Comparison between test and
reference sample datasets against a threshold value to define a match yield
satisfactory results. FAR, FRR and ROC metrics have been used to gauge the
performance of the algorithm for real-world deployment in unimodal and
multimodal biometric verification systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0038</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0038</id><created>2013-09-30</created><authors><author><keyname>Fernandes</keyname><forenames>Cristina G.</forenames></author><author><keyname>Ferreira</keyname><forenames>Carlos E.</forenames></author><author><keyname>Franco</keyname><forenames>&#xc1;lvaro J. P.</forenames></author><author><keyname>Schouery</keyname><forenames>Rafael C. S.</forenames></author></authors><title>The Unit-Demand Envy-Free Pricing Problem</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the unit-demand envy-free pricing problem, which is a unit-demand
auction where each bidder receives an item that maximizes his utility, and the
goal is to maximize the auctioneer's profit. This problem is NP-hard and
unlikely to be in APX. We present four new MIP formulations for it and
experimentally compare them to a previous one due to Shioda, Tun\c{c}el, and
Myklebust. We describe three models to generate different random instances for
general unit-demand auctions, that we designed for the computational
experiments. Each model has a nice economic interpretation. Aiming
approximation results, we consider the variant of the problem where the item
prices are restricted to be chosen from a geometric series, and prove that an
optimal solution for this variant has value that is a fraction (depending on
the series used) of the optimal value of the original problem. So this variant
is also unlikely to be in APX.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0041</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0041</id><created>2013-09-30</created><authors><author><keyname>Kazhdan</keyname><forenames>Michael</forenames></author><author><keyname>Burns</keyname><forenames>Randal</forenames></author><author><keyname>Kasthuri</keyname><forenames>Bobby</forenames></author><author><keyname>Lichtman</keyname><forenames>Jeff</forenames></author><author><keyname>Vogelstein</keyname><forenames>Jacob</forenames></author><author><keyname>Vogelstein</keyname><forenames>Joshua</forenames></author></authors><title>Gradient-Domain Processing for Large EM Image Stacks</title><categories>cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new gradient-domain technique for processing registered EM image
stacks to remove the inter-image discontinuities while preserving intra-image
detail. To this end, we process the image stack by first performing anisotropic
diffusion to smooth the data along the slice axis and then solving a
screened-Poisson equation within each slice to re-introduce the detail. The
final image stack is both continuous across the slice axis (facilitating the
tracking of information between slices) and maintains sharp details within each
slice (supporting automatic feature detection). To support this editing, we
describe the implementation of the first multigrid solver designed for
efficient gradient domain processing of large, out-of-core, voxel grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0046</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0046</id><created>2013-09-30</created><authors><author><keyname>Zhang</keyname><forenames>Xiao</forenames></author><author><keyname>Nadakuditi</keyname><forenames>Raj Rao</forenames></author><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>Spectra of random graphs with community structure and arbitrary degrees</title><categories>cs.SI cond-mat.stat-mech physics.soc-ph</categories><comments>9 pages, 3 figures</comments><journal-ref>Phys. Rev. E 89, 042816 (2014)</journal-ref><doi>10.1103/PhysRevE.89.042816</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using methods from random matrix theory researchers have recently calculated
the full spectra of random networks with arbitrary degrees and with community
structure. Both reveal interesting spectral features, including deviations from
the Wigner semicircle distribution and phase transitions in the spectra of
community structured networks. In this paper we generalize both calculations,
giving a prescription for calculating the spectrum of a network with both
community structure and an arbitrary degree distribution. In general the
spectrum has two parts, a continuous spectral band, which can depart strongly
from the classic semicircle form, and a set of outlying eigenvalues that
indicate the presence of communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0054</identifier>
 <datestamp>2014-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0054</id><created>2013-09-30</created><updated>2014-02-19</updated><authors><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author><author><keyname>Amuru</keyname><forenames>SaiDhiraj</forenames></author><author><keyname>Clancy</keyname><forenames>T. Charles</forenames></author><author><keyname>Buehrer</keyname><forenames>R. Michael</forenames></author></authors><title>Towards Optimal Secure Distributed Storage Systems with Exact Repair</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed storage systems in the presence of a wiretapper are considered. A
distributed storage system (DSS) is parameterized by three parameters (n, k,d),
in which a file stored across n distributed nodes, can be recovered from any k
out of n nodes. If a node fails, any d out of (n-1) nodes help in the repair of
the failed node. For such a (n,k,d)-DSS, two types of wiretapping scenarios are
investigated: (a) Type-I (node) adversary which can wiretap the data stored on
any l&lt;k nodes; and a more severe (b) Type-II (repair data) adversary which can
wiretap the contents of the repair data that is used to repair a set of l
failed nodes over time. The focus of this work is on the practically relevant
setting of exact repair regeneration in which the repair process must replace a
failed node by its exact replica. We make new progress on several non-trivial
instances of this problem which prior to this work have been open. The main
contribution of this paper is the optimal characterization of the secure
storage-vs-exact-repair-bandwidth tradeoff region of a (n,k,d)-DSS, with n&lt;=4
and any l&lt;k in the presence of both Type-I and Type-II adversaries. While the
problem remains open for a general (n,k,d)-DSS with n&gt;4, we present extensions
of these results to a (n, n-1,n-1)-DSS, in presence of a Type-II adversary that
can observe the repair data of any l=(n-2) nodes. The key technical
contribution of this work is in developing novel information theoretic converse
proofs for the Type-II adversarial scenario. From our results, we show that in
the presence of Type-II attacks, the only efficient point in the
storage-vs-exact-repair-bandwidth tradeoff is the MBR (minimum bandwidth
regenerating) point. This is in sharp contrast to the case of a Type-I attack
in which the storage-vs-exact-repair-bandwidth tradeoff allows a spectrum of
operating points beyond the MBR point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0056</identifier>
 <datestamp>2014-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0056</id><created>2013-09-30</created><updated>2014-04-29</updated><authors><author><keyname>Verschelde</keyname><forenames>Jan</forenames></author></authors><title>Modernizing PHCpack through phcpy</title><categories>cs.MS cs.SC math.AG math.NA</categories><comments>Part of the Proceedings of the 6th European Conference on Python in
  Science (EuroSciPy 2013), Pierre de Buyl and Nelle Varoquaux editors, (2014)</comments><report-no>euroscipy-proceedings2013-11</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  PHCpack is a large software package for solving systems of polynomial
equations. The executable phc is menu driven and file oriented. This paper
describes the development of phcpy, a Python interface to PHCpack. Instead of
navigating through menus, users of phcpy solve systems in the Python shell or
via scripts. Persistent objects replace intermediate files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0058</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0058</id><created>2013-09-30</created><authors><author><keyname>Wang</keyname><forenames>Xiaozhe</forenames></author><author><keyname>Chiang</keyname><forenames>Hsiao-Dong</forenames></author></authors><title>Some issues with Quasi-Steady State Model in Long-term Stability</title><categories>cs.SY</categories><comments>This paper was accepted and presented in 2013 IEEE Power&amp;Energy
  Society General Meeting</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Quasi Steady-State (QSS) model of long-term dynamics relies on the idea
of time-scale decomposition. Assuming that the fast variables are infinitely
fast and are stable in the long-term, the QSS model replaces the differential
equations of transient dynamics by their equilibrium equations to reduce
complexity and increase computation efficiency. Although the idea of QSS model
is intuitive, its theoretical foundation has not yet been developed. In this
paper, several counter examples in which the QSS model fails to provide a
correct approximation of the complete dynamic model in power system are
presented and the reasons of the failure are explained from the viewpoint of
nonlinear analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0063</identifier>
 <datestamp>2014-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0063</id><created>2013-09-30</created><updated>2014-04-01</updated><authors><author><keyname>Walters</keyname><forenames>Patrick</forenames></author><author><keyname>Dixon</keyname><forenames>Warren E.</forenames></author></authors><title>Online Approximate Optimal Station Keeping of an Autonomous Underwater
  Vehicle</title><categories>cs.SY cs.RO math.OC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online approximation of an optimal station keeping strategy for a fully
actuated six degrees-of-freedom autonomous underwater vehicle is considered.
The developed controller is an approximation of the solution to a two player
zero-sum game where the controller is the minimizing player and an external
disturbance is the maximizing player. The solution is approximated using a
reinforcement learning-based actor-critic framework. The result guarantees
uniformly ultimately bounded (UUB) convergence of the states and UUB
convergence of the approximated policies to the optimal polices without the
requirement of persistence of excitation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0064</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0064</id><created>2013-09-30</created><authors><author><keyname>Walters</keyname><forenames>Patrick</forenames></author><author><keyname>Kamalapurkar</keyname><forenames>Rushikesh</forenames></author><author><keyname>Andrews</keyname><forenames>Lindsey</forenames></author><author><keyname>Dixon</keyname><forenames>Warren E.</forenames></author></authors><title>Online Approximate Optimal Path-Following for a Kinematic Unicycle</title><categories>cs.SY math.OC</categories><comments>7 pages, 5 figures, submitted to 2014 American Control Conference,
  under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online approximation of an infinite horizon optimal path-following strategy
for a kinematic unicycle is considered. The solution to the optimal control
problem is approximated using an approximate dynamic programming technique that
uses concurrent-learning-based adaptive update laws to estimate the unknown
value function. The developed controller overcomes challenges with the
approximation of the infinite horizon value function using an auxiliary
function that describes the motion of a virtual target on the desired path. The
developed controller guarantees uniformly ultimately bounded (UUB) convergence
of the vehicle to a desired path while maintaining a desired speed profile and
UUB convergence of the approximate policy to the optimal policy. Simulation
results are included to demonstrate the controller's performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0068</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0068</id><created>2013-09-30</created><updated>2014-01-09</updated><authors><author><keyname>Vatankhah</keyname><forenames>Saeed</forenames></author><author><keyname>Ardestani</keyname><forenames>Vahid E</forenames></author><author><keyname>Renaut</keyname><forenames>Rosemary A</forenames></author></authors><title>Automatic estimation of the regularization parameter in 2-D focusing
  gravity inversion: an application to the Safo manganese mine in northwest of
  Iran</title><categories>cs.CE</categories><journal-ref>J. Geophys. Eng. 11 (2014) 045001</journal-ref><doi>10.1088/1742-2132/11/4/045001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the use of Tikhonov regularization with the minimum support
stabilizer for underdetermined 2-D inversion of gravity data. This stabilizer
produces models with non-smooth properties which is useful for identifying
geologic structures with sharp boundaries. A very important aspect of using
Tikhonov regularization is the choice of the regularization parameter that
controls the trade off between the data fidelity and the stabilizing
functional. The L-curve and generalized cross validation techniques, which only
require the relative sizes of the uncertainties in the observations are
considered. Both criteria are applied in an iterative process for which at each
iteration a value for regularization parameter is estimated. Suitable values
for the regularization parameter are successfully determined in both cases for
synthetic but practically relevant examples. Whenever the geologic situation
permits, it is easier and more efficient to model the subsurface with a 2-D
algorithm, rather than to apply a full 3-D approach. Then, because the problem
is not large it is appropriate to use the generalized singular value
decomposition for solving the problem efficiently. The method is applied on a
profile of gravity data acquired over the Safo mining camp in Maku-Iran, which
is well known for manganese ores. The presented results demonstrate success in
reconstructing the geometry and density distribution of the subsurface source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0070</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0070</id><created>2013-09-30</created><authors><author><keyname>Farsad</keyname><forenames>Nariman</forenames></author><author><keyname>Guo</keyname><forenames>Weisi</forenames></author><author><keyname>Eckford</keyname><forenames>Andrew W.</forenames></author></authors><title>Table-Top Molecular Communication: Text Messages Through Chemical
  Signals</title><categories>cs.ET cs.NI</categories><doi>10.1371/journal.pone.0082935</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we describe the first modular, and programmable platform
capable of transmitting a text message using chemical signalling -- a method
also known as molecular communication. This form of communication is attractive
for applications where conventional wireless systems perform poorly, from
nanotechnology to urban health monitoring. Using examples, we demonstrate the
use of our platform as a testbed for molecular communication, and illustrate
the features of these communication systems using experiments. By providing a
simple and inexpensive means of performing experiments, our system fills an
important gap in the molecular communication literature, where much current
work is done in simulation with simplified system models. A key finding in this
paper is that these systems are often nonlinear in practice, whereas current
simulations and analysis often assume that the system is linear. However, as we
show in this work, despite the nonlinearity, reliable communication is still
possible. Furthermore, this work motivates future studies on more realistic
modelling, analysis, and design of theoretical models and algorithms for these
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0097</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0097</id><created>2013-09-30</created><updated>2014-07-12</updated><authors><author><keyname>Welk</keyname><forenames>Martin</forenames></author></authors><title>Analysis of Amoeba Active Contours</title><categories>cs.CV</categories><comments>Revised version with several improvements for clarity, slightly
  extended experiments and discussion. Accepted for publication in Journal of
  Mathematical Imaging and Vision</comments><acm-class>I.4.6; I.4.3; G.1.8</acm-class><doi>10.1007/s10851-014-0524-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subject of this paper is the theoretical analysis of structure-adaptive
median filter algorithms that approximate curvature-based PDEs for image
filtering and segmentation. These so-called morphological amoeba filters are
based on a concept introduced by Lerallut et al. They achieve similar results
as the well-known geodesic active contour and self-snakes PDEs. In the present
work, the PDE approximated by amoeba active contours is derived for a general
geometric situation and general amoeba metric. This PDE is structurally similar
but not identical to the geodesic active contour equation. It reproduces the
previous PDE approximation results for amoeba median filters as special cases.
Furthermore, modifications of the basic amoeba active contour algorithm are
analysed that are related to the morphological force terms frequently used with
geodesic active contours. Experiments demonstrate the basic behaviour of amoeba
active contours and its similarity to geodesic active contours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0100</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0100</id><created>2013-09-30</created><authors><author><keyname>Hobeika</keyname><forenames>Christelle</forenames></author><author><keyname>Thibeault</keyname><forenames>Claude</forenames></author><author><keyname>Boland</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>Technical report: Functional Constraint Extraction From Register
  Transfer Level for ATPG</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed in &quot;Functional Constraint Extraction From Register Transfer Level
for ATPG&quot; that is currently submitted to TVLSI, an automatic functional
constraint extractor that can be applied on the RT level. These functional
constraints are used to generate pseudo functional test patterns with ATPG
tools. The patterns are then used to improve the verification process. This
technical report complements the work proposed as it contains the
implementation details of the proposed methodology and shows the detailed
intermediate and final results of the application of this methodology on a
concrete example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0101</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0101</id><created>2013-09-30</created><authors><author><keyname>Landau</keyname><forenames>L.</forenames></author><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author><author><keyname>Haardt</keyname><forenames>M.</forenames></author></authors><title>Robust Adaptive Beamforming Algorithms Based on the Constrained Constant
  Modulus Criterion</title><categories>cs.IT math.IT</categories><comments>11 pages, 8 figures and 4 tables. IET Signal Processing, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a robust adaptive beamforming algorithm based on the worst-case
criterion and the constrained constant modulus approach, which exploits the
constant modulus property of the desired signal. Similarly to the existing
worst-case beamformer with the minimum variance design, the problem can be
reformulated as a second-order cone (SOC) program and solved with interior
point methods. An analysis of the optimization problem is carried out and
conditions are obtained for enforcing its convexity and for adjusting its
parameters. Furthermore, low-complexity robust adaptive beamforming algorithms
based on the modified conjugate gradient (MCG) and an alternating optimization
strategy are proposed. The proposed low-complexity algorithms can compute the
existing worst-case constrained minimum variance (WC-CMV) and the proposed
worst-case constrained constant modulus (WC-CCM) designs with a quadratic cost
in the number of parameters. Simulations show that the proposed WC-CCM
algorithm performs better than existing robust beamforming algorithms.
Moreover, the numerical results also show that the performances of the proposed
low-complexity algorithms are equivalent or better than that of existing robust
algorithms, whereas the complexity is more than an order of magnitude lower.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0110</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0110</id><created>2013-09-30</created><authors><author><keyname>Konagurthu</keyname><forenames>Arun</forenames></author><author><keyname>Collier</keyname><forenames>James</forenames></author></authors><title>An information measure for comparing top $k$ lists</title><categories>cs.IT cs.LG math.IT</categories><comments>11 pages; 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comparing the top $k$ elements between two or more ranked results is a common
task in many contexts and settings. A few measures have been proposed to
compare top $k$ lists with attractive mathematical properties, but they face a
number of pitfalls and shortcomings in practice. This work introduces a new
measure to compare any two top k lists based on measuring the information these
lists convey. Our method investigates the compressibility of the lists, and the
length of the message to losslessly encode them gives a natural and robust
measure of their variability. This information-theoretic measure objectively
reconciles all the main considerations that arise when measuring
(dis-)similarity between lists: the extent of their non-overlapping elements in
each of the lists; the amount of disarray among overlapping elements between
the lists; the measurement of displacement of actual ranks of their overlapping
elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0116</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0116</id><created>2013-09-30</created><authors><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Ghosh</keyname><forenames>Amitava</forenames></author><author><keyname>Ratasuk</keyname><forenames>Rapeepat</forenames></author></authors><title>An Overview on 3GPP Device-to-Device Proximity Services</title><categories>cs.NI</categories><comments>submitted to IEEE Communications Magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-to-device (D2D) communication will likely be added to LTE in 3GPP
Release 12. In principle, exploiting direct communication between nearby mobile
devices will improve spectrum utilization, overall throughput, and energy
consumption, while enabling new peer-to-peer and location-based applications
and services. D2D-enabled LTE devices can also become competitive for fallback
public safety networks, that must function when cellular networks are not
available, or fail. Introducing D2D poses many challenges and risks to the
long-standing cellular architecture, which is centered around the base station.
We provide an overview on D2D standardization activities in 3GPP, identify
outstanding technical challenges, draw lessons from initial evaluation studies,
and summarize &quot;best practices&quot; in the design of a D2D-enabled air interface for
LTE-based cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0120</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0120</id><created>2013-09-30</created><authors><author><keyname>Chen</keyname><forenames>Zhixiong</forenames></author><author><keyname>Shparlinski</keyname><forenames>Igor E.</forenames></author><author><keyname>Winterhof</keyname><forenames>Arne</forenames></author></authors><title>Covering sets for limited-magnitude errors</title><categories>cs.IT math.IT math.NT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a set
  $\cM=\{-\mu,-\mu+1,\ldots, \lambda\}\setminus\{0\}$ with non-negative
integers $\lambda,\mu&lt;q$ not both 0, a subset $\cS$ of the residue class ring
$\Z_q$ modulo an integer $q\ge 1$ is called a $(\lambda,\mu;q)$-\emph{covering
set} if $$ \cM \cS=\{ms \bmod q : m\in \cM,\ s\in \cS\}=\Z_q. $$ Small covering
sets play an important role in codes correcting limited-magnitude errors. We
give an explicit construction of a $(\lambda,\mu;q)$-covering set $\cS$ which
is of the size $q^{1 + o(1)}\max\{\lambda,\mu\}^{-1/2}$ for almost all integers
$q\ge 1$ and of optimal size $p\max\{\lambda,\mu\}^{-1}$ if $q=p$ is prime.
Furthermore, using a bound on the fourth moment of character sums of Cochrane
and Shi we prove the bound $$\omega_{\lambda,\mu}(q)\le
q^{1+o(1)}\max\{\lambda,\mu\}^{-1/2},$$ for any integer $q\ge 1$, however the
proof of this bound is not constructive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0129</identifier>
 <datestamp>2014-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0129</id><created>2013-09-30</created><updated>2014-01-20</updated><authors><author><keyname>Takeoka</keyname><forenames>Masahiro</forenames></author><author><keyname>Guha</keyname><forenames>Saikat</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>The squashed entanglement of a quantum channel</title><categories>quant-ph cs.IT math.IT</categories><comments>v3: 25 pages, 3 figures, significant expansion of paper; v2: error in
  a prior version corrected (main result unaffected), cited Tucci for his work
  related to squashed entanglement; 5 + epsilon pages and 2-page appendix</comments><journal-ref>IEEE Transactions on Information Theory, vol. 60, no. 8, pages
  4987-4998, August 2014</journal-ref><doi>10.1109/TIT.2014.2330313</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper defines the squashed entanglement of a quantum channel as the
maximum squashed entanglement that can be registered by a sender and receiver
at the input and output of a quantum channel, respectively. A new subadditivity
inequality for the original squashed entanglement measure of Christandl and
Winter leads to the conclusion that the squashed entanglement of a quantum
channel is an additive function of a tensor product of any two quantum
channels. More importantly, this new subadditivity inequality, along with prior
results of Christandl, Winter, et al., establishes the squashed entanglement of
a quantum channel as an upper bound on the quantum communication capacity of
any channel assisted by unlimited forward and backward classical communication.
A similar proof establishes this quantity as an upper bound on the private
capacity of a quantum channel assisted by unlimited forward and backward public
classical communication. This latter result is relevant as a limitation on
rates achievable in quantum key distribution. As an important application, we
determine that these capacities can never exceed log((1+eta)/(1-eta)) for a
pure-loss bosonic channel for which a fraction eta of the input photons make it
to the output on average. The best known lower bound on these capacities is
equal to log(1/(1-eta)). Thus, in the high-loss regime for which eta &lt;&lt; 1, this
new upper bound demonstrates that the protocols corresponding to the above
lower bound are nearly optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0132</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0132</id><created>2013-09-30</created><authors><author><keyname>Zhou</keyname><forenames>Jianqin</forenames></author><author><keyname>Liu</keyname><forenames>Jun</forenames></author><author><keyname>Liu</keyname><forenames>Wanquan</forenames></author></authors><title>The 4-error linear complexity distribution for $2^n$-periodic binary
  sequences</title><categories>cs.CR cs.IT math.IT</categories><comments>15 pages. arXiv admin note: substantial text overlap with
  arXiv:1108.5793, arXiv:1112.6047, arXiv:1309.1829</comments><msc-class>94A55, 94A60, 11B50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By using the sieve method of combinatorics, we study $k$-error linear
complexity distribution of $2^n$-periodic binary sequences based on Games-Chan
algorithm. For $k=4,5$, the complete counting functions on the $k$-error linear
complexity of $2^n$-periodic balanced binary sequences (with linear complexity
less than $2^n$) are presented. As a consequence of the result, the complete
counting functions on the 4-error linear complexity of $2^n$-periodic binary
sequences (with linear complexity $2^n$ or less than $2^n$) are obvious.
Generally, the complete counting functions on the $k$-error linear complexity
of $2^n$-periodic binary sequences can be obtained with a similar approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0133</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0133</id><created>2013-09-30</created><authors><author><keyname>Cohen</keyname><forenames>Raphael</forenames></author><author><keyname>Miculescu</keyname><forenames>David</forenames></author><author><keyname>Reilley</keyname><forenames>Kevin</forenames></author><author><keyname>Pakmehr</keyname><forenames>Mehrdad</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Online Performance Optimization of a DC Motor Driving a Variable Pitch
  Propeller</title><categories>math.OC cs.SY</categories><comments>14 pages; 25 figures; this manuscript has been submitted to the 2014
  American Control Conference (ACC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A practical online optimization scheme is developed for performance
optimization of an electrical aircraft propulsion system. The goal is to
minimize the power extraction of the propulsion system for any given thrust
value. The online optimizer computes the optimum pitch angle of a variable
pitch propeller by minimizing the power of the system for a command thrust
value. This algorithm is tested on a DC motor driving a variable pitch
propeller; the experimental hardware setup of the DC motor along with its
variable pitch propeller is also described. Experimental results show the
efficiency and practicality of the proposed online optimization scheme.
Outstanding issues are sketched.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0141</identifier>
 <datestamp>2015-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0141</id><created>2013-10-01</created><updated>2015-02-25</updated><authors><author><keyname>Russakovsky</keyname><forenames>Alexander</forenames></author></authors><title>Hopping over Big Data: Accelerating Ad-hoc OLAP Queries with Grasshopper
  Algorithms</title><categories>cs.DB</categories><acm-class>H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a family of algorithms for fast subset filtering within
ordered sets of integers representing composite keys. Applications include
significant acceleration of (ad-hoc) analytic queries against a data warehouse
without any additional indexing. The algorithms work for point, range and set
restrictions on multiple attributes, in any combination, and are inherently
multidimensional. The main idea consists in intelligent combination of
sequential crawling with jumps over large portions of irrelevant keys. The way
to combine them is adaptive to characteristics of the underlying data store.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0145</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0145</id><created>2013-10-01</created><authors><author><keyname>Barco</keyname><forenames>John</forenames></author><author><keyname>Guerra</keyname><forenames>Andres</forenames></author><author><keyname>Mu&#xf1;oz</keyname><forenames>Luis</forenames></author><author><keyname>Quijano</keyname><forenames>Nicanor</forenames></author></authors><title>Optimal Routing and Scheduling of Charge for Electric Vehicles: Case
  Study</title><categories>cs.SY cs.MA</categories><comments>Highlights: We present a methodology for charging and route
  assignment for a BEVs fleet. We study the case of an airport shuttle service.
  We found the effects of scheduling of charge on the battery lifetime. Some
  conditions to perform a V2B operation are presented. V2B operation is only
  profitable under nonrealistic scenarios</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Colombia, there is an increasing interest about improving public
transportation. One of the proposed strategies in that way is the use battery
electric vehicles (BEVs). One of the new challenges is the BEVs routing
problem, which is subjected to the traditional issues of the routing problems,
and must also consider the particularities of autonomy, charge and battery
degradation of the BEVs. In this work, a scheme that coordinates the routing,
scheduling of charge and operating costs of BEVs is proposed. The simplified
operating costs have been modeled considering both charging fees and battery
degradation. A case study is presented, in order to illustrate the proposed
methodology. The given case considers an airport shuttle service scenario, in
which energy consumption of the BEVs is estimated based on experimentally
measured driving patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0152</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0152</id><created>2013-10-01</created><authors><author><keyname>Ripon</keyname><forenames>Shamim</forenames></author><author><keyname>Hossain</keyname><forenames>Sk. Jahir</forenames></author><author><keyname>Bhuiyan</keyname><forenames>Touhid</forenames></author></authors><title>Managing and Analysing Software Product Line Requirements</title><categories>cs.SE</categories><comments>13 pages, 11 figures</comments><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.4, No.5, September 2013</journal-ref><doi>10.5121/ijsea.2013.4505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modelling software product line (SPL) features plays a crucial role to a
successful development of SPL. Feature diagram is one of the widely used
notations to model SPL variants. However, there is a lack of precisely defined
formal notations for representing and verifying such models. This paper
presents an approach that we adopt to model SPL variants by using UML and
subsequently verify them by using first-order logic. UML provides an overall
modelling view of the system. First-order logic provides a precise and rigorous
interpretation of the feature diagrams. We model variants and their
dependencies by using propositional connectives and build logical expressions.
These expressions are then validated by the Alloy verification tool. The
analysis and verification process is illustrated by using Computer Aided
Dispatch (CAD) system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0154</identifier>
 <datestamp>2015-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0154</id><created>2013-10-01</created><updated>2015-02-13</updated><authors><author><keyname>Chen</keyname><forenames>Yudong</forenames></author></authors><title>Incoherence-Optimal Matrix Completion</title><categories>cs.IT cs.LG math.IT stat.ML</categories><comments>Fixed a minor error in Theorem 3 for matrix decomposition. To appear
  in the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the matrix completion problem. We show that it is not
necessary to assume joint incoherence, which is a standard but unintuitive and
restrictive condition that is imposed by previous studies. This leads to a
sample complexity bound that is order-wise optimal with respect to the
incoherence parameter (as well as to the rank $r$ and the matrix dimension $n$
up to a log factor). As a consequence, we improve the sample complexity of
recovering a semidefinite matrix from $O(nr^{2}\log^{2}n)$ to $O(nr\log^{2}n)$,
and the highest allowable rank from $\Theta(\sqrt{n}/\log n)$ to
$\Theta(n/\log^{2}n)$. The key step in proof is to obtain new bounds on the
$\ell_{\infty,2}$-norm, defined as the maximum of the row and column norms of a
matrix. To illustrate the applicability of our techniques, we discuss
extensions to SVD projection, structured matrix completion and semi-supervised
clustering, for which we provide order-wise improvements over existing results.
Finally, we turn to the closely-related problem of low-rank-plus-sparse matrix
decomposition. We show that the joint incoherence condition is unavoidable here
for polynomial-time algorithms conditioned on the Planted Clique conjecture.
This means it is intractable in general to separate a rank-$\omega(\sqrt{n})$
positive semidefinite matrix and a sparse matrix. Interestingly, our results
show that the standard and joint incoherence conditions are associated
respectively with the information (statistical) and computational aspects of
the matrix decomposition problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0160</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0160</id><created>2013-10-01</created><authors><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author></authors><title>Modern Summation Methods for Loop Integrals in Quantum Field Theory: The
  Packages Sigma, EvaluateMultiSums and SumProduction</title><categories>cs.SC hep-th math-ph math.MP</categories><comments>Uses the style jpconf</comments><doi>10.1088/1742-6596/523/1/012037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large class of Feynman integrals, like e.g., two-point parameter integrals
with at most one mass and containing local operator insertions, can be
transformed to multi-sums over hypergeometric expressions. In this survey
article we present a difference field approach for symbolic summation that
enables one to simplify such definite nested sums to indefinite nested sums. In
particular, the simplification is given -if possible- in terms of harmonic
sums, generalized harmonic sums, cyclotomic harmonic sums or binomial sums.
Special emphasis is put on the developed packages Sigma, EvaluateMultiSums and
SumProduction that assist in the task to perform these simplifications
completely automatically for huge input expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0163</identifier>
 <datestamp>2014-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0163</id><created>2013-10-01</created><updated>2014-05-01</updated><authors><author><keyname>Herrera-Yag&#xfc;e</keyname><forenames>C</forenames></author><author><keyname>Schneider</keyname><forenames>CM</forenames></author><author><keyname>Smoreda</keyname><forenames>Z</forenames></author><author><keyname>Couronn&#xe9;</keyname><forenames>T</forenames></author><author><keyname>Zufiria</keyname><forenames>PJ</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>MC</forenames></author></authors><title>The elliptic model for social fluxes</title><categories>physics.soc-ph cs.SI</categories><comments>Open sources implementations of the model in R, python and Matlab and
  test dataset available at http://humnetlab.mit.edu/elliptic. Journal of
  Statistical Mechanics: Theory and Experiment (2014) P04022</comments><doi>10.1088/1742-5468/2014/04/P04022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a model (called the elliptic model) is proposed to estimate
the number of social ties between two locations using population data in a
similar manner to how transportation research deals with trips. To overcome the
asymmetry of transportation models, the new model considers that the number of
relationships between two locations is inversely proportional to the population
in the ellipse whose foci are in these two locations. The elliptic model is
evaluated by considering the anonymous communications patterns of 25 million
users from three different countries, where a location has been assigned to
each user based on their most used phone tower or billing zip code. With this
information, spatial social networks are built at three levels of resolution:
tower, city and region for each of the three countries. The elliptic model
achieves a similar performance when predicting communication fluxes as
transportation models do when predicting trips. This shows that human
relationships are influenced at least as much by geography as is human
mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0171</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0171</id><created>2013-10-01</created><authors><author><keyname>Hashimoto</keyname><forenames>Marcelo</forenames></author><author><keyname>Junior</keyname><forenames>Roberto Marcondes Cesar</forenames></author></authors><title>Object Detection Using Keygraphs</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new framework for object detection based on a generalization of
the keypoint correspondence framework. This framework is based on replacing
keypoints by keygraphs, i.e. isomorph directed graphs whose vertices are
keypoints, in order to explore relative and structural information. Unlike
similar works in the literature, we deal directly with graphs in the entire
pipeline: we search for graph correspondences instead of searching for
individual point correspondences and then building graph correspondences from
them afterwards. We also estimate the pose from graph correspondences instead
of falling back to point correspondences through a voting table. The
contributions of this paper are the proposed framework and an implementation
that properly handles its inherent issues of loss of locality and combinatorial
explosion, showing its viability for real-time applications. In particular, we
introduce the novel concept of keytuples to solve a running time issue. The
accuracy of the implementation is shown by results of over 800 experiments with
a well-known database of images. The speed is illustrated by real-time tracking
with two different cameras in ordinary hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0177</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0177</id><created>2013-10-01</created><authors><author><keyname>Fotakis</keyname><forenames>Dimitris</forenames></author><author><keyname>Krysta</keyname><forenames>Piotr</forenames></author><author><keyname>Ventre</keyname><forenames>Carmine</forenames></author></authors><title>Combinatorial Auctions without Money</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic Mechanism Design attempts to marry computation and incentives,
mainly by leveraging monetary transfers between designer and selfish agents
involved. This is principally because in absence of money, very little can be
done to enforce truthfulness. However, in certain applications, money is
unavailable, morally unacceptable or might simply be at odds with the objective
of the mechanism. For example, in Combinatorial Auctions (CAs), the
paradigmatic problem of the area, we aim at solutions of maximum social welfare
but still charge the society to ensure truthfulness. Additionally, truthfulness
of CAs is poorly understood already in the case in which bidders happen to be
interested in only two different sets of goods.
  We focus on the design of incentive-compatible CAs without money in the
general setting of $k$-minded bidders. We trade monetary transfers with the
observation that the mechanism can detect certain lies of the bidders: i.e., we
study truthful CAs with verification and without money. We prove a
characterization of truthful mechanisms, which makes an interesting parallel
with the well-understood case of CAs with money for single-minded bidders. We
then give a host of upper bounds on the approximation ratio obtained by either
deterministic or randomized truthful mechanisms when the sets and valuations
are private knowledge of the bidders. (Most of these mechanisms run in
polynomial time and return solutions with (nearly) best possible approximation
guarantees.) We complement these positive results with a number of lower bounds
(some of which are essentially tight) that hold in the easier case of public
sets. We thus provide an almost complete picture of truthfully approximating
CAs in this general setting with multi-dimensional bidders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0178</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0178</id><created>2013-10-01</created><authors><author><keyname>Hartmann</keyname><forenames>Tanja</forenames></author><author><keyname>Wagner</keyname><forenames>Dorothea</forenames></author></authors><title>Dynamic Gomory-Hu Tree Construction -- fast and simple</title><categories>cs.DS</categories><comments>12 pages, 6 figures, Full version of the ISAAC 2012 publication &quot;Fast
  and Simple Fully-Dynamic Cut Tree Construction&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cut tree (or Gomory-Hu tree) of an undirected weighted graph G=(V,E)
encodes a minimum s-t-cut for each vertex pair {s,t} \subseteq V and can be
iteratively constructed by n-1 maximum flow computations. They solve the
multiterminal network flow problem, which asks for the all-pairs maximum flow
values in a network and at the same time they represent n-1 non-crossing,
linearly independent cuts that constitute a minimum cut basis of G. Hence, cut
trees are resident in at least two fundamental fields of network analysis and
graph theory, which emphasizes their importance for many applications. In this
work we present a fully-dynamic algorithm that efficiently maintains a cut tree
for a changing graph. The algorithm is easy to implement and has a high
potential for saving cut computations under the assumption that a local change
in the underlying graph does rarely affect the global cut structure. We
document the good practicability of our approach in a brief experiment on real
world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0185</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0185</id><created>2013-10-01</created><authors><author><keyname>Chebolu</keyname><forenames>Prasad</forenames></author><author><keyname>Cryan</keyname><forenames>Mary</forenames></author><author><keyname>Martin</keyname><forenames>Russell</forenames></author></authors><title>Exact counting of Euler Tours for Graphs of Bounded Treewidth</title><categories>cs.DM math.CO</categories><comments>16 pages, draft</comments><msc-class>05C85, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we give a simple polynomial-time algorithm to exactly count the
number of Euler Tours (ETs) of any Eulerian graph of bounded treewidth. The
problems of counting ETs are known to be #P-complete for general graphs
(Brightwell and Winkler, (Brightwell and Winkler, 2005). To date, no
polynomial-time algorithm for counting Euler tours of any class of graphs is
known except for the very special case of series-parallel graphs (which have
treewidth 2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0201</identifier>
 <datestamp>2013-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0201</id><created>2013-10-01</created><updated>2013-10-03</updated><authors><author><keyname>Coco</keyname><forenames>Moreno I.</forenames></author><author><keyname>Dale</keyname><forenames>Rick</forenames></author></authors><title>Cross-Recurrence Quantification Analysis of Categorical and Continuous
  Time Series: an R package</title><categories>cs.CL stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the R package crqa to perform cross-recurrence
quantification analysis of two time series of either a categorical or
continuous nature. Streams of behavioral information, from eye movements to
linguistic elements, unfold over time. When two people interact, such as in
conversation, they often adapt to each other, leading these behavioral levels
to exhibit recurrent states. In dialogue, for example, interlocutors adapt to
each other by exchanging interactive cues: smiles, nods, gestures, choice of
words, and so on. In order for us to capture closely the goings-on of dynamic
interaction, and uncover the extent of coupling between two individuals, we
need to quantify how much recurrence is taking place at these levels. Methods
available in crqa would allow researchers in cognitive science to pose such
questions as how much are two people recurrent at some level of analysis, what
is the characteristic lag time for one person to maximally match another, or
whether one person is leading another. First, we set the theoretical ground to
understand the difference between 'correlation' and 'co-visitation' when
comparing two time series, using an aggregative or cross-recurrence approach.
Then, we describe more formally the principles of cross-recurrence, and show
with the current package how to carry out analyses applying them. We end the
paper by comparing computational efficiency, and results' consistency, of crqa
R package, with the benchmark MATLAB toolbox crptoolbox. We show perfect
comparability between the two libraries on both levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0216</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0216</id><created>2013-10-01</created><authors><author><keyname>Das</keyname><forenames>Tamal</forenames></author><author><keyname>Caria</keyname><forenames>Marcel</forenames></author><author><keyname>Jukan</keyname><forenames>Admela</forenames></author><author><keyname>Hoffmann</keyname><forenames>Marco</forenames></author></authors><title>A Techno-economic Analysis of Network Migration to Software-Defined
  Networking</title><categories>cs.NI</categories><comments>6 pages, Submitted to ICC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the Software Defined Networking (SDN) paradigm gains momentum, every
network operator faces the obvious dilemma: when and how to migrate from
existing IP routers to SDN compliant equipments. A single step complete
overhaul of a fully functional network is impractical, while at the same time,
the immediate benefits of SDN are obvious. A viable solution is thus a gradual
migration over time, where questions of which routers should migrate first, and
whether the order of migration makes a difference, can be analyzed from techno
economic and traffic engineering perspective. In this paper, we address these
questions from the techno economic perspective, and establish the importance of
migration scheduling. We propose optimization techniques and greedy algorithms
to plan an effective migration schedule, based on various techno economic
aspects, such as technological gains in combinations with CapEx limitations. We
demonstrate the importance of an effective migration sequence through two
relevant network management metrics, namely, number of alternative paths
availed by a node on migration, and network capacity savings. Our results
suggest that the sequence of migration plays a vital role, especially in the
early stages of network migration to SDN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0229</identifier>
 <datestamp>2014-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0229</id><created>2013-10-01</created><updated>2014-03-26</updated><authors><author><keyname>Casas-Roma</keyname><forenames>Jordi</forenames></author><author><keyname>Herrera-Joancomart&#xed;</keyname><forenames>Jordi</forenames></author><author><keyname>Torra</keyname><forenames>Vicen&#xe7;</forenames></author></authors><title>Evolutionary Algorithm for Graph Anonymization</title><categories>cs.DB cs.SI</categories><comments>6 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent years there has been a significant increase in the use of graphs as
a tool for representing information. It is very important to preserve the
privacy of users when one wants to publish this information, especially in the
case of social graphs. In this case, it is essential to implement an
anonymization process in the data in order to preserve users' privacy. In this
paper we present an algorithm for graph anonymization, called Evolutionary
Algorithm for Graph Anonymization (EAGA), based on edge modifications to
preserve the k-anonymity model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0234</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0234</id><created>2013-10-01</created><authors><author><keyname>Shi</keyname><forenames>Yuanming</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Group Sparse Beamforming for Green Cloud-RAN</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cloud radio access network (Cloud-RAN) is a network architecture that holds
the promise of meeting the explosive growth of mobile data traffic. In this
architecture, all the baseband signal processing is shifted to a single
baseband unit (BBU) pool, which enables efficient resource allocation and
interference management. Meanwhile, conventional powerful base stations can be
replaced by low-cost low-power remote radio heads (RRHs), producing a green and
low-cost infrastructure. However, as all the RRHs need to be connected to the
BBU pool through optical transport links, the transport network power
consumption becomes significant. In this paper, we propose a new framework to
design a green Cloud-RAN, which is formulated as a joint RRH selection and
power minimization beamforming problem. To efficiently solve this problem, we
first propose a greedy selection algorithm, which is shown to provide near-
optimal performance. To further reduce the complexity, a novel group sparse
beamforming method is proposed by inducing the group-sparsity of beamformers
using the weighted $\ell_1/\ell_2$-norm minimization, where the group sparsity
pattern indicates those RRHs that can be switched off. Simulation results will
show that the proposed algorithms significantly reduce the network power
consumption and demonstrate the importance of considering the transport link
power consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0242</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0242</id><created>2013-10-01</created><authors><author><keyname>Bruntink</keyname><forenames>Magiel</forenames></author></authors><title>Towards Base Rates in Software Analytics</title><categories>cs.SE</categories><comments>Accepted for publication in the Science of Computer Programming
  special issue &quot;the Future of Understanding Software&quot;, honouring Paul Klint's
  65th birthday</comments><acm-class>D.2.8; D.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays a vast and growing body of open source software (OSS) project data
is publicly available on the internet. Despite this public body of project
data, the field of software analytics has not yet settled on a solid
quantitative base for basic properties such as code size, growth, team size,
activity, and project failure. What is missing is a quantification of the base
rates of such properties, where other fields (such as medicine) commonly rely
on base rates for decision making and the evaluation of experimental results.
The lack of knowledge in this area impairs both research activities in the
field of software analytics and decision making on software projects in
general. This paper contributes initial results of our research towards
obtaining base rates using the data available at Ohloh (a large-scale index of
OSS projects). Zooming in on the venerable 'lines of code' metric for code size
and growth, we present and discuss summary statistics and identify further
research challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0250</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0250</id><created>2013-10-01</created><authors><author><keyname>Glauner</keyname><forenames>Patrick O.</forenames></author><author><keyname>Iwaszkiewicz</keyname><forenames>Jan</forenames></author><author><keyname>Meur</keyname><forenames>Jean-Yves Le</forenames></author><author><keyname>Simko</keyname><forenames>Tibor</forenames></author></authors><title>Use of Solr and Xapian in the Invenio document repository software</title><categories>cs.IR cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Invenio is a free comprehensive web-based document repository and digital
library software suite originally developed at CERN. It can serve a variety of
use cases from an institutional repository or digital library to a web journal.
In order to fully use full-text documents for efficient search and ranking,
Solr was integrated into Invenio through a generic bridge. Solr indexes
extracted full-texts and most relevant metadata. Consequently, Invenio takes
advantage of Solr's efficient search and word similarity ranking capabilities.
In this paper, we first give an overview of Invenio, its capabilities and
features. We then present our open source Solr integration as well as
scalability challenges that arose for an Invenio-based multi-million record
repository: the CERN Document Server. We also compare our Solr adapter to an
alternative Xapian adapter using the same generic bridge. Both integrations are
distributed with the Invenio package and ready to be used by the institutions
using or adopting Invenio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0251</identifier>
 <datestamp>2014-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0251</id><created>2013-10-01</created><updated>2014-01-28</updated><authors><author><keyname>Qadir</keyname><forenames>Junaid</forenames></author><author><keyname>Ahmed</keyname><forenames>Nadeem</forenames></author><author><keyname>Ahad</keyname><forenames>Nauman</forenames></author></authors><title>Building Programmable Wireless Networks: An Architectural Survey</title><categories>cs.NI</categories><comments>19 pages</comments><journal-ref>EURASIP JWCN, October, 2014</journal-ref><doi>10.1186/1687-1499-2014-172</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent times, there have been a lot of efforts for improving the ossified
Internet architecture in a bid to sustain unstinted growth and innovation. A
major reason for the perceived architectural ossification is the lack of
ability to program the network as a system. This situation has resulted partly
from historical decisions in the original Internet design which emphasized
decentralized network operations through co-located data and control planes on
each network device. The situation for wireless networks is no different
resulting in a lot of complexity and a plethora of largely incompatible
wireless technologies. The emergence of &quot;programmable wireless networks&quot;, that
allow greater flexibility, ease of management and configurability, is a step in
the right direction to overcome the aforementioned shortcomings of the wireless
networks. In this paper, we provide a broad overview of the architectures
proposed in literature for building programmable wireless networks focusing
primarily on three popular techniques, i.e., software defined networks,
cognitive radio networks, and virtualized networks. This survey is a
self-contained tutorial on these techniques and its applications. We also
discuss the opportunities and challenges in building next-generation
programmable wireless networks and identify open research issues and future
research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0263</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0263</id><created>2013-10-01</created><authors><author><keyname>Melli&#xe8;s</keyname><forenames>Paul-Andr&#xe9;</forenames></author><author><keyname>Zeilberger</keyname><forenames>Noam</forenames></author></authors><title>Type refinement and monoidal closed bifibrations</title><categories>cs.LO cs.PL math.CT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of_refinement_ in type theory is a way of reconciling the
&quot;intrinsic&quot; and the &quot;extrinsic&quot; meanings of types. We begin with a rigorous
analysis of this concept, settling on the simple conclusion that the
type-theoretic notion of &quot;type refinement system&quot; may be identified with the
category-theoretic notion of &quot;functor&quot;. We then use this correspondence to give
an equivalent type-theoretic formulation of Grothendieck's definition of
(bi)fibration, and extend this to a definition of_monoidal closed
bifibrations_, which we see as a natural space in which to study the properties
of proofs and programs. Our main result is a representation theorem for strong
monads on a monoidal closed fibration, describing sufficient conditions for a
monad to be isomorphic to a continuations monad &quot;up to pullback&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0282</identifier>
 <datestamp>2015-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0282</id><created>2013-10-01</created><updated>2013-11-17</updated><authors><author><keyname>Liu</keyname><forenames>Yu</forenames></author><author><keyname>Sui</keyname><forenames>Zhengwei</forenames></author><author><keyname>Kang</keyname><forenames>Chaogui</forenames></author><author><keyname>Gao</keyname><forenames>Yong</forenames></author></authors><title>Uncovering patterns of inter-urban trip and spatial interaction from
  social media check-in data</title><categories>cs.SI physics.soc-ph</categories><comments>20 pages, 10 figures</comments><journal-ref>PLoS ONE 9(1): e86026</journal-ref><doi>10.1371/journal.pone.0086026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article revisits spatial interaction and distance decay from the
perspective of human mobility patterns and spatially-embedded networks based on
an empirical data set. We extract nationwide inter-urban movements in China
from a check-in data set that covers half million individuals and 370 cities to
analyze the underlying patterns of trips and spatial interactions. By fitting
the gravity model, we find that the observed spatial interactions are governed
by a power law distance decay effect. The obtained gravity model also well
reproduces the exponential trip displacement distribution. However, due to the
ecological fallacy issue, the movement of an individual may not obey the same
distance decay effect. We also construct a spatial network where the edge
weights denote the interaction strengths. The communities detected from the
network are spatially connected and roughly consistent with province
boundaries. We attribute this pattern to different distance decay parameters
between intra-province and inter-province trips.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0291</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0291</id><created>2013-10-01</created><updated>2014-01-27</updated><authors><author><keyname>Tsang</keyname><forenames>Mankei</forenames></author></authors><title>Mismatched Quantum Filtering and Entropic Information</title><categories>quant-ph cs.IT math.IT</categories><comments>v1: first draft, 8 pages, v2: added introduction and more results on
  mutual information and channel capacity, 12 pages, v3: minor updates, v4:
  updated the presentation</comments><journal-ref>Proceedings of IEEE International Symposium on Information Theory,
  Honolulu, Hawaii, USA, June 29-July 4 2014, pp. 321-325</journal-ref><doi>10.1109/ISIT.2014.6874847</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum filtering is a signal processing technique that estimates the
posterior state of a quantum system under continuous measurements and has
become a standard tool in quantum information processing, with applications in
quantum state preparation, quantum metrology, and quantum control. If the
filter assumes a nominal model that differs from reality, however, the
estimation accuracy is bound to suffer. Here I derive identities that relate
the excess error caused by quantum filter mismatch to the relative entropy
between the true and nominal observation probability measures, with one
identity for Gaussian measurements, such as optical homodyne detection, and
another for Poissonian measurements, such as photon counting. These identities
generalize recent seminal results in classical information theory and provide
new operational meanings to relative entropy, mutual information, and channel
capacity in the context of quantum experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0296</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0296</id><created>2013-10-01</created><authors><author><keyname>Kawai</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Bellman</keyname><forenames>Matthew J.</forenames></author><author><keyname>Downey</keyname><forenames>Ryan J.</forenames></author><author><keyname>Dixon</keyname><forenames>Warren E.</forenames></author></authors><title>Tracking Control for FES-Cycling based on Force Direction Efficiency
  with Antagonistic Bi-Articular Muscles</title><categories>cs.SY</categories><comments>8 pages, 4 figures, submitted to ACC2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A functional electrical stimulation (FES)-based tracking controller is
developed to enable cycling based on a strategy to yield force direction
efficiency by exploiting antagonistic bi-articular muscles. Given the input
redundancy naturally occurring among multiple muscle groups, the force
direction at the pedal is explicitly determined as a means to improve the
efficiency of cycling. A model of a stationary cycle and rider is developed as
a closed-chain mechanism. A strategy is then developed to switch between muscle
groups for improved efficiency based on the force direction of each muscle
group. Stability of the developed controller is analyzed through Lyapunov-based
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0302</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0302</id><created>2013-10-01</created><authors><author><keyname>Hrgeti&#x107;</keyname><forenames>Vedran</forenames></author><author><keyname>Pribani&#x107;</keyname><forenames>Tomislav</forenames></author></authors><title>Surface Registration Using Genetic Algorithm in Reduced Search Space</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0018</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Surface registration is a technique that is used in various areas such as
object recognition and 3D model reconstruction. Problem of surface registration
can be analyzed as an optimization problem of seeking a rigid motion between
two different views. Genetic algorithms can be used for solving this
optimization problem, both for obtaining the robust parameter estimation and
for its fine-tuning. The main drawback of genetic algorithms is that they are
time consuming which makes them unsuitable for online applications. Modern
acquisition systems enable the implementation of the solutions that would
immediately give the information on the rotational angles between the different
views, thus reducing the dimension of the optimization problem. The paper gives
an analysis of the genetic algorithm implemented in the conditions when the
rotation matrix is known and a comparison of these results with results when
this information is not available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0305</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0305</id><created>2013-10-01</created><authors><author><keyname>Mu&#x161;tra</keyname><forenames>Mario</forenames></author><author><keyname>Grgi&#x107;</keyname><forenames>Mislav</forenames></author></authors><title>Filtering for More Accurate Dense Tissue Segmentation in Digitized
  Mammograms</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0019</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Breast tissue segmentation into dense and fat tissue is important for
determining the breast density in mammograms. Knowing the breast density is
important both in diagnostic and computer-aided detection applications. There
are many different ways to express the density of a breast and good quality
segmentation should provide the possibility to perform accurate classification
no matter which classification rule is being used. Knowing the right breast
density and having the knowledge of changes in the breast density could give a
hint of a process which started to happen within a patient. Mammograms
generally suffer from a problem of different tissue overlapping which results
in the possibility of inaccurate detection of tissue types. Fibroglandular
tissue presents rather high attenuation of X-rays and is visible as brighter in
the resulting image but overlapping fibrous tissue and blood vessels could
easily be replaced with fibroglandular tissue in automatic segmentation
algorithms. Small blood vessels and microcalcifications are also shown as
bright objects with similar intensities as dense tissue but do have some
properties which makes possible to suppress them from the final results. In
this paper we try to divide dense and fat tissue by suppressing the scattered
structures which do not represent glandular or dense tissue in order to divide
mammograms more accurately in the two major tissue types. For suppressing blood
vessels and microcalcifications we have used Gabor filters of different size
and orientation and a combination of morphological operations on filtered image
with enhanced contrast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0306</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0306</id><created>2013-10-01</created><authors><author><keyname>Petkovi&#x107;</keyname><forenames>Tomislav</forenames></author><author><keyname>Juri&#x107;</keyname><forenames>Darko</forenames></author><author><keyname>Lon&#x10d;ari&#x107;</keyname><forenames>Sven</forenames></author></authors><title>Flexible Visual Quality Inspection in Discrete Manufacturing</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0020</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Most visual quality inspections in discrete manufacturing are composed of
length, surface, angle or intensity measurements. Those are implemented as
end-user configurable inspection tools that should not require an image
processing expert to set up. Currently available software solutions providing
such capability use a flowchart based programming environment, but do not fully
address an inspection flowchart robustness and can require a redefinition of
the flowchart if a small variation is introduced. In this paper we propose an
acquire-register-analyze image processing pattern designed for discrete
manufacturing that aims to increase the robustness of the inspection flowchart
by consistently addressing variations in product position, orientation and
size. A proposed pattern is transparent to the end-user and simplifies the
flowchart. We describe a developed software solution that is a practical
implementation of the proposed pattern. We give an example of its real-life use
in industrial production of electric components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0307</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0307</id><created>2013-10-01</created><updated>2013-10-02</updated><authors><author><keyname>Bani&#x107;</keyname><forenames>Nikola</forenames></author><author><keyname>Lon&#x10d;ari&#x107;</keyname><forenames>Sven</forenames></author></authors><title>Using the Random Sprays Retinex Algorithm for Global Illumination
  Estimation</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0010</report-no><doi>10.1109/LSP.2013.2285960</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper the use of Random Sprays Retinex (RSR) algorithm for global
illumination estimation is proposed and its feasibility tested. Like other
algorithms based on the Retinex model, RSR also provides local illumination
estimation and brightness adjustment for each pixel and it is faster than other
path-wise Retinex algorithms. As the assumption of the uniform illumination
holds in many cases, it should be possible to use the mean of local
illumination estimations of RSR as a global illumination estimation for images
with (assumed) uniform illumination allowing also the accuracy to be easily
measured. Therefore we propose a method for estimating global illumination
estimation based on local RSR results. To our best knowledge this is the first
time that RSR algorithm is used to obtain global illumination estimation. For
our tests we use a publicly available color constancy image database for
testing. The results are presented and discussed and it turns out that the
proposed method outperforms many existing unsupervised color constancy
algorithms. The source code is available at
http://www.fer.unizg.hr/ipg/resources/color_constancy/.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0308</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0308</id><created>2013-10-01</created><authors><author><keyname>Brki&#x107;</keyname><forenames>Karla</forenames></author><author><keyname>Ra&#x161;i&#x107;</keyname><forenames>Sr&#x111;an</forenames></author><author><keyname>Pinz</keyname><forenames>Axel</forenames></author><author><keyname>&#x160;egvi&#x107;</keyname><forenames>Sini&#x161;a</forenames></author><author><keyname>Kalafati&#x107;</keyname><forenames>Zoran</forenames></author></authors><title>Combining Spatio-Temporal Appearance Descriptors and Optical Flow for
  Human Action Recognition in Video Data</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0011</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper proposes combining spatio-temporal appearance (STA) descriptors
with optical flow for human action recognition. The STA descriptors are local
histogram-based descriptors of space-time, suitable for building a partial
representation of arbitrary spatio-temporal phenomena. Because of the
possibility of iterative refinement, they are interesting in the context of
online human action recognition. We investigate the use of dense optical flow
as the image function of the STA descriptor for human action recognition, using
two different algorithms for computing the flow: the Farneb\&quot;ack algorithm and
the TVL1 algorithm. We provide a detailed analysis of the influencing optical
flow algorithm parameters on the produced optical flow fields. An extensive
experimental validation of optical flow-based STA descriptors in human action
recognition is performed on the KTH human action dataset. The encouraging
experimental results suggest the potential of our approach in online human
action recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0309</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0309</id><created>2013-10-01</created><updated>2013-11-25</updated><authors><author><keyname>Charlier</keyname><forenames>Emilie</forenames></author><author><keyname>Leroy</keyname><forenames>Julien</forenames></author><author><keyname>Rigo</keyname><forenames>Michel</forenames></author></authors><title>An analogue of Cobham's theorem for graph directed iterated function
  systems</title><categories>math.DS cs.FL</categories><comments>30 pages; updated version, including a new introduction and some new
  references</comments><msc-class>28A80 (primary), and 28A78, 11B85, 68Q70, 11K16 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feng and Wang showed that two homogeneous iterated function systems in
$\mathbb{R}$ with multiplicatively independent contraction ratios necessarily
have different attractors. In this paper, we extend this result to graph
directed iterated function systems in $\mathbb{R}^n$ with contraction ratios
that are of the form $\frac{1}{\beta}$, for integers $\beta$. By using a result
of Boigelot et al., this allows us to give a proof of a conjecture of
Adamczewski and Bell. In doing so, we link the graph directed iterated function
systems to B\&quot;uchi automata. In particular, this link extends to real numbers
$\beta$. We introduce a logical formalism that permits to characterize sets of
$\mathbb{R}^n$ whose representations in base $\beta$ are recognized by some
B\&quot;uchi automata. This result depends on the algebraic properties of the base:
$\beta$ being a Pisot or a Parry number. The main motivation of this work is to
draw a general picture representing the different frameworks where an analogue
of Cobham's theorem is known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0310</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0310</id><created>2013-10-01</created><authors><author><keyname>Kre&#x161;o</keyname><forenames>Ivan</forenames></author><author><keyname>&#x160;evrovi&#x107;</keyname><forenames>Marko</forenames></author><author><keyname>&#x160;egvi&#x107;</keyname><forenames>Sini&#x161;a</forenames></author></authors><title>A Novel Georeferenced Dataset for Stereo Visual Odometry</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0017</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work, we present a novel dataset for assessing the accuracy of stereo
visual odometry. The dataset has been acquired by a small-baseline stereo rig
mounted on the top of a moving car. The groundtruth is supplied by a consumer
grade GPS device without IMU. Synchronization and alignment between GPS
readings and stereo frames are recovered after the acquisition. We show that
the attained groundtruth accuracy allows to draw useful conclusions in
practice. The presented experiments address influence of camera calibration,
baseline distance and zero-disparity features to the achieved reconstruction
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0311</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0311</id><created>2013-10-01</created><authors><author><keyname>Zadrija</keyname><forenames>Valentina</forenames></author><author><keyname>&#x160;egvi&#x107;</keyname><forenames>Sini&#x161;a</forenames></author></authors><title>Multiclass Road Sign Detection using Multiplicative Kernel</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0016</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We consider the problem of multiclass road sign detection using a
classification function with multiplicative kernel comprised from two kernels.
We show that problems of detection and within-foreground classification can be
jointly solved by using one kernel to measure object-background differences and
another one to account for within-class variations. The main idea behind this
approach is that road signs from different foreground variations can share
features that discriminate them from backgrounds. The classification function
training is accomplished using SVM, thus feature sharing is obtained through
support vector sharing. Training yields a family of linear detectors, where
each detector corresponds to a specific foreground training sample. The
redundancy among detectors is alleviated using k-medoids clustering. Finally,
we report detection and classification results on a set of road sign images
obtained from a camera on a moving vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0312</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0312</id><created>2013-10-01</created><updated>2014-10-30</updated><authors><author><keyname>Nesti</keyname><forenames>Alessandro</forenames></author><author><keyname>Beykirch</keyname><forenames>Karl A</forenames></author><author><keyname>MacNeilage</keyname><forenames>Paul R</forenames></author><author><keyname>Barnett-Cowan</keyname><forenames>Michael</forenames></author><author><keyname>B&#xfc;lthoff</keyname><forenames>Heinrich H</forenames></author></authors><title>The importance of stimulus noise analysis for self-motion studies</title><categories>cs.SY q-bio.NC</categories><comments>24 pages, 6 figures, 1 table</comments><doi>10.1371/journal.pone.0094570</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion simulators are widely employed in basic and applied research to study
the neural mechanisms of perception and action under inertial stimulations. In
these studies, uncontrolled simulator-introduced noise inevitably leads to a
mismatch between the reproduced motion and the trajectories meticulously
designed by the experimenter, possibly resulting in undesired motion cues to
the investigated system. An understanding of the simulator response to
different motion commands is therefore a crucial yet often underestimated step
towards the interpretation of experimental results. In this work, we developed
analysis methods based on signal processing techniques to quantify the noise in
the actual motion, and its deterministic and stochastic components. Our methods
allow comparisons between commanded and actual motion as well as between
different actual motion profiles. A specific practical example from one of our
studies is used to illustrate the methodologies and their relevance, but this
does not detract from its general applicability. Analyses of the simulator
inertial recordings show direction-dependent noise and nonlinearity related to
the command amplitude. The Signal-to-Noise Ratio is one order of magnitude
higher for the larger motion amplitudes we tested, compared to the smaller
motion amplitudes. Deterministic and stochastic noise components are of similar
magnitude for the weaker motions, whereas for stronger motions the
deterministic component dominates the stochastic component. The effect of
simulator noise on animal/human motion sensitivity is discussed. We conclude
that accurate analyses of a simulator motion are a crucial prerequisite for the
investigation of uncertainty in self-motion perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0314</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0314</id><created>2013-10-01</created><authors><author><keyname>Cupec</keyname><forenames>Robert</forenames></author><author><keyname>Nyarko</keyname><forenames>Emmanuel Karlo</forenames></author><author><keyname>Filko</keyname><forenames>Damir</forenames></author><author><keyname>Kitanov</keyname><forenames>Andrej</forenames></author><author><keyname>Petrovi&#x107;</keyname><forenames>Ivan</forenames></author></authors><title>Global Localization Based on 3D Planar Surface Segments</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0015</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Global localization of a mobile robot using planar surface segments extracted
from depth images is considered. The robot's environment is represented by a
topological map consisting of local models, each representing a particular
location modeled by a set of planar surface segments. The discussed
localization approach segments a depth image acquired by a 3D camera into
planar surface segments which are then matched to model surface segments. The
robot pose is estimated by the Extended Kalman Filter using surface segment
pairs as measurements. The reliability and accuracy of the considered approach
are experimentally evaluated using a mobile robot equipped by a Microsoft
Kinect sensor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0315</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0315</id><created>2013-10-01</created><authors><author><keyname>Kova&#x10d;i&#x107;</keyname><forenames>Kristian</forenames></author><author><keyname>Ivanjko</keyname><forenames>Edouard</forenames></author><author><keyname>Gold</keyname><forenames>Hrvoje</forenames></author></authors><title>Computer Vision Systems in Road Vehicles: A Review</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0014</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The number of road vehicles significantly increased in recent decades. This
trend accompanied a build-up of road infrastructure and development of various
control systems to increase road traffic safety, road capacity and travel
comfort. In traffic safety significant development has been made and today's
systems more and more include cameras and computer vision methods. Cameras are
used as part of the road infrastructure or in vehicles. In this paper a review
on computer vision systems in vehicles from the stand point of traffic
engineering is given. Safety problems of road vehicles are presented, current
state of the art in-vehicle vision systems is described and open problems with
future research directions are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0316</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0316</id><created>2013-10-01</created><authors><author><keyname>Sikiri&#x107;</keyname><forenames>Ivan</forenames></author><author><keyname>Brki&#x107;</keyname><forenames>Karla</forenames></author><author><keyname>&#x160;egvi&#x107;</keyname><forenames>Sini&#x161;a</forenames></author></authors><title>Classifying Traffic Scenes Using The GIST Image Descriptor</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0013</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper investigates classification of traffic scenes in a very low
bandwidth scenario, where an image should be coded by a small number of
features. We introduce a novel dataset, called the FM1 dataset, consisting of
5615 images of eight different traffic scenes: open highway, open road,
settlement, tunnel, tunnel exit, toll booth, heavy traffic and the overpass. We
evaluate the suitability of the GIST descriptor as a representation of these
images, first by exploring the descriptor space using PCA and k-means
clustering, and then by using an SVM classifier and recording its 10-fold
cross-validation performance on the introduced FM1 dataset. The obtained
recognition rates are very encouraging, indicating that the use of the GIST
descriptor alone could be sufficiently descriptive even when very high
performance is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0317</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0317</id><created>2013-10-01</created><authors><author><keyname>Lopar</keyname><forenames>Markan</forenames></author><author><keyname>Ribari&#x107;</keyname><forenames>Slobodan</forenames></author></authors><title>An Overview and Evaluation of Various Face and Eyes Detection Algorithms
  for Driver Fatigue Monitoring Systems</title><categories>cs.CV</categories><comments>Part of the Proceedings of the Croatian Computer Vision Workshop,
  CCVW 2013, Year 1</comments><report-no>UniZg-CRV-CCVW/2013/0012</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work various methods and algorithms for face and eyes detection are
examined in order to decide which of them are applicable for use in a driver
fatigue monitoring system. In the case of face detection the standard
Viola-Jones face detector has shown best results, while the method of finding
the eye centers by means of gradients has proven to be most appropriate in the
case of eyes detection. The later method has also a potential for retrieving
behavioral parameters needed for estimation of the level of driver fatigue.
This possibility will be examined in future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0319</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0319</id><created>2013-10-01</created><updated>2013-11-03</updated><authors><author><keyname>Lon&#x10d;ari&#x107;</keyname><forenames>Sven</forenames></author><author><keyname>&#x160;egvi&#x107;</keyname><forenames>Sini&#x161;a</forenames></author></authors><title>Second Croatian Computer Vision Workshop (CCVW 2013)</title><categories>cs.CV</categories><comments>Papers presented at the Second Croatian Computer Vision Workshop CCVW
  2013</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Proceedings of the Second Croatian Computer Vision Workshop (CCVW 2013,
http://www.fer.unizg.hr/crv/ccvw2013) held September 19, 2013, in Zagreb,
Croatia. Workshop was organized by the Center of Excellence for Computer Vision
of the University of Zagreb.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0322</identifier>
 <datestamp>2014-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0322</id><created>2013-10-01</created><updated>2014-06-25</updated><authors><author><keyname>Kirisits</keyname><forenames>Clemens</forenames></author><author><keyname>Lang</keyname><forenames>Lukas F.</forenames></author><author><keyname>Scherzer</keyname><forenames>Otmar</forenames></author></authors><title>Optical Flow on Evolving Surfaces with Space and Time Regularisation</title><categories>math.OC cs.CV</categories><comments>The final publication is available at Springer via
  http://dx.doi.org/10.1007/s10851-014-0513-4. This is an extended version of
  arXiv:1301.1576</comments><doi>10.1007/s10851-014-0513-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the concept of optical flow with spatiotemporal regularisation to a
dynamic non-Euclidean setting. Optical flow is traditionally computed from a
sequence of flat images. The purpose of this paper is to introduce variational
motion estimation for images that are defined on an evolving surface.
Volumetric microscopy images depicting a live zebrafish embryo serve as both
biological motivation and test data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0337</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0337</id><created>2013-09-28</created><authors><author><keyname>Tu</keyname><forenames>Ziran</forenames></author><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author><author><keyname>Li</keyname><forenames>Chunlei</forenames></author></authors><title>A Class of Binomial Permutation Polynomials</title><categories>math.NT cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, a criterion for a class of binomials to be permutation
polynomials is proposed. As a consequence, many classes of binomial permutation
polynomials and monomial complete permutation polynomials are obtained. The
exponents in these monomials are of Niho type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0340</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0340</id><created>2013-09-28</created><authors><author><keyname>Hell</keyname><forenames>Pavol</forenames></author><author><keyname>Huang</keyname><forenames>Shenwei</forenames></author></authors><title>Complexity of Coloring Graphs without Paths and Cycles</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P_t$ and $C_\ell$ denote a path on $t$ vertices and a cycle on $\ell$
vertices, respectively. In this paper we study the $k$-coloring problem for
$(P_t,C_\ell)$-free graphs. Maffray and Morel, and Bruce, Hoang and Sawada,
have proved that 3-colorability of $P_5$-free graphs has a finite forbidden
induced subgraphs characterization, while Hoang, Moore, Recoskie, Sawada, and
Vatshelle have shown that $k$-colorability of $P_5$-free graphs for $k \geq 4$
does not. These authors have also shown, aided by a computer search, that
4-colorability of $(P_5,C_5)$-free graphs does have a finite forbidden induced
subgraph characterization. We prove that for any $k$, the $k$-colorability of
$(P_6,C_4)$-free graphs has a finite forbidden induced subgraph
characterization. We provide the full lists of forbidden induced subgraphs for
$k=3$ and $k=4$. As an application, we obtain certifying polynomial time
algorithms for 3-coloring and 4-coloring $(P_6,C_4)$-free graphs. (Polynomial
time algorithms have been previously obtained by Golovach, Paulusma, and Song,
but those algorithms are not certifying); To complement these results we show
that in most other cases the $k$-coloring problem for $(P_t,C_\ell)$-free
graphs is NP-complete. Specifically, for $\ell=5$ we show that $k$-coloring is
NP-complete for $(P_t,C_5)$-free graphs when $k \ge 4$ and $t \ge 7$; for $\ell
\ge 6$ we show that $k$-coloring is NP-complete for $(P_t,C_\ell)$-free graphs
when $k \ge 5$, $t \ge 6$; and additionally, for $\ell=7$, we show that
$k$-coloring is also NP-complete for $(P_t,C_7)$-free graphs if $k = 4$ and
$t\ge 9$. This is the first systematic study of the complexity of the
$k$-coloring problem for $(P_t,C_\ell)$-free graphs. We almost completely
classify the complexity for the cases when $k \geq 4, \ell \geq 4$, and
identify the last three open cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0346</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0346</id><created>2013-10-01</created><authors><author><keyname>Rost</keyname><forenames>Matthias</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author></authors><title>The Constrained Virtual Steiner Arborescence Problem: Formal Definition,
  Single-Commodity Integer Programming Formulation and Computational Evaluation</title><categories>cs.NI cs.DC math.OC</categories><comments>A conference version of this Paper will appear in the proceedings of
  OPODIS 2013, (c) Springer LNCS. It will be available at link.springer.com</comments><acm-class>C.2.1; C.2.3; C.2.4; G.1.6; G.2.2; G.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the Internet becomes more virtualized and software-defined, new
functionality is introduced in the network core: the distributed resources
available in ISP central offices, universal nodes, or datacenter middleboxes
can be used to process (e.g., filter, aggregate or duplicate) data. Based on
this new networking paradigm, we formulate the Constrained Virtual Steiner
Arborescence Problem (CVSAP) which asks for optimal locations to perform
In-network processing, in order to jointly minimize processing costs and
network traffic while respecting link and node capacities.
  We prove that CVSAP cannot be approximated (unless P = NP), and accordingly,
develop the exact algorithm VirtuCast to compute (near) optimal solutions.
VirtuCast consists of: (1) a compact single-commodity flow Integer Programming
(IP) formulation; (2) a flow decomposition algorithm to reconstruct individual
routes from the IP solution. The compactness of the IP formulation allows for
computing lower bounds even on large instances quickly, speeding up the
algorithm. We rigorously prove VirtuCast's correctness.
  To complement our theoretical findings, we have implemented VirtuCast and
present an extensive computational evaluation, showing that using VirtuCast
realistically sized instances can be solved (close to) optimality. We show that
VirtuCast significantly improves upon naive multi-commodity formulations and
also initiate the study of primal heuristics to generate feasible solutions
during the branch-and-bound process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0354</identifier>
 <datestamp>2013-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0354</id><created>2013-10-01</created><updated>2013-12-06</updated><authors><author><keyname>Huang</keyname><forenames>Gary B.</forenames></author><author><keyname>Jain</keyname><forenames>Viren</forenames></author></authors><title>Deep and Wide Multiscale Recursive Networks for Robust Image Labeling</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feedforward multilayer networks trained by supervised learning have recently
demonstrated state of the art performance on image labeling problems such as
boundary prediction and scene parsing. As even very low error rates can limit
practical usage of such systems, methods that perform closer to human accuracy
remain desirable. In this work, we propose a new type of network with the
following properties that address what we hypothesize to be limiting aspects of
existing methods: (1) a `wide' structure with thousands of features, (2) a
large field of view, (3) recursive iterations that exploit statistical
dependencies in label space, and (4) a parallelizable architecture that can be
trained in a fraction of the time compared to benchmark multilayer
convolutional networks. For the specific image labeling problem of boundary
prediction, we also introduce a novel example weighting algorithm that improves
segmentation accuracy. Experiments in the challenging domain of connectomic
reconstruction of neural circuity from 3d electron microscopy data show that
these &quot;Deep And Wide Multiscale Recursive&quot; (DAWMR) networks lead to new levels
of image labeling performance. The highest performing architecture has twelve
layers, interwoven supervised and unsupervised stages, and uses an input field
of view of 157,464 voxels ($54^3$) to make a prediction at each image location.
We present an associated open source software package that enables the simple
and flexible creation of DAWMR networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0365</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0365</id><created>2013-10-01</created><authors><author><keyname>Golovinski</keyname><forenames>P. A.</forenames></author><author><keyname>Astapenko</keyname><forenames>V. A.</forenames></author></authors><title>The complex-valued encoding for dicision-making based on aliasing data</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is proposed a complex valued channel encoding for multidimensional data.
The basic approach contains overlapping of complex nonlinear mappings. Its
development leads to sparse representation of multi-channel data, increasing
their dimensions and the distance between the images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0371</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0371</id><created>2013-10-01</created><authors><author><keyname>Cheng</keyname><forenames>Teng-Hu</forenames></author><author><keyname>Kan</keyname><forenames>Zhen</forenames></author><author><keyname>Rosenfeld</keyname><forenames>Joel A.</forenames></author><author><keyname>Dixon</keyname><forenames>Warren E.</forenames></author></authors><title>Decentralized formation control with connectivity maintenance and
  collision avoidance under limited and intermittent sensing</title><categories>cs.SY math.OC</categories><comments>8 pages, 2 figures, submitted to ACC 2014</comments><msc-class>93-06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A decentralized switched controller is developed for dynamic agents to
perform global formation configuration convergence while maintaining network
connectivity and avoiding collision within agents and between stationary
obstacles, using only local feedback under limited and intermittent sensing.
Due to the intermittent sensing, constant position feedback may not be
available for agents all the time. Intermittent sensing can also lead to a
disconnected network or collisions between agents. Using a navigation function
framework, a decentralized switched controller is developed to navigate the
agents to the desired positions while ensuring network maintenance and
collision avoidance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0375</identifier>
 <datestamp>2014-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0375</id><created>2013-10-01</created><updated>2014-12-19</updated><authors><author><keyname>Hayden</keyname><forenames>David</forenames></author><author><keyname>Yuan</keyname><forenames>Ye</forenames></author><author><keyname>Goncalves</keyname><forenames>Jorge</forenames></author></authors><title>Network Reconstruction from Intrinsic Noise</title><categories>cs.SY math.OC</categories><comments>11 pages, submitted to IEEE Transactions on Automatic Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of inferring an unknown network of dynamical
systems driven by unknown, intrinsic, noise inputs. Equivalently we seek to
identify direct causal dependencies among manifest variables only from
observations of these variables. For linear, time-invariant systems of minimal
order, we characterise under what conditions this problem is well posed. We
first show that if the transfer matrix from the inputs to manifest states is
minimum phase, this problem has a unique solution irrespective of the network
topology. This is equivalent to there being only one valid spectral factor (up
to a choice of signs of the inputs) of the output spectral density.
  If the assumption of phase-minimality is relaxed, we show that the problem is
characterised by a single Algebraic Riccati Equation (ARE), of dimension
determined by the number of latent states. The number of solutions to this ARE
is an upper bound on the number of solutions for the network. We give necessary
and sufficient conditions for any two dynamical networks to have equal output
spectral density, which can be used to construct all equivalent networks.
Extensive simulations quantify the number of solutions for a range of problem
sizes. For a slightly simpler case, we also provide an algorithm to construct
all equivalent networks from the output spectral density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0395</identifier>
 <datestamp>2013-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0395</id><created>2013-10-01</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Bakri</keyname><forenames>Marwah Mohammed</forenames></author></authors><title>Protein Threading Based on Nonlinear Integer Programming</title><categories>cs.DS cs.CE</categories><comments>5 pages. arXiv admin note: substantial text overlap with
  arXiv:1204.4562</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protein threading is a method of computational protein structure prediction
used for protein sequences which have the same fold as proteins of known
structures but do not have homologous proteins with known structure. The most
popular algorithm is based on linear integer programming. In this paper, we
consider methods based on nonlinear integer programming. Actually, the existing
linear integer programming is directly linearized from the original quadratic
integer programming. We then develop corresponding efficient algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0398</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0398</id><created>2013-10-01</created><authors><author><keyname>Chen</keyname><forenames>Lin</forenames></author><author><keyname>Jansen</keyname><forenames>Klaus</forenames></author><author><keyname>Zhang</keyname><forenames>Guochuan</forenames></author></authors><title>On the optimality of approximation schemes for the classical scheduling
  problem</title><categories>cs.CC cs.DS</categories><comments>33 pages, to appear in SODA 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the classical scheduling problem on parallel identical machines
to minimize the makespan, and achieve the following results under the
Exponential Time Hypothesis (ETH)
  1. The scheduling problem on a constant number $m$ of identical machines,
which is denoted as $Pm||C_{max}$, is known to admit a fully polynomial time
approximation scheme (FPTAS) of running time $O(n) + (1/\epsilon)^{O(m)}$
(indeed, the algorithm works for an even more general problem where machines
are unrelated). We prove this algorithm is essentially the best possible in the
sense that a $(1/\epsilon)^{O(m^{1-\delta})}+n^{O(1)}$ time FPTAS for any
$\delta&gt;0$ implies that ETH fails.
  2. The scheduling problem on an arbitrary number of identical machines, which
is denoted as $P||C_{max}$, is known to admit a polynomial time approximation
scheme (PTAS) of running time $2^{O(1/\epsilon^2\log^3(1/\epsilon))}+n^{O(1)}$.
We prove this algorithm is nearly optimal in the sense that a
$2^{O((1/\epsilon)^{1-\delta})}+n^{O(1)}$ time PTAS for any $\delta&gt;0$ implies
that ETH fails, leaving a small room for improvement.
  To obtain these results we will provide two new reductions from 3SAT, one for
$Pm||C_{max}$ and another for $P||C_{max}$. Indeed, the new reductions explore
the structure of scheduling problems and can also lead to other interesting
results. For example, using the framework of our reduction for $P||C_{max}$,
Chen et al. (arXiv:1306.3727) is able to prove the APX-hardness of the
scheduling problem in which the matrix of job processing times
$P=(p_{ij})_{m\times n}$ is of rank 3, solving the open problem mentioned by
Bhaskara et al. (SODA 2013).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0402</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0402</id><created>2013-10-01</created><authors><author><keyname>Alizadeh</keyname><forenames>Mahnoosh</forenames></author><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Incentive Design for Direct Load Control Programs</title><categories>cs.SY</categories><comments>51st Annual Allerton Conference on Communication, Control, and
  Computing, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of optimal incentive design for voluntary participation
of electricity customers in a Direct Load Scheduling (DLS) program, a new form
of Direct Load Control (DLC) based on a three way communication protocol
between customers, embedded controls in flexible appliances, and the central
entity in charge of the program. Participation decisions are made in real-time
on an event-based basis, with every customer that needs to use a flexible
appliance considering whether to join the program given current incentives.
Customers have different interpretations of the level of risk associated with
committing to pass over the control over the consumption schedule of their
devices to an operator, and these risk levels are only privately known. The
operator maximizes his expected profit of operating the DLS program by posting
the right participation incentives for different appliance types, in a publicly
available and dynamically updated table. Customers are then faced with the
dynamic decision making problem of whether to take the incentives and
participate or not. We define an optimization framework to determine the
profit-maximizing incentives for the operator. In doing so, we also investigate
the utility that the operator expects to gain from recruiting different types
of devices. These utilities also provide an upper-bound on the benefits that
can be attained from any type of demand response program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0432</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0432</id><created>2013-10-01</created><authors><author><keyname>Shahrampour</keyname><forenames>Shahin</forenames></author><author><keyname>Rakhlin</keyname><forenames>Alexander</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Online Learning of Dynamic Parameters in Social Networks</title><categories>math.OC cs.LG cs.SI stat.ML</categories><comments>12 pages, To appear in Neural Information Processing Systems (NIPS)
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of online learning in a dynamic setting. We
consider a social network in which each individual observes a private signal
about the underlying state of the world and communicates with her neighbors at
each time period. Unlike many existing approaches, the underlying state is
dynamic, and evolves according to a geometric random walk. We view the scenario
as an optimization problem where agents aim to learn the true state while
suffering the smallest possible loss. Based on the decomposition of the global
loss function, we introduce two update mechanisms, each of which generates an
estimate of the true state. We establish a tight bound on the rate of change of
the underlying state, under which individuals can track the parameter with a
bounded variance. Then, we characterize explicit expressions for the steady
state mean-square deviation(MSD) of the estimates from the truth, per
individual. We observe that only one of the estimators recovers the optimal
MSD, which underscores the impact of the objective function decomposition on
the learning quality. Finally, we provide an upper bound on the regret of the
proposed methods, measured as an average of errors in estimating the parameter
in a finite time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0441</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0441</id><created>2013-10-01</created><authors><author><keyname>Kouchaksaraei</keyname><forenames>Hadi Razzaghi</forenames></author><author><keyname>Chefranov</keyname><forenames>Alexander G.</forenames></author></authors><title>Countering Wrapping Attack on XML Signature in SOAP Message for Cloud
  Computing</title><categories>cs.CR</categories><comments>6 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that the exchange of information between web applications is done
by means of the SOAP protocol. Securing this protocol is obviously a vital
issue for any computer network. However, when it comes to cloud computing
systems, the sensitivity of this issue rises, as the clients of system, release
their data to the cloud. XML signature is employed to secure SOAP messages.
However, there are also some weak points that have been identified, named as
XML signature wrapping attacks, which have been categorized into four major
groups; Simple Ancestry Context Attack, Optional element context attacks,
Sibling Value Context Attack, Sibling Order Context. In this paper, two
existing methods, for referencing the signed part of SOAP Message, named as ID
referencing and XPath method, are analyzed and examined. In addition, a new
method is proposed and tested, to secure the SOAP message. In the new method,
the XML any signature wrapping attack is prevented by employing the concept of
XML digital signature on the SOAP message. The results of conducted experiments
show that the proposed method is approximately three times faster than the
XPath method and even a little faster than ID.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0446</identifier>
 <datestamp>2014-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0446</id><created>2013-10-01</created><updated>2014-02-26</updated><authors><author><keyname>Davis</keyname><forenames>Sergio</forenames></author><author><keyname>Navarrete</keyname><forenames>Yasm&#xed;n</forenames></author><author><keyname>Guti&#xe9;rrez</keyname><forenames>Gonzalo</forenames></author></authors><title>A maximum entropy model for opinions in social groups</title><categories>physics.soc-ph cs.SI stat.AP</categories><journal-ref>Eur. Phys. J. B 87, 78 (2014)</journal-ref><doi>10.1140/epjb/e2014-40918-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study how the opinions of a group of individuals determine their spatial
distribution and connectivity, through an agent-based model. The interaction
between agents is described by a Potts-like Hamiltonian in which agents are
allowed to move freely without an underlying lattice (the average network
topology connecting them is determined from the parameters). This kind of model
was derived using maximum entropy statistical inference under fixed expectation
values of certain probabilities that (we propose) are relevant to social
organization. Control parameters emerge as Lagrange multipliers of the maximum
entropy problem, and they can be associated with the level of consequence
between the personal beliefs and external opinions, and the tendency to
socialize with peers of similar or opposing views. These parameters define a
phase diagram for the social system, which we studied using Monte Carlo
Metropolis simulations. Our model presents both first and second-order phase
transitions, depending on the ratio between the internal consequence and the
interaction with others. We have found a critical value for the level of
internal consequence, below which the personal beliefs of the agents seem to be
irrelevant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0504</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0504</id><created>2013-10-01</created><updated>2014-04-04</updated><authors><author><keyname>Petersen</keyname><forenames>Holger</forenames></author></authors><title>A Note on Pushdown Automata Systems</title><categories>cs.FL</categories><doi>10.1007/978-3-319-09704-6_30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In (Csuhaj-Varju et. al. 2000) Parallel Communicating Systems of Pushdown
Automata (PCPA) were introduced and shown to be able to simulate
nondeterministic one-way multi-head pushdown automata in returning mode, even
if communication is restricted to be one-way having a single target component.
A simulation of such centralized PCPA by one-way multi-head pushdown automata
(Balan 2009) turned out to be incomplete (Otto 2012). Subsequently it was shown
that centralized returning PCPA are universal even if the number of components
is two (Petersen 2013) and thus are separated from one-way multi-head pushdown
automata. Another line of research modified the definition of PCPA such that
communication is asynchronous (Otto 2013). While the simulation of one-way
multi-head pushdown automata is still possible, now a converse construction
shows this model in returning mode to be equivalent to the one-way multi-head
pushdown automaton in a very precise sense. It was left open, whether
non-centralized returning PCPA of degree two are universal. In the first part
of the paper we show this to be the case. Then we turn our attention to Uniform
Distributed Pushdown Automata Systems (UDPAS). These systems of automata work
in turn on a single tape. We show that UPDAS accepting with empty stack do not
form a hierarchy depending on the number of components and that the membership
problem is complete in NP, answering two open problems from (Arroyo et. al.
2012).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0505</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0505</id><created>2013-10-01</created><authors><author><keyname>Wang</keyname><forenames>Haiyan</forenames></author><author><keyname>Wang</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Kuai</forenames></author></authors><title>Modeling Information Diffusion in Online Social Networks with Partial
  Differential Equations</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online social networks such as Twitter and Facebook have gained tremendous
popularity for information exchange. The availability of unprecedented amounts
of digital data has accelerated research on information diffusion in online
social networks. However, the mechanism of information spreading in online
social networks remains elusive due to the complexity of social interactions
and rapid change of online social networks. Much of prior work on information
diffusion over online social networks has based on empirical and statistical
approaches. The majority of dynamical models arising from information diffusion
over online social networks involve ordinary differential equations which only
depend on time. In a number of recent papers, the authors propose to use
partial differential equations(PDEs) to characterize temporal and spatial
patterns of information diffusion over online social networks. Built on
intuitive cyber-distances such as friendship hops in online social networks,
the reaction-diffusion equations take into account influences from various
external out-of-network sources, such as the mainstream media, and provide a
new analytic framework to study the interplay of structural and topical
influences on information diffusion over online social networks. In this
survey, we discuss a number of PDE-based models that are validated with real
datasets collected from popular online social networks such as Digg and
Twitter. Some new developments including the conservation law of information
flow in online social networks and information propagation speeds based on
traveling wave solutions are presented to solidify the foundation of the PDE
models and highlight the new opportunities and challenges for mathematicians as
well as computer scientists and researchers in online social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0509</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0509</id><created>2013-10-01</created><updated>2013-11-25</updated><authors><author><keyname>Fidaner</keyname><forenames>I&#x15f;&#x131;k Bar&#x131;&#x15f;</forenames></author><author><keyname>Cemgil</keyname><forenames>Ali Taylan</forenames></author></authors><title>Summary Statistics for Partitionings and Feature Allocations</title><categories>cs.LG stat.ML</categories><comments>Accepted to NIPS 2013:
  https://nips.cc/Conferences/2013/Program/event.php?ID=3763</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Infinite mixture models are commonly used for clustering. One can sample from
the posterior of mixture assignments by Monte Carlo methods or find its maximum
a posteriori solution by optimization. However, in some problems the posterior
is diffuse and it is hard to interpret the sampled partitionings. In this
paper, we introduce novel statistics based on block sizes for representing
sample sets of partitionings and feature allocations. We develop an
element-based definition of entropy to quantify segmentation among their
elements. Then we propose a simple algorithm called entropy agglomeration (EA)
to summarize and visualize this information. Experiments on various infinite
mixture posteriors as well as a feature allocation dataset demonstrate that the
proposed statistics are useful in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0519</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0519</id><created>2013-10-01</created><authors><author><keyname>Ranjan</keyname><forenames>Apara</forenames></author><author><keyname>Gabora</keyname><forenames>Liane</forenames></author><author><keyname>O'Connor</keyname><forenames>Brian</forenames></author></authors><title>Evidence that Cross-Domain Re-interpretations of Creative Ideas are
  Recognizable</title><categories>q-bio.NC cs.HC</categories><comments>6 pages. arXiv admin note: substantial text overlap with
  arXiv:1308.4706</comments><journal-ref>Ranjan, A., Gabora, L., &amp; O'Connor, B. (2013). Proc Association
  for the Advancement of Artificial Intelligence (AAAI) Spring Symposium #2
  (Creativity and Cognitive Development). Stanford Univ, March 25-27. Menlo
  Park, CA: AAAI Press</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this study was to investigate the translate-ability of creative
works into other domains. We tested whether people were able to recognize which
works of art were inspired by which pieces of music. Three expert painters
created four paintings, each of which was the artist's interpretation of one of
four different pieces of instrumental music. Participants were able to identify
which paintings were inspired by which pieces of music at statistically
significant above-chance levels. The findings support the hypothesis that
creative ideas can exist in an at least somewhat domain-independent state of
potentiality and become more well-defined as they are actualized in accordance
with the constraints of a particular domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0522</identifier>
 <datestamp>2014-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0522</id><created>2013-10-01</created><updated>2014-09-03</updated><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>EVOC: A Computer Model of the Evolution of Culture</title><categories>cs.MA cs.NE</categories><comments>6 pages. arXiv admin note: substantial text overlap with
  arXiv:1005.1516, arXiv:0911.2390, arXiv:0811.2551; replaced version corrects
  error in reference at top of first page</comments><journal-ref>Gabora, L. (2008). EVOC: A computer model of cultural evolution.
  In V. Sloutsky, B. Love &amp; K. McRae (Eds.), 30th Annual Meeting of the
  Cognitive Science Society. Washington DC, July 23-26, North Salt Lake, UT:
  Sheridan Publishing</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EVOC is a computer model of the EVOlution of Culture. It consists of neural
network based agents that invent ideas for actions, and imitate neighbors'
actions. EVOC replicates using a different fitness function the results
obtained with an earlier model (MAV), including (1) an increase in mean fitness
of actions, and (2) an increase and then decrease in the diversity of actions.
Diversity of actions is positively correlated with number of needs, population
size and density, and with the erosion of borders between populations. Slowly
eroding borders maximize diversity, fostering specialization followed by
sharing of fit actions. Square (as opposed to toroidal) worlds also exhibit
higher diversity. Introducing a leader that broadcasts its actions throughout
the population increases the fitness of actions but reduces diversity; these
effects diminish the more leaders there are. Low density populations have less
fit ideas but broadcasting diminishes this effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0524</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0524</id><created>2013-09-27</created><authors><author><keyname>Patuck</keyname><forenames>Reshad</forenames></author><author><keyname>Hernandez-Castro</keyname><forenames>Julio</forenames></author></authors><title>Steganography using the Extensible Messaging and Presence Protocol
  (XMPP)</title><categories>cs.MM cs.CR</categories><comments>13 pages, 3 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here the first work to propose different mechanisms for hiding
data in the Extensible Messaging and Presence Protocol (XMPP). This is a very
popular instant messaging protocol used by many messaging platforms such as
Google Talk, Cisco, LiveJournal and many others. Our paper describes how to
send a secret message from one XMPP client to another, without raising the
suspicion of any intermediaries. The methods described primarily focus on using
the underlying protocol as a means for steganography, unlike other related
works that try to hide data in the content of instant messages. In doing so, we
provide a more robust means of data hiding and additionally offer some
preliminary analysis of its general security, in particular against
entropic-based steganalysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0530</identifier>
 <datestamp>2014-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0530</id><created>2013-10-01</created><updated>2014-09-25</updated><authors><author><keyname>Brislawn</keyname><forenames>Christopher M.</forenames></author></authors><title>On the group-theoretic structure of lifted filter banks</title><categories>cs.IT math.IT</categories><comments>Book chapter: 22 pages, 6 figures. Expository overview of recent
  research, including arXiv:1309.7665. Version 2: added BibTeX citation
  (BibTeX_citation.txt) and conference presentation slides
  (Brislawn_AMS_ABQ_2014_slides.pdf, 328 KB) as ancillary files</comments><report-no>LA-UR-12-21217</report-no><msc-class>42C40 (Primary), 94A29 (Secondary)</msc-class><acm-class>E.4; G.1.2</acm-class><journal-ref>In: &quot;Excursions in Harmonic Analysis, Vol. 2,&quot; ed. T. Andrews, R.
  Balan, J. Benedetto, W. Czaja &amp; K. Okoudjou, Boston: Birkhauser, 2013, pp.
  113-135</journal-ref><doi>10.1007/978-0-8176-8379-5_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The polyphase-with-advance matrix representations of whole-sample symmetric
(WS) unimodular filter banks form a multiplicative matrix Laurent polynomial
group. Elements of this group can always be factored into lifting matrices with
half-sample symmetric (HS) off-diagonal lifting filters; such linear phase
lifting factorizations are specified in the ISO/IEC JPEG 2000 image coding
standard. Half-sample symmetric unimodular filter banks do not form a group,
but such filter banks can be partially factored into a cascade of whole-sample
antisymmetric (WA) lifting matrices starting from a concentric, equal-length HS
base filter bank. An algebraic framework called a group lifting structure has
been introduced to formalize the group-theoretic aspects of matrix lifting
factorizations. Despite their pronounced differences, it has been shown that
the group lifting structures for both the WS and HS classes satisfy a polyphase
order-increasing property that implies uniqueness (&quot;modulo rescaling&quot;) of
irreducible group lifting factorizations in both group lifting structures.
These unique factorization results can in turn be used to characterize the
group-theoretic structure of the groups generated by the WS and HS group
lifting structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0547</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0547</id><created>2013-10-01</created><updated>2013-10-05</updated><authors><author><keyname>Li</keyname><forenames>Linjun</forenames></author><author><keyname>Wang</keyname><forenames>Xiangwen</forenames></author></authors><title>Growth of scale-free networks under heterogeneous control</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 5 figures</comments><msc-class>90B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-life networks often encounter vertex dysfunctions, which are usually
followed by recoveries after appropriate maintenances. In this paper we present
our research on a model of scale-free networks whose vertices are regularly
removed and put back. Both the frequency and length of time of the
disappearance of each vertex depend on the degree of the vertex, creating a
heterogeneous control over the network. Our simulation results show very
interesting growth pattern of this kind of networks. We also find that the
scale-free property of the degree distribution is maintained in the proposed
heterogeneously controlled networks. However, the overall growth rate of the
networks in our model can be remarkably reduced if the inactive periods of the
vertices are kept long.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0548</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0548</id><created>2013-10-01</created><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Mahdian</keyname><forenames>Mohammad</forenames></author><author><keyname>Mehta</keyname><forenames>Aranyak</forenames></author><author><keyname>Waggoner</keyname><forenames>Bo</forenames></author></authors><title>Designing Markets for Daily Deals</title><categories>cs.GT</categories><comments>This is the full version of the paper appearing at WINE 2013
  Proceedings of the Ninth Conference on Web and Internet Economics (WINE-13).
  2013</comments><acm-class>F.0; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Daily deals platforms such as Amazon Local, Google Offers, GroupOn, and
LivingSocial have provided a new channel for merchants to directly market to
consumers. In order to maximize consumer acquisition and retention, these
platforms would like to offer deals that give good value to users. Currently,
selecting such deals is done manually; however, the large number of submarkets
and localities necessitates an automatic approach to selecting good deals and
determining merchant payments.
  We approach this challenge as a market design problem. We postulate that
merchants already have a good idea of the attractiveness of their deal to
consumers as well as the amount they are willing to pay to offer their deal.
The goal is to design an auction that maximizes a combination of the revenue of
the auctioneer (platform), welfare of the bidders (merchants), and the positive
externality on a third party (the consumer), despite the asymmetry of
information about this consumer benefit. We design auctions that truthfully
elicit this information from the merchants and maximize the social welfare
objective, and we characterize the consumer welfare functions for which this
objective is truthfully implementable. We generalize this characterization to a
very broad mechanism-design setting and give examples of other applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0557</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0557</id><created>2013-10-01</created><authors><author><keyname>Shirvanimoghaddam</keyname><forenames>Mahyar</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Near-Capacity Adaptive Analog Fountain Codes for Wireless Channels</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a capacity-approaching analog fountain code (AFC)
for wireless channels. In AFC, the number of generated coded symbols is
potentially limitless. In contrast to the conventional binary rateless codes,
each coded symbol in AFC is a real-valued symbol, generated as a weighted sum
of $d$ randomly selected information bits, where $d$ and the weight
coefficients are randomly selected from predefined probability mass functions.
The coded symbols are then directly transmitted through wireless channels. We
analyze the error probability of AFC and design the weight set to minimize the
error probability. Simulation results show that AFC achieves the capacity of
the Gaussian channel in a wide range of signal to noise ratio (SNR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0569</identifier>
 <datestamp>2013-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0569</id><created>2013-10-02</created><authors><author><keyname>Kaur</keyname><forenames>Sukhdilpreet</forenames></author><author><keyname>Verma</keyname><forenames>Amandeep</forenames></author></authors><title>Design of Generic Framework for Botnet Detection in Network Forensics</title><categories>cs.CR</categories><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security volume 11 number 9 (2013) 38-45</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the raise in practice of Internet, in social, personal, commercial and
other aspects of life, the cybercrime is as well escalating at an alarming
rate. Such usage of Internet in diversified areas also augmented the illegal
activities, which in turn, bids many network attacks and threats. Network
forensics is used to detect the network attacks. This can be viewed as the
extension of network security. It is the technology, which detects and also
suggests prevention of the various network attacks. Botnet is one of the most
common attacks and is regarded as a network of hacked computers. It captures
the network packet, store it and then analyze and correlate to find the source
of attack. Various methods based on this approach for botnet detection are in
literature, but a generalized method is lacking. So, there is a requirement to
design a generic framework that can be used by any botnet detection. This
framework is of use for researchers, in the development of their own method of
botnet detection, by means of providing methodology and guidelines. In this
paper, various prevalent methods of botnet detection are studied, commonalities
among them are established and then a generalized model for the detection of
botnet is proposed. The proposed framework is described as UML diagrams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0572</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0572</id><created>2013-10-02</created><updated>2013-10-04</updated><authors><author><keyname>Jin</keyname><forenames>Boram</forenames><affiliation>BJ</affiliation></author><author><keyname>Yun</keyname><forenames>Se-Young</forenames><affiliation>BJ</affiliation></author><author><keyname>Kim</keyname><forenames>Deawoo</forenames><affiliation>BJ</affiliation></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames><affiliation>BJ</affiliation></author><author><keyname>Yi</keyname><forenames>Yung</forenames><affiliation>BJ</affiliation></author><author><keyname>Hong</keyname><forenames>Seongik</forenames><affiliation>BJ</affiliation></author><author><keyname>Byoung-Joon</keyname><affiliation>BJ</affiliation></author><author><keyname>Lee</keyname></author></authors><title>On the Delay Scaling Laws of Cache Networks</title><categories>cs.NI</categories><comments>10 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet is becoming more and more content-oriented, where one of main
components in content-oriented Internet architectures is network caching.
Despite a surge of extensive use of network cashing in the current and future
Internet architectures, analysis on the performance of general cache networks
are still quite limited due to complex inter-plays among various components and
thus analytical intractability. We study asymptotic delay performance of cache
networks, in particular, focusing on the impact of heterogeneous content
popularities and nodes' geometric `importances' in caching policies. Our
theoretical findings provide useful engineering implications such as when and
how various factors have impact on caching performance, and we provide
extensive simulation results on the real Internet topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0573</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0573</id><created>2013-10-02</created><authors><author><keyname>Bhalla</keyname><forenames>Deepti</forenames></author><author><keyname>Joshi</keyname><forenames>Nisheeth</forenames></author><author><keyname>Mathur</keyname><forenames>Iti</forenames></author></authors><title>Improving the Quality of MT Output using Novel Name Entity Translation
  Scheme</title><categories>cs.CL</categories><comments>In Proceedings of 2013 International Conference on Advances in
  Computing, Communications and Informatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach to machine translation by combining the
state of art name entity translation scheme. Improper translation of name
entities lapse the quality of machine translated output. In this work, name
entities are transliterated by using statistical rule based approach. This
paper describes the translation and transliteration of name entities from
English to Punjabi. We have experimented on four types of name entities which
are: Proper names, Location names, Organization names and miscellaneous.
Various rules for the purpose of syllabification have been constructed.
Transliteration of name entities is accomplished with the help of Probability
calculation. N-Gram probabilities for the extracted syllables have been
calculated using statistical machine translation toolkit MOSES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0575</identifier>
 <datestamp>2013-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0575</id><created>2013-10-02</created><updated>2013-10-09</updated><authors><author><keyname>Singh</keyname><forenames>Jyoti</forenames></author><author><keyname>Joshi</keyname><forenames>Nisheeth</forenames></author><author><keyname>Mathur</keyname><forenames>Iti</forenames></author></authors><title>Development of Marathi Part of Speech Tagger Using Statistical Approach</title><categories>cs.CL</categories><comments>In Proceedings of 2013 International Conference on Advances in
  Computing, Communications and Informatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Part-of-speech (POS) tagging is a process of assigning the words in a text
corresponding to a particular part of speech. A fundamental version of POS
tagging is the identification of words as nouns, verbs, adjectives etc. For
processing natural languages, Part of Speech tagging is a prominent tool. It is
one of the simplest as well as most constant and statistical model for many NLP
applications. POS Tagging is an initial stage of linguistics, text analysis
like information retrieval, machine translator, text to speech synthesis,
information extraction etc. In POS Tagging we assign a Part of Speech tag to
each word in a sentence and literature. Various approaches have been proposed
to implement POS taggers. In this paper we present a Marathi part of speech
tagger. It is morphologically rich language. Marathi is spoken by the native
people of Maharashtra. The general approach used for development of tagger is
statistical using Unigram, Bigram, Trigram and HMM Methods. It presents a clear
idea about all the algorithms with suitable examples. It also introduces a tag
set for Marathi which can be used for tagging Marathi text. In this paper we
have shown the development of the tagger as well as compared to check the
accuracy of taggers output. The three Marathi POS taggers viz. Unigram, Bigram,
Trigram and HMM gives the accuracy of 77.38%, 90.30%, 91.46% and 93.82%
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0576</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0576</id><created>2013-10-02</created><authors><author><keyname>Bonato</keyname><forenames>Roberto</forenames></author><author><keyname>Retor&#xe9;</keyname><forenames>Christian</forenames></author></authors><title>Learning Lambek grammars from proof frames</title><categories>cs.LG cs.AI cs.LO math.LO</categories><comments>A revised version will appear in a volume in honour of Lambek 90th
  birthday</comments><msc-class>03B47 (Primary) 68Q32, 68T50, 03B65 (Secondary)</msc-class><acm-class>F.4.1; I.2.6; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In addition to their limpid interface with semantics, categorial grammars
enjoy another important property: learnability. This was first noticed by
Buskowsky and Penn and further studied by Kanazawa, for Bar-Hillel categorial
grammars.
  What about Lambek categorial grammars? In a previous paper we showed that
product free Lambek grammars where learnable from structured sentences, the
structures being incomplete natural deductions. These grammars were shown to be
unlearnable from strings by Foret and Le Nir. In the present paper we show that
Lambek grammars, possibly with product, are learnable from proof frames that
are incomplete proof nets.
  After a short reminder on grammatical inference \`a la Gold, we provide an
algorithm that learns Lambek grammars with product from proof frames and we
prove its convergence. We do so for 1-valued also known as rigid Lambek
grammars with product, since standard techniques can extend our result to
$k$-valued grammars. Because of the correspondence between cut-free proof nets
and normal natural deductions, our initial result on product free Lambek
grammars can be recovered.
  We are sad to dedicate the present paper to Philippe Darondeau, with whom we
started to study such questions in Rennes at the beginning of the millennium,
and who passed away prematurely.
  We are glad to dedicate the present paper to Jim Lambek for his 90 birthday:
he is the living proof that research is an eternal learning process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0578</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0578</id><created>2013-10-02</created><authors><author><keyname>Gupta</keyname><forenames>Vaishali</forenames></author><author><keyname>Joshi</keyname><forenames>Nisheeth</forenames></author><author><keyname>Mathur</keyname><forenames>Iti</forenames></author></authors><title>Subjective and Objective Evaluation of English to Urdu Machine
  Translation</title><categories>cs.CL</categories><comments>In Proceedings of 2013 International Conference on Advances in
  Computing, Communications and Informatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine translation is research based area where evaluation is very important
phenomenon for checking the quality of MT output. The work is based on the
evaluation of English to Urdu Machine translation. In this research work we
have evaluated the translation quality of Urdu language which has been
translated by using different Machine Translation systems like Google, Babylon
and Ijunoon. The evaluation process is done by using two approaches - Human
evaluation and Automatic evaluation. We have worked for both the approaches
where in human evaluation emphasis is given to scales and parameters while in
automatic evaluation emphasis is given to some automatic metric such as BLEU,
GTM, METEOR and ATEC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0581</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0581</id><created>2013-10-02</created><authors><author><keyname>Gupta</keyname><forenames>Vaishali</forenames></author><author><keyname>Joshi</keyname><forenames>Nisheeth</forenames></author><author><keyname>Mathur</keyname><forenames>Iti</forenames></author></authors><title>Rule Based Stemmer in Urdu</title><categories>cs.CL</categories><comments>In Proceedings of 4th International Conference on Computer and
  Communication Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Urdu is a combination of several languages like Arabic, Hindi, English,
Turkish, Sanskrit etc. It has a complex and rich morphology. This is the reason
why not much work has been done in Urdu language processing. Stemming is used
to convert a word into its respective root form. In stemming, we separate the
suffix and prefix from the word. It is useful in search engines, natural
language processing and word processing, spell checkers, word parsing, word
frequency and count studies. This paper presents a rule based stemmer for Urdu.
The stemmer that we have discussed here is used in information retrieval. We
have also evaluated our results by verifying it with a human expert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0586</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0586</id><created>2013-10-02</created><authors><author><keyname>Zgraggen</keyname><forenames>Aldo U.</forenames></author><author><keyname>Fagiano</keyname><forenames>Lorenzo</forenames></author><author><keyname>Morari</keyname><forenames>Manfred</forenames></author></authors><title>Real-time Optimization and Adaptation of the Crosswind Flight of
  Tethered Wings for Airborne Wind Energy</title><categories>cs.SY math.OC</categories><comments>This manuscript is a preprint of a paper submitted for possible
  publication on the IEEE Transactions on Control Systems Technology and is
  subject to IEEE Copyright. If accepted, the copy of record will be available
  at IEEEXplore library: http://ieeexplore.ieee.org/</comments><doi>10.1109/TCST.2014.2332537</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Airborne wind energy systems aim to generate renewable energy by means of the
aerodynamic lift produced by a wing tethered to the ground and controlled to
fly crosswind paths. The problem of maximizing the average power developed by
the generator, in presence of limited information on wind speed and direction,
is considered. At constant tether speed operation, the power is related to the
traction force generated by the wing. First, a study of the traction force is
presented for a general path parametrization. In particular, the sensitivity of
the traction force on the path parameters is analyzed. Then, the results of
this analysis are exploited to design an algorithm to maximize the force, hence
the power, in real-time. The algorithm uses only the measured traction force on
the tether and it is able to adapt the system's operation to maximize the
average force with uncertain and time-varying wind. The influence of inaccurate
sensor readings and turbulent wind are also discussed. The presented algorithm
is not dependent on a specific hardware setup and can act as an extension of
existing control structures. Both numerical simulations and experimental
results are presented to highlight the effectiveness of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0598</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0598</id><created>2013-10-02</created><updated>2014-05-10</updated><authors><author><keyname>Krishnan</keyname><forenames>Vishaal</forenames></author><author><keyname>Mahindrakar</keyname><forenames>Arun D.</forenames></author><author><keyname>Hiremath</keyname><forenames>Somashekhar S.</forenames></author></authors><title>Synchronization and semistability analysis of the Kuramoto model of
  coupled nonlinear oscillators</title><categories>math.DS cs.SY</categories><comments>9 pages, 4 figures, Submitted to IEEE TCNS (under review)</comments><msc-class>93D05, 92B25 (Primary) 37C10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An interesting problem in synchronization is the study of coupled
oscillators, wherein oscillators with different natural frequencies synchronize
to a common frequency and equilibrium phase difference. In this paper, we
investigate the stability and convergence in a network of coupled oscillators
described by the Kuramoto model. We consider networks with finite number of
oscillators, arbitrary interconnection topology, non-uniform coupling gains and
non-identical natural frequencies. We show that such a network synchronizes
provided the underlying graph is connected and certain conditions on the
coupling gains are satisfied. In the analysis, we consider as states the phase
and angular frequency differences between the oscillators, and the resulting
dynamics possesses a continuum of equilibria. The synchronization problem
involves establishing the Lyapunov stability of the fixed points and showing
convergence of trajectories to these points. The synchronization result is
established in the framework of semistability theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0602</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0602</id><created>2013-10-02</created><authors><author><keyname>Geiger</keyname><forenames>Martin Josef</forenames></author></authors><title>Iterated Variable Neighborhood Search for the resource constrained
  multi-mode multi-project scheduling problem</title><categories>cs.AI</categories><journal-ref>In: Graham Kendall, Greet Vanden Berghe, and Barry McCollum
  (editors): Proceedings of the 6th Multidisciplinary International Conference
  on Scheduling: Theory and Applications, August 27-29, 2013, Gent, Belgium,
  pages 807-811</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The resource constrained multi-mode multi-project scheduling problem
(RCMMMPSP) is a notoriously difficult combinatorial optimization problem. For a
given set of activities, feasible execution mode assignments and execution
starting times must be found such that some optimization function, e.g. the
makespan, is optimized. When determining an optimal (or at least feasible)
assignment of decision variable values, a set of side constraints, such as
resource availabilities, precedence constraints, etc., has to be respected.
  In 2013, the MISTA 2013 Challenge stipulated research in the RCMMMPSP. It's
goal was the solution of a given set of instances under running time
restrictions. We have contributed to this challenge with the here presented
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0605</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0605</id><created>2013-10-02</created><updated>2013-10-14</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author><author><keyname>Reynaud</keyname><forenames>Jean-Claude</forenames><affiliation>RC</affiliation></author></authors><title>Patterns for computational effects arising from a monad or a comonad</title><categories>cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents equational-based logics for proving first order
properties of programming languages involving effects. We propose two dual
inference system patterns that can be instanciated with monads or comonads in
order to be used for proving properties of different effects. The first pattern
provides inference rules which can be interpreted in the Kleisli category of a
monad and the coKleisli category of the associated comonad. In a dual way, the
second pattern provides inference rules which can be interpreted in the
coKleisli category of a comonad and the Kleisli category of the associated
monad. The logics combine a 3-tier effect system for terms consisting of pure
terms and two other kinds of effects called 'constructors/observers' and
'modifiers', and a 2-tier system for 'up-to-effects' and 'strong' equations.
Each pattern provides generic rules for dealing with any monad (respectively
comonad), and it can be extended with specific rules for each effect. The paper
presents two use cases: a language with exceptions (using the standard monadic
semantics), and a language with state (using the less standard comonadic
semantics). Finally, we prove that the obtained inference system for states is
Hilbert-Post complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0607</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0607</id><created>2013-10-02</created><updated>2013-10-28</updated><authors><author><keyname>Xu</keyname><forenames>Dabo</forenames></author><author><keyname>Ugrinovskii</keyname><forenames>Valery</forenames></author></authors><title>Decentralized Measurement Feedback Stabilization of Large-scale Systems
  via Control Vector Lyapunov Functions</title><categories>cs.SY math.OC</categories><comments>Accepted for publication in the Systems and Control Letters. A
  preliminary version of this paper was presented at the 2011 Australian
  Control Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of decentralized measurement feedback
stabilization of nonlinear interconnected systems. As a natural extension of
the recent development on control vector Lyapunov functions, the notion of
output control vector Lyapunov function (OCVLF) is introduced for investigating
decentralized measurement feedback stabilization problems. Sufficient
conditions on (local) stabilizability are discussed which are based on the
proposed notion of OCVLF. It is shown that a decentralized controller for a
nonlinear interconnected system can be constructed using these conditions under
an additional vector dissipation-like condition. To illustrate the proposed
method, two examples are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0611</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0611</id><created>2013-10-02</created><authors><author><keyname>Li</keyname><forenames>Xu</forenames></author><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Qian</keyname><forenames>Gongbin</forenames></author></authors><title>Mapping and Coding Design for Channel Coded Physical-layer Network
  Coding</title><categories>cs.IT math.IT</categories><comments>6 pages and will appear in a conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although BICM can significantly improves the BER performance by iteration
processing between the demapping and the decoding in a traditional receiver,
its design and performance in PNC system has fewer studied. This paper
investigates a bit interleaved coded modulation (BICM) scheme in a Gaussian
two-way relay channel operated with physical layer network coding (PNC). In
particular, we first present an iterative demapping and decoding framework
specially designed for PNC. After that, we compare different constellation
mapping schemes in this framework, with the convergence analysis by using the
EXIT chart. It is found that the anti-Gray mapping outperforms the Gray
mapping, which is the best mapping in the traditional decoding schemes.
Finally, the numerical simulation shows the better performance of our framework
and verifies the mapping design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0612</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0612</id><created>2013-10-02</created><authors><author><keyname>Qu</keyname><forenames>Zhen</forenames></author><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Dai</keyname><forenames>Mingjun</forenames></author><author><keyname>Wang</keyname><forenames>Hui</forenames></author></authors><title>Secrecy Rate Study in Two-Hop Relay Channel with Finite Constellations</title><categories>cs.IT math.IT</categories><comments>submitted to ICC2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-hop security communication with an eavesdropper in wireless environment
is a hot research direction. The basic idea is that the destination,
simultaneously with the source, sends a jamming signal to interfere the
eavesdropper near to or co-located with the relay. Similar as physical layer
network coding, the friendly jamming signal will prevent the eavesdropper from
detecting the useful information originated from the source and will not affect
the destination on detecting the source information with the presence of the
known jamming signal. However, existing investigations are confined to Gaussian
distributed signals, which are seldom used in real systems. When finite
constellation signals are applied, the behavior of the secrecy rate becomes
very different. For example, the secrecy rate depends on phase difference
between the input signals with finite constellations, which is not observed
with Gaussian signals. In this paper, we investigate the secrecy capacity and
derive its upper bound for the two-hop relay model, by assuming an eavesdropper
near the relay and the widely used M-PSK modulation. With our upper bound, the
best and worst phase differences in high SNR region are then given. Numerical
studies verify our analysis and show that the derived upper bound is relatively
tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0621</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0621</id><created>2013-10-02</created><authors><author><keyname>Wang</keyname><forenames>Xianwen</forenames></author><author><keyname>Mao</keyname><forenames>Wenli</forenames></author><author><keyname>Liu</keyname><forenames>Chen</forenames></author></authors><title>Games and Culture: Using Online-gaming Data to Cluster Chinese Regional
  Cultures</title><categories>cs.CY cs.SI physics.soc-ph</categories><comments>9 pages, 5 figures, 4 tables. arXiv admin note: substantial text
  overlap with arXiv:1307.7208</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To identify cluster of societies and cultures is not easy in subject to the
availability of data. In this study, we propose a novel method to cluster
Chinese regional cultures. Using geotagged online-gaming data of Chinese
internet users playing online card and board games with regional features, 336
Chinese cities are grouped into 17 clusters. The distribution of clustering
units shows great geographical proximity when the boundary of the clusters
coincides well with the geographical boundary of provinces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0650</identifier>
 <datestamp>2015-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0650</id><created>2013-10-02</created><authors><author><keyname>Salo</keyname><forenames>Ville</forenames></author><author><keyname>T&#xf6;rm&#xe4;</keyname><forenames>Ilkka</forenames></author></authors><title>Playing with Subshifts</title><categories>math.DS cs.FL</categories><comments>22 pages, 4 figures. To appear in Fundamenta Informaticae</comments><doi>10.3233/FI-2014-1037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the class of word-building games, where two players pick letters
from a finite alphabet to construct a finite or infinite word. The outcome is
determined by whether the resulting word lies in a prescribed set (a win for
player $A$) or not (a win for player $B$). We focus on symbolic dynamical
games, where the target set is a subshift. We investigate the relation between
the target subshift and the set of turn orders for which $A$ has a winning
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0654</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0654</id><created>2013-10-02</created><authors><author><keyname>Salo</keyname><forenames>Ville</forenames></author><author><keyname>T&#xf6;rm&#xe4;</keyname><forenames>Ilkka</forenames></author></authors><title>Constructions with Countable Subshifts of Finite Type</title><categories>math.DS cs.FL</categories><comments>38 pages, 11 figures. Extended version of arXiv:1208.2756. To appear
  in Fundamenta Informaticae</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present constructions of countable two-dimensional subshifts of finite
type (SFTs) with interesting properties. Our main focus is on properties of the
topological derivatives and subpattern posets of these objects. We present a
countable SFT whose iterated derivatives are maximally complex from the
computational point of view, constructions of countable SFTs with high
Cantor-Bendixson ranks, a countable SFT whose subpattern poset contains an
infinite descending chain and a countable SFT whose subpattern poset contains
all finite posets. When possible, we make these constructions deterministic,
and ensure the sets of rows are very simple as one-dimensional subshifts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0670</identifier>
 <datestamp>2014-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0670</id><created>2013-10-02</created><updated>2014-08-28</updated><authors><author><keyname>T&#xf6;rm&#xe4;</keyname><forenames>Ilkka</forenames></author></authors><title>A Uniquely Ergodic Cellular Automaton</title><categories>math.DS cs.FL</categories><comments>47 pages, 8 figures. Submitted to Journal of Computer and System
  Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a one-dimensional uniquely ergodic cellular automaton which is
not nilpotent. This automaton can perform asymptotically infinitely sparse
computation, which nevertheless never disappears completely. The construction
builds on the self-simulating automaton of G\'acs. We also prove related
results of dynamical and computational nature, including the undecidability of
unique ergodicity, and the undecidability of nilpotency in uniquely ergodic
cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0677</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0677</id><created>2013-10-02</created><authors><author><keyname>Meric</keyname><forenames>Hugo</forenames></author><author><keyname>Piquer</keyname><forenames>Jose Miguel</forenames></author></authors><title>DVB-S2 Spectrum Efficiency Improvement with Hierarchical Modulation</title><categories>cs.NI cs.IT math.IT</categories><comments>Submitted for publication. arXiv admin note: substantial text overlap
  with arXiv:1112.4944</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the design of a DVB-S2 system in order to maximise spectrum
efficiency. This task is usually challenging due to channel variability. Modern
satellite communications systems such as DVB-SH and DVB-S2 rely mainly on a
time sharing strategy to optimise the spectrum efficiency. Recently, we showed
that combining time sharing with hierarchical modulation can provide
significant gains (in terms of spectrum efficiency) compared to the best time
sharing strategy. However, our previous design does not improve the DVB-S2
performance when all the receivers experience low or large signal-to-noise
ratios. In this article, we introduce and study a hierarchical QPSK and a
hierarchical 32-APSK to overcome the previous limitations.We show in a
realistic case based on DVB-S2 that the hierarchical QPSK provides an
improvement when the receivers experience poor channel condition, while the
32-APSK increases the spectrum efficiency when the receivers experience good
channel condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0709</identifier>
 <datestamp>2015-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0709</id><created>2013-09-29</created><updated>2015-01-16</updated><authors><author><keyname>Takahashi</keyname><forenames>Hayato</forenames></author></authors><title>Generalization of van Lambalgen's theorem and blind randomness for
  conditional probabilities</title><categories>math.LO cs.IT cs.LO math.IT</categories><comments>The previous version was presented at CCR2013. The current version is
  submitted to special issue of CCR2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalization of the Lambalgen's theorem is studied with the notion of
Hippocratic (blind) randomness without assuming computability of conditional
probabilities. In [Bauwence 2014], a counter-example for the generalization of
Lambalgen's theorem is shown when the conditional probability is not
computable. In this paper, it is shown that (i) finiteness of martingale for
blind randomness, (ii) classification of two blind randomness by likelihood
ratio test, (iii) sufficient conditions for the generalization of the
Lambalgen's theorem, and (iv) an example that satisfies the Lambalgen's theorem
but the conditional probabilities are not computable for all random parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0710</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0710</id><created>2013-10-02</created><authors><author><keyname>Bauer</keyname><forenames>Ulrich</forenames></author><author><keyname>Kerber</keyname><forenames>Michael</forenames></author><author><keyname>Reininghaus</keyname><forenames>Jan</forenames></author></authors><title>Distributed computation of persistent homology</title><categories>cs.CG cs.DC math.AT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Persistent homology is a popular and powerful tool for capturing topological
features of data. Advances in algorithms for computing persistent homology have
reduced the computation time drastically -- as long as the algorithm does not
exhaust the available memory. Following up on a recently presented parallel
method for persistence computation on shared memory systems, we demonstrate
that a simple adaption of the standard reduction algorithm leads to a variant
for distributed systems. Our algorithmic design ensures that the data is
distributed over the nodes without redundancy; this permits the computation of
much larger instances than on a single machine. Moreover, we observe that the
parallelism at least compensates for the overhead caused by communication
between nodes, and often even speeds up the computation compared to sequential
and even parallel shared memory algorithms. In our experiments, we were able to
compute the persistent homology of filtrations with more than a billion (10^9)
elements within seconds on a cluster with 32 nodes using less than 10GB of
memory per node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0720</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0720</id><created>2013-10-02</created><updated>2014-04-29</updated><authors><author><keyname>Asadi</keyname><forenames>Arash</forenames></author><author><keyname>Wang</keyname><forenames>Qing</forenames></author><author><keyname>Mancuso</keyname><forenames>Vincenzo</forenames></author></authors><title>A Survey on Device-to-Device Communication in Cellular Networks</title><categories>cs.GT cs.IT cs.NI math.IT</categories><comments>18 pages; 8 figures; Accepted for publication in IEEE Communications
  Surveys and Tutorials</comments><doi>10.1109/COMST.2014.2319555</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-to-Device (D2D) communication was initially proposed in cellular
networks as a new paradigm to enhance network performance. The emergence of new
applications such as content distribution and location-aware advertisement
introduced new use-cases for D2D communications in cellular networks. The
initial studies showed that D2D communication has advantages such as increased
spectral efficiency and reduced communication delay. However, this
communication mode introduces complications in terms of interference control
overhead and protocols that are still open research problems. The feasibility
of D2D communications in LTE-A is being studied by academia, industry, and the
standardization bodies. To date, there are more than 100 papers available on
D2D communications in cellular networks and, there is no survey on this field.
In this article, we provide a taxonomy based on the D2D communicating spectrum
and review the available literature extensively under the proposed taxonomy.
Moreover, we provide new insights to the over-explored and under-explored areas
which lead us to identify open research problems of D2D communication in
cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0721</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0721</id><created>2013-10-02</created><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bianchi</keyname><forenames>Marco</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author><author><keyname>Garello</keyname><forenames>Roberto</forenames></author><author><keyname>Maturo</keyname><forenames>Nicola</forenames></author><author><keyname>Sanchez</keyname><forenames>Ignacio Aguilar</forenames></author><author><keyname>Cioni</keyname><forenames>Stefano</forenames></author></authors><title>Advanced coding schemes against jamming in telecommand links</title><categories>cs.IT math.IT</categories><comments>7 pages, 9 figures, accepted for presentation at Milcom 2013, San
  Diego, CA, Nov. 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to study the performance of some coding schemes
recently proposed for updating the TC channel coding standard for space
applications, in the presence of jamming. Besides low-density parity-check
codes, that appear as the most eligible candidates, we also consider other
solutions based on parallel turbo codes and extended BCH codes. We show that
all these schemes offer very good performance, which approaches the theoretical
limits achievable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0731</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0731</id><created>2013-10-02</created><authors><author><keyname>Nizamani</keyname><forenames>Sarwat</forenames></author><author><keyname>Memon</keyname><forenames>Nasrullah</forenames></author><author><keyname>Galam</keyname><forenames>Serge</forenames></author></authors><title>From Public Outrage to the Burst of Public Violence: An Epidemic-Like
  Model</title><categories>physics.soc-ph cs.SI</categories><comments>22 pages, 9 figures</comments><doi>10.1016/j.physa.2014.09.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study extends classical models of spreading epidemics to describe the
phenomenon of contagious public outrage, which eventually leads to the spread
of violence following a disclosure of some unpopular political decisions and/or
activity. Accordingly, a mathematical model is proposed to simulate from the
start, the internal dynamics by which an external event is turned into internal
violence within a population. Five kinds of agents are considered: &quot;Upset&quot; (U),
&quot;Violent&quot; (V), &quot;Sensitive&quot; (S), &quot;Immune&quot; (I), and &quot;Relaxed&quot; (R), leading to a
set of ordinary differential equations, which in turn yield the dynamics of
spreading of each type of agents among the population. The process is stopped
with the deactivation of the associated issue. Conditions coinciding with a
twofold spreading of public violence are singled out. The results shed a new
light to understand terror activity and provides some hint on how to curb the
spreading of violence within population globally sensitive to specific world
issues. Recent world violent events are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0737</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0737</id><created>2013-10-01</created><authors><author><keyname>Veloz</keyname><forenames>Tomas</forenames></author><author><keyname>Temkin</keyname><forenames>Ilya</forenames></author><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>A Conceptual Network-Based Approach to Inferring the Cultural
  Evolutionary History of the Baltic Psaltery</title><categories>cs.DL q-bio.PE</categories><comments>6 pages</comments><journal-ref>(2012). Proceedings of the Annual Meeting of the Cognitive Science
  Society (pp. 2487-2492). August 1-4, Sapporo Japan. Houston TX: Cognitive
  Science Society</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The application of conventional phylogenetic techniques for inferring
cultural history is problematic due to differences in the nature of information
transmission in biological and cultural realms. In culture, units of
transmission are not just measurable attributes, but communicable concepts.
Therefore, relatedness amongst cultural elements often resides at the
conceptual level not captured by traditional phylogenetic methods. This paper
takes a cognitively inspired approach to analyzing material cultural history.
We show that combining data for physical attributes of cultural artifacts with
conceptual information can uncover cultural influences among different
ethnolinguistic groups, and reveal new patterns of cultural ancestry. Using the
Baltic psaltery, a musical instrument with a well-documented ethnographic and
archaeological record, we recovered a previously unacknowledged pattern of
historical relationship that is more congruent with geographical distribution
and temporal data than is obtained with other approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0740</identifier>
 <datestamp>2014-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0740</id><created>2013-10-02</created><updated>2014-04-07</updated><authors><author><keyname>Filippone</keyname><forenames>Maurizio</forenames></author><author><keyname>Girolami</keyname><forenames>Mark</forenames></author></authors><title>Pseudo-Marginal Bayesian Inference for Gaussian Processes</title><categories>stat.ML cs.LG stat.ME</categories><comments>14 pages double column</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main challenges that arise when adopting Gaussian Process priors in
probabilistic modeling are how to carry out exact Bayesian inference and how to
account for uncertainty on model parameters when making model-based predictions
on out-of-sample data. Using probit regression as an illustrative working
example, this paper presents a general and effective methodology based on the
pseudo-marginal approach to Markov chain Monte Carlo that efficiently addresses
both of these issues. The results presented in this paper show improvements
over existing sampling methods to simulate from the posterior distribution over
the parameters defining the covariance function of the Gaussian Process prior.
This is particularly important as it offers a powerful tool to carry out full
Bayesian inference of Gaussian Process based hierarchic statistical models in
general. The results also demonstrate that Monte Carlo based integration of all
model parameters is actually feasible in this class of models providing a
superior quantification of uncertainty in predictions. Extensive comparisons
with respect to state-of-the-art probabilistic classifiers confirm this
assertion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0741</identifier>
 <datestamp>2014-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0741</id><created>2013-10-02</created><updated>2014-11-12</updated><authors><author><keyname>Vida</keyname><forenames>Rafael</forenames></author><author><keyname>Galeano</keyname><forenames>Javier</forenames></author><author><keyname>Cuenda</keyname><forenames>Sara</forenames></author></authors><title>Vulnerability of state-interdependent networks under malware spreading</title><categories>physics.soc-ph cs.SI</categories><comments>Accepted for publication in Physica A</comments><doi>10.1016/j.physa.2014.11.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer viruses are evolving by developing spreading mechanisms based on the
use of multiple vectors of propagation. The use of the social network as an
extra vector of attack to penetrate the security measures in IP networks is
improving the effectiveness of malware, and have therefore been used by the
most aggressive viruses, like Conficker and Stuxnet. In this work we use
interdependent networks to model the propagation of these kind of viruses. In
particular, we study the propagation of a SIS model on interdependent networks
where the state of each node is layer-independent and the dynamics in each
network follows either a contact process or a reactive process, with different
propagation rates. We apply this study to the case of existing multilayer
networks, namely a Spanish scientific community of Statistical Physics, formed
by a social network of scientific collaborations and a physical network of
connected computers in each institution. We show that the interplay between
layers increases dramatically the infectivity of viruses in the long term and
their robustness against immunization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0744</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0744</id><created>2013-10-02</created><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bianchi</keyname><forenames>Marco</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author><author><keyname>Garello</keyname><forenames>Roberto</forenames></author><author><keyname>Sanchez</keyname><forenames>Ignacio Aguilar</forenames></author><author><keyname>Cioni</keyname><forenames>Stefano</forenames></author></authors><title>Advanced channel coding for space mission telecommand links</title><categories>cs.IT math.IT</categories><comments>5 pages, 7 figures, presented at IEEE VTC 2013 Fall, Las Vegas, USA,
  Sep. 2013 Proc. IEEE Vehicular Technology Conference (VTC 2013 Fall), ISBN
  978-1-6185-9, Las Vegas, USA, Sep. 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate and compare different options for updating the error
correcting code currently used in space mission telecommand links. Taking as a
reference the solutions recently emerged as the most promising ones, based on
Low-Density Parity-Check codes, we explore the behavior of alternative schemes,
based on parallel concatenated turbo codes and soft-decision decoded BCH codes.
Our analysis shows that these further options can offer similar or even better
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0754</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0754</id><created>2013-10-02</created><authors><author><keyname>Thangarasu</keyname><forenames>M.</forenames></author><author><keyname>Manavalan</keyname><forenames>R.</forenames></author></authors><title>Stemmers for Tamil Language: Performance Analysis</title><categories>cs.CL</categories><journal-ref>International Journal of Computer Science &amp; Engineering
  Technology, Vol. 4, No. 07, Jul 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stemming is the process of extracting root word from the given inflection
word and also plays significant role in numerous application of Natural
Language Processing (NLP). Tamil Language raises several challenges to NLP,
since it has rich morphological patterns than other languages. The rule based
approach light-stemmer is proposed in this paper, to find stem word for given
inflection Tamil word. The performance of proposed approach is compared to a
rule based suffix removal stemmer based on correctly and incorrectly predicted.
The experimental result clearly show that the proposed approach light stemmer
for Tamil language perform better than suffix removal stemmer and also more
effective in Information Retrieval System (IRS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0757</identifier>
 <datestamp>2014-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0757</id><created>2013-10-02</created><updated>2014-01-23</updated><authors><author><keyname>Hosseini</keyname><forenames>Ehsan</forenames></author><author><keyname>Perrins</keyname><forenames>Erik</forenames></author></authors><title>Timing, Carrier, and Frame Synchronization of Burst-Mode CPM</title><categories>cs.IT math.IT</categories><comments>Copyright 2013 IEEE</comments><journal-ref>IEEE Transactions on Communications, vol.61, no.12, pp.5125-5138,
  December 2013</journal-ref><doi>10.1109/TCOMM.2013.111613.130667</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a complete synchronization algorithm for continuous
phase modulation (CPM) signals in burst-mode transmission over additive white
Gaussian noise (AWGN) channels. The timing and carrier recovery are performed
through a data-aided (DA) maximum likelihood algorithm, which jointly estimates
symbol timing, carrier phase, and frequency offsets based on an optimized
synchronization preamble. Our algorithm estimates the frequency offset via a
one dimensional grid search, after which symbol timing and carrier phase are
computed via simple closed-form expressions. The mean-square error (MSE) of the
algorithm's estimates reveals that it performs very close to the theoretical
Cram\'er-Rao bound (CRB) for various CPMs at signal-to-noise ratios (SNRs) as
low as 0 dB. Furthermore, we present a frame synchronization algorithm that
detects the arrival of bursts and estimates the start-of-signal. We simulate
the performance of the frame synchronization algorithm along with the timing
and carrier recovery algorithm. The bit error rate results demonstrate near
ideal synchronization performance for low SNRs and short preambles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0768</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0768</id><created>2013-10-02</created><authors><author><keyname>Mio</keyname><forenames>Matteo</forenames></author></authors><title>Upper-Expectation Bisimilarity and Real-valued Modal Logics</title><categories>cs.LO</categories><comments>Preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several notions of bisimulation relations for probabilistic non-deterministic
transition systems have been considered in the literature. We consider a novel
testing-based behavioral equivalence called upper-expectation bisimilarity and
develop its theory using standard results from linear algebra and functional
analysis. We show that, for a wide class of systems, our new notion coincides
with Segala's convex bisimilarity. We develop logical characterizations in
terms of expressive probabilistic modal mu-calculi and a novel real-valued
modal logic. We prove that upper-expectation bisimilarity is a congruence for
the wide family of process algebras specified following the probabilistic GSOS
rule format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0776</identifier>
 <datestamp>2013-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0776</id><created>2013-10-02</created><updated>2013-10-07</updated><authors><author><keyname>Zieve</keyname><forenames>Michael</forenames></author></authors><title>Permutation polynomials on F_q induced from bijective Redei functions on
  subgroups of the multiplicative group of F_q</title><categories>math.NT cs.IT math.CO math.IT</categories><comments>8 pages; paper completely rewritten, now the results are much more
  general</comments><msc-class>11T06 (Primary) 05A05, 11T55 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct classes of permutation polynomials over F_{Q^2} by exhibiting
classes of low-degree rational functions over F_{Q^2} which induce bijections
on the set of (Q+1)-th roots of unity in F_{Q^2}. As a consequence, we prove
two conjectures about permutation trinomials from a recent paper by Tu, Zeng,
Hu and Li.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0794</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0794</id><created>2013-10-02</created><updated>2013-10-14</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author><author><keyname>Ekici</keyname><forenames>Burak</forenames><affiliation>LJK</affiliation></author><author><keyname>Pous</keyname><forenames>Damien</forenames><affiliation>LIP</affiliation></author></authors><title>Formal verification in Coq of program properties involving the global
  state effect</title><categories>cs.LO cs.PL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The syntax of an imperative language does not mention explicitly the state,
while its denotational semantics has to mention it. In this paper we present a
framework for the verification in Coq of properties of programs manipulating
the global state effect. These properties are expressed in a proof system which
is close to the syntax, as in effect systems, in the sense that the state does
not appear explicitly in the type of expressions which manipulate it. Rather,
the state appears via decorations added to terms and to equations. In this
system, proofs of programs thus present two aspects: properties can be verified
{\em up to effects} or the effects can be taken into account. The design of our
Coq library consequently reflects these two aspects: our framework is centered
around the construction of two inductive and dependent types, one for terms up
to effects and one for the manipulation of decorations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0801</identifier>
 <datestamp>2014-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0801</id><created>2013-10-02</created><updated>2014-02-15</updated><authors><author><keyname>Bringmann</keyname><forenames>Karl</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author><author><keyname>Stauffer</keyname><forenames>Alexandre</forenames></author><author><keyname>Sun</keyname><forenames>He</forenames></author></authors><title>Balls into bins via local search: cover time and maximum load</title><categories>math.PR cs.DM math.CO</categories><comments>arXiv admin note: text overlap with arXiv:1207.2125</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a natural process for allocating m balls into n bins that are
organized as the vertices of an undirected graph G. Balls arrive one at a time.
When a ball arrives, it first chooses a vertex u in G uniformly at random. Then
the ball performs a local search in G starting from u until it reaches a vertex
with local minimum load, where the ball is finally placed on. Then the next
ball arrives and this procedure is repeated. For the case m = n, we give an
upper bound for the maximum load on graphs with bounded degrees. We also
propose the study of the cover time of this process, which is defined as the
smallest m so that every bin has at least one ball allocated to it. We
establish an upper bound for the cover time on graphs with bounded degrees. Our
bounds for the maximum load and the cover time are tight when the graph is
transitive or sufficiently homogeneous. We also give upper bounds for the
maximum load when m &gt; n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1310.0802</identifier>
 <datestamp>2013-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1310.0802</id><created>2013-10-02</created><authors><author><keyname>Raki&#x107;</keyname><forenames>Gordana</forenames></author><author><keyname>Budimac</keyname><forenames>Zoran</forenames></author></authors><title>Introducing Enriched Concrete Syntax Trees</title><categories>cs.SE cs.PL</categories><comments>14th International Multiconference on Information Society (IS),
  Collaboration, Software And Services In Information Society (CSS), October
  10-14, 2011, Ljubljana</comments><journal-ref>In Proc. of the 14th International Multiconference on Information
  Society (IS), Collaboration, Software And Services In Information Society
  (CSS), October 10-14, 2011, Ljubljana, Slovenia, Volume A, pp. 211-214</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our earlier research an area of consistent and systematic application of
software metrics was explored. Strong dependency of applicability of software
metrics on input programming language was recognized as one of the main
weaknesses in this field. Introducing enriched Concrete Syntax Tree (eCST) for
internal and intermediate representation of the source code resulted with step
forward over this weakness. In this paper we explain innovation made by
introducing eCST and provide idea for broader applicability of eCST in some
other fields of software engineering.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="50000" completeListSize="102538">1122234|51001</resumptionToken>
</ListRecords>
</OAI-PMH>
