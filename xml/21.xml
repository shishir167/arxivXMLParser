<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:49:34Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|20001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2848</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2848</id><created>2011-03-15</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>Polynomial Weights or Generalized Geometric Weights: Yet Another Scheme
  for Assigning Credits to Multiple Authors</title><categories>cs.DL</categories><comments>12 pages, 1 table, 1 figure</comments><msc-class>68M20</msc-class><acm-class>H.3.1; H.3.2; H.3.3; H.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Devising a weight assignment policy for assigning credits to multiple authors
of a manuscript is a challenging task. In this paper, we present a scheme for
assigning credits to multiple authors that we call a polynomial weight
assignment scheme. We compare our scheme with other schemes proposed in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2865</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2865</id><created>2011-03-15</created><authors><author><keyname>Cook</keyname><forenames>Atlas F.</forenames><suffix>IV</suffix></author><author><keyname>Driemel</keyname><forenames>Anne</forenames></author><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author><author><keyname>Sherette</keyname><forenames>Jessica</forenames></author><author><keyname>Wenk</keyname><forenames>Carola</forenames></author></authors><title>Computing the Fr\'{e}chet Distance Between Folded Polygons</title><categories>cs.CG</categories><comments>19 pages, 10 figures. Submitted to WADS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the Fr\'{e}chet distance for surfaces is a surprisingly hard
problem and the only known algorithm is limited to computing it between flat
surfaces. We adapt this algorithm to create one for computing the Fr\'{e}chet
distance for a class of non-flat surfaces which we call folded polygons.
Unfortunately, the original algorithm cannot be extended directly. We present
three different methods to adapt it. The first of which is a fixed-parameter
tractable algorithm. The second is a polynomial-time approximation algorithm.
Finally, we present a restricted class of folded polygons for which we can
compute the Fr\'{e}chet distance in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2882</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2882</id><created>2011-03-15</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>On optimum strategies for minimizing the exponential moments of a given
  cost function</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>26 pages, 1 figure; submitted to the IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general problem of finding a strategy that minimizes the
exponential moment of a given cost function, with an emphasis on its relation
to the more common criterion of minimization the expectation of the first
moment of the same cost function. In particular, our main result is a theorem
that gives simple sufficient conditions for a strategy to be optimum in the
exponential moment sense. This theorem may be useful in various situations, and
application examples are given. We also examine the asymptotic regime and
investigate universal asymptotically optimum strategies in light of the
aforementioned sufficient conditions, as well as phenomena of irregularities,
or phase transitions, in the behavior of the asymptotic performance, which can
be viewed and understood from a statistical-mechanical perspective. Finally, we
propose a new route for deriving lower bounds on exponential moments of certain
cost functions (like the square error in estimation problems) on the basis of
well known lower bounds on their expectations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2886</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2886</id><created>2011-03-15</created><authors><author><keyname>Sirotkin</keyname><forenames>Pavel</forenames></author></authors><title>Predicting User Preferences</title><categories>cs.IR</categories><acm-class>H.3.4</acm-class><journal-ref>Information und Wissen: global, sozial und frei? Proceedings des
  12. Internationalen Symposiums f\&quot;ur Informationswissenschaft. Joachim
  Griesbaum, Thomas Mandl, Christa Womser-Hacker (Editors). VWH, Boizenburg,
  2011. Pages 24-35</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The many metrics employed for the evaluation of search engine results have
not themselves been conclusively evaluated. We propose a new measure for a
metric's ability to identify user preference of result lists. Using this
measure, we evaluate the metrics Discounted Cumulated Gain, Mean Average
Precision and classical precision, finding that the former performs best. We
also show that considering more results for a given query can impair rather
than improve a metric's ability to predict user preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2897</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2897</id><created>2011-03-15</created><authors><author><keyname>Lorenz</keyname><forenames>Dirk A.</forenames></author></authors><title>Constructing test instances for Basis Pursuit Denoising</title><categories>cs.IT math.IT</categories><msc-class>94A12, 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of available algorithms for the so-called Basis Pursuit Denoising
problem (or the related LASSO-problem) is large and keeps growing. Similarly,
the number of experiments to evaluate and compare these algorithms on different
instances is growing.
  In this note, we present a method to produce instances with exact solutions
which is based on a simple observation which is related to the so called source
condition from sparse regularization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2903</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2903</id><created>2011-03-15</created><authors><author><keyname>Nielsen</keyname><forenames>Finn &#xc5;rup</forenames></author></authors><title>A new ANEW: Evaluation of a word list for sentiment analysis in
  microblogs</title><categories>cs.IR cs.CL</categories><comments>6 pages, 4 figures, 1 table, Submitted to &quot;Making Sense of Microposts
  (#MSM2011)&quot;</comments><msc-class>68M11</msc-class><acm-class>H.4.3; J.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Sentiment analysis of microblogs such as Twitter has recently gained a fair
amount of attention. One of the simplest sentiment analysis approaches compares
the words of a posting against a labeled word list, where each word has been
scored for valence, -- a 'sentiment lexicon' or 'affective word lists'. There
exist several affective word lists, e.g., ANEW (Affective Norms for English
Words) developed before the advent of microblogging and sentiment analysis. I
wanted to examine how well ANEW and other word lists performs for the detection
of sentiment strength in microblog posts in comparison with a new word list
specifically constructed for microblogs. I used manually labeled postings from
Twitter scored for sentiment. Using a simple word matching I show that the new
word list may perform better than ANEW, though not as good as the more
elaborate approach found in SentiStrength.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2913</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2913</id><created>2011-03-15</created><authors><author><keyname>Kumar</keyname><forenames>Mrinal</forenames></author><author><keyname>Maheswari</keyname><forenames>Gaurav</forenames></author><author><keyname>Sadagopan</keyname><forenames>N.</forenames></author></authors><title>A Characterization of all Stable Minimal Separator Graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, our goal is to characterize two graph classes based on the
properties of minimal vertex (edge) separators. We first present a structural
characterization of graphs in which every minimal vertex separator is a stable
set. We show that such graphs are precisely those in which the induced
subgraph, namely, a cycle with exactly one chord is forbidden. We also show
that deciding maximum such forbidden subgraph is NP-complete by establishing a
polynomial time reduction from maximum induced cycle problem [1]. This result
is of independent interest and can be used in other combinatorial problems.
Secondly, we prove that a graph has the following property: every minimal edge
separator induces a matching (that is no two edges share a vertex in common) if
and only if it is a tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2923</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2923</id><created>2011-03-15</created><authors><author><keyname>Jebai</keyname><forenames>AlKassem</forenames></author><author><keyname>Malrait</keyname><forenames>Francois</forenames></author><author><keyname>Martin</keyname><forenames>Philippe</forenames></author><author><keyname>Rouchon</keyname><forenames>Pierre</forenames></author></authors><title>Estimation of Saturation of Permanent-Magnet Synchronous Motors Through
  an Energy-Based Model</title><categories>math.OC cs.SY physics.ins-det</categories><comments>IEMDC-2011 (preliminary version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a parametric model of the saturated Permanent-Magnet Synchronous
Motor (PMSM) together with an estimation method of the magnetic parameters. The
model is based on an energy function which simply encompasses the saturation
effects. Injection of fast-varying pulsating voltages and measurements of the
resulting current ripples then permit to identify the magnetic parameters by
linear least squares. Experimental results on a surface-mounted PMSM and an
interoir magnet PMSM illustrate the relevance of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2950</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2950</id><created>2011-03-15</created><authors><author><keyname>Li</keyname><forenames>Wentian</forenames></author><author><keyname>Miramontes</keyname><forenames>Pedro</forenames></author></authors><title>Fitting Ranked English and Spanish Letter Frequency Distribution in U.S.
  and Mexican Presidential Speeches</title><categories>cs.CL</categories><comments>7 figures</comments><journal-ref>Journal of Quantitative Linguistics, 18(4):359-380 (2011)</journal-ref><doi>10.1080/09296174.2011.608606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The limited range in its abscissa of ranked letter frequency distributions
causes multiple functions to fit the observed distribution reasonably well. In
order to critically compare various functions, we apply the statistical model
selections on ten functions, using the texts of U.S. and Mexican presidential
speeches in the last 1-2 centuries. Dispite minor switching of ranking order of
certain letters during the temporal evolution for both datasets, the letter
usage is generally stable. The best fitting function, judged by either
least-square-error or by AIC/BIC model selection, is the Cocho/Beta function.
We also use a novel method to discover clusters of letters by their
observed-over-expected frequency ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2952</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2952</id><created>2011-03-14</created><authors><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>Data sets of very large linear feasibility problems solved by projection
  methods</title><categories>cs.MS math.OC</categories><comments>4 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a link to a page on the Web on which we deposited a set of eight huge
Linear Programming (LP) problems for Intensity-Modulated Proton Therapy (IMPT)
treatment planning. These huge LP problems were employed in our recent research
and we were asked to make them public.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2960</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2960</id><created>2011-03-15</created><authors><author><keyname>Mishali</keyname><forenames>Moshe</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Xampling: Compressed Sensing of Analog Signals</title><categories>cs.IT cs.SY math.IT</categories><comments>58 pages, 26 figures</comments><journal-ref>in: &quot;Compressed Sensing: Theory and Applications&quot;, Cambridge
  University Press, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Xampling generalizes compressed sensing (CS) to reduced-rate sampling of
analog signals. A unified framework is introduced for low rate sampling and
processing of signals lying in a union of subspaces. Xampling consists of two
main blocks: Analog compression that narrows down the input bandwidth prior to
sampling with commercial devices followed by a nonlinear algorithm that detects
the input subspace prior to conventional signal processing. A variety of analog
CS applications are reviewed within the unified Xampling framework including a
general filter-bank scheme for sparse shift-invariant spaces, periodic
nonuniform sampling and modulated wideband conversion for multiband
communications with unknown carrier frequencies, acquisition techniques for
finite rate of innovation signals with applications to medical and radar
imaging, and random demodulation of sparse harmonic tones. A hardware-oriented
viewpoint is advocated throughout, addressing practical constraints and
exemplifying hardware realizations where relevant. It will appear as a chapter
in a book on &quot;Compressed Sensing: Theory and Applications&quot; edited by Yonina
Eldar and Gitta Kutyniok.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.2986</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.2986</id><created>2011-03-15</created><updated>2011-11-18</updated><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Li</keyname><forenames>Baiyu</forenames></author><author><keyname>Ye</keyname><forenames>Yuli</forenames></author></authors><title>Syntactic Complexity of Prefix-, Suffix-, Bifix-, and Factor-Free
  Regular Languages</title><categories>cs.FL</categories><comments>28 pages, 6 figures, 3 tables. An earlier version of this paper was
  presented in: M. Holzer, M. Kutrib, G. Pighizzini, eds., 13th Int. Workshop
  on Descriptional Complexity of Formal Systems, DCFS 2011, Vol. 6808 of LNCS,
  Springer, 2011, pp. 93-106. The current version contains improved bounds for
  suffix-free languages, new results about factor-free languages, and new
  results about reversal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The syntactic complexity of a regular language is the cardinality of its
syntactic semigroup. The syntactic complexity of a subclass of the class of
regular languages is the maximal syntactic complexity of languages in that
class, taken as a function of the state complexity $n$ of these languages. We
study the syntactic complexity of prefix-, suffix-, bifix-, and factor-free
regular languages. We prove that $n^{n-2}$ is a tight upper bound for
prefix-free regular languages. We present properties of the syntactic
semigroups of suffix-, bifix-, and factor-free regular languages, conjecture
tight upper bounds on their size to be $(n-1)^{n-2}+(n-2)$, $(n-1)^{n-3} +
(n-2)^{n-3} + (n-3)2^{n-3}$, and $(n-1)^{n-3} + (n-3)2^{n-3} + 1$,
respectively, and exhibit languages with these syntactic complexities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3002</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3002</id><created>2011-03-15</created><authors><author><keyname>Hamad</keyname><forenames>Ibrahim Abou</forenames><affiliation>Florida State University</affiliation></author><author><keyname>Rikvold</keyname><forenames>Per Arne</forenames><affiliation>Florida State University</affiliation></author><author><keyname>Poroseva</keyname><forenames>Svetlana V.</forenames><affiliation>University of New Mexico</affiliation></author></authors><title>Floridian high-voltage power-grid network partitioning and cluster
  optimization using simulated annealing</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>9 pages, 3 figures, University of Georgia 24th Annual CSP Workshop</comments><journal-ref>Physics Procedia 15, 2-6 (2011)</journal-ref><doi>10.1016/j.phpro.2011.05.051</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many partitioning methods may be used to partition a network into smaller
clusters while minimizing the number of cuts needed. However, other
considerations must also be taken into account when a network represents a real
system such as a power grid. In this paper we use a simulated annealing Monte
Carlo (MC) method to optimize initial clusters on the Florida high-voltage
power-grid network that were formed by associating each load with its &quot;closest&quot;
generator. The clusters are optimized to maximize internal connectivity within
the individual clusters and minimize the power deficiency or surplus that
clusters may otherwise have.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3005</identifier>
 <datestamp>2015-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3005</id><created>2011-03-15</created><updated>2012-05-05</updated><authors><author><keyname>Georgiou</keyname><forenames>Tryphon T.</forenames></author><author><keyname>Lindquist</keyname><forenames>Anders</forenames></author></authors><title>The Separation Principle in Stochastic Control, Redux</title><categories>math.OC cs.SY</categories><comments>23 pages, 6 figures, 2nd revision: added references, corrections</comments><msc-class>93E20</msc-class><journal-ref>Automatic Control, IEEE Transactions on 58.10 (2013): 2481-2494</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last 50 years a steady stream of accounts have been written on the
separation principle of stochastic control. Even in the context of the
linear-quadratic regulator in continuous time with Gaussian white noise, subtle
difficulties arise, unexpected by many, that are often overlooked. In this
paper we propose a new framework for establishing the separation principle.
This approach takes the viewpoint that stochastic systems are well-defined maps
between sample paths rather than stochastic processes per se and allows us to
extend the separation principle to systems driven by martingales with possible
jumps. While the approach is more in line with &quot;real-life&quot; engineering thinking
where signals travel around the feedback loop, it is unconventional from a
probabilistic point of view in that control laws for which the feedback
equations are satisfied almost surely, and not deterministically for every
sample path, are excluded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3017</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3017</id><created>2011-03-15</created><authors><author><keyname>Gavinsky</keyname><forenames>Dmitry</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author><author><keyname>Roland</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author></authors><title>Quantum algorithm for the Boolean hidden shift problem</title><categories>quant-ph cs.CC</categories><comments>10 pages, 1 figure</comments><journal-ref>17th International Computing &amp; Combinatorics Conference
  (COCOON'11), Lecture Notes in Computer Science 6842 (Springer, 2011), pages
  158-167</journal-ref><doi>10.1007/978-3-642-22685-4_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hidden shift problem is a natural place to look for new separations
between classical and quantum models of computation. One advantage of this
problem is its flexibility, since it can be defined for a whole range of
functions and a whole range of underlying groups. In a way, this distinguishes
it from the hidden subgroup problem where more stringent requirements about the
existence of a periodic subgroup have to be made. And yet, the hidden shift
problem proves to be rich enough to capture interesting features of problems of
algebraic, geometric, and combinatorial flavor. We present a quantum algorithm
to identify the hidden shift for any Boolean function. Using Fourier analysis
for Boolean functions we relate the time and query complexity of the algorithm
to an intrinsic property of the function, namely its minimum influence. We show
that for randomly chosen functions the time complexity of the algorithm is
polynomial. Based on this we show an average case exponential separation
between classical and quantum time complexity. A perhaps interesting aspect of
this work is that, while the extremal case of the Boolean hidden shift problem
over so-called bent functions can be reduced to a hidden subgroup problem over
an abelian group, the more general case studied here does not seem to allow
such a reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3020</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3020</id><created>2011-03-15</created><authors><author><keyname>Mouton</keyname><forenames>Claire</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A study of the existing linear algebra libraries that you can use from
  C++ (Une \'etude des biblioth\`eques d'alg\`ebre lin\'eaire utilisables en
  C++)</title><categories>cs.MS cs.SE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A study of the existing linear algebra libraries that you can use from C++
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3021</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3021</id><created>2011-03-15</created><authors><author><keyname>Mouton</keyname><forenames>Claire</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A study of the existing libraries to read from configuration files (from
  C++)</title><categories>cs.SE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A study of the existing libraries to read from configuration files (from C++)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3026</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3026</id><created>2011-03-15</created><authors><author><keyname>Grigori</keyname><forenames>Laura</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Nataf</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LJLL</affiliation></author></authors><title>Generalized Filtering Decomposition</title><categories>cs.NA</categories><proxy>ccsd</proxy><report-no>RR-7569</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new preconditioning technique that is suitable for
matrices arising from the discretization of a system of PDEs on unstructured
grids. The preconditioner satisfies a so-called filtering property, which
ensures that the input matrix is identical with the preconditioner on a given
filtering vector. This vector is chosen to alleviate the effect of low
frequency modes on convergence and so decrease or eliminate the plateau which
is often observed in the convergence of iterative methods. In particular, the
paper presents a general approach that allows to ensure that the filtering
condition is satisfied in a matrix decomposition. The input matrix can have an
arbitrary sparse structure. Hence, it can be reordered using nested dissection,
to allow a parallel computation of the preconditioner and of the iterative
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3054</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3054</id><created>2011-03-15</created><updated>2011-06-01</updated><authors><author><keyname>&#x15e;en</keyname><forenames>Nevroz</forenames></author><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author><author><keyname>Alajaji</keyname><forenames>Fady</forenames></author></authors><title>On the Capacity of Memoryless Finite-State Multiple Access Channels with
  Asymmetric Noisy State Information at the Encoders</title><categories>cs.IT math.IT</categories><comments>To be submitted Allerton Conference 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the capacity of memoryless finite-state multiple access channel
(FS-MAC) with causal asymmetric noisy state information available at both
transmitters and complete state information available at the receiver. Single
letter inner and outer bounds are provided for the capacity of such channels
when the state process is independent and identically distributed. The outer
bound is attained by observing that the proposed inner bound is tight for the
sum-rate capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3075</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3075</id><created>2011-03-15</created><authors><author><keyname>Cartledge</keyname><forenames>Charles L.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Connectivity Damage to a Graph by the Removal of an Edge or a Vertex</title><categories>cs.DL cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The approach of quantifying the damage inflicted on a graph in Albert, Jeong
and Barabsi's (AJB) report &quot;Error and Attack Tolerance of Complex Networks&quot;
using the size of the largest connected component and the average size of the
remaining components does not capture our intuitive idea of the damage to a
graph caused by disconnections. We evaluate an alternative metric based on
average inverse path lengths (AIPLs) that better fits our intuition that a
graph can still be reasonably functional even when it is disconnected. We
compare our metric with AJB's using a test set of graphs and report the
differences. AJB's report should not be confused with a report by Crucitti et
al. with the same name. Based on our analysis of graphs of different sizes and
types, and using various numerical and statistical tools; the ratio of the
average inverse path lengths of a connected graph of the same size as the sum
of the size of the fragments of the disconnected graph can be used as a metric
about the damage of a graph by the removal of an edge or a node. This damage is
reported in the range (0,1) where 0 means that the removal had no effect on the
graph's capability to perform its functions. A 1 means that the graph is
totally dysfunctional. We exercise our metric on a collection of sample graphs
that have been subjected to various attack profiles that focus on edge, node or
degree betweenness values. We believe that this metric can be used to quantify
the damage done to the graph by an attacker, and that it can be used in
evaluating the positive effect of adding additional edges to an existing graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3076</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3076</id><created>2011-03-15</created><updated>2012-02-27</updated><authors><author><keyname>Bell</keyname><forenames>Nathan</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author></authors><title>PyDEC: Software and Algorithms for Discretization of Exterior Calculus</title><categories>cs.NA cs.CG cs.MS math.DG math.NA</categories><comments>Revised as per referee reports. Added information on scalability,
  removed redundant text, emphasized the role of matrix based algorithms,
  shortened length of paper</comments><msc-class>65N30</msc-class><acm-class>G.4; G.1.8; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the algorithms, features and implementation of PyDEC, a
Python library for computations related to the discretization of exterior
calculus. PyDEC facilitates inquiry into both physical problems on manifolds as
well as purely topological problems on abstract complexes. We describe
efficient algorithms for constructing the operators and objects that arise in
discrete exterior calculus, lowest order finite element exterior calculus and
in related topological problems. Our algorithms are formulated in terms of
high-level matrix operations which extend to arbitrary dimension. As a result,
our implementations map well to the facilities of numerical libraries such as
NumPy and SciPy. The availability of such libraries makes Python suitable for
prototyping numerical methods. We demonstrate how PyDEC is used to solve
physical and topological problems through several concise examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3093</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3093</id><created>2011-03-16</created><authors><author><keyname>Da</keyname><forenames>Bin</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Exploiting Interference Alignment in Multi-Cell Cooperative OFDMA
  Resource Allocation</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures, GC2011 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies interference alignment (IA) based multi-cell cooperative
resource allocation for the downlink OFDMA with universal frequency reuse.
Unlike the traditional scheme that treats subcarriers as separate dimensions
for resource allocation, the IA technique is utilized to enable
frequency-domain precoding over parallel subcarriers. In this paper, the joint
optimization of frequency-domain precoding via IA, subcarrier user selection
and power allocation is investigated for a cooperative three-cell OFDMA system
to maximize the downlink throughput. Numerical results for a simplified
symmetric channel setup reveal that the IA-based scheme achieves notable
throughput gains over the traditional scheme only when the inter-cell
interference link has a comparable strength as the direct link, and the
receiver SNR is sufficiently large. Motivated by this observation, a practical
hybrid scheme is proposed for cellular systems with heterogenous channel
conditions, where the total spectrum is divided into two subbands, over which
the IAbased scheme and the traditional scheme are applied for resource
allocation to users located in the cell-intersection region and cellnon-
intersection region, respectively. It is shown that this hybrid resource
allocation scheme flexibly exploits the downlink IA gains for OFDMA-based
cellular systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3095</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3095</id><created>2011-03-16</created><authors><author><keyname>Mahalanabis</keyname><forenames>Satyaki</forenames></author></authors><title>A note on active learning for smooth problems</title><categories>cs.LG stat.ML</categories><msc-class>68Q32: Computational learning theory</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the disagreement coefficient of certain smooth hypothesis
classes is $O(m)$, where $m$ is the dimension of the hypothesis space, thereby
answering a question posed in \cite{friedman09}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3099</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3099</id><created>2011-03-16</created><updated>2011-03-19</updated><authors><author><keyname>Urgaonkar</keyname><forenames>Rahul</forenames></author><author><keyname>Urgaonkar</keyname><forenames>Bhuvan</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author><author><keyname>Sivasubramaniam</keyname><forenames>Anand</forenames></author></authors><title>Optimal Power Cost Management Using Stored Energy in Data Centers</title><categories>cs.PF cs.SY math.OC</categories><comments>Full version of Sigmetrics 2011 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the electricity bill of a data center constitutes a significant portion
of its overall operational costs, reducing this has become important. We
investigate cost reduction opportunities that arise by the use of uninterrupted
power supply (UPS) units as energy storage devices. This represents a deviation
from the usual use of these devices as mere transitional fail-over mechanisms
between utility and captive sources such as diesel generators. We consider the
problem of opportunistically using these devices to reduce the time average
electric utility bill in a data center. Using the technique of Lyapunov
optimization, we develop an online control algorithm that can optimally exploit
these devices to minimize the time average cost. This algorithm operates
without any knowledge of the statistics of the workload or electricity cost
processes, making it attractive in the presence of workload and pricing
uncertainties. An interesting feature of our algorithm is that its deviation
from optimality reduces as the storage capacity is increased. Our work opens up
a new area in data center power management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3102</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3102</id><created>2011-03-16</created><authors><author><keyname>Parameswaran</keyname><forenames>Aditya</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Sarma</keyname><forenames>Anish Das</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Garcia-Molina</keyname><forenames>Hector</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Polyzotis</keyname><forenames>Neoklis</forenames><affiliation>UC Santa Cruz</affiliation></author><author><keyname>Widom</keyname><forenames>Jennifer</forenames><affiliation>Stanford University</affiliation></author></authors><title>Human-Assisted Graph Search: It's Okay to Ask Questions</title><categories>cs.DB cs.DS</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 5, pp.
  267-278 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of human-assisted graph search: given a directed
acyclic graph with some (unknown) target node(s), we consider the problem of
finding the target node(s) by asking an omniscient human questions of the form
&quot;Is there a target node that is reachable from the current node?&quot;. This general
problem has applications in many domains that can utilize human intelligence,
including curation of hierarchies, debugging workflows, image segmentation and
categorization, interactive search and filter synthesis. To our knowledge, this
work provides the first formal algorithmic study of the optimization of human
computation for this problem. We study various dimensions of the problem space,
providing algorithms and complexity results. Our framework and algorithms can
be used in the design of an optimizer for crowd-sourcing platforms such as
Mechanical Turk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3103</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3103</id><created>2011-03-16</created><authors><author><keyname>Yakout</keyname><forenames>Mohamed</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Elmagarmid</keyname><forenames>Ahmed K.</forenames><affiliation>Qatar Computing Research Institute</affiliation></author><author><keyname>Neville</keyname><forenames>Jennifer</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Ouzzani</keyname><forenames>Mourad</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Ilyas</keyname><forenames>Ihab F.</forenames><affiliation>University of Waterloo</affiliation></author></authors><title>Guided Data Repair</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 5, pp.
  279-289 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present GDR, a Guided Data Repair framework that
incorporates user feedback in the cleaning process to enhance and accelerate
existing automatic repair techniques while minimizing user involvement. GDR
consults the user on the updates that are most likely to be beneficial in
improving data quality. GDR also uses machine learning methods to identify and
apply the correct updates directly to the database without the actual
involvement of the user on these specific updates. To rank potential updates
for consultation by the user, we first group these repairs and quantify the
utility of each group using the decision-theory concept of value of information
(VOI). We then apply active learning to order updates within a group based on
their ability to improve the learned model. User feedback is used to repair the
database and to adaptively refine the training set for the model. We
empirically evaluate GDR on a real-world dataset and show significant
improvement in data quality using our user guided repairing process. We also,
assess the trade-off between the user efforts and the resulting data quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3105</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3105</id><created>2011-03-16</created><authors><author><keyname>He</keyname><forenames>Bingsheng</forenames><affiliation>Nanyang Technological University</affiliation></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames><affiliation>Chinese University of Hong Kong</affiliation></author></authors><title>High-Throughput Transaction Executions on Graphics Processors</title><categories>cs.DB cs.DC</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 5, pp.
  314-325 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  OLTP (On-Line Transaction Processing) is an important business system sector
in various traditional and emerging online services. Due to the increasing
number of users, OLTP systems require high throughput for executing tens of
thousands of transactions in a short time period. Encouraged by the recent
success of GPGPU (General-Purpose computation on Graphics Processors), we
propose GPUTx, an OLTP engine performing high-throughput transaction executions
on the GPU for in-memory databases. Compared with existing GPGPU studies
usually optimizing a single task, transaction executions require handling many
small tasks concurrently. Specifically, we propose the bulk execution model to
group multiple transactions into a bulk and to execute the bulk on the GPU as a
single task. The transactions within the bulk are executed concurrently on the
GPU. We study three basic execution strategies (one with locks and the other
two lock-free), and optimize them with the GPU features including the hardware
support of atomic operations, the massive thread parallelism and the SPMD
(Single Program Multiple Data) execution. We evaluate GPUTx on a recent NVIDIA
GPU in comparison with its counterpart on a quad-core CPU. Our experimental
results show that optimizations on GPUTx significantly improve the throughput,
and the optimized GPUTx achieves 4-10 times higher throughput than its
CPU-based counterpart on public transaction processing benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3107</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3107</id><created>2011-03-16</created><updated>2011-04-16</updated><authors><author><keyname>Koc</keyname><forenames>Mehmet Levent</forenames><affiliation>University of Wisconsin-Madiso</affiliation></author><author><keyname>R&#xe9;</keyname><forenames>Christopher</forenames><affiliation>University of Wisconsin-Madison</affiliation></author></authors><title>Incrementally Maintaining Classification using an RDBMS</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>Uwe Roehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 5, pp.
  302-313 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of imprecise data has motivated both researchers and the
database industry to push statistical techniques into relational database
management systems (RDBMSs). We study algorithms to maintain model-based views
for a popular statistical technique, classification, inside an RDBMS in the
presence of updates to the training examples. We make three technical
contributions: (1) An algorithm that incrementally maintains classification
inside an RDBMS. (2) An analysis of the above algorithm that shows that our
algorithm is optimal among all deterministic algorithms (and asymptotically
within a factor of 2 of a nondeterministic optimal). (3) An index structure
based on the technical ideas that underlie the above algorithm which allows us
to store only a fraction of the entities in memory. We apply our techniques to
text processing, and we demonstrate that our algorithms provide several orders
of magnitude improvement over non-incremental approaches to classification on a
variety of data sets: such as the Cora, UCI Machine Learning Repository data
sets, Citeseer, and DBLife.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3111</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3111</id><created>2011-03-16</created><authors><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames></author></authors><title>Proceedings Types for Proofs and Programs, Revised Selected Papers</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 53, 2011</journal-ref><doi>10.4204/EPTCS.53</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Types for Proofs and Programs is the annual meeting of the Types Project,
whose aim is to develop the technology of formal reasoning and computer
programming based on Type Theory. This is done by improving the languages and
computerised tools for reasoning, and by applying the technology in several
domains such as analysis of programming languages, certified software,
formalisation of mathematics and mathematics education.
  The 2009 meeting took place in Aussois, France, and we thank the invited
speakers Richard Garner, Peter Hancock, Pawe{\l} Urzyczyn for excellent talks.
The present volume consists of papers not necessarily presented at the
workshop, selected by Thorsten Altenkirch, Tom Hirschowitz, Christophe
Raffalli, and Alan Schmitt, with help from Matthieu Sozeau and Makarius Wenzel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3113</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3113</id><created>2011-03-16</created><authors><author><keyname>Tang</keyname><forenames>Xiaojun</forenames></author><author><keyname>Liu</keyname><forenames>Ruoheng</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>A Broadcast Approach To Secret Key Generation Over Slow Fading Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A secret-key generation scheme based on a layered broadcasting strategy is
introduced for slow-fading channels. In the model considered, Alice wants to
share a key with Bob while keeping the key secret from Eve, who is a passive
eavesdropper. Both Alice-Bob and Alice-Eve channels are assumed to undergo slow
fading, and perfect channel state information (CSI) is assumed to be known only
at the receivers during the transmission. In each fading slot, Alice broadcasts
a continuum of coded layers and, hence, allows Bob to decode at the rate
corresponding to the fading state (unknown to Alice). The index of a reliably
decoded layer is sent back from Bob to Alice via a public and error-free
channel and used to generate a common secret key. In this paper, the achievable
secrecy key rate is first derived for a given power distribution over coded
layers. The optimal power distribution is then characterized. It is shown that
layered broadcast coding can increase the secrecy key rate significantly
compared to single-level coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3114</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3114</id><created>2011-03-16</created><updated>2011-07-13</updated><authors><author><keyname>Goto</keyname><forenames>Keisuke</forenames></author><author><keyname>Bannai</keyname><forenames>Hideo</forenames></author><author><keyname>Inenaga</keyname><forenames>Shunsuke</forenames></author><author><keyname>Takeda</keyname><forenames>Masayuki</forenames></author></authors><title>Fast $q$-gram Mining on SLP Compressed Strings</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present simple and efficient algorithms for calculating $q$-gram
frequencies on strings represented in compressed form, namely, as a straight
line program (SLP). Given an SLP of size $n$ that represents string $T$, we
present an $O(qn)$ time and space algorithm that computes the occurrence
frequencies of $q$-grams in $T$. Computational experiments show that our
algorithm and its variation are practical for small $q$, actually running
faster on various real string data, compared to algorithms that work on the
uncompressed text. We also discuss applications in data mining and
classification of string data, for which our algorithms can be useful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3117</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3117</id><created>2011-03-16</created><authors><author><keyname>Braun</keyname><forenames>Michael</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>Linearity and Complements in Projective Space</title><categories>cs.IT math.IT</categories><comments>submitted to Linear Algebra and Its Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The projective space of order $n$ over the finite field $\Fq$, denoted here
as $\Ps$, is the set of all subspaces of the vector space $\Fqn$. The
projective space can be endowed with distance function $d_S(X,Y) = \dim(X) +
\dim(Y) - 2\dim(X\cap Y)$ which turns $\Ps$ into a metric space. With this,
\emph{an $(n,M,d)$ code $\C$ in projective space} is a subset of $\Ps$ of size
$M$ such that the distance between any two codewords (subspaces) is at least
$d$. Koetter and Kschischang recently showed that codes in projective space are
precisely what is needed for error-correction in networks: an $(n,M,d)$ code
can correct $t$ packet errors and $\rho$ packet erasures introduced
(adversarially) anywhere in the network as long as $2t + 2\rho &lt; d$. This
motivates new interest in such codes.
  In this paper, we examine the two fundamental concepts of
\myemph{complements} and \myemph{linear codes} in the context of $\Ps$. These
turn out to be considerably more involved than their classical counterparts.
These concepts are examined from two different points of view, coding theory
and lattice theory. Our discussion reveals some surprised phenomena of these
concepts in $\Ps$ and leaves some interesting problems for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3123</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3123</id><created>2011-03-16</created><updated>2011-03-24</updated><authors><author><keyname>Lai</keyname><forenames>Yong</forenames></author><author><keyname>Liu</keyname><forenames>Dayou</forenames></author><author><keyname>Wang</keyname><forenames>Shengsheng</forenames></author></authors><title>Reduced Ordered Binary Decision Diagram with Implied Literals: A New
  knowledge Compilation Approach</title><categories>cs.AI</categories><comments>18 pages, 13 figures</comments><acm-class>I.2.3; I.2.4</acm-class><doi>10.1007/s10115-012-0525-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge compilation is an approach to tackle the computational
intractability of general reasoning problems. According to this approach,
knowledge bases are converted off-line into a target compilation language which
is tractable for on-line querying. Reduced ordered binary decision diagram
(ROBDD) is one of the most influential target languages. We generalize ROBDD by
associating some implied literals in each node and the new language is called
reduced ordered binary decision diagram with implied literals (ROBDD-L). Then
we discuss a kind of subsets of ROBDD-L called ROBDD-i with precisely i implied
literals (0 \leq i \leq \infty). In particular, ROBDD-0 is isomorphic to ROBDD;
ROBDD-\infty requires that each node should be associated by the implied
literals as many as possible. We show that ROBDD-i has uniqueness over some
specific variables order, and ROBDD-\infty is the most succinct subset in
ROBDD-L and can meet most of the querying requirements involved in the
knowledge compilation map. Finally, we propose an ROBDD-i compilation algorithm
for any i and a ROBDD-\infty compilation algorithm. Based on them, we implement
a ROBDD-L package called BDDjLu and then get some conclusions from preliminary
experimental results: ROBDD-\infty is obviously smaller than ROBDD for all
benchmarks; ROBDD-\infty is smaller than the d-DNNF the benchmarks whose
compilation results are relatively small; it seems that it is better to
transform ROBDDs-\infty into FBDDs and ROBDDs rather than straight compile the
benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3130</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3130</id><created>2011-03-16</created><authors><author><keyname>Pimbblet</keyname><forenames>Kevin A.</forenames></author></authors><title>The h-index in Australian Astronomy</title><categories>astro-ph.IM cs.DL physics.soc-ph</categories><comments>Accepted for publication in the Publications of the Astronomical
  Society of Australia</comments><doi>10.1071/AS11002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Hirsch (2005) h-index is now widely used as a metric to compare
individual researchers. To evaluate it in the context of Australian Astronomy,
the h-index for every member of the Astronomical Society of Australia (ASA) is
found using NASA's Astrophysics Data System Bibliographic Services (ADS).
Percentiles of the h-index distribution are detailed for a variety of
categories of ASA members, including students. This enables a list of the top
ten Australian researchers by h-index to be produced. These top researchers
have h-index values in the range 53&lt;h&lt;77, which is less than that recently
reported for the American Astronomical Society Membership. We suggest that
membership of extremely large consortia such as SDSS may partially explain the
difference. We further suggest that many student ASA members with large h-index
values have probably already received their Ph.D.'s and need to upgrade their
ASA membership status. To attempt to specify the h-index distribution relative
to opportunity, we also detail the percentiles of its distribution by years
since Ph.D. award date. This shows a steady increase in h-index with seniority,
as can be expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3136</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3136</id><created>2011-03-16</created><authors><author><keyname>Itoh</keyname><forenames>Jin-ichi</forenames></author><author><keyname>V\^\ilcu</keyname><forenames>Costin</forenames></author></authors><title>Orientable cut locus structures on graphs</title><categories>math.DG cs.DM</categories><comments>24 pages, 14 pages. Fourth in a series of four papers</comments><msc-class>53C22, 05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We showed in another paper [arXiv:1103.1759] that every connected graph can
be realized as the cut locus of some point on some riemannian surface $S$.
Here, criteria for the orientability of $S$ are given, and are applied to
classify the distinct, orientable, cut locus structures on graphs with four
generating cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3159</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3159</id><created>2011-03-16</created><authors><author><keyname>Das</keyname><forenames>Ashok Kumar</forenames></author></authors><title>Cryptanalysis And Further Improvement Of A Biometric-Based Remote User
  Authentication Scheme Using Smart Cards</title><categories>cs.CR</categories><comments>16 pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol. 3, No. 2, 2011</journal-ref><doi>10.5121/ijnsa.2011.3202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Li et al. proposed a secure biometric-based remote user
authentication scheme using smart cards to withstand the security flaws of
Li-Hwang's efficient biometric-based remote user authentication scheme using
smart cards. Li et al.'s scheme is based on biometrics verification, smart card
and one-way hash function, and it also uses the random nonce rather than a
synchronized clock, and thus it is efficient in computational cost and more
secure than Li-Hwang's scheme. Unfortunately, in this paper we show that Li et
al.'s scheme still has some security weaknesses in their design. In order to
withstand those weaknesses in their scheme, we further propose an improvement
of their scheme so that the improved scheme always provides proper
authentication and as a result, it establishes a session key between the user
and the server at the end of successful user authentication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3160</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3160</id><created>2011-03-16</created><updated>2014-08-13</updated><authors><author><keyname>Morosetti</keyname><forenames>Stefano</forenames></author></authors><title>sin[n Delta t sin (n Delta t1)] as a source of unpredictable dynamics</title><categories>nlin.CD cs.MS math.DS</categories><comments>15 pages, 11 figures New version: Revised demonstration in section
  2.1, results unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the ability of the function sin[n Delta t sin (n Delta t1)],
where n is an integer and growing number, to produce unpredictable sequences of
numbers. Classical mathematical tools for distinguishing periodic from chaotic
or random behaviour, such as sensitivity to the initial conditions, Fourier
analysis, and autocorrelation are used. Moreover, the function acos{sin[n Delta
t sin (n Delta t1)]}/pigreek is introduced to have an uniform density of
numbers in the interval [0,1], so it can be submitted to a battery of widely
used tests for random number generators. All these tools show that a proper
choice of Delta t and Delta t1, can produce a sequence of numbers behaving as
unpredictable dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3174</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3174</id><created>2011-03-16</created><authors><author><keyname>Boyd</keyname><forenames>Andrew W.</forenames></author></authors><title>A Longitudinal Study of Social Media Privacy Behavior</title><categories>cs.SI cs.CY</categories><comments>10 pages, 6 tables, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing constructs for privacy concerns and behaviors do not adequately
model deviations between user attitudes and behaviors. Although a number of
studies have examined supposed deviations from rationality by online users,
true explanations for these behaviors may lie in factors not previously
addressed in privacy concern constructs. In particular, privacy attitudes and
behavioral changes over time have not been examined within the context of an
empirical study. This paper presents the results of an Agile, sprint-based
longitudinal study of Social Media users conducted over a two year period
between April of 2009 and March of 2011. This study combined concepts drawn
from Privacy Regulation Theory with the constructs of the Internet Users'
Information and Privacy Concern model to create a series of online surveys that
examined changes of Social Media privacy attitudes and self-reported behaviors
over time. The main findings of this study are that, over a two year period
between 2009 and 2011, respondents' privacy concerns and distrust of Social
Media Sites increased significantly, while their disclosure of personal
information and willingness to connect with new online friends decreased
significantly. Further qualitative interviews of selected respondents
identified these changes as emblematic of users developing ad-hoc risk
mitigation strategies to address privacy threats.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3190</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3190</id><created>2011-03-11</created><authors><author><keyname>Karout</keyname><forenames>Johnny</forenames></author><author><keyname>Agrell</keyname><forenames>Erik</forenames></author><author><keyname>Szczerba</keyname><forenames>Krzysztof</forenames></author><author><keyname>Karlsson</keyname><forenames>Magnus</forenames></author></authors><title>Designing Power-Efficient Modulation Formats for Noncoherent Optical
  Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to Globecom 2011</comments><journal-ref>Proc. Global Communications Conference (GlobeCom), Houston, TX,
  Dec. 2011 (best paper award)</journal-ref><doi>10.1109/GLOCOM.2011.6133546</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We optimize modulation formats for the additive white Gaussian noise channel
with a nonnegative input constraint, also known as the intensity-modulated
direct detection channel, with and without confining them to a lattice
structure. Our optimization criteria are the average electrical and optical
power. The nonnegativity input signal constraint is translated into a conical
constraint in signal space, and modulation formats are designed by sphere
packing inside this cone. Some remarkably dense packings are found, which yield
more power-efficient modulation formats than previously known. For example, at
a spectral efficiency of 1 bit/s/Hz, the obtained modulation format offers a
0.86 dB average electrical power gain and 0.43 dB average optical power gain
over the previously best known modulation formats to achieve a symbol error
rate of 10^-6. This modulation turns out to have a lattice-based structure. At
a spectral efficiency of 3/2 bits/s/Hz and to achieve a symbol error rate of
10^-6, the modulation format obtained for optimizing the average electrical
power offers a 0.58 dB average electrical power gain over the best
lattice-based modulation and 2.55 dB gain over the best previously known
format. However, the modulation format optimized for average optical power
offers a 0.46 dB average optical power gain over the best lattice-based
modulation and 1.35 dB gain over the best previously known format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3196</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3196</id><created>2011-03-16</created><updated>2012-12-03</updated><authors><author><keyname>Su</keyname><forenames>Guifeng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaobing</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author></authors><title>Condensation phase transition in nonlinear fitness networks</title><categories>cond-mat.stat-mech cs.SI nlin.AO physics.soc-ph</categories><comments>6 pages, 5 figures</comments><journal-ref>Europhys. Lett., 100 (2012) 38003</journal-ref><doi>10.1209/0295-5075/100/38003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the condensation phase transitions in out-of-equilibrium complex
networks in a unifying framework which includes the nonlinear model and the
fitness model as its appropriate limits. We show a novel phase structure which
depends on both the fitness parameter and the nonlinear exponent. The
occurrence of the condensation phase transitions in the dynamical evolution of
the network is demonstrated by using Bianconi-Barabasi method. We find that the
nonlinear and the fitness preferential attachment mechanisms play important
roles in formation of an interesting phase structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3216</identifier>
 <datestamp>2011-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3216</id><created>2011-03-16</created><updated>2011-06-28</updated><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Which cities produce excellent papers worldwide more than can be
  expected? A new mapping approach--using Google Maps--based on statistical
  significance testing</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The methods presented in this paper allow for a statistical analysis
revealing centers of excellence around the world using programs that are freely
available. Based on Web of Science data, field-specific excellence can be
identified in cities where highly-cited papers were published significantly.
Compared to the mapping approaches published hitherto, our approach is more
analytically oriented by allowing the assessment of an observed number of
excellent papers for a city (in the sample) against the expected number. Using
this test, the approach cannot only identify the top performers in output but
the &quot;true jewels.&quot; These are cities locating authors who publish significantly
more top cited papers than can be expected. As the examples in this paper show
for physics, chemistry, and psychology, these cities do not necessarily have a
high output of excellent papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3223</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3223</id><created>2011-03-16</created><authors><author><keyname>Giacomelli</keyname><forenames>Piero</forenames></author><author><keyname>Munaro</keyname><forenames>Giulia</forenames></author><author><keyname>Rosso</keyname><forenames>Roberto</forenames></author></authors><title>Using Soft Computer Techniques on Smart Devices for Monitoring Chronic
  Diseases: the CHRONIOUS case</title><categories>cs.AI</categories><comments>presented at &quot;The Third International Conference on eHealth,
  Telemedicine, and Social Medicine (eTELEMED 2011)&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CHRONIOUS is an Open, Ubiquitous and Adaptive Chronic Disease Management
Platform for Chronic Obstructive Pulmonary Disease(COPD) Chronic Kidney Disease
(CKD) and Renal Insufficiency. It consists of several modules: an ontology
based literature search engine, a rule based decision support system, remote
sensors interacting with lifestyle interfaces (PDA, monitor touchscreen) and a
machine learning module. All these modules interact each other to allow the
monitoring of two types of chronic diseases and to help clinician in taking
decision for cure purpose. This paper illustrates how some machine learning
algorithms and a rule based decision support system can be used in smart
devices, to monitor chronic patient. We will analyse how a set of machine
learning algorithms can be used in smart devices to alert the clinician in case
of a patient health condition worsening trend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3224</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3224</id><created>2011-03-16</created><authors><author><keyname>Xu</keyname><forenames>Yangyang</forenames></author><author><keyname>Cui</keyname><forenames>Jinchuan</forenames></author></authors><title>A variant of multitask n-vehicle exploration problem: maximizing every
  processor's average profit</title><categories>math.OC cs.DS</categories><comments>This work is part of what I did as a graduate student in the Academy
  of Mathematics and Systems Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a variant of multitask n-vehicle exploration problem. Instead of
requiring an optimal permutation of vehicles in every group, the new problem
asks all vehicles in a group to arrive at a same destination. It can also be
viewed as to maximize every processor's average profit, given n tasks, and each
task's consume-time and profit. Meanwhile, we propose a new kind of partition
problem in fractional form, and analyze its computational complexity. Moreover,
by regarding fractional partition as a special case, we prove that the
maximizing average profit problem is NP-hard when the number of processors is
fixed and it is strongly NP-hard in general. At last, a pseudo-polynomial time
algorithm for the maximizing average profit problem and the fractional
partition problem is presented, thanks to the idea of the pseudo-polynomial
time algorithm for the classical partition problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3225</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3225</id><created>2011-03-16</created><authors><author><keyname>Bergstrom</keyname><forenames>Lars</forenames></author></authors><title>Measuring NUMA effects with the STREAM benchmark</title><categories>cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern high-end machines feature multiple processor packages, each of which
contains multiple independent cores and integrated memory controllers connected
directly to dedicated physical RAM. These packages are connected via a shared
bus, creating a system with a heterogeneous memory hierarchy. Since this shared
bus has less bandwidth than the sum of the links to memory, aggregate memory
bandwidth is higher when parallel threads all access memory local to their
processor package than when they access memory attached to a remote package.
  But, the impact of this heterogeneous memory architecture is not easily
understood from vendor benchmarks. Even where these measurements are available,
they provide only best-case memory throughput. This work presents a series of
modifications to the well-known STREAM benchmark to measure the effects of NUMA
on both a 48-core AMD Opteron machine and a 32-core Intel Xeon machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3228</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3228</id><created>2011-03-16</created><authors><author><keyname>Guven</keyname><forenames>H. Emre</forenames></author><author><keyname>Miller</keyname><forenames>Eric L.</forenames></author><author><keyname>Cleveland</keyname><forenames>Robin O.</forenames></author></authors><title>Multi-parameter acoustic imaging of uniform objects in inhomogeneous
  media</title><categories>cs.CV physics.med-ph</categories><comments>25 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem studied in this paper is ultrasound image reconstruction from
frequency-domain measurements of the scattered field from an object with
contrast in attenuation and sound speed. The case where the object has uniform
but unknown contrast in these properties relative to the background is
considered. Background clutter is taken into account in a physically realistic
manner by considering an exact scattering model for randomly located small
scatterers that vary in sound speed. The resulting statistical characteristics
of the interference is incorporated into the imaging solution, which includes
applying a total-variation minimization based approach where the relative
effect of perturbation in sound speed to attenuation is included as a
parameter. Convex optimization methods provide the basis for the reconstruction
algorithm. Numerical data for inversion examples are generated by solving the
discretized Lippman-Schwinger equation for the object and speckle-forming
scatterers in the background. A statistical model based on the Born
approximation is used for reconstruction of the object profile. Results are
presented for a two dimensional problem in terms of classification performance
and compared to minimum-l2-norm reconstruction. Classification using the
proposed method is shown to be robust down to a signal-to-clutter ratio of less
than 1 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3239</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3239</id><created>2011-03-16</created><authors><author><keyname>Kissig</keyname><forenames>Christian</forenames></author><author><keyname>Kurz</keyname><forenames>Alexander</forenames></author></authors><title>Generic Trace Logics</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We combine previous work on coalgebraic logic with the coalgebraic traces
semantics of Hasuo, Jacobs, and Sokolova.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3240</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3240</id><created>2011-03-02</created><updated>2012-10-09</updated><authors><author><keyname>Duffy</keyname><forenames>K. R.</forenames></author><author><keyname>Bordenave</keyname><forenames>C.</forenames></author><author><keyname>Leith</keyname><forenames>D. J.</forenames></author></authors><title>Decentralized Constraint Satisfaction</title><categories>cs.AI</categories><acm-class>F.2.0</acm-class><journal-ref>IEEE/ACM Transactions on Networking, 21 (4), 1298-1308, 2013</journal-ref><doi>10.1109/TNET.2012.2222923</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that several important resource allocation problems in wireless
networks fit within the common framework of Constraint Satisfaction Problems
(CSPs). Inspired by the requirements of these applications, where variables are
located at distinct network devices that may not be able to communicate but may
interfere, we define natural criteria that a CSP solver must possess in order
to be practical. We term these algorithms decentralized CSP solvers. The best
known CSP solvers were designed for centralized problems and do not meet these
criteria. We introduce a stochastic decentralized CSP solver and prove that it
will find a solution in almost surely finite time, should one exist, also
showing it has many practically desirable properties. We benchmark the
algorithm's performance on a well-studied class of CSPs, random k-SAT,
illustrating that the time the algorithm takes to find a satisfying assignment
is competitive with stochastic centralized solvers on problems with order a
thousand variables despite its decentralized nature. We demonstrate the
solver's practical utility for the problems that motivated its introduction by
using it to find a non-interfering channel allocation for a network formed from
data from downtown Manhattan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3292</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3292</id><created>2011-03-16</created><authors><author><keyname>Li</keyname><forenames>Jin-Hao</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Feedback Reduction for MIMO Broadcast Channel with Heterogeneous Fading</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers feedback load reduction for multiuser multiple input
multiple output (MIMO) broadcast channel where the users' channel distributions
are not homogeneous. A cluster-based feedback scheme is proposed such that the
range of possible signal-to-noise ratio (SNR) of the users are divided into
several clusters according to the order statistics of the users' SNRs. Each
cluster has a corresponding threshold, and the users compare their measured
instantaneous SNRs with the thresholds to determine whether and how many bits
they should use to feed back their instantaneous SNRs. If a user's
instantaneous SNR is lower than a certain threshold, the user does not feed
back. Feedback load reduction is thus achieved. For a given number of clusters,
the sum rate loss using the cluster-based feedback scheme is investigated. Then
the minimum number of clusters given a maximum tolerable sum rate loss is
derived. Through simulations, it is shown that, when the number of users is
large, full multiuser diversity can be achieved by the proposed feedback
scheme, which is more efficient than the conventional schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3296</identifier>
 <datestamp>2012-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3296</id><created>2011-03-16</created><updated>2012-12-18</updated><authors><author><keyname>Barreto</keyname><forenames>Paulo S. L. M.</forenames></author><author><keyname>Misoczki</keyname><forenames>Rafael</forenames></author><author><keyname>Lindner</keyname><forenames>Richard</forenames></author></authors><title>Decoding square-free Goppa codes over $\F_p$</title><categories>cs.CR</categories><msc-class>94A60, 14G50, 94B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new, efficient non-deterministic decoding algorithm for
square-free Goppa codes over $\F_p$ for any prime $p$. If the code in question
has degree $t$ and the average distance to the closest codeword is at least
$(4/p)t + 1$, the proposed decoder can uniquely correct up to $(2/p)t$ errors
with high probability. The correction capability is higher if the distribution
of error magnitudes is not uniform, approaching or reaching $t$ errors when any
particular error value occurs much more often than others or exclusively. This
makes the method interesting for (semantically secure) cryptosystems based on
the decoding problem for permuted and punctured Goppa codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3301</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3301</id><created>2011-03-16</created><updated>2011-09-11</updated><authors><author><keyname>Gastner</keyname><forenames>Michael T.</forenames></author></authors><title>Scaling and entropy in p-median facility location along a line</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI physics.comp-ph</categories><comments>7 pages, 6 figures, Physical Review E, in press</comments><journal-ref>Physical Review E 84, 036112 (2011)</journal-ref><doi>10.1103/PhysRevE.84.036112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The p-median problem is a common model for optimal facility location. The
task is to place p facilities (e.g., warehouses or schools) in a
heterogeneously populated space such that the average distance from a person's
home to the nearest facility is minimized. Here we study the special case where
the population lives along a line (e.g., a road or a river). If facilities are
optimally placed, the length of the line segment served by a facility is
inversely proportional to the square root of the population density. This
scaling law is derived analytically and confirmed for concrete numerical
examples of three US Interstate highways and the Mississippi River. If facility
locations are permitted to deviate from the optimum, the number of possible
solutions increases dramatically. Using Monte Carlo simulations, we compute how
scaling is affected by an increase in the average distance to the nearest
facility. We find that the scaling exponents change and are most sensitive near
the optimum facility distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3308</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3308</id><created>2011-03-16</created><authors><author><keyname>Mana</keyname><forenames>Mohammed</forenames></author><author><keyname>Feham</keyname><forenames>Mohammed</forenames></author><author><keyname>Bensaber</keyname><forenames>Boucif Amar</forenames></author></authors><title>A Light Weight Protocol to Provide Location Privacy in Wireless Body
  Area networks</title><categories>cs.CR</categories><comments>11 pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.2, March 2011</journal-ref><doi>10.5121/ijnsa.2011.3201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location privacy is one of the major security problems in a Wireless Body
Area Networks (WBANs). An eavesdropper can keep track of the place and time
devices are communicating. To make things even worse, the attacker does not
have to be physically close to the communicating devices, he can use a device
with a stronger antenna. The unique hardware address of a mobile device can
often be linked to the identity of the user operating the device. This
represents a violation of the user's privacy. The user should decide when
his/her location is revealed and when not. In this paper, we first categorize
the type of eavesdroppers for WBANs, and then we propose a new scheme to
provide the location privacy in Wireless Body Area Networks (WBANs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3310</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3310</id><created>2011-03-16</created><updated>2011-04-27</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>S&#xf8;rensen</keyname><forenames>Troels Bjerre</forenames></author></authors><title>Path coalitional games</title><categories>cs.GT</categories><comments>15 pages; To be presented at The Second Workshop on Cooperative Games
  in Multiagent Systems (COOPMAS 2011)</comments><msc-class>91A12, 68Q15</msc-class><acm-class>F.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general framework to model strategic aspects and stable and fair
resource allocations in networks via variants and generalizations of path
coalitional games. In these games, a coalition of edges or vertices is
successful if it can enable an s-t path. We present polynomial-time algorithms
to compute and verify least core payoffs of cost-based generalizations of path
coalitional games and their duals, thereby settling a number of open problems.
The least core payoffs of path coalitional games are completely characterized
and a polynomial-time algorithm for computing the nucleolus of edge path
coalitional games on undirected series-parallel graphs is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3316</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3316</id><created>2011-03-16</created><updated>2011-03-27</updated><authors><author><keyname>Sarvotham</keyname><forenames>Shriram</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Deterministic Bounds for Restricted Isometry of Compressed Sensing
  Matrices</title><categories>cs.IT math.IT</categories><comments>41 Pages, 3 Figures. Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Sensing (CS) is an emerging field that enables reconstruction of a
sparse signal $x \in {\mathbb R} ^n$ that has only $k \ll n$ non-zero
coefficients from a small number $m \ll n$ of linear projections. The
projections are obtained by multiplying $x$ by a matrix $\Phi \in {\mathbb
R}^{m \times n}$ --- called a CS matrix --- where $k &lt; m \ll n$. In this work,
we ask the following question: given the triplet $\{k, m, n \}$ that defines
the CS problem size, what are the deterministic limits on the performance of
the best CS matrix in ${\mathbb R}^{m \times n}$? We select Restricted Isometry
as the performance metric. We derive two deterministic converse bounds and one
deterministic achievable bound on the Restricted Isometry for matrices in
${\mathbb R}^{m \times n}$ in terms of $n$, $m$ and $k$. The first converse
bound (structural bound) is derived by exploiting the intricate relationships
between the singular values of sub-matrices and the complete matrix. The second
converse bound (packing bound) and the achievable bound (covering bound) are
derived by recognizing the equivalence of CS matrices to codes on Grassmannian
spaces. Simulations reveal that random Gaussian $\Phi$ provide far from optimal
performance. The derivation of the three bounds offers several new geometric
insights that relate optimal CS matrices to equi-angular tight frames, the
Welch bound, codes on Grassmannian spaces, and the Generalized Pythagorean
Theorem (GPT).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3319</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3319</id><created>2011-03-16</created><authors><author><keyname>Asperti</keyname><forenames>Andrea</forenames><affiliation>University of Bologna</affiliation></author><author><keyname>Tassi</keyname><forenames>Enrico</forenames><affiliation>Microsoft Research - INRIA Joint Centre</affiliation></author></authors><title>Superposition as a logical glue</title><categories>cs.LO</categories><comments>In Proceedings TYPES 2009, arXiv:1103.3111</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 53, 2011, pp. 1-15</journal-ref><doi>10.4204/EPTCS.53.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The typical mathematical language systematically exploits notational and
logical abuses whose resolution requires not just the knowledge of domain
specific notation and conventions, but not trivial skills in the given
mathematical discipline. A large part of this background knowledge is expressed
in form of equalities and isomorphisms, allowing mathematicians to freely move
between different incarnations of the same entity without even mentioning the
transformation. Providing ITP-systems with similar capabilities seems to be a
major way to improve their intelligence, and to ease the communication between
the user and the machine. The present paper discusses our experience of
integration of a superposition calculus within the Matita interactive prover,
providing in particular a very flexible, &quot;smart&quot; application tactic, and a
simple, innovative approach to automation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3320</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3320</id><created>2011-03-16</created><authors><author><keyname>Coen</keyname><forenames>Claudio Sacerdoti</forenames><affiliation>University of bologna</affiliation></author><author><keyname>Tassi</keyname><forenames>Enrico</forenames><affiliation>Microsoft Research - INRIA Joint Centre</affiliation></author></authors><title>Nonuniform Coercions via Unification Hints</title><categories>cs.LO</categories><comments>In Proceedings TYPES 2009, arXiv:1103.3111</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 53, 2011, pp. 16-29</journal-ref><doi>10.4204/EPTCS.53.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of nonuniform coercion, which is the promotion of a
value of one type to an enriched value of a different type via a nonuniform
procedure. Nonuniform coercions are a generalization of the (uniform) coercions
known in the literature and they arise naturally when formalizing mathematics
in an higher order interactive theorem prover using convenient devices like
canonical structures, type classes or unification hints. We also show how
nonuniform coercions can be naturally implemented at the user level in an
interactive theorem prover that allows unification hints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3321</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3321</id><created>2011-03-16</created><authors><author><keyname>Feng</keyname><forenames>Yangyue</forenames><affiliation>Department of Computer Science, RHUL</affiliation></author><author><keyname>Luo</keyname><forenames>Zhaohui</forenames><affiliation>Department of Computer Science, RHUL</affiliation></author></authors><title>Typed Operational Semantics for Dependent Record Types</title><categories>cs.LO</categories><comments>In Proceedings TYPES 2009, arXiv:1103.3111</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 53, 2011, pp. 30-46</journal-ref><doi>10.4204/EPTCS.53.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typed operational semantics is a method developed by H. Goguen to prove
meta-theoretic properties of type systems. This paper studies the metatheory of
a type system with dependent record types, using the approach of typed
operational semantics. In particular, the metatheoretical properties we have
proved include strong normalisation, Church-Rosser and subject reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3322</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3322</id><created>2011-03-16</created><authors><author><keyname>Wiedijk</keyname><forenames>Freek</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>Stateless HOL</title><categories>cs.LO</categories><comments>In Proceedings TYPES 2009, arXiv:1103.3111</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 53, 2011, pp. 47-61</journal-ref><doi>10.4204/EPTCS.53.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a version of the HOL Light system that supports undoing
definitions in such a way that this does not compromise the soundness of the
logic. In our system the code that keeps track of the constants that have been
defined thus far has been moved out of the kernel. This means that the kernel
now is purely functional.
  The changes to the system are small. All existing HOL Light developments can
be run by the stateless system with only minor changes.
  The basic principle behind the system is not to name constants by strings,
but by pairs consisting of a string and a definition. This means that the data
structures for the terms are all merged into one big graph. OCaml - the
implementation language of the system - can use pointer equality to establish
equality of data structures fast. This allows the system to run at acceptable
speeds. Our system runs at about 85% of the speed of the stateful version of
HOL Light.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3332</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3332</id><created>2011-03-17</created><authors><author><keyname>Singh</keyname><forenames>Raju</forenames></author><author><keyname>Vatsa</keyname><forenames>A. K.</forenames></author></authors><title>Confidentiality &amp; Authentication Mechanism for Biometric Information
  Transmitted over Low Bandwidth &amp; Unreliable channel</title><categories>cs.CR</categories><comments>9 Pages,2 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The security of bio-metric information - finger print, retina mapping, DNA
mapping and some other chemical and biological modified genes related
information - transfer through low bandwidth and unreliable or covert channel
is challenging task. Therefore, Security of biometric information is essential
requirement in this fast developing communication world. Thus, in this paper,
we propose efficient and effective mechanism for confidentiality and
authentication for biometric information transmitted by using arithmetic
encoding representation over low bandwidth and unreliable channel. It enhances
the speed of encryption, decryption and authentication process. It uses
arithmetic encoding scheme and public key cryptography e.g. modified version of
RSA algorithm called RSA-2 algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3333</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3333</id><created>2011-03-17</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>A Robust Mechanism for Defending Distributed Denial OF Service Attacks
  on Web Servers</title><categories>cs.CR</categories><comments>18 pages, 3 figures, 5 tables</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.2, pp. 162 - 179, March 2011</journal-ref><doi>10.5121/ijnsa.2011.3213</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Denial of Service (DDoS) attacks have emerged as a popular means
of causing mass targeted service disruptions, often for extended periods of
time. The relative ease and low costs of launching such attacks, supplemented
by the current inadequate sate of any viable defense mechanism, have made them
one of the top threats to the Internet community today. Since the increasing
popularity of web-based applications has led to several critical services being
provided over the Internet, it is imperative to monitor the network traffic so
as to prevent malicious attackers from depleting the resources of the network
and denying services to legitimate users. This paper first presents a brief
discussion on some of the important types of DDoS attacks that currently exist
and some existing mechanisms to combat these attacks. It then points out the
major drawbacks of the currently existing defense mechanisms and proposes a new
mechanism for protecting a web-server against a DDoS attack. In the proposed
mechanism, incoming traffic to the server is continuously monitored and any
abnormal rise in the inbound traffic is immediately detected. The detection
algorithm is based on a statistical analysis of the inbound traffic on the
server and a robust hypothesis testing framework. Simulations carried out on
the proposed mechanism have produced results that demonstrate effectiveness of
the proposed defense mechanism against DDoS attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3339</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3339</id><created>2011-03-17</created><authors><author><keyname>Nasiruzzaman</keyname><forenames>A. B. M.</forenames></author><author><keyname>Pota</keyname><forenames>H. R.</forenames></author></authors><title>Transient Stability Assessment of Smart Power System using Complex
  Networks Framework</title><categories>cs.OH cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new methodology for stability assessment of a smart power
system is proposed. The key to this assessment is an index called betweenness
index which is based on ideas from complex network theory. The proposed
betweenness index is an improvement of previous works since it considers the
actual real power flow through the transmission lines along the network.
Furthermore, this work initiates a new area for complex system research to
assess the stability of the power system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3340</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3340</id><created>2011-03-17</created><authors><author><keyname>Rebai</keyname><forenames>Ahmed Riadh</forenames></author><author><keyname>Hanafi</keyname><forenames>Said</forenames></author></authors><title>A Dynamic Multimedia User-Weight Classification Scheme for IEEE_802.11
  WLANs</title><categories>cs.NI</categories><comments>15 pages, 8 figures, 3 tables, International Journal of Computer
  Networks &amp; Communications (IJCNC)</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.3, No.2, March 2011</journal-ref><doi>10.5121/ijcnc.2011.3214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we expose a dynamic traffic-classification scheme to support
multimedia applications such as voice and broadband video transmissions over
IEEE 802.11 Wireless Local Area Networks (WLANs). Obviously, over a Wi-Fi link
and to better serve these applications - which normally have strict bounded
transmission delay or minimum link rate requirement - a service differentiation
technique can be applied to the media traffic transmitted by the same mobile
node using the well-known 802.11e Enhanced Distributed Channel Access (EDCA)
protocol. However, the given EDCA mode does not offer user differentiation,
which can be viewed as a deficiency in multi-access wireless networks.
Accordingly, we propose a new inter-node priority access scheme for IEEE
802.11e networks which is compatible with the EDCA scheme. The proposed scheme
joins a dynamic user-weight to each mobile station depending on its outgoing
data, and therefore deploys inter-node priority for the channel access to
complement the existing EDCA inter-frame priority. This provides efficient
quality of service control across multiple users within the same coverage area
of an access point. We provide performance evaluations to compare the proposed
access model with the basic EDCA 802.11 MAC protocol mode to elucidate the
quality improvement achieved for multimedia communication over 802.11 WLANs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3361</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3361</id><created>2011-03-17</created><authors><author><keyname>Zetzsche</keyname><forenames>Georg</forenames></author></authors><title>On the capabilities of grammars, automata, and transducers controlled by
  monoids</title><categories>cs.FL math.GR</categories><comments>13 pages, submitted</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  During the last decades, classical models in language theory have been
extended by control mechanisms defined by monoids. We study which monoids cause
the extensions of context-free grammars, finite automata, or finite state
transducers to exceed the capacity of the original model. Furthermore, we
investigate when, in the extended automata model, the nondeterministic variant
differs from the deterministic one in capacity. We show that all these
conditions are in fact equivalent and present an algebraic characterization. In
particular, the open question of whether every language generated by a valence
grammar over a finite monoid is context-free is provided with a positive
answer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3371</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3371</id><created>2011-03-17</created><authors><author><keyname>Amrahov</keyname><forenames>&#x15e;ahin Emrah</forenames></author><author><keyname>Gasilov</keyname><forenames>Nizami</forenames></author><author><keyname>Fatullayev</keyname><forenames>Afet Golayoglu</forenames></author></authors><title>Numerical solution of a fuzzy time-optimal control problem</title><categories>cs.NA cs.SY math.OC</categories><comments>11 pages, 3 figures</comments><msc-class>49N05, 65P99, 03E72</msc-class><acm-class>G.1.6; G.1.10; G.1.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a time-optimal control problem with uncertainties.
Dynamics of controlled object is expressed by crisp linear system of
differential equations with fuzzy initial and final states. We introduce a
notion of fuzzy optimal time and reduce its calculation to two crisp optimal
control problems. We examine the proposed approach on an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3372</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3372</id><created>2011-03-17</created><authors><author><keyname>Liu</keyname><forenames>Jiang</forenames></author><author><keyname>Zhan</keyname><forenames>Naijun</forenames></author><author><keyname>Zhao</keyname><forenames>Hengjun</forenames></author></authors><title>Automatically Discovering Relaxed Lyapunov Functions for Polynomial
  Dynamical Systems</title><categories>math.DS cs.SY math.OC</categories><comments>6 pages, one algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of Lyapunov function plays a key role in design and verification
of dynamical systems, as well as hybrid and cyber-physical systems. In this
paper, to analyze the asymptotic stability of a dynamical system, we generalize
standard Lyapunov functions to relaxed Lyapunov functions (RLFs), by
considering higher order Lie derivatives of certain functions along the
system's vector field. Furthermore, we present a complete method to
automatically discovering polynomial RLFs for polynomial dynamical systems
(PDSs). Our method is complete in the sense that it is able to discover all
polynomial RLFs by enumerating all polynomial templates for any PDS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3378</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3378</id><created>2011-03-17</created><authors><author><keyname>Manjula</keyname><forenames>V.</forenames></author><author><keyname>Chellappan</keyname><forenames>Dr. C.</forenames></author></authors><title>Replication Attack Mitigations for Static and Mobile WSN</title><categories>cs.CR cs.DC cs.NI</categories><comments>12 pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications (
  IJNSA ),March 2011, Volume 3. Number 2</journal-ref><doi>10.5121/ijnsa.2011.3210</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security is important for many sensor network applications. Wireless Sensor
Networks (WSN) are often deployed in hostile environments as static or mobile,
where an adversary can physically capture some of the nodes. once a node is
captured, adversary collects all the credentials like keys and identity etc.
the attacker can re-program it and replicate the node in order to eavesdrop the
transmitted messages or compromise the functionality of the network. Identity
theft leads to two types attack: clone and sybil. In particularly a harmful
attack against sensor networks where one or more node(s) illegitimately claims
an identity as replicas is known as the node replication attack. The
replication attack can be exceedingly injurious to many important functions of
the sensor network such as routing, resource allocation, misbehavior detection,
etc. This paper analyzes the threat posed by the replication attack and several
novel techniques to detect and defend against the replication attack, and
analyzes their effectiveness in both static and mobile WSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3381</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3381</id><created>2011-03-17</created><authors><author><keyname>Ahmadi</keyname><forenames>Omran</forenames></author><author><keyname>Granger</keyname><forenames>Robert</forenames></author></authors><title>On isogeny classes of Edwards curves over finite fields</title><categories>math.NT cs.CR</categories><comments>27 pages</comments><msc-class>14H52, 14K02, 14G17,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We count the number of isogeny classes of Edwards curves over finite fields,
answering a question recently posed by Rezaeian and Shparlinski. We also show
that each isogeny class contains a {\em complete} Edwards curve, and that an
Edwards curve is isogenous to an {\em original} Edwards curve over $\F_q$ if
and only if its group order is divisible by 8 if $q \equiv -1 \pmod{4}$, and 16
if $q \equiv 1 \pmod{4}$. Furthermore, we give formulae for the proportion of
$d \in \F_q \setminus \{0,1\}$ for which the Edwards curve $E_d$ is complete or
original, relative to the total number of $d$ in each isogeny class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3382</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3382</id><created>2011-03-17</created><authors><author><keyname>Mohammad</keyname><forenames>Abdulbaset H.</forenames></author></authors><title>A New Localized Network Based Routing Model in Computer and
  Communication networks</title><categories>cs.NI</categories><comments>18 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In view of the fact that routing algorithms are network layer entities and
the varying performance of any routing algorithm depends on the underlying
networks. Localized routing algorithms avoid the problems associated with the
maintenance of global network state by using statistics of flow blocking
probabilities. We developed a new network parameter that can be used to predict
which network topology gives better performance on the quality of localized QoS
routing algorithms. Using this parameter we explore a simple model that can be
rewired to introduce increasing the performance. We find that this model have
small characteristic path length. Simulations of random and complex networks
used to show that the performance is significantly affected by the level of
connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3390</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3390</id><created>2011-03-17</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author><author><keyname>Pugliese</keyname><forenames>Paolo</forenames></author><author><keyname>Famularo</keyname><forenames>Domenico</forenames></author></authors><title>Index Information Algorithm with Local Tuning for Solving
  Multidimensional Global Optimization Problems with Multiextremal Constraints</title><categories>math.OC cs.NA math.NA physics.comp-ph</categories><comments>29 pages, 5 figures</comments><msc-class>65K05, 90C26</msc-class><journal-ref>Mathematical Programming, Ser. A, 96 (2003) 489-512</journal-ref><doi>10.1007/s10107-003-0372-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional optimization problems where the objective function and the
constraints are multiextremal non-differentiable Lipschitz functions (with
unknown Lipschitz constants) and the feasible region is a finite collection of
robust nonconvex subregions are considered. Both the objective function and the
constraints may be partially defined. To solve such problems an algorithm is
proposed, that uses Peano space-filling curves and the index scheme to reduce
the original problem to a H\&quot;{o}lder one-dimensional one. Local tuning on the
behaviour of the objective function and constraints is used during the work of
the global optimization procedure in order to accelerate the search. The method
neither uses penalty coefficients nor additional variables. Convergence
conditions are established. Numerical experiments confirm the good performance
of the technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3391</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3391</id><created>2011-03-17</created><authors><author><keyname>Burke</keyname><forenames>Edmund K.</forenames></author><author><keyname>Leite-Rocha</keyname><forenames>Pedro</forenames></author><author><keyname>Petrovic</keyname><forenames>Sanja</forenames></author></authors><title>An Integer Linear Programming Model for the Radiotherapy Treatment
  Scheduling Problem</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radiotherapy represents an important phase of treatment for a large number of
cancer patients. It is essential that resources used to deliver this treatment
are employed effectively. This paper presents a new integer linear programming
model for real-world radiotherapy treatment scheduling and analyses the
effectiveness of using this model on a daily basis in a hospital. Experiments
are conducted varying the days on which schedules can be created. Results
obtained using real-world data from the Nottingham University Hospitals NHS
Trust, UK, are presented and show how the proposed model can be used with
different policies in order to achieve good quality schedules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3397</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3397</id><created>2011-03-17</created><updated>2011-08-25</updated><authors><author><keyname>Tib&#xe9;ly</keyname><forenames>Gergely</forenames></author></authors><title>Criterions for locally dense subgraphs</title><categories>physics.soc-ph cs.SI physics.comp-ph</categories><comments>Revised version. 26 pages, 8 figures, 1 table</comments><doi>10.1016/j.physa.2011.09.040</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection is one of the most investigated problems in the field of
complex networks. Although several methods were proposed, there is still no
precise definition of communities. As a step towards a definition, I highlight
two necessary properties of communities, separation and internal cohesion, the
latter being a new concept. I propose a local method of community detection
based on two-dimensional local optimization, which I tested on common
benchmarks and on the word association database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3417</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3417</id><created>2011-03-17</created><authors><author><keyname>Farhan</keyname><forenames>Hazim A.</forenames></author><author><keyname>Owaied</keyname><forenames>Hussein H.</forenames></author><author><keyname>Al-Ghazi</keyname><forenames>Suhaib I.</forenames></author></authors><title>Finding Shortest Path for Developed Cognitive Map Using Medial Axis</title><categories>cs.AI</categories><comments>9 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT), ISSN: 2221-0741, Vol. 1, No. 2, 17-25, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  this paper presents an enhancement of the medial axis algorithm to be used
for finding the optimal shortest path for developed cognitive map. The
cognitive map has been developed, based on the architectural blueprint maps.
The idea for using the medial-axis is to find main path central pixels; each
center pixel represents the center distance between two side boarder pixels.
The need for these pixels in the algorithm comes from the need of building a
network of nodes for the path, where each node represents a turning in the real
world (left, right, critical left, critical right...). The algorithm also
ignores from finding the center pixels paths that are too small for intelligent
robot navigation. The Idea of this algorithm is to find the possible shortest
path between start and end points. The goal of this research is to extract a
simple, robust representation of the shape of the cognitive map together with
the optimal shortest path between start and end points. The intelligent robot
will use this algorithm in order to decrease the time that is needed for
sweeping the targeted building.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3420</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3420</id><created>2011-03-17</created><authors><author><keyname>Haboubi</keyname><forenames>Sofiene</forenames></author><author><keyname>Maddouri</keyname><forenames>Samia</forenames></author></authors><title>Extraction of handwritten areas from colored image of bank checks by an
  hybrid method</title><categories>cs.AI</categories><comments>International Conference on Machine Intelligence (ACIDCA-ICIM),
  Tozeur, Tunisia, November 2005</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  One of the first step in the realization of an automatic system of check
recognition is the extraction of the handwritten area. We propose in this paper
an hybrid method to extract these areas. This method is based on digit
recognition by Fourier descriptors and different steps of colored image
processing . It requires the bank recognition of its code which is located in
the check marking band as well as the handwritten color recognition by the
method of difference of histograms. The areas extraction is then carried out by
the use of some mathematical morphology tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3430</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3430</id><created>2011-03-17</created><authors><author><keyname>Haboubi</keyname><forenames>Sofiene</forenames></author><author><keyname>Maddouri</keyname><forenames>Samia</forenames></author><author><keyname>Amiri</keyname><forenames>Hamid</forenames></author></authors><title>Identification of arabic word from bilingual text using character
  features</title><categories>cs.AI cs.CV</categories><comments>FAHR 2010 - the 1st International Workshop on Frontiers in Arabic
  Handwriting Recognition</comments><journal-ref>International Workshop on Frontiers in Arabic Handwriting
  Recognition (2010) 50-54</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The identification of the language of the script is an important stage in the
process of recognition of the writing. There are several works in this research
area, which treat various languages. Most of the used methods are global or
statistical. In this present paper, we study the possibility of using the
features of scripts to identify the language. The identification of the
language of the script by characteristics returns the identification in the
case of multilingual documents less difficult. We present by this work, a study
on the possibility of using the structural features to identify the Arabic
language from an Arabic / Latin text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3440</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3440</id><created>2011-03-17</created><authors><author><keyname>Shirdhonkar</keyname><forenames>M. S.</forenames></author><author><keyname>Kokare</keyname><forenames>Manesh</forenames></author></authors><title>Off-Line Handwritten Signature Identification Using Rotated Complex
  Wavelet Filters</title><categories>cs.CV</categories><comments>5 pages</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 1, January 2011 ISSN (Online): 1694-0814</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, a new method for handwritten signature identification based on
rotated complex wavelet filters is proposed. We have proposed to use the
rotated complex wavelet filters (RCWF) and dual tree complex wavelet
transform(DTCWT) together to derive signature feature extraction, which
captures information in twelve different directions. In identification phase,
Canberra distance measure is used. The proposed method is compared with
discrete wavelet transform (DWT). From experimental results it is found that
signature identification rate of proposed method is superior over DWT
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3457</identifier>
 <datestamp>2011-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3457</id><created>2011-03-17</created><authors><author><keyname>Ormerod</keyname><forenames>Paul</forenames></author><author><keyname>Evans</keyname><forenames>Ellie</forenames></author></authors><title>Ex ante prediction of cascade sizes on networks of agents facing binary
  outcomes</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in this paper the potential for ex ante prediction of the cascade
size in a model of binary choice with externalities (Schelling 1973, Watts
2002). Agents are connected on a network and can be in one of two states of the
world, 0 or 1. Initially, all are in state 0 and a small number of seeds are
selected at random to switch to state1. A simple threshold rule specifies
whether other agents switch subsequently. The cascade size (the percolation) is
the proportion of all agents which eventually switches to state 1. We select
information on the connectivity of the initial seeds, the connectivity of the
agents to which they are connected, the thresholds of these latter agents, and
the thresholds of the agents to which these are connected. We obtain results
for random, small world and scale -free networks with different network
parameters and numbers of initial seeds. The results are robust with respect to
these factors. We perform least squares regression of the logit transformation
of the cascade size (Hosmer and Lemeshow 1989) on these potential explanatory
variables. We find considerable explanatory power for the ex ante prediction of
cascade sizes. For the random networks, on average 32 per cent of the variance
of the cascade sizes is explained, 40 per cent for the small world and 46 per
cent for the scale-free. The connectivity variables are hardly ever significant
in the regressions, whether relating to the seeds themselves or to the agents
connected to the seeds. In contrast, the information on the thresholds of
agents contains much more explanatory power. This supports the conjecture of
Watts and Dodds (2007.) that large cascades are driven by a small mass of
easily influenced agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3478</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3478</id><created>2011-03-17</created><authors><author><keyname>Pirandola</keyname><forenames>Stefano</forenames></author></authors><title>Quantum Reading of a Classical Digital Memory</title><categories>quant-ph cond-mat.other cs.ET physics.optics</categories><comments>PRL selected by the APS editors for a synopsis in &quot;Physics&quot;. This
  document is the published Letter only. See arXiv:0907.3398 for a longer
  document which includes both the Letter (4 pages) and the Supplemental
  Material (21 pages)</comments><journal-ref>Phys. Rev. Lett. 106, 090504 (2011)</journal-ref><doi>10.1103/PhysRevLett.106.090504</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a basic model of digital memory where each cell is composed of a
reflecting medium with two possible reflectivities. By fixing the mean number
of photons irradiated over each memory cell, we show that a non-classical
source of light can retrieve more information than any classical source. This
improvement is shown in the regime of few photons and high reflectivities,
where the gain of information can be surprising. As a result, the use of
quantum light can have non-trivial applications in the technology of digital
memories, such as optical disks and barcodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3510</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3510</id><created>2011-03-17</created><authors><author><keyname>Somaraju</keyname><forenames>Ram</forenames></author><author><keyname>Trumpf</keyname><forenames>Jochen</forenames></author></authors><title>Degrees of Freedom of a Communication Channel and Kolmogorov numbers</title><categories>cs.IT math.FA math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we show that the operator theoretic concept of Kolmogorov
numbers and the number of degrees of freedom at level $\epsilon$ of a
communication channel are closely related. Linear communication channels may be
modeled using linear compact operators on Banach or Hilbert spaces and the
number of degrees of freedom of such channels is defined to be the number of
linearly independent signals that may be communicated over this channel, where
the channel is restricted by a threshold noise level. Kolmogorov numbers are a
particular example of $s$-numbers, which are defined over the class of bounded
operators between Banach spaces. We demonstrate that these two concepts are
closely related, namely that the Kolmogorov numbers correspond to the &quot;jump
points&quot; in the function relating numbers of degrees of freedom with the noise
level $\epsilon$. We also establish a useful numerical computation result for
evaluating Kolmogorov numbers of compact operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3515</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3515</id><created>2011-03-17</created><authors><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Masuzawa</keyname><forenames>Toshimitsu</forenames><affiliation>Department of Information and Computer sciences Osaka University</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Self-Stabilization, Byzantine Containment, and Maximizable Metrics:
  Necessary Conditions</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-stabilization is a versatile approach to fault-tolerance since it
permits a distributed system to recover from any transient fault that
arbitrarily corrupts the contents of all memories in the system. Byzantine
tolerance is an attractive feature of distributed systems that permits to cope
with arbitrary malicious behaviors. We consider the well known problem of
constructing a maximum metric tree in this context. Combining these two
properties leads to some impossibility results. In this paper, we provide two
necessary conditions to construct maximum metric tree in presence of transients
and (permanent) Byzantine faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3532</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3532</id><created>2011-03-17</created><authors><author><keyname>Chaari</keyname><forenames>Lotfi</forenames></author><author><keyname>M&#xe9;riaux</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Badillo</keyname><forenames>Solveig</forenames></author><author><keyname>Pesquet</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Ciuciu</keyname><forenames>Philippe</forenames></author></authors><title>4D Wavelet-Based Regularization for Parallel MRI Reconstruction: Impact
  on Subject and Group-Levels Statistical Sensitivity in fMRI</title><categories>stat.ME cs.CV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel MRI is a fast imaging technique that enables the acquisition of
highly resolved images in space. It relies on $k$-space undersampling and
multiple receiver coils with complementary sensitivity profiles in order to
reconstruct a full Field-Of-View (FOV) image. The performance of parallel
imaging mainly depends on the reconstruction algorithm, which can proceed
either in the original $k$-space (GRAPPA, SMASH) or in the image domain
(SENSE-like methods). To improve the performance of the widely used SENSE
algorithm, 2D- or slice-specific regularization in the wavelet domain has been
efficiently investigated. In this paper, we extend this approach using
3D-wavelet representations in order to handle all slices together and address
reconstruction artifacts which propagate across adjacent slices. The extension
also accounts for temporal correlations that exist between successive scans in
functional MRI (fMRI). The proposed 4D reconstruction scheme is fully
\emph{unsupervised} in the sense that all regularization parameters are
estimated in the maximum likelihood sense on a reference scan. The gain induced
by such extensions is first illustrated on EPI image reconstruction but also
measured in terms of statistical sensitivity during a fast event-related fMRI
protocol. The proposed 4D-UWR-SENSE algorithm outperforms the SENSE
reconstruction at the subject and group-levels (15 subjects) for different
contrasts of interest and using different parallel acceleration factors on
$2\times2\times3$mm$^3$ EPI images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3541</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3541</id><created>2011-03-17</created><updated>2011-11-16</updated><authors><author><keyname>Mertikopoulos</keyname><forenames>Panayotis</forenames></author><author><keyname>Belmega</keyname><forenames>Elena V.</forenames></author><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author></authors><title>Distributed Learning Policies for Power Allocation in Multiple Access
  Channels</title><categories>cs.GT cs.LG cs.NI</categories><comments>11 pages, 8 figures. Revised manuscript structure and added more
  material and figures for the case of stochastically fluctuating channels.
  This version will appear in the IEEE Journal on Selected Areas in
  Communication, Special Issue on Game Theory in Wireless Communications</comments><journal-ref>IEEE Journal on Selected Areas in Communication, vol. 30, no. 1,
  pp. 1-11, January 2012</journal-ref><doi>10.1109/JSAC.2012.1201xx</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the problem of distributed power allocation for orthogonal
multiple access channels by considering a continuous non-cooperative game whose
strategy space represents the users' distribution of transmission power over
the network's channels. When the channels are static, we find that this game
admits an exact potential function and this allows us to show that it has a
unique equilibrium almost surely. Furthermore, using the game's potential
property, we derive a modified version of the replicator dynamics of
evolutionary game theory which applies to this continuous game, and we show
that if the network's users employ a distributed learning scheme based on these
dynamics, then they converge to equilibrium exponentially quickly. On the other
hand, a major challenge occurs if the channels do not remain static but
fluctuate stochastically over time, following a stationary ergodic process. In
that case, the associated ergodic game still admits a unique equilibrium, but
the learning analysis becomes much more complicated because the replicator
dynamics are no longer deterministic. Nonetheless, by employing results from
the theory of stochastic approximation, we show that users still converge to
the game's unique equilibrium.
  Our analysis hinges on a game-theoretical result which is of independent
interest: in finite player games which admit a (possibly nonlinear) convex
potential function, the replicator dynamics (suitably modified to account for
nonlinear payoffs) converge to an eps-neighborhood of an equilibrium at time of
order O(log(1/eps)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3569</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3569</id><created>2011-03-18</created><authors><author><keyname>Wang</keyname><forenames>Deqing</forenames></author><author><keyname>Lin</keyname><forenames>Mengxiang</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author><author><keyname>Hu</keyname><forenames>Hongping</forenames></author></authors><title>Detect Related Bugs from Source Code Using Bug Information</title><categories>cs.SE</categories><comments>10 pages, 5 figures, 4 tables conference; 2010 IEEE 34th Annual
  Computer Software and Applications Conference</comments><doi>10.1109/COMPSAC.2010.27</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Open source projects often maintain open bug repositories during development
and maintenance, and the reporters often point out straightly or implicitly the
reasons why bugs occur when they submit them. The comments about a bug are very
valuable for developers to locate and fix the bug. Meanwhile, it is very common
in large software for programmers to override or overload some methods
according to the same logic. If one method causes a bug, it is obvious that
other overridden or overloaded methods maybe cause related or similar bugs. In
this paper, we propose and implement a tool Rebug- Detector, which detects
related bugs using bug information and code features. Firstly, it extracts bug
features from bug information in bug repositories; secondly, it locates bug
methods from source code, and then extracts code features of bug methods;
thirdly, it calculates similarities between each overridden or overloaded
method and bug methods; lastly, it determines which method maybe causes
potential related or similar bugs. We evaluate Rebug-Detector on an open source
project: Apache Lucene-Java. Our tool totally detects 61 related bugs,
including 21 real bugs and 10 suspected bugs, and it costs us about 15.5
minutes. The results show that bug features and code features extracted by our
tool are useful to find real bugs in existing projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3580</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3580</id><created>2011-03-18</created><authors><author><keyname>Borissov</keyname><forenames>Yuri L.</forenames></author></authors><title>On a Connection between Ideal Two-level Autocorrelation and Almost
  Balancedness of $p$-ary Sequences</title><categories>cs.IT math.IT</categories><comments>6 pages, submitted to Comptes rendus de l'Academie Bulgare des
  Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, for every periodic $p-$ary sequence satisfying ideal
two-level autocorrelation property the existence of an element of the field
${\bf GF}(p)$ which appears one time less than all the rest that are equally
distributed in a period of that sequence, is proved by algebraic method. In
addition, it is shown that such a special element might not be only the zero
element but as well arbitrary element of that field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3585</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3585</id><created>2011-03-18</created><authors><author><keyname>Sandin</keyname><forenames>Fredrik</forenames></author><author><keyname>Emruli</keyname><forenames>Blerim</forenames></author><author><keyname>Sahlgren</keyname><forenames>Magnus</forenames></author></authors><title>Incremental dimension reduction of tensors with random index</title><categories>cs.DS cs.CL cs.IR</categories><comments>36 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an incremental, scalable and efficient dimension reduction
technique for tensors that is based on sparse random linear coding. Data is
stored in a compactified representation with fixed size, which makes memory
requirements low and predictable. Component encoding and decoding are performed
on-line without computationally expensive re-analysis of the data set. The
range of tensor indices can be extended dynamically without modifying the
component representation. This idea originates from a mathematical model of
semantic memory and a method known as random indexing in natural language
processing. We generalize the random-indexing algorithm to tensors and present
signal-to-noise-ratio simulations for representations of vectors and matrices.
We present also a mathematical analysis of the approximate orthogonality of
high-dimensional ternary vectors, which is a property that underpins this and
other similar random-coding approaches to dimension reduction. To further
demonstrate the properties of random indexing we present results of a synonym
identification task. The method presented here has some similarities with
random projection and Tucker decomposition, but it performs well at high
dimensionality only (n&gt;10^3). Random indexing is useful for a range of complex
practical problems, e.g., in natural language processing, data mining, pattern
recognition, event detection, graph searching and search engines. Prototype
software is provided. It supports encoding and decoding of tensors of order &gt;=
1 in a unified framework, i.e., vectors, matrices and higher order tensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3596</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3596</id><created>2011-03-18</created><updated>2011-05-28</updated><authors><author><keyname>Gohari</keyname><forenames>Amin Aminzadeh</forenames></author><author><keyname>Yang</keyname><forenames>Shenghao</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author></authors><title>Beyond the Cut-Set Bound: Uncertainty Computations in Network Coding
  with Correlated Sources</title><categories>cs.IT math.IT</categories><comments>12 pages, A short version appears in ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cut-set bounds on achievable rates for network communication protocols are
not in general tight. In this paper we introduce a new technique for proving
converses for the problem of transmission of correlated sources in networks,
that results in bounds that are tighter than the corresponding cut-set bounds.
We also define the concept of &quot;uncertainty region&quot; which might be of
independent interest. We provide a full characterization of this region for the
case of two correlated random variables. The bounding technique works as
follows: on one hand we show that if the communication problem is solvable, the
uncertainty of certain random variables in the network with respect to
imaginary parties that have partial knowledge of the sources must satisfy some
constraints that depend on the network architecture. On the other hand, the
same uncertainties have to satisfy constraints that only depend on the joint
distribution of the sources. Matching these two leads to restrictions on the
statistical joint distribution of the sources in communication problems that
are solvable over a given network architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3616</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3616</id><created>2011-03-18</created><updated>2011-03-22</updated><authors><author><keyname>Aydin</keyname><forenames>Nursen</forenames></author><author><keyname>Karaca</keyname><forenames>Mehmet</forenames></author><author><keyname>Ercetin</keyname><forenames>Ozgur</forenames></author></authors><title>Energy-Optimal Scheduling in Low Duty Cycle Sensor Networks</title><categories>cs.NI cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy consumption of a wireless sensor node mainly depends on the amount of
time the node spends in each of the high power active (e.g., transmit, receive)
and low power sleep modes. It has been well established that in order to
prolong node's lifetime the duty-cycle of the node should be low. However, low
power sleep modes usually have low current draw but high energy cost while
switching to the active mode with a higher current draw. In this work, we
investigate a MaxWeightlike opportunistic sleep-active scheduling algorithm
that takes into account time- varying channel and traffic conditions. We show
that our algorithm is energy optimal in the sense that the proposed ESS
algorithm can achieve an energy consumption which is arbitrarily close to the
global minimum solution. Simulation studies are provided to confirm the
theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3624</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3624</id><created>2011-03-16</created><updated>2014-07-08</updated><authors><author><keyname>Borg</keyname><forenames>Frank</forenames></author></authors><title>Analyzing biosignals using the R freeware (open source) tool</title><categories>physics.data-an cs.CE physics.bio-ph</categories><comments>18 pages and supplementary material. Added two new subsections. An
  error corrected in supplementary file EMGfuns.R</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For researchers in electromyography (EMG), and similar biosginals, signal
processing is naturally an essential topic. There are a number of excellent
tools available. To these one may add the freely available open source
statistical software package R, which is in fact also a programming language.
It is becoming one the standard tools for scientists to visualize and process
data. A large number of additional packages are continually contributed by an
active community. The purpose of this paper is to alert biomechanics
researchers to the usefulness of this versatile tool. We discuss a set of basic
signal processing methods and their realizations with R which are provided in
the supplementary material. The data used in the examples are EMG and force
plate data acquired during a quiet standing test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3641</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3641</id><created>2011-03-18</created><updated>2012-03-06</updated><authors><author><keyname>Zumbr&#xe4;gel</keyname><forenames>Jens</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>On the Pseudocodeword Redundancy of Binary Linear Codes</title><categories>cs.IT math.IT</categories><comments>14 pages. arXiv admin note: substantial text overlap with
  arXiv:1005.3486</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The AWGNC, BSC, and max-fractional pseudocodeword redundancies of a binary
linear code are defined to be the smallest number of rows in a parity-check
matrix such that the corresponding minimum pseudoweight is equal to the minimum
Hamming distance of the code. It is shown that most codes do not have a finite
pseudocodeword redundancy. Also, upper bounds on the pseudocodeword redundancy
for some families of codes, including codes based on designs, are provided. The
pseudocodeword redundancies for all codes of small length (at most 9) are
computed. Furthermore, comprehensive results are provided on the cases of
cyclic codes of length at most 250 for which the eigenvalue bound of Vontobel
and Koetter is sharp.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3648</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3648</id><created>2011-03-18</created><updated>2011-05-13</updated><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>Tijssen</keyname><forenames>Robert J. W.</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author></authors><title>Globalisation of science in kilometres</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ongoing globalisation of science has undisputedly a major impact on how
and where scientific research is being conducted nowadays. Yet, the big picture
remains blurred. It is largely unknown where this process is heading, and at
which rate. Which countries are leading or lagging? Many of its key features
are difficult if not impossible to capture in measurements and comparative
statistics. Our empirical study measures the extent and growth of scientific
globalisation in terms of physical distances between co-authoring researchers.
Our analysis, drawing on 21 million research publications across all countries
and fields of science, reveals that contemporary science has globalised at a
fairly steady rate during recent decades. The average collaboration distance
per publication has increased from 334 kilometres in 1980 to 1553 in 2009.
Despite significant differences in globalisation rates across countries and
fields of science, we observe a pervasive process in motion, moving towards a
truly interconnected global science system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3656</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3656</id><created>2011-03-18</created><authors><author><keyname>Neuhaus</keyname><forenames>T.</forenames></author><author><keyname>Peschina</keyname><forenames>M.</forenames></author><author><keyname>Michielsen</keyname><forenames>K.</forenames></author><author><keyname>De Raedt</keyname><forenames>H.</forenames></author></authors><title>Classical and Quantum Annealing in the Median of Three Satisfiability</title><categories>cond-mat.stat-mech cs.CC quant-ph</categories><journal-ref>Phys. Rev. A 83, 012309 (2011)</journal-ref><doi>10.1103/PhysRevA.83.012309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the classical and quantum complexities of a specific ensemble of
three-satisfiability problems with a unique satisfying assignment for up to
N=100 and N=80 variables, respectively. In the classical limit we employ
generalized ensemble techniques and measure the time that a Markovian Monte
Carlo process spends in searching classical ground states. In the quantum limit
we determine the maximum finite correlation length along a quantum adiabatic
trajectory determined by the linear sweep of the adiabatic control parameter in
the Hamiltonian composed of the problem Hamiltonian and the constant transverse
field Hamiltonian. In the median of our ensemble both complexities diverge
exponentially with the number of variables. Hence, standard, conventional
adiabatic quantum computation fails to reduce the computational complexity to
polynomial. Moreover, the growth-rate constant in the quantum limit is 3.8
times as large as the one in the classical limit, making classical fluctuations
more beneficial than quantum fluctuations in ground-state searches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3665</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3665</id><created>2011-03-18</created><authors><author><keyname>Kvasov</keyname><forenames>Dmitri E.</forenames></author><author><keyname>Pizzuti</keyname><forenames>Clara</forenames></author><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author></authors><title>Local tuning and partition strategies for diagonal GO methods</title><categories>math.OC cs.NA math.NA physics.comp-ph</categories><comments>15 pages, 4 figures</comments><msc-class>65K05, 90C30</msc-class><journal-ref>Numerische Mathematik, 94(1), (2003) 93-106</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, global optimization (GO) Lipschitz problems are considered
where the multi-dimensional multiextremal objective function is determined over
a hyperinterval. An efficient one-dimensional GO method using local tuning on
the behavior of the objective function is generalized to the multi-dimensional
case by the diagonal approach using two partition strategies. Global
convergence conditions are established for the obtained diagonal geometric
methods. Results of a wide numerical comparison show a strong acceleration
reached by the new methods working with estimates of the local Lipschitz
constants over different subregions of the search domain in comparison with the
traditional approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3671</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3671</id><created>2011-03-18</created><updated>2011-03-20</updated><authors><author><keyname>Biely</keyname><forenames>Martin</forenames></author><author><keyname>Robinson</keyname><forenames>Peter</forenames></author><author><keyname>Schmid</keyname><forenames>Ulrich</forenames></author></authors><title>Easy Impossibility Proofs for k-Set Agreement in Message Passing Systems</title><categories>cs.DC</categories><comments>15 pages</comments><report-no>Research Report 2/2011, Technische Universitaet Wien</report-no><acm-class>C.2.4; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite of being quite similar agreement problems, consensus and general
k-set agreement require surprisingly different techniques for proving the
impossibility in asynchronous systems with crash failures: Rather than
relatively simple bivalence arguments as in the impossibility proof for
consensus (= 1-set agreement) in the presence of a single crash failure, known
proofs for the impossibility of k-set agreement in systems with at least k&gt;1
crash failures use algebraic topology or a variant of Sperner's Lemma. In this
paper, we present a generic theorem for proving the impossibility of k-set
agreement in various message passing settings, which is based on a simple
reduction to the consensus impossibility in a certain subsystem. We demonstrate
the broad applicability of our result by exploring the
possibility/impossibility border of k-set agreement in several message-passing
system models: (i) asynchronous systems with crash failures, (ii) partially
synchronous processes with (initial) crash failures, and (iii) asynchronous
systems augmented with failure detectors. In (i) and (ii), the impossibility
part is just an instantiation of our main theorem, whereas the possibility of
achieving k-set agreement in (ii) follows by generalizing the consensus
algorithm for initial crashes by Fisher, Lynch and Patterson. In (iii),
applying our technique yields the exact border for the parameter k where k-set
agreement is solvable with the failure detector class (Sigma_k,Omega_k), for
(1&lt;= k&lt;= n-1), of Bonnet and Raynal. Considering that Sigma_k was shown to be
necessary for solving k-set agreement, this result yields new insights on the
quest for the weakest failure detector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3673</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3673</id><created>2011-03-18</created><authors><author><keyname>Ikhlef</keyname><forenames>Aissa</forenames></author><author><keyname>Michalopoulos</keyname><forenames>Diomidis S.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Buffers Improve the Performance of Relay Selection</title><categories>cs.IT math.IT</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the performance of relay selection can be improved by employing
relays with buffers. Under the idealized assumption that no buffer is full or
empty, the best source-relay and the best relay-destination channels can be
simultaneously exploited by selecting the corresponding relays for reception
and transmission, respectively. The resulting relay selection scheme is
referred to as max-max relay selection (MMRS). Since for finite buffer sizes,
empty and full buffers are practically unavoidable if MMRS is employed, we
propose a hybrid relay selection (HRS) scheme, which is a combination of
conventional best relay selection (BRS) and MMRS. We analyze the outage
probabilities of MMRS and HRS and show that both schemes achieve the same
diversity gain as conventional BRS and a superior coding gain. Furthermore, our
results show that for moderate buffer sizes (e.g. 30 packets) HRS closely
approaches the performance of idealized MMRS and the performance gain compared
to BRS approaches 3 dB as the number of relays increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3686</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3686</id><created>2011-03-18</created><updated>2011-06-21</updated><authors><author><keyname>Espa&#xf1;a</keyname><forenames>Sergio</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Arturo</forenames></author><author><keyname>Pastor</keyname><forenames>&#xd3;scar</forenames></author><author><keyname>Ruiz</keyname><forenames>Marcela</forenames></author></authors><title>Integration of Communication Analysis and the OO-Method: Rules for the
  manual derivation of the Conceptual Model</title><categories>cs.SE</categories><comments>38 pages, 25 figures</comments><report-no>ProS-TR-2011-10</report-no><msc-class>68N01</msc-class><acm-class>D.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enterprise information systems can be developed following a model-driven
paradigm. This way, models that represent the organisational work practice are
used to produce models that represent the information system. Current software
development methods are starting to provide guidelines for the construction of
conceptual models, taking as input requirements models. This paper proposes the
integration of two methods: Communication Analysis (a communication-oriented
requirements engineering method [Espa\~na, Gonz\'alez et al. 2009]) and the
OO-Method (a model-driven object-oriented software development method [Pastor
and Molina 2007]). For this purpose, a systematic technique for deriving
OO-Method Conceptual Models from business process and requirements models is
proposed. The business process specifications (which include message
structures) are processed in order to obtain static and dynamic views of the
computerised information system. Then, using the OLIVANOVA framework, software
source code can be generated automatically [CARE Technologies].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3687</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3687</id><created>2011-03-18</created><authors><author><keyname>Cushing</keyname><forenames>William</forenames></author><author><keyname>Benton</keyname><forenames>J.</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author></authors><title>Cost Based Satisficing Search Considered Harmful</title><categories>cs.AI</categories><comments>Longer version of an extended abstract from SOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, several researchers have found that cost-based satisficing search
with A* often runs into problems. Although some &quot;work arounds&quot; have been
proposed to ameliorate the problem, there has not been any concerted effort to
pinpoint its origin. In this paper, we argue that the origins can be traced
back to the wide variance in action costs that is observed in most planning
domains. We show that such cost variance misleads A* search, and that this is
no trifling detail or accidental phenomenon, but a systemic weakness of the
very concept of &quot;cost-based evaluation functions + systematic search +
combinatorial graphs&quot;. We show that satisficing search with sized-based
evaluation functions is largely immune to this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3693</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3693</id><created>2011-03-18</created><authors><author><keyname>Kullmann</keyname><forenames>Oliver</forenames></author></authors><title>Constraint satisfaction problems in clausal form</title><categories>cs.DM math.CO</categories><comments>91 pages, to appear in Fundamenta Informaticae, 2011, as Constraint
  satisfaction problems in clausal form I: Autarkies and deficiency, Constraint
  satisfaction problems in clausal form II: Minimal unsatisfiability and
  conflict structure</comments><msc-class>68R05</msc-class><acm-class>F.2.2</acm-class><journal-ref>Fundamenta Informaticae, 2011, 109(1): pages 27-81, 83-119</journal-ref><doi>10.3233/FI-2011-428; 10.3233/FI-2011-429</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the report-version of a mini-series of two articles on the
foundations of satisfiability of conjunctive normal forms with non-boolean
variables, to appear in Fundamenta Informaticae, 2011. These two parts are here
bundled in one report, each part yielding a chapter.
  Generalised conjunctive normal forms are considered, allowing literals of the
form &quot;variable not-equal value&quot;. The first part sets the foundations for the
theory of autarkies, with emphasise on matching autarkies. Main results concern
various polynomial time results in dependency on the deficiency. The second
part considers translations to boolean clause-sets and irredundancy as well as
minimal unsatisfiability. Main results concern classification of minimally
unsatisfiable clause-sets and the relations to the hermitian rank of graphs.
Both parts contain also discussions of many open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3698</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3698</id><created>2011-03-21</created><updated>2011-12-23</updated><authors><author><keyname>Orieux</keyname><forenames>F.</forenames></author><author><keyname>Giovannelli</keyname><forenames>J. -F.</forenames></author><author><keyname>Rodet</keyname><forenames>T.</forenames></author><author><keyname>Abergel</keyname><forenames>A.</forenames></author><author><keyname>Ayasso</keyname><forenames>H.</forenames></author><author><keyname>Husson</keyname><forenames>M.</forenames></author></authors><title>Super-resolution in map-making based on a physical instrument model and
  regularized inversion. Application to SPIRE/Herschel</title><categories>astro-ph.CO astro-ph.IM cs.CE</categories><comments>Astronomy &amp; Astrophysics</comments><doi>10.1051/0004-6361/201116817</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate super-resolution methods for image reconstruction from data
provided by a family of scanning instruments like the Herschel observatory. To
do this, we constructed a model of the instrument that faithfully reflects the
physical reality, accurately taking the acquisition process into account to
explain the data in a reliable manner. The inversion, ie the image
reconstruction process, is based on a linear approach resulting from a
quadratic regularized criterion and numerical optimization tools. The
application concerns the reconstruction of maps for the SPIRE instrument of the
Herschel observatory. The numerical evaluation uses simulated and real data to
compare the standard tool (coaddition) and the proposed method. The inversion
approach is capable to restore spatial frequencies over a bandwidth four times
that possible with coaddition and thus to correctly show details invisible on
standard maps. The approach is also applied to real data with significant
improvement in spatial resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3719</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3719</id><created>2011-03-18</created><authors><author><keyname>Lee</keyname><forenames>Chung-Pi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Diversity-Multiplexing Tradeoff in the Multiaccess Relay Channel with
  Finite Block Length</title><categories>cs.IT math.IT</categories><comments>28 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dynamic Decode-and-Forward (DDF) protocol and the Hybrid DDF and
Amplified-and-Forward (HDAF) protocol for the multiple-access relay channel
(MARC) with quasi static fading are evaluated using the Zheng-Tse
diversity-multiplexing tradeoff (DMT). We assume that there are two users, one
half-duplex relay, and a common destination, each equipped with single antenna.
For the Rayleigh fading, the DDF protocol is well known and has been analyzed
in terms of the DMT with infinite block length. By carefully dealing with
properties specific to finite block length, we characterize the finite block
length DMT which takes into account the fact that the event of decoding error
at the relay causes the degradation in error performance when the block length
is finite. Furthermore, we consider the situation where the destination does
not have a priori knowledge of the relay decision time at which the relay
switches from listening to transmitting. By introducing a decision rejection
criterion such that the relay forwards message only when its decision is
reliable, and the generalized likelihood ratio test (GLRT) at the destination
that jointly decodes the relay decision time and the information message, our
analysis show that the optimal DMT is achievable as if there is no decoding
error at the relay and the relay decision time is known at the destination.
Therefore, infinite block length and additional overhead for communicating the
decision time are not needed for the DDF to achieve the optimal DMT. To further
improve the DMT, we propose the HDAF protocol which take advantages of both the
DDF and the Amplified-and-Forward protocols by judiciously choosing which
protocol to use. Our result shows that the HDAF protocol outperforms the
original DDF in the DMT perspective. Finally, a variant of the HDAF protocol
with lower implementation complexity without sacrificing the DMT performance is
devised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3721</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3721</id><created>2011-03-18</created><authors><author><keyname>Wu</keyname><forenames>Xin</forenames></author><author><keyname>Jaekel</keyname><forenames>Arunita</forenames></author><author><keyname>Bari</keyname><forenames>Ataul</forenames></author></authors><title>Optimal channel allocation with dynamic power control in cellular
  networks</title><categories>cs.NI</categories><comments>11 pages</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.3, No.2, March 2011</journal-ref><doi>10.5121/ijcnc.2011.3206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Techniques for channel allocation in cellular networks have been an area of
intense research interest for many years. An efficient channel allocation
scheme can significantly reduce call-blocking and calldropping probabilities.
Another important issue is to effectively manage the power requirements for
communication. An efficient power control strategy leads to reduced power
consumption and improved signal quality. In this paper, we present a novel
integer linear program (ILP) formulation that jointly optimizes channel
allocation and power control for incoming calls, based on the
carrier-to-interference ratio (CIR). In our approach we use a hybrid channel
assignment scheme, where an incoming call is admitted only if a suitable
channel is found such that the CIR of all ongoing calls on that channel, as
well as that of the new call, will be above a specified value. Our formulation
also guarantees that the overall power requirement for the selected channel
will be minimized as much as possible and that no ongoing calls will be dropped
as a result of admitting the new call. We have run simulations on a benchmark
49 cell environment with 70 channels to investigate the effect of different
parameters such as the desired CIR. The results indicate that our approach
leads to significant improvements over existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3732</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3732</id><created>2011-03-18</created><authors><author><keyname>Lin</keyname><forenames>Min Chih</forenames></author><author><keyname>Soulignac</keyname><forenames>Francisco J.</forenames></author><author><keyname>Szwarcfiter</keyname><forenames>Jayme L.</forenames></author></authors><title>Subclasses of Normal Helly Circular-Arc Graphs</title><categories>cs.DM</categories><comments>39 pages, 13 figures. A previous version of the paper (entitled
  Proper Helly Circular-Arc Graphs) appeared at WG'07</comments><msc-class>05C62, 68R10</msc-class><doi>10.1016/j.dam.2012.11.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Helly circular-arc model M = (C,A) is a circle C together with a Helly
family \A of arcs of C. If no arc is contained in any other, then M is a proper
Helly circular-arc model, if every arc has the same length, then M is a unit
Helly circular-arc model, and if there are no two arcs covering the circle,
then M is a normal Helly circular-arc model. A Helly (resp. proper Helly, unit
Helly, normal Helly) circular-arc graph is the intersection graph of the arcs
of a Helly (resp. proper Helly, unit Helly, normal Helly) circular-arc model.
In this article we study these subclasses of Helly circular-arc graphs. We show
natural generalizations of several properties of (proper) interval graphs that
hold for some of these Helly circular-arc subclasses. Next, we describe
characterizations for the subclasses of Helly circular-arc graphs, including
forbidden induced subgraphs characterizations. These characterizations lead to
efficient algorithms for recognizing graphs within these classes. Finally, we
show how do these classes of graphs relate with straight and round digraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3735</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3735</id><created>2011-03-18</created><authors><author><keyname>Moon</keyname><forenames>Taesup</forenames></author><author><keyname>Chu</keyname><forenames>Wei</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author><author><keyname>Zheng</keyname><forenames>Zhaohui</forenames></author><author><keyname>Chang</keyname><forenames>Yi</forenames></author></authors><title>Refining Recency Search Results with User Click Feedback</title><categories>cs.IR cs.AI cs.LG</categories><comments>22 pages, 9 figures, 1 table. A preliminary and shorter version
  presented at CIKM-2010</comments><acm-class>H.3.3; H.3.5; I.6.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional machine-learned ranking systems for web search are often trained
to capture stationary relevance of documents to queries, which has limited
ability to track non-stationary user intention in a timely manner. In recency
search, for instance, the relevance of documents to a query on breaking news
often changes significantly over time, requiring effective adaptation to user
intention. In this paper, we focus on recency search and study a number of
algorithms to improve ranking results by leveraging user click feedback. Our
contributions are three-fold. First, we use real search sessions collected in a
random exploration bucket for \emph{reliable} offline evaluation of these
algorithms, which provides an unbiased comparison across algorithms without
online bucket tests. Second, we propose a re-ranking approach to improve search
results for recency queries using user clicks. Third, our empirical comparison
of a dozen algorithms on real-life search data suggests importance of a few
algorithmic choices in these applications, including generalization across
different query-document pairs, specialization to popular queries, and
real-time adaptation of user clicks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3737</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3737</id><created>2011-03-18</created><authors><author><keyname>Tamo</keyname><forenames>Itzhak</forenames></author><author><keyname>Wang</keyname><forenames>Zhiying</forenames></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author></authors><title>MDS Array Codes with Optimal Rebuilding</title><categories>cs.IT cs.DC math.IT</categories><comments>14 pages, 4 figures, a short version submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MDS array codes are widely used in storage systems to protect data against
erasures. We address the \emph{rebuilding ratio} problem, namely, in the case
of erasures, what is the the fraction of the remaining information that needs
to be accessed in order to rebuild \emph{exactly} the lost information? It is
clear that when the number of erasures equals the maximum number of erasures
that an MDS code can correct then the rebuilding ratio is 1 (access all the
remaining information). However, the interesting (and more practical) case is
when the number of erasures is smaller than the erasure correcting capability
of the code. For example, consider an MDS code that can correct two erasures:
What is the smallest amount of information that one needs to access in order to
correct a single erasure? Previous work showed that the rebuilding ratio is
bounded between 1/2 and 3/4, however, the exact value was left as an open
problem. In this paper, we solve this open problem and prove that for the case
of a single erasure with a 2-erasure correcting code, the rebuilding ratio is
1/2. In general, we construct a new family of $r$-erasure correcting MDS array
codes that has optimal rebuilding ratio of $\frac{1}{r}$ in the case of a
single erasure. Our array codes have efficient encoding and decoding algorithms
(for the case $r=2$ they use a finite field of size 3) and an optimal update
property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3742</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3742</id><created>2011-03-18</created><authors><author><keyname>Yosh</keyname><forenames>Harry</forenames></author></authors><title>The key exchange cryptosystem used with higher order Diophantine
  equations</title><categories>cs.IT math.IT</categories><comments>8 pages, 0 figure</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.2, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-way functions are widely used for encrypting the secret in public key
cryptography, although they are regarded as plausibly one-way but have not been
proven so. Here we discuss the public key cryptosystem based on the system of
higher order Diophantine equations. In this system those Diophantine equations
are used as public keys for sender and recipient, and sender can recover the
secret from the Diophantine equation returned from recipient with a trapdoor.
In general the system of Diophantine equations is hard to solve when it is
positive-dimensional and it implies the Diophantine equations in this
cryptosystem works as a possible one-way function. We also discuss some
problems on implementation, which are caused from additional complexity
necessary for constructing Diophantine equations in order to prevent from
attacking by tamperers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3745</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3745</id><created>2011-03-18</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Quimper</keyname><forenames>Claude-Guy</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>The AllDifferent Constraint with Precedences</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose AllDiffPrecedence, a new global constraint that combines together
an AllDifferent constraint with precedence constraints that strictly order
given pairs of variables. We identify a number of applications for this global
constraint including instruction scheduling and symmetry breaking. We give an
efficient propagation algorithm that enforces bounds consistency on this global
constraint. We show how to implement this propagator using a decomposition that
extends the bounds consistency enforcing decomposition proposed for the
AllDifferent constraint. Finally, we prove that enforcing domain consistency on
this global constraint is NP-hard in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3746</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3746</id><created>2011-03-18</created><updated>2011-03-31</updated><authors><author><keyname>Cuff</keyname><forenames>Paul</forenames></author></authors><title>Using a Secret Key to Foil an Eavesdropper</title><categories>cs.CR cs.IT math.IT</categories><comments>Allerton 2010, 6 pages, 1 figure, uses IEEEtran.cls</comments><msc-class>94A62</msc-class><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work addresses private communication with distributed systems in mind.
We consider how to best use secret key resources and communication to transmit
signals across a system so that an eavesdropper is least capable to act on the
signals. One of the key assumptions is that the private signals are publicly
available with a delay---in this case a delay of one. We find that even if the
source signal (information source) is memoryless, the design and performance of
the optimal system has a strong dependence on which signals are assumed to be
available to the eavesdropper with delay.
  Specifically, we consider a distributed system with two components where
information is known to only one component and communication resources are
limited. Instead of measuring secrecy by &quot;equivocation,&quot; we define a value
function for the system, based on the actions of the system and the adversary,
and characterize the optimal performance of the system, as measured by the
average value obtained against the worst adversary. The resulting optimal
rate-payoff region is expressed with information theoretic inequalities, and
the optimal communication methods are not standard source coding techniques but
instead are methods that stem from synthesizing a memoryless channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3753</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3753</id><created>2011-03-19</created><updated>2011-04-25</updated><authors><author><keyname>Sz&#xe9;pk&#xfa;ti</keyname><forenames>Istv&#xe1;n</forenames></author></authors><title>On the Scalability of Multidimensional Databases</title><categories>cs.DB</categories><comments>18 pages, 1 figure, 8 tables. Paper presented at the Second
  Conference of PhD Students in Computer Science, Szeged, Hungary, 20 - 23 July
  2000. For further details, please refer to
  http://www.inf.u-szeged.hu/~szepkuti/papers.html#scalability</comments><journal-ref>Periodica Polytechnica Electrical Engineering, Vol. 44, Number 1,
  pp. 103-119, 2000</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is commonly accepted in the practice of on-line analytical processing of
databases that the multidimensional database organization is less scalable than
the relational one. It is easy to see that the size of the multidimensional
organization may increase very quickly. For example, if we introduce one
additional dimension, then the total number of possible cells will be at least
doubled. However, this reasoning does not takethe fact into account that the
multidimensional organization can be compressed. There are compression
techniques, which can remove all or at least a part of the empty cells from the
multidimensional organization, while maintaining a good retrieval performance.
Relational databases often use B-tree indices to speed up the access to given
rows of tables. It can be proven, under some reasonable assumptions, that the
total size of the table and the B-tree index is bigger than a compressed
multidimensional representation. This implies that the compressed array results
in a smaller database and faster access at the same time. This paper compares
several compression techniques and shows when we should and should not apply
compressed arrays instead of relational tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3756</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3756</id><created>2011-03-19</created><updated>2012-09-21</updated><authors><author><keyname>Foucaud</keyname><forenames>Florent</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Perarnau</keyname><forenames>Guillem</forenames><affiliation>UPC</affiliation></author></authors><title>Bounds for identifying codes in terms of degree parameters</title><categories>cs.DM math.CO</categories><proxy>ccsd</proxy><journal-ref>The Electronic Journal of Combinatorics 19 (2012) P32</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An identifying code is a subset of vertices of a graph such that each vertex
is uniquely determined by its neighbourhood within the identifying code. If
$\M(G)$ denotes the minimum size of an identifying code of a graph $G$, it was
conjectured by F. Foucaud, R. Klasing, A. Kosowski and A. Raspaud that there
exists a constant $c$ such that if a connected graph $G$ with $n$ vertices and
maximum degree $d$ admits an identifying code, then $\M(G)\leq
n-\tfrac{n}{d}+c$. We use probabilistic tools to show that for any $d\geq 3$,
$\M(G)\leq n-\tfrac{n}{\Theta(d)}$ holds for a large class of graphs
containing, among others, all regular graphs and all graphs of bounded clique
number. This settles the conjecture (up to constants) for these classes of
graphs. In the general case, we prove $\M(G)\leq n-\tfrac{n}{\Theta(d^{3})}$.
In a second part, we prove that in any graph $G$ of minimum degree $\delta$ and
girth at least 5, $\M(G)\leq(1+o_\delta(1))\tfrac{3\log\delta}{2\delta}n$.
Using the former result, we give sharp estimates for the size of the minimum
identifying code of random $d$-regular graphs, which is about $\tfrac{\log
d}{d}n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3766</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3766</id><created>2011-03-19</created><authors><author><keyname>Li</keyname><forenames>Jie</forenames></author><author><keyname>Wu</keyname><forenames>Jian-ping</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>SafeZone: A Hierarchical Inter-Domain Authenticated Source Address
  Validation Solution</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Next generation Internet is highly concerned about the issue of reliability.
Principally, the foundation of reliability is authentication of the source IP
address. With the signature-and-verification based defense mechanisms available
today, unfortunately, there is a lack of hierarchical architecture, which makes
the structure of the trust alliance excessively flat and single. Moreover, with
the increasing scale of the trust alliance, costs of validation grow so quickly
that they do not adapt to incremental deployment. Via comparison with
traditional solutions, this article proposes a hierarchical, inter-domain
authenticated source address validation solution named SafeZone. SafeZone
employs two intelligent designs, lightweight tag replacement and a hierarchical
partitioning scheme, each of which helps to ensure that SafeZone can construct
trustworthy and hierarchical trust alliances without the negative influences
and complex operations on de facto networks. Extensive experiments also
indicate that SafeZone can effectively obtain the design goals of a
hierarchical architecture, along with lightweight, loose coupling and
&quot;multi-fence support&quot; and as well as an incremental deployment scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3779</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3779</id><created>2011-03-19</created><authors><author><keyname>Khraiwesh</keyname><forenames>Mahmoud</forenames></author></authors><title>Validation Measures in CMMI</title><categories>cs.SE</categories><comments>8 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT),ISSN: 2221-0741, Vol. 1, No. 2, 26-33, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Validation is one of the software engineering disciplines that help build
quality into software. The major objective of software validation process is to
determine that the software performs its intended functions correctly and
provide information about its quality and reliability. This paper identifies
general measures for the specific goals and its specific practices of
Validation Process Area (PA) in Capability Maturity Model Integration (CMMI).
CMMI is developed by Software Engineering Institute (SEI). CMMI is a framework
for improvement and assessment of a software development process. CMMI needs a
measurement program that is practical. The method we used to define the
measures is to apply the Goal Question Metrics (GQM) paradigm to the specific
goals and its specific practices of Validation Process Area in CMMI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3782</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3782</id><created>2011-03-19</created><authors><author><keyname>Lin</keyname><forenames>Xingqin</forenames></author><author><keyname>Lok</keyname><forenames>Tat-Ming</forenames></author></authors><title>Learning Equilibrium Play for Stochastic Parallel Gaussian Interference
  Channels</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed power control for parallel Gaussian interference channels
recently draws great interests. However, all existing works only studied this
problem under deterministic communication channels and required certain perfect
information to carry out their proposed algorithms. In this paper, we study
this problem for stochastic parallel Gaussian interference channels. In
particular, we take into account the randomness of the communication
environment and the estimation errors of the desired information, and thus
formulate a stochastic noncooperative power control game. We then propose a
stochastic distributed learning algorithm SDLA-I to help communication pairs
learn the Nash equilibrium. A careful convergence analysis on SDLA-I is
provided based on stochastic approximation theory and projected dynamic systems
approach. We further propose another learning algorithm SDLA-II by including a
simple iterate averaging idea into SDLA-I to improve algorithmic convergence
performance. Numerical results are also presented to demonstrate the
performance of our algorithms and theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3787</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3787</id><created>2011-03-19</created><authors><author><keyname>Inoue</keyname><forenames>Jun-ichi</forenames></author></authors><title>Pattern-recalling processes in quantum Hopfield networks far from
  saturation</title><categories>cond-mat.dis-nn cs.LG physics.bio-ph</categories><comments>10 pages, 3 figures, using jpconf.cls, Proc. of Statphys-Kolkata VII</comments><doi>10.1088/1742-6596/297/1/012012</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  As a mathematical model of associative memories, the Hopfield model was now
well-established and a lot of studies to reveal the pattern-recalling process
have been done from various different approaches. As well-known, a single
neuron is itself an uncertain, noisy unit with a finite unnegligible error in
the input-output relation. To model the situation artificially, a kind of 'heat
bath' that surrounds neurons is introduced. The heat bath, which is a source of
noise, is specified by the 'temperature'. Several studies concerning the
pattern-recalling processes of the Hopfield model governed by the
Glauber-dynamics at finite temperature were already reported. However, we might
extend the 'thermal noise' to the quantum-mechanical variant. In this paper, in
terms of the stochastic process of quantum-mechanical Markov chain Monte Carlo
method (the quantum MCMC), we analytically derive macroscopically deterministic
equations of order parameters such as 'overlap' in a quantum-mechanical variant
of the Hopfield neural networks (let us call &quot;quantum Hopfield model&quot; or
&quot;quantum Hopfield networks&quot;). For the case in which non-extensive number $p$ of
patterns are embedded via asymmetric Hebbian connections, namely, $p/N \to 0$
for the number of neuron $N \to \infty$ ('far from saturation'), we evaluate
the recalling processes for one of the built-in patterns under the influence of
quantum-mechanical noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3791</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3791</id><created>2011-03-19</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author><author><keyname>Famularo</keyname><forenames>Domenico</forenames></author><author><keyname>Pugliese</keyname><forenames>Paolo</forenames></author></authors><title>Index Branch-and-Bound Algorithm for Global Optimization with
  Multiextremal Constraints</title><categories>math.OC cs.NA math.NA</categories><comments>26 pages, 5 figures</comments><msc-class>65K05, 90C30</msc-class><journal-ref>Journal of Global Optimization, 21(3) (2001) 317-341</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Lipschitz univariate constrained global optimization problems
where both the objective function and constraints can be multiextremal are
considered. The constrained problem is reduced to a discontinuous unconstrained
problem by the index scheme without introducing additional parameters or
variables. A Branch-and-Bound method that does not use derivatives for solving
the reduced problem is proposed. The method either determines the infeasibility
of the original problem or finds lower and upper bounds for the global
solution. Not all the constraints are evaluated during every iteration of the
algorithm, providing a significant acceleration of the search. Convergence
conditions of the new method are established. Test problems and extensive
numerical experiments are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3792</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3792</id><created>2011-03-19</created><authors><author><keyname>Sathishkumar</keyname><forenames>G. A.</forenames></author><author><keyname>bagan</keyname><forenames>Dr. K. Bhoopathy</forenames></author><author><keyname>Sriraam</keyname><forenames>Dr. N.</forenames></author></authors><title>Image Encryption Based on Diffusion and Multiple Chaotic Maps</title><categories>cs.CR</categories><comments>14 pages,9 figures and 5 tables;
  http://airccse.org/journal/jnsa11_current.html, 2011</comments><doi>10.5121/ijnsa.2011.3214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent world, security is a prime important issue, and encryption is
one of the best alternative way to ensure security. More over, there are many
image encryption schemes have been proposed, each one of them has its own
strength and weakness. This paper presents a new algorithm for the image
encryption/decryption scheme. This paper is devoted to provide a secured image
encryption technique using multiple chaotic based circular mapping. In this
paper, first, a pair of sub keys is given by using chaotic logistic maps.
Second, the image is encrypted using logistic map sub key and in its
transformation leads to diffusion process. Third, sub keys are generated by
four different chaotic maps. Based on the initial conditions, each map may
produce various random numbers from various orbits of the maps. Among those
random numbers, a particular number and from a particular orbit are selected as
a key for the encryption algorithm. Based on the key, a binary sequence is
generated to control the encryption algorithm. The input image of 2-D is
transformed into a 1- D array by using two different scanning pattern (raster
and Zigzag) and then divided into various sub blocks. Then the position
permutation and value permutation is applied to each binary matrix based on
multiple chaos maps. Finally the receiver uses the same sub keys to decrypt the
encrypted images. The salient features of the proposed image encryption method
are loss-less, good peak signal-to-noise ratio (PSNR), Symmetric key
encryption, less cross correlation, very large number of secret keys, and
key-dependent pixel value replacement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3794</identifier>
 <datestamp>2012-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3794</id><created>2011-03-19</created><updated>2011-07-06</updated><authors><author><keyname>Trifina</keyname><forenames>Lucian</forenames></author><author><keyname>T&#x103;rniceriu</keyname><forenames>Daniela</forenames></author><author><keyname>Munteanu</keyname><forenames>Valeriu</forenames></author></authors><title>Improved QPP Interleavers for LTE Standard</title><categories>cs.IT math.IT</categories><comments>IEEE International Symposium on Signals, Circuits and Systems - ISSCS
  2011, pp. 403-406, June 30-July 1, 2011, Iasi, Romania</comments><journal-ref>IEEE International Symposium on Signals, Circuits and Systems -
  ISSCS 2011, pp. 403-406, June 30-July 1, 2011, Iasi, Romania</journal-ref><doi>10.1109/ISSCS.2011.5978745</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes and proves a theorem which stipulates sufficient
conditions the coefficients of two quadratic permutation polynomials (QPP) must
satisfy, so that the permutations generated by them are identical. The result
is used to reduce the search time of QPP interleavers with lengths given by
Long Term Evolution (LTE) standard up to 512, by improving the distance
spectrum over the set of polynomials with the largest spreading factor.
Polynomials that lead to better performance compared to LTE standard are found
for several lengths. Simulations show that 0.5 dB coding gains can be obtained
compared to LTE standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3799</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3799</id><created>2011-03-19</created><updated>2011-05-04</updated><authors><author><keyname>Long</keyname><forenames>Feichi</forenames></author><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author></authors><title>Relaxed Belief Propagation for MIMO Detection</title><categories>cs.IT math.IT</categories><comments>5 Pages, 8 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, relaxed belief propagation (RBP) based detectors are proposed
for multiple-input multiple-out (MIMO) system. The factor graph is leveraged to
represent the MIMO channels, and based on which our algorithms are developed.
Unlike the existing complicated standard belief propagation (SBP) detector that
considers all the edges of the factor graph when updating messages, the
proposed RBP focuses on partial edges, which largely reduces computational
complexity. In particular, relax degree is introduced in to determine how many
edges to be selected, whereby RBP is a generalized edge selection based BP
method and SBP is a special case of RBP having the smallest relax degree.
Moreover, we propose a novel Gaussian approximation with feedback information
mechanism to enable the proposed RBP detector. In order to further improve the
detection performance, we also propose to cascade a minimum mean square error
(MMSE) detector before the RBP detector, from which pseudo priori information
is judiciously exploited. Convergence and complexity analyses, along with the
numerical simulation results, verify that the proposed RBP outperform other BP
methods having the similar complexity, and the MMSE cascaded RBP even
outperform SBP at the largest relax degree in large MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3801</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3801</id><created>2011-03-19</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author><author><keyname>Daponte</keyname><forenames>Pasquale</forenames></author><author><keyname>Grimaldi</keyname><forenames>Domenico</forenames></author><author><keyname>Molinaro</keyname><forenames>Anna</forenames></author></authors><title>Two methods for solving optimization problems arising in electronic
  measurements and electrical engineering</title><categories>math.NA cs.CE cs.NA math.OC physics.comp-ph</categories><msc-class>90C30, 94A12, 65Z05</msc-class><journal-ref>SIAM Journal on Optimization, 10(1) (1999) 1-21</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a common problem in electronic measurements and
electrical engineering: finding the first root from the left of an equation in
the presence of some initial conditions. We present examples of
electrotechnical devices (analog signal filtering), where it is necessary to
solve it. Two new methods for solving this problem, based on global
optimization ideas, are introduced. The first uses the exact a priori given
global Lipschitz constant for the first derivative. The second method
adaptively estimates local Lipschitz constants during the search. Both
algorithms either find the first root from the left or determine the global
minimizers (in the case when the objective function has no roots). Sufficient
conditions for convergence of the new methods to the desired solution are
established in both cases. The results of numerical experiments for real
problems and a set of test functions are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3802</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3802</id><created>2011-03-19</created><authors><author><keyname>Kumar</keyname><forenames>Sumit</forenames></author><author><keyname>Kumar</keyname><forenames>Santosh</forenames></author><author><keyname>Nandi</keyname><forenames>Sukumar</forenames></author></authors><title>Stage Staffing Scheme for Copyright Protection in Multimedia</title><categories>cs.MM</categories><comments>13 pages, 7 figures</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.2, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Copyright protection has become a need in today's world. To achieve a secure
copyright protection we embedded some information in images and videos and that
image or video is called copyright protected. The embedded information can't be
detected by human eye but some attacks and operations can tamper that
information to breach protection. So in order to find a secure technique of
copyright protection, we have analyzed image processing techniques i.e. Spatial
Domain (Least Significant Bit (LSB)), Transform Domain (Discrete Cosine
Transform (DCT)), Discrete Wavelet Transform (DWT) and there are numerous
algorithm for watermarking using them. After having a good understanding of the
same we have proposed a novel algorithm named as Stage Staffing Algorithm that
generates results with high effectiveness, additionally we can use self
extracted-watermark technique to increase the security and automate the process
of watermark image. The proposed algorithm provides protection in three stages.
We have implemented the algorithm and results of the simulations are shown. The
various factors affecting spatial domain watermarking are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3807</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3807</id><created>2011-03-19</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Framework for Clique-based Fusion of Graph Streams in Multi-function
  System Testing</title><categories>cs.SE</categories><comments>6 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper describes a framework for multi-function system testing.
Multi-function system testing is considered as fusion (or revelation) of
clique-like structures. The following sets are considered: (i) subsystems
(system parts or units / components / modules), (ii) system functions and a
subset of system components for each system function, and (iii) function
clusters (some groups of system functions which are used jointly). Test
procedures (as units testing) are used for each subsystem. The procedures lead
to an ordinal result (states, colors) for each component, e.g., [1,2,3,4]
(where 1 corresponds to 'out of service', 2 corresponds to 'major faults', 3
corresponds to 'minor faults', 4 corresponds to 'trouble free service'). Thus,
for each system function a graph over corresponding system components is
examined while taking into account ordinal estimates/colors of the components.
Further, an integrated graph (i.e., colored graph) for each function cluster is
considered (this graph integrates the graphs for corresponding system
functions). For the integrated graph (for each function cluster) structure
revelation problems are under examination (revelation of some subgraphs which
can lead to system faults): (1) revelation of clique and quasi-clique (by
vertices at level 1, 2, etc.; by edges/interconnection existence) and (2)
dynamical problems (when vertex colors are functions of time) are studied as
well: existence of a time interval when clique or quasi-clique can exist.
Numerical examples illustrate the approach and problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3809</identifier>
 <datestamp>2014-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3809</id><created>2011-03-19</created><updated>2011-11-22</updated><authors><author><keyname>Grytczuk</keyname><forenames>Jaros&#x142;aw</forenames></author><author><keyname>Kozik</keyname><forenames>Jakub</forenames></author><author><keyname>Micek</keyname><forenames>Piotr</forenames></author></authors><title>A new approach to nonrepetitive sequences</title><categories>math.CO cs.DM</categories><comments>5 pages, no figures.arXiv admin note: substantial text overlap with
  arXiv:1103.3810</comments><doi>10.1002/rsa.20411</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sequence is nonrepetitive if it does not contain two adjacent identical
blocks. The remarkable construction of Thue asserts that 3 symbols are enough
to build an arbitrarily long nonrepetitive sequence. It is still not settled
whether the following extension holds: for every sequence of 3-element sets
$L_1,..., L_n$ there exists a nonrepetitive sequence $s_1, ..., s_n$ with
$s_i\in L_i$. Applying the probabilistic method one can prove that this is true
for sufficiently large sets $L_i$. We present an elementary proof that sets of
size 4 suffice (confirming the best known bound). The argument is a simple
counting with Catalan numbers involved. Our approach is inspired by a new
algorithmic proof of the Lov\'{a}sz Local Lemma due to Moser and Tardos and its
interpretations by Fortnow and Tao. The presented method has further
applications to nonrepetitive games and nonrepetitive colorings of graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3810</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3810</id><created>2011-03-19</created><updated>2011-11-22</updated><authors><author><keyname>Grytczuk</keyname><forenames>Jaros&#x142;aw</forenames></author><author><keyname>Kozik</keyname><forenames>Jakub</forenames></author><author><keyname>Micek</keyname><forenames>Piotr</forenames></author></authors><title>Nonrepetitive games</title><categories>math.CO cs.DM</categories><comments>8 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (Note. The results of this manuscript has been merged and published with
another paper of the same authors: A new approach to nonrepetitve sequences.)
  A repetition of size $h$ ($h\geqslant1$) in a given sequence is a subsequence
of consecutive terms of the form: $xx=x_1... x_hx_1... x_h$. A sequence is
nonrepetitive if it does not contain a repetition of any size. The remarkable
construction of Thue asserts that 3 different symbols are enough to build an
arbitrarily long nonrepetitive sequence. We consider game-theoretic versions of
results on nonrepetitive sequences. A nonrepetitive game is played by two
players who pick, one by one, consecutive terms of a sequence over a given set
of symbols. The first player tries to avoid repetitions, while the second
player, in contrast, wants to create them. Of course, by simple imitation, the
second player can force lots of repetitions of size 1. However, as proved by
Pegden, there is a strategy for the first player to build an arbitrarily long
sequence over 37 symbols with no repetitions of size $&gt;1$. Our techniques allow
to reduce 37 to 6. Another game we consider is an erase-repetition game. Here,
whenever a repetition occurs, the repeated block is immediately erased and the
next player to move continues the play. We prove that there is a strategy for
the first player to build an arbitrarily long nonrepetitive sequence over 8
symbols. Our approach is inspired by a new algorithmic proof of the Lov\'asz
Local Lemma due to Moser and Tardos and previous work of Moser (his so called
entropy compression argument).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3831</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3831</id><created>2011-03-20</created><authors><author><keyname>Behera</keyname><forenames>H. S.</forenames></author><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Nayak</keyname><forenames>Debashree</forenames></author></authors><title>A New Proposed Dynamic Quantum with Re-Adjusted Round Robin Scheduling
  Algorithm and Its Performance Analysis</title><categories>cs.OS</categories><comments>06 pages; International Journal of Computer Applications, Vol. 5, No.
  5, August 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheduling is the central concept used frequently in Operating System. It
helps in choosing the processes for execution. Round Robin (RR) is one of the
most widely used CPU scheduling algorithm. But, its performance degrades with
respect to context switching, which is an overhead and it occurs during each
scheduling. Overall performance of the system depends on choice of an optimal
time quantum, so that context switching can be reduced. In this paper, we have
proposed a new variant of RR scheduling algorithm, known as Dynamic Quantum
with Readjusted Round Robin (DQRRR) algorithm. We have experimentally shown
that performance of DQRRR is better than RR by reducing number of context
switching, average waiting time and average turn around time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3832</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3832</id><created>2011-03-20</created><authors><author><keyname>Behera</keyname><forenames>H. S.</forenames></author><author><keyname>Patel</keyname><forenames>Simpi</forenames></author><author><keyname>Panda</keyname><forenames>Bijayalakshmi</forenames></author></authors><title>A New Dynamic Round Robin and SRTN Algorithm with Variable Original Time
  Slice and Intelligent Time Slice for Soft Real Time Systems</title><categories>cs.OS</categories><comments>07 pages; International Journal of Computer Applications, Vol 16, No.
  1(9) February 2011</comments><doi>10.5120/2037-2648</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of the paper is to improve the Round Robin (RR) algorithm
using dynamic ITS by coalescing it with Shortest Remaining Time Next (SRTN)
algorithm thus reducing the average waiting time, average turnaround time and
the number of context switches. The original time slice has been calculated for
each process based on its burst time.This is mostly suited for soft real time
systems where meeting of deadlines is desirable to increase its performance.
The advantage is that processes that are closer to their remaining completion
time will get more chances to execute and leave the ready queue. This will
reduce the number of processes in the ready queue by knocking out short jobs
relatively faster in a hope to reduce the average waiting time, turn around
time and number of context switches. This paper improves the algorithm [8] and
the experimental analysis shows that the proposed algorithm performs better
than algorithm [6] and [8] when the processes are having an increasing order,
decreasing order and random order of burst time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3837</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3837</id><created>2011-03-20</created><authors><author><keyname>Kim</keyname><forenames>Heejin</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Rim</forenames></author><author><keyname>Lee</keyname><forenames>Kyoung-Jae</forenames></author><author><keyname>Lee</keyname><forenames>Inkyu</forenames></author></authors><title>Transmission Selection Schemes using Sum Rate Analysis in Distributed
  Antenna Systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, Submitted to Globecom 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study single cell multi-user downlink distributed antenna
systems (DAS) where the antenna ports are geographically separated in a cell.
First, we derive an expression of the ergodic sum rate for DAS in the presence
of pathloss. Then, we propose a transmission selection scheme based on the
derived expressions to maximize the overall ergodic sum rate. Utilizing the
knowledge of distance information from a user to each distributed antenna (DA)
port, we consider the pairings of each DA port and its supporting user to
optimize the system performance. Then, we compute the ergodic sum rate for
various transmission mode candidates and adopt a transmission selection scheme
which chooses the best mode maximizing the ergodic sum rate among the mode
candidates. In our proposed scheme, the number of mode candidates are greatly
reduced compared to that of the ideal mode selection. Through Monte Carlo
simulations, we will show the accuracy of our derivation for the ergodic sum
rate expression. Moreover, simulation results with the pathloss modeling
confirm that the proposed transmission selection scheme produces the average
sum rate identical to the ideal mode selection with significantly reduced
selection candidates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3843</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3843</id><created>2011-03-20</created><authors><author><keyname>Saucan</keyname><forenames>Emil</forenames></author></authors><title>A Simple Sampling Method for Metric Measure Spaces</title><categories>cs.IT math.IT math.MG</categories><comments>34 pages</comments><msc-class>94A20, 60D05, 30L10, 52C23</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new, simple metric method of sampling metric measure spaces,
based on a well-known &quot;snowflakeing operator&quot; and we show that, as a
consequence of a classical result of Assouad, the sampling of doubling metric
spaces is bilipschitz equivalent to that of subsets of some $\mathbb{R}^N$.
Moreover, we compare this new method with two other approaches, in particular
to one that represents a direct application of our triangulation method of
metric measure spaces satisfying a generalized Ricci curvature condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3844</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3844</id><created>2011-03-20</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author><author><keyname>Andrushevich</keyname><forenames>Aliaksei</forenames></author><author><keyname>Klapproth</keyname><forenames>Alexander</forenames></author></authors><title>Composition of Management System for Smart Homes</title><categories>cs.SE</categories><comments>9 pages, 7 figures</comments><journal-ref>Information Processes, 2010, 10(1), 78-86</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper addresses modular hierarchical design (composition) of a management
system for smart homes. The management system consists of security subsystem
(access control, alarm control), comfort subsystem (temperature, etc.),
intelligence subsystem (multimedia, houseware). The design solving process is
based on Hierarchical Morphological Multicriteria Design (HMMD) approach: (1)
design of a tree-like system model, (2) generation of design alternatives for
leaf nodes of the system model, (3) Bottom-Up process: (i) multicriteria
selection of design alternatives for system parts/components and (ii) composing
the selected alternatives into a resultant combination (while taking into
account ordinal quality of the alternatives above and their compatibility). A
realistic numerical example illustrates the design process of a management
system for smart homes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3845</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3845</id><created>2011-03-20</created><authors><author><keyname>Levin</keyname><forenames>Mark Sh.</forenames></author></authors><title>Course on System Design (structural approach)</title><categories>cs.SE</categories><comments>22 pages, 14 figures</comments><journal-ref>Information processes, 10(4), 303-324, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article describes a course on system design (structural approach) which
involves the following: issues of systems engineering; structural models; basic
technological problems (structural system modeling, modular design,
evaluation/comparison, revelation of bottlenecks, improvement/upgrade,
multistage design, modeling of system evolution); solving methods
(optimization, combinatorial optimization, multicriteria decision making);
design frameworks; and applications. The course contains lectures and a set of
special laboratory works. The laboratory works consist in designing and
implementing a set of programs to solve multicriteria problems
(ranking/selection, multiple choice problem, clustering, assignment). The
programs above are used to solve some standard problems (e.g., hierarchical
design of a student plan, design of a marketing strategy). Concurrently, each
student can examine a unique applied problem from his/her applied domain(s)
(e.g., telemetric system, GSM network, integrated security system, testing of
microprocessor systems, wireless sensor, corporative communication network,
network topology). Mainly, the course is targeted to developing the student
skills in modular analysis and design of various multidisciplinary composite
systems (e.g., software, electronic devices, information, computers,
communications). The course was implemented in Moscow Institute of Physics and
Technology (State University).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3846</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3846</id><created>2011-03-20</created><authors><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Xu</keyname><forenames>Zhiqiang</forenames></author></authors><title>The Performance of PCM Quantization Under Tight Frame Representations</title><categories>math.NA cs.IT math.FA math.IT</categories><comments>23 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the performance of the PCM scheme with linear
quantization rule for quantizing finite unit-norm tight frame expansions for
$\R^d$ and derive the PCM quantization error without the White Noise
Hypothesis. We prove that for the class of unit norm tight frames derived from
uniform frame paths the quantization error has an upper bound of
$O(\delta^{3/2})$ regardless of the frame redundancy. This is achieved using
some of the techniques developed by G\&quot;{u}nt\&quot;{u}rk in his study of Sigma-Delta
quantization. Using tools of harmonic analysis we show that this upper bound is
sharp for $d=2$. A consequence of this result is that, unlike with Sigma-Delta
quantization, the error for PCM quantization in general does not diminish to
zero as one increases the frame redundancy. We extend the result to high
dimension and show that the PCM quantization error has an upper bound
$O(\delta^{(d+1)/2})$ for asymptopitcally equidistributed unit-norm tight frame
of $\R^{d}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3854</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3854</id><created>2011-03-20</created><authors><author><keyname>Dohmen</keyname><forenames>Klaus</forenames></author><author><keyname>Tittmann</keyname><forenames>Peter</forenames></author></authors><title>Domination Reliability</title><categories>math.CO cs.DM math.PR</categories><comments>14 pages</comments><msc-class>05C30, 05C31 (Primary) 62N05, 68M15, 90B25 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new network reliability measure for some particular kind of
service networks, which we refer to as domination reliability. We relate this
new reliability measure to the domination polynomial of a graph and the
coverage probability of a hypergraph. We derive explicit and recursive formulae
for domination reliability and its associated domination reliability
polynomial, deduce an analogue of Whitney's broken circuit theorem, and prove
that computing domination reliability is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3857</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3857</id><created>2011-03-20</created><updated>2011-04-26</updated><authors><author><keyname>Sz&#xe9;pk&#xfa;ti</keyname><forenames>Istv&#xe1;n</forenames></author></authors><title>Difference Sequence Compression of Multidimensional Databases</title><categories>cs.DB</categories><comments>22 pages, 4 figures, 5 tables. Paper presented at the Third
  Conference of PhD Students in Computer Science, Szeged, Hungary, 1 - 4 July
  2002. For further details, please refer to
  http://www.inf.u-szeged.hu/~szepkuti/papers.html#differencesequence</comments><journal-ref>Periodica Polytechnica Electrical Engineering, Vol. 48, Number
  3-4, pp. 197-218, 2004</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multidimensional databases often use compression techniques in order to
decrease the size of the database. This paper introduces a new method called
difference sequence compression. Under some conditions, this new technique is
able to create a smaller size multidimensional database than others like single
count header compression, logical position compression or base-offset
compression. Keywords: compression, multidimensional database, On-line
Analytical Processing, OLAP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3863</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3863</id><created>2011-03-20</created><updated>2011-04-19</updated><authors><author><keyname>Sz&#xe9;pk&#xfa;ti</keyname><forenames>Istv&#xe1;n</forenames></author></authors><title>Multidimensional or Relational? / How to Organize an On-line Analytical
  Processing Database</title><categories>cs.DB</categories><comments>28 pages, 2 figures, 13 tables. Talk presented at the XIV
  International Conference on Mathematical Programming, Matrahaza, Hungary, 28
  - 31 March 1999; Computing Research Repository, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years, the number of OLAP applications increased quickly.
These applications use two significantly different DB structures:
multidimensional (MD) and table-based. One can show that the traditional model
of relational databases cannot make difference between these two structures.
Another model is necessary to make the differences visible. One of these is the
speed of the system. It can be proven that the multidimensional DB organization
results in shorter response times. And it is crucial, since a manager may
become impatient, if he or she has to wait say more than 20 seconds for the
next screen. On the other hand, we have to pay for the speed with a bigger DB
size. Why does the size of MD databases grow so quickly? The reason is the
sparsity of data: The MD matrix contains many empty cells. Efficient handling
of sparse matrices is indispensable in an OLAP application. One way to handle
sparsity is to take the structure closer to the table-based one. Thus the DB
size decreases, while the application gets slower. Therefore, other methods are
needed. This paper deals with the comparison of the two DB structures and the
limits of their usage. The new results of the paper: (1) It gives a
constructive proof that all relations can be represented in MD arrays. (2) It
also shows when the MD array representation is quicker than the table-based
one. (3) The MD representation results in smaller DB size under some
conditions. One such sufficient condition is proved in the paper. (4) A
variation of the single count header compression scheme is described with an
algorithm, which creates the compressed array from the ordered table without
materializing the uncompressed array. (5) The speed of the two different
database organizations is tested with experiments, as well. The tests are done
on benchmark as well as real life data. The experiments support the theoretical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3866</identifier>
 <datestamp>2011-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3866</id><created>2011-03-20</created><authors><author><keyname>Lei</keyname><forenames>Jiang</forenames></author><author><keyname>V&#xe1;zquez-Castro</keyname><forenames>M. A.</forenames></author></authors><title>Multibeam Satellite Frequency/Time Duality Study and Capacity
  Optimization</title><categories>cs.IT cs.NI math.IT</categories><comments>9 pages, 9 figures, Submitted to Journal of Communications and
  Networks</comments><journal-ref>Journal of Communications and Networks, vol. 13, no. 5, pp.
  472-480, Oct. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate two new candidate transmission schemes,
Non-Orthogonal Frequency Reuse (NOFR) and Beam-Hoping (BH). They operate in
different domains (frequency and time/space, respectively), and we want to know
which domain shows overall best performance. We propose a novel formulation of
the Signal-to-Interference plus Noise Ratio (SINR) which allows us to prove the
frequency/time duality of these schemes. Further, we propose two novel capacity
optimization approaches assuming per-beam SINR constraints in order to use the
satellite resources (e.g. power and bandwidth) more efficiently. Moreover, we
develop a general methodology to include technological constraints due to
realistic implementations, and obtain the main factors that prevent the two
technologies dual of each other in practice, and formulate the technological
gap between them. The Shannon capacity (upper bound) and current
state-of-the-art coding and modulations are analyzed in order to quantify the
gap and to evaluate the performance of the two candidate schemes. Simulation
results show significant improvements in terms of power gain, spectral
efficiency and traffic matching ratio when comparing with conventional systems,
which are designed based on uniform bandwidth and power allocation. The results
also show that BH system turns out to show a less complex design and performs
better than NOFR system specially for non-real time services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3872</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3872</id><created>2011-03-20</created><updated>2011-06-19</updated><authors><author><keyname>Wang</keyname><forenames>Xing M.</forenames></author></authors><title>Probability Bracket Notation, Term Vector Space, Concept Fock Space and
  Induced Probabilistic IR Models</title><categories>cs.IR math-ph math.MP math.PR</categories><comments>23 pages; added a simple example of Bayesian inference; added more
  test scenarios (e.g., weight formulas); added more references</comments><acm-class>H.3.3; G.3; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After a brief introduction to Probability Bracket Notation (PBN) for discrete
random variables in time-independent probability spaces, we apply both PBN and
Dirac notation to investigate probabilistic modeling for information retrieval
(IR). We derive the expressions of relevance of document to query (RDQ) for
various probabilistic models, induced by Term Vector Space (TVS) and by Concept
Fock Space (CFS). The inference network model (INM) formula is symmetric and
can be used to evaluate relevance of document to document (RDD); the
CFS-induced models contain ingredients of all three classical IR models. The
relevance formulas are tested and compared on different scenarios against a
famous textbook example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3882</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3882</id><created>2011-03-20</created><updated>2012-05-10</updated><authors><author><keyname>Bavirisetti</keyname><forenames>Teja Damodaram</forenames></author><author><keyname>Abhinav</keyname><forenames>G.</forenames></author><author><keyname>Prasad</keyname><forenames>K.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Transform Approach to Linear Network Coding for Acyclic Networks with
  Delay</title><categories>cs.IT math.IT</categories><comments>Edits to Section II A, Theorem 4, Theorem 5. Lemma 4 newly added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The algebraic formulation for linear network coding in acyclic networks with
the links having integer delay is well known. Based on this formulation, for a
given set of connections over an arbitrary acyclic network with integer delay
assumed for the links, the output symbols at the sink nodes, at any given time
instant, is a \mathbb{F}_{q}$-linear combination of the input symbols across
different generations, where $\mathbb{F}_{q}$ denotes the field over which the
network operates. We use finite-field discrete fourier transform (DFT) to
convert the output symbols at the sink nodes, at any given time instant, into a
$\mathbb{F}_{q}$-linear combination of the input symbols generated during the
same generation. We call this as transforming the acyclic network with delay
into {\em $n$-instantaneous networks} ($n$ is sufficiently large). We show that
under certain conditions, there exists a network code satisfying sink demands
in the usual (non-transform) approach if and only if there exists a network
code satisfying sink demands in the transform approach. Furthermore, we show
that the transform method (along with the use of alignment strategies) can be
employed to achieve half the rate corresponding to the individual
source-destination min-cut (which are assumed to be equal to 1) for some
classes of three-source three-destination unicast network with delays, when the
zero-interference conditions are not satisfied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3885</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3885</id><created>2011-03-20</created><authors><author><keyname>Li</keyname><forenames>Jin-Hao</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author><author><keyname>Tsai</keyname><forenames>Yu-Lun</forenames></author></authors><title>Feedback Reduction for Random Beamforming in Multiuser MIMO Broadcast
  Channel</title><categories>cs.IT math.IT</categories><comments>25 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the multiuser multiple-input multiple-output (MIMO) downlink channel, the
users feedback their channel state information (CSI) to help the base station
(BS) schedule users and improve the system sum rate. However, this incurs a
large aggregate feedback bandwidth which grows linearly with the number of
users. In this paper, we propose a novel scheme to reduce the feedback load in
a downlink orthogonal space division multiple access (SDMA) system with
zero-forcing receivers by allowing the users to dynamically determine the
number of feedback bits to use according to multiple decision thresholds.
Through theoretical analysis, we show that, while keeping the aggregate
feedback load of the entire system constant regardless of the number of users,
the proposed scheme almost achieves the optimal asymptotic sum rate scaling
with respect to the number of users (also known as the multiuser diversity).
Specifically, given the number of thresholds, the proposed scheme can achieve a
constant portion of the optimal sum rate achievable only by the system where
all the users always feedback, and the remaining portion (referred to as the
sum rate loss) decreases exponentially to zero as the number of thresholds
increases. By deriving a tight upper bound for the sum rate loss, the minimum
number of thresholds for a given tolerable sum rate loss is determined. In
addition, a fast bit allocation method is discussed for the proposed scheme,
and the simulation results show that the sum rate performances with the complex
optimal bit allocation method and with the fast algorithm are almost the same.
We compare our multi-threshold scheme to some previously proposed feedback
schemes. Through simulation, we demonstrate that the proposed scheme can reduce
the feedback load and utilize the limited feedback bandwidth more effectively
than the existing feedback methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3890</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3890</id><created>2011-03-20</created><updated>2011-05-08</updated><authors><author><keyname>Gnedin</keyname><forenames>Alexander</forenames></author></authors><title>The Monty Hall Problem: Switching is Forced by the Strategic Thinking</title><categories>math.HO cs.GT</categories><msc-class>97A20, 91A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game versions of the Monty Hall Problem are discussed. The focus is on the
principle of eliminating the dominated strategies, both in the zero-sum and
noncooperative formulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3903</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3903</id><created>2011-03-20</created><authors><author><keyname>Rand</keyname><forenames>Alexander</forenames></author></authors><title>Improved Examples of Non-Termination for Ruppert's Algorithm</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improving the best known examples, two planar straight-line graphs which
cause the non-termination of Ruppert's algorithm for a minimum angle threshold
as low as 29.06 degrees are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3904</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3904</id><created>2011-03-20</created><authors><author><keyname>Harabor</keyname><forenames>Daniel</forenames></author><author><keyname>Kilby</keyname><forenames>Philip</forenames></author></authors><title>Informed Heuristics for Guiding Stem-and-Cycle Ejection Chains</title><categories>cs.AI cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The state of the art in local search for the Traveling Salesman Problem is
dominated by ejection chain methods utilising the Stem-and-Cycle reference
structure. Though effective such algorithms employ very little information in
their successor selection strategy, typically seeking only to minimise the cost
of a move. We propose an alternative approach inspired from the AI literature
and show how an admissible heuristic can be used to guide successor selection.
We undertake an empirical analysis and demonstrate that this technique often
produces better results than less informed strategies albeit at the cost of
running in higher polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3911</identifier>
 <datestamp>2015-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3911</id><created>2011-03-20</created><updated>2015-04-24</updated><authors><author><keyname>Chen</keyname><forenames>Danny Z.</forenames></author><author><keyname>Wang</keyname><forenames>Haitao</forenames></author></authors><title>Computing Shortest Paths among Curved Obstacles in the Plane</title><categories>cs.CG cs.DS</categories><comments>45 pages, 21 figures; to appear in TALG; an extended-abstract
  appeared in SoCG 2013</comments><journal-ref>ACM Transactions on Algorithms, Vol. 11(4), Article No. 26, 2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in computational geometry is to compute an
obstacle-avoiding Euclidean shortest path between two points in the plane. The
case of this problem on polygonal obstacles is well studied. In this paper, we
consider the problem version on curved obstacles, commonly modeled as
splinegons. A splinegon can be viewed as replacing each edge of a polygon by a
convex curved edge (polygons are special splinegons). Each curved edge is
assumed to be of O(1) complexity. Given in the plane two points s and t and a
set of $h$ pairwise disjoint splinegons with a total of $n$ vertices, we
compute a shortest s-to-t path avoiding the splinegons, in
$O(n+h\log^{1+\epsilon}h+k)$ time, where k is a parameter sensitive to the
structures of the input splinegons and is upper-bounded by $O(h^2)$. In
particular, when all splinegons are convex, $k$ is proportional to the number
of common tangents in the free space (called &quot;free common tangents&quot;) among the
splinegons. We develop techniques for solving the problem on the general
(non-convex) splinegon domain, which also improve several previous results. In
particular, our techniques produce an optimal output-sensitive algorithm for a
basic visibility problem of computing all free common tangents among $h$
pairwise disjoint convex splinegons with a total of $n$ vertices. Our algorithm
runs in $O(n+h\log h+k)$ time and $O(n)$ space, where $k$ is the number of all
free common tangents. Even for the special case where all splinegons are convex
polygons, the previously best algorithm for this visibility problem takes
$O(n+h^2\log n)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3915</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3915</id><created>2011-03-20</created><authors><author><keyname>Wong</keyname><forenames>Chan Wong</forenames></author><author><keyname>Wong</keyname><forenames>Tan F.</forenames></author><author><keyname>Shea</keyname><forenames>John M.</forenames></author></authors><title>LDPC Code Design for the BPSK-constrained Gaussian Wiretap Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE GLOBECOM 2011 - Communication Theory Symposium</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coding scheme based on irregular low-density parity-check (LDPC) codes is
proposed to send secret messages from a source over the Gaussian wiretap
channel to a destination in the presence of a wiretapper, with the restriction
that the source can send only binary phase-shift keyed (BPSK) symbols. The
secrecy performance of the proposed coding scheme is measured by the secret
message rate through the wiretap channel as well as the equivocation rate about
the message at the wiretapper. A code search procedure is suggested to obtain
irregular LDPC codes that achieve good secrecy performance in such context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3933</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3933</id><created>2011-03-21</created><updated>2011-06-22</updated><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Product Constructions for Perfect Lee Codes</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well known conjecture of Golomb and Welch is that the only nontrivial
perfect codes in the Lee and Manhattan metrics have length two or minimum
distance three. This problem and related topics were subject for extensive
research in the last forty years. In this paper two product constructions for
perfect Lee codes and diameter perfect Lee codes are presented. These
constructions yield a large number of nonlinear perfect codes and nonlinear
diameter perfect codes in the Lee and Manhattan metrics. A short survey and
other related problems on perfect codes in the Lee and the Manhattan metrics
are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3949</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3949</id><created>2011-03-21</created><updated>2012-11-01</updated><authors><author><keyname>Gomes</keyname><forenames>Ana Sofia</forenames></author><author><keyname>Alferes</keyname><forenames>Jose Julio</forenames></author><author><keyname>Swift</keyname><forenames>Terrance</forenames></author></authors><title>A Goal-Directed Implementation of Query Answering for Hybrid MKNF
  Knowledge Bases</title><categories>cs.AI</categories><doi>10.1017/S1471068412000439</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontologies and rules are usually loosely coupled in knowledge representation
formalisms. In fact, ontologies use open-world reasoning while the leading
semantics for rules use non-monotonic, closed-world reasoning. One exception is
the tightly-coupled framework of Minimal Knowledge and Negation as Failure
(MKNF), which allows statements about individuals to be jointly derived via
entailment from an ontology and inferences from rules. Nonetheless, the
practical usefulness of MKNF has not always been clear, although recent work
has formalized a general resolution-based method for querying MKNF when rules
are taken to have the well-founded semantics, and the ontology is modeled by a
general oracle. That work leaves open what algorithms should be used to relate
the entailments of the ontology and the inferences of rules. In this paper we
provide such algorithms, and describe the implementation of a query-driven
system, CDF-Rules, for hybrid knowledge bases combining both (non-monotonic)
rules under the well-founded semantics and a (monotonic) ontology, represented
by a CDF Type-1 (ALQ) theory. To appear in Theory and Practice of Logic
Programming (TPLP)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3950</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3950</id><created>2011-03-21</created><authors><author><keyname>Hassidim</keyname><forenames>Avinatan</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Mansour</keyname><forenames>Yishay</forenames></author><author><keyname>Nisan</keyname><forenames>Noam</forenames></author></authors><title>Non-Price Equilibria in Markets of Discrete Goods</title><categories>cs.GT</categories><comments>ACM EC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study markets of indivisible items in which price-based (Walrasian)
equilibria often do not exist due to the discrete non-convex setting. Instead
we consider Nash equilibria of the market viewed as a game, where players bid
for items, and where the highest bidder on an item wins it and pays his bid. We
first observe that pure Nash-equilibria of this game excatly correspond to
price-based equilibiria (and thus need not exist), but that mixed-Nash
equilibria always do exist, and we analyze their structure in several simple
cases where no price-based equilibrium exists. We also undertake an analysis of
the welfare properties of these equilibria showing that while pure equilibria
are always perfectly efficient (&quot;first welfare theorem&quot;), mixed equilibria need
not be, and we provide upper and lower bounds on their amount of inefficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3952</identifier>
 <datestamp>2011-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3952</id><created>2011-03-21</created><updated>2011-11-22</updated><authors><author><keyname>D&#x119;bowski</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Mixing, Ergodic, and Nonergodic Processes with Rapidly Growing
  Information between Blocks</title><categories>cs.IT cs.CL math.IT</categories><comments>21 pages</comments><msc-class>37A25, 94A17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct mixing processes over an infinite alphabet and ergodic processes
over a finite alphabet for which Shannon mutual information between adjacent
blocks of length $n$ grows as $n^\beta$, where $\beta\in(0,1)$. The processes
are a modification of nonergodic Santa Fe processes, which were introduced in
the context of natural language modeling. The rates of mutual information for
the latter processes are alike and also established in this paper. As an
auxiliary result, it is shown that infinite direct products of mixing processes
are also mixing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.3954</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.3954</id><created>2011-03-21</created><authors><author><keyname>Bailleux</keyname><forenames>Olivier</forenames></author></authors><title>BoolVar/PB v1.0, a java library for translating pseudo-Boolean
  constraints into CNF formulae</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BoolVar/PB is an open source java library dedicated to the translation of
pseudo-Boolean constraints into CNF formulae. Input constraints can be
categorized with tags. Several encoding schemes are implemented in a way that
each input constraint can be translated using one or several encoders,
according to the related tags. The library can be easily extended by adding new
encoders and / or new output formats.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4007</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4007</id><created>2011-03-21</created><authors><author><keyname>Permuter</keyname><forenames>Haim</forenames></author><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author></authors><title>Multiple Access Channel with Partial and Controlled Cribbing Encoders</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a multiple access channel (MAC) with partial
cribbing encoders. This means that each of two encoders obtains a deterministic
function of the other encoder output with or without delay. The partial
cribbing scheme is especially motivated by the additive noise Gaussian MAC
since perfect cribbing results in the degenerated case of full cooperation
between the encoders and requires an infinite entropy link. We derive a single
letter characterization of the capacity of the MAC with partial cribbing for
the cases of causal and strictly causal partial cribbing. Several numerical
examples, such as quantized cribbing, are presented. We further consider and
derive the capacity region where the cribbing depends on actions that are
functions of the previous cribbed observations. In particular, we consider a
scenario where the action is &quot;to crib or not to crib&quot; and show that a naive
time-sharing strategy is not optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4012</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4012</id><created>2011-03-21</created><authors><author><keyname>Pompei</keyname><forenames>Simone</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author><author><keyname>Tria</keyname><forenames>Francesca</forenames></author></authors><title>On the accuracy of language trees</title><categories>physics.soc-ph cs.CL q-bio.QM</categories><comments>36 pages, 14 figures</comments><doi>10.1371/journal.pone.0020109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Historical linguistics aims at inferring the most likely language
phylogenetic tree starting from information concerning the evolutionary
relatedness of languages. The available information are typically lists of
homologous (lexical, phonological, syntactic) features or characters for many
different languages.
  From this perspective the reconstruction of language trees is an example of
inverse problems: starting from present, incomplete and often noisy,
information, one aims at inferring the most likely past evolutionary history. A
fundamental issue in inverse problems is the evaluation of the inference made.
A standard way of dealing with this question is to generate data with
artificial models in order to have full access to the evolutionary process one
is going to infer. This procedure presents an intrinsic limitation: when
dealing with real data sets, one typically does not know which model of
evolution is the most suitable for them. A possible way out is to compare
algorithmic inference with expert classifications. This is the point of view we
take here by conducting a thorough survey of the accuracy of reconstruction
methods as compared with the Ethnologue expert classifications. We focus in
particular on state-of-the-art distance-based methods for phylogeny
reconstruction using worldwide linguistic databases.
  In order to assess the accuracy of the inferred trees we introduce and
characterize two generalizations of standard definitions of distances between
trees. Based on these scores we quantify the relative performances of the
distance-based algorithms considered. Further we quantify how the completeness
and the coverage of the available databases affect the accuracy of the
reconstruction. Finally we draw some conclusions about where the accuracy of
the reconstructions in historical linguistics stands and about the leading
directions to improve it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4016</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4016</id><created>2011-03-21</created><authors><author><keyname>Mahmood</keyname><forenames>Kashif</forenames></author><author><keyname>Vehkaper&#xe4;</keyname><forenames>Mikko</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author></authors><title>Delay Constrained Throughput Analysis of a Correlated MIMO Wireless
  Channel</title><categories>cs.NI</categories><comments>Submitted to ICCCN 2011, 8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximum traffic arrival rate at the network for a given delay guarantee
(delay constrained throughput) has been well studied for wired channels.
However, few results are available for wireless channels, especially when
multiple antennas are employed at the transmitter and receiver. In this work,
we analyze the network delay constrained throughput of a multiple input
multiple output (MIMO) wireless channel with time-varying spatial correlation.
The MIMO channel is modeled via its virtual representation, where the
individual spatial paths between the antenna pairs are Gilbert-Elliot channels.
The whole system is then described by a K-State Markov chain, where K depends
upon the degree of freedom (DOF) of the channel. We prove that the DOF based
modeling is indeed accurate. Furthermore, we study the impact of the delay
requirements at the network layer, violation probability and the number of
antennas on the throughput under different fading speeds and signal strength.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4039</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4039</id><created>2011-03-21</created><authors><author><keyname>Dubbini</keyname><forenames>Nevio</forenames></author><author><keyname>Piccoli</keyname><forenames>Benedetto</forenames></author><author><keyname>Bicchi</keyname><forenames>Antonio</forenames></author></authors><title>Left invertibility of discrete-time output-quantized systems: the linear
  case with finite inputs</title><categories>math.OC cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies left invertibility of discrete-time linear
output-quantized systems. Quantized outputs are generated according to a given
partition of the state-space, while inputs are sequences on a finite alphabet.
Left invertibility, i.e. injectivity of I/O map, is reduced to left
D-invertibility, under suitable conditions. While left invertibility takes into
account membership to sets of a given partition, left D-invertibility considers
only membership to a single set, and is much easier to detect. The condition
under which left invertibility and left D-invertibility are equivalent is that
the elements of the dynamic matrix of the system form an algebraically
independent set. Our main result is a method to compute left D-invertibility
for all linear systems with no eigenvalue of modulus one. Therefore we are able
to check left invertibility of output-quantized linear systems for a full
measure set of matrices. Some examples are presented to show the application of
the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4056</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4056</id><created>2011-03-21</created><authors><author><keyname>Dabrowski</keyname><forenames>Robert</forenames></author><author><keyname>Stencel</keyname><forenames>Krzysztof</forenames></author><author><keyname>Timoszuk</keyname><forenames>Grzegorz</forenames></author></authors><title>Software is a directed multigraph (and so is software process)</title><categories>cs.SE</categories><comments>4 pages, 2 figures</comments><acm-class>D.2.8; D.2.9; D.2.11; D.2.13</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a software system, its architecture is typically defined as the
fundamental organization of the system incorporated by its components, their
relationships to one another and their environment, and the principles
governing their design. If contributed to by the artifacts coresponding to
engineering processes that govern the system's evolution, the definition gets
natually extended into the architecture of software and software process.
Obviously, as long as there were no software systems, managing their
architecture was no problem at all; when there were only small systems,
managing their architecture became a mild problem; and now we have gigantic
software systems, and managing their architecture has become an equally
gigantic problem (to paraphrase Edsger Dijkstra). In this paper we propose a
simple, yet we believe effective, model for organizing architecture of software
systems. First of all we postulate that only a hollistic approach that supports
continuous integration and verification for all software and software process
architectural artifacts is the one worth taking. Next we indicate a graph-based
model that not only allows collecting and maintaining the architectural
knowledge in respect to both software and software process, but allows to
conveniently create various quantitive metric to asses their respective quality
or maturity. Such model is actually independent of the development
methodologies that are currently in-use, that is it could well be applied for
projects managed in an adaptive, as well as in a formal approach. Eventually we
argue that the model could actually be implemented by already existing tools,
in particular graph databases are a convenient implementation of architectural
repository.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4059</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4059</id><created>2011-03-21</created><updated>2011-06-24</updated><authors><author><keyname>Marceau</keyname><forenames>Vincent</forenames></author><author><keyname>No&#xeb;l</keyname><forenames>Pierre-Andr&#xe9;</forenames></author><author><keyname>H&#xe9;bert-Dufresne</keyname><forenames>Laurent</forenames></author><author><keyname>Allard</keyname><forenames>Antoine</forenames></author><author><keyname>Dub&#xe9;</keyname><forenames>Louis J.</forenames></author></authors><title>Modeling the dynamical interaction between epidemics on overlay networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>Accepted for publication in Phys. Rev. E. 15 pages, 7 figures</comments><journal-ref>Phys. Rev. E 84, 026105, (2011)</journal-ref><doi>10.1103/PhysRevE.84.026105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Epidemics seldom occur as isolated phenomena. Typically, two or more viral
agents spread within the same host population and may interact dynamically with
each other. We present a general model where two viral agents interact via an
immunity mechanism as they propagate simultaneously on two networks connecting
the same set of nodes. Exploiting a correspondence between the propagation
dynamics and a dynamical process performing progressive network generation, we
develop an analytic approach that accurately captures the dynamical interaction
between epidemics on overlay networks. The formalism allows for overlay
networks with arbitrary joint degree distribution and overlap. To illustrate
the versatility of our approach, we consider a hypothetical delayed
intervention scenario in which an immunizing agent is disseminated in a host
population to hinder the propagation of an undesirable agent (e.g. the spread
of preventive information in the context of an emerging infectious disease).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4065</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4065</id><created>2011-03-21</created><updated>2011-03-24</updated><authors><author><keyname>Cizelj</keyname><forenames>Igor</forenames></author><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Lahijanian</keyname><forenames>Morteza</forenames></author><author><keyname>Pinto</keyname><forenames>Alessandro</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author></authors><title>Probabilistically Safe Vehicle Control in a Hostile Environment</title><categories>cs.SY cs.RO math.OC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we present an approach to control a vehicle in a hostile
environment with static obstacles and moving adversaries. The vehicle is
required to satisfy a mission objective expressed as a temporal logic
specification over a set of properties satisfied at regions of a partitioned
environment. We model the movements of adversaries in between regions of the
environment as Poisson processes. Furthermore, we assume that the time it takes
for the vehicle to traverse in between two facets of each region is
exponentially distributed, and we obtain the rate of this exponential
distribution from a simulator of the environment. We capture the motion of the
vehicle and the vehicle updates of adversaries distributions as a Markov
Decision Process. Using tools in Probabilistic Computational Tree Logic, we
find a control strategy for the vehicle that maximizes the probability of
accomplishing the mission objective. We demonstrate our approach with
illustrative case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4071</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4071</id><created>2011-03-21</created><authors><author><keyname>Cole</keyname><forenames>Richard</forenames></author><author><keyname>Ramachandran</keyname><forenames>Vijaya</forenames></author></authors><title>Efficient Resource Oblivious Algorithms for Multicores</title><categories>cs.DC cs.DS</categories><acm-class>F.2.2; C.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the design of efficient algorithms for a multicore computing
environment with a global shared memory and p cores, each having a cache of
size M, and with data organized in blocks of size B. We characterize the class
of `Hierarchical Balanced Parallel (HBP)' multithreaded computations for
multicores. HBP computations are similar to the hierarchical divide &amp; conquer
algorithms considered in recent work, but have some additional features that
guarantee good performance even when accounting for the cache misses due to
false sharing. Most of our HBP algorithms are derived from known
cache-oblivious algorithms with high parallelism, however we incorporate new
techniques that reduce the effect of false-sharing.
  Our approach to addressing false sharing costs (or more generally, block
misses) is to ensure that any task that can be stolen shares O(1) blocks with
other tasks. We use a gapping technique for computations that have larger than
O(1) block sharing. We also incorporate the property of limited access writes
analyzed in a companion paper, and we bound the cost of accessing shared blocks
on the execution stacks of tasks.
  We present the Priority Work Stealing (PWS) scheduler, and we establish that,
given a sufficiently `tall' cache, PWS deterministically schedules several
highly parallel HBP algorithms, including those for scans, matrix computations
and FFT, with cache misses bounded by the sequential complexity, when
accounting for both traditional cache misses and for false sharing. We also
present a list ranking algorithm with almost optimal bounds. PWS schedules
without using cache or block size information, and uses knowledge of processors
only to the extent of determining the available locations from which tasks may
be stolen; thus it schedules resource-obliviously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4072</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4072</id><created>2011-03-21</created><updated>2011-08-30</updated><authors><author><keyname>Jiang</keyname><forenames>Jonathan Q.</forenames></author><author><keyname>McQuay</keyname><forenames>Lisa J.</forenames></author></authors><title>Modularity functions maximization with nonnegative relaxation
  facilitates community detection in networks</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.physa.2011.08.043</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show here that the problem of maximizing a family of quantitative
functions, encompassing both the modularity (Q-measure) and modularity density
(D-measure), for community detection can be uniformly understood as a
combinatoric optimization involving the trace of a matrix called modularity
Laplacian. Instead of using traditional spectral relaxation, we apply
additional nonnegative constraint into this graph clustering problem and design
efficient algorithms to optimize the new objective. With the explicit
nonnegative constraint, our solutions are very close to the ideal community
indicator matrix and can directly assign nodes into communities. The
near-orthogonal columns of the solution can be reformulated as the posterior
probability of corresponding node belonging to each community. Therefore, the
proposed method can be exploited to identify the fuzzy or overlapping
communities and thus facilitates the understanding of the intrinsic structure
of networks. Experimental results show that our new algorithm consistently,
sometimes significantly, outperforms the traditional spectral relaxation
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4080</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4080</id><created>2011-03-21</created><authors><author><keyname>Wagoum</keyname><forenames>A. U. Kemloh</forenames></author><author><keyname>Seyfried</keyname><forenames>A.</forenames></author><author><keyname>Holl</keyname><forenames>S.</forenames></author></authors><title>Modelling dynamic route choice of pedestrians to assess the criticality
  of building evacuation</title><categories>cs.OH</categories><comments>15 pages, 34 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an event-driven way finding algorithm for pedestrians in
an evacuation scenario, which operates on a graph-based structure. The
motivation of each pedestrian is to leave the facility. The events used to
redirect pedestrians include the identification of a jam situation and/or
identification of a better route than the current. This study considers two
types of pedestrians: familiar and unfamiliar with the facility. Four
strategies are modelled to cover those groups. The modelled strategies are the
shortest path (local and global); They are combined with a quickest path
approach, which is based on an observation principle. In the quickest path
approach, pedestrians take their decisions based on the observed environment
and are routed dynamically in the network using an appropriate cost benefit
analysis function. The dynamic modelling of route choice with different
strategies and types of pedestrians considers the manifold of in uences which
appears in the real system and raises questions about the criticality of an
evacuation process. To address this question criteria are elaborated. The
criteria we focus on in this contribution are the evacuation time, the
individual times spent in jam, the jam size evolution and the overall jam size
itself. The in uences of the different strategies on those evaluation criteria
are investigated. The sensibility of the system to disturbances (e.g. broken
escape route) is also analysed. Keywords: pedestrian dynamics, routing,
quickest path, evacuation, jam, critical state
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4086</identifier>
 <datestamp>2013-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4086</id><created>2011-03-21</created><updated>2013-01-09</updated><authors><author><keyname>Oggier</keyname><forenames>Fr&#xe9;d&#xe9;rique</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Lattice Codes for the Wiretap Gaussian Channel: Construction and
  Analysis</title><categories>cs.IT math.IT</categories><comments>43 pages, 16 figures, submitted to IEEE Trans. on Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Gaussian wiretap channel, where two legitimate players Alice
and Bob communicate over an additive white Gaussian noise (AWGN) channel, while
Eve is eavesdropping, also through an AWGN channel. We propose a coding
strategy based on lattice coset encoding. We analyze Eve's probability of
decoding, from which we define the secrecy gain as a design criterion for
wiretap lattice codes, expressed in terms of the lattice theta series, which
characterizes Eve's confusion as a function of the channel parameters. The
secrecy gain is studied for even unimodular lattices, and an asymptotic
analysis shows that it grows exponentially in the dimension of the lattice.
Examples of wiretap lattice codes are given. Interestingly, minimizing Eve's
probability of error involves the same optimization of the theta series as does
the flatness factor, another newly defined code design that characterizes
lattice codes that achieve strong secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4090</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4090</id><created>2011-03-21</created><updated>2011-04-22</updated><authors><author><keyname>Louren&#xe7;o</keyname><forenames>An&#xe1;lia</forenames></author><author><keyname>Conover</keyname><forenames>Michael</forenames></author><author><keyname>Wong</keyname><forenames>Andrew</forenames></author><author><keyname>Nematzadeh</keyname><forenames>Azadeh</forenames></author><author><keyname>Pan</keyname><forenames>Fengxia</forenames></author><author><keyname>Shatkay</keyname><forenames>Hagit</forenames></author><author><keyname>Rocha</keyname><forenames>Luis M.</forenames></author></authors><title>A Linear Classifier Based on Entity Recognition Tools and a Statistical
  Approach to Method Extraction in the Protein-Protein Interaction Literature</title><categories>q-bio.QM cs.CL cs.IR cs.LG</categories><comments>BMC Bioinformatics. In Press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We participated, in the Article Classification and the Interaction Method
subtasks (ACT and IMT, respectively) of the Protein-Protein Interaction task of
the BioCreative III Challenge. For the ACT, we pursued an extensive testing of
available Named Entity Recognition and dictionary tools, and used the most
promising ones to extend our Variable Trigonometric Threshold linear
classifier. For the IMT, we experimented with a primarily statistical approach,
as opposed to employing a deeper natural language processing strategy. Finally,
we also studied the benefits of integrating the method extraction approach that
we have used for the IMT into the ACT pipeline. For the ACT, our linear article
classifier leads to a ranking and classification performance significantly
higher than all the reported submissions. For the IMT, our results are
comparable to those of other systems, which took very different approaches. For
the ACT, we show that the use of named entity recognition tools leads to a
substantial improvement in the ranking and classification of articles relevant
to protein-protein interaction. Thus, we show that our substantially expanded
linear classifier is a very competitive classifier in this domain. Moreover,
this classifier produces interpretable surfaces that can be understood as
&quot;rules&quot; for human understanding of the classification. In terms of the IMT
task, in contrast to other participants, our approach focused on identifying
sentences that are likely to bear evidence for the application of a PPI
detection method, rather than on classifying a document as relevant to a
method. As BioCreative III did not perform an evaluation of the evidence
provided by the system, we have conducted a separate assessment; the evaluators
agree that our tool is indeed effective in detecting relevant evidence for PPI
detection methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4093</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4093</id><created>2011-03-21</created><updated>2011-03-22</updated><authors><author><keyname>Fine</keyname><forenames>Benjamin</forenames></author><author><keyname>Habeeb</keyname><forenames>Maggie</forenames></author><author><keyname>Kahrobaei</keyname><forenames>Delaram</forenames></author><author><keyname>Rosenberger</keyname><forenames>Gerhard</forenames></author></authors><title>Aspects of Nonabelian Group Based Cryptography: A Survey and Open
  Problems</title><categories>cs.CR math.GR</categories><msc-class>68 (Primary), 20 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most common public key cryptosystems and public key exchange protocols
presently in use, such as the RSA algorithm, Diffie-Hellman, and elliptic curve
methods are number theory based and hence depend on the structure of abelian
groups. The strength of computing machinery has made these techniques
theoretically susceptible to attack and hence recently there has been an active
line of research to develop cryptosystems and key exchange protocols using
noncommutative cryptographic platforms. This line of investigation has been
given the broad title of noncommutative algebraic cryptography. This was
initiated by two public key protocols that used the braid groups, one by Ko,
Lee et.al.and one by Anshel, Anshel and Goldfeld. The study of these protocols
and the group theory surrounding them has had a large effect on research in
infinite group theory. In this paper we survey these noncommutative group based
methods and discuss several ideas in abstract infinite group theory that have
arisen from them. We then present a set of open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4118</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4118</id><created>2011-03-21</created><authors><author><keyname>Thielemann</keyname><forenames>Henning</forenames></author></authors><title>Sampling-rate-aware noise generation</title><categories>cs.SD</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the generation of discrete white noise. Despite
this seems to be a simple problem, common noise generator implementations do
not deliver comparable results at different sampling rates. First we define
what we mean with &quot;comparable results&quot;. From this we conclude, that the
variance of the random variables shall grow proportionally to the sampling
rate. Eventually we consider how noise behaves under common signal
transformations, such as frequency filters, quantisation and impulse generation
and we explore how these signal transformations must be designed in order
generate sampling-rate-aware results when applied to white noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4125</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4125</id><created>2011-03-21</created><updated>2011-04-06</updated><authors><author><keyname>Reem</keyname><forenames>Daniel</forenames></author></authors><title>The geometric stability of Voronoi diagrams with respect to small
  changes of the sites</title><categories>cs.CG math.FA</categories><comments>30 pages (13 pages in appendices); a few corrections and additions,
  mainly regarding the references and the counterexamples; minor additional
  modifications; Theorem 8.13 and the figures were slightly improved; a
  modification of this paper will appear in SoCG 2011</comments><msc-class>46N99, 68U05, 46B20, 65D18</msc-class><acm-class>F.2.2; G.0; I.3.5</acm-class><journal-ref>Extended abstract in: Proceedings of the 27th Annual ACM Symposium
  on Computational Geometry (SoCG 2011), pp. 254-263</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voronoi diagrams appear in many areas in science and technology and have
numerous applications. They have been the subject of extensive investigation
during the last decades. Roughly speaking, they are a certain decomposition of
a given space into cells, induced by a distance function and by a tuple of
subsets called the generators or the sites. Consider the following question:
does a small change of the sites, e.g., of their position or shape, yield a
small change in the corresponding Voronoi cells? This question is by all means
natural and fundamental, since in practice one approximates the sites either
because of inexact information about them, because of inevitable numerical
errors in their representation, for simplification purposes and so on, and it
is important to know whether the resulting Voronoi cells approximate the real
ones well. The traditional approach to Voronoi diagrams, and, in particular, to
(variants of) this question, is combinatorial. However, it seems that there has
been a very limited discussion in the geometric sense (the shape of the cells),
mainly an intuitive one, without proofs, in Euclidean spaces. We formalize this
question precisely, and then show that the answer is positive in the case of
R^d, or, more generally, in (possibly infinite dimensional) uniformly convex
normed spaces, assuming there is a common positive lower bound on the distance
between the sites. Explicit bounds are given, and we allow infinitely many
sites of a general form. The relevance of this result is illustrated using
several pictures and many real-world and theoretical examples and
counterexamples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4133</identifier>
 <datestamp>2014-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4133</id><created>2011-03-21</created><updated>2012-09-17</updated><authors><author><keyname>Hanus</keyname><forenames>Michael</forenames></author><author><keyname>Koschnicke</keyname><forenames>Sven</forenames></author></authors><title>An ER-based Framework for Declarative Web Programming</title><categories>cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP)</comments><doi>10.1017/S1471068412000385</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a framework to support the implementation of web-based systems
intended to manipulate data stored in relational databases. Since the
conceptual model of a relational database is often specified as an
entity-relationship (ER) model, we propose to use the ER model to generate a
complete implementation in the declarative programming language Curry. This
implementation contains operations to create and manipulate entities of the
data model, supports authentication, authorization, session handling, and the
composition of individual operations to user processes. Furthermore, the
implementation ensures the consistency of the database w.r.t. the data
dependencies specified in the ER model, i.e., updates initiated by the user
cannot lead to an inconsistent state of the database. In order to generate a
high-level declarative implementation that can be easily adapted to individual
customer requirements, the framework exploits previous works on declarative
database programming and web user interface construction in Curry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4142</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4142</id><created>2011-03-21</created><authors><author><keyname>Cole</keyname><forenames>Richard</forenames></author><author><keyname>Ramachandran</keyname><forenames>Vijaya</forenames></author></authors><title>Analysis of Randomized Work Stealing with False Sharing</title><categories>cs.DC cs.DS</categories><acm-class>F.2.2; C.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the cache miss cost of algorithms when scheduled using
randomized work stealing (RWS) in a parallel environment, taking into account
the effects of false sharing.
  First, prior analyses (due to Acar et al.) are extended to incorporate false
sharing. However, to control the possible delays due to false sharing, some
restrictions on the algorithms seem necessary. Accordingly, the class of
Hierarchical Tree algorithms is introduced and their performance analyzed.
  In addition, the paper analyzes the performance of a subclass of the
Hierarchical Tree Algorithms, called HBP algorithms, when scheduled using RWS;
improved complexity bounds are obtained for this subclass. This class was
introduced in a companion paper with efficient resource oblivious computation
in mind.
  Finally, we note that in a scenario in which there is no false sharing the
results in this paper match prior bounds for cache misses but with reduced
assumptions, and in particular with no need for a bounding concave function for
the cost of cache misses as in prior work by Frigo and Strumpen. This allows
non-trivial cache miss bounds in this case to be obtained for a larger class of
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4168</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4168</id><created>2011-03-21</created><updated>2011-05-02</updated><authors><author><keyname>Sz&#xe9;pk&#xfa;ti</keyname><forenames>Istv&#xe1;n</forenames></author></authors><title>Caching in Multidimensional Databases</title><categories>cs.DB</categories><comments>14 pages, 5 figures, 8 tables. Paper presented at the Fifth
  Conference of PhD Students in Computer Science, Szeged, Hungary, 27 - 30 June
  2006. For further details, please refer to
  http://www.inf.u-szeged.hu/~szepkuti/papers.html#caching</comments><journal-ref>Periodica Polytechnica Electrical Engineering, Vol. 51, Number
  3-4, pp. 119-132, 2007</journal-ref><doi>10.3311/pp.ee.2007-3-4.06</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One utilisation of multidimensional databases is the field of On-line
Analytical Processing (OLAP). The applications in this area are designed to
make the analysis of shared multidimensional information fast [9]. On one hand,
speed can be achieved by specially devised data structures and algorithms. On
the other hand, the analytical process is cyclic. In other words, the user of
the OLAP application runs his or her queries one after the other. The output of
the last query may be there (at least partly) in one of the previous results.
Therefore caching also plays an important role in the operation of these
systems. However, caching itself may not be enough to ensure acceptable
performance. Size does matter: The more memory is available, the more we gain
by loading and keeping information in there. Oftentimes, the cache size is
fixed. This limits the performance of the multidimensional database, as well,
unless we compress the data in order to move a greater proportion of them into
the memory. Caching combined with proper compression methods promise further
performance improvements. In this paper, we investigate how caching influences
the speed of OLAP systems. Different physical representations (multidimensional
and table) are evaluated. For the thorough comparison, models are proposed. We
draw conclusions based on these models, and the conclusions are verified with
empirical data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4169</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4169</id><created>2011-03-21</created><updated>2011-04-20</updated><authors><author><keyname>Sz&#xe9;pk&#xfa;ti</keyname><forenames>Istv&#xe1;n</forenames></author></authors><title>Difference-Huffman Coding of Multidimensional Databases</title><categories>cs.DB</categories><comments>23 pages, 3 figures, 6 tables. Revised version of this paper appeared
  in Periodica Polytechnica Electrical Engineering. Please refer to
  http://arxiv.org/abs/1103.4168; Computing Research Repository, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new compression method called difference-Huffman coding (DHC) is introduced
in this paper. It is verified empirically that DHC results in a smaller
multidimensional physical representation than those for other previously
published techniques (single count header compression, logical position
compression, base-offset compression and difference sequence compression). The
article examines how caching influences the expected retrieval time of the
multidimensional and table representations of relations. A model is proposed
for this, which is then verified with empirical data. Conclusions are drawn,
based on the model and the experiment, about when one physical representation
outperforms another in terms of retrieval time. Over the tested range of
available memory, the performance for the multidimensional representation was
always much quicker than for the table representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4177</identifier>
 <datestamp>2014-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4177</id><created>2011-03-21</created><updated>2014-12-09</updated><authors><author><keyname>Wang</keyname><forenames>Lele</forenames></author><author><keyname>Naghshvar</keyname><forenames>Mohammad</forenames></author></authors><title>On the Capacity of the Noncausal Relay Channel</title><categories>cs.IT math.IT</categories><comments>19 pages, 5 figures, submitted to the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the noncausal relay channel, also known as the relay
channel with unlimited lookahead, introduced by El Gamal, Hassanpour, and
Mammen. Unlike the standard relay channel model, where the relay encodes its
signal based on the previous received output symbols, the relay in the
noncausal relay channel encodes its signal as a function of the entire received
sequence. In the existing coding schemes, the relay uses this noncausal
information solely to recover the transmitted message and then cooperates with
the sender to communicate this message to the receiver. However, it is shown in
this paper that by applying the Gelfand--Pinsker coding scheme, the relay can
take further advantage of the noncausally available information, which can
achieve strictly higher rates than existing coding schemes. This paper also
provides a new upper bound on the capacity of the noncausal relay that strictly
improves upon the cutset bound. These new lower and upper bounds on the
capacity coincide for the class of degraded noncausal relay channels and
establish the capacity for this class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4193</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4193</id><created>2011-03-21</created><authors><author><keyname>Kahrobaei</keyname><forenames>Delaram</forenames></author><author><keyname>Majewicz</keyname><forenames>Stephen</forenames></author></authors><title>On the residual solvability of generalized free products of solvable
  groups</title><categories>math.GR cs.DM</categories><comments>Discrete Mathematics &amp; Theoretical Computer Science, Vol 13, 2011</comments><msc-class>20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the residual solvability of the generalized free
product of solvable groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4195</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4195</id><created>2011-03-21</created><authors><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author></authors><title>Gossip PCA</title><categories>cs.DS cs.DC</categories><comments>13 pages, 1 figure</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Eigenvectors of data matrices play an important role in many computational
problems, ranging from signal processing to machine learning and control. For
instance, algorithms that compute positions of the nodes of a wireless network
on the basis of pairwise distance measurements require a few leading
eigenvectors of the distances matrix. While eigenvector calculation is a
standard topic in numerical linear algebra, it becomes challenging under severe
communication or computation constraints, or in absence of central scheduling.
In this paper we investigate the possibility of computing the leading
eigenvectors of a large data matrix through gossip algorithms.
  The proposed algorithm amounts to iteratively multiplying a vector by
independent random sparsification of the original matrix and averaging the
resulting normalized vectors. This can be viewed as a generalization of gossip
algorithms for consensus, but the resulting dynamics is significantly more
intricate. Our analysis is based on controlling the convergence to stationarity
of the associated Kesten-Furstenberg Markov chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4196</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4196</id><created>2011-03-21</created><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Deng</keyname><forenames>Xiaotie</forenames></author></authors><title>On Nash Dynamics of Matching Market Equilibria</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the Nash dynamics of strategic interplays of n buyers
in a matching market setup by a seller, the market maker. Taking the standard
market equilibrium approach, upon receiving submitted bid vectors from the
buyers, the market maker will decide on a price vector to clear the market in
such a way that each buyer is allocated an item for which he desires the most
(a.k.a., a market equilibrium solution). While such equilibrium outcomes are
not unique, the market maker chooses one (maxeq) that optimizes its own
objective --- revenue maximization. The buyers in turn change bids to their
best interests in order to obtain higher utilities in the next round's market
equilibrium solution.
  This is an (n+1)-person game where buyers place strategic bids to gain the
most from the market maker's equilibrium mechanism. The incentives of buyers in
deciding their bids and the market maker's choice of using the maxeq mechanism
create a wave of Nash dynamics involved in the market. We characterize Nash
equilibria in the dynamics in terms of the relationship between maxeq and mineq
(i.e., minimum revenue equilibrium), and develop convergence results for Nash
dynamics from the maxeq policy to a mineq solution, resulting an outcome
equivalent to the truthful VCG mechanism.
  Our results imply revenue equivalence between maxeq and mineq, and address
the question that why short-term revenue maximization is a poor long run
strategy, in a deterministic and dynamic setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4198</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4198</id><created>2011-03-22</created><authors><author><keyname>wenczel</keyname><forenames>rob</forenames></author><author><keyname>hill</keyname><forenames>robin</forenames></author></authors><title>Continuous-time performance limitations for overshoot and resulted
  tracking measures</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A dual formulation for the problem of determining absolute performance
limitations on overshoot, undershoot, maximum amplitude and fluctuation
minimization for continuous-time feedback systems is constructed. Determining,
for example, the minimum possible overshoot attainable by all possible
stabilizing controllers is an optimization task that cannot be expressed as a
minimum-norm problem. It is this fact, coupled with the continuous-time rather
than discrete-time formulation, that makes these problems challenging. We
extend previous results to include more general reference functions, and derive
new results (in continuous time) on the influence of pole/zero locations on
achievable time-domain performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4204</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4204</id><created>2011-03-22</created><authors><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Karampatziakis</keyname><forenames>Nikos</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Smola</keyname><forenames>Alex</forenames></author></authors><title>Parallel Online Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study parallelization of online learning, a core primitive in
machine learning. In a parallel environment all known approaches for parallel
online learning lead to delayed updates, where the model is updated using
out-of-date information. In the worst case, or when examples are temporally
correlated, delay can have a very adverse effect on the learning algorithm.
Here, we analyze and present preliminary empirical results on a set of learning
architectures based on a feature sharding approach that present various
tradeoffs between delay, degree of parallelism, representation power and
empirical performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4218</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4218</id><created>2011-03-22</created><authors><author><keyname>Poleev</keyname><forenames>Andrej</forenames></author></authors><title>Universal Metadata Standard</title><categories>cs.DL</categories><comments>http://www.enzymes.at/download/metadata.pdf,
  urn:nbn:de:101:1-201103202935</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The creation of a next generation internet (semantic web) is impossible
without attributes, allowing the semantic association of documents and their
integration into information context. To achieve these goals, the Universal
Metadata Standard (ums) may be an ultimative tool, which could serve as a basis
for documentography, and is functionally required for interpretation of
documents by the automatic operating systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4223</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4223</id><created>2011-03-22</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>A Stochastic-Geometry Approach to Coverage in Cellular Networks with
  Multi-Cell Cooperation</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-cell cooperation is a promising approach for mitigating inter-cell
interference in dense cellular networks. Quantifying the performance of
multi-cell cooperation is challenging as it integrates physical-layer
techniques and network topologies. For tractability, existing work typically
relies on the over-simplified Wyner-type models. In this paper, we propose a
new stochastic-geometry model for a cellular network with multi-cell
cooperation, which accounts for practical factors including the irregular
locations of base stations (BSs) and the resultant path-losses. In particular,
the proposed network-topology model has three key features: i) the cells are
modeled using a Poisson random tessellation generated by Poisson distributed
BSs, ii) multi-antenna BSs are clustered using a hexagonal lattice and BSs in
the same cluster mitigate mutual interference by spatial interference
avoidance, iii) BSs near cluster edges access a different sub-channel from that
by other BSs, shielding cluster-edge mobiles from strong interference. Using
this model and assuming sparse scattering, we analyze the shapes of the outage
probabilities of mobiles served by cluster-interior BSs as the average number
$K$ of BSs per cluster increases. The outage probability of a mobile near a
cluster center is shown to be proportional to $e^{-c(2-\sqrt{\nu})^2K}$ where
$\nu$ is the fraction of BSs lying in the interior of clusters and $c$ is a
constant. Moreover, the outage probability of a typical mobile is proved to
scale proportionally with $e^{-c' (1-\sqrt{\nu})^2K}$ where $c'$ is a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4271</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4271</id><created>2011-03-22</created><updated>2011-06-02</updated><authors><author><keyname>Catanese</keyname><forenames>Salvatore</forenames></author><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Fiumara</keyname><forenames>Giacomo</forenames></author><author><keyname>Pagano</keyname><forenames>Francesco</forenames></author></authors><title>Rendering of 3D Dynamic Virtual Environments</title><categories>cs.GR cs.MM</categories><comments>8 pages, 11 figures, Proceedings of the 4th International ICST
  Conference on Simulation Tools and Techniques (2011)</comments><msc-class>68</msc-class><acm-class>H.5.1; I.2.1; I.3.7</acm-class><doi>10.4108/icst.simutools.2011.245524</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a framework for the rendering of dynamic 3D virtual
environments which can be integrated in the development of videogames. It
includes methods to manage sounds and particle effects, paged static
geometries, the support of a physics engine and various input systems. It has
been designed with a modular structure to allow future expansions. We exploited
some open-source state-of-the-art components such as OGRE, PhysX,
ParticleUniverse, etc.; all of them have been properly integrated to obtain
peculiar physical and environmental effects. The stand-alone version of the
application is fully compatible with Direct3D and OpenGL APIs and adopts OpenAL
APIs to manage audio cards. Concluding, we devised a showcase demo which
reproduces a dynamic 3D environment, including some particular effects: the
alternation of day and night infuencing the lighting of the scene, the
rendering of terrain, water and vegetation, the reproduction of sounds and
atmospheric agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4282</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4282</id><created>2011-03-22</created><updated>2011-03-30</updated><authors><author><keyname>Twigg</keyname><forenames>Andy</forenames></author><author><keyname>Byde</keyname><forenames>Andrew</forenames></author><author><keyname>Milos</keyname><forenames>Grzegorz</forenames></author><author><keyname>Moreton</keyname><forenames>Tim</forenames></author><author><keyname>Wilkes</keyname><forenames>John</forenames></author><author><keyname>Wilkie</keyname><forenames>Tom</forenames></author></authors><title>Stratified B-trees and versioning dictionaries</title><categories>cs.DS cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classic versioned data structure in storage and computer science is the
copy-on-write (CoW) B-tree -- it underlies many of today's file systems and
databases, including WAFL, ZFS, Btrfs and more. Unfortunately, it doesn't
inherit the B-tree's optimality properties; it has poor space utilization,
cannot offer fast updates, and relies on random IO to scale. Yet, nothing
better has been developed since. We describe the `stratified B-tree', which
beats all known semi-external memory versioned B-trees, including the CoW
B-tree. In particular, it is the first versioned dictionary to achieve optimal
tradeoffs between space, query and update performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4286</identifier>
 <datestamp>2013-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4286</id><created>2011-03-22</created><authors><author><keyname>Wang</keyname><forenames>Xinhua</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Design and frequency analysis of continuous finite-time-convergent
  differentiator</title><categories>cs.SY math.DS math.OC</categories><journal-ref>Aerospace Science and Technology, 2012, 18, 69-78</journal-ref><doi>10.1016/j.ast.2011.04.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a continuous finite-time-convergent differentiator is
presented based on a strong Lyapunov function. The continuous differentiator
can reduce chattering phenomenon sufficiently than normal sliding mode
differentiator, and the outputs of signal tracking and derivative estimation
are all smooth. Frequency analysis is applied to compare the continuous
differentiator with sliding mode differentiator. The beauties of the continuous
finite-time-convergent differentiator include its simplicity, restraining
noises sufficiently, and avoiding the chattering phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4295</identifier>
 <datestamp>2016-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4295</id><created>2011-03-22</created><authors><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author></authors><title>Linking Literature and Data: Status Report and Future Efforts</title><categories>astro-ph.IM cs.DL</categories><comments>9 pages, 2 figures, to appear in: Future Professional Communication
  in Astronomy II (FPCA-II)</comments><doi>10.1007/978-1-4419-8369-5_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current era of data-intensive science, it is increasingly important
for researchers to be able to have access to published results, the supporting
data, and the processes used to produce them. Six years ago, recognizing this
need, the American Astronomical Society and the Astrophysics Data Centers
Executive Committee (ADEC) sponsored an effort to facilitate the annotation and
linking of datasets during the publishing process, with limited success. I will
review the status of this effort and describe a new, more general one now being
considered in the context of the Virtual Astronomical Observatory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4298</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4298</id><created>2011-03-22</created><authors><author><keyname>Borwein</keyname><forenames>Jonathan M.</forenames></author><author><keyname>Straub</keyname><forenames>Armin</forenames></author></authors><title>Special Values of Generalized Log-sine Integrals</title><categories>math.CA cs.SC math-ph math.MP</categories><comments>8 pages, to be published in the proceedings of ISSAC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study generalized log-sine integrals at special values. At $\pi$ and
multiples thereof explicit evaluations are obtained in terms of Nielsen
polylogarithms at $\pm1$. For general arguments we present algorithmic
evaluations involving Nielsen polylogarithms at related arguments. In
particular, we consider log-sine integrals at $\pi/3$ which evaluate in terms
of polylogarithms at the sixth root of unity. An implementation of our results
for the computer algebra systems Mathematica and SAGE is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4311</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4311</id><created>2011-03-22</created><authors><author><keyname>Wang</keyname><forenames>Xinhua</forenames></author><author><keyname>Lin</keyname><forenames>Hai</forenames></author></authors><title>Design and analysis of continuous hybrid differentiator</title><categories>cs.SY math.DS math.OC</categories><journal-ref>IET Control Theory and Applications, 2011, Vol. 5, Iss. 11, pp.
  1321--1334</journal-ref><doi>10.1049/iet-cta.2010.0330</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a continuous hybrid differentiator is presented based on a
strong Lyapunov function. The differentiator design can not only reduce
sufficiently chattering phenomenon of derivative estimation by introducing a
perturbation parameter, but also the dynamical performances are improved by
adding linear correction terms to the nonlinear ones. Moreover, strong
robustness ability is obtained by integrating sliding mode items and the linear
filter. Frequency analysis is applied to compare the hybrid continuous
differentiator with sliding mode differentiator. The merits of the continuous
hybrid differentiator include the excellent dynamical performances, restraining
noises sufficiently, and avoiding the chattering phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4317</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4317</id><created>2011-03-22</created><authors><author><keyname>Cooper</keyname><forenames>Colin</forenames></author><author><keyname>Frieze</keyname><forenames>Alan</forenames></author></authors><title>Stationary distribution and cover time of random walks on random
  digraphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study properties of a simple random walk on the random digraph D_{n,p}
when np={d\log n},\; d&gt;1.
  We prove that whp the stationary probability pi_v of a vertex v is asymptotic
to deg^-(v)/m where deg^-(v) is the in-degree of v and m=n(n-1)p is the
expected number of edges of D_{n,p}. If d=d(n) tends to infinity with n, the
stationary distribution is asymptotically uniform whp.
  Using this result we prove that, for d&gt;1, whp the cover time of D_{n,p} is
asymptotic to d\log (d/(d-1))n\log n. If d=d(n) tends to infinity with n, then
the cover time is asymptotic to n\log n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4324</identifier>
 <datestamp>2015-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4324</id><created>2011-03-22</created><updated>2015-07-02</updated><authors><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>A survey of paraconsistent logics</title><categories>cs.LO math.LO</categories><comments>20 pages; references made up-to-date</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A survey of paraconsistent logics that are prominent representatives of the
different approaches that have been followed to develop paraconsistent logics
is provided. The paraconsistent logics that will be discussed are an enrichment
of Priest's logic LP, the logic RM3 from the school of relevance logic, da
Costa's logics Cn, Jaskowski's logic D2, and Subrahmanian's logics Ptau. A
deontic logic based on the first of these logics will be discussed as well.
Moreover, some proposed adaptations of the AGM theory of belief revision to
paraconsistent logics will be mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4335</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4335</id><created>2011-03-22</created><updated>2011-03-24</updated><authors><author><keyname>Randriam</keyname><forenames>Hugues</forenames></author></authors><title>Diviseurs de la forme 2D-G sans sections et rang de la multiplication
  dans les corps finis (Divisors of the form 2D-G without sections and bilinear
  complexity of multiplication in finite fields)</title><categories>math.AG cs.CC cs.IT math.IT math.NT</categories><comments>35 pages, in French; French and English abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let X be an algebraic curve, defined over a perfect field, and G a divisor on
X. If X has sufficiently many points, we show how to construct a divisor D on X
such that l(2D-G)=0, of essentially any degree such that this is compatible the
Riemann-Roch theorem. We also generalize this construction to the case of a
finite number of constraints, l(k_i.D-G_i)=0, where |k_i|\leq 2.
  Such a result was previously claimed by Shparlinski-Tsfasman-Vladut, in
relation with the Chudnovsky-Chudnovsky method for estimating the bilinear
complexity of the multiplication in finite fields based on interpolation on
curves; unfortunately, as noted by Cascudo et al., their proof was flawed. So
our work fixes the proof of Shparlinski-Tsfasman-Vladut and shows that their
estimate m_q\leq 2(1+1/(A(q)-1)) holds, at least when A(q)\geq 5. We also fix a
statement of Ballet that suffers from the same problem, and then we point out a
few other possible applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4339</identifier>
 <datestamp>2013-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4339</id><created>2011-03-22</created><updated>2013-09-30</updated><authors><author><keyname>Mironchenko</keyname><forenames>Andrii</forenames></author><author><keyname>Kozlowski</keyname><forenames>Jan</forenames></author></authors><title>Optimal allocation patterns and optimal seed mass of a perennial plant</title><categories>q-bio.PE cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel optimal allocation model for perennial plants, in which
assimilates are not allocated directly to vegetative or reproductive parts but
instead go first to a storage compartment from where they are then optimally
redistributed. We do not restrict considerations purely to periods favourable
for photosynthesis, as it was done in published models of perennial species,
but analyse the whole life period of a perennial plant. As a result, we obtain
the general scheme of perennial plant development, for which annual and
monocarpic strategies are special cases.
  We not only re-derive predictions from several previous optimal allocation
models, but also obtain more information about plants' strategies during
transitions between favourable and unfavourable seasons. One of the model's
predictions is that a plant can begin to re-establish vegetative tissues from
storage, some time before the beginning of favourable conditions, which in turn
allows for better production potential when conditions become better. By means
of numerical examples we show that annual plants with single or multiple
reproduction periods, monocarps, evergreen perennials and polycarpic perennials
can be studied successfully with the help of our unified model.
  Finally, we build a bridge between optimal allocation models and models
describing trade-offs between size and the number of seeds: a modelled plant
can control the distribution of not only allocated carbohydrates but also seed
size. We provide sufficient conditions for the optimality of producing the
smallest and largest seeds possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4340</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4340</id><created>2011-03-22</created><updated>2011-04-07</updated><authors><author><keyname>Di Benedetto</keyname><forenames>Maria D.</forenames></author><author><keyname>D'Innocenzo</keyname><forenames>Alessandro</forenames></author><author><keyname>Serra</keyname><forenames>Emmanuele</forenames></author></authors><title>Fault Tolerant Stabilizability of Multi-Hop Control Networks</title><categories>math.OC cs.SY</categories><comments>Accepted for publication; Proceedings of the 18th IFAC World
  Congress, Milan, Italy, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Multi-hop Control Network (MCN) consists of a plant where the communication
between sensor, actuator and computational unit is supported by a wireless
multi-hop communication network, and data flow is performed using scheduling
and routing of sensing and actuation data. We address the problem of
characterizing controllability and observability of a MCN, by means of
necessary and sufficient conditions on the plant dynamics and on the
communication scheduling and routing. We provide a methodology to design
scheduling and routing, in order to satisfy controllability and observability
of a MCN for any fault occurrence in a given set of configurations of failures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4342</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4342</id><created>2011-03-22</created><updated>2011-03-23</updated><authors><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>MDP Optimal Control under Temporal Logic Constraints</title><categories>cs.RO cs.SY math.OC</categories><comments>Technical report accompanying the CDC2011 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a method to automatically generate a control policy
for a dynamical system modeled as a Markov Decision Process (MDP). The control
specification is given as a Linear Temporal Logic (LTL) formula over a set of
propositions defined on the states of the MDP. We synthesize a control policy
such that the MDP satisfies the given specification almost surely, if such a
policy exists. In addition, we designate an &quot;optimizing proposition&quot; to be
repeatedly satisfied, and we formulate a novel optimization criterion in terms
of minimizing the expected cost in between satisfactions of this proposition.
We propose a sufficient condition for a policy to be optimal, and develop a
dynamic programming algorithm that synthesizes a policy that is optimal under
some conditions, and sub-optimal otherwise. This problem is motivated by
robotic applications requiring persistent tasks, such as environmental
monitoring or data gathering, to be performed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4343</identifier>
 <datestamp>2011-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4343</id><created>2011-03-22</created><authors><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Kumbhar</keyname><forenames>Abhaykumar</forenames></author></authors><title>Undirected Connectivity of Sparse Yao Graphs</title><categories>cs.CG</categories><comments>7 pages, 11 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a finite set S of points in the plane and a real value d &gt; 0, the
d-radius disk graph G^d contains all edges connecting pairs of points in S that
are within distance d of each other. For a given graph G with vertex set S, the
Yao subgraph Y_k[G] with integer parameter k &gt; 0 contains, for each point p in
S, a shortest edge pq from G (if any) in each of the k sectors defined by k
equally-spaced rays with origin p. Motivated by communication issues in mobile
networks with directional antennas, we study the connectivity properties of
Y_k[G^d], for small values of k and d. In particular, we derive lower and upper
bounds on the minimum radius d that renders Y_k[G^d] connected, relative to the
unit radius assumed to render G^d connected. We show that d=sqrt(2) is
necessary and sufficient for the connectivity of Y_4[G^d]. We also show that,
for d &lt;= ~1.056, the graph Y_3[G^d] can be disconnected, but for d &gt;=
2/sqrt(3), Y_3[G^d] is always connected. Finally, we show that Y_2[G^d] can be
disconnected, for any d &gt;= 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4358</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4358</id><created>2011-03-22</created><authors><author><keyname>Szabo</keyname><forenames>Gyorgy</forenames></author><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author></authors><title>Selfishness, fraternity, and other-regarding preference in spatial
  evolutionary games</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>7 two-column pages, 8 figures; accepted for publication in J. Theor.
  Biol</comments><journal-ref>J. Theor. Biol 299 (2012) 81-87</journal-ref><doi>10.1016/j.jtbi.2011.03.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial evolutionary games are studied with myopic players whose payoff
interest, as a personal character, is tuned from selfishness to other-regarding
preference via fraternity. The players are located on a square lattice and
collect income from symmetric two-person two-strategy (called cooperation and
defection) games with their nearest neighbors. During the elementary steps of
evolution a randomly chosen player modifies her strategy in order to maximize
stochastically her utility function composed from her own and the co-players'
income with weight factors $1-Q$ and Q. These models are studied within a wide
range of payoff parameters using Monte Carlo simulations for noisy strategy
updates and by spatial stability analysis in the low noise limit. For fraternal
players ($Q=1/2$) the system evolves into ordered arrangements of strategies in
the low noise limit in a way providing optimum payoff for the whole society.
Dominance of defectors, representing the &quot;tragedy of the commons&quot;, is found
within the regions of prisoner's dilemma and stag hunt game for selfish players
(Q=0). Due to the symmetry in the effective utility function the system
exhibits similar behavior even for Q=1 that can be interpreted as the &quot;lovers'
dilemma&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4361</identifier>
 <datestamp>2013-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4361</id><created>2011-03-22</created><updated>2013-06-04</updated><authors><author><keyname>Xia</keyname><forenames>Ge</forenames></author></authors><title>The Stretch Factor of the Delaunay Triangulation Is Less Than 1.998</title><categories>cs.CG</categories><comments>41 pages, 16 figures. A preliminary version of this paper appeared in
  the Proceedings of the 27th Annual Symposium on Computational Geometry (SoCG
  2011). This is a revised version of the previous preprint [v1]</comments><acm-class>F.2.2</acm-class><journal-ref>SIAM Journal on Computing, 42(4), 1620-1659, 2013</journal-ref><doi>10.1137/110832458</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $S$ be a finite set of points in the Euclidean plane. Let $D$ be a
Delaunay triangulation of $S$. The {\em stretch factor} (also known as {\em
dilation} or {\em spanning ratio}) of $D$ is the maximum ratio, among all
points $p$ and $q$ in $S$, of the shortest path distance from $p$ to $q$ in $D$
over the Euclidean distance $||pq||$. Proving a tight bound on the stretch
factor of the Delaunay triangulation has been a long standing open problem in
computational geometry.
  In this paper we prove that the stretch factor of the Delaunay triangulation
of a set of points in the plane is less than $\rho = 1.998$, improving the
previous best upper bound of 2.42 by Keil and Gutwin (1989). Our bound 1.998 is
better than the current upper bound of 2.33 for the special case when the point
set is in convex position by Cui, Kanj and Xia (2009). This upper bound breaks
the barrier 2, which is significant because previously no family of plane
graphs was known to have a stretch factor guaranteed to be less than 2 on any
set of points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4395</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4395</id><created>2011-03-22</created><authors><author><keyname>Molavi</keyname><forenames>Pooya</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>On Non-Bayesian Social Learning</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a model of information aggregation and social learning recently
proposed by Jadbabaie, Sandroni, and Tahbaz-Salehi, in which individual agents
try to learn a correct state of the world by iteratively updating their beliefs
using private observations and beliefs of their neighbors. No individual
agent's private signal might be informative enough to reveal the unknown state.
As a result, agents share their beliefs with others in their social
neighborhood to learn from each other. At every time step each agent receives a
private signal, and computes a Bayesian posterior as an intermediate belief.
The intermediate belief is then averaged with the belief of neighbors to form
the individual's belief at next time step. We find a set of minimal sufficient
conditions under which the agents will learn the unknown state and reach
consensus on their beliefs without any assumption on the private signal
structure. The key enabler is a result that shows that using this update,
agents will eventually forecast the indefinite future correctly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4399</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4399</id><created>2011-03-22</created><updated>2011-07-19</updated><authors><author><keyname>Schmitz</keyname><forenames>Sylvain</forenames></author><author><keyname>Schnoebelen</keyname><forenames>Philippe</forenames></author></authors><title>Multiply-Recursive Upper Bounds with Higman's Lemma</title><categories>cs.LO cs.CC</categories><acm-class>D.2.4; F.1.3; F.2; F.4.2</acm-class><journal-ref>In Aceto, L., Henzinger, M., and Sgall, J., editors, ICALP 2011,
  38th International Colloquium on Automata, Languages and Programming, volume
  6756 of Lecture Notes in Computer Science, pages 441--452. Springer
  Heidelberg</journal-ref><doi>10.1007/978-3-642-22012-8_35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new analysis for the length of controlled bad sequences in
well-quasi-orderings based on Higman's Lemma. This leads to tight
multiply-recursive upper bounds that readily apply to several verification
algorithms for well-structured systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4401</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4401</id><created>2011-03-22</created><authors><author><keyname>Yagan</keyname><forenames>Osman</forenames></author><author><keyname>Makowski</keyname><forenames>Armand M.</forenames></author></authors><title>On the gradual deployment of random pairwise key distribution schemes
  (Extended Version)</title><categories>cs.CR cs.DM cs.IT math.IT</categories><comments>The extended version of a paper that will appear at WiOpt 2011.
  Additional parts may later be reported elsewhere</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of wireless sensor networks, the pairwise key distribution
scheme of Chan et al. has several advantages over other key distribution
schemes including the original scheme of Eschenauer and Gligor. However, this
offline pairwise key distribution mechanism requires that the network size be
set in advance, and involves all sensor nodes simultaneously. Here, we address
this issue by describing an implementation of the pairwise scheme that supports
the gradual deployment of sensor nodes in several consecutive phases. We
discuss the key ring size needed to maintain the secure connectivity throughout
all the deployment phases. In particular we show that the number of keys at
each sensor node can be taken to be $O(\log n)$ in order to achieve secure
connectivity (with high probability).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4406</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4406</id><created>2011-03-22</created><authors><author><keyname>Yousafzai</keyname><forenames>Aimal Khan</forenames></author><author><keyname>Nakhai</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Interference Alignment with Partially Coordinated Transmit Precoding</title><categories>cs.IT math.IT</categories><comments>19 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an efficient interference alignment (IA)
algorithm exploiting partially coordinated transmit precoding to improve the
number of concurrent interference-free transmissions, i.e., the multiplexing
gain, in multicell downlink. The proposed coordination model is such that each
base-station simultaneously transmits to two users and each user is served by
two base-stations. First, we show in a K-user system operating at the
information theoretic upper bound of degrees of freedom (DOF), the generic IA
is proper when $K \leq 3$, whereas the proposed partially coordinated IA is
proper when $K \leq 5$. Then, we derive a non-iterative, i.e., one shot, IA
algorithm for the proposed scheme when $K \leq 5$. We show that for a given
latency, the backhaul data rate requirement of the proposed method grows
linearly with K. Monte-Carlo simulation results show that the proposed one-shot
algorithm offers higher system throughput than the iterative IA at practical
SNR levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4410</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4410</id><created>2011-03-22</created><authors><author><keyname>Cao</keyname><forenames>Zhao</forenames><affiliation>University of Massachusetts</affiliation></author><author><keyname>Sutton</keyname><forenames>Charles</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Diao</keyname><forenames>Yanlei</forenames><affiliation>University of Massachusetts</affiliation></author><author><keyname>Shenoy</keyname><forenames>Prashant</forenames><affiliation>University of Massachusetts</affiliation></author></authors><title>Distributed Inference and Query Processing for RFID Tracking and
  Monitoring</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 5, pp.
  326-337 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the design of a scalable, distributed stream
processing system for RFID tracking and monitoring. Since RFID data lacks
containment and location information that is key to query processing, we
propose to combine location and containment inference with stream query
processing in a single architecture, with inference as an enabling mechanism
for high-level query processing. We further consider challenges in
instantiating such a system in large distributed settings and design techniques
for distributed inference and query processing. Our experimental results, using
both real-world data and large synthetic traces, demonstrate the accuracy,
efficiency, and scalability of our proposed techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4433</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4433</id><created>2011-03-23</created><updated>2011-12-22</updated><authors><author><keyname>Ariffin</keyname><forenames>M. R. K.</forenames></author><author><keyname>Asbullah</keyname><forenames>M. A.</forenames></author><author><keyname>Abu</keyname><forenames>N. A.</forenames></author></authors><title>Security Features of an Asymmetric Cryptosystem based on the Diophantine
  Equation Hard Problem</title><categories>cs.CR</categories><msc-class>94A60, 68P25, 11D45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Diophantine Equation Hard Problem (DEHP) is a potential cryptographic
problem on the Diophantine equation $U=\sum \limits_{i=1}^n {V_i x_{i}}$. A
proper implementation of DEHP would render an attacker to search for private
parameters amongst the exponentially many solutions. However, an improper
implementation would provide an attacker exponentially many choices to solve
the DEHP. The AA\,$_{\beta}$-cryptosystem is an asymmetric cryptographic scheme
that utilizes this concept together with the factorization problem of two large
primes and is implemented only by using the multiplication operation for both
encryption and decryption. With this simple mathematical structure, it would
have low computational requirements and would enable communication devices with
low computing power to deploy secure communication procedures efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4435</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4435</id><created>2011-03-23</created><updated>2011-04-03</updated><authors><author><keyname>Emad</keyname><forenames>Amin</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Information Theoretic Bounds for Tensor Rank Minimization over Finite
  Fields</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of noiseless and noisy low-rank tensor completion
from a set of random linear measurements. In our derivations, we assume that
the entries of the tensor belong to a finite field of arbitrary size and that
reconstruction is based on a rank minimization framework. The derived results
show that the smallest number of measurements needed for exact reconstruction
is upper bounded by the product of the rank, the order and the dimension of a
cubic tensor. Furthermore, this condition is also sufficient for unique
minimization. Similar bounds hold for the noisy rank minimization scenario,
except for a scaling function that depends on the channel error probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4438</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4438</id><created>2011-03-23</created><authors><author><keyname>Sukhavasi</keyname><forenames>Ravi Teja</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Anytime Reliable Codes for Stabilizing Plants over Erasure Channels</title><categories>cs.SY cs.IT math.IT math.OC</categories><comments>Submitted to CDC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of stabilizing an unstable plant over a noisy communication link
is an increasingly important one that arises in problems of distributed control
and networked control systems. Although the work of Schulman and Sahai over the
past two decades, and their development of the notions of &quot;tree codes&quot; and
&quot;anytime capacity&quot;, provides the theoretical framework for studying such
problems, there has been scant practical progress in this area because explicit
constructions of tree codes with efficient encoding and decoding did not exist.
To stabilize an unstable plant driven by bounded noise over a noisy channel one
needs real-time encoding and real-time decoding and a reliability which
increases exponentially with delay, which is what tree codes guarantee. We
prove the existence of linear tree codes with high probability and, for erasure
channels, give an explicit construction with an expected encoding and decoding
complexity that is constant per time instant. We give sufficient conditions on
the rate and reliability required of the tree codes to stabilize vector plants
and argue that they are asymptotically tight. This work takes a major step
towards controlling plants over noisy channels, and we demonstrate the efficacy
of the method through several examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4454</identifier>
 <datestamp>2012-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4454</id><created>2011-03-23</created><authors><author><keyname>Cannarsa</keyname><forenames>Piermarco</forenames><affiliation>DIPMAT</affiliation></author><author><keyname>Cardaliaguet</keyname><forenames>Pierre</forenames><affiliation>CEREMADE</affiliation></author></authors><title>Regularity Results for Eikonal-Type Equations with Nonsmooth
  Coefficients</title><categories>math.OC cs.SY math.AP</categories><proxy>ccsd</proxy><journal-ref>Nonlinear Differential Equations and Applications 19, 6 (2012)
  751--769</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solutions of the Hamilton-Jacobi equation $H(x,-Du(x))=1$, with $H(\cdot,p)$
H\&quot;older continuous and $H(x,\cdot)$ convex and positively homogeneous of
degree 1, are shown to be locally semiconcave with a power-like modulus. An
essential step of the proof is the ${\mathcal C}^{1,\alpha}$-regularity of the
extremal trajectories associated with the multifunction generated by $D_pH$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4457</identifier>
 <datestamp>2013-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4457</id><created>2011-03-23</created><updated>2013-07-04</updated><authors><author><keyname>Decreusefond</keyname><forenames>Laurent</forenames><affiliation>LTCI</affiliation></author><author><keyname>Ferraz</keyname><forenames>Eduardo</forenames><affiliation>LTCI</affiliation></author><author><keyname>Randriam</keyname><forenames>Hugues</forenames><affiliation>LTCI</affiliation></author><author><keyname>Vergne</keyname><forenames>Ana&#xef;s</forenames><affiliation>LTCI</affiliation></author></authors><title>Simplicial Homology of Random Configurations</title><categories>math.PR cs.NI math.AT math.KT</categories><proxy>ccsd</proxy><journal-ref>Advances in Applied Probability 46, 2 (2014) 1-20</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a Poisson process on a $d$-dimensional torus, its random geometric
simplicial complex is the complex whose vertices are the points of the Poisson
process and simplices are given by the \u{C}ech complex associated to the
coverage of each point. By means of Malliavin calculus, we compute explicitly
the n$th$ order moment of the number of $k$-simplices. The two first order
moments of this quantity allow us to find the mean and the variance of the
Euler caracteristic. Also, we show that the number of any connected geometric
simplicial complex converges to the Gaussian law when the intensity of the
Poisson point process tends to infinity. We use a concentration inequality to
find bounds for the for the distribution of the Betti number of first order and
the Euler characteristic in such simplicial complex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4480</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4480</id><created>2011-03-23</created><authors><author><keyname>Barman</keyname><forenames>Kishor</forenames></author><author><keyname>Dabeer</keyname><forenames>Onkar</forenames></author></authors><title>Clustered regression with unknown clusters</title><categories>cs.LG stat.ML</categories><comments>9 pages, Submitted to KDD 2011, San Diego</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a collection of prediction experiments, which are clustered in
the sense that groups of experiments ex- hibit similar relationship between the
predictor and response variables. The experiment clusters as well as the
regres- sion relationships are unknown. The regression relation- ships define
the experiment clusters, and in general, the predictor and response variables
may not exhibit any clus- tering. We call this prediction problem clustered
regres- sion with unknown clusters (CRUC) and in this paper we focus on linear
regression. We study and compare several methods for CRUC, demonstrate their
applicability to the Yahoo Learning-to-rank Challenge (YLRC) dataset, and in-
vestigate an associated mathematical model. CRUC is at the crossroads of many
prior works and we study several prediction algorithms with diverse origins: an
adaptation of the expectation-maximization algorithm, an approach in- spired by
K-means clustering, the singular value threshold- ing approach to matrix rank
minimization under quadratic constraints, an adaptation of the Curds and Whey
method in multiple regression, and a local regression (LoR) scheme reminiscent
of neighborhood methods in collaborative filter- ing. Based on empirical
evaluation on the YLRC dataset as well as simulated data, we identify the LoR
method as a good practical choice: it yields best or near-best prediction
performance at a reasonable computational load, and it is less sensitive to the
choice of the algorithm parameter. We also provide some analysis of the LoR
method for an asso- ciated mathematical model, which sheds light on optimal
parameter choice and prediction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4487</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4487</id><created>2011-03-23</created><authors><author><keyname>Cire&#x15f;an</keyname><forenames>Dan C.</forenames></author><author><keyname>Meier</keyname><forenames>Ueli</forenames></author><author><keyname>Gambardella</keyname><forenames>Luca M.</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Handwritten Digit Recognition with a Committee of Deep Neural Nets on
  GPUs</title><categories>cs.LG cs.AI cs.CV cs.NE</categories><comments>9 pages, 4 figures, 3 tables</comments><report-no>IDSIA-03-11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The competitive MNIST handwritten digit recognition benchmark has a long
history of broken records since 1998. The most recent substantial improvement
by others dates back 7 years (error rate 0.4%) . Recently we were able to
significantly improve this result, using graphics cards to greatly speed up
training of simple but deep MLPs, which achieved 0.35%, outperforming all the
previous more complex methods. Here we report another substantial improvement:
0.31% obtained using a committee of MLPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4496</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4496</id><created>2011-03-23</created><authors><author><keyname>Das</keyname><forenames>Ashok Kumar</forenames></author></authors><title>An Improved Efficient Key Distribution Mechanism for Large-Scale
  Heterogeneous Mobile Sensor Networks</title><categories>cs.CR</categories><comments>12 pages</comments><journal-ref>International Journal of Information Processing, Vol. 2, No. 3,
  pp. 21 - 32, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to resource constraints of the sensor nodes, traditional public key
cryptographic techniques are not feasible in most sensor network architectures.
Several symmetric key distribution mechanisms are proposed for establishing
pairwise keys between sensor nodes in sensor networks, but most of them are not
scalable and also are not much suited for mobile sensor networks because they
incur much communication as well as computational overheads. Moreover, these
schemes are either vulnerable to a small number of compromised sensor nodes or
involve expensive protocols for establishing keys. In this paper, we introduce
a new scheme for establishing keys between sensor nodes with the help of
additional high-end sensor nodes, called the auxiliary nodes. Our scheme
provides unconditional security against sensor node captures and high network
connectivity. In addition, our scheme requires minimal storage requirement for
storing keys mainly due to only a single key before deployment in each node in
the sensor network, supports efficiently addition of new nodes after initial
deployment and also works for any deployment topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4502</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4502</id><created>2011-03-23</created><authors><author><keyname>Moussa</keyname><forenames>M. Ibrahim</forenames><affiliation>Benha University, Benha, Egypt</affiliation></author></authors><title>An Algorithm for Odd Gracefulness of the Tensor Product of Two Line
  Graphs</title><categories>cs.DM</categories><comments>12 Pages, JGraph-Hoc Journal Vol.3, No. 1, 2011</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  An odd graceful labeling of a graph G=(V,E) is a function
f:V(G)-&gt;[0,1,2,...,2|E(G)|-1} such that |f(u)-f(v)| is odd value less than or
equal to 2|E(G)-1| for any u, v in V(G). In spite of the large number of papers
published on the subject of graph labeling, there are few algorithms to be used
by researchers to gracefully label graphs. This work provides generalized odd
graceful solutions to all the vertices and edges for the tensor product of the
two paths P_n and P_m denoted P_n^P_m . Firstly, we describe an algorithm to
label the vertices and the edges of the vertex set V(P_n^P_m) and the edge set
E(P_n^P_m) respectively. Finally, we prove that the graph P_n^P_m is odd
graceful for all integers n and m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4503</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4503</id><created>2011-03-23</created><authors><author><keyname>Giannopoulos</keyname><forenames>Panos</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Wahlstr&#xf6;m</keyname><forenames>Magnus</forenames></author><author><keyname>Werner</keyname><forenames>Daniel</forenames></author></authors><title>Hardness of discrepancy computation and epsilon-net verification in high
  dimension</title><categories>cs.CG</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrepancy measures how uniformly distributed a point set is with respect to
a given set of ranges. There are two notions of discrepancy, namely continuous
discrepancy and combinatorial discrepancy. Depending on the ranges, several
possible variants arise, for example star discrepancy, box discrepancy, and
discrepancy of half-spaces. In this paper, we investigate the hardness of these
problems with respect to the dimension d of the underlying space.
  All these problems are solvable in time {n^O(d)}, but such a time dependency
quickly becomes intractable for high-dimensional data. Thus it is interesting
to ask whether the dependency on d can be moderated.
  We answer this question negatively by proving that the canonical decision
problems are W[1]-hard with respect to the dimension. This is done via a
parameterized reduction from the Clique problem. As the parameter stays linear
in the input parameter, the results moreover imply that these problems require
{n^\Omega(d)} time, unless 3-Sat can be solved in {2^o(n)} time.
  Further, we derive that testing whether a given set is an {\epsilon}-net with
respect to half-spaces takes {n^\Omega(d)} time under the same assumption. As
intermediate results, we discover the W[1]-hardness of other well known
problems, such as determining the largest empty star inside the unit cube. For
this, we show that it is even hard to approximate within a factor of {2^n}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4513</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4513</id><created>2011-03-23</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Eisenstat</keyname><forenames>Sarah</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author><author><keyname>Wilson</keyname><forenames>David A.</forenames></author></authors><title>Remarks on separating words</title><categories>cs.FL cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The separating words problem asks for the size of the smallest DFA needed to
distinguish between two words of length &lt;= n (by accepting one and rejecting
the other). In this paper we survey what is known and unknown about the
problem, consider some variations, and prove several new results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4515</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4515</id><created>2011-03-23</created><authors><author><keyname>Bergstra</keyname><forenames>Jan Aldert</forenames></author></authors><title>Real Islamic Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Four options for assigning a meaning to Islamic Logic are surveyed including
a new proposal for an option named &quot;Real Islamic Logic&quot; (RIL). That approach to
Islamic Logic should serve modern Islamic objectives in a way comparable to the
functionality of Islamic Finance. The prospective role of RIL is analyzed from
several perspectives: (i) parallel distributed systems design, (ii) reception
by a community structured audience, (iii) informal logic and applied
non-classical logics, and (iv) (in)tractability and artificial intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4521</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4521</id><created>2011-03-23</created><authors><author><keyname>Fisikopoulos</keyname><forenames>Vissarion</forenames></author></authors><title>An implementation of range trees with fractional cascading in C++</title><categories>cs.DS cs.CG cs.SE</categories><comments>Technical report</comments><acm-class>E.1; I.3.5; D.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Range trees are multidimensional binary trees which are used to perform
d-dimensional orthogonal range searching. In this technical report we study the
implementation issues of range trees with fractional cascading, named layered
range trees. We also document our implementation of range trees with fractional
cascading in C++ using STL and generic programming techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4525</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4525</id><created>2011-03-23</created><authors><author><keyname>Huang</keyname><forenames>Huang</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Du</keyname><forenames>Yinggang</forenames></author><author><keyname>Liu</keyname><forenames>Sheng</forenames></author></authors><title>Robust Lattice Alignment for K-user MIMO Interference Channels with
  Imperfect Channel Knowledge</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2011.2135855</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a robust lattice alignment design for K-user
quasi-static MIMO interference channels with imperfect channel knowledge. With
random Gaussian inputs, the conventional interference alignment (IA) method has
the feasibility problem when the channel is quasi-static. On the other hand,
structured lattices can create structured interference as opposed to the random
interference caused by random Gaussian symbols. The structured interference
space can be exploited to transmit the desired signals over the gaps. However,
the existing alignment methods on the lattice codes for quasi-static channels
either require infinite SNR or symmetric interference channel coefficients.
Furthermore, perfect channel state information (CSI) is required for these
alignment methods, which is difficult to achieve in practice. In this paper, we
propose a robust lattice alignment method for quasi-static MIMO interference
channels with imperfect CSI at all SNR regimes, and a two-stage decoding
algorithm to decode the desired signal from the structured interference space.
We derive the achievable data rate based on the proposed robust lattice
alignment method, where the design of the precoders, decorrelators, scaling
coefficients and interference quantization coefficients is jointly formulated
as a mixed integer and continuous optimization problem. The effect of imperfect
CSI is also accommodated in the optimization formulation, and hence the derived
solution is robust to imperfect CSI. We also design a low complex iterative
optimization algorithm for our robust lattice alignment method by using the
existing iterative IA algorithm that was designed for the conventional IA
method. Numerical results verify the advantages of the proposed robust lattice
alignment method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4547</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4547</id><created>2011-03-23</created><updated>2012-05-18</updated><authors><author><keyname>Ahmad</keyname><forenames>Ayaz</forenames></author><author><keyname>Assaad</keyname><forenames>Mohamad</forenames></author></authors><title>Canonical Dual Method for Resource Allocation and Adaptive Modulation in
  Uplink SC-FDMA Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study resource allocation and adaptive modulation in
SC-FDMA which is adopted as the multiple access scheme for the uplink in the
3GPP-LTE standard. A sum-utility maximization (SUmax), and a joint adaptive
modulation and sum-cost minimization (JAMSCmin) problems are considered. Unlike
OFDMA, in addition to the restriction of allocating a sub-channel to one user
at most, the multiple sub-channels allocated to a user in SC-FDMA should be
consecutive as well. This renders the resource allocation problem prohibitively
difficult and the standard optimization tools (e.g., Lagrange dual approach
widely used for OFDMA, etc.) can not help towards its optimal solution. We
propose a novel optimization framework for the solution of these problems that
is inspired from the recently developed canonical duality theory. We first
formulate the optimization problems as binary-integer programming problems and
then transform these binary-integer programming problems into continuous space
canonical dual problems that are concave maximization problems. Based on the
solution of the continuous space dual problems, we derive resource allocation
(joint with adaptive modulation for JAMSCmin) algorithms for both the problems
which have polynomial complexities. We provide conditions under which the
proposed algorithms are optimal. We also propose an adaptive modulation scheme
for SUmax problem. We compare the proposed algorithms with the existing
algorithms in the literature to assess their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4550</identifier>
 <datestamp>2013-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4550</id><created>2011-03-23</created><authors><author><keyname>Cordasco</keyname><forenames>Gennaro</forenames></author><author><keyname>Gargano</keyname><forenames>Luisa</forenames></author></authors><title>Community Detection via Semi-Synchronous Label Propagation Algorithms</title><categories>cs.SI physics.soc-ph</categories><comments>In Proc. of The International Workshop on Business Applications of
  Social Network Analysis (BASNA '10)</comments><journal-ref>Int. J. of Social Network Mining 2012 - Vol. 1, No.1 pp. 3 - 26</journal-ref><doi>10.1504/..045103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recently introduced novel community detection strategy is based on a label
propagation algorithm (LPA) which uses the diffusion of information in the
network to identify communities. Studies of LPAs showed that the strategy is
effective in finding a good community structure. Label propagation step can be
performed in parallel on all nodes (synchronous model) or sequentially
(asynchronous model); both models present some drawback, e.g., algorithm
termination is nor granted in the first case, performances can be worst in the
second case. In this paper, we present a semi-synchronous version of LPA which
aims to combine the advantages of both synchronous and asynchronous models. We
prove that our models always converge to a stable labeling. Moreover, we
experimentally investigate the effectiveness of the proposed strategy comparing
its performance with the asynchronous model both in terms of quality,
efficiency and stability. Tests show that the proposed protocol does not harm
the quality of the partitioning. Moreover it is quite efficient; each
propagation step is extremely parallelizable and it is more stable than the
asynchronous model, thanks to the fact that only a small amount of
randomization is used by our proposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4558</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4558</id><created>2011-03-23</created><authors><author><keyname>Ferraris</keyname><forenames>Paolo</forenames></author><author><keyname>Lee</keyname><forenames>Joohyung</forenames></author><author><keyname>Lierler</keyname><forenames>Yuliya</forenames></author><author><keyname>Lifschitz</keyname><forenames>Vladimir</forenames></author><author><keyname>Yang</keyname><forenames>Fangkai</forenames></author></authors><title>Representing First-Order Causal Theories by Logic Programs</title><categories>cs.AI cs.LO</categories><comments>29 pages. To appear in Theory and Practice of Logic Programming
  (TPLP); Theory and Practice of Logic Programming, May, 2011</comments><doi>10.1017/S1471068411000081</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonmonotonic causal logic, introduced by Norman McCain and Hudson Turner,
became a basis for the semantics of several expressive action languages.
McCain's embedding of definite propositional causal theories into logic
programming paved the way to the use of answer set solvers for answering
queries about actions described in such languages. In this paper we extend this
embedding to nondefinite theories and to first-order causal logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4566</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4566</id><created>2011-03-23</created><updated>2011-03-24</updated><authors><author><keyname>Kantor</keyname><forenames>Erez</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author><author><keyname>Parter</keyname><forenames>Merav</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author></authors><title>The Topology of Wireless Communication</title><categories>cs.DS</categories><comments>64 pages, appeared in STOC'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the topological properties of wireless communication
maps and their usability in algorithmic design. We consider the SINR model,
which compares the received power of a signal at a receiver against the sum of
strengths of other interfering signals plus background noise. To describe the
behavior of a multi-station network, we use the convenient representation of a
\emph{reception map}. In the SINR model, the resulting \emph{SINR diagram}
partitions the plane into reception zones, one per station, and the
complementary region of the plane where no station can be heard. We consider
the general case where transmission energies are arbitrary (or non-uniform).
Under that setting, the reception zones are not necessarily convex or even
connected. This poses the algorithmic challenge of designing efficient point
location techniques as well as the theoretical challenge of understanding the
geometry of SINR diagrams. We achieve several results in both directions. We
establish a form of weaker convexity in the case where stations are aligned on
a line. In addition, one of our key results concerns the behavior of a
$(d+1)$-dimensional map. Specifically, although the $d$-dimensional map might
be highly fractured, drawing the map in one dimension higher &quot;heals&quot; the zones,
which become connected. In addition, as a step toward establishing a weaker
form of convexity for the $d$-dimensional map, we study the interference
function and show that it satisfies the maximum principle. Finally, we turn to
consider algorithmic applications, and propose a new variant of approximate
point location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4577</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4577</id><created>2011-03-23</created><authors><author><keyname>Deng</keyname><forenames>Yuxin</forenames></author><author><keyname>Du</keyname><forenames>Wenjie</forenames></author></authors><title>Logical, Metric, and Algorithmic Characterisations of Probabilistic
  Bisimulation</title><categories>cs.LO</categories><comments>25 pages</comments><acm-class>F.3.2; D.3.1</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many behavioural equivalences or preorders for probabilistic processes
involve a lifting operation that turns a relation on states into a relation on
distributions of states. We show that several existing proposals for lifting
relations can be reconciled to be different presentations of essentially the
same lifting operation. More interestingly, this lifting operation nicely
corresponds to the Kantorovich metric, a fundamental concept used in
mathematics to lift a metric on states to a metric on distributions of states,
besides the fact the lifting operation is related to the maximum flow problem
in optimisation theory.
  The lifting operation yields a neat notion of probabilistic bisimulation, for
which we provide logical, metric, and algorithmic characterisations.
Specifically, we extend the Hennessy-Milner logic and the modal mu-calculus
with a new modality, resulting in an adequate and an expressive logic for
probabilistic bisimilarity, respectively. The correspondence of the lifting
operation and the Kantorovich metric leads to a natural characterisation of
bisimulations as pseudometrics which are post-fixed points of a monotone
function. We also present an &quot;on the fly&quot; algorithm to check if two states in a
finitary system are related by probabilistic bisimilarity, exploiting the close
relationship between the lifting operation and the maximum flow problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4578</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4578</id><created>2011-03-22</created><updated>2011-03-24</updated><authors><author><keyname>Wang</keyname><forenames>Chengpu</forenames></author></authors><title>Common Signal Analysis</title><categories>cs.IT math.IT</categories><comments>8 Pages, 1 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common signal is defined for any two signals which have non-zero
correlation. A mathematical method is provided to extract the best obtainable
common signal between the two signals. This analysis is extended to extracting
common signal among three signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4584</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4584</id><created>2011-03-23</created><updated>2011-08-04</updated><authors><author><keyname>Benerecetti</keyname><forenames>Massimo</forenames></author><author><keyname>Faella</keyname><forenames>Marco</forenames></author><author><keyname>Minopoli</keyname><forenames>Stefano</forenames></author></authors><title>Automatic Synthesis of Switching Controllers for Linear Hybrid Automata</title><categories>cs.LO cs.FL cs.SY math.OC</categories><comments>22 pages, 5 figures (same contribution as earlier version, improved
  proofs)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of automatically generating switching
controllers for the class of Linear Hybrid Automata, with respect to safety
objectives. We identify and solve inaccuracies contained in previous
characterizations of the problem, providing a sound and complete symbolic
fixpoint procedure, based on polyhedral abstractions of the state space. We
also prove the termination of each iteration of the procedure. Some promising
experimental results are presented, based on an implementation of the fixpoint
procedure on top of the tool PHAVer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4601</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4601</id><created>2011-03-23</created><updated>2011-05-05</updated><authors><author><keyname>Dudik</keyname><forenames>Miroslav</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author></authors><title>Doubly Robust Policy Evaluation and Learning</title><categories>cs.LG cs.AI cs.RO stat.AP stat.ML</categories><comments>Published at ICML 2011, 8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study decision making in environments where the reward is only partially
observed, but can be modeled as a function of an action and an observed
context. This setting, known as contextual bandits, encompasses a wide variety
of applications including health-care policy and Internet advertising. A
central task is evaluation of a new policy given historic data consisting of
contexts, actions and received rewards. The key challenge is that the past data
typically does not faithfully represent proportions of actions taken by a new
policy. Previous approaches rely either on models of rewards or models of the
past policy. The former are plagued by a large bias whereas the latter have a
large variance.
  In this work, we leverage the strength and overcome the weaknesses of the two
approaches by applying the doubly robust technique to the problems of policy
evaluation and optimization. We prove that this approach yields accurate value
estimates when we have either a good (but not necessarily consistent) model of
rewards or a good (but not necessarily consistent) model of past policy.
Extensive empirical comparison demonstrates that the doubly robust approach
uniformly improves over existing techniques, achieving both lower variance in
value estimation and better policies. As such, we expect the doubly robust
approach to become common practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4659</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4659</id><created>2011-03-23</created><authors><author><keyname>Zhang</keyname><forenames>W.</forenames></author><author><keyname>Lim</keyname><forenames>C.</forenames></author><author><keyname>Sreenivasan</keyname><forenames>S.</forenames></author><author><keyname>Xie</keyname><forenames>J.</forenames></author><author><keyname>Szymanski</keyname><forenames>B. K.</forenames></author><author><keyname>Korniss</keyname><forenames>G.</forenames></author></authors><title>Social Influencing and Associated Random Walk Models: Asymptotic
  Consensus Times on the Complete Graph</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><journal-ref>Chaos 21, 025115 (2011)</journal-ref><doi>10.1063/1.3598450</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate consensus formation and the asymptotic consensus times in
stylized individual- or agent-based models, in which global agreement is
achieved through pairwise negotiations with or without a bias. Considering a
class of individual-based models on finite complete graphs, we introduce a
coarse-graining approach (lumping microscopic variables into macrostates) to
analyze the ordering dynamics in an associated random-walk framework. Within
this framework, yielding a linear system, we derive general equations for the
expected consensus time and the expected time spent in each macro-state.
Further, we present the asymptotic solutions of the 2-word naming game, and
separately discuss its behavior under the influence of an external field and
with the introduction of committed agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4676</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4676</id><created>2011-03-24</created><authors><author><keyname>Das</keyname><forenames>Ashok Kumar</forenames></author><author><keyname>Giri</keyname><forenames>Debasis</forenames></author></authors><title>An Identity Based Key Management Scheme in Wireless Sensor Networks</title><categories>cs.CR</categories><comments>7 pages, Published in Proceedings of 4th Asian International Mobile
  Computing Conference (AMOC 2006), Kolkata, India, pp. 70-76, January 4-7,
  2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pairwise key establishment is one of the fundamental security services in
sensor networks which enables sensor nodes in a sensor network to communicate
securely with each other using cryptographic techniques. It is not feasible to
apply traditional public key management techniques in resource-constrained
sensor nodes, and also because the sensor nodes are vulnerable to physical
capture. In this paper, we introduce a new scheme called the identity based key
pre-distribution using a pseudo random function (IBPRF), which has better
trade-off between communication overhead, network connectivity and resilience
against node capture compared to the other key pre-distribution schemes. Our
scheme can be easily adapted in mobile sensor networks. This scheme supports
the addition of new sensor nodes after the initial deployment and also works
for any deployment topology. In addition, we propose an improved version of our
scheme to support large sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4678</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4678</id><created>2011-03-24</created><authors><author><keyname>Das</keyname><forenames>Ashok Kumar</forenames></author></authors><title>An Unconditionally Secure Key Management Scheme for Large-Scale
  Heterogeneous Wireless Sensor Networks</title><categories>cs.CR</categories><comments>10 pages, Published in Proceedings of First International Conference
  on COMmunication Systems and NETworkS (COMSNETS 2009), IEEE Computer Society
  Press, pp. 1 - 10, Bangalore, India, January 5-10, 2009</comments><doi>10.1109/COMSNETS.2009.4808919</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Key establishment in sensor networks becomes a challenging problem because of
the resource limitations of the sensors and also due to vulnerability to
physical capture of the sensor nodes. In this paper, we propose an
unconditionally secure probabilistic group-based key pre-distribution scheme
for a heterogeneous wireless sensor network. The proposed scheme always
guarantees that no matter how many sensor nodes are compromised, the
non-compromised nodes can still communicate with 100% secrecy, i.e., the
proposed scheme is always unconditionally secure against node capture attacks.
Moreover, it provides significantly better trade-off between communication
overhead, computational overhead, network connectivity and security against
node capture as compared to the existing key pre-distribution schemes. It also
supports dynamic node addition after the initial deployment of the nodes in the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4684</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4684</id><created>2011-03-24</created><authors><author><keyname>Samarasinghe</keyname><forenames>Tharaka</forenames></author><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Vector Broadcast Channels: Optimality of Threshold Feedback Policies</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE International Symposium on Information Theory, St.
  Petersburg, Russia, Aug 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beamforming techniques utilizing only partial channel state information (CSI)
has gained popularity over other communication strategies requiring perfect CSI
thanks to their lower feedback requirements. The amount of feedback in
beamforming based communication systems can be further reduced through
selective feedback techniques in which only the users with channels good enough
are allowed to feed back by means of a decentralized feedback policy. In this
paper, we prove that thresholding at the receiver is the rate-wise optimal
decentralized feedback policy for feedback limited systems with prescribed
feedback constraints. This result is highly adaptable due to its distribution
independent nature, provides an analytical justification for the use of
threshold feedback policies in practical systems, and reinforces previous work
analyzing threshold feedback policies as a selective feedback technique without
proving its optimality. It is robust to selfish unilateral deviations. Finally,
it reduces the search for rate-wise optimal feedback policies subject to
feedback constraints from function spaces to a finite dimensional Euclidean
space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4686</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4686</id><created>2011-03-24</created><authors><author><keyname>Badarla</keyname><forenames>Suresh</forenames></author><author><keyname>Rama</keyname><forenames>R</forenames></author></authors><title>Note on minimally k-connected graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A k-tree is either a complete graph on (k+1) vertices or given a k-tree G'
with n vertices, a k-tree G with (n+1) vertices can be constructed by
introducing a new vertex v and picking a k-clique Q in G' and then joining each
vertex u in Q. A graph G is k-edge-connected if the graph remains connected
even after deleting fewer edges than k from the graph. A k-edge-connected graph
G is said to be minimally k-connected if G \ {e} is no longer k-edge-connected
for any edge e belongs to E(G) where E(G) denotes the set of edges of G. In
this paper we find two separate O (n2) algorithms so that a minimally
2-connected graph can be obtained from a 2-tree and a minimally k-connected
graph can be obtained from a k-tree. In a k-tree (k \geq 2) we find the edges
which are insensitive to the k-connectivity have both their end vertices of
degrees greater than or equal to k+1.This property is fully exploited to find
an algorithm which reduces any k-tree to a minimally k-connected graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4687</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4687</id><created>2011-03-24</created><authors><author><keyname>Samarasinghe</keyname><forenames>Tharaka</forenames></author><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author></authors><title>Vector Broadcast Channels: Optimal Threshold Selection Problem</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE International Symposium on Information Theory, St.
  Petersburg, Russia, Aug 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Threshold feedback policies are well known and provably rate-wise optimal
selective feedback techniques for communication systems requiring partial
channel state information (CSI). However, optimal selection of thresholds at
mobile users to maximize information theoretic data rates subject to feedback
constraints is an open problem. In this paper, we focus on the optimal
threshold selection problem, and provide a solution for this problem for finite
feedback systems. Rather surprisingly, we show that using the same threshold
values at all mobile users is not always a rate-wise optimal feedback strategy,
even for a system with identical users experiencing statistically the same
channel conditions. By utilizing the theory of majorization, we identify an
underlying Schur-concave structure in the rate function and obtain sufficient
conditions for a homogenous threshold feedback policy to be optimal. Our
results hold for most fading channel models, and we illustrate an application
of our results to familiar Rayleigh fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4689</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4689</id><created>2011-03-24</created><authors><author><keyname>Schicho</keyname><forenames>Josef</forenames></author><author><keyname>Sevilla</keyname><forenames>David</forenames></author></authors><title>Deciding trigonality of algebraic curves</title><categories>math.AG cs.SC</categories><comments>Extended abstract, 5 pages. Presented at MEGA 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let C be a non-hyperelliptic algebraic curve of genus at least 3. Enriques
and Babbage proved that its canonical image is the intersection of the quadrics
that contain it, except when C is trigonal (that is, it has a linear system of
degree 3 and dimension 1) or C is isomorphic to a plane quintic (genus 6). We
present a method to decide whether a given algebraic curve is trigonal, and in
the affirmative case to compute a map from C to the projective line whose
fibers cut out the linear system. It is based on the Lie algebra method
presented in Schicho (2006). Our algorithm is part of a larger effort to
determine whether a given algebraic curve admits a radical parametrization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4690</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4690</id><created>2011-03-24</created><updated>2011-09-20</updated><authors><author><keyname>Golab</keyname><forenames>Wojciech</forenames></author><author><keyname>Higham</keyname><forenames>Lisa</forenames></author><author><keyname>Woelfel</keyname><forenames>Philipp</forenames></author></authors><title>Linearizable Implementations Do Not Suffice for Randomized Distributed
  Computation</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linearizability is the gold standard among algorithm designers for deducing
the correctness of a distributed algorithm using implemented shared objects
from the correctness of the corresponding algorithm using atomic versions of
the same objects. We show that linearizability does not suffice for this
purpose when processes can exploit randomization, and we discuss the existence
of alternative correctness conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4694</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4694</id><created>2011-03-24</created><authors><author><keyname>Voicu</keyname><forenames>Razvan</forenames></author><author><keyname>Li</keyname><forenames>Mengran</forenames></author></authors><title>Cyclic and Inductive Calculi are equivalent</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brotherston and Simpson [citation] have formalized and investigated cyclic
reasoning, reaching the important conclusion that it is at least as powerful as
inductive reasoning (specifically, they showed that each inductive proof can be
translated into a cyclic proof). We add to their investigation by proving the
converse of this result, namely that each inductive proof can be translated
into an inductive one. This, in effect, establishes the equivalence between
first order cyclic and inductive calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4697</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4697</id><created>2011-03-24</created><authors><author><keyname>Berberich</keyname><forenames>Eric</forenames></author><author><keyname>Emeliyanenko</keyname><forenames>Pavel</forenames></author><author><keyname>Kobel</keyname><forenames>Alexander</forenames></author><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>Arrangement Computation for Planar Algebraic Curves</title><categories>cs.SC cs.CG cs.MS math.AG math.GT</categories><comments>19 pages, 3 figures, 5 tables, submitted to SNC 2011, data sets
  available for download:
  http://www.mpi-inf.mpg.de/departments/d1/projects/Geometry/DataSetsSNC-2011.zip</comments><msc-class>14Q05 (Primary), 14h50, 14P10 (Secondary)</msc-class><acm-class>I.1.2; G.4; D.2.13</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new certified and complete algorithm to compute arrangements of
real planar algebraic curves. Our algorithm provides a geometric-topological
analysis of the decomposition of the plane induced by a finite number of
algebraic curves in terms of a cylindrical algebraic decomposition of the
plane. Compared to previous approaches, we improve in two main aspects:
Firstly, we significantly reduce the amount of exact operations, that is, our
algorithms only uses resultant and gcd as purely symbolic operations. Secondly,
we introduce a new hybrid method in the lifting step of our algorithm which
combines the usage of a certified numerical complex root solver and information
derived from the resultant computation. Additionally, we never consider any
coordinate transformation and the output is also given with respect to the
initial coordinate system. We implemented our algorithm as a prototypical
package of the C++-library CGAL. Our implementation exploits graphics hardware
to expedite the resultant and gcd computation. We also compared our
implementation with the current reference implementation, that is, CGAL's curve
analysis and arrangement for algebraic curves. For various series of
challenging instances, our experiments show that the new implementation
outperforms the existing one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4712</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4712</id><created>2011-03-24</created><authors><author><keyname>Kodavalla</keyname><forenames>Vijay Kumar</forenames></author><author><keyname>Mohan</keyname><forenames>Dr. P. G. Krishna</forenames></author></authors><title>Distributed Video Coding: Codec Architecture and Implementation</title><categories>cs.MM</categories><comments>Signal &amp; Image Processing : An International Journal(SIPIJ) Vol.2,
  No.1, March 2011</comments><doi>10.5121/sipij.2011.2111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Video Coding (DVC) is a new coding paradigm for video
compression, based on Slepian- Wolf (lossless coding) and Wyner-Ziv (lossy
coding) information theoretic results. DVC is useful for emerging applications
such as wireless video cameras, wireless low-power surveillance networks and
disposable video cameras for medical applications etc. The primary objective of
DVC is low-complexity video encoding, where bulk of computation is shifted to
the decoder, as opposed to low-complexity decoder in conventional video
compression standards such as H.264 and MPEG etc. There are couple of early
architectures and implementations of DVC from Stanford University[2][3] in
2002, Berkeley University PRISM (Power-efficient, Robust, hIgh-compression,
Syndrome-based Multimedia coding)[4][5] in 2002 and European project DISCOVER
(DIStributed COding for Video SERvices)[6] in 2007. Primarily there are two
types of DVC techniques namely pixel domain and transform domain based.
Transform domain design will have better rate-distortion (RD) performance as it
exploits spatial correlation between neighbouring samples and compacts the
block energy into as few transform coefficients as possible (aka energy
compaction). In this paper, architecture, implementation details and &quot;C&quot; model
results of our transform domain DVC are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4717</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4717</id><created>2011-03-24</created><authors><author><keyname>Breitwieser</keyname><forenames>Christian</forenames></author><author><keyname>Eibel</keyname><forenames>Christoph</forenames></author></authors><title>TiA -- Documentation of TOBI Interface A</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document contains the documentation of TOBI (Tools for BCI) Interface A
(TiA).
  TiA is a standardized interface to transmit raw biosignals. It is able to
deal with multirate and block-oriented data transmission. Data is distinguished
by different signal types (e.g., EEG, EOG, NIRS,...), whereby those signals can
be acquired at the same time from different acquisition devices. TiA is built
as a client-server model. Multiple clients can connect to one server.
Information is exchanged via a control- and a separated data connection.
Control commands and meta information are transmitted over the control
connection. Raw biosignal data is delivered using the data connection in a
unidirectional way. For this purpose a standardized handshaking protocol and
raw data packet have been developed. Thus, an abstraction layer between
hardware devices and data processing was evolved facilitating standardization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4720</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4720</id><created>2011-03-24</created><updated>2011-03-25</updated><authors><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author></authors><title>Computer Modelling of 3D Geological Surface</title><categories>cs.CE</categories><comments>05 Pages, and 05 Figures</comments><acm-class>H.2.8; I.3.5</acm-class><journal-ref>International Journal of Computer Science and Information
  Security, Vol. 9, No. 2, February 2011, pp: 175-179</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The geological surveying presently uses methods and tools for the computer
modeling of 3D-structures of the geographical subsurface and geotechnical
characterization as well as the application of geoinformation systems for
management and analysis of spatial data, and their cartographic presentation.
The objectives of this paper are to present a 3D geological surface model of
Latur district in Maharashtra state of India. This study is undertaken through
the several processes which are discussed in this paper to generate and
visualize the automated 3D geological surface model of a projected area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4723</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4723</id><created>2011-03-24</created><updated>2012-03-01</updated><authors><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author></authors><title>Automatic Extraction of Open Space Area from High Resolution Urban
  Satellite Imagery</title><categories>cs.CV</categories><comments>This paper has been withdrawn by the author due to a crucial error in
  algorithm</comments><acm-class>I.4; I.5</acm-class><journal-ref>International Journal of Image Processing (IJIP), Volume (4):
  Issue (2),2010, PP: 164-174</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the 21st century, Aerial and satellite images are information rich. They
are also complex to analyze. For GIS systems, many features require fast and
reliable extraction of open space area from high resolution satellite imagery.
In this paper we will study efficient and reliable automatic extraction
algorithm to find out the open space area from the high resolution urban
satellite imagery. This automatic extraction algorithm uses some filters and
segmentations and grouping is applying on satellite images. And the result
images may use to calculate the total available open space area and the built
up area. It may also use to compare the difference between present and past
open space area using historical urban satellite images of that same projection
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4727</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4727</id><created>2011-03-24</created><authors><author><keyname>Kalidindi</keyname><forenames>Ramaprasada R.</forenames></author><author><keyname>Raju</keyname><forenames>KVSVN</forenames></author><author><keyname>Kumari</keyname><forenames>V. Valli</forenames></author><author><keyname>Reddy</keyname><forenames>C. S.</forenames></author></authors><title>Trust Based Participant Driven Privacy Control in Participatory Sensing</title><categories>cs.NI</categories><comments>14 pages</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.2, No.1, March 2011, pp.71-84</journal-ref><doi>10.5121/ijasuc.2011.2107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Widespread use of sensors and multisensory personal devices generate a lot of
personal information. Sharing this information with others could help in
various ways. However, this information may be misused when shared with all.
Sharing of information between trusted parties overcomes this problem. This
paper describes a model to share information based on interactions and opinions
to build trust among peers. It also considers institutional and other controls,
which influence the behaviour of the peers. The trust and control build
confidence. The computed confidence bespeaks whether to reveal information or
not thereby increasing trusted cooperation among peers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4749</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4749</id><created>2011-03-24</created><authors><author><keyname>Splendiani</keyname><forenames>Andrea</forenames></author><author><keyname>Rawlings</keyname><forenames>Chris J</forenames></author><author><keyname>Kuo</keyname><forenames>Shao-Chih</forenames></author><author><keyname>Stevens</keyname><forenames>Robert</forenames></author><author><keyname>Lord</keyname><forenames>Phillip</forenames></author></authors><title>Lost in translation: data integration tools meet the Semantic Web
  (experiences from the Ondex project)</title><categories>cs.SE</categories><comments>Presented at DEIT, Data Engineering and Internet Technology, 2011
  IEEE: CFP1113L-CDR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More information is now being published in machine processable form on the
web and, as de-facto distributed knowledge bases are materializing, partly
encouraged by the vision of the Semantic Web, the focus is shifting from the
publication of this information to its consumption. Platforms for data
integration, visualization and analysis that are based on a graph
representation of information appear first candidates to be consumers of
web-based information that is readily expressible as graphs. The question is
whether the adoption of these platforms to information available on the
Semantic Web requires some adaptation of their data structures and semantics.
Ondex is a network-based data integration, analysis and visualization platform
which has been developed in a Life Sciences context. A number of features,
including semantic annotation via ontologies and an attention to provenance and
evidence, make this an ideal candidate to consume Semantic Web information, as
well as a prototype for the application of network analysis tools in this
context. By analyzing the Ondex data structure and its usage, we have found a
set of discrepancies and errors arising from the semantic mismatch between a
procedural approach to network analysis and the implications of a web-based
representation of information. We report in the paper on the simple methodology
that we have adopted to conduct such analysis, and on issues that we have found
which may be relevant for a range of similar platforms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4756</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4756</id><created>2011-03-24</created><authors><author><keyname>Westra</keyname><forenames>Ronald L.</forenames></author><author><keyname>Petreczky</keyname><forenames>Mih&#xe1;ly</forenames></author><author><keyname>Peeters</keyname><forenames>Ralf L. M.</forenames></author></authors><title>Identification of Piecewise Linear Models of Complex Dynamical Systems</title><categories>math.OC cs.SY</categories><msc-class>93B15, 93B20, 93B25, 93C99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper addresses the realization and identification problem or a subclass
of piecewise-affine hybrid systems. The paper provides necessary and sufficient
conditions for existence of a realization, a characterization of minimality,
and an identification algorithm for this subclass of hybrid systems. The
considered system class and the identification problem are motivated by
applications in systems biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4767</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4767</id><created>2011-03-24</created><authors><author><keyname>Mohajer</keyname><forenames>Mojgan</forenames></author><author><keyname>Englmeier</keyname><forenames>Karl-Hans</forenames></author><author><keyname>Schmid</keyname><forenames>Volker J.</forenames></author></authors><title>A comparison of Gap statistic definitions with and without logarithm
  function</title><categories>stat.ME cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gap statistic is a standard method for determining the number of clusters
in a set of data. The Gap statistic standardizes the graph of $\log(W_{k})$,
where $W_{k}$ is the within-cluster dispersion, by comparing it to its
expectation under an appropriate null reference distribution of the data. We
suggest to use $W_{k}$ instead of $\log(W_{k})$, and to compare it to the
expectation of $W_{k}$ under a null reference distribution. In fact, whenever a
number fulfills the original Gap statistic inequality, this number also
fulfills the inequality of a Gap statistic using $W_{k}$, but not \textit{vice
versa}. The two definitions of the Gap function are evaluated on several
simulated data sets and on a real data of DCE-MR images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4769</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4769</id><created>2011-03-24</created><authors><author><keyname>Manju</keyname></author><author><keyname>Pujari</keyname><forenames>Arun K.</forenames></author></authors><title>High-Energy-First (HEF) Heuristic for Energy-Efficient Target Coverage
  Problem</title><categories>cs.NI</categories><comments>14 pages, 6 figures, IJASUC</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.2, No.1, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Target coverage problem in wireless sensor networks is concerned with
maximizing the lifetime of the network while continuously monitoring a set of
targets. A sensor covers targets which are within the sensing range. For a set
of sensors and a set of targets, the sensor-target coverage relationship is
assumed to be known. A sensor cover is a set of sensors that covers all the
targets. The target coverage problem is to determine a set of sensor covers
with maximum aggregated lifetime while constraining the life of each sensor by
its initial battery life. The problem is proved to be NP-complete and heuristic
algorithms to solve this problem are proposed. In the present study, we give a
unified interpretation of earlier algorithms and propose a new and efficient
algorithm. We show that all known algorithms are based on a common reasoning
though they seem to be derived from different algorithmic paradigms. We also
show that though some algorithms guarantee bound on the quality of the
solution, this bound is not meaningful and not practical too. Our
interpretation provides a better insight to the solution techniques. We propose
a new greedy heuristic which prioritizes sensors on residual battery life. We
show empirically that the proposed algorithm outperforms all other heuristics
in terms of quality of solution. Our experimental study over a large set of
randomly generated problem instances also reveals that a very na\&quot;ive greedy
approach yields solutions which is reasonably (appx. 10%) close to the actual
optimal solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4774</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4774</id><created>2011-03-24</created><authors><author><keyname>Dutta</keyname><forenames>Biswajit</forenames></author><author><keyname>Barik</keyname><forenames>Somsubhra</forenames></author><author><keyname>Chockalingam</keyname><forenames>A.</forenames></author></authors><title>Full-Rate Full-Diversity Achieving MIMO Precoding with Partial CSIT</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a $n_t\times n_r$ multiple-input multiple-output
(MIMO) channel subjected to block fading. Reliability (in terms of achieved
diversity order) and rate (in number of symbols transmitted per channel use)
are of interest in such channels. We propose a new precoding scheme which
achieves both full diversity ($n_tn_r$th order diversity) as well as full rate
($n_t$ symbols per channel use) using partial channel state information at the
transmitter (CSIT), applicable in MIMO systems including $n_r&lt;n_t$ asymmetric
MIMO. The proposed scheme achieves full diversity and improved coding gain
through an optimization over the choice of constellation sets. The optimization
maximizes $d_{min}^2$ for our precoding scheme subject to an energy constraint.
The scheme requires feedback of $n_t-1$ angle parameter values, compared to
$2n_tn_r$ real coefficients in case of full CSIT. Error rate performance
results for $3\times 1$, $3\times 2$, $4\times 1$, $8\times 1$ precoded MIMO
systems (with $n_t=3,3,4,8$ symbols per channel use, respectively) show that
the proposed precoding achieves 3rd, 6th, 4th and 8th order diversities,
respectively. These performances are shown to be better than other precoding
schemes in the literature; the better performance is due to the choice of the
signal sets and the feedback angles in the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4778</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4778</id><created>2011-03-24</created><authors><author><keyname>Balc&#xe1;zar</keyname><forenames>Jos&#xe9; L.</forenames></author></authors><title>Formal and Computational Properties of the Confidence Boost of
  Association Rules</title><categories>cs.DB cs.AI</categories><msc-class>68</msc-class><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some existing notions of redundancy among association rules allow for a
logical-style characterization and lead to irredundant bases of absolutely
minimum size. One can push the intuition of redundancy further and find an
intuitive notion of interest of an association rule, in terms of its &quot;novelty&quot;
with respect to other rules. Namely: an irredundant rule is so because its
confidence is higher than what the rest of the rules would suggest; then, one
can ask: how much higher? We propose to measure such a sort of &quot;novelty&quot;
through the confidence boost of a rule, which encompasses two previous similar
notions (confidence width and rule blocking, of which the latter is closely
related to the earlier measure &quot;improvement&quot;). Acting as a complement to
confidence and support, the confidence boost helps to obtain small and crisp
sets of mined association rules, and solves the well-known problem that, in
certain cases, rules of negative correlation may pass the confidence bound. We
analyze the properties of two versions of the notion of confidence boost, one
of them a natural generalization of the other. We develop efficient
algorithmics to filter rules according to their confidence boost, compare the
concept to some similar notions in the bibliography, and describe the results
of some experimentation employing the new notions on standard benchmark
datasets. We describe an open-source association mining tool that embodies one
of our variants of confidence boost in such a way that the data mining process
does not require the user to select any value for any parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4784</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4784</id><created>2011-03-24</created><authors><author><keyname>Tian</keyname><forenames>Chao</forenames></author></authors><title>Latent Capacity Region: A Case Study on Symmetric Broadcast With Common
  Messages</title><categories>cs.IT math.IT</categories><comments>13 pages, 4 figures, double column format. to appear in IEEE Trans.
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of broadcast with common messages, and focus on the
case that the common message rate $R_{\mathcal{A}}$, i.e., the rate of the
message intended for all the receivers in the set $\mathcal{A}$, is the same
for all the set $\mathcal{A}$ of the same cardinality. Instead of attempting to
characterize the capacity region of general broadcast channels, we only
consider the structure of the capacity region that any broadcast channel should
bear. The concept of latent capacity region is useful in capturing these
underlying constraints, and we provide a complete characterization of the
latent capacity region for the symmetric broadcast problem. The converse proof
of this tight characterization relies on a deterministic broadcast channel
model. The achievability proof generalizes the familiar rate transfer argument
to include more involved erasure correction coding among messages, thus
revealing an inherent connection between broadcast with common message and
erasure correction codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4787</identifier>
 <datestamp>2011-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4787</id><created>2011-03-24</created><updated>2011-07-06</updated><authors><author><keyname>Castiglione</keyname><forenames>Paolo</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author><author><keyname>Zemen</keyname><forenames>Thomas</forenames></author></authors><title>Energy Management Policies for Energy-Neutral Source-Channel Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications in March 2011; last
  update in July 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cyber-physical systems where sensors measure the temporal evolution of a
given phenomenon of interest and radio communication takes place over short
distances, the energy spent for source acquisition and compression may be
comparable with that used for transmission. Additionally, in order to avoid
limited lifetime issues, sensors may be powered via energy harvesting and thus
collect all the energy they need from the environment. This work addresses the
problem of energy allocation over source acquisition/compression and
transmission for energy-harvesting sensors. At first, focusing on a
single-sensor, energy management policies are identified that guarantee a
maximal average distortion while at the same time ensuring the stability of the
queue connecting source and channel encoders. It is shown that the identified
class of policies is optimal in the sense that it stabilizes the queue whenever
this is feasible by any other technique that satisfies the same average
distortion constraint. Moreover, this class of policies performs an independent
resource optimization for the source and channel encoders. Analog transmission
techniques as well as suboptimal strategies that do not use the energy buffer
(battery) or use it only for adapting either source or channel encoder energy
allocation are also studied for performance comparison. The problem of
optimizing the desired trade-off between average distortion and delay is then
formulated and solved via dynamic programming tools. Finally, a system with
multiple sensors is considered and time-division scheduling strategies are
derived that are able to maintain the stability of all data queues and to meet
the average distortion constraints at all sensors whenever it is feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4820</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4820</id><created>2011-03-24</created><authors><author><keyname>Tantar</keyname><forenames>Alexandru-Adrian</forenames></author><author><keyname>Tantar</keyname><forenames>Emilia</forenames></author><author><keyname>Bouvry</keyname><forenames>Pascal</forenames></author></authors><title>Design and classification of dynamic multi-objective optimization
  problems</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we provide a formal model for the different time-dependent
components that can appear in dynamic multi-objective optimization problems,
along with a classification of these components. Four main classes are
identified, corresponding to the influence of the parameters, objective
functions, previous states of the dynamic system and, last, environment
changes, which in turn lead to online optimization problems. For illustration
purposes, examples are provided for each class identified - by no means
standing as the most representative ones or exhaustive in scope.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4854</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4854</id><created>2011-03-24</created><authors><author><keyname>Gintautas</keyname><forenames>Vadas</forenames></author><author><keyname>Hagberg</keyname><forenames>Aric</forenames></author><author><keyname>Bettencourt</keyname><forenames>Luis M. A.</forenames></author></authors><title>When is social computation better than the sum of its parts?</title><categories>cs.IT cs.AI math.IT</categories><comments>5 pages, 1 figure; In H. Liu, J. J. Salerno, and M. J. Young,
  editors, Social Computing, Behavior Modeling, and Prediction, 2009</comments><report-no>LA-UR 09-00432</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social computation, whether in the form of searches performed by swarms of
agents or collective predictions of markets, often supplies remarkably good
solutions to complex problems. In many examples, individuals trying to solve a
problem locally can aggregate their information and work together to arrive at
a superior global solution. This suggests that there may be general principles
of information aggregation and coordination that can transcend particular
applications. Here we show that the general structure of this problem can be
cast in terms of information theory and derive mathematical conditions that
lead to optimal multi-agent searches. Specifically, we illustrate the problem
in terms of local search algorithms for autonomous agents looking for the
spatial location of a stochastic source. We explore the types of search
problems, defined in terms of the statistical properties of the source and the
nature of measurements at each agent, for which coordination among multiple
searchers yields an advantage beyond that gained by having the same number of
independent searchers. We show that effective coordination corresponds to
synergy and that ineffective coordination corresponds to independence as
defined using information theory. We classify explicit types of sources in
terms of their potential for synergy. We show that sources that emit
uncorrelated signals provide no opportunity for synergetic coordination while
sources that emit signals that are correlated in some way, do allow for strong
synergy between searchers. These general considerations are crucial for
designing optimal algorithms for particular search problems in real world
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4865</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4865</id><created>2011-03-24</created><authors><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Kalyanaraman</keyname><forenames>Kaushik</forenames></author></authors><title>Numerical Experiments for Darcy Flow on a Surface Using Mixed Exterior
  Calculus Methods</title><categories>cs.NA cs.CG math.NA</categories><comments>14 pages, 11 figures</comments><msc-class>65N30, 65N08, 76S05</msc-class><acm-class>G.1.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are very few results on mixed finite element methods on surfaces. A
theory for the study of such methods was given recently by Holst and Stern,
using a variational crimes framework in the context of finite element exterior
calculus. However, we are not aware of any numerical experiments where mixed
finite elements derived from discretizations of exterior calculus are used for
a surface domain. This short note shows results of our preliminary experiments
using mixed methods for Darcy flow (hence scalar Poisson's equation in mixed
form) on surfaces. We demonstrate two numerical methods. One is derived from
the primal-dual Discrete Exterior Calculus and the other from lowest order
finite element exterior calculus. The programming was done in the language
Python, using the PyDEC package which makes the code very short and easy to
read. The qualitative convergence studies seem to be promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4868</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4868</id><created>2011-03-24</created><updated>2011-08-29</updated><authors><author><keyname>Parsaeefard</keyname><forenames>Saeedeh</forenames></author><author><keyname>Sharafat</keyname><forenames>Ahmad R.</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Robust Additively Coupled Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the robust Nash equilibrium (RNE) for a class of games in
communications systems and networks where the impact of users on each other is
an additive function of their strategies. Each user measures this impact, which
may be corrupted by uncertainty in feedback delays, estimation errors,
movements of users, etc. To study the outcome of the game in which such
uncertainties are encountered, we utilize the worst-case robust optimization
theory. The existence and uniqueness conditions of RNE are derived using
finite-dimensions variational inequalities. To describe the effect of
uncertainty on the performance of the system, we use two criteria measured at
the RNE and at the equilibrium of the game without uncertainty. The first is
the difference between the respective social utility of users and, the second
is the differences between the strategies of users at their respective
equilibria. These differences are obtained for the case of a unique NE and
multiple NEs. To reach the RNE, we propose a distributed algorithm based on the
proximal response map and derive the conditions for its convergence.
Simulations of the power control game in interference channels, and Jackson
networks validate our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4873</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4873</id><created>2011-03-24</created><authors><author><keyname>Parsaeefard</keyname><forenames>Saeedeh</forenames></author><author><keyname>Sharafat</keyname><forenames>Ahmad R.</forenames></author></authors><title>Robust Spectrum Sharing via Worst Case Approach</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers non-cooperative and fully-distributed power-allocation
for secondary-users (SUs) in spectrum-sharing environments when
normalized-interference to each secondary-user is uncertain. We model each
uncertain parameter by the sum of its nominal (estimated) value and a bounded
additive error in a convex set, and show that the allocated power always
converges to its equilibrium, called robust Nash equilibrium (RNE). In the case
of a bounded and symmetric uncertainty set, we show that the power allocation
problem for each SU is simplified, and can be solved in a distributed manner.
We derive the conditions for RNE's uniqueness and for convergence of the
distributed algorithm; and show that the total throughput (social utility) is
less than that at NE when RNE is unique. We also show that for multiple RNEs,
the the social utility may be higher at a RNE as compared to that at the
corresponding NE, and demonstrate that this is caused by SUs' orthogonal
utilization of bandwidth for increasing the social utility. Simulations confirm
our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4875</identifier>
 <datestamp>2011-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4875</id><created>2011-03-24</created><updated>2011-08-31</updated><authors><author><keyname>Stanton</keyname><forenames>Isabelle</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author></authors><title>Constructing and Sampling Graphs with a Prescribed Joint Degree
  Distribution</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most influential recent results in network analysis is that many
natural networks exhibit a power-law or log-normal degree distribution. This
has inspired numerous generative models that match this property. However, more
recent work has shown that while these generative models do have the right
degree distribution, they are not good models for real life networks due to
their differences on other important metrics like conductance. We believe this
is, in part, because many of these real-world networks have very different
joint degree distributions, i.e. the probability that a randomly selected edge
will be between nodes of degree k and l. Assortativity is a sufficient
statistic of the joint degree distribution, and it has been previously noted
that social networks tend to be assortative, while biological and technological
networks tend to be disassortative.
  We suggest understanding the relationship between network structure and the
joint degree distribution of graphs is an interesting avenue of further
research. An important tool for such studies are algorithms that can generate
random instances of graphs with the same joint degree distribution. This is the
main topic of this paper and we study the problem from both a theoretical and
practical perspective. We provide an algorithm for constructing simple graphs
from a given joint degree distribution, and a Monte Carlo Markov Chain method
for sampling them. We also show that the state space of simple graphs with a
fixed degree distribution is connected via end point switches. We empirically
evaluate the mixing time of this Markov Chain by using experiments based on the
autocorrelation of each edge. These experiments show that our Markov Chain
mixes quickly on real graphs, allowing for utilization of our techniques in
practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4881</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4881</id><created>2011-03-24</created><authors><author><keyname>Rodrigues</keyname><forenames>Wendell</forenames></author><author><keyname>Guyomarc'h</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Dekeyser</keyname><forenames>Jean-Luc</forenames></author></authors><title>Programming Massively Parallel Architectures using MARTE: a Case Study</title><categories>cs.DC cs.SE</categories><comments>2nd Workshop on Model Based Engineering for Embedded Systems Design
  on DATE 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, several industrial applications are being ported to parallel
architectures. These applications take advantage of the potential parallelism
provided by multiple core processors. Many-core processors, especially the
GPUs(Graphics Processing Unit), have led the race of floating-point performance
since 2003. While the performance improvement of general- purpose
microprocessors has slowed significantly, the GPUs have continued to improve
relentlessly. As of 2009, the ratio between many-core GPUs and multicore CPUs
for peak floating-point calculation throughput is about 10 times. However, as
parallel programming requires a non-trivial distribution of tasks and data,
developers find it hard to implement their applications effectively. Aiming to
improve the use of many-core processors, this work presents an case-study using
UML and MARTE profile to specify and generate OpenCL code for intensive signal
processing applications. Benchmark results show us the viability of the use of
MDE approaches to generate GPU applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4888</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4888</id><created>2011-03-24</created><authors><author><keyname>Gintautas</keyname><forenames>Vadas</forenames></author><author><keyname>Hagberg</keyname><forenames>Aric</forenames></author><author><keyname>Bettencourt</keyname><forenames>Luis M. A.</forenames></author></authors><title>Cooperative searching for stochastic targets</title><categories>cs.IT cs.AI math.IT</categories><comments>Journal of Intelligence Community Research and Development,
  permanently available on Intelink, October 2010</comments><report-no>LA-UR 09-07676</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial search problems abound in the real world, from locating hidden
nuclear or chemical sources to finding skiers after an avalanche. We exemplify
the formalism and solution for spatial searches involving two agents that may
or may not choose to share information during a search. For certain classes of
tasks, sharing information between multiple searchers makes cooperative
searching advantageous. In some examples, agents are able to realize synergy by
aggregating information and moving based on local judgments about maximal
information gathering expectations. We also explore one- and two-dimensional
simplified situations analytically and numerically to provide a framework for
analyzing more complex problems. These general considerations provide a guide
for designing optimal algorithms for real-world search problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4893</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4893</id><created>2011-03-24</created><authors><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Savla</keyname><forenames>Ketan</forenames></author><author><keyname>Acemoglu</keyname><forenames>Daron</forenames></author><author><keyname>Dahleh</keyname><forenames>Munther A.</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Robust Distributed Routing in Dynamical Flow Networks - Part II: Strong
  Resilience, Equilibrium Selection and Cascaded Failures</title><categories>cs.SY math.CA math.DS math.OC nlin.AO</categories><comments>33 pages, 7 figures, journal submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Strong resilience properties of dynamical flow networks are analyzed for
distributed routing policies. The latter are characterized by the property that
the way the inflow at a non-destination node gets split among its outgoing
links is allowed to depend only on local information about the current particle
densities on the outgoing links. The strong resilience of the network is
defined as the infimum sum of link-wise flow capacity reductions under which
the network cannot maintain the asymptotic total inflow to the destination node
to be equal to the inflow at the origin. A class of distributed routing
policies that are locally responsive to local information is shown to yield the
maximum possible strong resilience under such local information constraints for
an acyclic dynamical flow network with a single origin-destination pair. The
maximal strong resilience achievable is shown to be equal to the minimum node
residual capacity of the network. The latter depends on the limit flow of the
unperturbed network and is defined as the minimum, among all the
non-destination nodes, of the sum, over all the links outgoing from the node,
of the differences between the maximum flow capacity and the limit flow of the
unperturbed network. We propose a simple convex optimization problem to solve
for equilibrium limit flows of the unperturbed network that minimize average
delay subject to strong resilience guarantees, and discuss the use of tolls to
induce such an equilibrium limit flow in transportation networks. Finally, we
present illustrative simulations to discuss the connection between cascaded
failures and the resilience properties of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4896</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4896</id><created>2011-03-24</created><authors><author><keyname>Louradour</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Larochelle</keyname><forenames>Hugo</forenames></author></authors><title>Classification of Sets using Restricted Boltzmann Machines</title><categories>cs.LG stat.ML</categories><comments>17 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of classification when inputs correspond to sets of
vectors. This setting occurs in many problems such as the classification of
pieces of mail containing several pages, of web sites with several sections or
of images that have been pre-segmented into smaller regions. We propose
generalizations of the restricted Boltzmann machine (RBM) that are appropriate
in this context and explore how to incorporate different assumptions about the
relationship between the input sets and the target class within the RBM. In
experiments on standard multiple-instance learning datasets, we demonstrate the
competitiveness of approaches based on RBMs and apply the proposed variants to
the problem of incoming mail classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4904</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4904</id><created>2011-03-25</created><authors><author><keyname>Feldman</keyname><forenames>Vitaly</forenames></author></authors><title>Distribution-Independent Evolvability of Linear Threshold Functions</title><categories>cs.LG cs.CC cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Valiant's (2007) model of evolvability models the evolutionary process of
acquiring useful functionality as a restricted form of learning from random
examples. Linear threshold functions and their various subclasses, such as
conjunctions and decision lists, play a fundamental role in learning theory and
hence their evolvability has been the primary focus of research on Valiant's
framework (2007). One of the main open problems regarding the model is whether
conjunctions are evolvable distribution-independently (Feldman and Valiant,
2008). We show that the answer is negative. Our proof is based on a new
combinatorial parameter of a concept class that lower-bounds the complexity of
learning from correlations.
  We contrast the lower bound with a proof that linear threshold functions
having a non-negligible margin on the data points are evolvable
distribution-independently via a simple mutation algorithm. Our algorithm
relies on a non-linear loss function being used to select the hypotheses
instead of 0-1 loss in Valiant's (2007) original definition. The proof of
evolvability requires that the loss function satisfies several mild conditions
that are, for example, satisfied by the quadratic loss function studied in
several other works (Michael, 2007; Feldman, 2009; Valiant, 2010). An important
property of our evolution algorithm is monotonicity, that is the algorithm
guarantees evolvability without any decreases in performance. Previously,
monotone evolvability was only shown for conjunctions with quadratic loss
(Feldman, 2009) or when the distribution on the domain is severely restricted
(Michael, 2007; Feldman, 2009; Kanade et al., 2010)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4905</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4905</id><created>2011-03-25</created><authors><author><keyname>Rahamatkar</keyname><forenames>Surendra</forenames></author><author><keyname>Agarwal</keyname><forenames>Dr. Ajay</forenames></author></authors><title>A Reference Based, Tree Structured Time Synchronization Approach and its
  Analysis in WSN</title><categories>cs.DC cs.NI</categories><comments>12 pages</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC)Vol.2, No.1, March 2011</journal-ref><doi>10.5121/ijasuc.2011.2103</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Time synchronization for wireless sensor networks (WSNs) has been studied in
recent years as a fundamental and significant research issue. Many applications
based on these WSNs assume local clocks at each sensor node that need to be
synchronized to a common notion of time. Time synchronization in a WSN is
critical for accurate time stamping of events and fine-tuned coordination among
the sensor nodes to reduce power consumption. This paper proposes a
bidirectional, reference based, tree structured time synchronization service
for WSNs along with network evaluation phase. This offers a push mechanism for
(i) accurate and (ii) low overhead for global time synchronization. Analysis
study of proposed approach shows that it is lightweight as the number of
required broadcasting messages is constant in one broadcasting domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4907</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4907</id><created>2011-03-25</created><authors><author><keyname>Satheesh</keyname><forenames>S.</forenames></author><author><keyname>Prasad</keyname><forenames>KVSVR</forenames></author></authors><title>Medical Image Denoising using Adaptive Threshold Based on Contourlet
  Transform</title><categories>cs.OH</categories><comments>7 pages, 6 figures,Advanced Computing: An International Journal
  (ACIJ) ISSN: 2229 - 6727 [Online]; 2229 - 726X [Print]</comments><doi>10.5121/acij.2011.2205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image denoising has become an essential exercise in medical imaging
especially the Magnetic Resonance Imaging (MRI). This paper proposes a medical
image denoising algorithm using contourlet transform. Numerical results show
that the proposed algorithm can obtained higher peak signal to noise ratio
(PSNR) than wavelet based denoising algorithms using MR Images in the presence
of AWGN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4913</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4913</id><created>2011-03-25</created><authors><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author></authors><title>Automatic Open Space Area Extraction and Change Detection from High
  Resolution Urban Satellite Images</title><categories>cs.CV</categories><comments>07 page, 13 figures</comments><acm-class>I.4.6; I.5</acm-class><journal-ref>IJCA,Special Issue on RTIPPR (2):76-82, 2010. Published By
  Foundation of Computer Science</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study efficient and reliable automatic extraction algorithm
to find out the open space area from the high resolution urban satellite
imagery, and to detect changes from the extracted open space area during the
period 2003, 2006 and 2008. This automatic extraction and change detection
algorithm uses some filters, segmentation and grouping that are applied on
satellite images. The resultant images may be used to calculate the total
available open space area and the built up area. It may also be used to compare
the difference between present and past open space area using historical urban
satellite images of that same projection, which is an important geo spatial
data management application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4914</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4914</id><created>2011-03-25</created><authors><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author></authors><title>Generating contour lines using different elevation data file formats</title><categories>cs.OH</categories><comments>07 Pages, 10 Figures</comments><acm-class>H.2.8; G.1.2</acm-class><journal-ref>International Journal of Computer Science and Applications
  (IJCSA), 2010, Vol. 3, No 1. PP: 19-25</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In terrain mapping, there are so many ways to measure and estimate the
terrain measurements like contouring, vertical profiling, hill shading,
hypsometric tinting, perspective view, etc. Here in this paper we are using the
contouring techniques to generate the contours for the different digital
elevation data like DEM, HGT, IMG etc. The elevation data is captured in dem,
hgt and img formats of the same projected area and the contour is generated
using the existing techniques and applications. The exact differences, errors
of elevation (contour) intervals, slopes and heights are analyzed and
recovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4916</identifier>
 <datestamp>2012-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4916</id><created>2011-03-25</created><updated>2012-03-09</updated><authors><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author></authors><title>Detection of Spatial Changes using Spatial Data Mining</title><categories>cs.DB</categories><comments>This paper has been withdrawn by the author</comments><acm-class>H.2.8; I.5.3</acm-class><journal-ref>Advances in Information Mining, ISSN: 0975-3265, Volume 2, Issue
  2, 2010, pp-14-18</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Change detection based on analysis and samples are analyzed. Land
use/cover change detection based on SDM is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4919</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4919</id><created>2011-03-25</created><authors><author><keyname>Feng</keyname><forenames>Xu</forenames></author><author><keyname>Zhao</keyname><forenames>Jichang</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Link Prediction in Complex Networks: A Clustering Perspective</title><categories>cs.SI physics.soc-ph</categories><comments>7 pages, 3 figures</comments><journal-ref>Eur. Phys. J. B (2012) 85: 3</journal-ref><doi>10.1140/epjb/e2011-20207-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link prediction is an open problem in the complex network, which attracts
much research interest currently. However, little attention has been paid to
the relation between network structure and the performance of prediction
methods. In order to fill this vital gap, we try to understand how the network
structure affects the performance of link prediction methods in the view of
clustering. Our experiments on both synthetic and real-world networks show that
as the clustering grows, the precision of these methods could be improved
remarkably, while for the sparse and weakly clustered network, they perform
poorly. We explain this through the distinguishment caused by increased
clustering between the score distribution of positive and negative instances.
Our finding also sheds light on the problem of how to select appropriate
approaches for different networks with various densities and clusterings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4951</identifier>
 <datestamp>2012-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4951</id><created>2011-03-25</created><updated>2012-04-05</updated><authors><author><keyname>de Castro</keyname><forenames>Yohann</forenames><affiliation>IMT</affiliation></author><author><keyname>Gamboa</keyname><forenames>Fabrice</forenames><affiliation>IMT</affiliation></author></authors><title>Exact Reconstruction using Beurling Minimal Extrapolation</title><categories>math.ST cs.IT math.IT math.OC math.PR stat.TH</categories><comments>27 pages, 3 figures version 2 : minor changes and new title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that measures with finite support on the real line are the unique
solution to an algorithm, named generalized minimal extrapolation, involving
only a finite number of generalized moments (which encompass the standard
moments, the Laplace transform, the Stieltjes transformation, etc). Generalized
minimal extrapolation shares related geometric properties with basis pursuit of
Chen, Donoho and Saunders [CDS98]. Indeed we also extend some standard results
of compressed sensing (the dual polynomial, the nullspace property) to the
signed measure framework. We express exact reconstruction in terms of a simple
interpolation problem. We prove that every nonnegative measure, supported by a
set containing s points,can be exactly recovered from only 2s + 1 generalized
moments. This result leads to a new construction of deterministic sensing
matrices for compressed sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4959</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4959</id><created>2011-03-25</created><updated>2011-04-20</updated><authors><author><keyname>Chatterjee</keyname><forenames>Debasish</forenames></author><author><keyname>Hokayem</keyname><forenames>Peter</forenames></author><author><keyname>Ramponi</keyname><forenames>Federico</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>On mean-square boundedness of stochastic linear systems with quantized
  observations</title><categories>math.OC cs.SY</categories><comments>4 pages, 2 fig</comments><msc-class>93E15</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose a procedure to design a state-quantizer with finitely many bins
for a marginally stable stochastic linear system evolving in $\R^d$, and a
bounded policy based on the resulting quantized state measurements to ensure
bounded second moment in closed-loop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4977</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4977</id><created>2011-03-25</created><authors><author><keyname>K&#xe4;llberg</keyname><forenames>David</forenames></author><author><keyname>Leonenko</keyname><forenames>Nikolaj</forenames></author><author><keyname>Seleznjev</keyname><forenames>Oleg</forenames></author></authors><title>Statistical Inference for R\'enyi Entropy Functionals</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>15 pages, 4 figures</comments><msc-class>94A15, 62G20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous entropy-type characteristics (functionals) generalizing R\'enyi
entropy are widely used in mathematical statistics, physics, information
theory, and signal processing for characterizing uncertainty in probability
distributions and distribution identification problems. We consider estimators
of some entropy (integral) functionals for discrete and continuous
distributions based on the number of epsilon-close vector records in the
corresponding independent and identically distributed samples from two
distributions. The estimators form a triangular scheme of generalized
U-statistics. We show the asymptotic properties of these estimators (e.g.,
consistency and asymptotic normality). The results can be applied in various
problems in computer science and mathematical statistics (e.g., approximate
matching for random databases, record linkage, image matching).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4979</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4979</id><created>2011-03-25</created><updated>2016-02-29</updated><authors><author><keyname>Iyer</keyname><forenames>K. Viswanathan</forenames></author></authors><title>An Introduction to Functional dependency in Relational Databases</title><categories>cs.DB</categories><comments>Revised 2nd version</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This write-up is the suggested lecture notes for a second level course on
advanced topics in database systems for master's students of Computer Science
with a theoretical focus. A prerequisite in algorithms and an exposure to
database systems are required. Additional reading may require exposure to
mathematical logic. The starting point for these notes are from M.Y.Vardi's
survey listed herein as a reference - some of the proofs are presented as such
. This select rewrite on functional dependency is intended to provide a few
clarifications even though radically new design approaches are now being
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4984</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4984</id><created>2011-03-25</created><updated>2011-10-17</updated><authors><author><keyname>Koiran</keyname><forenames>Pascal</forenames></author><author><keyname>Zouzias</keyname><forenames>Anastasios</forenames></author></authors><title>On the Certification of the Restricted Isometry Property</title><categories>cs.CC cs.DM</categories><comments>21 pages, This version corrects a small typo at the end of the proof
  of Theorem 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a technique for finding sparse solutions to
underdetermined linear systems. This technique relies on properties of the
sensing matrix such as the restricted isometry property. Sensing matrices that
satisfy the restricted isometry property with optimal parameters are mainly
obtained via probabilistic arguments. Given any matrix, deciding whether it
satisfies the restricted isometry property is a non-trivial computational
problem. In this paper, we give reductions from dense subgraph problems to the
certification of the restricted isometry property. This gives evidence that
certifying the restricted isometry property is unlikely to be feasible in
polynomial-time. Moreover, on the positive side we propose an improvement on
the brute-force enumeration algorithm for checking the restricted isometry
property.
  Another contribution of independent interest is a spectral algorithm for
certifying that a random graph does not contain any dense k-subgraph. This
&quot;skewed spectral algorithm&quot; performs better than the basic spectral algorithm
in a certain range of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.4990</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.4990</id><created>2011-03-25</created><updated>2011-11-15</updated><authors><author><keyname>Beyersdorff</keyname><forenames>Olaf</forenames><affiliation>Leibniz Universit&#xe4;t Hannover, Germany</affiliation></author><author><keyname>Meier</keyname><forenames>Arne</forenames><affiliation>Leibniz Universit&#xe4;t Hannover</affiliation></author><author><keyname>Mundhenk</keyname><forenames>Martin</forenames><affiliation>Friedrich-Schiller-Universit&#xe4;t Jena</affiliation></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames><affiliation>University of Manchester</affiliation></author><author><keyname>Thomas</keyname><forenames>Michael</forenames><affiliation>Leibniz Universit&#xe4;t Hannover</affiliation></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames><affiliation>Leibniz Universit&#xe4;t Hannover</affiliation></author></authors><title>Model Checking CTL is Almost Always Inherently Sequential</title><categories>cs.LO cs.CC</categories><proxy>LMCS</proxy><acm-class>cs.CC</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 17,
  2011) lmcs:1007</journal-ref><doi>10.2168/LMCS-7(2:12)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The model checking problem for CTL is known to be P-complete (Clarke,
Emerson, and Sistla (1986), see Schnoebelen (2002)). We consider fragments of
CTL obtained by restricting the use of temporal modalities or the use of
negations---restrictions already studied for LTL by Sistla and Clarke (1985)
and Markey (2004). For all these fragments, except for the trivial case without
any temporal operator, we systematically prove model checking to be either
inherently sequential (P-complete) or very efficiently parallelizable
(LOGCFL-complete). For most fragments, however, model checking for CTL is
already P-complete. Hence our results indicate that, in cases where the
combined complexity is of relevance, approaching CTL model checking by
parallelism cannot be expected to result in any significant speedup. We also
completely determine the complexity of the model checking problem for all
fragments of the extensions ECTL, CTL+, and ECTL+.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5002</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5002</id><created>2011-03-25</created><authors><author><keyname>Fortuna</keyname><forenames>Blaz</forenames></author><author><keyname>Mladenic</keyname><forenames>Dunja</forenames></author><author><keyname>Grobelnik</keyname><forenames>Marko</forenames></author></authors><title>User Modeling Combining Access Logs, Page Content and Semantics</title><categories>cs.IR cs.AI cs.HC</categories><comments>1st International Workshop on Usage Analysis and the Web of Data
  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),
  Hyderabad, India, March 28th, 2011</comments><report-no>WWW2011USEWOD/2011/formlagro</report-no><acm-class>H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes an approach to modeling users of large Web sites based on
combining different data sources: access logs and content of the accessed pages
are combined with semantic information about the Web pages, the users and the
accesses of the users to the Web site. The assumption is that we are dealing
with a large Web site providing content to a large number of users accessing
the site. The proposed approach represents each user by a set of features
derived from the different data sources, where some feature values may be
missing for some users. It further enables user modeling based on the provided
characteristics of the targeted user subset. The approach is evaluated on
real-world data where we compare performance of the automatic assignment of a
user to a predefined user segment when different data sources are used to
represent the users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5027</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5027</id><created>2011-03-25</created><authors><author><keyname>Ermann</keyname><forenames>Leonardo</forenames></author><author><keyname>Shepelyansky</keyname><forenames>Dima L.</forenames></author></authors><title>Google matrix of the world trade network</title><categories>q-fin.GN cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>14 pages, 13 figures. More detailed data and high definition figures
  are available on the website:
  http://www.quantware.ups-tlse.fr/QWLIB/tradecheirank/index.html</comments><journal-ref>Acta Physica Polonica A, vol. 120 (6A), A-158 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the United Nations Commodity Trade Statistics Database
[http://comtrade.un.org/db/] we construct the Google matrix of the world trade
network and analyze its properties for various trade commodities for all
countries and all available years from 1962 to 2009. The trade flows on this
network are classified with the help of PageRank and CheiRank algorithms
developed for the World Wide Web and other large scale directed networks. For
the world trade this ranking treats all countries on equal democratic grounds
independent of country richness. Still this method puts at the top a group of
industrially developed countries for trade in {\it all commodities}. Our study
establishes the existence of two solid state like domains of rich and poor
countries which remain stable in time, while the majority of countries are
shown to be in a gas like phase with strong rank fluctuations. A simple random
matrix model provides a good description of statistical distribution of
countries in two-dimensional rank plane. The comparison with usual ranking by
export and import highlights new features and possibilities of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5028</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5028</id><created>2011-03-25</created><updated>2013-06-06</updated><authors><author><keyname>Lambert</keyname><forenames>Dean</forenames></author><author><keyname>Hamilton</keyname><forenames>Alasdair C.</forenames></author><author><keyname>Constable</keyname><forenames>George</forenames></author><author><keyname>Snehanshu</keyname><forenames>Harsh</forenames></author><author><keyname>Talati</keyname><forenames>Sharvil</forenames></author><author><keyname>Courtial</keyname><forenames>Johannes</forenames></author></authors><title>User guide to TIM, a ray-tracing program for forbidden ray optics</title><categories>physics.ed-ph cs.GR</categories><comments>20 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This user guide outlines the use of TIM, an interactive ray-tracing program
with a number of special powers. TIM can be customised and embedded into
internet pages, making it suitable not only for research but also for its
dissemination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5034</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5034</id><created>2011-03-23</created><authors><author><keyname>Chern</keyname><forenames>Tong</forenames></author></authors><title>On Understanding and Machine Understanding</title><categories>cs.AI</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, we try to propose a self-similar network theory for the
basic understanding. By extending the natural languages to a kind of so called
idealy sufficient language, we can proceed a few steps to the investigation of
the language searching and the language understanding of AI.
  Image understanding, and the familiarity of the brain to the surrounding
environment are also discussed. Group effects are discussed by addressing the
essense of the power of influences, and constructing the influence network of a
society. We also give a discussion of inspirations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5035</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5035</id><created>2011-03-25</created><authors><author><keyname>Bejuri</keyname><forenames>Wan Mohd. Yaakob Wan</forenames></author><author><keyname>Mohamad</keyname><forenames>Mohd. Murtadha</forenames></author><author><keyname>Sapri</keyname><forenames>Maimunah</forenames></author></authors><title>Ubiquitous Positioning: A Taxonomy for Location Determination on Mobile
  Navigation System</title><categories>cs.HC</categories><comments>15 Pages, 3 figures</comments><doi>10.5121/sipij.2011.2103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The location determination in obstructed area can be very challenging
especially if Global Positioning System are blocked. Users will find it
difficult to navigate directly on-site in such condition, especially indoor car
park lot or obstructed environment. Sometimes, it needs to combine with other
sensors and positioning methods in order to determine the location with more
intelligent, reliable and ubiquity. By using ubiquitous positioning in mobile
navigation system, it is a promising ubiquitous location technique in a mobile
phone since as it is a familiar personal electronic device for many people.
However, as research on ubiquitous positioning systems goes beyond basic
methods there is an increasing need for better comparison of proposed
ubiquitous positioning systems. System developers are also lacking of good
frameworks for understanding different options during building ubiquitous
positioning systems. This paper proposes taxonomy to address both of these
problems. The proposed taxonomy has been constructed from a literature study of
papers and articles on positioning estimation that can be used to determine
location everywhere on mobile navigation system. For researchers the taxonomy
can also be used as an aid for scoping out future research in the area of
ubiquitous positioning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5043</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5043</id><created>2011-03-25</created><authors><author><keyname>Arias</keyname><forenames>Mario</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Javier D.</forenames></author><author><keyname>Mart&#xed;nez-Prieto</keyname><forenames>Miguel A.</forenames></author><author><keyname>de la Fuente</keyname><forenames>Pablo</forenames></author></authors><title>An Empirical Study of Real-World SPARQL Queries</title><categories>cs.IR cs.AI cs.HC</categories><comments>1st International Workshop on Usage Analysis and the Web of Data
  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),
  Hyderabad, India, March 28th, 2011</comments><report-no>WWW2011USEWOD/2011/arifermarfue</report-no><acm-class>H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding how users tailor their SPARQL queries is crucial when designing
query evaluation engines or fine-tuning RDF stores with performance in mind. In
this paper we analyze 3 million real-world SPARQL queries extracted from logs
of the DBPedia and SWDF public endpoints. We aim at finding which are the most
used language elements both from syntactical and structural perspectives,
paying special attention to triple patterns and joins, since they are indeed
some of the most expensive SPARQL operations at evaluation phase. We have
determined that most of the queries are simple and include few triple patterns
and joins, being Subject-Subject, Subject-Object and Object-Object the most
common join types. The graph patterns are usually star-shaped and despite
triple pattern chains exist, they are generally short.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5044</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5044</id><created>2011-03-25</created><authors><author><keyname>Sureka</keyname><forenames>Ashish</forenames></author></authors><title>Mining User Comment Activity for Detecting Forum Spammers in YouTube</title><categories>cs.IR cs.AI cs.HC</categories><comments>1st International Workshop on Usage Analysis and the Web of Data
  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),
  Hyderabad, India, March 28th, 2011</comments><report-no>WWW2011USEWOD/2011/sur</report-no><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research shows that comment spamming (comments which are unsolicited,
unrelated, abusive, hateful, commercial advertisements etc) in online
discussion forums has become a common phenomenon in Web 2.0 applications and
there is a strong need to counter or combat comment spamming. We present a
method to automatically detect comment spammer in YouTube (largest and a
popular video sharing website) forums. The proposed technique is based on
mining comment activity log of a user and extracting patterns (such as time
interval between subsequent comments, presence of exactly same comment across
multiple unrelated videos) indicating spam behavior. We perform empirical
analysis on data crawled from YouTube and demonstrate that the proposed method
is effective for the task of comment spammer detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5045</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5045</id><created>2011-03-25</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>Bounds and Inequalities Relating h-Index, g-Index, e-Index and
  Generalized Impact Factor</title><categories>cs.DL</categories><comments>17 pages, 6 figures, 5 tables</comments><msc-class>68M20</msc-class><acm-class>H.3.1; C.3.3; C.2.3</acm-class><doi>10.1371/journal.pone.0033699</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding relationships among different indices such as h-index, g-index,
e-index, and generalized impact factor is a challenging task. In this paper, we
describe some bounds and inequalities relating h-index, g-index, e-index, and
generalized impact factor. We derive the bounds and inequalities relating these
indexing parameters from their basic definitions and without assuming any
continuous model to be followed by any of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5046</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5046</id><created>2011-03-25</created><authors><author><keyname>Kirchberg</keyname><forenames>Markus</forenames></author><author><keyname>Ko</keyname><forenames>Ryan K L</forenames></author><author><keyname>Lee</keyname><forenames>Bu Sung</forenames></author></authors><title>From Linked Data to Relevant Data -- Time is the Essence</title><categories>cs.IR cs.AI cs.HC</categories><comments>1st International Workshop on Usage Analysis and the Web of Data
  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),
  Hyderabad, India, March 28th, 2011</comments><report-no>WWW2011USEWOD/2011/kirkolee</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Semantic Web initiative puts emphasis not primarily on putting data on
the Web, but rather on creating links in a way that both humans and machines
can explore the Web of data. When such users access the Web, they leave a trail
as Web servers maintain a history of requests. Web usage mining approaches have
been studied since the beginning of the Web given the log's huge potential for
purposes such as resource annotation, personalization, forecasting etc.
However, the impact of any such efforts has not really gone beyond generating
statistics detailing who, when, and how Web pages maintained by a Web server
were visited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5055</identifier>
 <datestamp>2011-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5055</id><created>2011-03-25</created><updated>2011-09-15</updated><authors><author><keyname>Chugh</keyname><forenames>Ravi</forenames></author><author><keyname>Rondon</keyname><forenames>Patrick M.</forenames></author><author><keyname>Jhala</keyname><forenames>Ranjit</forenames></author></authors><title>Nested Refinements for Dynamic Languages</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Programs written in dynamic languages make heavy use of features --- run-time
type tests, value-indexed dictionaries, polymorphism, and higher-order
functions --- that are beyond the reach of type systems that employ either
purely syntactic or purely semantic reasoning. We present a core calculus,
System D, that merges these two modes of reasoning into a single powerful
mechanism of nested refinement types wherein the typing relation is itself a
predicate in the refinement logic. System D coordinates SMT-based logical
implication and syntactic subtyping to automatically typecheck sophisticated
dynamic language programs. By coupling nested refinements with McCarthy's
theory of finite maps, System D can precisely reason about the interaction of
higher-order functions, polymorphism, and dictionaries. The addition of type
predicates to the refinement logic creates a circularity that leads to unique
technical challenges in the metatheory, which we solve with a novel
stratification approach that we use to prove the soundness of System D.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5071</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5071</id><created>2011-03-25</created><authors><author><keyname>Fisikopoulos</keyname><forenames>Vissarion</forenames></author></authors><title>Study of the effect of cost policies in the convergence of selfish
  strategies in Pure Nash Equilibria in Congestion Games</title><categories>cs.GT</categories><comments>Extended Abstract</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this work we study of competitive situations among users of a set of
global resources. More precisely we study the effect of cost policies used by
these resources in the convergence time to a pure Nash equilibrium. The work is
divided in two parts. In the theoretical part we prove lower and upper bounds
on the convergence time for various cost policies. We then implement all the
models we study and provide some experimental results. These results follows
the theoretical with one exception which is the most interesting among the
experiments. In the case of coalitional users the theoretical upper bound is
pseudo-polynomial to the number of users but the experimental results shows
that the convergence time is polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5078</identifier>
 <datestamp>2014-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5078</id><created>2011-03-25</created><authors><author><keyname>&#x106;iri&#x107;</keyname><forenames>Miroslav</forenames></author><author><keyname>Ignjatovi&#x107;</keyname><forenames>Jelena</forenames></author><author><keyname>Jan&#x10d;i&#x107;</keyname><forenames>Ivana</forenames></author><author><keyname>Damljanovi&#x107;</keyname><forenames>Nada</forenames></author></authors><title>Algorithms for computing the greatest simulations and bisimulations
  between fuzzy automata</title><categories>cs.FL cs.AI</categories><comments>19 pages, submitted to a journal</comments><msc-class>68Q05, 68Q45, 68Q70, 68Q85, 68T37, 03E72, 15B15</msc-class><acm-class>F.1.1; I.2.3</acm-class><journal-ref>Fuzzy Sets and Systems 208 (2012) 22-42</journal-ref><doi>10.1016/j.fss.2012.05.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, two types of simulations (forward and backward simulations) and
four types of bisimulations (forward, backward, forward-backward, and
backward-forward bisimulations) between fuzzy automata have been introduced. If
there is at least one simulation/bisimulation of some of these types between
the given fuzzy automata, it has been proved that there is the greatest
simulation/bisimulation of this kind. In the present paper, for any of the
above-mentioned types of simulations/bisimulations we provide an effective
algorithm for deciding whether there is a simulation/bisimulation of this type
between the given fuzzy automata, and for computing the greatest one, whenever
it exists. The algorithms are based on the method developed in [J.
Ignjatovi\'c, M. \'Ciri\'c, S. Bogdanovi\'c, On the greatest solutions to
certain systems of fuzzy relation inequalities and equations, Fuzzy Sets and
Systems 161 (2010) 3081-3113], which comes down to the computing of the
greatest post-fixed point, contained in a given fuzzy relation, of an isotone
function on the lattice of fuzzy relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5081</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5081</id><created>2011-03-25</created><updated>2011-06-28</updated><authors><author><keyname>Kuruvada</keyname><forenames>Praveen</forenames></author></authors><title>Using Variable Threshold to Increase Capacity in a Feedback Neural
  Network</title><categories>cs.NE</categories><comments>16 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents new results on the use of variable thresholds to
increase the capacity of a feedback neural network. Non-binary networks are
also considered in this analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5082</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5082</id><created>2011-03-25</created><authors><author><keyname>Moser</keyname><forenames>Georg</forenames></author><author><keyname>Schnabl</keyname><forenames>Andreas</forenames></author></authors><title>Termination Proofs in the Dependency Pair Framework May Induce Multiple
  Recursive Derivational Complexity</title><categories>cs.LO</categories><comments>22 pages, extended conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the derivational complexity of rewrite systems whose termination is
provable in the dependency pair framework using the processors for reduction
pairs, dependency graphs, or the subterm criterion. We show that the
derivational complexity of such systems is bounded by a multiple recursive
function, provided the derivational complexity induced by the employed base
techniques is at most multiple recursive. Moreover we show that this upper
bound is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5102</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5102</id><created>2011-03-25</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Data-Oblivious External-Memory Algorithms for the Compaction, Selection,
  and Sorting of Outsourced Data</title><categories>cs.DS cs.CR cs.DC</categories><comments>Full version of a paper appearing in 2011 ACM Symp. on Parallelism in
  Algorithms and Architectures (SPAA)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present data-oblivious algorithms in the external-memory model for
compaction, selection, and sorting. Motivation for such problems comes from
clients who use outsourced data storage services and wish to mask their data
access patterns. We show that compaction and selection can be done
data-obliviously using $O(N/B)$ I/Os, and sorting can be done, with a high
probability of success, using $O((N/B)\log_{M/B} (N/B))$ I/Os. Our methods use
a number of new algorithmic techniques, including data-oblivious uses of
invertible Bloom lookup tables, a butterfly-like compression network,
randomized data thinning, and &quot;shuffle-and-deal&quot; data perturbation. In
addition, since data-oblivious sorting is the bottleneck in the &quot;inner loop&quot; in
existing oblivious RAM simulations, our sorting result improves the amortized
time overhead to do oblivious RAM simulation by a logarithmic factor in the
external-memory model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5110</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5110</id><created>2011-03-26</created><updated>2011-08-18</updated><authors><author><keyname>Li</keyname><forenames>Menghui</forenames></author><author><keyname>Guan</keyname><forenames>Shuguang</forenames></author><author><keyname>Lai</keyname><forenames>Choy-Heng</forenames></author></authors><title>Formation of Modularity in a Model of Evolving Networks</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>6 pages, 4 figurs</comments><journal-ref>EPL, 95 (2011) 58004</journal-ref><doi>10.1209/0295-5075/95/58004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modularity structures are common in various social and biological networks.
However, its dynamical origin remains an open question. In this work, we set up
a dynamical model describing the evolution of a social network. Based on the
observations of real social networks, we introduced a link-creating/deleting
strategy according to the local dynamics in the model. Thus the coevolution of
dynamics and topology naturally determines the network properties. It is found
that for a small coupling strength, the networked system cannot reach any
synchronization and the network topology is homogeneous. Interestingly, when
the coupling strength is large enough, the networked system spontaneously forms
communities with different dynamical states. Meanwhile, the network topology
becomes heterogeneous with modular structures. It is further shown that in a
certain parameter regime, both the degree and the community size in the formed
network follow a power-law distribution, and the networks are found to be
assortative. These results are consistent with the characteristics of many
empirical networks, and are helpful to understand the mechanism of formation of
modularity in complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5115</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5115</id><created>2011-03-26</created><authors><author><keyname>Mutaf</keyname><forenames>Pars</forenames></author></authors><title>Defeating Internet attacks and Spam using &quot;disposable&quot; Mobile IPv6 home
  addresses</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model of operation for next generation wireless Internet, in
which a mobile host has hundreds of &quot;disposable&quot; Mobile IPv6 home addresses.
Each correspondent is distributed a different disposable home address. If
attacked on a given home address, the mobile user can block packets to that
address and become unreachable to the attacker. Blocking one address does not
affect other addresses. Other correspondents can still reach the mobile host. A
new home address can also be requested via e-mail, instant messaging, or
directly from the target host using a protocol that we develop. This model is
especially useful against battery exhausting Denial-of-Service (DoS) attacks
and CPU exhausting distributed DoS attacks, since it seems to be the only
viable solution, currently. We show however that this model can also be used to
defeat other attacks and also to stop spam.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5119</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5119</id><created>2011-03-26</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>A protocol for a message system for the tiles of the heptagrid, in the
  hyperbolic plane</title><categories>cs.DM</categories><comments>30 pages, 5 figures</comments><msc-class>68M12, 68M10</msc-class><acm-class>C.2.2; C.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a communication system for the tiles of the heptagrid,
a tiling of the hyperbolic plane. The method can be extended to other tilings
of this plane. The paper focuses on an actual implementation at the programming
stage with a short account of two experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5120</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5120</id><created>2011-03-26</created><updated>2011-04-28</updated><authors><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Cimini</keyname><forenames>Giulio</forenames></author><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Emergence of scale-free leadership structure in social recommender
  systems</title><categories>physics.soc-ph cs.IR cs.SI</categories><journal-ref>PLoS ONE 6(7): e20648 (2011)</journal-ref><doi>10.1371/journal.pone.0020648</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of the organization of social networks is important for
understanding of opinion formation, rumor spreading, and the emergence of
trends and fashion. This paper reports empirical analysis of networks extracted
from four leading sites with social functionality (Delicious, Flickr, Twitter
and YouTube) and shows that they all display a scale-free leadership structure.
To reproduce this feature, we propose an adaptive network model driven by
social recommending. Artificial agent-based simulations of this model highlight
a &quot;good get richer&quot; mechanism where users with broad interests and good
judgments are likely to become popular leaders for the others. Simulations also
indicate that the studied social recommendation mechanism can gradually improve
the user experience by adapting to tastes of its users. Finally we outline
implications for real online resource-sharing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5128</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5128</id><created>2011-03-26</created><authors><author><keyname>Lee</keyname><forenames>Chia-han</forenames></author><author><keyname>Wolf</keyname><forenames>Wayne</forenames></author></authors><title>Power Consumption of LDPC Decoders in Software Radio</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LDPC code is a powerful error correcting code and has been applied to many
advanced communication systems. The prosperity of software radio has motivated
us to investigate the implementation of LDPC decoders on processors. In this
paper, we estimate and compare complexity and power consumption of LDPC
decoding algorithms running on general purpose processors. Using the estimation
results, we show two power control schemes for software radio: SNR-based
algorithm diversity and joint transmit power and receiver energy management.
Overall, this paper discusses general concerns about using processors as the
software radio platform for the implementation of LDPC decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5131</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5131</id><created>2011-03-26</created><updated>2011-06-12</updated><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Oh</keyname><forenames>Jaelynn</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>Analysis of Equilibria and Strategic Interaction in Complex Networks</title><categories>cs.GT cs.SI cs.SY math.OC</categories><comments>7 pages, 3 figures. Related papers, data and software at
  http://alum.mit.edu/www/vmp</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies $n$-person simultaneous-move games with linear best
response function, where individuals interact within a given network structure.
This class of games have been used to model various settings, such as, public
goods, belief formation, peer effects, and oligopoly. The purpose of this paper
is to study the effect of the network structure on Nash equilibrium outcomes of
this class of games. Bramoull\'{e} et al. derived conditions for uniqueness and
stability of a Nash equilibrium in terms of the smallest eigenvalue of the
adjacency matrix representing the network of interactions. Motivated by this
result, we study how local structural properties of the network of interactions
affect this eigenvalue, influencing game equilibria. In particular, we use
algebraic graph theory and convex optimization to derive new bounds on the
smallest eigenvalue in terms of the distribution of degrees, cycles, and other
relevant substructures. We illustrate our results with numerical simulations
involving online social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5133</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5133</id><created>2011-03-26</created><updated>2012-10-14</updated><authors><author><keyname>Behboodi</keyname><forenames>Arash</forenames></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author></authors><title>Cooperative Strategies for Simultaneous and Broadcast Relay Channels</title><categories>cs.IT math.IT</categories><comments>32 pages, 7 figures, To appear in IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the \emph{simultaneous relay channel} (SRC) which consists of a set
of relay channels where the source wishes to transmit common and private
information to each of the destinations. This problem is recognized as being
equivalent to that of sending common and private information to several
destinations in presence of helper relays where each channel outcome becomes a
branch of the \emph{broadcast relay channel} (BRC). Cooperative schemes and
capacity region for a set with two memoryless relay channels are investigated.
The proposed coding schemes, based on \emph{Decode-and-Forward} (DF) and
\emph{Compress-and-Forward} (CF) must be capable of transmitting information
simultaneously to all destinations in such set.
  Depending on the quality of source-to-relay and relay-to-destination
channels, inner bounds on the capacity of the general BRC are derived. Three
cases of particular interest are considered: cooperation is based on DF
strategy for both users --referred to as DF-DF region--, cooperation is based
on CF strategy for both users --referred to as CF-CF region--, and cooperation
is based on DF strategy for one destination and CF for the other --referred to
as DF-CF region--. These results can be seen as a generalization and hence
unification of previous works. An outer-bound on the capacity of the general
BRC is also derived. Capacity results are obtained for the specific cases of
semi-degraded and degraded Gaussian simultaneous relay channels. Rates are
evaluated for Gaussian models where the source must guarantee a minimum amount
of information to both users while additional information is sent to each of
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5142</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5142</id><created>2011-03-26</created><authors><author><keyname>Braca</keyname><forenames>Paolo</forenames></author><author><keyname>Marano</keyname><forenames>Stefano</forenames></author><author><keyname>Matta</keyname><forenames>Vincenzo</forenames></author></authors><title>Asymptotic Properties of One-Bit Distributed Detection with Ordered
  Transmissions</title><categories>cs.IT cs.MA math.IT stat.AP</categories><comments>Submitted to IEEE Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a sensor network made of remote nodes connected to a common fusion
center. In a recent work Blum and Sadler [1] propose the idea of ordered
transmissions -sensors with more informative samples deliver their messages
first- and prove that optimal detection performance can be achieved using only
a subset of the total messages. Taking to one extreme this approach, we show
that just a single delivering allows making the detection errors as small as
desired, for a sufficiently large network size: a one-bit detection scheme can
be asymptotically consistent. The transmission ordering is based on the modulus
of some local statistic (MO system). We derive analytical results proving the
asymptotic consistency and, for the particular case that the local statistic is
the log-likelihood (\ell-MO system), we also obtain a bound on the error
convergence rate. All the theorems are proved under the general setup of random
number of sensors. Computer experiments corroborate the analysis and address
typical examples of applications including: non-homogeneous Poisson-deployed
networks, detection by per-sensor censoring, monitoring of energy-constrained
phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5162</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5162</id><created>2011-03-26</created><authors><author><keyname>Scherer</keyname><forenames>Michael</forenames><affiliation>LORIA</affiliation></author><author><keyname>Sidhom</keyname><forenames>Sahbi</forenames><affiliation>LORIA</affiliation></author></authors><title>Progress of concepts and processes in library information system:
  towards Library 2.0</title><categories>cs.DL</categories><proxy>ccsd</proxy><journal-ref>Information Systems and Economic Intelligence (SIIE'2011) : 4th
  edition 1 (2011) 123-130</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main principle of the Library 2.0 is in the fact that the information has
to be spread from the library to the user and viceversa, to allow fast and
permanent adaptation of the library services. Within the framework of the
implementation of the &quot;Departmental Plan of the Public Services Reading&quot; by the
&quot;General Council of Moselle&quot;, the division of the public reading develops a
departmental portal as main vector of the information with various users'
profile. The context of this research work takes a part of a Master degree
training Diploma in STI-Economic Intelligence (Nancy2 University), combining
facets of R&amp;D in a professional context at the &quot;Conseil G\'en\'eral de la
Moselle&quot; in France.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5163</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5163</id><created>2011-03-26</created><authors><author><keyname>Chambrion</keyname><forenames>Thomas</forenames><affiliation>INRIA Lorraine / IECN / MMAS, IECN</affiliation></author><author><keyname>Munnier</keyname><forenames>Alexandre</forenames><affiliation>INRIA Lorraine / IECN / MMAS, IECN</affiliation></author></authors><title>Generic Controllability of 3D Swimmers in a Perfect Fluid</title><categories>math.OC cs.SY physics.bio-ph</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of controlling a dynamical system governing the motion
of a 3D weighted shape changing body swimming in a perfect fluid. The rigid
displacement of the swimmer results from the exchange of momentum between
prescribed shape changes and the flow, the total impulse of the fluid-swimmer
system being constant for all times. We prove the following tracking results:
(i) Synchronized swimming: Maybe up to an arbitrarily small change of its
density, any swimmer can approximately follow any given trajectory while, in
addition, undergoing approximately any given shape changes. In this statement,
the control consists in arbitrarily small superimposed deformations; (ii)
Freestyle swimming: Maybe up to an arbitrarily small change of its density, any
swimmer can approximately tracks any given trajectory by combining suitably at
most five basic movements that can be generically chosen (no macro shape
changes are prescribed in this statement).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5167</identifier>
 <datestamp>2011-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5167</id><created>2011-03-26</created><updated>2011-06-14</updated><authors><author><keyname>Might</keyname><forenames>Matthew</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>A family of abstract interpretations for static analysis of concurrent
  higher-order programs</title><categories>cs.PL</categories><comments>The 18th International Static Analysis Symposium (SAS 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a framework for computing two foundational analyses for concurrent
higher-order programs: (control-)flow analysis (CFA) and may-happen-in-parallel
analysis (MHP). We pay special attention to the unique challenges posed by the
unrestricted mixture of first-class continuations and dynamically spawned
threads. To set the stage, we formulate a concrete model of concurrent
higher-order programs: the P(CEK*)S machine. We find that the systematic
abstract interpretation of this machine is capable of computing both flow and
MHP analyses. Yet, a closer examination finds that the precision for MHP is
poor. As a remedy, we adapt a shape analytic technique-singleton abstraction-to
dynamically spawned threads (as opposed to objects in the heap). We then show
that if MHP analysis is not of interest, we can substantially accelerate the
computation of flow analysis alone by collapsing thread interleavings with a
second layer of abstraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5169</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5169</id><created>2011-03-26</created><updated>2011-04-11</updated><authors><author><keyname>Lee</keyname><forenames>Ritchie</forenames></author><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author></authors><title>Game theoretic modeling of pilot behavior during mid-air encounters</title><categories>cs.GT</categories><comments>NIPS2010: Decision Making with Multiple Imperfect Decision Makers. 38
  pages, 13 figures</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We show how to combine Bayes nets and game theory to predict the behavior of
hybrid systems involving both humans and automated components. We call this
novel framework &quot;Semi Network-Form Games,&quot; and illustrate it by predicting
aircraft pilot behavior in potential near mid-air collisions. At present, at
the beginning of such potential collisions, a collision avoidance system in the
aircraft cockpit advises the pilots what to do to avoid the collision. However
studies of mid-air encounters have found wide variability in pilot responses to
avoidance system advisories. In particular, pilots rarely perfectly execute the
recommended maneuvers, despite the fact that the collision avoidance system's
effectiveness relies on their doing so. Rather pilots decide their actions
based on all information available to them (advisory, instrument readings,
visual observations). We show how to build this aspect into a semi network-form
game model of the encounter and then present computational simulations of the
resultant model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5170</identifier>
 <datestamp>2012-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5170</id><created>2011-03-26</created><updated>2012-03-13</updated><authors><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Procopiuc</keyname><forenames>Magda</forenames></author><author><keyname>Shen</keyname><forenames>Entong</forenames></author><author><keyname>Srivastava</keyname><forenames>Divesh</forenames></author><author><keyname>Yu</keyname><forenames>Ting</forenames></author></authors><title>Differentially Private Spatial Decompositions</title><categories>cs.DB</categories><comments>ICDE 2012 (supplementary acknowledgments)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy has recently emerged as the de facto standard for
private data release. This makes it possible to provide strong theoretical
guarantees on the privacy and utility of released data. While it is well-known
how to release data based on counts and simple functions under this guarantee,
it remains to provide general purpose techniques to release different kinds of
data. In this paper, we focus on spatial data such as locations and more
generally any data that can be indexed by a tree structure. Directly applying
existing differential privacy methods to this type of data simply generates
noise. Instead, we introduce a new class of &quot;private spatial decompositions&quot;:
these adapt standard spatial indexing methods such as quadtrees and kd-trees to
provide a private description of the data distribution. Equipping such
structures with differential privacy requires several steps to ensure that they
provide meaningful privacy guarantees. Various primitives, such as choosing
splitting points and describing the distribution of points within a region,
must be done privately, and the guarantees of the different building blocks
composed to provide an overall guarantee. Consequently, we expose the design
space for private spatial decompositions, and analyze some key examples. Our
experimental study demonstrates that it is possible to build such
decompositions efficiently, and use them to answer a variety of queries
privately with high accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5188</identifier>
 <datestamp>2014-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5188</id><created>2011-03-27</created><updated>2011-08-25</updated><authors><author><keyname>Alvim</keyname><forenames>M&#xe1;rio S.</forenames></author><author><keyname>Andr&#xe9;s</keyname><forenames>Miguel E.</forenames></author><author><keyname>Chatzikokolakis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Degano</keyname><forenames>Pierpaolo</forenames></author><author><keyname>Palamidessi</keyname><forenames>Catuscia</forenames></author></authors><title>Differential Privacy: on the trade-off between Utility and Information
  Leakage</title><categories>cs.CR cs.DB cs.IT math.IT</categories><comments>30 pages; HAL repository</comments><report-no>inria-00580122</report-no><journal-ref>Proceedings of the 8th International Workshop on Formal Aspects of
  Security &amp; Trust (FAST'11), Springer, LNCS 7140, pp. 39-54, 2011</journal-ref><doi>10.1007/978-3-642-29420-4_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a notion of privacy that has become very popular in
the database community. Roughly, the idea is that a randomized query mechanism
provides sufficient privacy protection if the ratio between the probabilities
that two adjacent datasets give the same answer is bound by e^epsilon. In the
field of information flow there is a similar concern for controlling
information leakage, i.e. limiting the possibility of inferring the secret
information from the observables. In recent years, researchers have proposed to
quantify the leakage in terms of R\'enyi min mutual information, a notion
strictly related to the Bayes risk. In this paper, we show how to model the
query system in terms of an information-theoretic channel, and we compare the
notion of differential privacy with that of mutual information. We show that
differential privacy implies a bound on the mutual information (but not
vice-versa). Furthermore, we show that our bound is tight. Then, we consider
the utility of the randomization mechanism, which represents how close the
randomized answers are, in average, to the real ones. We show that the notion
of differential privacy implies a bound on utility, also tight, and we propose
a method that under certain conditions builds an optimal randomization
mechanism, i.e. a mechanism which provides the best utility while guaranteeing
differential privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5197</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5197</id><created>2011-03-27</created><authors><author><keyname>Babaheidarian</keyname><forenames>Parisa</forenames></author><author><keyname>Salimi</keyname><forenames>Somayeh</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>A New Secret key Agreement Scheme in a Four-Terminal Network</title><categories>cs.CR cs.IT math.IT</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new scenario for generating a secret key and two private keys among three
Terminals in the presence of an external eavesdropper is considered. Terminals
1, 2 and 3 intend to share a common secret key concealed from the external
eavesdropper (Terminal 4) and simultaneously, each of Terminals 1 and 2 intends
to share a private key with Terminal 3 while keeping it concealed from each
other and from Terminal 4. All four Terminals observe i.i.d. outputs of
correlated sources and there is a public channel from Terminal 3 to Terminals 1
and 2. An inner bound of the &quot;secret key-private keys capacity region&quot; is
derived and the single letter capacity regions are obtained for some special
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5199</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5199</id><created>2011-03-27</created><authors><author><keyname>Petrov</keyname><forenames>A. S.</forenames></author><author><keyname>Plotnikov</keyname><forenames>A. D.</forenames></author></authors><title>Encipher of information on the basis of geometrical presentations</title><categories>cs.CR</categories><comments>7 pages</comments><msc-class>94A60, 68P25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we examine a ciphertext on the basis of using geometrical
objects. Each symbol normative alphabet is determined as a point on the plane.
We consider possible ways for presentation of these points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5215</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5215</id><created>2011-03-27</created><updated>2012-08-09</updated><authors><author><keyname>Le</keyname><forenames>Dai Tri Man</forenames><affiliation>University of Toronto</affiliation></author><author><keyname>Cook</keyname><forenames>Stephen A.</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Formalizing Randomized Matching Algorithms</title><categories>cs.LO cs.CC math.LO</categories><proxy>LMCS</proxy><acm-class>F.2.2, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 10,
  2012) lmcs:973</journal-ref><doi>10.2168/LMCS-8(3:5)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using Je\v{r}\'abek 's framework for probabilistic reasoning, we formalize
the correctness of two fundamental RNC^2 algorithms for bipartite perfect
matching within the theory VPV for polytime reasoning. The first algorithm is
for testing if a bipartite graph has a perfect matching, and is based on the
Schwartz-Zippel Lemma for polynomial identity testing applied to the Edmonds
polynomial of the graph. The second algorithm, due to Mulmuley, Vazirani and
Vazirani, is for finding a perfect matching, where the key ingredient of this
algorithm is the Isolating Lemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5218</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5218</id><created>2011-03-27</created><updated>2011-03-30</updated><authors><author><keyname>Taneja</keyname><forenames>Inder Jeet</forenames></author></authors><title>Generalized Symmetric Divergence Measures and the Probability of Error</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are three classical divergence measures exist in the literature on
information theory and statistics. These are namely, Jeffryes-Kullback-Leiber
J-divergence. Sibson-Burbea-Rao Jensen-Shannon divegernce and Taneja
Arithmetic-Geometric divergence. These three measures bear an interesting
relationship among each other. The divergence measures like Hellinger
discrimination, symmetric chi-square divergence, and triangular discrimination
are also known in the literature. In this paper, we have considered generalized
symmetric divergence measures having the measures given above as particular
cases. Bounds on the probability of error are obtained in terms of generalized
symmetric divergence measures. Study of bounds on probability of error is
extended for the difference of divergence measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5219</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5219</id><created>2011-03-27</created><authors><author><keyname>Taneja</keyname><forenames>Inder Jeet</forenames></author></authors><title>Upper Bounds on the Probability of Error in terms of Mean Divergence
  Measures</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we shall consider some famous means such as arithmetic,
harmonic, geometric, root square mean, etc. Considering the difference of these
means, we can establish. some inequalities among them. Interestingly, the
difference of mean considered is convex functions. Applying some properties,
upper bounds on the probability of error are established in this paper. It is
also shown that the results obtained are sharper than obtained directly
applying known inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5230</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5230</id><created>2011-03-27</created><authors><author><keyname>Kolpakov</keyname><forenames>Roman</forenames></author></authors><title>On primary and secondary repetitions in words</title><categories>cs.FL</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combinatorial properties of maximal repetitions (runs) in formal words are
studied. We classify all maximal repetitions in a word as primary and secondary
where the set of all primary repetitions determines all the other repetitons in
the word. Essential combinatorial properties of primary repetitions are
established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5231</identifier>
 <datestamp>2011-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5231</id><created>2011-03-27</created><authors><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Yeung</keyname><forenames>Chi Ho</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Leaders in Social Networks, the Delicious Case</title><categories>physics.soc-ph cs.IR cs.SI</categories><comments>14 pages, 6 figures, with supporting information</comments><journal-ref>PLoS ONE 6(6): e21202 (2011)</journal-ref><doi>10.1371/journal.pone.0021202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding pertinent information is not limited to search engines. Online
communities can amplify the influence of a small number of power users for the
benefit of all other users. Users' information foraging in depth and breadth
can be greatly enhanced by choosing suitable leaders. For instance in
delicious.com, users subscribe to leaders' collection which lead to a deeper
and wider reach not achievable with search engines. To consolidate such
collective search, it is essential to utilize the leadership topology and
identify influential users. Google's PageRank, as a successful search algorithm
in the World Wide Web, turns out to be less effective in networks of people. We
thus devise an adaptive and parameter-free algorithm, the LeaderRank, to
quantify user influence. We show that LeaderRank outperforms PageRank in terms
of ranking effectiveness, as well as robustness against manipulations and noisy
data. These results suggest that leaders who are aware of their clout may
reinforce the development of social networks, and thus the power of collective
search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5241</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5241</id><created>2011-03-27</created><updated>2011-06-13</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>Integrated Impact Indicators (I3) compared with Impact Factors (IFs): An
  alternative research design with policy implications</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In bibliometrics, the association of &quot;impact&quot; with central-tendency
statistics is mistaken. Impacts add up, and citation curves should therefore be
integrated instead of averaged. For example, the journals MIS Quarterly and
JASIST differ by a factor of two in terms of their respective impact factors
(IF), but the journal with the lower IF has the higher impact. Using percentile
ranks (e.g., top-1%, top-10%, etc.), an integrated impact indicator (I3) can be
based on integration of the citation curves, but after normalization of the
citation curves to the same scale. The results across document sets can be
compared as percentages of the total impact of a reference set. Total number of
citations, however, should not be used instead because the shape of the
citation curves is then not appreciated. I3 can be applied to any document set
and any citation window. The results of the integration (summation) are fully
decomposable in terms of journals or instititutional units such as nations,
universities, etc., because percentile ranks are determined at the paper level.
In this study, we first compare I3 with IFs for the journals in two ISI Subject
Categories (&quot;Information Science &amp; Library Science&quot; and &quot;Multidisciplinary
Sciences&quot;). The LIS set is additionally decomposed in terms of nations. Policy
implications of this possible paradigm shift in citation impact analysis are
specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5254</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5254</id><created>2011-03-27</created><updated>2011-05-06</updated><authors><author><keyname>Waugh</keyname><forenames>Kevin</forenames></author><author><keyname>Ziebart</keyname><forenames>Brian D.</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>Computational Rationalization: The Inverse Equilibrium Problem</title><categories>cs.GT</categories><comments>8 pages, 4 page appendix, ICML 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling the purposeful behavior of imperfect agents from a small number of
observations is a challenging task. When restricted to the single-agent
decision-theoretic setting, inverse optimal control techniques assume that
observed behavior is an approximately optimal solution to an unknown decision
problem. These techniques learn a utility function that explains the example
behavior and can then be used to accurately predict or imitate future behavior
in similar observed or unobserved situations.
  In this work, we consider similar tasks in competitive and cooperative
multi-agent domains. Here, unlike single-agent settings, a player cannot
myopically maximize its reward --- it must speculate on how the other agents
may act to influence the game's outcome. Employing the game-theoretic notion of
regret and the principle of maximum entropy, we introduce a technique for
predicting and generalizing behavior, as well as recovering a reward function
in these domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5258</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5258</id><created>2011-03-27</created><updated>2012-01-31</updated><authors><author><keyname>Grong</keyname><forenames>Erlend</forenames></author></authors><title>Controllability of rolling without twisting or slipping in higher
  dimensions</title><categories>math.OC cs.SY math.DG</categories><comments>21 pages</comments><msc-class>37J60, 53A55, 53A17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe how the dynamical system of rolling two $n$-dimensional
connected, oriented Riemannian manifolds $M$ and $\hat M$ without twisting or
slipping, can be lifted to a nonholonomic system of elements in the product of
the oriented orthonormal frame bundles belonging to the manifolds. By
considering the lifted problem and using properties of the elements in the
respective principal Ehresmann connections, we obtain sufficient conditions for
the local controllability of the system in terms of the curvature tensors and
the sectional curvatures of the manifolds involved. We also give some results
for the particular cases when $M$ and $\hat M$ are locally symmetric or
complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5269</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5269</id><created>2011-03-27</created><authors><author><keyname>Lu</keyname><forenames>Qiming</forenames></author><author><keyname>Korniss</keyname><forenames>G.</forenames></author><author><keyname>Szymanski</keyname><forenames>B. K.</forenames></author></authors><title>Naming Games in Two-Dimensional and Small-World-Connected Random
  Geometric Networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><journal-ref>Phys. Rev. E 77, 016111 (2008)</journal-ref><doi>10.1103/PhysRevE.77.016111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a prototypical agent-based model, the Naming Game, on
two-dimensional random geometric networks. The Naming Game [A. Baronchelli et
al., J. Stat. Mech.: Theory Exp. (2006) P06014.] is a minimal model, employing
local communications that captures the emergence of shared communication
schemes (languages) in a population of autonomous semiotic agents. Implementing
the Naming Games with local broadcasts on random geometric graphs, serves as a
model for agreement dynamics in large-scale, autonomously operating wireless
sensor networks. Further, it captures essential features of the scaling
properties of the agreement process for spatially-embedded autonomous agents.
Among the relevant observables capturing the temporal properties of the
agreement process, we investigate the cluster-size distribution and the
distribution of the agreement times, both exhibiting dynamic scaling. We also
present results for the case when a small density of long-range communication
links are added on top of the random geometric graph, resulting in a
&quot;small-world&quot;-like network and yielding a significantly reduced time to reach
global agreement. We construct a finite-size scaling analysis for the agreement
times in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5286</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5286</id><created>2011-03-28</created><updated>2011-05-14</updated><authors><author><keyname>Gore</keyname><forenames>Rajeev</forenames><affiliation>The Australian National University</affiliation></author><author><keyname>Postniece</keyname><forenames>Linda</forenames><affiliation>The Australian National University</affiliation></author><author><keyname>Tiu</keyname><forenames>Alwen F</forenames><affiliation>The Australian National University</affiliation></author></authors><title>On the Correspondence between Display Postulates and Deep Inference in
  Nested Sequent Calculi for Tense Logics</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 17,
  2011) lmcs:971</journal-ref><doi>10.2168/LMCS-7(2:8)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two styles of proof calculi for a family of tense logics,
presented in a formalism based on nested sequents. A nested sequent can be seen
as a tree of traditional single-sided sequents. Our first style of calculi is
what we call &quot;shallow calculi&quot;, where inference rules are only applied at the
root node in a nested sequent. Our shallow calculi are extensions of Kashima's
calculus for tense logic and share an essential characteristic with display
calculi, namely, the presence of structural rules called &quot;display postulates&quot;.
Shallow calculi enjoy a simple cut elimination procedure, but are unsuitable
for proof search due to the presence of display postulates and other structural
rules. The second style of calculi uses deep-inference, whereby inference rules
can be applied at any node in a nested sequent. We show that, for a range of
extensions of tense logic, the two styles of calculi are equivalent, and there
is a natural proof theoretic correspondence between display postulates and deep
inference. The deep inference calculi enjoy the subformula property and have no
display postulates or other structural rules, making them a better framework
for proof search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5290</identifier>
 <datestamp>2012-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5290</id><created>2011-03-28</created><updated>2012-05-09</updated><authors><author><keyname>Ho</keyname><forenames>Chin Keong</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Optimal Energy Allocation for Wireless Communications with Energy
  Harvesting Constraints</title><categories>cs.IT math.IT</categories><comments>27 pages, 6 figures, accepted for publications at IEEE Transactions
  on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the use of energy harvesters, in place of conventional batteries
with fixed energy storage, for point-to-point wireless communications. In
addition to the challenge of transmitting in a channel with time selective
fading, energy harvesters provide a perpetual but unreliable energy source. In
this paper, we consider the problem of energy allocation over a finite horizon,
taking into account channel conditions and energy sources that are time
varying, so as to maximize the throughput. Two types of side information (SI)
on the channel conditions and harvested energy are assumed to be available:
causal SI (of the past and present slots) or full SI (of the past, present and
future slots). We obtain structural results for the optimal energy allocation,
via the use of dynamic programming and convex optimization techniques. In
particular, if unlimited energy can be stored in the battery with harvested
energy and the full SI is available, we prove the optimality of a water-filling
energy allocation solution where the so-called water levels follow a staircase
function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5320</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5320</id><created>2011-03-28</created><updated>2011-03-29</updated><authors><author><keyname>Montresor</keyname><forenames>Alberto</forenames></author><author><keyname>De Pellegrini</keyname><forenames>Francesco</forenames></author><author><keyname>Miorandi</keyname><forenames>Daniele</forenames></author></authors><title>Distributed k-Core Decomposition</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among the novel metrics used to study the relative importance of nodes in
complex networks, k-core decomposition has found a number of applications in
areas as diverse as sociology, proteinomics, graph visualization, and
distributed system analysis and design. This paper proposes new distributed
algorithms for the computation of the k-core decomposition of a network, with
the purpose of (i) enabling the run-time computation of k-cores in &quot;live&quot;
distributed systems and (ii) allowing the decomposition, over a set of
connected machines, of very large graphs, that cannot be hosted in a single
machine. Lower bounds on the algorithms complexity are given, and an exhaustive
experimental analysis on real-world graphs is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5348</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5348</id><created>2011-03-28</created><updated>2012-10-04</updated><authors><author><keyname>Duyck</keyname><forenames>Dieter</forenames></author><author><keyname>Boutros</keyname><forenames>Joseph Jean</forenames></author><author><keyname>Moeneclaey</keyname><forenames>Marc</forenames></author></authors><title>Precoding for Outage Probability Minimization on Block Fading Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to Transactions on Information Theory on March 23, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The outage probability limit is a fundamental and achievable lower bound on
the word error rate of coded communication systems affected by fading. This
limit is mainly determined by two parameters: the diversity order and the
coding gain. With linear precoding, full diversity on a block fading channel
can be achieved without error-correcting code. However, the effect of precoding
on the coding gain is not well known, mainly due to the complicated expression
of the outage probability. Using a geometric approach, this paper establishes
simple upper bounds on the outage probability, the minimization of which yields
to precoding matrices that achieve very good performance. For discrete
alphabets, it is shown that the combination of constellation expansion and
precoding is sufficient to closely approach the minimum possible outage
achieved by an i.i.d. Gaussian input distribution, thus essentially maximizing
the coding gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5362</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5362</id><created>2011-03-28</created><authors><author><keyname>Ausloos</keyname><forenames>Marcel R.</forenames></author><author><keyname>Vitanov</keyname><forenames>Nikolay K.</forenames></author><author><keyname>Dimitrova</keyname><forenames>Zlatinka I.</forenames></author></authors><title>Verhulst-Lotka-Volterra (VLV) model of ideological struggles</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>based on N.K. Ivanov invited paper at Dyses 2010
  (http://www.dyses2010.unisannio.it/INDEX.PHP)</comments><journal-ref>Advances and Applications in Statistical Sciences 6 (2011) 497 -
  505</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let the population of e.g. a country where some opinion struggle occurs be
varying in time, according to Verhulst equation. Consider next some competition
between opinions such as the dynamics be described by Lotka and Volterra
equations. Two kinds of influences can be used, in such a model, for describing
the dynamics of an agent opinion conversion: this can occur (i) either by means
of mass communication tools, under some external field influence, or (ii) by
means of direct interactions between agents. It results, among other features,
that change(s) in environmental conditions can prevent the extinction of
populations of followers of some ideology due to different kinds of
resurrection effects. The tension arising in the country population is proposed
to be measured by an appropriately defined scale index.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5364</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5364</id><created>2011-03-28</created><updated>2013-11-04</updated><authors><author><keyname>Boulch</keyname><forenames>Alexandre</forenames></author><author><keyname>de Verdi&#xe8;re</keyname><forenames>&#xc9;ric Colin</forenames></author><author><keyname>Nakamoto</keyname><forenames>Atsuhiro</forenames></author></authors><title>Irreducible triangulations of surfaces with boundary</title><categories>math.CO cs.DM</categories><msc-class>05C10, 57M15, 57N05</msc-class><journal-ref>Graphs and Combinatorics 29(6):1675-1688, 2013</journal-ref><doi>10.1007/s00373-012-1244-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A triangulation of a surface is irreducible if no edge can be contracted to
produce a triangulation of the same surface. In this paper, we investigate
irreducible triangulations of surfaces with boundary. We prove that the number
of vertices of an irreducible triangulation of a (possibly non-orientable)
surface of genus g&gt;=0 with b&gt;=0 boundaries is O(g+b). So far, the result was
known only for surfaces without boundary (b=0). While our technique yields a
worse constant in the O(.) notation, the present proof is elementary, and
simpler than the previous ones in the case of surfaces without boundary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5382</identifier>
 <datestamp>2012-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5382</id><created>2011-03-28</created><authors><author><keyname>Ausloos</keyname><forenames>M.</forenames></author></authors><title>On religion and language evolutions seen through mathematical and agent
  based models</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>15 pages, 2 figures, invited paper at CHESS 2009; Proceedings of the
  First Interdisciplinary Chess Interactions Conference: Saskatoon,
  Saskatchewan, Canada 17-20 August 2009 ; pp. 157-182</comments><journal-ref>Proceedings of the First Interdisciplinary Chess Interactions
  Conference (World Scientific, Singapore, 2010) pp. 157-182</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  (shortened version) Religions and languages are social variables, like age,
sex, wealth or political opinions, to be studied like any other organizational
parameter. In fact, religiosity is one of the most important sociological
aspects of populations. Languages are also a characteristics of the human kind.
New religions, new languages appear though others disappear. All religions and
languages evolve when they adapt to the society developments. On the other
hand, the number of adherents of a given religion, the number of persons
speaking a language is not fixed. Several questions can be raised. E.g. from a
macroscopic point of view : How many religions/languages exist at a given time?
What is their distribution? What is their life time? How do they evolve?. From
a microscopic view point: can one invent agent based models to describe
macroscopic aspects? Does it exist simple evolution equations? It is
intuitively accepted, but also found through from statistical analysis of the
frequency distribution that an attachment process is the primary cause of the
distribution evolution : usually the initial religion/language is that of the
mother. Later on, changes can occur either due to heterogeneous agent
interaction processes or due to external field constraints, - or both. Such
cases can be illustrated with historical facts and data. It is stressed that
characteristic time scales are different, and recalled that external fields are
very relevant in the case of religions, rending the study more interesting
within a mechanistic approach
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5405</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5405</id><created>2011-03-28</created><authors><author><keyname>Chen</keyname><forenames>Phoebus</forenames></author><author><keyname>Ramesh</keyname><forenames>Chithrupa</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author></authors><title>Network Estimation and Packet Delivery Prediction for Control over
  Wireless Mesh Networks</title><categories>cs.SY cs.NI math.OC</categories><comments>20 pages, 8 figures. Originally submitted to KTH Royal Institute of
  Technology Technical Report Database on October 20, 2010</comments><report-no>TRITA-EE:043</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Much of the current theory of networked control systems uses simple
point-to-point communication models as an abstraction of the underlying
network. As a result, the controller has very limited information on the
network conditions and performs suboptimally. This work models the underlying
wireless multihop mesh network as a graph of links with transmission success
probabilities, and uses a recursive Bayesian estimator to provide packet
delivery predictions to the controller. The predictions are a joint probability
distribution on future packet delivery sequences, and thus capture correlations
between successive packet deliveries. We look at finite horizon LQG control
over a lossy actuation channel and a perfect sensing channel, both without
delay, to study how the controller can compensate for predicted network
outages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5410</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5410</id><created>2011-03-28</created><authors><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author><author><keyname>di Gennaro</keyname><forenames>Corinna</forenames></author></authors><title>Political protest Italian-style: The dissonance between the blogosphere
  and mainstream media in the promotion and coverage of Beppe Grillo's V-day</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>30 pages; First Monday. Volume 14, Number 12. 2009</comments><journal-ref>First Monday. Volume 14, Number 12. 2009</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We analyze the organization, promotion and public perception of V-day, a
political rally that took place on September 8, 2007, to protest against
corruption in the Italian Parliament. Launched by blogger Beppe Grillo, and
promoted via a word of mouth mobilization on the Italian blogosphere, V-day
brought close to one million Italians in the streets on a single day, but was
mostly ignored by mainstream media. This article is divided into two parts. In
the first part, we analyze the volume and content of online articles published
by both bloggers and mainstream news sources from June 14 (the day V-day was
announced) until September 15, 2007 (one week after it took place) . We find
that the success of V-day can be attributed to the coverage of bloggers and
small-scale local news outlets only, suggesting a strong grassroots component
in the organization of the rally. We also find a dissonant thematic
relationship between content published by blogs and mainstream media: while the
majority of blogs analyzed promote V-day, major mainstream media sources
critique the methods of information production and dissemination employed by
Grillo. Based on this finding, in the second part of the study, we explore the
role of Grillo in the organization of the rally from a network analysis
perspective. We study the interlinking structure of the V-day blogosphere
network, to determine its structure, its levels of heterogeneity, and
resilience. Our analysis contradicts the hypothesis that Grillo served as a
top-down, broadcast-like source of information. Rather, we find that
information about V-day was transferred across heterogeneous nodes in a
moderately robust and resilient core network of blogs. We speculate that the
organization of V-day represents the very first case, in Italian history, of a
political demonstration developed and promoted primarily via the use of social
media on the web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5421</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5421</id><created>2011-03-28</created><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author><author><keyname>Ivan</keyname><forenames>Szabolcs</forenames></author></authors><title>Context-free ordinals</title><categories>cs.FL</categories><msc-class>68Q70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider context-free languages equipped with the lexicographic ordering.
We show that when the lexicographic ordering of a context-free language is
scattered, then its Hausdorff rank is less than $\omega^\omega$. As a corollary
of this result we obtain that an ordinal is the order type of a well-ordered
context-free language iff it is less than $\omega^{\omega^\omega}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5426</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5426</id><created>2011-03-28</created><updated>2012-05-06</updated><authors><author><keyname>Vahid</keyname><forenames>Alireza</forenames></author><author><keyname>Suh</keyname><forenames>Changho</forenames></author><author><keyname>Avestimehr</keyname><forenames>Amir Salman</forenames></author></authors><title>Interference Channels with Rate-Limited Feedback</title><categories>cs.IT math.IT</categories><comments>A mistake in the derivation of inequalities (27) and (75) is
  corrected. Inequalities (26g), (26l), (26m), (33c) and (63c) are updated
  accordingly</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the two-user interference channel with rate-limited feedback.
Related prior works focus on the case where feedback links have infinite
capacity, while no research has been done for the rate-limited feedback
problem. Several new challenges arise due to the capacity limitations of the
feedback links, both in deriving inner-bounds and outer-bounds. We study this
problem under three different interference models: the El Gamal-Costa
deterministic model, the linear deterministic model, and the Gaussian model.
For the first two models, we develop an achievable scheme that employs three
techniques: Han-Kobayashi message splitting, quantize-and-binning, and
decode-and-forward. We also derive new outer-bounds for all three models and we
show the optimality of our scheme under the linear deterministic model. In the
Gaussian case, we propose a transmission strategy that incorporates lattice
codes, inspired by the ideas developed in the first two models. For symmetric
channel gains, we prove that the gap between the achievable sum-rate of the
proposed scheme and our new outer-bounds is bounded by a constant number of
bits, independent of the channel gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5431</identifier>
 <datestamp>2013-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5431</id><created>2011-03-28</created><updated>2013-03-20</updated><authors><author><keyname>Manchester</keyname><forenames>Ian R.</forenames></author><author><keyname>Tobenkin</keyname><forenames>Mark M.</forenames></author><author><keyname>Wang</keyname><forenames>Jennifer</forenames></author></authors><title>Identification of Nonlinear Systems with Stable Limit Cycles via Convex
  Optimization</title><categories>math.OC cs.SY</categories><comments>11 pages, 4 figures. Journal submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a convex optimization procedure for black-box identification of
nonlinear state-space models for systems that exhibit stable limit cycles
(unforced periodic solutions). It extends the &quot;robust identification error&quot;
framework in which a convex upper bound on simulation error is optimized to fit
rational polynomial models with a strong stability guarantee. In this work, we
relax the stability constraint using the concepts of transverse dynamics and
orbital stability, thus allowing systems with autonomous oscillations to be
identified. The resulting optimization problem is convex, and can be formulated
as a semidefinite program. A simulation-error bound is proved without assuming
that the true system is in the model class, or that the number of measurements
goes to infinity. Conditions which guarantee existence of a unique limit cycle
of the model are proved and related to the model class that we search over. The
method is illustrated by identifying a high-fidelity model from experimental
recordings of a live rat hippocampal neuron in culture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5433</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5433</id><created>2011-03-28</created><updated>2011-07-25</updated><authors><author><keyname>Assels</keyname><forenames>Michael J.</forenames></author><author><keyname>Echtner</keyname><forenames>Dana</forenames></author><author><keyname>Spanner</keyname><forenames>Michael</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Carri&#xe8;re</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Taveroff</keyname><forenames>Manny</forenames></author></authors><title>Multifaceted Faculty Network Design and Management: Practice and
  Experience Report</title><categories>cs.NI cs.CR</categories><comments>19 pages, 11 figures, TOC and index; a short version presented at
  C3S2E'11; v6: more proofreading, index, TOC, references</comments><acm-class>C.2.0; C.2.3; C.2.1; C.2.5; C.2.6</acm-class><journal-ref>Proceedings of The Fourth International C* Conference on Computer
  Science and Software Engineering (C3S2E '11). 2011, ACM, New York, NY, USA,
  151-155</journal-ref><doi>10.1145/1992896.1992916</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on our experience on multidimensional aspects of our faculty's
network design and management, including some unique aspects such as
campus-wide VLANs and ghosting, security and monitoring, switching and routing,
and others. We outline a historical perspective on certain research, design,
and development decisions and discuss the network topology, its scalability,
and management in detail; the services our network provides, and its evolution.
We overview the security aspects of the management as well as data management
and automation and the use of the data by other members of the IT group in the
faculty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5441</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5441</id><created>2011-03-28</created><authors><author><keyname>Mao</keyname><forenames>Rukun</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author></authors><title>Nobody but You: Sensor Selection for Voltage Regulation in Smart Grid</title><categories>cs.SY math.OC</categories><comments>6 pages, submitted to GlOBECOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing availability of distributed energy resources (DERs) and
sensors in smart grid, as well as overlaying communication network, provides
substantial potential benefits for improving the power system's reliability. In
this paper, the problem of sensor selection is studied for the MAC layer design
of wireless sensor networks for regulating the voltages in smart grid. The
framework of hybrid dynamical system is proposed, using Kalman filter for
voltage state estimation and LQR feedback control for voltage adjustment. The
approach to obtain the optimal sensor selection sequence is studied. A sub-
optimal sequence is obtained by applying the sliding window algorithm.
Simulation results show that the proposed sensor selection strategy achieves a
40% performance gain over the baseline algorithm of the round-robin sensor
polling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5448</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5448</id><created>2011-03-28</created><authors><author><keyname>Reula</keyname><forenames>Oscar A.</forenames></author></authors><title>Numerical treatment of interfaces in Quantum Mechanics</title><categories>quant-ph cs.NA math.NA</categories><comments>11 pages, 6 figures</comments><msc-class>35Q41</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we develop a numerical scheme to deal with interfaces between
touching numerical grids when solving Schr\&quot;o{}dinger equation. In order to
pass the information among grids we use the values of the fields only at the
contact point between them. Surprisingly we obtain a convergent methods which
is third order accurate with respect to the spatial resolution. In test cases,
at the minimal resolution needed to describe correctly the waves, the error of
this approximation is similar to that of a homogeneous (centered differences
everywhere) scheme with three points stencil, that is a sixth order finite
difference operator. The semi-discrete approximation preserves the norm and
uses standard finite difference operators satisfying summation by parts. For
the time integrator we use a semi-implicit IMEX Runge Kutta method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5451</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5451</id><created>2011-03-28</created><authors><author><keyname>O'Danleyman</keyname><forenames>Grastivia</forenames></author><author><keyname>Lee</keyname><forenames>Jake Jungbin</forenames></author><author><keyname>Seebens</keyname><forenames>Hanno</forenames></author><author><keyname>Blasius</keyname><forenames>Bernd</forenames></author><author><keyname>Brockmann</keyname><forenames>Dirk</forenames></author></authors><title>Complexity in human transportation networks: A comparative analysis of
  worldwide air transportation and global cargo ship movements</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a comparative network theoretic analysis of the two largest global
transportation networks: The worldwide air-transportation network (WAN) and the
global cargoship network (GCSN). We show that both networks exhibit striking
statistical similarities despite significant differences in topology and
connectivity. Both networks exhibit a discontinuity in node and link
betweenness distributions which implies that these networks naturally segragate
in two different classes of nodes and links. We introduce a technique based on
effective distances, shortest paths and shortest-path trees for strongly
weighted symmetric networks and show that in a shortest-path-tree
representation the most significant features of both networks can be readily
seen. We show that effective shortest-path distance, unlike conventional
geographic distance measures, strongly correlates with node centrality
measures. Using the new technique we show that network resilience can be
investigated more precisely than with contemporary techniques that are based on
percolation theory. We extract a functional relationship between node
characteristics and resilience to network disruption. Finally we discuss the
results, their implications and conclude that dynamic processes that evolve on
both networks are expected to share universal dynamic characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5453</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5453</id><created>2011-03-28</created><authors><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>Using a Non-Commutative Bernstein Bound to Approximate Some Matrix
  Algorithms in the Spectral Norm</title><categories>cs.DS</categories><comments>Working paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on \emph{row sampling} based approximations for matrix algorithms,
in particular matrix multipication, sparse matrix reconstruction, and
\math{\ell_2} regression. For \math{\matA\in\R^{m\times d}} (\math{m} points in
\math{d\ll m} dimensions), and appropriate row-sampling probabilities, which
typically depend on the norms of the rows of the \math{m\times d} left singular
matrix of \math{\matA} (the \emph{leverage scores}), we give row-sampling
algorithms with linear (up to polylog factors) dependence on the stable rank of
\math{\matA}. This result is achieved through the application of
non-commutative Bernstein bounds. Keywords: row-sampling; matrix
multiplication; matrix reconstruction; estimating spectral norm; linear
regression; randomized
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5474</identifier>
 <datestamp>2016-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5474</id><created>2011-03-28</created><authors><author><keyname>Grothkopf</keyname><forenames>Uta</forenames></author><author><keyname>Lagerstrom</keyname><forenames>Jill</forenames></author></authors><title>Telescope Bibliometrics 101</title><categories>astro-ph.IM cs.DL</categories><comments>11 pages, 3 figures. To appear in: Future Professional Communication
  in Astronomy II (FPCA-II)</comments><doi>10.1007/978-1-4419-8369-5_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During recent years, bibliometric studies have become increasingly important
in evaluating individual scientists, institutes, and entire observatories. In
astronomy, often librarians are involved in maintaining publication databases
and compiling statistics for their institutions. In this paper, we present a
look behind the scenes to understand who is interested in bibliometric
statistics, which methodologies astronomy librarians apply, and what kind of
features next-generation bibliographies may include.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5478</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5478</id><created>2011-03-28</created><authors><author><keyname>Abbe</keyname><forenames>Emmanuel</forenames></author><author><keyname>Huang</keyname><forenames>Shao-Lun</forenames></author><author><keyname>Telatar</keyname><forenames>Emre</forenames></author></authors><title>Proof of the outage probability conjecture for MISO channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Telatar 1999, it is conjectured that the covariance matrices minimizing
the outage probability for MIMO channels with Gaussian fading are diagonal with
either zeros or constant values on the diagonal. In the MISO setting, this is
equivalent to conjecture that the Gaussian quadratic forms having largest tale
probability correspond to such diagonal matrices. We prove here the conjecture
in the MISO setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5479</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5479</id><created>2011-03-28</created><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author><author><keyname>Plan</keyname><forenames>Yaniv</forenames></author></authors><title>Unicity conditions for low-rank matrix recovery</title><categories>math.NA cs.IT cs.SY math.IT math.OC math.PR</categories><doi>10.1117/12.891933</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-rank matrix recovery addresses the problem of recovering an unknown
low-rank matrix from few linear measurements. Nuclear-norm minimization is a
tractible approach with a recent surge of strong theoretical backing. Analagous
to the theory of compressed sensing, these results have required random
measurements. For example, m &gt;= Cnr Gaussian measurements are sufficient to
recover any rank-r n x n matrix with high probability. In this paper we address
the theoretical question of how many measurements are needed via any method
whatsoever --- tractible or not. We show that for a family of random
measurement ensembles, m &gt;= 4nr - 4r^2 measurements are sufficient to guarantee
that no rank-2r matrix lies in the null space of the measurement operator with
probability one. This is a necessary and sufficient condition to ensure uniform
recovery of all rank-r matrices by rank minimization. Furthermore, this value
of $m$ precisely matches the dimension of the manifold of all rank-2r matrices.
We also prove that for a fixed rank-r matrix, m &gt;= 2nr - r^2 + 1 random
measurements are enough to guarantee recovery using rank minimization. These
results give a benchmark to which we may compare the efficacy of nuclear-norm
minimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5510</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5510</id><created>2011-03-28</created><authors><author><keyname>Chan</keyname><forenames>Timothy M.</forenames></author><author><keyname>Larsen</keyname><forenames>Kasper Green</forenames></author><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author></authors><title>Orthogonal Range Searching on the RAM, Revisited</title><categories>cs.CG cs.DS</categories><comments>To appear in SoCG 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several new results on one of the most extensively studied topics
in computational geometry, orthogonal range searching. All our results are in
the standard word RAM model for points in rank space:
  ** We present two data structures for 2-d orthogonal range emptiness. The
first achieves O(n lglg n) space and O(lglg n) query time. This improves the
previous results by Alstrup, Brodal, and Rauhe(FOCS'00), with O(n lg^eps n)
space and O(lglg n) query time, or with O(nlglg n) space and O(lg^2 lg n) query
time. Our second data structure uses O(n) space and answers queries in O(lg^eps
n) time. The best previous O(n)-space data structure, due to Nekrich (WADS'07),
answers queries in O(lg n/lglg n) time.
  ** For 3-d orthogonal range reporting, we obtain space O(n lg^{1+eps} n) and
query time O(lglg n + k), for any constant eps&gt;0. This improves previous
results by Afshani (ESA'08), Karpinski and Nekrich (COCOON'09), and Chan
(SODA'11), with O(n lg^3 n) space and O(lglg n + k) query time, or with O(n
lg^{1+eps} n) space and O(lg^2 lg n + k) query time. This implies improved
bounds for orthogonal range reporting in all constant dimensions above 3.
  ** We give a randomized algorithm for 4-d offline dominance range
reporting/emptiness with running time O(n lg n + k). This resolves two open
problems from Preparata and Shamos' seminal book:
  **** given n axis-aligned rectangles in the plane, we can report all k
enclosure pairs in O(n lg n + k) expected time. The best known result was an
O([n lg n + k] lglg n) algorithm from SoCG'95 by Gupta, Janardan, Smid, and
Dasgupta.
  **** given n points in 4-d, we can find all maximal points in O(n lg n)
expected time. The best previous result was an O(n lg n lglg n) algorithm due
to Gabow, Bentley, and Tarjan (STOC'84). This implies record time bounds for
the maxima problem in all constant dimensions above 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5520</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5520</id><created>2011-03-28</created><authors><author><keyname>Wu</keyname><forenames>Yue</forenames></author><author><keyname>Noonan</keyname><forenames>Joseph P.</forenames></author><author><keyname>Agaian</keyname><forenames>Sos</forenames></author></authors><title>Shannon Entropy based Randomness Measurement and Test for Image
  Encryption</title><categories>cs.CR cs.IT math.IT</categories><comments>23 Pages, 7 figures and 5 tables. Submitted to the Journal of
  Information Sciences</comments><doi>10.1016/j.ins.2012.07.049</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quality of image encryption is commonly measured by the Shannon entropy
over the ciphertext image. However, this measurement does not consider to the
randomness of local image blocks and is inappropriate for scrambling based
image encryption methods. In this paper, a new information entropy-based
randomness measurement for image encryption is introduced which, for the first
time, answers the question of whether a given ciphertext image is sufficiently
random-like. It measures the randomness over the ciphertext in a fairer way by
calculating the averaged entropy of a series of small image blocks within the
entire test image. In order to fulfill both quantitative and qualitative
measurement, the expectation and the variance of this averaged block entropy
for a true-random image are strictly derived and corresponding numerical
reference tables are also provided. Moreover, a hypothesis test at
significance?-level is given to help accept or reject the hypothesis that the
test image is ideally encrypted/random-like. Simulation results show that the
proposed test is able to give both e?ectively quantitative and qualitative
results for image encryption. The same idea can also be applied to measure
other digital data, like audio and video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5531</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5531</id><created>2011-03-28</created><authors><author><keyname>Lyons</keyname><forenames>Andrew</forenames></author></authors><title>Acyclic and Star Colorings of Cographs</title><categories>cs.DS cs.DM math.CO</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An \emph{acyclic coloring} of a graph is a proper vertex coloring such that
the union of any two color classes induces a disjoint collection of trees. The
more restricted notion of \emph{star coloring} requires that the union of any
two color classes induces a disjoint collection of stars. We prove that every
acyclic coloring of a cograph is also a star coloring and give a linear-time
algorithm for finding an optimal acyclic and star coloring of a cograph. If the
graph is given in the form of a cotree, the algorithm runs in O(n) time. We
also show that the acyclic chromatic number, the star chromatic number, the
treewidth plus one, and the pathwidth plus one are all equal for cographs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5535</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5535</id><created>2011-03-28</created><authors><author><keyname>Song</keyname><forenames>Yiwei</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>A Lattice Compress-and-Forward Scheme</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a nested lattice-code-based strategy that achieves the
random-coding based Compress-and-Forward (CF) rate for the three node Gaussian
relay channel. To do so, we first outline a lattice-based strategy for the
$(X+Z_1,X+Z_2)$ Wyner-Ziv lossy source-coding with side-information problem in
Gaussian noise, a re-interpretation of the nested lattice-code-based Gaussian
Wyner-Ziv scheme presented by Zamir, Shamai, and Erez. We use the notation
$(X+Z_1,X+Z_2)$ Wyner-Ziv to mean that the source is of the form $X+ Z_1$ and
the side-information at the receiver is of the form $X+ Z_2$, for independent
Gaussian $X, Z_1$ and $Z_2$. We next use this $(X+Z_1,X+Z_2)$ Wyner-Ziv scheme
to implement a &quot;structured&quot; or lattice-code-based CF scheme which achieves the
classic CF rate for Gaussian relay channels. This suggests that lattice codes
may not only be useful in point-to-point single-hop source and channel coding,
in multiple access and broadcast channels, but that they may also be useful in
larger relay networks. The usage of lattice codes in larger networks is
motivated by their structured nature (possibly leading to rate gains) and
decoding (relatively simple) being more practically realizable than their
random coding based counterparts. We furthermore expect the proposed
lattice-based CF scheme to constitute a first step towards a generic structured
achievability scheme for networks such as a structured version of the recently
introduced &quot;noisy network coding&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5542</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5542</id><created>2011-03-29</created><updated>2011-03-30</updated><authors><author><keyname>Ilic</keyname><forenames>Jovana</forenames></author><author><keyname>Strohmer</keyname><forenames>Thomas</forenames></author></authors><title>Sparsity Enhanced Decision Feedback Equalization</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2012.2189387</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For single-carrier systems with frequency domain equalization, decision
feedback equalization (DFE) performs better than linear equalization and has
much lower computational complexity than sequence maximum likelihood detection.
The main challenge in DFE is the feedback symbol selection rule. In this paper,
we give a theoretical framework for a simple, sparsity based thresholding
algorithm. We feed back multiple symbols in each iteration, so the algorithm
converges fast and has a low computational cost. We show how the initial
solution can be obtained via convex relaxation instead of linear equalization,
and illustrate the impact that the choice of the initial solution has on the
bit error rate performance of our algorithm. The algorithm is applicable in
several existing wireless communication systems (SC-FDMA, MC-CDMA, MIMO-OFDM).
Numerical results illustrate significant performance improvement in terms of
bit error rate compared to the MMSE solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5554</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5554</id><created>2011-03-29</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Alberto Alonso</forenames></author><author><keyname>Fres</keyname><forenames>Omar &#xc1;lvarez</forenames></author><author><keyname>Alonso</keyname><forenames>Ignacio Gonz&#xe1;lez</forenames></author><author><keyname>Hu</keyname><forenames>Huosheng</forenames></author></authors><title>Visual Localisation of Mobile Devices in an Indoor Environment under
  Network Delay Conditions</title><categories>cs.RO</categories><journal-ref>International Journal of Distributed and Parallel Systems (IJDPS)
  Vol.2, No.2, March 2011</journal-ref><doi>10.5121/ijdps.2011.2201</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Current progresses in home automation and service robotic environment have
highlighted the need to develop interoperability mechanisms that allow a
standard communication between the two systems. During the development of the
DHCompliant protocol, the problem of locating mobile devices in an indoor
environment has been investigated. The communication of the device with the
location service has been carried out to study the time delay that web services
offer in front of the sockets. The importance of obtaining data from real-time
location systems portends that a basic tool for interoperability, such as web
services, can be ineffective in this scenario because of the delays added in
the invocation of services. This paper is focused on introducing a web service
to resolve a coordinates request without any significant delay in comparison
with the sockets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5560</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5560</id><created>2011-03-29</created><updated>2011-04-07</updated><authors><author><keyname>Salam</keyname><forenames>Sameera Muhamed</forenames></author><author><keyname>Parvathy</keyname><forenames>K. N.</forenames></author><author><keyname>Sudeep</keyname><forenames>K. S.</forenames></author><author><keyname>Krishnan</keyname><forenames>K. Murali</forenames></author></authors><title>On the Complexity of Edge Packing and Vertex Packing</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the computational complexity of the Edge Packing problem
and the Vertex Packing problem. The edge packing problem (denoted by
$\bar{EDS}$) and the vertex packing problem (denoted by $\bar{DS} $) are linear
programming duals of the edge dominating set problem and the dominating set
problem respectively. It is shown that these two problems are equivalent to the
set packing problem with respect to hardness of approximation and parametric
complexity. It follows that $\bar{EDS}$ and $\bar{DS}$ cannot be approximated
asymptotically within a factor of $O(N^{1/2-\epsilon})$ for any $\epsilon&gt;0$
unless $NP=ZPP$ where, $N$ is the number of vertices in the given graph. This
is in contrast with the fact that the edge dominating set problem is
2-approximable where as the dominating set problem is known to have an $O(\log$
$|V|)$ approximation algorithm. It also follows from our proof that $\bar{EDS}$
and $\bar{DS}$ are $W[1]$-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5569</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5569</id><created>2011-03-29</created><authors><author><keyname>Krings</keyname><forenames>Gautier</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author></authors><title>An upper bound on community size in scalable community detection</title><categories>physics.soc-ph cs.SI</categories><comments>4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that community detection methods based on modularity
optimization often fails to discover small communities. Several objective
functions used for community detection therefore involve a resolution parameter
that allows the detection of communities at different scales. We provide an
explicit upper bound on the community size of communities resulting from the
optimization of several of these functions. We also show with a simple example
that the use of the resolution parameter may artificially force the complete
disaggregation of large and densely connected communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5580</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5580</id><created>2011-03-29</created><updated>2011-04-02</updated><authors><author><keyname>Kayani</keyname><forenames>Saheeb Ahmed</forenames></author></authors><title>Designing a Miniature Wheel Arrangement for Mobile Robot Platforms</title><categories>cs.RO</categories><comments>Final published version, hardcopy available from technical library of
  NUST College of E&amp;ME, Rawalpindi, Pakistan on request</comments><report-no>DME-RR-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research report details of design of a miniature wheel arrangement
are presented. This miniature wheel arrangement is essentially a direction
control mechanism intended for use on a mobile robot platform or base. The
design is a specific one employing a stepper motor as actuator and as described
can only be used on a certain type of wheeled robots. However, as a basic
steering control element, more than one of these miniature wheel arrangements
can be grouped together to implement more elaborate and intelligent direction
control schemes on varying configurations of wheeled mobile robot platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5582</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5582</id><created>2011-03-29</created><authors><author><keyname>Cooper</keyname><forenames>Kathryn</forenames></author><author><keyname>Barahona</keyname><forenames>Mauricio</forenames></author></authors><title>Role-similarity based comparison of directed networks</title><categories>physics.soc-ph cs.SI q-bio.MN</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The widespread relevance of complex networks is a valuable tool in the
analysis of a broad range of systems. There is a demand for tools which enable
the extraction of meaningful information and allow the comparison between
different systems. We present a novel measure of similarity between nodes in
different networks as a generalization of the concept of self-similarity. A
similarity matrix is assembled as the distance between feature vectors that
contain the in and out paths of all lengths for each node. Hence, nodes
operating in a similar flow environment are considered similar regardless of
network membership. We demonstrate that this method has the potential to be
influential in tasks such as assigning identity or function to uncharacterized
nodes. In addition an innovative application of graph partitioning to the raw
results extends the concept to the comparison of networks in terms of their
underlying role-structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5586</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5586</id><created>2011-03-29</created><authors><author><keyname>Tam</keyname><forenames>Adrian S. -W.</forenames></author><author><keyname>Xi</keyname><forenames>Kang</forenames></author><author><keyname>Chao</keyname><forenames>H. Jonathan</forenames></author></authors><title>Use of Devolved Controllers in Data Center Networks</title><categories>cs.NI cs.SY math.OC</categories><comments>Appears in INFOCOM 2011 Cloud Computing Workshop</comments><journal-ref>In Proc. IEEE Conference on Computer Communications Workshops
  (INFOCOM WKSHPS), pp.596--601, 10-15 April 2011, Shanghai China</journal-ref><doi>10.1109/INFCOMW.2011.5928883</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a data center network, for example, it is quite often to use controllers
to manage resources in a centralized man- ner. Centralized control, however,
imposes a scalability problem. In this paper, we investigate the use of
multiple independent controllers instead of a single omniscient controller to
manage resources. Each controller looks after a portion of the network only,
but they together cover the whole network. This therefore solves the
scalability problem. We use flow allocation as an example to see how this
approach can manage the bandwidth use in a distributed manner. The focus is on
how to assign components of a network to the controllers so that (1) each
controller only need to look after a small part of the network but (2) there is
at least one controller that can answer any request. We outline a way to
configure the controllers to fulfill these requirements as a proof that the use
of devolved controllers is possible. We also discuss several issues related to
such implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5589</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5589</id><created>2011-03-29</created><authors><author><keyname>Mohammadi</keyname><forenames>Shahriar</forenames></author><author><keyname>Jadidoleslamy</keyname><forenames>Hossein</forenames></author></authors><title>A Comparison of Link Layer Attacks on Wireless Sensor Networks</title><categories>cs.CR</categories><comments>22 pages, 10 figures, 6 tables, International journal on applications
  of graph theory in wireless ad hoc networks and sensor networks(GRAPH-HOC)
  Vol.3, No.1, March 2011</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks (GRAPH-HOC) Vol.3, No.1, March 2011</journal-ref><doi>10.5121/jgraphhoc.2011.3103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) have many potential applications [1, 5] and
unique challenges. They usually consist of hundreds or thousands small sensor
nodes such as MICA2, which operate autonomously; conditions such as cost,
invisible deployment and many application domains, lead to small size and
limited resources sensors [2]. WSNs are susceptible to many types of link layer
attacks [1] and most of traditional networks security techniques are unusable
on WSNs [2]; due to wireless and shared nature of communication channel,
untrusted transmissions, deployment in open environments, unattended nature and
limited resources [1]. So, security is a vital requirement for these networks;
but we have to design a proper security mechanism that attends to WSN's
constraints and requirements. In this paper, we focus on security of WSNs,
divide it (the WSNs security) into four categories and will consider them,
include: an overview of WSNs, security in WSNs, the threat model on WSNs, a
wide variety of WSNs' link layer attacks and a comparison of them. This work
enables us to identify the purpose and capabilities of the attackers; also, the
goal and effects of the link layer attacks on WSNs are introduced. Also, this
paper discusses known approaches of security detection and defensive mechanisms
against the link layer attacks; this would enable it security managers to
manage the link layer attacks of WSNs more effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5599</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5599</id><created>2011-03-29</created><updated>2011-04-14</updated><authors><author><keyname>Bessy</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Perez</keyname><forenames>Anthony</forenames></author></authors><title>Polynomial kernels for Proper Interval Completion and related problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph G = (V,E) and a positive integer k, the Proper Interval
Completion problem asks whether there exists a set F of at most k pairs of (V
\times V)\E such that the graph H = (V,E \cup F) is a proper interval graph.
The Proper Interval Completion problem finds applications in molecular biology
and genomic research. First announced by Kaplan, Tarjan and Shamir in FOCS '94,
this problem is known to be FPT, but no polynomial kernel was known to exist.
We settle this question by proving that Proper Interval Completion admits a
kernel with at most O(k^5) vertices. Moreover, we prove that a related problem,
the so-called Bipartite Chain Deletion problem, admits a kernel with at most
O(k^2) vertices, completing a previous result of Guo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5602</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5602</id><created>2011-03-29</created><updated>2011-09-29</updated><authors><author><keyname>Ferrante</keyname><forenames>Augusto</forenames></author><author><keyname>Masiero</keyname><forenames>Chiara</forenames></author><author><keyname>Pavon</keyname><forenames>Michele</forenames></author></authors><title>Time and spectral domain relative entropy: A new approach to
  multivariate spectral estimation</title><categories>math.OC cs.SY</categories><comments>32 pages, submitted for publication</comments><msc-class>46N10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of spectral relative entropy rate is introduced for jointly
stationary Gaussian processes. Using classical information-theoretic results,
we establish a remarkable connection between time and spectral domain relative
entropy rates. This naturally leads to a new spectral estimation technique
where a multivariate version of the Itakura-Saito distance is employed}. It may
be viewed as an extension of the approach, called THREE, introduced by Byrnes,
Georgiou and Lindquist in 2000 which, in turn, followed in the footsteps of the
Burg-Jaynes Maximum Entropy Method. Spectral estimation is here recast in the
form of a constrained spectrum approximation problem where the distance is
equal to the processes relative entropy rate. The corresponding solution
entails a complexity upper bound which improves on the one so far available in
the multichannel framework. Indeed, it is equal to the one featured by THREE in
the scalar case. The solution is computed via a globally convergent matricial
Newton-type algorithm. Simulations suggest the effectiveness of the new
technique in tackling multivariate spectral estimation tasks, especially in the
case of short data records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5609</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5609</id><created>2011-03-29</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Reichman</keyname><forenames>Daniel</forenames></author></authors><title>Recoverable Values for Independent Sets</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of {\em recoverable value} was advocated in work of Feige,
Immorlica, Mirrokni and Nazerzadeh [Approx 2009] as a measure of quality for
approximation algorithms. There this concept was applied to facility location
problems. In the current work we apply a similar framework to the maximum
independent set problem (MIS). We say that an approximation algorithm has {\em
recoverable value} $\rho$, if for every graph it recovers an independent set of
size at least $\max_I \sum_{v\in I} \min[1,\rho/(d(v) + 1)]$, where $d(v)$ is
the degree of vertex $v$, and $I$ ranges over all independent sets in $G$.
Hence, in a sense, from every vertex $v$ in the maximum independent set the
algorithm recovers a value of at least $\rho/(d_v + 1)$ towards the solution.
This quality measure is most effective in graphs in which the maximum
independent set is composed of low degree vertices. It easily follows from
known results that some simple algorithms for MIS ensure $\rho \ge 1$. We
design a new randomized algorithm for MIS that ensures an expected recoverable
value of at least $\rho \ge 7/3$. In addition, we show that approximating MIS
in graphs with a given $k$-coloring within a ratio larger than $2/k$ is unique
games hard. This rules out a natural approach for obtaining $\rho \ge 2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5616</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5616</id><created>2011-03-29</created><authors><author><keyname>Elnashar</keyname><forenames>Alaa Ismail</forenames></author></authors><title>To Parallelize or Not to Parallelize, Speed Up Issue</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Running parallel applications requires special and expensive processing
resources to obtain the required results within a reasonable time. Before
parallelizing serial applications, some analysis is recommended to be carried
out to decide whether it will benefit from parallelization or not. In this
paper we discuss the issue of speed up gained from parallelization using
Message Passing Interface (MPI) to compromise between the overhead of
parallelization cost and the gained parallel speed up. We also propose an
experimental method to predict the speed up of MPI applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5621</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5621</id><created>2011-03-29</created><authors><author><keyname>Som</keyname><forenames>Hafizan Mat</forenames></author><author><keyname>Zain</keyname><forenames>Jasni Mohamad</forenames></author><author><keyname>Ghazali</keyname><forenames>Amzari Jihadi</forenames></author></authors><title>Application of Threshold Techniques for Readability Improvement of Jawi
  Historical Manuscript Images</title><categories>cs.CV</categories><comments>10 pages, 6 figures, 2 tables, Advance Computing: An International
  Journal (ACIJ)</comments><journal-ref>Advanced Computing: An International Journal ( ACIJ ), Vol.2,
  No.2, March 2011</journal-ref><doi>10.5121/acij.2011.2206</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Historical documents such as old books and manuscripts have a high aesthetic
value and highly appreciated. Unfortunately, there are some documents cannot be
read due to quality problems like faded paper, ink expand, uneven colour tone,
torn paper and other elements disruption such as the existence of small spots.
The study aims to produce a copy of manuscript that shows clear wordings so
they can easily be read and the copy can also be displayed for visitors. 16
samples of Jawi historical manuscript with different quality problems were
obtained from The Royal Museum of Pahang, Malaysia. We applied three
binarization techniques; Otsu's method represents global threshold technique;
Sauvola and Niblack method which are categorized as local threshold techniques.
We compared the binarized images with the original manuscript to be visually
inspected by the museum's curator. The unclear features were marked and
analyzed. Most of the examined images show that with optimal parameters and
effective pre processing technique, local thresholding methods are work well
compare with the other one. Niblack's and Sauvola's techniques seem to be the
suitable approaches for these types of images. Most of binarized images with
these two methods show improvement for readability and character recognition.
For this research, even the differences of image result were hard to be
distinguished by human capabilities, after comparing the time cost and overall
achievement rate of recognized symbols, Niblack's method is performing better
than Sauvola's. We could improve the post processing step by adding edge
detection techniques and further enhanced by an innovative image refinement
technique and a formulation of a class proper method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5625</identifier>
 <datestamp>2012-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5625</id><created>2011-03-21</created><updated>2012-06-08</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Information Theory and Population Genetics</title><categories>q-bio.PE cs.IT math.IT</categories><comments>29 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key findings of classical population genetics are derived using a
framework based on information theory using the entropies of the allele
frequency distribution as a basis. The common results for drift, mutation,
selection, and gene flow will be rewritten both in terms of information
theoretic measurements and used to draw the classic conclusions for balance
conditions and common features of one locus dynamics. Linkage disequilibrium
will also be discussed including the relationship between mutual information
and r^2 and a simple model of hitchhiking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5633</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5633</id><created>2011-03-29</created><updated>2011-06-15</updated><authors><author><keyname>Nov&#xe1;k</keyname><forenames>J.</forenames></author><author><keyname>Kaczmarczyk</keyname><forenames>&#x141;.</forenames></author><author><keyname>Grassl</keyname><forenames>P.</forenames></author><author><keyname>Zeman</keyname><forenames>J.</forenames></author><author><keyname>Pearce</keyname><forenames>C. J.</forenames></author></authors><title>A micromechanics-enhanced finite element formulation for modelling
  heterogeneous materials</title><categories>cond-mat.mtrl-sci cs.CE</categories><comments>28 pages, 12 figures, 2 tables</comments><journal-ref>Computer Methods in Applied Mechanics and Engineering (201--204),
  53-64, 2012</journal-ref><doi>10.1016/j.cma.2011.09.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the analysis of composite materials with heterogeneous microstructures,
full resolution of the heterogeneities using classical numerical approaches can
be computationally prohibitive. This paper presents a micromechanics-enhanced
finite element formulation that accurately captures the mechanical behaviour of
heterogeneous materials in a computationally efficient manner. The strategy
exploits analytical solutions derived by Eshelby for ellipsoidal inclusions in
order to determine the mechanical perturbation fields as a result of the
underlying heterogeneities. Approximation functions for these perturbation
fields are then incorporated into a finite element formulation to augment those
of the macroscopic fields. A significant feature of this approach is that the
finite element mesh does not explicitly resolve the heterogeneities and that no
additional degrees of freedom are introduced. In this paper, hybrid-Trefftz
stress finite elements are utilised and performance of the proposed formulation
is demonstrated with numerical examples. The method is restricted here to
elastic particulate composites with ellipsoidal inclusions but it has been
designed to be extensible to a wider class of materials comprising arbitrary
shaped inclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5639</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5639</id><created>2011-03-29</created><updated>2011-11-24</updated><authors><author><keyname>Michaeli</keyname><forenames>Tomer</forenames></author><author><keyname>Sigalov</keyname><forenames>Daniel</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Partially Linear Estimation with Application to Sparse Signal Recovery
  From Measurement Pairs</title><categories>cs.IT math.IT</categories><comments>13 pages, 5 figures</comments><doi>10.1109/TSP.2012.2185232</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of estimating a random vector X from two sets of
measurements Y and Z, such that the estimator is linear in Y. We show that the
partially linear minimum mean squared error (PLMMSE) estimator does not require
knowing the joint distribution of X and Y in full, but rather only its
second-order moments. This renders it of potential interest in various
applications. We further show that the PLMMSE method is minimax-optimal among
all estimators that solely depend on the second-order statistics of X and Y. We
demonstrate our approach in the context of recovering a signal, which is sparse
in a unitary dictionary, from noisy observations of it and of a filtered
version of it. We show that in this setting PLMMSE estimation has a clear
computational advantage, while its performance is comparable to
state-of-the-art algorithms. We apply our approach both in static and dynamic
estimation applications. In the former category, we treat the problem of image
enhancement from blurred/noisy image pairs, where we show that PLMMSE
estimation performs only slightly worse than state-of-the art algorithms, while
running an order of magnitude faster. In the dynamic setting, we provide a
recursive implementation of the estimator and demonstrate its utility in the
context of tracking maneuvering targets from position and acceleration
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5669</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5669</id><created>2011-03-29</created><authors><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>Symmetry of information and bounds on nonuniform randomness extraction
  via Kolmogorov extractors</title><categories>cs.CC</categories><comments>To appear in the proceedings of CCC 2011</comments><msc-class>68Q30, 68Q17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a strong Symmetry of Information relation for random strings (in the
sense of Kolmogorov complexity) and establish tight bounds on the amount on
nonuniformity that is necessary for extracting a string with randomness rate 1
from a single source of randomness. More precisely, as instantiations of more
general results, we show: (1) For all n-bit random strings x and y, x is random
conditioned by y if and only if y is random conditioned by x, and (2) while
O(1) amount of advice regarding the source is not enough for extracting a
string with randomness rate 1 from a source string with constant random rate,
\omega(1) amount of advice is. The proofs use Kolmogorov extractors as the main
technical device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5676</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5676</id><created>2011-03-29</created><authors><author><keyname>Kuhn</keyname><forenames>Tobias</forenames></author></authors><title>Codeco: A Grammar Notation for Controlled Natural Language in Predictive
  Editors</title><categories>cs.CL</categories><acm-class>H.5.2; F.4.2</acm-class><journal-ref>In Pre-Proceedings of the Second Workshop on Controlled Natural
  Languages (CNL 2010), CEUR Workshop Proceedings, Volume 622, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing grammar frameworks do not work out particularly well for controlled
natural languages (CNL), especially if they are to be used in predictive
editors. I introduce in this paper a new grammar notation, called Codeco, which
is designed specifically for CNLs and predictive editors. Two different parsers
have been implemented and a large subset of Attempto Controlled English (ACE)
has been represented in Codeco. The results show that Codeco is practical,
adequate and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5678</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5678</id><created>2011-03-29</created><authors><author><keyname>Terelius</keyname><forenames>H&#xe5;kan</forenames></author><author><keyname>Shi</keyname><forenames>Guodong</forenames></author><author><keyname>Dowling</keyname><forenames>Jim</forenames></author><author><keyname>Payberah</keyname><forenames>Amir</forenames></author><author><keyname>Gattami</keyname><forenames>Ather</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>Converging an Overlay Network to a Gradient Topology</title><categories>cs.SY math.OC</categories><comments>Submitted to 50th IEEE Conference on Decision and Control (CDC 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the topology convergence problem for the
gossip-based Gradient overlay network. In an overlay network where each node
has a local utility value, a Gradient overlay network is characterized by the
properties that each node has a set of neighbors with the same utility value (a
similar view) and a set of neighbors containing higher utility values (gradient
neighbor set), such that paths of increasing utilities emerge in the network
topology. The Gradient overlay network is built using gossiping and a
preference function that samples from nodes using a uniform random peer
sampling service. We analyze it using tools from matrix analysis, and we prove
both the necessary and sufficient conditions for convergence to a complete
gradient structure, as well as estimating the convergence time and providing
bounds on worst-case convergence time. Finally, we show in simulations the
potential of the Gradient overlay, by building a more efficient live-streaming
peer-to-peer (P2P) system than one built using uniform random peer sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5689</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5689</id><created>2011-03-29</created><authors><author><keyname>Bilotta</keyname><forenames>Stefano</forenames></author><author><keyname>Merlini</keyname><forenames>Donatella</forenames></author><author><keyname>Pergola</keyname><forenames>Elisa</forenames></author><author><keyname>Pinzani</keyname><forenames>Renzo</forenames></author></authors><title>Binary words avoiding a pattern and marked succession rule</title><categories>cs.DM</categories><comments>19</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the enumeration and the construction of particular
binary words avoiding the pattern $1^{j+1}0^j$. By means of the theory of
Riordan arrays, we solve the enumeration problem and we give a particular
succession rule, called jumping and marked succession rule, which describes the
growth of such words according to their number of ones. Moreover, the problem
of associating a word to a path in the generating tree obtained by the
succession rule is solved by introducing an algorithm which constructs all
binary words and then kills those containing the forbidden pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5695</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5695</id><created>2011-03-29</created><authors><author><keyname>Hasenfratz</keyname><forenames>David</forenames></author><author><keyname>Meier</keyname><forenames>Andreas</forenames></author><author><keyname>Woehrle</keyname><forenames>Matthias</forenames></author><author><keyname>Zimmerling</keyname><forenames>Marco</forenames></author><author><keyname>Thiele</keyname><forenames>Lothar</forenames></author></authors><title>Poster Abstract: If You Have Time, Save Energy with Pull</title><categories>cs.NI</categories><comments>2 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze push and pull for data collection in wireless sensor networks.
Most applications to date use the traditional push approach, where nodes
transmit sensed data immedi- ately to the sink. Using a pull approach, nodes
store the data in their local flash memory, and only engage in commu- nication
during dedicated collection phases. We show how one can transform an existing
push-based collection protocol into a pull-based one, and compare the power
consumption of both approaches on a 35-node testbed. Our results show that
substantial energy gains are possible with pull, provided that the application
can tolerate a long latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5703</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5703</id><created>2011-03-29</created><updated>2011-05-20</updated><authors><author><keyname>Lopez</keyname><forenames>Jose-Luis</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Calbet</keyname><forenames>Xavier</forenames></author></authors><title>Exponential wealth distribution in a random market. A rigorous
  explanation</title><categories>q-fin.GN cs.MA nlin.AO</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In simulations of some economic gas-like models, the asymptotic regime shows
an exponential wealth distribution, independently of the initial wealth
distribution given to the system. The appearance of this statistical
equilibrium for this type of gas-like models is explained in a rigorous
analytical way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5708</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5708</id><created>2011-03-29</created><authors><author><keyname>Sun</keyname><forenames>Yi</forenames></author><author><keyname>Gomez</keyname><forenames>Faustino</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Planning to Be Surprised: Optimal Bayesian Exploration in Dynamic
  Environments</title><categories>cs.AI stat.ML</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  To maximize its success, an AGI typically needs to explore its initially
unknown world. Is there an optimal way of doing so? Here we derive an
affirmative answer for a broad class of environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5712</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5712</id><created>2011-03-29</created><authors><author><keyname>Reddy</keyname><forenames>Rohith Singi</forenames></author></authors><title>Key Management in Wireless Sensor Networks Using a Modified Blom Scheme</title><categories>cs.CR</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Key establishment between any pair of nodes is an essential requirement for
providing secure services in wireless sensor networks. Blom's scheme is a
prominent key management scheme but its shortcomings include large computation
overhead and memory cost. We propose a new scheme in this paper that modifies
Blom's scheme in a manner that reduces memory and computation costs. This paper
also provides the value for secure parameter t such that the network is
resilient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5736</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5736</id><created>2011-03-29</created><authors><author><keyname>Slavici</keyname><forenames>Vlad</forenames></author><author><keyname>Kunkle</keyname><forenames>Daniel</forenames></author><author><keyname>Cooperman</keyname><forenames>Gene</forenames></author><author><keyname>Linton</keyname><forenames>Stephen</forenames></author></authors><title>Finding the Minimal DFA of Very Large Finite State Automata with an
  Application to Token Passing Networks</title><categories>cs.DC math.CO math.GR</categories><comments>14 pages, 4 figures</comments><msc-class>05C30, 05A05</msc-class><acm-class>H.3.4; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite state automata (FSA) are ubiquitous in computer science. Two of the
most important algorithms for FSA processing are the conversion of a
non-deterministic finite automaton (NFA) to a deterministic finite automaton
(DFA), and then the production of the unique minimal DFA for the original NFA.
We exhibit a parallel disk-based algorithm that uses a cluster of 29 commodity
computers to produce an intermediate DFA with almost two billion states and
then continues by producing the corresponding unique minimal DFA with less than
800,000 states. The largest previous such computation in the literature was
carried out on a 512-processor CM-5 supercomputer in 1996. That computation
produced an intermediate DFA with 525,000 states and an unreported number of
states for the corresponding minimal DFA. The work is used to provide strong
experimental evidence satisfying a conjecture on a series of token passing
networks. The conjecture concerns stack sortable permutations for a finite
stack and a 3-buffer. The origins of this problem lie in the work on restricted
permutations begun by Knuth and Tarjan in the late 1960s. The parallel
disk-based computation is also compared with both a single-threaded and
multi-threaded RAM-based implementation using a 16-core 128 GB large shared
memory computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5738</identifier>
 <datestamp>2011-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5738</id><created>2011-03-29</created><authors><author><keyname>Ghauch</keyname><forenames>Hadi G.</forenames></author><author><keyname>Papadias</keyname><forenames>Constantinos B.</forenames></author></authors><title>Interference Alignment: A one-sided approach</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE GLOBECOM 2011 conference, under the Signal
  Processing for Communications Track: 5 pages, double columns, 5 figures</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference Alignment (IA) is the process of designing signals in such a way
that they cast overlapping shadows at their unintended receivers, while
remaining distinguishable at the intended ones. Our goal in this paper is to
come up with an algorithm for IA that runs at the transmitters only (and is
transparent to the receivers), that doesn't require channel reciprocity, and
that alleviates the need to alternate between the forward and reverse network
as is the case in Distributed IA (Gomadam, Cadambe, Jafar 08'), thereby
inducing significant overhead in certain environments where the channel changes
frequently. Most importantly, our effort is focused on ensuring that this
one-sided approach does not degrade the performance of the system w.r.t.
Distributed IA (since it cannot improve it). As a first step, we model the
interference in each receiver's desired signal as a function of the
transmitters' beamforming vectors. We then propose a simple steepest descent
(SD) algorithm and use it to minimize the interference in each receiver's
desired signal space. We mathematically establish equivalences between our
approach and the Distributed IA algorithm (Gomadam, Cadambe, Jafar 08') and
show that our algorithm also converges to an alignment solution (when the
solution is feasible).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5740</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5740</id><created>2011-03-29</created><updated>2011-08-30</updated><authors><author><keyname>Haynal</keyname><forenames>Steve</forenames></author><author><keyname>Haynal</keyname><forenames>Heidi</forenames></author></authors><title>Generating and Searching Families of FFT Algorithms</title><categories>cs.IT cs.LO cs.SC math.IT</categories><comments>Preprint submitted on March 28, 2011, to the Journal on
  Satisfiability, Boolean Modeling and Computation</comments><journal-ref>Journal on Satisfiability, Boolean Modeling and Computation,
  7:145-187, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental question of longstanding theoretical interest is to prove the
lowest exact count of real additions and multiplications required to compute a
power-of-two discrete Fourier transform (DFT). For 35 years the split-radix
algorithm held the record by requiring just 4n log n - 6n + 8 arithmetic
operations on real numbers for a size-n DFT, and was widely believed to be the
best possible. Recent work by Van Buskirk et al. demonstrated improvements to
the split-radix operation count by using multiplier coefficients or &quot;twiddle
factors&quot; that are not n-th roots of unity for a size-n DFT. This paper presents
a Boolean Satisfiability-based proof of the lowest operation count for certain
classes of DFT algorithms. First, we present a novel way to choose new yet
valid twiddle factors for the nodes in flowgraphs generated by common
power-of-two fast Fourier transform algorithms, FFTs. With this new technique,
we can generate a large family of FFTs realizable by a fixed flowgraph. This
solution space of FFTs is cast as a Boolean Satisfiability problem, and a
modern Satisfiability Modulo Theory solver is applied to search for FFTs
requiring the fewest arithmetic operations. Surprisingly, we find that there
are FFTs requiring fewer operations than the split-radix even when all twiddle
factors are n-th roots of unity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5743</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5743</id><created>2011-03-29</created><authors><author><keyname>Hossain</keyname><forenames>M. Shahriar</forenames></author><author><keyname>Fuad</keyname><forenames>M. Muztaba</forenames></author><author><keyname>Deb</keyname><forenames>Debzani</forenames></author><author><keyname>Khan</keyname><forenames>Kazi Muhammad Najmul Hasan</forenames></author><author><keyname>Joarder</keyname><forenames>Md. Mahbubul Alam</forenames></author></authors><title>Load Balancing in a Networked Environment through Homogenization</title><categories>cs.DC</categories><comments>International Conference on Cybernetics and Information Technologies,
  Orlando, USA, July 21-25, 2004, Pages 99-104</comments><journal-ref>International Conference on Cybernetics and Information
  Technologies, Systems and Applications Orlando, USA, July 21-25, CITSA 2004,
  Pages: 99-104</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed processing across a networked environment suffers from
unpredictable behavior of speedup due to heterogeneous nature of the hardware
and software in the remote machines. It is challenging to get a better
performance from a distributed system by distributing task in an intelligent
manner such that the heterogeneous nature of the system do not have any effect
on the speedup ratio. This paper introduces homogenization, a technique that
distributes and balances the workload in such a manner that the user gets the
highest speedup possible from a distributed environment. Along with providing
better performance, homogenization is totally transparent to the user and
requires no interaction with the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5760</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5760</id><created>2011-03-29</created><authors><author><keyname>Hossain</keyname><forenames>M. Shahriar</forenames></author><author><keyname>Khan</keyname><forenames>Kazi Muhammad Najmul Hasan</forenames></author><author><keyname>Fuad</keyname><forenames>M. Muztaba</forenames></author><author><keyname>Deb</keyname><forenames>Debzani</forenames></author></authors><title>Triangular Dynamic Architecture for Distributed Computing in a LAN
  Environment</title><categories>cs.DC</categories><comments>Published</comments><journal-ref>6th International Conference on Computer and Information
  Technology, Dhaka, Bangladesh, 2003, Pages 481-486</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A computationally intensive large job, granulized to concurrent pieces and
operating in a dynamic environment should reduce the total processing time.
However, distributing jobs across a networked environment is a tedious and
difficult task. Job distribution in a Local Area Network based on Triangular
Dynamic Architecture (TDA) is a mechanism that establishes a dynamic
environment for job distribution, load balancing and distributed processing
with minimum interaction from the user. This paper introduces TDA and discusses
its architecture and shows the benefits gained by utilizing such architecture
in a distributed computing environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5764</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5764</id><created>2011-03-29</created><authors><author><keyname>Hossain</keyname><forenames>M. Shahriar</forenames></author><author><keyname>Fuad</keyname><forenames>M. Muztaba</forenames></author><author><keyname>Joarder</keyname><forenames>Md. Mahbubul Alam</forenames></author></authors><title>Agent Based Processing of Global Evaluation Function</title><categories>cs.DC</categories><journal-ref>Journal of Electronics and Computer Science, Jahangirnagar
  University Press, Bangladesh, Vol.6, June 2005, Pages 35-45</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Load balancing across a networked environment is a monotonous job. Moreover,
if the job to be distributed is a constraint satisfying one, the distribution
of load demands core intelligence. This paper proposes parallel processing
through Global Evaluation Function by means of randomly initialized agents for
solving Constraint Satisfaction Problems. A potential issue about the number of
agents in a machine under the invocation of distribution is discussed here for
securing the maximum benefit from Global Evaluation and parallel processing.
The proposed system is compared with typical solution that shows an exclusive
outcome supporting the nobility of parallel implementation of Global Evaluation
Function with certain number of agents in each invoked machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5776</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5776</id><created>2011-03-29</created><authors><author><keyname>Semerci</keyname><forenames>Oguz</forenames></author><author><keyname>Miller</keyname><forenames>Eric L.</forenames></author></authors><title>A Parametric Level Set Approach to Simultaneous Object Identification
  and Background Reconstruction for Dual Energy Computed Tomography</title><categories>cs.CV physics.med-ph</categories><doi>10.1109/TIP.2012.2186308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual energy computerized tomography has gained great interest because of its
ability to characterize the chemical composition of a material rather than
simply providing relative attenuation images as in conventional tomography. The
purpose of this paper is to introduce a novel polychromatic dual energy
processing algorithm with an emphasis on detection and characterization of
piecewise constant objects embedded in an unknown, cluttered background.
Physical properties of the objects, specifically the Compton scattering and
photoelectric absorption coefficients, are assumed to be known with some level
of uncertainty. Our approach is based on a level-set representation of the
characteristic function of the object and encompasses a number of
regularization techniques for addressing both the prior information we have
concerning the physical properties of the object as well as fundamental,
physics-based limitations associated with our ability to jointly recover the
Compton scattering and photoelectric absorption properties of the scene. In the
absence of an object with appropriate physical properties, our approach returns
a null characteristic function and thus can be viewed as simultaneously solving
the detection and characterization problems. Unlike the vast majority of
methods which define the level set function non-parametrically, i.e., as a
dense set of pixel values), we define our level set parametrically via radial
basis functions (RBF's) and employ a Gauss-Newton type algorithm for cost
minimization. Numerical results show that the algorithm successfully detects
objects of interest, finds their shape and location, and gives a adequate
reconstruction of the background.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5783</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5783</id><created>2011-03-29</created><authors><author><keyname>Hassan</keyname><forenames>Maaly Awad S</forenames></author><author><keyname>Abuhaiba</keyname><forenames>Ibrahim Soliman I</forenames></author></authors><title>Image Encryption Using Differential Evolution Approach in Frequency
  Domain</title><categories>cs.CR</categories><comments>19 pages, 15 figures, 3 tables</comments><journal-ref>Signal &amp; Image Processing: An International Journal (SIPIJ) Vol.2,
  No.1, pp. 51-69, March 2011</journal-ref><doi>10.5121/sipij.2011.2105</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new effective method for image encryption which employs
magnitude and phase manipulation using Differential Evolution (DE) approach.
The novelty of this work lies in deploying the concept of keyed discrete
Fourier transform (DFT) followed by DE operations for encryption purpose. To
this end, a secret key is shared between both encryption and decryption sides.
Firstly two dimensional (2-D) keyed discrete Fourier transform is carried out
on the original image to be encrypted. Secondly crossover is performed between
two components of the encrypted image, which are selected based on Linear
Feedback Shift Register (LFSR) index generator. Similarly, keyed mutation is
performed on the real parts of a certain components selected based on LFSR
index generator. The LFSR index generator initializes it seed with the shared
secret key to ensure the security of the resulting indices. The process
shuffles the positions of image pixels. A new image encryption scheme based on
the DE approach is developed which is composed with a simple diffusion
mechanism. The deciphering process is an invertible process using the same key.
The resulting encrypted image is found to be fully distorted, resulting in
increasing the robustness of the proposed work. The simulation results validate
the proposed image encryption scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5789</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5789</id><created>2011-03-29</created><updated>2012-05-19</updated><authors><author><keyname>Zhou</keyname><forenames>Lei</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>On the Capacity of the K-User Cyclic Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>ISIT, Saint Petersburg, Russia, Aug 2011, pp. 1171-1175</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper studies the capacity region of a $K$-user cyclic Gaussian
interference channel, where the $k$th user interferes with only the $(k-1)$th
user (mod $K$) in the network. Inspired by the work of Etkin, Tse and Wang,
which derived a capacity region outer bound for the two-user Gaussian
interference channel and proved that a simple Han-Kobayashi power splitting
scheme can achieve to within one bit of the capacity region for all values of
channel parameters, this paper shows that a similar strategy also achieves the
capacity region for the $K$-user cyclic interference channel to within a
constant gap in the weak interference regime. Specifically, a compact
representation of the Han-Kobayashi achievable rate region using
Fourier-Motzkin elimination is first derived, a capacity region outer bound is
then established. It is shown that the Etkin-Tse-Wang power splitting strategy
gives a constant gap of at most two bits (or one bit per dimension) in the weak
interference regime. Finally, the capacity result of the $K$-user cyclic
Gaussian interference channel in the strong interference regime is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5791</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5791</id><created>2011-03-29</created><authors><author><keyname>Hassan</keyname><forenames>Maaly Awad</forenames></author><author><keyname>Chickadel</keyname><forenames>Andrew</forenames></author></authors><title>A Review of Interference Reduction in Wireless Networks Using Graph
  Coloring Methods</title><categories>cs.NI</categories><comments>10 pages, 5 figures</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks (GRAPH-HOC) Vol. 3, No. 1, pp. 58-67,
  March 2011</journal-ref><doi>10.5121/jgraphhoc.2011.3104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interference imposes a significant negative impact on the performance of
wireless networks. With the continuous deployment of larger and more
sophisticated wireless networks, reducing interference in such networks is
quickly being focused upon as a problem in today's world. In this paper we
analyze the interference reduction problem from a graph theoretical viewpoint.
A graph coloring methods are exploited to model the interference reduction
problem. However, additional constraints to graph coloring scenarios that
account for various networking conditions result in additional complexity to
standard graph coloring. This paper reviews a variety of algorithmic solutions
for specific network topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5794</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5794</id><created>2011-03-29</created><updated>2011-12-21</updated><authors><author><keyname>Helmi</keyname><forenames>Maryam</forenames></author><author><keyname>Higham</keyname><forenames>Lisa</forenames></author><author><keyname>Pacheco</keyname><forenames>Eduardo</forenames></author><author><keyname>Woelfel</keyname><forenames>Philipp</forenames></author></authors><title>The Space Complexity of Long-lived and One-Shot Timestamp
  Implementations</title><categories>cs.DC</categories><acm-class>F.2.m; D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the problem of implementing an unbounded
timestamp object from multi-writer atomic registers, in an asynchronous
distributed system of n processors with distinct identifiers where timestamps
are taken from an arbitrary universe. Ellen, Fatourou and Ruppert (2008) showed
that sqrt{n}/2-O(1) registers are required for any obstruction-free
implementation of long-lived timestamp systems from atomic registers (meaning
processors can repeatedly get timestamps). We improve this existing lower bound
in two ways. First we establish a lower bound of n/6 - O(1) registers for the
obstruction-free long-lived timestamp problem. Previous such linear lower
bounds were only known for constrained versions of the timestamp problem. This
bound is asymptotically tight; Ellen, Fatourou and Ruppert (2008) constructed a
wait-free algorithm that uses n-1 registers. Second we show that sqrt{n} - O(1)
registers are required for any obstruction-free implementation of one-shot
timestamp systems(meaning each processor can get a timestamp at most once). We
show that this bound is also asymptotically tight by providing a wait-free
one-shot timestamp system that uses fewer than 2 sqrt{n} registers, thus
establishing a space complexity gap between one-shot and long-lived timestamp
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5795</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5795</id><created>2011-03-29</created><authors><author><keyname>Hossain</keyname><forenames>M. Shahriar</forenames></author><author><keyname>Angryk</keyname><forenames>Rafal A.</forenames></author></authors><title>Heuristic Algorithm for Interpretation of Non-Atomic Categorical
  Attributes in Similarity-based Fuzzy Databases - Scalability Evaluation</title><categories>cs.DB</categories><journal-ref>M. S. Hossain, R. A. Angryk, Heuristic Algorithm for
  Interpretation of Non-Atomic Categorical Attributes in Similarity-based Fuzzy
  Databases - Scalability Evaluation, NAFIPS 2007: 233-238</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we are analyzing scalability of the heuristic algorithm we used
in the past to discover knowledge from multi-valued symbolic attributes in
fuzzy databases. The non-atomic descriptors, characterizing a single attribute
of a database record, are commonly used in fuzzy databases to reflect
uncertainty about the recorded observation. In this paper, we present
implementation details and scalability tests of the algorithm, which we
developed to precisely interpret such non-atomic values and to transfer (i.e.
defuzzify) the fuzzy tuples to the forms acceptable for many regular (i.e.
atomic values based) data mining algorithms. Important advantages of our
approach are: (1) its linear scalability, and (2) its unique capability of
incorporating background knowledge, implicitly stored in the fuzzy database
models in the form of fuzzy similarity hierarchy, into the
interpretation/defuzzification process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5797</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5797</id><created>2011-03-29</created><updated>2011-05-06</updated><authors><author><keyname>Wagner</keyname><forenames>Markus</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author></authors><title>Computational Complexity Results for Genetic Programming and the Sorting
  Problem</title><categories>cs.NE</categories><comments>12 pages</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genetic Programming (GP) has found various applications. Understanding this
type of algorithm from a theoretical point of view is a challenging task. The
first results on the computational complexity of GP have been obtained for
problems with isolated program semantics. With this paper, we push forward the
computational complexity analysis of GP on a problem with dependent program
semantics. We study the well-known sorting problem in this context and analyze
rigorously how GP can deal with different measures of sortedness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5808</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5808</id><created>2011-03-29</created><authors><author><keyname>Heinrich</keyname><forenames>Stuart B.</forenames></author><author><keyname>Snyder</keyname><forenames>Wesley E.</forenames></author></authors><title>Improved Edge Awareness in Discontinuity Preserving Smoothing</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discontinuity preserving smoothing is a fundamentally important procedure
that is useful in a wide variety of image processing contexts. It is directly
useful for noise reduction, and frequently used as an intermediate step in
higher level algorithms. For example, it can be particularly useful in edge
detection and segmentation. Three well known algorithms for discontinuity
preserving smoothing are nonlinear anisotropic diffusion, bilateral filtering,
and mean shift filtering. Although slight differences make them each better
suited to different tasks, all are designed to preserve discontinuities while
smoothing. However, none of them satisfy this goal perfectly: they each have
exception cases in which smoothing may occur across hard edges. The principal
contribution of this paper is the identification of a property we call edge
awareness that should be satisfied by any discontinuity preserving smoothing
algorithm. This constraint can be incorporated into existing algorithms to
improve quality, and usually has negligible changes in runtime performance
and/or complexity. We present modifications necessary to augment diffusion and
mean shift, as well as a new formulation of the bilateral filter that unifies
the spatial and range spaces to achieve edge awareness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5855</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5855</id><created>2011-03-30</created><authors><author><keyname>Kosinska</keyname><forenames>Ilona D.</forenames><affiliation>Wroclaw University of Technology, Institute of Biomedical Engineering and Instrumentation, Poland</affiliation></author></authors><title>The FEM approach to the 3D electrodiffusion on 'meshes' optimized with
  the Metropolis algorithm</title><categories>cs.CG cs.CE math-ph math.MP</categories><comments>16 pages, 7 figures</comments><msc-class>74S05, 35Qxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The presented article contains a 3D mesh generation routine optimized with
the Metropolis algorithm. The procedure enables to produce meshes of a
prescribed volume V_0 of elements. The finite volume meshes are used with the
Finite Element approach. The FEM analysis enables to deal with a set of coupled
nonlinear differential equations that describes the electrodiffusional problem.
Mesh quality and accuracy of FEM solutions are also examined. High quality of
FEM type space-dependent approximation and correctness of discrete
approximation in time are ensured by finding solutions to the 3D Laplace
problem and to the 3D diffusion equation, respectively. Their comparison with
analytical solutions confirms accuracy of obtained approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5881</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5881</id><created>2011-03-30</created><authors><author><keyname>Abdel-qader</keyname><forenames>Maher</forenames></author><author><keyname>AL-Jaber</keyname><forenames>Ahmad</forenames></author><author><keyname>AL-Hamami</keyname><forenames>Alaa</forenames></author></authors><title>Using Short Message Service (SMS) to Support Business Continuity</title><categories>cs.NI</categories><comments>5 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT), ISSN: 2221-0741, Vol. 1, No. 2, 34-38, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now a day's many organizations are required to communicate online on a daily
basis, 24-hour, seven-days-a-week, to gain the desired competitive advantages
and profits; although there are a variety of disruptions that may occur within
business application such as broken (off-line) database-links and unhanded
database exceptions. Such cases will end the automated business work, and force
business users to continue business procedures and functionalities via paper
work, which causes additional resources with less business competitive
advantages. In this paper, we will propose a new model in which we embed short
message services (SMS) within business applications using the SMS Gateway such
as &quot;Ozeki Message Server&quot;, and programmed application packages. By using our
proposed model, we can maintain business continuity when a partial disruption
occurs and then switch to our application model. As a result to the
experimental work, we conclude that our model supports business continuity
since it supports the account balance modification while the database link is
disrupted. In addition, we carried out each step twice and the scenario was
reliable since all of its steps were reliable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5901</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5901</id><created>2011-03-30</created><authors><author><keyname>Lorenz</keyname><forenames>David H.</forenames></author><author><keyname>Rosenan</keyname><forenames>Boaz</forenames></author></authors><title>A Comparative Case Study of Code Reuse With Language Oriented
  Programming</title><categories>cs.SE cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a gap between our ability to reuse high-level concepts in software
design and our ability to reuse the code implementing them. Language Oriented
Programming (LOP) is a software development paradigm that aims to close this
gap, through extensive use of Domain Specific Languages (DSLs). With LOP, the
high-level reusable concepts become reusable DSL constructs, and their
translation into code level concepts is done in the DSL implementation.
Particular products are implemented using DSL code, thus reusing only
high-level concepts. In this paper we provide a comparison between two
implementation approaches for LOP: (a) using external DSLs with a projectional
language workbench (MPS); and (b) using internal DSLs with an LOP language
(Cedalion). To demonstrate how reuse is achieved in each approach, we present a
small case study, where LOP is used to build a Software Product Line (SPL) of
calculator software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5916</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5916</id><created>2011-03-30</created><authors><author><keyname>van Glabbeek</keyname><forenames>Rob</forenames></author><author><keyname>Goltz</keyname><forenames>Ursula</forenames></author><author><keyname>Schicke</keyname><forenames>Jens-Wolfhard</forenames></author></authors><title>Abstract Processes of Place/Transition Systems</title><categories>cs.LO</categories><acm-class>F.1.2</acm-class><journal-ref>Information Processing Letters 111(13), 2011, pp. 626-633</journal-ref><doi>10.1016/j.ipl.2011.03.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known problem in Petri net theory is to formalise an appropriate
causality-based concept of process or run for place/transition systems. The
so-called individual token interpretation, where tokens are distinguished
according to their causal history, giving rise to the processes of Goltz and
Reisig, is often considered too detailed. The problem of defining a fully
satisfying more abstract concept of process for general place/transition
systems has so-far not been solved. In this paper, we recall the proposal of
defining an abstract notion of process, here called BD-process, in terms of
equivalence classes of Goltz-Reisig processes, using an equivalence proposed by
Best and Devillers. It yields a fully satisfying solution for at least all
one-safe nets. However, for certain nets which intuitively have different
conflicting behaviours, it yields only one maximal abstract process. Here we
identify a class of place/transition systems, called structural conflict nets,
where conflict and concurrency due to token multiplicity are clearly separated.
We show that, in the case of structural conflict nets, the equivalence proposed
by Best and Devillers yields a unique maximal abstract process only for
conflict-free nets. Thereby BD-processes constitute a simple and fully
satisfying solution in the class of structural conflict nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5946</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5946</id><created>2011-03-30</created><authors><author><keyname>Li</keyname><forenames>Zhifang</forenames></author><author><keyname>Hu</keyname><forenames>Yanqing</forenames></author><author><keyname>Xu</keyname><forenames>Beishan</forenames></author><author><keyname>Di</keyname><forenames>Zengru</forenames></author><author><keyname>Fan</keyname><forenames>Ying</forenames></author></authors><title>Detecting the optimal number of communities in complex networks</title><categories>physics.soc-ph cs.SI stat.AP</categories><comments>8 pages, 6 figs</comments><doi>10.1016/j.physa.2011.06.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To obtain the optimal number of communities is an important problem in
detecting community structure. In this paper, we extend the measurement of
community detecting algorithms to find the optimal community number. Based on
the normalized mutual information index, which has been used as a measure for
similarity of communities, a statistic $\Omega(c)$ is proposed to detect the
optimal number of communities. In general, when $\Omega(c)$ reaches its local
maximum, especially the first one, the corresponding number of communities
\emph{c} is likely to be optimal in community detection. Moreover, the
statistic $\Omega(c)$ can also measure the significance of community structures
in complex networks, which has been paid more attention recently. Numerical and
empirical results show that the index $\Omega(c)$ is effective in both
artificial and real world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5957</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5957</id><created>2011-03-30</created><authors><author><keyname>Chen</keyname><forenames>Phoebus</forenames></author><author><keyname>Johansson</keyname><forenames>Karl H.</forenames></author><author><keyname>Balister</keyname><forenames>Paul</forenames></author><author><keyname>Bollob&#xe1;s</keyname><forenames>B&#xe9;la</forenames></author><author><keyname>Sastry</keyname><forenames>Shankar</forenames></author></authors><title>Multi-path Routing Metrics for Reliable Wireless Mesh Routing Topologies</title><categories>cs.NI</categories><comments>11 pages, 8 figures. Originally submitted to KTH Royal Institute of
  Technology Technical Report Database on March 30, 2011</comments><report-no>TRITA-EE 2011:033</report-no><acm-class>C.2.1; G.2.2; G.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Several emerging classes of applications that run over wireless networks have
a need for mathematical models and tools to systematically characterize the
reliability of the network. We propose two metrics for measuring the
reliability of wireless mesh routing topologies, one for flooding and one for
unicast routing. The Flooding Path Probability (FPP) metric measures the
end-to-end packet delivery probability when each node broadcasts a packet after
hearing from all its upstream neighbors. The Unicast Retransmission Flow (URF)
metric measures the end-to-end packet delivery probability when a relay node
retransmits a unicast packet on its outgoing links until it receives an
acknowledgement or it tries all the links. Both metrics rely on specific packet
forwarding models, rather than heuristics, to derive explicit expressions of
the end-to-end packet delivery probability from individual link probabilities
and the underlying connectivity graph.
  We also propose a distributed, greedy algorithm that uses the URF metric to
construct a reliable routing topology. This algorithm constructs a Directed
Acyclic Graph (DAG) from a weighted, undirected connectivity graph, where each
link is weighted by its success probability. The algorithm uses a vector of
decreasing reliability thresholds to coordinate when nodes can join the routing
topology. Simulations demonstrate that, on average, this algorithm constructs a
more reliable topology than the usual minimum hop DAG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5958</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5958</id><created>2011-03-30</created><authors><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames></author><author><keyname>Dave</keyname><forenames>Rahul</forenames></author></authors><title>Semantic Interlinking of Resources in the Virtual Observatory Era</title><categories>astro-ph.IM cs.DL</categories><comments>10 pages, 3 figures, to appear in: ASPC 442 (2011), Proceedings of
  Astronomical Data Analysis Software and Systems XX</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the coming era of data-intensive science, it will be increasingly
important to be able to seamlessly move between scientific results, the data
analyzed in them, and the processes used to produce them. As observations,
derived data products, publications, and object metadata are curated by
different projects and archived in different locations, establishing the proper
linkages between these resources and describing their relationships becomes an
essential activity in their curation and preservation. In this paper we
describe initial efforts to create a semantic knowledge base allowing easier
integration and linking of the body of heterogeneous astronomical resources
which we call the Virtual Observatory (VO). The ultimate goal of this effort is
the creation of a semantic layer over existing resources, allowing applications
to cross boundaries between archives. The proposed approach follows the current
best practices in Semantic Computing and the architecture of the web, allowing
the use of off-the-shelf technologies and providing a path for VO resources to
become part of the global web of linked data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5985</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5985</id><created>2011-03-30</created><authors><author><keyname>Vit&#xe1;nyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI and University of Amsterdam</affiliation></author></authors><title>On Empirical Entropy</title><categories>cs.IT cs.LG math.IT</categories><comments>14 pages, LaTeX</comments><msc-class>68, 94</msc-class><acm-class>H.1; F.1; J.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a compression-based version of the empirical entropy of a finite
string over a finite alphabet. Whereas previously one considers the naked
entropy of (possibly higher order) Markov processes, we consider the sum of the
description of the random variable involved plus the entropy it induces. We
assume only that the distribution involved is computable. To test the new
notion we compare the Normalized Information Distance (the similarity metric)
with a related measure based on Mutual Information in Shannon's framework. This
way the similarities and differences of the last two concepts are exposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.5991</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.5991</id><created>2011-03-30</created><updated>2011-06-03</updated><authors><author><keyname>Malloy</keyname><forenames>Matthew</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>Sequential Analysis in High Dimensional Multiple Testing and Sparse
  Recovery</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of high-dimensional multiple testing and
sparse recovery from the perspective of sequential analysis. In this setting,
the probability of error is a function of the dimension of the problem. A
simple sequential testing procedure is proposed. We derive necessary conditions
for reliable recovery in the non-sequential setting and contrast them with
sufficient conditions for reliable recovery using the proposed sequential
testing procedure. Applications of the main results to several commonly
encountered models show that sequential testing can be exponentially more
sensitive to the difference between the null and alternative distributions (in
terms of the dependence on dimension), implying that subtle cases can be much
more reliably determined using sequential methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6006</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6006</id><created>2011-03-30</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author></authors><title>Parallel Information Algorithm with Local Tuning for Solving
  Multidimensional GO Problems</title><categories>math.OC cs.NA math.NA physics.comp-ph</categories><comments>11 pages</comments><msc-class>90C26, 65K05, 68W10</msc-class><journal-ref>Journal of Global Optimization, 1999, 15(2), 157-167</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a new parallel algorithm for solving global
optimization (GO) multidimensional problems. The method unifies two powerful
approaches for accelerating the search: parallel computations and local tuning
on the behavior of the objective function. We establish convergence conditions
for the algorithm and theoretically show that the usage of local information
during the global search permits to accelerate solving the problem
significantly. Results of numerical experiments executed with 100 test
functions are also reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6007</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6007</id><created>2011-03-30</created><updated>2011-04-21</updated><authors><author><keyname>Buliga</keyname><forenames>Marius</forenames></author></authors><title>Computing with space: a tangle formalism for chora and difference</title><categories>math.MG cs.LO q-bio.NC</categories><comments>56 pages, added content and reorganized the paper, title changed,
  many figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is space computing, simulation, or understanding? Converging from
several sources, this seems to be something more primitive than what is usually
meant by computation, something that was along with us since antiquity (the
word &quot;choros&quot;, &quot;chora&quot;, denotes &quot;space&quot; or &quot;place&quot; and is seemingly the most
mysterious notion from Plato, described in Timaeus 48e - 53c) which has to do
with cybernetics and with the understanding of the front end visual system. It
may have some unexpected applications, also. Here, inspired by Bateson (see
Supplementary Material), I explore from the mathematical side the point of view
that there is no difference between the map and the territory, but instead the
transformation of one into another can be understood by using a formalism of
tangle diagrams.
  This paper continues arXiv:1009.5028 &quot;What is a space? Computations in
emergent algebras and the front end visual system&quot; and the arXiv:1007.2362
&quot;Introduction to metric spaces with dilations&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6019</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6019</id><created>2011-03-30</created><updated>2011-08-04</updated><authors><author><keyname>Hunter</keyname><forenames>Paul</forenames></author></authors><title>LIFO-search on digraphs: A searching game for cycle-rank</title><categories>cs.DM</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the extension of the last-in-first-out graph searching game of
Giannopoulou and Thilikos to digraphs. We show that all common variations of
the game require the same number of searchers, and the minimal number of
searchers required is one more than the cycle-rank of the digraph. We also
obtain a tight duality theorem, giving a precise min-max characterization of
obstructions for cycle-rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6049</identifier>
 <datestamp>2013-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6049</id><created>2011-03-30</created><updated>2013-02-12</updated><authors><author><keyname>Al-Bawani</keyname><forenames>Kamal</forenames></author><author><keyname>Souza</keyname><forenames>Alexander</forenames></author></authors><title>Buffer Overflow Management with Class Segregation</title><categories>cs.DS cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a new model for buffer management of network switches with
Quality of Service (QoS) requirements. A stream of packets, each attributed
with a value representing its Class of Service (CoS), arrives over time at a
network switch and demands a further transmission. The switch is equipped with
multiple queues of limited capacities, where each queue stores packets of one
value only. The objective is to maximize the total value of the transmitted
packets (i.e., the weighted throughput).
  We analyze a natural greedy algorithm, GREEDY, which sends in each time step
a packet with the greatest value. For general packet values $(v_1 &lt; \cdots &lt;
v_m)$, we show that GREEDY is $(1+r)$-competitive, where $r = \max_{1\le i \le
m-1} \{v_i/v_{i+1}\}$. Furthermore, we show a lower bound of $2 - v_m /
\sum_{i=1}^m v_i$ on the competitiveness of any deterministic online algorithm.
In the special case of two packet values (1 and $\alpha &gt; 1$), GREEDY is shown
to be optimal with a competitive ratio of $(\alpha + 2)/(\alpha + 1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6052</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6052</id><created>2011-03-30</created><authors><author><keyname>Heinrich</keyname><forenames>Stuart B.</forenames></author><author><keyname>Snyder</keyname><forenames>Wesley E.</forenames></author></authors><title>Internal Constraints of the Trifocal Tensor</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental matrix and trifocal tensor are convenient algebraic
representations of the epipolar geometry of two and three view configurations,
respectively. The estimation of these entities is central to most
reconstruction algorithms, and a solid understanding of their properties and
constraints is therefore very important. The fundamental matrix has 1 internal
constraint which is well understood, whereas the trifocal tensor has 8
independent algebraic constraints. The internal tensor constraints can be
represented in many ways, although there is only one minimal and sufficient set
of 8 constraints known. In this paper, we derive a second set of minimal and
sufficient constraints that is simpler. We also show how this can be used in a
new parameterization of the trifocal tensor. We hope that this increased
understanding of the internal constraints may lead to improved algorithms for
estimating the trifocal tensor, although the primary contribution is an
improved theoretical understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6060</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6060</id><created>2011-03-30</created><authors><author><keyname>Wang</keyname><forenames>Chenwei</forenames><affiliation>Shitz</affiliation></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Wigger</keyname><forenames>Michele</forenames></author></authors><title>Interference, Cooperation and Connectivity - A Degrees of Freedom
  Perspective</title><categories>cs.IT math.IT</categories><comments>Submitted to 2011 IEEE International Symposium on Information Theory
  (ISIT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the interplay between interference, cooperation and connectivity
in heterogeneous wireless interference networks. Specifically, we consider a
4-user locally-connected interference network with pairwise clustered decoding
and show that its degrees of freedom (DoF) are bounded above by 12/5.
Interestingly, when compared to the corresponding fully connected setting which
is known to have 8/3 DoF, the locally connected network is only missing
interference-carrying links, but still has lower DoF, i.e., eliminating these
interference-carrying links reduces the DoF. The 12/5 DoF outer bound is
obtained through a novel approach that translates insights from interference
alignment over linear vector spaces into corresponding sub-modularity
relationships between entropy functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6067</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6067</id><created>2011-03-30</created><updated>2012-01-12</updated><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Nayak</keyname><forenames>Ashwin</forenames></author></authors><title>Short proofs of the Quantum Substate Theorem</title><categories>quant-ph cs.CC cs.IT math.IT</categories><comments>11 pages. Rewritten; included new references; presented the results
  in terms of smooth relative min-entropy; stronger results; included converse
  and proof using SDP duality</comments><msc-class>94A17, 94A15, 81P45, 81P94, 68P30, 68Q12, 47B65</msc-class><acm-class>F.0; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Quantum Substate Theorem due to Jain, Radhakrishnan, and Sen (2002) gives
us a powerful operational interpretation of relative entropy, in fact, of the
observational divergence of two quantum states, a quantity that is related to
their relative entropy. Informally, the theorem states that if the
observational divergence between two quantum states rho, sigma is small, then
there is a quantum state rho' close to rho in trace distance, such that rho'
when scaled down by a small factor becomes a substate of sigma. We present new
proofs of this theorem. The resulting statement is optimal up to a constant
factor in its dependence on observational divergence. In addition, the proofs
are both conceptually simpler and significantly shorter than the earlier proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6073</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6073</id><created>2011-03-30</created><authors><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author></authors><title>Colorful Triangle Counting and a MapReduce Implementation</title><categories>cs.DS cs.DM cs.SI</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we introduce a new randomized algorithm for counting triangles
in graphs. We show that under mild conditions, the estimate of our algorithm is
strongly concentrated around the true number of triangles. Specifically, if $p
\geq \max{(\frac{\Delta \log{n}}{t}, \frac{\log{n}}{\sqrt{t}})}$, where $n$,
$t$, $\Delta$ denote the number of vertices in $G$, the number of triangles in
$G$, the maximum number of triangles an edge of $G$ is contained, then for any
constant $\epsilon&gt;0$ our unbiased estimate $T$ is concentrated around its
expectation, i.e., $ \Prob{|T - \Mean{T}| \geq \epsilon \Mean{T}} = o(1)$.
Finally, we present a \textsc{MapReduce} implementation of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6087</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6087</id><created>2011-03-31</created><authors><author><keyname>Liu</keyname><forenames>Xu</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Zhan</keyname><forenames>Kunlin</forenames></author><author><keyname>Shi</keyname><forenames>Weisong</forenames></author><author><keyname>Yuan</keyname><forenames>Lin</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author></authors><title>Automatic Performance Debugging of SPMD-style Parallel Programs</title><categories>cs.DC</categories><comments>16 pages, 23 figures. Accepted by Journal of Parallel and Distributed
  Computing (JPDC)</comments><journal-ref>Journal of Parallel and Distributed Computing (JPDC), March, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The simple program and multiple data (SPMD) programming model is widely used
for both high performance computing and Cloud computing. In this paper, we
design and implement an innovative system, AutoAnalyzer, that automates the
process of debugging performance problems of SPMD-style parallel programs,
including data collection, performance behavior analysis, locating bottlenecks,
and uncovering their root causes. AutoAnalyzer is unique in terms of two
features: first, without any apriori knowledge, it automatically locates
bottlenecks and uncovers their root causes for performance optimization;
second, it is lightweight in terms of the size of performance data to be
collected and analyzed. Our contributions are three-fold: first, we propose two
effective clustering algorithms to investigate the existence of performance
bottlenecks that cause process behavior dissimilarity or code region behavior
disparity, respectively; meanwhile, we present two searching algorithms to
locate bottlenecks; second, on a basis of the rough set theory, we propose an
innovative approach to automatically uncovering root causes of bottlenecks;
third, on the cluster systems with two different configurations, we use two
production applications, written in Fortran 77, and one open source
code-MPIBZIP2 (http://compression.ca/mpibzip2/), written in C++, to verify the
effectiveness and correctness of our methods. For three applications, we also
propose an experimental approach to investigating the effects of different
metrics on locating bottlenecks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6103</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6103</id><created>2011-03-31</created><authors><author><keyname>Zhang</keyname><forenames>Liangsheng</forenames></author><author><keyname>Chen</keyname><forenames>Wenjin</forenames></author><author><keyname>Antony</keyname><forenames>Mathis</forenames></author><author><keyname>Szeto</keyname><forenames>K. Y.</forenames></author></authors><title>Phase diagram of Symmetric Iterated Prisoner's Dilemma of Two-Companies
  with Partial Imitation Rule</title><categories>physics.soc-ph cs.GT</categories><comments>14 pages, 3 figures</comments><msc-class>91A22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of two companies of agents with one-step memory playing game is
investigated in the context of the Iterated Prisoner's Dilemma under the
partial imitation rule, where a player can imitate only those moves that he has
observed in his games with his opponent. We limit our study to the special case
where the players in the two groups enjoy the same conditions on a fully
connected network, so that there are only two payoff matrices required: one for
players playing games with members of the same company, and the other one for
players playing games with members from a different company. We show that this
symmetric case of two companies of players can be reduced to the one-company
case with an effective payoff matrix, from which a phase diagram for the
players using the two dominant strategies, Pavlov and Grim Trigger can be
constructed. The phase diagram is computed by numerical integration of the
approximate mean value equations. The results are in good agreement with
simulations of the two-company model. The phase diagram leads to an interesting
conclusion that a player will more likely become a Grim Trigger, regardless of
their affiliated company, when the noise level increases so that he is more
irrational, or when the intra-group temptation to defect increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6114</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6114</id><created>2011-03-31</created><updated>2011-04-06</updated><authors><author><keyname>Jaffe</keyname><forenames>Alexander</forenames></author><author><keyname>Moscibroda</keyname><forenames>Thomas</forenames></author><author><keyname>Effinger-Dean</keyname><forenames>Laura</forenames></author><author><keyname>Ceze</keyname><forenames>Luis</forenames></author><author><keyname>Strauss</keyname><forenames>Karin</forenames></author></authors><title>The Impact of Memory Models on Software Reliability in Multiprocessors</title><categories>cs.DC</categories><comments>15 pages, 2 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The memory consistency model is a fundamental system property characterizing
a multiprocessor. The relative merits of strict versus relaxed memory models
have been widely debated in terms of their impact on performance, hardware
complexity and programmability. This paper adds a new dimension to this
discussion: the impact of memory models on software reliability. By allowing
some instructions to reorder, weak memory models may expand the window between
critical memory operations. This can increase the chance of an undesirable
thread-interleaving, thus allowing an otherwise-unlikely concurrency bug to
manifest. To explore this phenomenon, we define and study a probabilistic model
of shared-memory parallel programs that takes into account such reordering. We
use this model to formally derive bounds on the \emph{vulnerability} to
concurrency bugs of different memory models. Our results show that for 2 (or a
small constant number of) concurrent threads, weaker memory models do indeed
have a higher likelihood of allowing bugs. On the other hand, we show that as
the number of parallel threads increases, the gap between the different memory
models becomes proportionally insignificant. This suggests the
counter-intuitive rule that \emph{as the number of parallel threads in the
system increases, the importance of using a strict memory model diminishes};
which potentially has major implications on the choice of memory consistency
models in future multi-core systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6149</identifier>
 <datestamp>2013-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6149</id><created>2011-03-31</created><updated>2013-01-29</updated><authors><author><keyname>Elkouss</keyname><forenames>David</forenames></author><author><keyname>Martinez-Mateo</keyname><forenames>Jesus</forenames></author><author><keyname>Martin</keyname><forenames>Vicente</forenames></author></authors><title>Untainted Puncturing for Irregular Low-Density Parity-Check Codes</title><categories>cs.IT math.IT</categories><comments>4 pages, 3 figures</comments><journal-ref>Wireless Communications Letters, IEEE Volume: 1 , Issue: 6,
  Publication Year: 2012 , Page(s): 585 - 588</journal-ref><doi>10.1109/WCL.2012.082712.120531</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Puncturing is a well-known coding technique widely used for constructing
rate-compatible codes. In this paper, we consider the problem of puncturing
low-density parity-check codes and propose a new algorithm for intentional
puncturing. The algorithm is based on the puncturing of untainted symbols, i.e.
nodes with no punctured symbols within their neighboring set. It is shown that
the algorithm proposed here performs better than previous proposals for a range
of coding rates and short proportions of punctured symbols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6161</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6161</id><created>2011-03-31</created><updated>2011-08-17</updated><authors><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>The Grothendieck constant is strictly smaller than Krivine's bound</title><categories>math.FA cs.DS</categories><comments>An extended abstract describing the contents of this work will appear
  in FOCS 2011. Suggestions of the FOCS reviewers have been addressed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that $K_G&lt;\frac{\pi}{2\log(1+\sqrt{2})}$, where $K_G$ is the
Grothendieck constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6187</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6187</id><created>2011-03-31</created><authors><author><keyname>Chen</keyname><forenames>Li</forenames></author></authors><title>Cook's Theory and the Twentieth Century Mathematics</title><categories>cs.CY</categories><comments>7 page 2 pictures. Li Chen, Cook's Theory and the Twentieth Century
  Mathematics, Journal of Scientific &amp; Practical Computing, Vol 3, No 1,
  pp57-63</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comprehensive review on Cook's contribution in the theory of
NP-Completeness with relations to modern mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6212</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6212</id><created>2011-03-31</created><authors><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author></authors><title>QCSP on partially reflexive forests</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the (non-uniform) quantified constraint satisfaction problem QCSP(H)
as H ranges over partially reflexive forests. We obtain a complexity-theoretic
dichotomy: QCSP(H) is either in NL or is NP-hard. The separating condition is
related firstly to connectivity, and thereafter to accessibility from all
vertices of H to connected reflexive subgraphs. In the case of partially
reflexive paths, we give a refinement of our dichotomy: QCSP(H) is either in NL
or is Pspace-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6219</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6219</id><created>2011-03-31</created><updated>2011-07-01</updated><authors><author><keyname>Laptyeva</keyname><forenames>T. V.</forenames></author><author><keyname>Flach</keyname><forenames>S.</forenames></author><author><keyname>Kladko</keyname><forenames>K.</forenames></author></authors><title>The weak password problem: chaos, criticality, and encrypted p-CAPTCHAs</title><categories>cs.CR cond-mat.other nlin.CD</categories><comments>5 pages, 6 figers</comments><doi>10.1209/0295-5075/95/50007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vulnerabilities related to weak passwords are a pressing global economic and
security issue. We report a novel, simple, and effective approach to address
the weak password problem. Building upon chaotic dynamics, criticality at phase
transitions, CAPTCHA recognition, and computational round-off errors we design
an algorithm that strengthens security of passwords. The core idea of our
method is to split a long and secure password into two components. The first
component is memorized by the user. The second component is transformed into a
CAPTCHA image and then protected using evolution of a two-dimensional dynamical
system close to a phase transition, in such a way that standard brute-force
attacks become ineffective. We expect our approach to have wide applications
for authentication and encryption technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6222</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6222</id><created>2011-03-31</created><updated>2011-05-23</updated><authors><author><keyname>Kennedy</keyname><forenames>W. Sean</forenames></author><author><keyname>King</keyname><forenames>Andrew D.</forenames></author></authors><title>Finding a smallest odd hole in a claw-free graph using global structure</title><categories>cs.DM math.CO</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lemma of Fouquet implies that a claw-free graph contains an induced $C_5$,
contains no odd hole, or is quasi-line. In this paper we use this result to
give an improved shortest-odd-hole algorithm for claw-free graphs by exploiting
the structural relationship between line graphs and quasi-line graphs suggested
by Chudnovsky and Seymour's structure theorem for quasi-line graphs. Our
approach involves reducing the problem to that of finding a shortest odd cycle
of length $\geq 5$ in a graph. Our algorithm runs in $O(m^2+n^2\log n)$ time,
improving upon Shrem, Stern, and Golumbic's recent $O(nm^2)$ algorithm, which
uses a local approach. The best known recognition algorithms for claw-free
graphs run in $O(m^{1.69}) \cap O(n^{3.5})$ time, or $O(m^2) \cap O(n^{3.5})$
without fast matrix multiplication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6241</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6241</id><created>2011-03-31</created><authors><author><keyname>Liu</keyname><forenames>Chun-Hung</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Ergodic Transmission Capacity of Wireless Ad Hoc Networks with
  Interference Management</title><categories>cs.IT math.IT</categories><comments>25 pages, 5 figures and 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most work on wireless network throughput ignores the temporal correlation
inherent to wireless channels because it degrades tractability. To better model
and quantify the temporal variations of wireless network throughput, this paper
introduces a metric termed ergodic transmission capacity (ETC), which includes
spatial and temporal ergodicity. All transmitters in the network form a
homogeneous Poisson point process and all channels are modeled by a finite
state Markov chain. The bounds on outage probability and ETC are characterized,
and their scaling behaviors for a sparse and dense network are discussed. From
these results, we show that the ETC can be characterized by the inner product
of the channel-state related vector and the invariant probability vector of the
Markov chain. This indicates that channel-aware opportunistic transmission does
not always increase ETC. Finally, we look at outage probability with
interference management from a stochastic geometry point of view. The improved
bounds on outage probability and ETC due to interference management are
characterized and they provide some useful insights on how to effectively
manage interference in sparse and dense networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6246</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6246</id><created>2011-03-31</created><updated>2011-07-15</updated><authors><author><keyname>Sturm</keyname><forenames>Bob L.</forenames></author></authors><title>Sparse Vector Distributions and Recovery from Compressed Sensing</title><categories>cs.DS</categories><comments>Originally submitted to IEEE Signal Processing Letters in March 2011,
  but rejected June 2011. Revised, expanded, and submitted July 2011 to EURASIP
  Journal special issue on sparse signal processing</comments><acm-class>F.2.1; G.1.2; G.1.3; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the performance of sparse vector recovery algorithms
from compressive measurements can depend on the distribution underlying the
non-zero elements of a sparse vector. However, the extent of these effects has
yet to be explored, and formally presented. In this paper, I empirically
investigate this dependence for seven distributions and fifteen recovery
algorithms. The two morals of this work are: 1) any judgement of the recovery
performance of one algorithm over that of another must be prefaced by the
conditions for which this is observed to be true, including sparse vector
distributions, and the criterion for exact recovery; and 2) a recovery
algorithm must be selected carefully based on what distribution one expects to
underlie the sensed sparse signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6248</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6248</id><created>2011-03-31</created><authors><author><keyname>Logg</keyname><forenames>Anders</forenames></author><author><keyname>Wells</keyname><forenames>Garth N.</forenames></author></authors><title>DOLFIN: Automated Finite Element Computing</title><categories>cs.MS cs.NA</categories><journal-ref>ACM Transactions on Mathematical Software 37(2), Article 20 (April
  2010), 28 pages</journal-ref><doi>10.1145/1731022.1731030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe here a library aimed at automating the solution of partial
differential equations using the finite element method. By employing novel
techniques for automated code generation, the library combines a high level of
expressiveness with efficient computation. Finite element variational forms may
be expressed in near mathematical notation, from which low-level code is
automatically generated, compiled and seamlessly integrated with efficient
implementations of computational meshes and high-performance linear algebra.
Easy-to-use object-oriented interfaces to the library are provided in the form
of a C++ library and a Python module. This paper discusses the mathematical
abstractions and methods used in the design of the library and its
implementation. A number of examples are presented to demonstrate the use of
the library in application code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6258</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6258</id><created>2011-03-31</created><authors><author><keyname>Guo</keyname><forenames>Wangmei</forenames></author><author><keyname>Cai</keyname><forenames>Ning</forenames></author><author><keyname>Shi</keyname><forenames>Xiaomeng</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Localized Dimension Growth in Random Network Coding: A Convolutional
  Approach</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure, submitted to IEEE ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient Adaptive Random Convolutional Network Coding (ARCNC)
algorithm to address the issue of field size in random network coding. ARCNC
operates as a convolutional code, with the coefficients of local encoding
kernels chosen randomly over a small finite field. The lengths of local
encoding kernels increase with time until the global encoding kernel matrices
at related sink nodes all have full rank. Instead of estimating the necessary
field size a priori, ARCNC operates in a small finite field. It adapts to
unknown network topologies without prior knowledge, by locally incrementing the
dimensionality of the convolutional code. Because convolutional codes of
different constraint lengths can coexist in different portions of the network,
reductions in decoding delay and memory overheads can be achieved with ARCNC.
We show through analysis that this method performs no worse than random linear
network codes in general networks, and can provide significant gains in terms
of average decoding delay in combination networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1103.6280</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1103.6280</id><created>2011-03-31</created><authors><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Malec</keyname><forenames>David</forenames></author><author><keyname>Malekian</keyname><forenames>Azarakhsh</forenames></author></authors><title>Bayesian Mechanism Design for Budget-Constrained Agents</title><categories>cs.GT</categories><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Bayesian mechanism design problems in settings where agents have
budgets. Specifically, an agent's utility for an outcome is given by his value
for the outcome minus any payment he makes to the mechanism, as long as the
payment is below his budget, and is negative infinity otherwise. This
discontinuity in the utility function presents a significant challenge in the
design of good mechanisms, and classical &quot;unconstrained&quot; mechanisms fail to
work in settings with budgets. The goal of this paper is to develop general
reductions from budget-constrained Bayesian MD to unconstrained Bayesian MD
with small loss in performance. We consider this question in the context of the
two most well-studied objectives in mechanism design---social welfare and
revenue---and present constant factor approximations in a number of settings.
Some of our results extend to settings where budgets are private and agents
need to be incentivized to reveal them truthfully.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0005</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0005</id><created>2011-03-31</created><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames><affiliation>Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author></authors><title>On the binary codes with parameters of triply-shortened 1-perfect codes</title><categories>cs.IT math.CO math.IT</categories><comments>12 pages</comments><msc-class>24B25</msc-class><journal-ref>Des. Codes Cryptogr. 64(3) 2012, 275-283</journal-ref><doi>10.1007/s10623-011-9574-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study properties of binary codes with parameters close to the parameters
of 1-perfect codes. An arbitrary binary $(n=2^m-3, 2^{n-m-1}, 4)$ code $C$,
i.e., a code with parameters of a triply-shortened extended Hamming code, is a
cell of an equitable partition of the $n$-cube into six cells. An arbitrary
binary $(n=2^m-4, 2^{n-m}, 3)$ code $D$, i.e., a code with parameters of a
triply-shortened Hamming code, is a cell of an equitable family (but not a
partition) from six cells. As a corollary, the codes $C$ and $D$ are completely
semiregular; i.e., the weight distribution of such a code depends only on the
minimal and maximal codeword weights and the code parameters. Moreover, if $D$
is self-complementary, then it is completely regular. As an intermediate
result, we prove, in terms of distance distributions, a general criterion for a
partition of the vertices of a graph (from rather general class of graphs,
including the distance-regular graphs) to be equitable. Keywords: 1-perfect
code; triply-shortened 1-perfect code; equitable partition; perfect coloring;
weight distribution; distance distribution
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0025</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0025</id><created>2011-03-31</created><authors><author><keyname>Adami</keyname><forenames>Christoph</forenames></author><author><keyname>Qian</keyname><forenames>Jifeng</forenames></author><author><keyname>Rupp</keyname><forenames>Matthew</forenames></author><author><keyname>Hintze</keyname><forenames>Arend</forenames></author></authors><title>Information content of colored motifs in complex networks</title><categories>q-bio.QM cs.IT math.IT nlin.AO q-bio.MN q-bio.NC q-bio.PE</categories><comments>21 pages, 8 figures, to appear in Artificial Life</comments><journal-ref>Artificial Life 17 (2011) 375-390</journal-ref><doi>10.1162/artl_a_00045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study complex networks in which the nodes of the network are tagged with
different colors depending on the functionality of the nodes (colored graphs),
using information theory applied to the distribution of motifs in such
networks. We find that colored motifs can be viewed as the building blocks of
the networks (much more so than the uncolored structural motifs can be) and
that the relative frequency with which these motifs appear in the network can
be used to define the information content of the network. This information is
defined in such a way that a network with random coloration (but keeping the
relative number of nodes with different colors the same) has zero color
information content. Thus, colored motif information captures the
exceptionality of coloring in the motifs that is maintained via selection. We
study the motif information content of the C. elegans brain as well as the
evolution of colored motif information in networks that reflect the interaction
between instructions in genomes of digital life organisms. While we find that
colored motif information appears to capture essential functionality in the C.
elegans brain (where the color assignment of nodes is straightforward) it is
not obvious whether the colored motif information content always increases
during evolution, as would be expected from a measure that captures network
complexity. For a single choice of color assignment of instructions in the
digital life form Avida, we find rather that colored motif information content
increases or decreases during evolution, depending on how the genomes are
organized, and therefore could be an interesting tool to dissect genomic
rearrangements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0043</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0043</id><created>2011-03-31</created><authors><author><keyname>Liang</keyname><forenames>Guanfeng</forenames></author><author><keyname>Vaidya</keyname><forenames>Nitin</forenames></author></authors><title>Capacity of Byzantine Consensus with Capacity-Limited Point-to-Point
  Links</title><categories>cs.DC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximizing the throughput of Byzantine consensus,
when communication links have finite capacity. Byzantine consensus is a
classical problem in distributed computing. In existing literature, the
communication links are implicitly assumed to have infinite capacity. The
problem changes significantly when the capacity of links is finite. We define
the throughput and capacity of consensus, and identify upper bound of
achievable consensus throughput. We propose an algorithm that achieves
consensus capacity in complete four-node networks with at most 1 failure with
arbitrary distribution of link capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0052</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0052</id><created>2011-03-31</created><updated>2011-07-22</updated><authors><author><keyname>Bodine-Baron</keyname><forenames>Elizabeth</forenames></author><author><keyname>Lee</keyname><forenames>Christina</forenames></author><author><keyname>Chong</keyname><forenames>Anthony</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author><author><keyname>Wierman</keyname><forenames>Adam</forenames></author></authors><title>Peer Effects and Stability in Matching Markets</title><categories>cs.SI cs.GT physics.soc-ph</categories><comments>Working paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many-to-one matching markets exist in numerous different forms, such as
college admissions, matching medical interns to hospitals for residencies,
assigning housing to college students, and the classic firms and workers
market. In all these markets, externalities such as complementarities and peer
effects severely complicate the preference ordering of each agent. Further,
research has shown that externalities lead to serious problems for market
stability and for developing efficient algorithms to find stable matchings. In
this paper we make the observation that peer effects are often the result of
underlying social connections, and we explore a formulation of the many-to-one
matching market where peer effects are derived from an underlying social
network. The key feature of our model is that it captures peer effects and
complementarities using utility functions, rather than traditional preference
ordering. With this model and considering a weaker notion of stability, namely
two-sided exchange stability, we prove that stable matchings always exist and
characterize the set of stable matchings in terms of social welfare. We also
give distributed algorithms that are guaranteed to converge to a two-sided
exchange stable matching. To assess the competitive ratio of these algorithms
and to more generally characterize the efficiency of matching markets with
externalities, we provide general bounds on how far the welfare of the
worst-case stable matching can be from the welfare of the optimal matching, and
find that the structure of the social network (e.g. how well clustered the
network is) plays a large role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0057</identifier>
 <datestamp>2012-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0057</id><created>2011-03-31</created><updated>2011-04-13</updated><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author></authors><title>Distributed Denial of Service is a Scalability Problem</title><categories>cs.NI</categories><comments>6 pages, 1 figure</comments><acm-class>C.2.1; K.6.5</acm-class><journal-ref>ACM SIGCOMM Computer Communication Review, 42 (2012) 69-71</journal-ref><doi>10.1145/2096149.2096160</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed denial of service attacks are often considered a security
problem. While this may be the way to view the problem with today's Internet,
new network architectures attempting to address the issue should view it as a
scalability problem. In addition, they need to address the problem based on a
rigorous foundation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0085</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0085</id><created>2011-04-01</created><authors><author><keyname>Chen</keyname><forenames>Shuo-Tsung</forenames></author><author><keyname>Huang</keyname><forenames>Huang-Nan</forenames></author><author><keyname>Chen</keyname><forenames>Chur-Jen</forenames></author></authors><title>Adaptive Audio Watermarking via the Optimization Point of View on the
  Wavelet-Based Entropy</title><categories>cs.CR</categories><comments>31 pages, 5 figures, 14 tables, 16 references</comments><msc-class>90C47</msc-class><acm-class>K.4.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This study aims to present an adaptive audio watermarking method using ideas
of wavelet-based entropy (WBE). The method converts low-frequency coefficients
of discrete wavelet transform (DWT) into the WBE domain, followed by the
calculations of mean values of each audio as well as derivation of some
essential properties of WBE. A characteristic curve relating the WBE and DWT
coefficients is also presented. The foundation of the embedding process lies on
the approximately invariant property demonstrated from the mean of each audio
and the characteristic curve. Besides, the quality of the watermarked audio is
optimized. In the detecting process, the watermark can be extracted using only
values of the WBE. Finally, the performance of the proposed watermarking method
is analyzed in terms of signal to noise ratio, mean opinion score and
robustness. Experimental results confirm that the embedded data are robust to
resist the common attacks like re-sampling, MP3 compression, low-pass
filtering, and amplitude-scaling
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0087</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0087</id><created>2011-04-01</created><authors><author><keyname>Chen</keyname><forenames>S. -T.</forenames></author><author><keyname>Huang</keyname><forenames>H. -N.</forenames></author><author><keyname>Tu</keyname><forenames>S. -Y.</forenames></author></authors><title>Quantization Audio Watermarking with Optimal Scaling on Wavelet
  Coefficients</title><categories>cs.CR math.OC</categories><comments>30 pages, 8 figures, 14 tables, 22 references</comments><msc-class>49K35, 90.C47</msc-class><acm-class>K.4.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent years, discrete wavelet transform (DWT) provides an useful platform
for digital information hiding and copyright protection. Many DWT-based
algorithms for this aim are proposed. The performance of these algorithms is in
term of signal-to-noise ratio (SNR) and bit-error-rate (BER) which are used to
measure the quality and the robustness of an embedded audio. However, there is
a tradeoff relationship between the embedded-audio quality and robustness. The
tradeoff relationship is a signal processing problem in the wavelet domain. To
solve this problem, this study presents an optimization-based scaling scheme
using optimal multi-coefficients quantization in the wavelet domain. Firstly,
the multi-coefficients quantization technique is rewritten as an equation with
arbitrary scaling on DWT coefficients and set SNR to be a performance index.
Then, a functional connecting the equation and the performance index is
derived. Secondly, Lagrange Principle is used to obtain the optimal solution.
Thirdly, the scaling factors of the DWT coefficients are also optimized.
Moreover, the invariant feature of these optimized scaling factors is used to
resist the amplitude scaling. Experimental results show that the embedded audio
has high SNR and strong robustness against many attacks
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0111</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0111</id><created>2011-04-01</created><authors><author><keyname>Gai</keyname><forenames>Yi</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author></authors><title>Decentralized Online Learning Algorithms for Opportunistic Spectrum
  Access</title><categories>cs.LG cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental problem of multiple secondary users contending for
opportunistic spectrum access over multiple channels in cognitive radio
networks has been formulated recently as a decentralized multi-armed bandit
(D-MAB) problem. In a D-MAB problem there are $M$ users and $N$ arms (channels)
that each offer i.i.d. stochastic rewards with unknown means so long as they
are accessed without collision. The goal is to design a decentralized online
learning policy that incurs minimal regret, defined as the difference between
the total expected rewards accumulated by a model-aware genie, and that
obtained by all users applying the policy. We make two contributions in this
paper. First, we consider the setting where the users have a prioritized
ranking, such that it is desired for the $K$-th-ranked user to learn to access
the arm offering the $K$-th highest mean reward. For this problem, we present
the first distributed policy that yields regret that is uniformly logarithmic
over time without requiring any prior assumption about the mean rewards.
Second, we consider the case when a fair access policy is required, i.e., it is
desired for all users to experience the same mean reward. For this problem, we
present a distributed policy that yields order-optimal regret scaling with
respect to the number of users and arms, better than previously proposed
policies in the literature. Both of our distributed policies make use of an
innovative modification of the well known UCB1 policy for the classic
multi-armed bandit problem that allows a single user to learn how to play the
arm that yields the $K$-th largest mean reward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0118</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0118</id><created>2011-04-01</created><authors><author><keyname>Alexandropoulos</keyname><forenames>George C.</forenames></author><author><keyname>Papadogiannis</keyname><forenames>Agisilaos</forenames></author><author><keyname>Sofotasios</keyname><forenames>Paschalis C.</forenames></author></authors><title>A Comparative Study of Relaying Schemes with Decode-and-Forward over
  Nakagami-m Fading Channels</title><categories>cs.IT cs.PF math.IT</categories><comments>Submitted to Journal of Computer Systems, Networks, and
  Communications</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Utilizing relaying techniques to improve performance of wireless systems is a
promising avenue. However, it is crucial to understand what type of relaying
schemes should be used for achieving different performance objectives under
realistic fading conditions. In this paper, we present a general framework for
modelling and evaluating the performance of relaying schemes based on the
decode-and-forward (DF) protocol over independent and not necessarily
identically distributed (INID) Nakagami-m fading channels. In particular, we
present closed-form expressions for the statistics of the instantaneous output
signal-to-noise ratio of four significant relaying schemes with DF; two based
on repetitive transmission and the other two based on relay selection (RS).
These expressions are then used to obtain closed-form expressions for the
outage probability and the average symbol error probability for several
modulations of all considered relaying schemes over INID Nakagami-m fading.
Importantly, it is shown that when the channel state information for RS is
perfect, RS-based transmission schemes always outperform repetitive ones.
Furthermore, when the direct link between the source and the destination nodes
is sufficiently strong, relaying may not result in any gains and in this case
it should be switched-off.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0121</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0121</id><created>2011-04-01</created><authors><author><keyname>Yazdani</keyname><forenames>A.</forenames></author><author><keyname>Jeffrey</keyname><forenames>P.</forenames></author></authors><title>Complex network analysis of water distribution systems</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI math-ph math.MP stat.AP</categories><comments>11 pages, 4 figures</comments><msc-class>05C82, 05C42, 05C40, 62P35, 68R10, 68M14, 68M15</msc-class><journal-ref>Chaos 21, 016111(2011)</journal-ref><doi>10.1063/1.3540339</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores a variety of strategies for understanding the formation,
structure, efficiency and vulnerability of water distribution networks. Water
supply systems are studied as spatially organized networks for which the
practical applications of abstract evaluation methods are critically evaluated.
Empirical data from benchmark networks are used to study the interplay between
network structure and operational efficiency, reliability and robustness.
Structural measurements are undertaken to quantify properties such as
redundancy and optimal-connectivity, herein proposed as constraints in network
design optimization problems. The role of the supply-demand structure towards
system efficiency is studied and an assessment of the vulnerability to failures
based on the disconnection of nodes from the source(s) is undertaken. The
absence of conventional degree-based hubs (observed through uncorrelated
non-heterogeneous sparse topologies) prompts an alternative approach to
studying structural vulnerability based on the identification of network
cut-sets and optimal connectivity invariants. A discussion on the scope,
limitations and possible future directions of this research is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0122</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0122</id><created>2011-04-01</created><authors><author><keyname>Christ</keyname><forenames>Tobias</forenames></author><author><keyname>Francke</keyname><forenames>Andrea</forenames></author><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author><author><keyname>Matou&#x161;ek</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Uno</keyname><forenames>Takeaki</forenames></author></authors><title>A Doubly Exponentially Crumbled Cake</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following cake cutting game: Alice chooses a set P of n
points in the square (cake) [0,1]^2, where (0,0) is in P; Bob cuts out n
axis-parallel rectangles with disjoint interiors, each of them having a point
of P as the lower left corner; Alice keeps the rest. It has been conjectured
that Bob can always secure at least half of the cake. This remains unsettled,
and it is not even known whether Bob can get any positive fraction independent
of n. We prove that if Alice can force Bob's share to tend to zero, then she
must use very many points; namely, to prevent Bob from gaining more than 1/r of
the cake, she needs at least 2^{2^{\Omega(r)}} points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0126</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0126</id><created>2011-04-01</created><authors><author><keyname>Abel</keyname><forenames>Fabian</forenames></author><author><keyname>Celik</keyname><forenames>Ilknur</forenames></author><author><keyname>Hauff</keyname><forenames>Claudia</forenames></author><author><keyname>Hollink</keyname><forenames>Laura</forenames></author><author><keyname>Houben</keyname><forenames>Geert-Jan</forenames></author></authors><title>U-Sem: Semantic Enrichment, User Modeling and Mining of Usage Data on
  the Social Web</title><categories>cs.IR cs.AI cs.HC</categories><comments>1st International Workshop on Usage Analysis and the Web of Data
  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),
  Hyderabad, India, March 28th, 2011</comments><report-no>WWW2011USEWOD/2011/abecelhauholhou</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing popularity of Social Web applications, more and more user
data is published on the Web everyday. Our research focuses on investigating
ways of mining data from such platforms that can be used for modeling users and
for semantically augmenting user profiles. This process can enhance adaptation
and personalization in various adaptive Web-based systems. In this paper, we
present the U-Sem people modeling service, a framework for the semantic
enrichment and mining of people's profiles from usage data on the Social Web.
We explain the architecture of our people modeling service and describe its
application in an adult e-learning context as an example. Versions: Mar 21,
10:10, Mar 25, 09:37
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0127</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0127</id><created>2011-04-01</created><updated>2011-04-27</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Tracol</keyname><forenames>Mathieu</forenames></author></authors><title>The Decidability Frontier for Probabilistic Automata on Infinite Words</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider probabilistic automata on infinite words with acceptance defined
by safety, reachability, B\&quot;uchi, coB\&quot;uchi, and limit-average conditions. We
consider quantitative and qualitative decision problems. We present extensions
and adaptations of proofs for probabilistic finite automata and present a
complete characterization of the decidability and undecidability frontier of
the quantitative and qualitative decision problems for probabilistic automata
on infinite words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0128</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0128</id><created>2011-04-01</created><authors><author><keyname>Hollink</keyname><forenames>Vera</forenames></author><author><keyname>de Vries</keyname><forenames>Arjen</forenames></author></authors><title>Towards an automated query modification assistant</title><categories>cs.IR cs.AI cs.HC</categories><comments>1st International Workshop on Usage Analysis and the Web of Data
  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),
  Hyderabad, India, March 28th, 2011</comments><report-no>WWW2011USEWOD/2011/holvri</report-no><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Users who need several queries before finding what they need can benefit from
an automatic search assistant that provides feedback on their query
modification strategies. We present a method to learn from a search log which
types of query modifications have and have not been effective in the past. The
method analyses query modifications along two dimensions: a traditional
term-based dimension and a semantic dimension, for which queries are enriches
with linked data entities. Applying the method to the search logs of two search
engines, we identify six opportunities for a query modification assistant to
improve search: modification strategies that are commonly used, but that often
do not lead to satisfactory results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0136</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0136</id><created>2011-04-01</created><authors><author><keyname>Buehler</keyname><forenames>J.</forenames></author><author><keyname>Wunder</keyname><forenames>G.</forenames></author></authors><title>On Interference Alignment and the Deterministic Capacity for Cellular
  Channels with Weak Symmetric Cross Links</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE International Symposium on Information Theory
  (ISIT) 2011, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the uplink of a cellular system using the linear
deterministic approximation model, where there are two users transmitting to a
receiver, mutually interfering with a third transmitter communicating with a
second receiver. We give an achievable coding scheme and prove its optimality,
i.e. characterize the capacity region. This scheme is a form of interference
alignment which exploits the channel gain difference of the two-user cell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0142</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0142</id><created>2011-04-01</created><authors><author><keyname>Kumar</keyname><forenames>Sumit</forenames><affiliation>International Institute of Information Technology, India</affiliation></author><author><keyname>Singhal</keyname><forenames>Deepti</forenames><affiliation>International Institute of Information Technology, India</affiliation></author><author><keyname>Garimella</keyname><forenames>Rama Murthy</forenames><affiliation>International Institute of Information Technology, India</affiliation></author></authors><title>Doubly Cognitive Architecture Based Cognitive Wireless Sensor Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays scarcity of spectrum availability is increasing highly. Adding
cognition to the existing Wireless Sensor Network (WSN) infrastructure will
help in this situation. As sensor nodes in WSN are limited with some constrains
like power, efforts are required to increase the lifetime and other performance
measures of the network. In this paper we propose the idea of Doubly Cognitive
WSN. The basic idea is to progressively allocate the sensing resources only to
the most promising areas of the spectrum. This work is based on Artificial
Neural Network as well as on Support Vector Machine (SVM) concept. As the load
of sensing resource is reduced significantly, this approach will save the
energy of the nodes, and also reduce the sensing time dramatically. The
proposed work can be enhanced by doing the pattern analysis thing after a
sufficiently long time again and again to review the strategy of sensing. Thus
Doubly Cognitive WSN will enable current WSN to overcome the spectrum scarcity
as well as save the energy of the sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0148</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0148</id><created>2011-04-01</created><authors><author><keyname>Britton</keyname><forenames>Tom</forenames></author><author><keyname>Lindholm</keyname><forenames>Mathias</forenames></author><author><keyname>Turova</keyname><forenames>Tatyana</forenames></author></authors><title>A dynamic network in a dynamic population: asymptotic properties</title><categories>math.PR cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive asymptotic properties for a stochastic dynamic network model in a
stochastic dynamic population. In the model, nodes give birth to new nodes
until they die, each node being equipped with a social index given at birth.
During the life of a node it creates edges to other nodes, nodes with high
social index at higher rate, and edges disappear randomly in time. For this
model we derive criterion for when a giant connected component exists after the
process has evolved for a long period of time, assuming the node population
grows to infinity. We also obtain an explicit expression for the degree
correlation $\rho$ (of neighbouring nodes) which shows that $\rho$ is always
positive irrespective of parameter values in one of the two treated submodels,
and may be either positive or negative in the other model, depending on the
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0151</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0151</id><created>2011-04-01</created><authors><author><keyname>Shi</keyname><forenames>Dong-Mei</forenames></author><author><keyname>Zhuang</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author></authors><title>Effect of depreciation of the public goods in spatial public goods games</title><categories>physics.soc-ph cs.GT</categories><doi>10.1088/1742-5468/2011/10/P10007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, depreciated effect of the public goods is considered in the
public goods games, which is realized by rescaling the multiplication factor r
of each group as r' = r(nc/G)^beta (beat&gt;= 0). It is assumed that each
individual enjoys the full profit of the public goods if all the players of
this group are cooperators, otherwise, the value of the public goods is reduced
to r'. It is found that compared with the original version (beta = 0),
emergence of cooperation is remarkably promoted for beta &gt; 0, and there exit
optimal values of beta inducing the best cooperation. Moreover, the optimal
plat of beta broadens as r increases. Furthermore, effect of noise on the
evolution of cooperation is studied, it is presented that variation of
cooperator density with the noise is dependent of the value of beta and r, and
cooperation dominates over most of the range of noise at an intermediate value
of beta = 1.0. We study the initial distribution of the multiplication factor
at beta = 1.0, and find that all the distributions can be described as Gauss
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0172</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0172</id><created>2011-04-01</created><authors><author><keyname>Jurrius</keyname><forenames>Relinde</forenames></author></authors><title>Weight enumeration of codes from finite spaces</title><categories>math.CO cs.IT math.IT</categories><comments>10 pages</comments><msc-class>05B25, 11T71</msc-class><doi>10.1007/s10623-011-9557-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the generalized and extended weight enumerator of the q-ary Simplex
code and the q-ary first order Reed-Muller code. For our calculations we use
that these codes correspond to a projective system containing all the points in
a finite projective or affine space. As a result from the geometric method we
use for the weight enumeration, we also completely determine the set of
supports of subcodes and words in an extension code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0183</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0183</id><created>2011-04-01</created><updated>2011-09-06</updated><authors><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author><author><keyname>Stepanov</keyname><forenames>Mikhail</forenames></author><author><keyname>Pan</keyname><forenames>Feng</forenames></author><author><keyname>Baldick</keyname><forenames>Ross</forenames></author></authors><title>Exact and Efficient Algorithm to Discover Extreme Stochastic Events in
  Wind Generation over Transmission Power Grids</title><categories>cs.SY math.OC physics.soc-ph</categories><comments>7 pages, 3 figures, invited session on Smart Grid Integration of
  Renewable Energy: Failure analysis, Microgrids, and Estimation at CDC/ECC
  2011</comments><report-no>LA-UR 11-01920</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript we continue the thread of [M. Chertkov, F. Pan, M.
Stepanov, Predicting Failures in Power Grids: The Case of Static Overloads,
IEEE Smart Grid 2011] and suggest a new algorithm discovering most probable
extreme stochastic events in static power grids associated with intermittent
generation of wind turbines. The algorithm becomes EXACT and EFFICIENT
(polynomial) in the case of the proportional (or other low parametric) control
of standard generation, and log-concave probability distribution of the
renewable generation, assumed known from the wind forecast. We illustrate the
algorithm's ability to discover problematic extreme events on the example of
the IEEE RTS-96 model of transmission with additions of 10%, 20% and 30% of
renewable generation. We observe that the probability of failure may grow but
it may also decrease with increase in renewable penetration, if the latter is
sufficiently diversified and distributed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0185</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0185</id><created>2011-04-01</created><updated>2011-05-20</updated><authors><author><keyname>Grohe</keyname><forenames>Martin</forenames></author><author><keyname>Thurley</keyname><forenames>Marc</forenames></author></authors><title>Counting Homomorphisms and Partition Functions</title><categories>cs.CC cs.DM</categories><comments>51 pages</comments><acm-class>A.1; F.2.1; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Homomorphisms between relational structures are not only fundamental
mathematical objects, but are also of great importance in an applied
computational context. Indeed, constraint satisfaction problems (CSPs), a wide
class of algorithmic problems that occur in many different areas of computer
science such as artificial intelligence or database theory, may be viewed as
asking for homomorphisms between two relational structures [FedVar98]. In a
logical setting, homomorphisms may be viewed as witnesses for positive
primitive formulas in a relational language. As we shall see, homomorphisms, or
more precisely the numbers of homomorphisms between two structures, are also
related to a fundamental computational problem of statistical physics.
  In this article, we are concerned with the complexity of counting
homomorphisms from a given structure A to a fixed structure B. Actually, we are
mainly interested in a generalization of this problem to weighted homomorphisms
(or partition functions). We almost exclusively focus on graphs. The first part
of the article is a short survey of what is known about the problem. In the
second part, we give a proof of a theorem due to Bulatov and the first author
of this paper [BulGro05], which classifies the complexity of partition
functions described by matrices with non-negative entries. The proof we give
here is essentially the same as the original one, with a few shortcuts due to
[Thu09], but it is phrased in a different, more graph theoretical language that
may make it more accessible to most readers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0186</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0186</id><created>2011-04-01</created><authors><author><keyname>Valori</keyname><forenames>Luca</forenames></author><author><keyname>Picciolo</keyname><forenames>Francesco</forenames></author><author><keyname>Allansdottir</keyname><forenames>Agnes</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author></authors><title>Reconciling long-term cultural diversity and short-term collective
  social behavior</title><categories>physics.soc-ph cs.SI physics.comp-ph</categories><journal-ref>PNAS vol. 109, no. 4, pp. 1068-1073 (2012)</journal-ref><doi>10.1073/pnas.1109514109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An outstanding open problem is whether collective social phenomena occurring
over short timescales can systematically reduce cultural heterogeneity in the
long run, and whether offline and online human interactions contribute
differently to the process. Theoretical models suggest that short-term
collective behavior and long-term cultural diversity are mutually excluding,
since they require very different levels of social influence. The latter
jointly depends on two factors: the topology of the underlying social network
and the overlap between individuals in multidimensional cultural space.
However, while the empirical properties of social networks are well understood,
little is known about the large-scale organization of real societies in
cultural space, so that random input specifications are necessarily used in
models. Here we use a large dataset to perform a high-dimensional analysis of
the scientific beliefs of thousands of Europeans. We find that inter-opinion
correlations determine a nontrivial ultrametric hierarchy of individuals in
cultural space, a result unaccessible to one-dimensional analyses and in
striking contrast with random assumptions. When empirical data are used as
inputs in models, we find that ultrametricity has strong and counterintuitive
effects, especially in the extreme case of long-range online-like interactions
bypassing social ties. On short time-scales, it strongly facilitates a
symmetry-breaking phase transition triggering coordinated social behavior. On
long time-scales, it severely suppresses cultural convergence by restricting it
within disjoint groups. We therefore find that, remarkably, the empirical
distribution of individuals in cultural space appears to optimize the
coexistence of short-term collective behavior and long-term cultural diversity,
which can be realized simultaneously for the same moderate level of mutual
influence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0193</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0193</id><created>2011-04-01</created><updated>2012-10-19</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames><affiliation>Universit&#xe0; di Bologna</affiliation></author><author><keyname>Gaboardi</keyname><forenames>Marco</forenames><affiliation>Universit&#xe0; di Bologna and University of Pennsylvania</affiliation></author></authors><title>Linear Dependent Types and Relative Completeness</title><categories>cs.LO cs.PL</categories><comments>44 pages, 1 figure</comments><proxy>LMCS</proxy><acm-class>F.3.2, F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 4 (October
  23, 2012) lmcs:974</journal-ref><doi>10.2168/LMCS-8(4:11)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A system of linear dependent types for the lambda calculus with full
higher-order recursion, called dlPCF, is introduced and proved sound and
relatively complete. Completeness holds in a strong sense: dlPCF is not only
able to precisely capture the functional behaviour of PCF programs (i.e. how
the output relates to the input) but also some of their intensional properties,
namely the complexity of evaluating them with Krivine's Machine. dlPCF is
designed around dependent types and linear logic and is parametrized on the
underlying language of index terms, which can be tuned so as to sacrifice
completeness for tractability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0195</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0195</id><created>2011-04-01</created><updated>2011-06-27</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Zorzi</keyname><forenames>Margherita</forenames></author></authors><title>Probabilistic Operational Semantics for the Lambda Calculus</title><categories>cs.LO cs.PL</categories><comments>35 pages</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic operational semantics for a nondeterministic extension of pure
lambda calculus is studied. In this semantics, a term evaluates to a (finite or
infinite) distribution of values. Small-step and big-step semantics are both
inductively and coinductively defined. Moreover, small-step and big-step
semantics are shown to produce identical outcomes, both in call-by- value and
in call-by-name. Plotkin's CPS translation is extended to accommodate the
choice operator and shown correct with respect to the operational semantics.
Finally, the expressive power of the obtained system is studied: the calculus
is shown to be sound and complete with respect to computable probability
distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0198</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0198</id><created>2011-04-01</created><authors><author><keyname>Lubachevsky</keyname><forenames>Boris D.</forenames></author></authors><title>Why The Results of Parallel and Serial Monte Carlo Simulations May
  Differ</title><categories>cs.DC</categories><comments>2 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel Monte Carlo simulations often expose faults in random number
generators
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0199</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0199</id><created>2011-04-01</created><authors><author><keyname>&#xd8;lgaard</keyname><forenames>Kristian B.</forenames></author><author><keyname>Wells</keyname><forenames>Garth N.</forenames></author></authors><title>Optimisations for quadrature representations of finite element tensors
  through automated code generation</title><categories>cs.MS</categories><journal-ref>ACM Trans. Math. Softw. 37, 1, Article 8 (January 2010), 23 pages</journal-ref><doi>10.1145/1644001.1644009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine aspects of the computation of finite element matrices and vectors
which are made possible by automated code generation. Given a variational form
in a syntax which resembles standard mathematical notation, the low-level
computer code for building finite element tensors, typically matrices, vectors
and scalars, can be generated automatically via a form compiler. In particular,
the generation of code for computing finite element matrices using a quadrature
approach is addressed. For quadrature representations, a number of optimisation
strategies which are made possible by automated code generation are presented.
The relative performance of two different automatically generated
representations of finite element matrices is examined, with a particular
emphasis on complicated variational forms. It is shown that approaches which
perform best for simple forms are not tractable for more complicated problems
in terms of run time performance, the time required to generate the code or the
size of the generated code. The approach and optimisations elaborated here are
effective for a range of variational forms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0215</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0215</id><created>2011-04-01</created><updated>2013-10-09</updated><authors><author><keyname>Michel</keyname><forenames>Lo&#xef;c</forenames></author><author><keyname>Michiels</keyname><forenames>Wim</forenames></author><author><keyname>Boucher</keyname><forenames>Xavier</forenames></author></authors><title>Model-free control of microgrids</title><categories>cs.SY math.OC</categories><comments>5 pages, 11 figures - Accepted to IEEE CCECE 2013</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A new &quot;model-free&quot; control methodology is applied for the first time to power
systems included in microgrids networks. We evaluate its performances regarding
output load and supply variations in different working configuration of the
microgrid. Our approach, which utilizes &quot;intelligent&quot; PI controllers, does not
require any converter or microgrid model identification while ensuring the
stability and the robustness of the controlled system. Simulations results show
that with a simple control structure, the proposed control method is almost
insensitive to fluctuations and large load variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0219</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0219</id><created>2011-04-01</created><authors><author><keyname>Kontchakov</keyname><forenames>Roman</forenames><affiliation>Birkbeck College London</affiliation></author><author><keyname>Nenov</keyname><forenames>Yavor</forenames><affiliation>School of Computer Science, University of Manchester</affiliation></author><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames><affiliation>School of Computer Science, University of Manchester</affiliation></author><author><keyname>Zakharyaschev</keyname><forenames>Michael</forenames><affiliation>Birkbeck College London</affiliation></author></authors><title>On the Decidability of Connectedness Constraints in 2D and 3D Euclidean
  Spaces</title><categories>cs.LO</categories><comments>Accepted for publication in the IJCAI 2011 proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate (quantifier-free) spatial constraint languages with equality,
contact and connectedness predicates as well as Boolean operations on regions,
interpreted over low-dimensional Euclidean spaces. We show that the complexity
of reasoning varies dramatically depending on the dimension of the space and on
the type of regions considered. For example, the logic with the
interior-connectedness predicate (and without contact) is undecidable over
polygons or regular closed sets in the Euclidean plane, NP-complete over
regular closed sets in three-dimensional Euclidean space, and ExpTime-complete
over polyhedra in three-dimensional Euclidean space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0224</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0224</id><created>2011-04-01</created><authors><author><keyname>Eftekhari</keyname><forenames>Yaser</forenames></author><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author><author><keyname>Lambadaris</keyname><forenames>Ioannis</forenames></author></authors><title>Density Evolution Analysis of Node-Based Verification-Based Algorithms
  in Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>70 Pages, Submitted to Trans. IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new approach for the analysis of iterative
node-based verification-based (NB-VB) recovery algorithms in the context of
compressive sensing. These algorithms are particularly interesting due to their
low complexity (linear in the signal dimension $n$). The asymptotic analysis
predicts the fraction of unverified signal elements at each iteration $\ell$ in
the asymptotic regime where $n \rightarrow \infty$. The analysis is similar in
nature to the well-known density evolution technique commonly used to analyze
iterative decoding algorithms. To perform the analysis, a message-passing
interpretation of NB-VB algorithms is provided. This interpretation lacks the
extrinsic nature of standard message-passing algorithms to which density
evolution is usually applied. This requires a number of non-trivial
modifications in the analysis. The analysis tracks the average performance of
the recovery algorithms over the ensembles of input signals and sensing
matrices as a function of $\ell$. Concentration results are devised to
demonstrate that the performance of the recovery algorithms applied to any
choice of the input signal over any realization of the sensing matrix follows
the deterministic results of the analysis closely. Simulation results are also
provided which demonstrate that the proposed asymptotic analysis matches the
performance of recovery algorithms for large but finite values of $n$. Compared
to the existing technique for the analysis of NB-VB algorithms, which is based
on numerically solving a large system of coupled differential equations, the
proposed method is much simpler and more accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0230</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0230</id><created>2011-04-01</created><updated>2011-05-09</updated><authors><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Tuncel</keyname><forenames>Ertem</forenames></author></authors><title>Separate Source-Channel Coding for Broadcasting Correlated Gaussians</title><categories>cs.IT math.IT</categories><comments>6 pages (with an extra proof), ISIT2011, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of broadcasting a pair of correlated Gaussian sources using
optimal separate source and channel codes is studied. Considerable performance
gains over previously known separate source-channel schemes are observed.
Although source-channel separation yields suboptimal performance in general, it
is shown that the proposed scheme is very competitive for any bandwidth
compression/expansion scenarios. In particular, for a high channel SNR
scenario, it can be shown to achieve optimal power-distortion tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0235</identifier>
 <datestamp>2011-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0235</id><created>2011-04-01</created><authors><author><keyname>Ginodi</keyname><forenames>Ido</forenames></author><author><keyname>Globerson</keyname><forenames>Amir</forenames></author></authors><title>Gaussian Robust Classification</title><categories>cs.LG</categories><comments>Master's dissertation of the first author, carried out under the
  supervision of the second author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised learning is all about the ability to generalize knowledge.
Specifically, the goal of the learning is to train a classifier using training
data, in such a way that it will be capable of classifying new unseen data
correctly. In order to acheive this goal, it is important to carefully design
the learner, so it will not overfit the training data. The later can is done
usually by adding a regularization term. The statistical learning theory
explains the success of this method by claiming that it restricts the
complexity of the learned model. This explanation, however, is rather abstract
and does not have a geometric intuition. The generalization error of a
classifier may be thought of as correlated with its robustness to perturbations
of the data: a classifier that copes with disturbance is expected to generalize
well. Indeed, Xu et al. [2009] have shown that the SVM formulation is
equivalent to a robust optimization (RO) formulation, in which an adversary
displaces the training and testing points within a ball of pre-determined
radius. In this work we explore a different kind of robustness, namely changing
each data point with a Gaussian cloud centered at the sample. Loss is evaluated
as the expectation of an underlying loss function on the cloud. This setup fits
the fact that in many applications, the data is sampled along with noise. We
develop an RO framework, in which the adversary chooses the covariance of the
noise. In our algorithm named GURU, the tuning parameter is a spectral bound on
the noise, thus it can be estimated using physical or applicative
considerations. Our experiments show that this framework performs as well as
SVM and even slightly better in some cases. Generalizations for Mercer kernels
and for the multiclass case are presented as well. We also show that our
framework may be further generalized, using the technique of convex perspective
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0261</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0261</id><created>2011-04-01</created><updated>2011-04-05</updated><authors><author><keyname>Brune</keyname><forenames>Peter R.</forenames></author><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author><author><keyname>Scott</keyname><forenames>L. Ridgway</forenames></author></authors><title>Unstructured Geometric Multigrid in Two and Three Dimensions on Complex
  and Graded Meshes</title><categories>cs.NA cs.CG math.NA</categories><comments>17 pages, 5 figures, 4 tables</comments><msc-class>65N30, 65M50, 65M55</msc-class><journal-ref>SIAM Journal on Scientific Computing, 35(1), A173-A191, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of multigrid and related preconditioners with the finite element
method is often limited by the difficulty of applying the algorithm effectively
to a problem, especially when the domain has a complex shape or adaptive
refinement. We introduce a simplification of a general topologically-motivated
mesh coarsening algorithm for use in creating hierarchies of meshes for
geometric unstructured multigrid methods. The connections between the
guarantees of this technique and the quality criteria necessary for multigrid
methods for non-quasi-uniform problems are noted. The implementation details,
in particular those related to coarsening, remeshing, and interpolation, are
discussed. Computational tests on pathological test cases from adaptive finite
element methods show the performance of the technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0262</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0262</id><created>2011-04-01</created><authors><author><keyname>Osher</keyname><forenames>Stanley</forenames></author><author><keyname>Mao</keyname><forenames>Yu</forenames></author><author><keyname>Dong</keyname><forenames>Bin</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>Fast Linearized Bregman Iteration for Compressive Sensing and Sparse
  Denoising</title><categories>math.OC cs.IT math.IT</categories><msc-class>65K10, 93B40</msc-class><journal-ref>Communications in Mathematical Sciences, 8(1), pp. 93-111, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and analyze an extremely fast, efficient, and simple method for
solving the problem:min{parallel to u parallel to(1) : Au = f, u is an element
of R-n}.This method was first described in [J. Darbon and S. Osher, preprint,
2007], with more details in [W. Yin, S. Osher, D. Goldfarb and J. Darbon, SIAM
J. Imaging Sciences, 1(1), 143-168, 2008] and rigorous theory given in [J. Cai,
S. Osher and Z. Shen, Math. Comp., to appear, 2008, see also UCLA CAM Report
08-06] and [J. Cai, S. Osher and Z. Shen, UCLA CAM Report, 08-52, 2008]. The
motivation was compressive sensing, which now has a vast and exciting history,
which seems to have started with Candes, et. al. [E. Candes, J. Romberg and T.
Tao, 52(2), 489-509, 2006] and Donoho, [D. L. Donoho, IEEE Trans. Inform.
Theory, 52, 1289-1306, 2006]. See [W. Yin, S. Osher, D. Goldfarb and J. Darbon,
SIAM J. Imaging Sciences 1(1), 143-168, 2008] and [J. Cai, S. Osher and Z.
Shen, Math. Comp., to appear, 2008, see also UCLA CAM Report, 08-06] and [J.
Cai, S. Osher and Z. Shen, UCLA CAM Report, 08-52, 2008] for a large set of
references. Our method introduces an improvement called &quot;kicking&quot; of the very
efficient method of [J. Darbon and S. Osher, preprint, 2007] and [W. Yin, S.
Osher, D. Goldfarb and J. Darbon, SIAM J. Imaging Sciences, 1(1), 143-168,
2008] and also applies it to the problem of denoising of undersampled signals.
The use of Bregman iteration for denoising of images began in [S. Osher, M.
Burger, D. Goldfarb, J. Xu and W. Yin, Multiscale Model. Simul, 4(2), 460-489,
2005] and led to improved results for total variation based methods. Here we
apply it to denoise signals, especially essentially sparse signals, which might
even be undersampled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0283</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0283</id><created>2011-04-01</created><authors><author><keyname>Stimpson</keyname><forenames>Mike</forenames></author></authors><title>Evolving a New Feature for a Working Program</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A genetic programming system is created. A first fitness function f1 is used
to evolve a program that implements a first feature. Then the fitness function
is switched to a second function f2, which is used to evolve a program that
implements a second feature while still maintaining the first feature. The
median number of generations G1 and G2 needed to evolve programs that work as
defined by f1 and f2 are measured. The behavior of G1 and G2 are observed as
the difficulty of the problem is increased.
  In these systems, the density D1 of programs that work (for fitness function
f1) is measured in the general population of programs. The relationship
G1~1/sqrt(D1) is observed to approximately hold. Also, the density D2 of
programs that work (for fitness function f2) is measured in the general
population of programs. The relationship G2~1/sqrt(D2) is observed to
approximately hold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0291</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0291</id><created>2011-04-02</created><updated>2012-04-14</updated><authors><author><keyname>Haddad</keyname><forenames>Serge</forenames><affiliation>LSV</affiliation></author><author><keyname>Mairesse</keyname><forenames>Jean</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Nguyen</keyname><forenames>Hoang-Thach</forenames><affiliation>LIAFA</affiliation></author></authors><title>Synthesis and Analysis of Product-form Petri Nets</title><categories>cs.DM</categories><comments>This is a version including proofs of the conference paper: Haddad,
  Mairesse and Nguyen. Synthesis and Analysis of Product-form Petri Nets.
  Accepted at the conference Petri Nets 2011</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a large Markovian model, a &quot;product form&quot; is an explicit description of
the steady-state behaviour which is otherwise generally untractable. Being
first introduced in queueing networks, it has been adapted to Markovian Petri
nets. Here we address three relevant issues for product-form Petri nets which
were left fully or partially open: (1) we provide a sound and complete set of
rules for the synthesis; (2) we characterise the exact complexity of classical
problems like reachability; (3) we introduce a new subclass for which the
normalising constant (a crucial value for product-form expression) can be
efficiently computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0298</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0298</id><created>2011-04-02</created><authors><author><keyname>Khatir</keyname><forenames>Ashkan</forenames></author><author><keyname>Abdolahzadegan</keyname><forenames>Shaghayegh</forenames></author><author><keyname>Mahmoudi</keyname><forenames>Iman</forenames></author></authors><title>High Speed Multiple Valued Logic Full Adder Using Carbon Nano Tube Field
  Effect Transistor</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High speed Full-Adder (FA) module is a critical element in designing high
performance arithmetic circuits. In this paper, we propose a new high speed
multiple-valued logic FA module. The proposed FA is constructed by 14
transistors and 3 capacitors, using carbon nano-tube field effect transistor
(CNFET) technology. Furthermore, our proposed technique has been examined in
different voltages (i.e., 0.65v and 0.9v). The observed results reveal power
consumption and power delay product (PDP) improvements compared to existing FA
counterparts
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0319</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0319</id><created>2011-04-02</created><authors><author><keyname>Pfeiffer</keyname><forenames>Joseph J.</forenames><suffix>III</suffix></author><author><keyname>Neville</keyname><forenames>Jennifer</forenames></author></authors><title>Methods to Determine Node Centrality and Clustering in Graphs with
  Uncertain Structure</title><categories>cs.SI physics.soc-ph</categories><comments>Longer version of paper appearing in Fifth International AAAI
  Conference on Weblogs and Social Media. 9 pages, 4 Figures</comments><msc-class>91D30</msc-class><acm-class>H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of the past work in network analysis has focused on analyzing discrete
graphs, where binary edges represent the &quot;presence&quot; or &quot;absence&quot; of a
relationship. Since traditional network measures (e.g., betweenness centrality)
utilize a discrete link structure, complex systems must be transformed to this
representation in order to investigate network properties. However, in many
domains there may be uncertainty about the relationship structure and any
uncertainty information would be lost in translation to a discrete
representation. Uncertainty may arise in domains where there is moderating link
information that cannot be easily observed, i.e., links become inactive over
time but may not be dropped or observed links may not always corresponds to a
valid relationship. In order to represent and reason with these types of
uncertainty, we move beyond the discrete graph framework and develop social
network measures based on a probabilistic graph representation. More
specifically, we develop measures of path length, betweenness centrality, and
clustering coefficient---one set based on sampling and one based on
probabilistic paths. We evaluate our methods on three real-world networks from
Enron, Facebook, and DBLP, showing that our proposed methods more accurately
capture salient effects without being susceptible to local noise, and that the
resulting analysis produces a better understanding of the graph structure and
the uncertainty resulting from its change over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0323</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0323</id><created>2011-04-02</created><authors><author><keyname>Miller</keyname><forenames>Jeffrey W.</forenames></author><author><keyname>Harrison</keyname><forenames>Matthew T.</forenames></author></authors><title>Exact Enumeration and Sampling of Matrices with Specified Margins</title><categories>stat.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a dynamic programming algorithm for exact counting and exact
uniform sampling of matrices with specified row and column sums. The algorithm
runs in polynomial time when the column sums are bounded. Binary or
non-negative integer matrices are handled. The method is distinguished by
applicability to non-regular margins, tractability on large matrices, and the
capacity for exact sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0327</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0327</id><created>2011-04-02</created><updated>2013-06-27</updated><authors><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Asymptotically Tight Steady-State Queue Length Bounds Implied By Drift
  Conditions</title><categories>math.PR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Foster-Lyapunov theorem and its variants serve as the primary tools for
studying the stability of queueing systems. In addition, it is well known that
setting the drift of the Lyapunov function equal to zero in steady-state
provides bounds on the expected queue lengths. However, such bounds are often
very loose due to the fact that they fail to capture resource pooling effects.
The main contribution of this paper is to show that the approach of &quot;setting
the drift of a Lyapunov function equal to zero&quot; can be used to obtain bounds on
the steady-state queue lengths which are tight in the heavy-traffic limit. The
key is to establish an appropriate notion of state-space collapse in terms of
steady-state moments of weighted queue length differences, and use this
state-space collapse result when setting the Lyapunov drift equal to zero. As
an application of the methodology, we prove the steady-state equivalent of the
heavy-traffic optimality result of Stolyar for wireless networks operating
under the MaxWeight scheduling policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0354</identifier>
 <datestamp>2013-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0354</id><created>2011-04-03</created><updated>2011-08-25</updated><authors><author><keyname>Chen</keyname><forenames>Yudong</forenames></author><author><keyname>Jalali</keyname><forenames>Ali</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author></authors><title>Low-rank Matrix Recovery from Errors and Erasures</title><categories>cs.IT math.IT stat.ML</categories><comments>27 pages, 3 figures. Appeared in ISIT 2011</comments><journal-ref>IEEE Transactions on Information Theory, vol. 59, no. 7,
  4324-4337, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the recovery of a low-rank matrix from an observed
version that simultaneously contains both (a) erasures: most entries are not
observed, and (b) errors: values at a constant fraction of (unknown) locations
are arbitrarily corrupted. We provide a new unified performance guarantee on
when the natural convex relaxation of minimizing rank plus support succeeds in
exact recovery. Our result allows for the simultaneous presence of random and
deterministic components in both the error and erasure patterns. On the one
hand, corollaries obtained by specializing this one single result in different
ways recover (up to poly-log factors) all the existing works in matrix
completion, and sparse and low-rank matrix recovery. On the other hand, our
results also provide the first guarantees for (a) recovery when we observe a
vanishing fraction of entries of a corrupted matrix, and (b) deterministic
matrix completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0355</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0355</id><created>2011-04-03</created><authors><author><keyname>Heidari</keyname><forenames>Ehsan</forenames></author><author><keyname>Movaghar</keyname><forenames>Ali</forenames></author></authors><title>An Efficient Method Based on Genetic Algorithms to Solve Sensor Network
  Optimization Problem</title><categories>cs.NI</categories><comments>16 pages, 18 figures, Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimization of the number of cluster heads in a wireless sensor network is a
very important problem to reduce channel contention and to improve the
efficiency of the algorithm when executed at the level of cluster-heads. In
this paper, we propose an efficient method based on genetic algorithms (GAs) to
solve a sensor network optimization problem. Long communication distances
between sensors and a sink in a sensor network can greatly drain the energy of
sensors and reduce the lifetime of a network. By clustering a sensor network
into a number of independent clusters using a GA, we can greatly minimize the
total communication distance, thus prolonging the network lifetime. Simulation
results show that our algorithm can quickly find a good solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0360</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0360</id><created>2011-04-03</created><updated>2011-12-15</updated><authors><author><keyname>Furuichi</keyname><forenames>S.</forenames></author><author><keyname>Minculete</keyname><forenames>N.</forenames></author><author><keyname>Mitroi</keyname><forenames>F. -C.</forenames></author></authors><title>Some inequalities on generalized entropies</title><categories>math.CA cond-mat.stat-mech cs.IT math.IT</categories><comments>15 pages</comments><journal-ref>J. Inequal. Appl., 2012, 2012:226</journal-ref><doi>10.1186/1029-242X-2012-226</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give several inequalities on generalized entropies involving Tsallis
entropies, using some inequalities obtained by improvements of Young's
inequality. We also give a generalized Han's inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0379</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0379</id><created>2011-04-03</created><updated>2011-05-06</updated><authors><author><keyname>Rothenberg</keyname><forenames>Robert</forenames></author></authors><title>Proof-Theoretic Soundness and Completeness</title><categories>cs.LO math.LO</categories><comments>3 page extended abstract, 1 figure, extended version of abstact for
  ARW 2011</comments><msc-class>03</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a calculus for reasoning about the first-order fragment of classical
logic that is adequate for giving the truth conditions of intuitionistic Kripke
frames, and outline a proof-theoretic soundness and completeness proof, which
we believe is conducive to automation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0384</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0384</id><created>2011-04-03</created><authors><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Relations between redundancy patterns of the Shannon code and wave
  diffraction patterns of partially disordered media</title><categories>cs.IT cond-mat.other cond-mat.stat-mech math.IT</categories><comments>10 pages; Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The average redundancy of the Shannon code, $R_n$, as a function of the block
length $n$, is known to exhibit two very different types of behavior, depending
on the rationality or irrationality of certain parameters of the source: It
either converges to 1/2 as $n$ grows without bound, or it may have a
non-vanishing, oscillatory, (quasi-) periodic pattern around the value 1/2 for
all large $n$. In this paper, we make an attempt to shed some insight into this
erratic behavior of $R_n$, by drawing an analogy with the realm of physics of
wave propagation, in particular, the elementary theory of scattering and
diffraction. It turns out that there are two types of behavior of wave
diffraction patterns formed by crystals, which are correspondingly analogous to
the two types of patterns of $R_n$. When the crystal is perfect, the
diffraction intensity spectrum exhibits very sharp peaks, a.k.a. Bragg peaks,
at wavelengths of full constructive interference. These wavelengths correspond
to the frequencies of the harmonic waves of the oscillatory mode of $R_n$. On
the other hand, when the crystal is imperfect and there is a considerable
degree of disorder in its structure, the Bragg peaks disappear, and the
behavior of this mode is analogous to the one where $R_n$ is convergent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0388</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0388</id><created>2011-04-03</created><authors><author><keyname>Gusev</keyname><forenames>Vladimir V.</forenames></author><author><keyname>Pribavkina</keyname><forenames>Elena V.</forenames></author></authors><title>On Non-Complete Sets and Restivo's Conjecture</title><categories>cs.FL</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A finite set S of words over the alphabet A is called non-complete if
Fact(S*) is different from A*. A word w in A* - Fact(S*) is said to be
uncompletable. We present a series of non-complete sets S_k whose minimal
uncompletable words have length 5k^2 - 17k + 13, where k &gt; 3 is the maximal
length of words in S_k. This is an infinite series of counterexamples to
Restivo's conjecture, which states that any non-complete set possesses an
uncompletable word of length at most 2k^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0395</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0395</id><created>2011-04-03</created><updated>2011-10-02</updated><authors><author><keyname>Zhu</keyname><forenames>Yu-Xiao</forenames></author><author><keyname>L&#xfc;</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Qian-Ming</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Uncovering missing links with cold ends</title><categories>physics.data-an cs.IR cs.SI physics.soc-ph</categories><comments>16 pages, 5 figures, 6 tables</comments><journal-ref>Physica A 391 (2012) 5769-5778</journal-ref><doi>10.1016/j.physa.2012.06.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To evaluate the performance of prediction of missing links, the known data
are randomly divided into two parts, the training set and the probe set. We
argue that this straightforward and standard method may lead to terrible bias,
since in real biological and information networks, missing links are more
likely to be links connecting low-degree nodes. We therefore study how to
uncover missing links with low-degree nodes, namely links in the probe set are
of lower degree products than a random sampling. Experimental analysis on ten
local similarity indices and four disparate real networks reveals a surprising
result that the Leicht-Holme-Newman index [E. A. Leicht, P. Holme, and M. E. J.
Newman, Phys. Rev. E 73, 026120 (2006)] performs the best, although it was
known to be one of the worst indices if the probe set is a random sampling of
all links. We further propose an parameter-dependent index, which considerably
improves the prediction accuracy. Finally, we show the relevance of the
proposed index on three real sampling methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0405</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0405</id><created>2011-04-03</created><updated>2012-11-11</updated><authors><author><keyname>Nguyen</keyname><forenames>Linh Anh</forenames></author></authors><title>A Cut-Free ExpTime Tableau Decision Procedure for the Logic Extending
  Converse-PDL with Regular Inclusion Axioms</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first cut-free ExpTime (optimal) tableau decision procedure for
the logic CPDLreg, which extends Converse-PDL with regular inclusion axioms
characterized by finite automata. The logic CPDLreg is the combination of
Converse-PDL and regular grammar logic with converse. Our tableau decision
procedure uses global state caching and has been designed to increase
efficiency and allow various optimization techniques, including on-the-fly
propagation of local and global (in)consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0419</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0419</id><created>2011-04-03</created><updated>2011-04-13</updated><authors><author><keyname>Yoon</keyname><forenames>Daejung</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>Soft-Decision-Driven Channel Estimation for Pipelined Turbo Receivers</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>11 pages; IEEE Transactions on Communications 2011</comments><report-no>TCOM-10_0238, 2011</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider channel estimation specific to turbo equalization for
multiple-input multiple-output (MIMO) wireless communication. We develop a
soft-decision-driven sequential algorithm geared to the pipelined turbo
equalizer architecture operating on orthogonal frequency division multiplexing
(OFDM) symbols. One interesting feature of the pipelined turbo equalizer is
that multiple soft-decisions become available at various processing stages. A
tricky issue is that these multiple decisions from different pipeline stages
have varying levels of reliability. This paper establishes an effective
strategy for the channel estimator to track the target channel, while dealing
with observation sets with different qualities. The resulting algorithm is
basically a linear sequential estimation algorithm and, as such, is
Kalman-based in nature. The main difference here, however, is that the proposed
algorithm employs puncturing on observation samples to effectively deal with
the inherent correlation among the multiple demapper/decoder module outputs
that cannot easily be removed by the traditional innovations approach. The
proposed algorithm continuously monitors the quality of the feedback decisions
and incorporates it in the channel estimation process. The proposed channel
estimation scheme shows clear performance advantages relative to existing
channel estimation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0422</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0422</id><created>2011-04-03</created><authors><author><keyname>Jankowski</keyname><forenames>Bartosz</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>PadSteg: Introducing Inter-Protocol Steganography</title><categories>cs.CR</categories><comments>9 pages, 12 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hiding information in network traffic may lead to leakage of confidential
information. In this paper we introduce a new steganographic system: the
PadSteg (Padding Steganography). To authors' best knowledge it is the first
information hiding solution which represents inter-protocol steganography i.e.
usage of relation between two or more protocols from the TCP/IP stack to enable
secret communication. PadSteg utilizes ARP and TCP protocols together with an
Etherleak vulnerability (improper Ethernet frame padding) to facilitate secret
communication for hidden groups in LANs (Local Area Networks). Basing on real
network traces we confirm that PadSteg is feasible in today's networks and we
estimate what steganographic bandwidth is achievable while limiting the chance
of disclosure. We also point at possible countermeasures against PadSteg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0430</identifier>
 <datestamp>2012-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0430</id><created>2011-04-03</created><updated>2012-11-15</updated><authors><author><keyname>Razaghi</keyname><forenames>Peyman</forenames></author><author><keyname>Zhou</keyname><forenames>Song Nam Hong. Lei</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Two Birds and One Stone: Gaussian Interference Channel with a Shared
  Out-of-Band Relay of Limited Rate</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The two-user Gaussian interference channel with a shared out-of-band relay is
considered. The relay observes a linear combination of the source signals and
broadcasts a common message to the two destinations, through a perfect link of
fixed limited rate $R_0$ bits per channel use. The out-of-band nature of the
relay is reflected by the fact that the common relay message does not interfere
with the received signal at the two destinations. A general achievable rate is
established, along with upper bounds on the capacity region for the Gaussian
case. For $R_0$ values below a certain threshold, which depends on channel
parameters, the capacity region of this channel is determined in this paper to
within a constant gap of $\Delta=1.95$ bits. We identify interference regimes
where a two-for-one gain in achievable rates is possible for every bit relayed,
up to a constant approximation error. Instrumental to these results is a
carefully-designed quantize-and-forward type of relay strategy along with a
joint decoding scheme employed at destination ends. Further, we also study
successive decoding strategies with optimal decoding order (corresponding to
the order at which common, private, and relay messages are decoded), and show
that successive decoding also achieves two-for-one gains asymptotically in
regimes where a two-for-one gain is achievable by joint decoding; yet,
successive decoding produces unbounded loss asymptotically when compared to
joint decoding, in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0446</identifier>
 <datestamp>2012-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0446</id><created>2011-04-03</created><updated>2012-03-12</updated><authors><author><keyname>Mao</keyname><forenames>Yu</forenames></author></authors><title>Reconstruction of Binary Functions and Shapes from Incomplete Frequency
  Information</title><categories>cs.IT math.IT math.OC</categories><comments>IEEE Transactions on Information Theory, 2012</comments><msc-class>49M20, 65K10, 90C26, 93B40</msc-class><journal-ref>IEEE Transactions on Information Theory, vol. 58, no. 6, 2012</journal-ref><doi>10.1109/TIT.2012.2190041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The characterization of a binary function by partial frequency information is
considered. We show that it is possible to reconstruct binary signals from
incomplete frequency measurements via the solution of a simple linear
optimization problem. We further prove that if a binary function is spatially
structured (e.g. a general black-white image or an indicator function of a
shape), then it can be recovered from very few low frequency measurements in
general. These results would lead to efficient methods of sensing,
characterizing and recovering a binary signal or a shape as well as other
applications like deconvolution of binary functions blurred by a low-pass
filter. Numerical results are provided to demonstrate the theoretical
arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0454</identifier>
 <datestamp>2012-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0454</id><created>2011-04-03</created><updated>2012-11-07</updated><authors><author><keyname>Olshevsky</keyname><forenames>Alex</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John</forenames></author></authors><title>Degree Fluctuations and the Convergence Time of Consensus Algorithms</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a consensus algorithm in which every node in a sequence of
undirected, B-connected graphs assigns equal weight to each of its neighbors.
Under the assumption that the degree of each node is fixed (except for times
when the node has no connections to other nodes), we show that consensus is
achieved within a given accuracy $\epsilon$ on n nodes in time $B+4n^3 B
\ln(2n/\epsilon)$. Because there is a direct relation between consensus
algorithms in time-varying environments and inhomogeneous random walks, our
result also translates into a general statement on such random walks. Moreover,
we give a simple proof of a result of Cao, Spielman, and Morse that the worst
case convergence time becomes exponentially large in the number of nodes $n$
under slight relaxation of the degree constancy assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0457</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0457</id><created>2011-04-03</created><updated>2012-11-07</updated><authors><author><keyname>Leonard</keyname><forenames>Naomi Ehrich</forenames></author><author><keyname>Olshevsky</keyname><forenames>Alex</forenames></author></authors><title>Nonuniform Coverage Control on the Line</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates control laws allowing mobile, autonomous agents to
optimally position themselves on the line for distributed sensing in a
nonuniform field. We show that a simple static control law, based only on local
measurements of the field by each agent, drives the agents close to the optimal
positions after the agents execute in parallel a number of
sensing/movement/computation rounds that is essentially quadratic in the number
of agents. Further, we exhibit a dynamic control law which, under slightly
stronger assumptions on the capabilities and knowledge of each agent, drives
the agents close to the optimal positions after the agents execute in parallel
a number of sensing/communication/computation/movement rounds that is
essentially linear in the number of agents. Crucially, both algorithms are
fully distributed and robust to unpredictable loss and addition of agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0458</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0458</id><created>2011-04-03</created><updated>2013-03-29</updated><authors><author><keyname>Cho</keyname><forenames>Jeong-woo</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author></authors><title>On the Payoff Mechanisms in Peer-Assisted Services with Multiple Content
  Providers: Rationality and Fairness</title><categories>cs.NI cs.GT</categories><comments>14 pages, 11 figures, 1 table. Accepted for publication in IEEE/ACM
  Transactions on Networking, March 2013. arXiv admin note: substantial text
  overlap with arXiv:1012.2332</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies an incentive structure for cooperation and its stability
in peer-assisted services when there exist multiple content providers, using a
coalition game theoretic approach. We first consider a generalized coalition
structure consisting of multiple providers with many assisting peers, where
peers assist providers to reduce the operational cost in content distribution.
To distribute the profit from cost reduction to players (i.e., providers and
peers), we then establish a generalized formula for individual payoffs when a
&quot;Shapley-like&quot; payoff mechanism is adopted. We show that the grand coalition is
unstable, even when the operational cost functions are concave, which is in
sharp contrast to the recently studied case of a single provider where the
grand coalition is stable. We also show that irrespective of stability of the
grand coalition, there always exist coalition structures which are not
convergent to the grand coalition under a dynamic among coalition structures.
Our results give us an incontestable fact that a provider does not tend to
cooperate with other providers in peer-assisted services, and be separated from
them. Three facets of the noncooperative (selfish) providers are illustrated;
(i) underpaid peers, (ii) service monopoly, and (iii) oscillatory coalition
structure. Lastly, we propose a stable payoff mechanism which improves fairness
of profit-sharing by regulating the selfishness of the players as well as
grants the content providers a limited right of realistic bargaining. Our study
opens many new questions such as realistic and efficient incentive structures
and the tradeoffs between fairness and individual providers' competition in
peer-assisted services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0459</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0459</id><created>2011-04-03</created><updated>2011-04-05</updated><authors><author><keyname>Li</keyname><forenames>Yaping</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author><author><keyname>Li</keyname><forenames>Qiwei</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author></authors><title>Enabling Multi-level Trust in Privacy Preserving Data Mining</title><categories>cs.DB stat.AP</categories><comments>20 pages, 5 figures. Accepted for publication in IEEE Transactions on
  Knowledge and Data Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy Preserving Data Mining (PPDM) addresses the problem of developing
accurate models about aggregated data without access to precise information in
individual data record. A widely studied \emph{perturbation-based PPDM}
approach introduces random perturbation to individual values to preserve
privacy before data is published. Previous solutions of this approach are
limited in their tacit assumption of single-level trust on data miners.
  In this work, we relax this assumption and expand the scope of
perturbation-based PPDM to Multi-Level Trust (MLT-PPDM). In our setting, the
more trusted a data miner is, the less perturbed copy of the data it can
access. Under this setting, a malicious data miner may have access to
differently perturbed copies of the same data through various means, and may
combine these diverse copies to jointly infer additional information about the
original data that the data owner does not intend to release. Preventing such
\emph{diversity attacks} is the key challenge of providing MLT-PPDM services.
We address this challenge by properly correlating perturbation across copies at
different trust levels. We prove that our solution is robust against diversity
attacks with respect to our privacy goal. That is, for data miners who have
access to an arbitrary collection of the perturbed copies, our solution prevent
them from jointly reconstructing the original data more accurately than the
best effort using any individual copy in the collection. Our solution allows a
data owner to generate perturbed copies of its data for arbitrary trust levels
on-demand. This feature offers data owners maximum flexibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0471</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0471</id><created>2011-04-04</created><updated>2011-12-31</updated><authors><author><keyname>Wu</keyname><forenames>Haoyang</forenames></author></authors><title>Quantum Bayesian implementation</title><categories>physics.data-an cs.GT</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian implementation concerns decision making problems when agents have
incomplete information. This paper proposes that the traditional sufficient
conditions for Bayesian implementation shall be amended by virtue of a quantum
Bayesian mechanism. In addition, by using an algorithmic Bayesian mechanism,
this amendment holds in the macro world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0478</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0478</id><created>2011-04-04</created><authors><author><keyname>Chabot</keyname><forenames>Christophe</forenames><affiliation>LJK</affiliation></author><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Fousse</keyname><forenames>Laurent</forenames><affiliation>LJK</affiliation></author><author><keyname>Giorgi</keyname><forenames>Pascal</forenames><affiliation>LIRMM</affiliation></author></authors><title>Recursive double-size fixed precision arithmetic</title><categories>cs.CR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is a part of the SHIVA (Secured Hardware Immune Versatile
Architecture) project whose purpose is to provide a programmable and
reconfigurable hardware module with high level of security. We propose a
recursive double-size fixed precision arithmetic called RecInt. Our work can be
split in two parts. First we developped a C++ software library with
performances comparable to GMP ones. Secondly our simple representation of the
integers allows an implementation on FPGA. Our idea is to consider sizes that
are a power of 2 and to apply doubling techniques to implement them
efficiently: we design a recursive data structure where integers of size 2^k,
for k&gt;k0 can be stored as two integers of size 2^{k-1}. Obviously for k&lt;=k0 we
use machine arithmetic instead (k0 depending on the architecture).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0497</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0497</id><created>2011-04-04</created><authors><author><keyname>Chakraborty</keyname><forenames>Arnab</forenames></author></authors><title>QuECT: A New Quantum Programming Paradigm</title><categories>quant-ph cs.PL</categories><comments>18 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum computation constitutes a rapidly expanding subfield of computer
science. Development quantum algorithms is facilitated by the availability of
efficient quantum programming languages, and a plethora of approaches has been
already suggested in the literature, ranging from GUI-based simple tools to
elaborate standalone programming languages. In this paper we propose a novel
paradigm called Quantum Embeddable Circuit Technique (QuECT) that allows a
programmer to embed a circuit diagram in a classical &quot;host&quot; language. The
paradigm can be implemented in any modern classical language. A prototype has
been developed by the author using Java.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0504</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0504</id><created>2011-04-04</created><updated>2011-05-14</updated><authors><author><keyname>Faggian</keyname><forenames>Claudia</forenames><affiliation>CNRS - Paris7</affiliation></author><author><keyname>Basaldella</keyname><forenames>Michele</forenames><affiliation>RIMS - Kyoto Univ.</affiliation></author></authors><title>Ludics with repetitions (Exponentials, Interactive types and
  Completeness)</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, F.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 17,
  2011) lmcs:1095</journal-ref><doi>10.2168/LMCS-7(2:13)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ludics is peculiar in the panorama of game semantics: we first have the
definition of interaction-composition and then we have semantical types, as a
set of strategies which &quot;behave well&quot; and react in the same way to a set of
tests. The semantical types which are interpretations of logical formulas enjoy
a fundamental property, called internal completeness, which characterizes
ludics and sets it apart also from realizability. Internal completeness entails
standard full completeness as a consequence. A growing body of work start to
explore the potential of this specific interactive approach. However, ludics
has some limitations, which are consequence of the fact that in the original
formulation, strategies are abstractions of MALL proofs. On one side, no
repetitions are allowed. On the other side, the proofs tend to rely on the very
specific properties of the MALL proof-like strategies, making it difficult to
transfer the approach to semantical types into different settings. In this
paper, we provide an extension of ludics which allows repetitions and show that
one can still have interactive types and internal completeness. From this, we
obtain full completeness w.r.t. a polarized version of MELL. In our extension,
we use less properties than in the original formulation, which we believe is of
independent interest. We hope this may open the way to applications of ludics
approach to larger domains and different settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0510</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0510</id><created>2011-04-04</created><authors><author><keyname>H</keyname><forenames>Jos&#xe9; Antonio Mart&#xed;n</forenames></author></authors><title>Minimal non-extensible precolorings and implicit-relations</title><categories>math.CO cs.CC cs.DM</categories><msc-class>Primary 05C15, 05C75, Secondary 05C90, 05C69</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I study a variant of the general vertex coloring problem called
precoloring. Specifically, I study graph precolorings, by developing new
theory, for characterizing the minimal non-extensible precolorings. It is
interesting per se that, for graphs of arbitrarily large chromatic number, the
minimal number of colored vertices, in a non-extensible precoloring, remains
constant; only two vertices $u,v$ suffice. Here, the relation between such
$u,v$ is called an implicit-relation, distinguishing two cases: (i)
implicit-edges where $u,v$ are precolored with the same color and (ii)
implicit-identities where $u,v$ are precolored distinct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0529</identifier>
 <datestamp>2015-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0529</id><created>2011-04-04</created><authors><author><keyname>Blythe</keyname><forenames>Richard A</forenames></author></authors><title>Random copying in space</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>26 pages, 11 figures. Based on invited talk at AHRC CECD Conference
  on &quot;Cultural Evolution in Spatially Structured Populations&quot; at UCL, September
  2010. To appear in ACS - Advances in Complex Systems</comments><journal-ref>ACS - Advances in Complex Systems (2012) 15 1150012</journal-ref><doi>10.1142/S0219525911003396</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random copying is a simple model for population dynamics in the absence of
selection, and has been applied to both biological and cultural evolution. In
this work, we investigate the effect that spatial structure has on the
dynamics. We focus in particular on how a measure of the diversity in the
population changes over time. We show that even when the vast majority of a
population's history may be well-described by a spatially-unstructured model,
spatial structure may nevertheless affect the expected level of diversity seen
at a local scale. We demonstrate this phenomenon explicitly by examining the
random copying process on small-world networks, and use our results to comment
on the use of simple random-copying models in an empirical context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0547</identifier>
 <datestamp>2011-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0547</id><created>2011-04-04</created><updated>2011-08-27</updated><authors><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author><author><keyname>Vedantam</keyname><forenames>Satish</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Joint Transmission and State Estimation: A Constrained Channel Coding
  Approach</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A scenario involving a source, a channel, and a destination, where the
destination is interested in {\em both} reliably reconstructing the message
transmitted by the source and estimating with a fidelity criterion the state of
the channel, is considered. The source knows the channel statistics, but is
oblivious to the actual channel state realization. Herein it is established
that a distortion constraint for channel state estimation can be reduced to an
additional cost constraint on the source input distribution, in the limit of
large coding block length. A newly defined capacity-distortion function thus
characterizes the fundamental tradeoff between transmission rate and state
estimation distortion. It is also shown that non-coherent communication coupled
with channel state estimation conditioned on treating the decoded message as
training symbols achieves the capacity-distortion function. Among the various
examples considered, the capacity-distortion function for a memoryless Rayleigh
fading channel is characterized to within 1.443 bits at high signal-to-noise
ratio. The constrained channel coding approach is also extended to multiple
access channels, leading to a coupled cost constraint on the input
distributions for the transmitting sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0553</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0553</id><created>2011-04-04</created><updated>2011-05-30</updated><authors><author><keyname>Benedikt</keyname><forenames>Michael</forenames></author><author><keyname>Gottlob</keyname><forenames>Georg</forenames></author><author><keyname>Senellart</keyname><forenames>Pierre</forenames></author></authors><title>Determining Relevance of Accesses at Runtime (Extended Version)</title><categories>cs.DB</categories><acm-class>H.2.3; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the situation where a query is to be answered using Web sources that
restrict the accesses that can be made on backend relational data by requiring
some attributes to be given as input of the service. The accesses provide
lookups on the collection of attributes values that match the binding. They can
differ in whether or not they require arguments to be generated from prior
accesses. Prior work has focused on the question of whether a query can be
answered using a set of data sources, and in developing static access plans
(e.g., Datalog programs) that implement query answering. We are interested in
dynamic aspects of the query answering problem: given partial information about
the data, which accesses could provide relevant data for answering a given
query? We consider immediate and long-term notions of &quot;relevant accesses&quot;, and
ascertain the complexity of query relevance, for both conjunctive queries and
arbitrary positive queries. In the process, we relate dynamic relevance of an
access to query containment under access limitations and characterize the
complexity of this problem; we produce several complexity results about
containment that are of interest by themselves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0576</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0576</id><created>2011-04-04</created><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir R.</forenames></author><author><keyname>Schober</keyname><forenames>Steffen</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor V.</forenames></author></authors><title>Adaptive Single-Trial Error/Erasure Decoding of Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><comments>Accepted for the 2011 Canadian Workshop on Information Theory,
  Kelowna, BC, Canada, May 17 - 20, 2011. 5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebraic decoding algorithms are commonly applied for the decoding of
Reed-Solomon codes. Their main advantages are low computational complexity and
predictable decoding capabilities. Many algorithms can be extended for
correction of both errors and erasures. This enables the decoder to exploit
binary quantized reliability information obtained from the transmission
channel: Received symbols with high reliability are forwarded to the decoding
algorithm while symbols with low reliability are erased. In this paper we
investigate adaptive single-trial error/erasure decoding of Reed-Solomon codes,
i.e. we derive an adaptive erasing strategy which minimizes the residual
codeword error probability after decoding. Our result is applicable to any
error/erasure decoding algorithm as long as its decoding capabilities can be
expressed by a decoder capability function. Examples are Bounded Minimum
Distance decoding with the Berlekamp-Massey- or the Sugiyama algorithms and the
Guruswami-Sudan list decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0579</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0579</id><created>2011-04-04</created><authors><author><keyname>Ji</keyname><forenames>Ye</forenames></author></authors><title>Image Retrieval Method Using Top-surf Descriptor</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report presents the results and details of a content-based image
retrieval project using the Top-surf descriptor. The experimental results are
preliminary, however, it shows the capability of deducing objects from parts of
the objects or from the objects that are similar. This paper uses a dataset
consisting of 1200 images of which 800 images are equally divided into 8
categories, namely airplane, beach, motorbike, forest, elephants, horses, bus
and building, while the other 400 images are randomly picked from the Internet.
The best results achieved are from building category.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0582</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0582</id><created>2011-04-04</created><authors><author><keyname>Tao</keyname><forenames>Ran</forenames></author></authors><title>Visual Concept Detection and Real Time Object Detection</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bag-of-words model is implemented and tried on 10-class visual concept
detection problem. The experimental results show that &quot;DURF+ERT+SVM&quot;
outperforms &quot;SIFT+ERT+SVM&quot; both in detection performance and computation
efficiency. Besides, combining DURF and SIFT results in even better detection
performance. Real-time object detection using SIFT and RANSAC is also tried on
simple objects, e.g. drink can, and good result is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0594</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0594</id><created>2011-04-04</created><authors><author><keyname>Pal</keyname><forenames>Ranjan</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author></authors><title>Modeling Internet Security Investments: The Case of Dealing with
  Information Uncertainty</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern distributed communication networks like the Internet and
censorship-resistant networks (also a part of the Internet) are characterized
by nodes (users) interconnected with one another via communication links. In
this regard, the security of individual nodes depend not only on their own
efforts, but also on the efforts and underlying connectivity structure of
neighboring network nodes. By the term 'effort', we imply the amount of
investments made by a user in security mechanisms like antivirus softwares,
firewalls, etc., to improve its security. However, often due to the large
magnitude of such networks, it is not always possible for nodes to have
complete effort and connectivity structure information about all their neighbor
nodes. Added to this is the fact that in many applications, the Internet users
are selfish and are not willing to co-operate with other users on sharing
effort information. In this paper, we adopt a non-cooperative game-theoretic
approach to analyze individual user security in a communication network by
accounting for both, the partial information that a network node possess about
its underlying neighborhood connectivity structure, as well as the presence of
positive externalities arising from efforts exerted by neighboring nodes. We
investigate the equilibrium behavior of nodes and show 1) the existence of
symmetric Bayesian Nash equilibria of efforts and 2) better connected nodes
choose lower efforts to exert but earn higher utilities with respect to
security improvement irrespective of the nature of node degree correlations
amongst the neighboring nodes. Our results provide ways for Internet users to
appropriately invest in security mechanisms under realistic environments of
information uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0599</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0599</id><created>2011-04-04</created><authors><author><keyname>Hassani</keyname><forenames>S. Hamed</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author><author><keyname>Mori</keyname><forenames>Ryuhei</forenames></author></authors><title>Near concavity of the growth rate for coupled LDPC chains</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Low-Density-Parity-Check (LDPC) ensembles have excellent
performance. Their iterative threshold increases with their average degree, or
with the size of the coupling window in randomized constructions. In the later
case, as the window size grows, the Belief Propagation (BP) threshold attains
the maximum-a-posteriori (MAP) threshold of the underlying ensemble. In this
contribution we show that a similar phenomenon happens for the growth rate of
coupled ensembles. Loosely speaking, we observe that as the coupling strength
grows, the growth rate of the coupled ensemble comes close to the concave hull
of the underlying ensemble's growth rate. For ensembles randomly coupled across
a window the growth rate actually tends to the concave hull of the underlying
one as the window size increases. Our observations are supported by the
calculations of the combinatorial growth rate, and that of the growth rate
derived from the replica method. The observed concavity is a general feature of
coupled mean field graphical models and is already present at the level of
coupled Curie-Weiss models. There, the canonical free energy of the coupled
system tends to the concave hull of the underlying one. As we explain, the
behavior of the growth rate of coupled ensembles is exactly analogous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0607</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0607</id><created>2011-04-04</created><authors><author><keyname>Lohmann</keyname><forenames>Peter</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>Complexity Results for Modal Dependence Logic</title><categories>cs.LO cs.CC</categories><comments>22 pages, full version of CSL 2010 paper</comments><acm-class>F.2.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modal dependence logic was introduced recently by V\&quot;a\&quot;an\&quot;anen. It enhances
the basic modal language by an operator =(). For propositional variables
p_1,...,p_n, =(p_1,...,p_(n-1);p_n) intuitively states that the value of p_n is
determined by those of p_1,...,p_(n-1). Sevenster (J. Logic and Computation,
2009) showed that satisfiability for modal dependence logic is complete for
nondeterministic exponential time. In this paper we consider fragments of modal
dependence logic obtained by restricting the set of allowed propositional
connectives. We show that satisfibility for poor man's dependence logic, the
language consisting of formulas built from literals and dependence atoms using
conjunction, necessity and possibility (i.e., disallowing disjunction), remains
NEXPTIME-complete. If we only allow monotone formulas (without negation, but
with disjunction), the complexity drops to PSPACE-completeness. We also extend
V\&quot;a\&quot;an\&quot;anen's language by allowing classical disjunction besides dependence
disjunction and show that the satisfiability problem remains NEXPTIME-complete.
If we then disallow both negation and dependence disjunction, satistiability is
complete for the second level of the polynomial hierarchy. In this way we
completely classify the computational complexity of the satisfiability problem
for all restrictions of propositional and dependence operators considered by
V\&quot;a\&quot;an\&quot;anen and Sevenster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0617</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0617</id><created>2011-04-04</created><authors><author><keyname>Abdulla</keyname><forenames>Parosh Aziz</forenames></author><author><keyname>Mayr</keyname><forenames>Richard</forenames></author></authors><title>Computing Optimal Coverability Costs in Priced Timed Petri Nets</title><categories>cs.LO</categories><comments>26 pages. Contribution to LICS 2011</comments><acm-class>F.1.1; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider timed Petri nets, i.e., unbounded Petri nets where each token
carries a real-valued clock. Transition arcs are labeled with time intervals,
which specify constraints on the ages of tokens. Our cost model assigns token
storage costs per time unit to places, and firing costs to transitions. We
study the cost to reach a given control-state. In general, a cost-optimal run
may not exist. However, we show that the infimum of the costs is computable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0622</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0622</id><created>2011-04-04</created><authors><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author><author><keyname>Gao</keyname><forenames>Jie</forenames></author><author><keyname>Guibas</keyname><forenames>Leonidas J.</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Koltun</keyname><forenames>Vladlen</forenames></author><author><keyname>Rubin</keyname><forenames>Natan</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>Kinetic Stable Delaunay Graphs</title><categories>cs.CG</categories><comments>A preliminary version appeared in Proc. SoCG 2010</comments><acm-class>F.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maintaining the Euclidean Delaunay triangulation
$\DT$ of a set $P$ of $n$ moving points in the plane, along algebraic
trajectories of constant description complexity. Since the best known upper
bound on the number of topological changes in the full $\DT$ is nearly cubic,
we seek to maintain a suitable portion of it that is less volatile yet retains
many useful properties. We introduce the notion of a stable Delaunay graph,
which is a dynamic subgraph of the Delaunay triangulation. The stable Delaunay
graph (a) is easy to define, (b) experiences only a nearly quadratic number of
discrete changes, (c) is robust under small changes of the norm, and (d)
possesses certain useful properties.
  The stable Delaunay graph ($\SDG$ in short) is defined in terms of a
parameter $\alpha&gt;0$, and consists of Delaunay edges $pq$ for which the angles
at which $p$ and $q$ see their Voronoi edge $e_{pq}$ are at least $\alpha$. We
show that (i) $\SDG$ always contains at least roughly one third of the Delaunay
edges; (ii) it contains the $\beta$-skeleton of $P$, for
$\beta=1+\Omega(\alpha^2)$; (iii) it is stable, in the sense that its edges
survive for long periods of time, as long as the orientations of the segments
connecting (nearby) points of $P$ do not change by much; and (iv) stable
Delaunay edges remain stable (with an appropriate redefinition of stability) if
we replace the Euclidean norm by any sufficiently close norm.
  In particular, we can approximate the Euclidean norm by a polygonal norm
(namely, a regular $k$-gon, with $k=\Theta(1/\alpha)$), and keep track of a
Euclidean $\SDG$ by maintaining the full Delaunay triangulation of $P$ under
the polygonal norm.
  We describe two kinetic data structures for maintaining $\SDG$. Both
structures use $O^*(n)$ storage and process $O^*(n^2)$ events during the
motion, each in $O^*(1)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0628</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0628</id><created>2011-04-04</created><authors><author><keyname>&#xd8;lgaard</keyname><forenames>Kristian B.</forenames></author><author><keyname>Logg</keyname><forenames>Anders</forenames></author><author><keyname>Wells</keyname><forenames>Garth N.</forenames></author></authors><title>Automated code generation for discontinuous Galerkin methods</title><categories>cs.MS</categories><msc-class>65N30, 68N20</msc-class><journal-ref>SIAM J. Sci. Comput. 31(2), 2008, pp. 849-864</journal-ref><doi>10.1137/070710032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A compiler approach for generating low-level computer code from high-level
input for discontinuous Galerkin finite element forms is presented. The input
language mirrors conventional mathematical notation, and the compiler generates
efficient code in a standard programming language. This facilitates the rapid
generation of efficient code for general equations in varying spatial
dimensions. Key concepts underlying the compiler approach and the automated
generation of computer code are elaborated. The approach is demonstrated for a
range of common problems, including the Poisson, biharmonic,
advection--diffusion and Stokes equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0636</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0636</id><created>2011-04-04</created><updated>2011-11-06</updated><authors><author><keyname>Barone</keyname><forenames>Sal</forenames></author><author><keyname>Basu</keyname><forenames>Saugata</forenames></author></authors><title>Refined bounds on the number of connected components of sign conditions
  on a variety</title><categories>math.CO cs.CG</categories><comments>Bound made more precise and references added. Final version to appear
  in Discrete and Computational Geometry</comments><msc-class>14P10, 14P25 (Primary) 52C10, 52C45 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\R$ be a real closed field, $\mathcal{P},\mathcal{Q} \subset
\R[X_1,...,X_k]$ finite subsets of polynomials, with the degrees of the
polynomials in $\mathcal{P}$ (resp. $\mathcal{Q}$) bounded by $d$ (resp.
$d_0$). Let $V \subset \R^k$ be the real algebraic variety defined by the
polynomials in $\mathcal{Q}$ and suppose that the real dimension of $V$ is
bounded by $k'$. We prove that the number of semi-algebraically connected
components of the realizations of all realizable sign conditions of the family
$\mathcal{P}$ on $V$ is bounded by $$ \displaylines{\sum_{j=0}^{k'}4^j{s
+1\choose j}F_{d,d_0,k,k'}(j),}$$ where $s = \card \; \mathcal{P}$, and
$$F_{d,d_0,k,k'}(j)= \textstyle\binom{k+1}{k-k'+j+1} \;(2d_0)^{k-k'}d^j\;
\max{2d_0,d}^{k'-j} +2(k-j+1) .$$
  In case $2 d_0 \leq d$, the above bound can be written simply as $$
\displaylines{\sum_{j = 0}^{k'} {s+1 \choose j}d^{k'} d_0^{k-k'} O(1)^{k} =
(sd)^{k'} d_0^{k-k'} O(1)^k} $$ (in this form the bound was suggested by J.
Matousek. Our result improves in certain cases (when $d_0 \ll d$) the best
known bound of $$ \sum_{1 \leq j \leq k'}
  \binom{s}{j} 4^{j} d(2d-1)^{k-1} $$ on the same number proved earlier in the
case $d=d_0$.
  The distinction between the bound $d_0$ on the degrees of the polynomials
defining the variety $V$ and the bound $d$ on the degrees of the polynomials in
$\mathcal{P}$ that appears in the new bound is motivated by several
applications in discrete geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0640</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0640</id><created>2011-04-04</created><updated>2011-09-05</updated><authors><author><keyname>Natarajan</keyname><forenames>Lakshmi Prasad</forenames></author><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>On the Sphere Decoding Complexity of STBCs for Asymmetric MIMO Systems</title><categories>cs.IT math.IT</categories><comments>Improved the organization over version 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the landmark paper by Hassibi and Hochwald, it is claimed without proof
that the upper triangular matrix R encountered during the sphere decoding of
any linear dispersion code is full-ranked whenever the rate of the code is less
than the minimum of the number of transmit and receive antennas. In this paper,
we show that this claim is true only when the number of receive antennas is at
least as much as the number of transmit antennas. We also show that all known
families of high rate (rate greater than 1 complex symbol per channel use)
multigroup ML decodable codes have rank-deficient R matrix even when the
criterion on rate is satisfied, and that this rank-deficiency problem arises
only in asymmetric MIMO with number of receive antennas less than the number of
transmit antennas. Unlike the codes with full-rank R matrix, the average sphere
decoding complexity of the STBCs whose R matrix is rank-deficient is polynomial
in the constellation size. We derive the sphere decoding complexity of most of
the known high rate multigroup ML decodable codes, and show that for each code,
the complexity is a decreasing function of the number of receive antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0644</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0644</id><created>2011-04-04</created><authors><author><keyname>El-Zawawy</keyname><forenames>Mohamed A.</forenames></author></authors><title>Program Optimization Based Pointer Analysis and Live Stack-Heap Analysis</title><categories>cs.SE cs.PL</categories><comments>10 pages, 7 figures</comments><journal-ref>International Journal of Computer Science Issues, Volume 8, Issue
  2, pages 98-107, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present type systems for flow-sensitive pointer analysis,
live stack-heap (variables) analysis, and program optimization. The type system
for live stack-heap analysis is an enrichment of that for pointer analysis; the
enrichment has the form of a second component being added to types of the
latter system. Results of pointer analysis are proved useful via their use in
the type system for live stack-heap analysis. The type system for program
optimization is also an augmentation of that for live stack-heap analysis, but
the augmentation takes the form of a transformation component being added to
inference rules of the latter system. The form of program optimization being
achieved is that of dead-code elimination. A form of program correction may
result indirectly from eliminating faulty code (causing the program to abort)
that is dead. Therefore program optimization can result in program correction.
Our type systems have the advantage of being compositional and
relatively-simply structured.
  The novelty of our work comes from the fact that our type system for program
optimization associates the optimized version of a program with a justification
(in the form of a type derivation) for the optimization. This justification is
pretty much appreciated in many research areas like certified code
(proof-carrying code) which is the motivation of this work
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0645</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0645</id><created>2011-04-04</created><authors><author><keyname>Broustis</keyname><forenames>Ioannis</forenames></author><author><keyname>Paschos</keyname><forenames>Georgios</forenames></author><author><keyname>Syrivelis</keyname><forenames>Dimitris</forenames></author><author><keyname>Georgiadis</keyname><forenames>Leonidas</forenames></author><author><keyname>Tassiulas</keyname><forenames>Leandros</forenames></author></authors><title>NCRAWL: Network Coding for Rate Adaptive Wireless Links</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intersession network coding (NC) can provide significant performance benefits
via mixing packets at wireless routers; these benefits are especially
pronounced when NC is applied in conjunction with intelligent link scheduling.
NC however imposes certain processing operations, such as encoding, decoding,
copying and storage. When not utilized carefully, all these operations can
induce tremendous processing overheads in practical, wireless, multi-rate
settings. Our measurements with prior NC implementations suggest that such
processing operations severely degrade the router throughput, especially at
high bit rates. Motivated by this, we design {\bf NCRAWL}, a Network Coding
framework for Rate Adaptive Wireless Links. The design of NCRAWL facilitates
low overhead NC functionalities, thereby effectively approaching the
theoretically expected capacity benefits of joint NC and scheduling. We
implement and evaluate NCRAWL on a wireless testbed. Our experiments
demonstrate that NCRAWL meets the theoretical predicted throughput gain while
requiring much less CPU processing, compared to related frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0651</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0651</id><created>2011-04-04</created><updated>2011-07-19</updated><authors><author><keyname>Tepper</keyname><forenames>Mariano</forenames></author><author><keyname>Mus&#xe9;</keyname><forenames>Pablo</forenames></author><author><keyname>Almansa</keyname><forenames>Andr&#xe9;s</forenames></author></authors><title>Meaningful Clustered Forest: an Automatic and Robust Clustering
  Algorithm</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new clustering technique that can be regarded as a numerical
method to compute the proximity gestalt. The method analyzes edge length
statistics in the MST of the dataset and provides an a contrario cluster
detection criterion. The approach is fully parametric on the chosen distance
and can detect arbitrarily shaped clusters. The method is also automatic, in
the sense that only a single parameter is left to the user. This parameter has
an intuitive interpretation as it controls the expected number of false
detections. We show that the iterative application of our method can (1)
provide robustness to noise and (2) solve a masking phenomenon in which a
highly populated and salient cluster dominates the scene and inhibits the
detection of less-populated, but still salient, clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0654</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0654</id><created>2011-04-04</created><updated>2012-04-13</updated><authors><author><keyname>Elhamifar</keyname><forenames>Ehsan</forenames></author><author><keyname>Vidal</keyname><forenames>Rene</forenames></author></authors><title>Block-Sparse Recovery via Convex Optimization</title><categories>math.OC cs.CV cs.IT math.IT</categories><comments>IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2012.2196694</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a dictionary that consists of multiple blocks and a signal that lives
in the range space of only a few blocks, we study the problem of finding a
block-sparse representation of the signal, i.e., a representation that uses the
minimum number of blocks. Motivated by signal/image processing and computer
vision applications, such as face recognition, we consider the block-sparse
recovery problem in the case where the number of atoms in each block is
arbitrary, possibly much larger than the dimension of the underlying subspace.
To find a block-sparse representation of a signal, we propose two classes of
non-convex optimization programs, which aim to minimize the number of nonzero
coefficient blocks and the number of nonzero reconstructed vectors from the
blocks, respectively. Since both classes of problems are NP-hard, we propose
convex relaxations and derive conditions under which each class of the convex
programs is equivalent to the original non-convex formulation. Our conditions
depend on the notions of mutual and cumulative subspace coherence of a
dictionary, which are natural generalizations of existing notions of mutual and
cumulative coherence. We evaluate the performance of the proposed convex
programs through simulations as well as real experiments on face recognition.
We show that treating the face recognition problem as a block-sparse recovery
problem improves the state-of-the-art results by 10% with only 25% of the
training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0689</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0689</id><created>2011-04-04</created><authors><author><keyname>Chen</keyname><forenames>Changbo</forenames></author><author><keyname>Maza</keyname><forenames>Marc Moreno</forenames></author></authors><title>Algorithms for Computing Triangular Decompositions of Polynomial Systems</title><categories>cs.SC cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose new algorithms for computing triangular decompositions of
polynomial systems incrementally. With respect to previous works, our
improvements are based on a {\em weakened} notion of a polynomial GCD modulo a
regular chain, which permits to greatly simplify and optimize the
sub-algorithms. Extracting common work from similar expensive computations is
also a key feature of our algorithms. In our experimental results the
implementation of our new algorithms, realized with the {\RegularChains}
library in {\Maple}, outperforms solvers with similar specifications by several
orders of magnitude on sufficiently difficult problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0729</identifier>
 <datestamp>2012-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0729</id><created>2011-04-05</created><updated>2011-06-16</updated><authors><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Bartlett</keyname><forenames>Peter</forenames></author></authors><title>Online and Batch Learning Algorithms for Data with Missing Features</title><categories>cs.LG stat.ML</categories><journal-ref>27th Conference on Uncertainty in Artificial Intelligence (UAI
  2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce new online and batch algorithms that are robust to data with
missing features, a situation that arises in many practical applications. In
the online setup, we allow for the comparison hypothesis to change as a
function of the subset of features that is observed on any given round,
extending the standard setting where the comparison hypothesis is fixed
throughout. In the batch setup, we present a convex relation of a non-convex
problem to jointly estimate an imputation function, used to fill in the values
of missing features, along with the classification hypothesis. We prove regret
bounds in the online setting and Rademacher complexity bounds for the batch
i.i.d. setting. The algorithms are tested on several UCI datasets, showing
superior performance over baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0733</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0733</id><created>2011-04-05</created><authors><author><keyname>Ren</keyname><forenames>Wei</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>A Note on: `Algorithms for Connected Set Cover Problem and
  Fault-Tolerant Connected Set Cover Problem'</title><categories>cs.DS</categories><comments>6 pages, 1 figure, submitted to Theoretical Computer Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A flaw in the greedy approximation algorithm proposed by Zhang et al. for
minimum connected set cover problem is corrected, and a stronger result on the
approximation ratio of the modified greedy algorithm is established. The
results are now consistent with the existing results on connected dominating
set problem which is a special case of the minimum connected set cover problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0735</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0735</id><created>2011-04-05</created><authors><author><keyname>Muralidharan</keyname><forenames>Vijayvaradharaj T</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Non-Orthogonal DF Scheme for the Single Relay Channel and the Effect
  of Labelling</title><categories>cs.IT math.IT</categories><comments>10 pages, 14 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the uncoded transmission over the half-duplex single relay
channel, with a single antenna at the source, relay and destination nodes, in a
Rayleigh fading environment. The phase during which the relay is in reception
mode is referred to as Phase 1 and the phase during which the relay is in
transmission mode is referred to as Phase 2. The following two cases are
considered: the Non-Orthogonal Decode and Forward (NODF) scheme, in which both
the source and the relay transmit during Phase 2 and the Orthogonal Decode and
Forward (ODF) scheme, in which the relay alone transmits during Phase 2. A near
ML decoder which gives full diversity (diversity order 2) for the NODF scheme
is proposed. Due to the proximity of the relay to the destination, the
Source-Destination link, in general, is expected to be much weaker than the
Relay-Destination link. Hence it is not clear whether the transmission made by
the source during Phase 2 in the NODF scheme, provides any performance
improvement over the ODF scheme or not. In this regard, it is shown that the
NODF scheme provides significant performance improvement over the ODF scheme.
In fact, at high SNR, the performance of the NODF scheme with the non-ideal
Source-Relay link, is same as that of the NODF scheme with an ideal
Source-Relay link. In other words, to study the high SNR performance of the
NODF scheme, one can assume that the Source-Relay link is ideal, whereas the
same is not true for the ODF scheme. Further, it is shown that proper choice of
the mapping of the bits on to the signal points at the source and the relay,
provides a significant improvement in performance, for both the NODF and the
ODF schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0739</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0739</id><created>2011-04-05</created><authors><author><keyname>Gelles</keyname><forenames>Ran</forenames></author><author><keyname>Sahai</keyname><forenames>Amit</forenames></author></authors><title>Potent Tree Codes and their applications: Coding for Interactive
  Communication, revisited</title><categories>cs.DS</categories><comments>26 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the fundamental problem of reliable interactive communication over a
noisy channel. In a breakthrough sequence of papers published in 1992 and 1993,
Schulman gave non-constructive proofs of the existence of general methods to
emulate any two-party interactive protocol such that: (1) the emulation
protocol takes a constant-factor longer than the original protocol, and (2) if
the emulation protocol is executed over a noisy channel, then the probability
that the emulation protocol fails is exponentially small in the total length of
the protocol. Unfortunately, Schulman's emulation procedures either only work
in a model with a large amount of shared randomness, or are non-constructive in
that they rely on the existence of good tree codes. The only known proofs of
the existence of good tree codes are non-constructive, and finding an explicit
construction remains an important open problem. Indeed, randomly generated tree
codes are not good tree codes with overwhelming probability.
  In this work, we revisit the problem of reliable interactive communication,
and obtain the following results: We introduce a new notion of goodness for a
tree code, and define the notion of a potent tree code. We believe that this
notion is of independent interest. We prove the correctness of an explicit
emulation procedure based on any potent tree code. We show that a randomly
generated tree code (with suitable constant alphabet size) is a potent tree
code with overwhelming probability. Furthermore we are able to partially
derandomize this result using only O(n) random bits, where $n$ is the depth of
the tree.
  These results allow us to obtain the first fully explicit emulation procedure
for reliable interactive communication over noisy channels with a constant
communication overhead, and exponentially small failure probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0742</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0742</id><created>2011-04-05</created><updated>2011-08-22</updated><authors><author><keyname>Wu</keyname><forenames>Lingfei</forenames></author><author><keyname>Zhang</keyname><forenames>Jiang</forenames></author></authors><title>Accelerating Growth and Size-dependent Distribution of Human Activities
  Online</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 2 figures</comments><journal-ref>Physical Review E 84, 026113 (2011)</journal-ref><doi>10.1103/PhysRevE.84.026113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on human online activities usually assumes that total activity $T$
increases linearly with active population $P$, that is, $T\propto
P^{\gamma}(\gamma=1)$. However, we find examples of systems where total
activity grows faster than active population. Our study shows that the power
law relationship $T\propto P^{\gamma}(\gamma&gt;1)$ is in fact ubiquitous in
online activities such as micro-blogging, news voting and photo tagging. We
call the pattern &quot;accelerating growth&quot; and find it relates to a type of
distribution that changes with system size. We show both analytically and
empirically how the growth rate $\gamma$ associates with a scaling parameter
$b$ in the size-dependent distribution. As most previous studies explain
accelerating growth by power law distribution, the model of size-dependent
distribution is novel and worth further exploration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0746</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0746</id><created>2011-04-05</created><authors><author><keyname>Gao</keyname><forenames>Sicun</forenames></author><author><keyname>Platzer</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Clarke</keyname><forenames>Edmund M.</forenames></author></authors><title>Quantifier Elimination over Finite Fields Using Gr\&quot;obner Bases</title><categories>cs.SC cs.LO</categories><comments>A shorter version is to appear in International Conference on
  Algebraic Informatics 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an algebraic quantifier elimination algorithm for the first-order
theory over any given finite field using Gr\&quot;obner basis methods. The algorithm
relies on the strong Nullstellensatz and properties of elimination ideals over
finite fields. We analyze the theoretical complexity of the algorithm and show
its application in the formal analysis of a biological controller model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0752</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0752</id><created>2011-04-05</created><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author></authors><title>Modeling network technology deployment rates with different network
  models</title><categories>cs.NI</categories><comments>14 pages, 9 figures</comments><acm-class>K.1; C.2.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To understand the factors that encourage the deployment of a new networking
technology, we must be able to model how such technology gets deployed. We
investigate how network structure influences deployment with a simple
deployment model and different network models through computer simulations. The
results indicate that a realistic model of networking technology deployment
should take network structure into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0753</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0753</id><created>2011-04-05</created><updated>2012-03-23</updated><authors><author><keyname>D&#xed;az-Ba&#xf1;ez</keyname><forenames>J. M.</forenames></author><author><keyname>Korman</keyname><forenames>M.</forenames></author><author><keyname>P&#xe9;rez-Lantero</keyname><forenames>P.</forenames></author><author><keyname>Ventura</keyname><forenames>I.</forenames></author></authors><title>Locating a service facility and a rapid transit line</title><categories>cs.CG</categories><comments>Abstract submitted to the XIV Spanish Meeting on Computational
  Geometry</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a facility location problem in the plane in which a
single point (facility) and a rapid transit line (highway) are simultaneously
located in order to minimize the total travel time of the clients to the
facility, using the $L_1$ or Manhattan metric. The rapid transit line is
represented by a line segment with fixed length and arbitrary orientation. The
highway is an alternative transportation system that can be used by the clients
to reduce their travel time to the facility. This problem was introduced by
Espejo and Ch\'ia in [7]. They gave both a characterization of the optimal
solutions and an algorithm running in $O(n^3\log n)$ time, where $n$ represents
the number of clients. In this paper we show that the Espejo and Ch\'ia's
algorithm does not always work correctly. At the same time, we provide a proper
characterization of the solutions with a simpler proof and give an algorithm
solving the problem in $O(n^3)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0769</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0769</id><created>2011-04-05</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Enhanced stiffness modeling of manipulators with passive joints</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Mechanism and Machine Theory 46, 5 (2011) 10-18</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a methodology to enhance the stiffness analysis of serial
and parallel manipulators with passive joints. It directly takes into account
the loading influence on the manipulator configuration and, consequently, on
its Jacobians and Hessians. The main contributions of this paper are the
introduction of a non-linear stiffness model for the manipulators with passive
joints, a relevant numerical technique for its linearization and computing of
the Cartesian stiffness matrix which allows rank-deficiency. Within the
developed technique, the manipulator elements are presented as pseudo-rigid
bodies separated by multidimensional virtual springs and perfect passive
joints. Simulation examples are presented that deal with parallel manipulators
of the Ortholide family and demonstrate the ability of the developed
methodology to describe non-linear behavior of the manipulator structure such
as a sudden change of the elastic instability properties (buckling).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0775</identifier>
 <datestamp>2011-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0775</id><created>2011-04-05</created><updated>2011-06-16</updated><authors><author><keyname>Wagner</keyname><forenames>Markus</forenames></author><author><keyname>Day</keyname><forenames>Jareth</forenames></author><author><keyname>Jordan</keyname><forenames>Diora</forenames></author><author><keyname>Kroeger</keyname><forenames>Trent</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author></authors><title>Evolving Pacing Strategies for Team Pursuit Track Cycling</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Team pursuit track cycling is a bicycle racing sport held on velodromes and
is part of the Summer Olympics. It involves the use of strategies to minimize
the overall time that a team of cyclists needs to complete a race. We present
an optimisation framework for team pursuit track cycling and show how to evolve
strategies using metaheuristics for this interesting real-world problem. Our
experimental results show that these heuristics lead to significantly better
strategies than state-of-art strategies that are currently used by teams of
cyclists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0779</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0779</id><created>2011-04-05</created><updated>2011-08-07</updated><authors><author><keyname>Even</keyname><forenames>Guy</forenames><affiliation>Moni</affiliation></author><author><keyname>Fais</keyname><forenames>Yaniv</forenames><affiliation>Moni</affiliation></author><author><keyname>Medina</keyname><forenames>Moti</forenames><affiliation>Moni</affiliation></author><author><keyname>Shimon</keyname><affiliation>Moni</affiliation></author><author><keyname>Shahar</keyname></author><author><keyname>Zadorojniy</keyname><forenames>Alexander</forenames></author></authors><title>Real-Time Video Streaming in Multi-hop Wireless Static Ad Hoc Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We deal with the problem of streaming multiple video streams between pairs of
nodes in a multi-hop wireless ad hoc network. The nodes are static, know their
locations, and are synchronized (via GPS). We introduce a new interference
model that uses variable interference radiuses. We present an algorithm for
computing a frequency assignment and a schedule whose goal is to maximize
throughput over all the video streams. In addition, we developed a localized
flow-control mechanism to stabilize the queue lengths.
  We simulated traffic scheduled by the algorithm using OMNET++/MixiM (i.e.,
physical SINR interference model with 802.11g) to test whether the computed
throughput is achieved. The results of the simulation show that the computed
solution is \SINR-feasible and achieves predictable stable throughputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0780</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0780</id><created>2011-04-05</created><authors><author><keyname>Chedmail</keyname><forenames>Patrick</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Roy</keyname><forenames>Christophe Le</forenames><affiliation>Airbus</affiliation></author></authors><title>A distributed Approach for Access and Visibility Task with a Manikin and
  a Robot in a Virtual Reality Environment</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Industrial Electronics 50, 4 (2003) 692-698</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method, based on a multi-agent system and on a
digital mock-up technology, to assess an efficient path planner for a manikin
or a robot for access and visibility task taking into account ergonomic
constraints or joint and mechanical limits. In order to solve this problem, the
human operator is integrated in the process optimization to contribute to a
global perception of the environment. This operator cooperates, in real-time,
with several automatic local elementary agents. The result of this work
validates solutions through the digital mock-up; it can be applied to simulate
maintenability and mountability tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0800</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0800</id><created>2011-04-05</created><authors><author><keyname>Shah</keyname><forenames>Jolly</forenames></author><author><keyname>Saxena</keyname><forenames>Dr. Vikas</forenames></author></authors><title>Video Encryption: A Survey</title><categories>cs.CR</categories><journal-ref>International Journal of Computer Science Issues,Volume 8, Issue
  2, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimedia data security is becoming important with the continuous increase
of digital communications on internet. The encryption algorithms developed to
secure text data are not suitable for multimedia application because of the
large data size and real time constraint. In this paper, classification and
description of various video encryption algorithms are presented. Analysis and
Comparison of these algorithms with respect to various parameters like visual
degradation, encryption ratio, speed, compression friendliness, format
compliance and cryptographic security is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0807</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0807</id><created>2011-04-05</created><updated>2011-07-29</updated><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Marx</keyname><forenames>Werner</forenames></author></authors><title>The Anna Karenina principle: A concept for the explanation of success in
  science</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first sentence of Leo Tolstoy's novel Anna Karenina is: &quot;Happy families
are all alike; every unhappy family is unhappy in its own way.&quot; Here Tolstoy
means that for a family to be happy, several key aspects must be given (such as
good health of all family members, acceptable financial security, and mutual
affection). If there is a deficiency in any one or more of these key aspects,
the family will be unhappy. In this paper we introduce the Anna Karenina
principle as a concept that can explain success in science. Here we will refer
to three central areas in modern science in which scarce resources will most
usually lead to failure: (1) peer review of research grant proposals and
manuscripts (money and journal space as scarce resources), (2) citation of
publications (reception as a scarce resource), and (3) new scientific
discoveries (recognition as a scarce resource). If resources are scarce
(journal space, funds, reception, and recognition), there can be success only
when several key prerequisites for the allocation of the resources are
fulfilled. If any one of these prerequisites is not fulfilled, the grant
proposal, manuscript submission, the published paper, or the discovery will not
be successful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0809</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0809</id><created>2011-04-05</created><authors><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author></authors><title>SLDs for Visualizing Multicolor Elevation Contour Lines in Geo-Spatial
  Web Applications</title><categories>cs.MM</categories><comments>5 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT), ISSN: 2221-0741, Vol. 1, No. 2, 39-43, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the need for geospatial consumers (either humans or
machines) to visualize multicolored elevation contour poly lines with respect
their different contour intervals and control the visual portrayal of the data
with which they work. The current OpenGIS Web Map Service (WMS) specification
supports the ability for an information provider to specify very basic styling
options by advertising a preset collection of visual portrayals for each
available data set. However, while a WMS currently can provide the user with a
choice of style options, the WMS can only tell the user the name of each style.
It cannot tell the user what portrayal will look like on the map. More
importantly, the user has no way of defining their own styling rules. The
ability for a human or machine client to define these rules requires a styling
language that the client and server can both understand. Defining this
language, called the StyledLayerDescriptor (SLD), is the main focus of this
paper, and it can be used to portray the output of Web Map Servers, Web Feature
Servers and Web Coverage Servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0824</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0824</id><created>2011-04-04</created><authors><author><keyname>Ranka</keyname><forenames>Deepesh</forenames></author><author><keyname>Rana</keyname><forenames>Ashwani K.</forenames></author><author><keyname>Yadav</keyname><forenames>Rakesh Kumar</forenames></author><author><keyname>Yadav</keyname><forenames>Kamalesh</forenames></author><author><keyname>Giri</keyname><forenames>Devendra</forenames></author></authors><title>Performance evaluation of FD-SOI Mosfets for different metal gate work
  function</title><categories>cs.OH</categories><comments>14 pages,12 figures,International Journal of VLSI design &amp;
  Communication Systems (VLSICS) Vol.2, No.1, March 2011</comments><journal-ref>International Journal of VLSI design &amp; Communication Systems
  (VLSICS) Vol.2, No.1, March 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Fully depleted (FD) Silicon on Insulator (SOI) metal oxide Field Effect
Transistor (MOSFET) Is the Leading Contender for Sun 65nm Regime. This paper
presents a study of effects of work functions of metal gate on the performance
of FD-SOI MOSFET. Sentaurus TCAD simulation tool is used to investigate the
effect of work function of gates ont he performance FDSOI MOSFET. Specific
channel length of the device that had been concentrated is 25nm. From
simulation we observed that by changing the work function of the metal gates of
FD-SOI MOSFET we can change the threshold voltage. Hence by using this
technique we can set the appropriate threshold voltage of FD-SOI MOSFET at same
voltage and we can decrease the leakage current, gate tunneling current and
short channel effects and increase drive current.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0834</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0834</id><created>2011-04-05</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Hoessler</keyname><forenames>Bernard</forenames></author><author><keyname>Guibert</keyname><forenames>Matthieu</forenames></author></authors><title>Haptic devices and objects, robots and mannequin simulation in a CAD-CAM
  software: eM-Virtual Desktop</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>M\'ecanique \&amp; Industries 5, 2 (2004) 189-197</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the development of a new software in order to manage
objects, robots and mannequins in using the possibilities given by the haptic
feedback of the Phantom desktop devices. The haptic device provides 6
positional degrees of freedom sensing but three degrees force feedback. This
software called eM-Virtual Desktop is integrated in the Tecnomatix's solution
called eM-Workplace. The eM-Workplace provides powerful solutions for planning
and designing of complex assembly facilities, lines and workplaces. In the
digital mockup context, the haptic interfaces can be used to reduce the
development cycle of products. Three different loops are used to manage the
graphic, the collision detection and the haptic feedback according to theirs
own frequencies. The developed software is currently tested in industrial
context by a European automotive constructor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0839</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0839</id><created>2011-04-05</created><authors><author><keyname>Ma</keyname><forenames>Ruina</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN, DIE</affiliation></author></authors><title>A framework of motion capture system based human behaviours simulation
  for ergonomic analysis</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>14th International Conference on Human-Computer Interaction,
  Orlando : United States (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing of computer capabilities, Computer aided ergonomics (CAE)
offers new possibilities to integrate conventional ergonomic knowledge and to
develop new methods into the work design process. As mentioned in [1],
different approaches have been developed to enhance the efficiency of the
ergonomic evaluation. Ergonomic expert systems, ergonomic oriented information
systems, numerical models of human, etc. have been implemented in numerical
ergonomic software. Until now, there are ergonomic software tools available,
such as Jack, Ergoman, Delmia Human, 3DSSPP, and Santos, etc. [2-4]. The main
functions of these tools are posture analysis and posture prediction. In the
visualization part, Jack and 3DSSPP produce results to visualize virtual human
tasks in 3-dimensional, but without realistic physical properties. Nowadays,
with the development of computer technology, the simulation of physical world
is paid more attention. Physical engines [5] are used more and more in computer
game (CG) field. The advantage of physical engine is the nature physical world
environment simulation. The purpose of our research is to use the CG technology
to create a virtual environment with physical properties for ergonomic analysis
of virtual human.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0840</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0840</id><created>2011-04-05</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Moroz</keyname><forenames>Guillaume</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Uniqueness domains and non singular assembly mode changing trajectories</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>International Conference on Robotics and Automation, Shanghai :
  China (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel robots admit generally several solutions to the direct kinematics
problem. The aspects are associated with the maximal singularity free domains
without any singular configurations. Inside these regions, some trajectories
are possible between two solutions of the direct kinematic problem without
meeting any type of singularity: non-singular assembly mode trajectories. An
established condition for such trajectories is to have cusp points inside the
joint space that must be encircled. This paper presents an approach based on
the notion of uniqueness domains to explain this behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0843</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0843</id><created>2011-04-05</created><updated>2011-06-03</updated><authors><author><keyname>Gao</keyname><forenames>Jian</forenames></author><author><keyname>Yin</keyname><forenames>Minghao</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Phase Transitions in Knowledge Compilation: an Experimental Study</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phase transitions in many complex combinational problems have been widely
studied in the past decade. In this paper, we investigate phase transitions in
the knowledge compilation empirically, where DFA, OBDD and d-DNNF are chosen as
the target languages to compile random k-SAT instances. We perform intensive
experiments to analyze the sizes of compilation results and draw the following
conclusions: there exists an easy-hard-easy pattern in compilations; the peak
point of sizes in the pattern is only related to the ratio of the number of
clauses to that of variables when k is fixed, regardless of target languages;
most sizes of compilation results increase exponentially with the number of
variables growing, but there also exists a phase transition that separates a
polynomial-increment region from the exponential-increment region; Moreover, we
explain why the phase transition in compilations occurs by analyzing
microstructures of DFAs, and conclude that a kind of solution
interchangeability with more than 2 variables has a sharp transition near the
peak point of the easy-hard-easy pattern, and thus it has a great impact on
sizes of DFAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0848</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0848</id><created>2011-04-05</created><authors><author><keyname>Babu</keyname><forenames>Ajesh</forenames></author><author><keyname>Limaye</keyname><forenames>Nutan</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>Jaikumar</forenames></author><author><keyname>Varma</keyname><forenames>Girish</forenames></author></authors><title>Streaming algorithms for language recognition problems</title><categories>cs.DS cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of the following problems in the streaming model.
  Membership testing for \DLIN We show that every language in \DLIN\ can be
recognised by a randomized one-pass $O(\log n)$ space algorithm with inverse
polynomial one-sided error, and by a deterministic p-pass $O(n/p)$ space
algorithm. We show that these algorithms are optimal.
  Membership testing for \LL$(k)$ For languages generated by \LL$(k)$ grammars
with a bound of $r$ on the number of nonterminals at any stage in the left-most
derivation, we show that membership can be tested by a randomized one-pass
$O(r\log n)$ space algorithm with inverse polynomial (in $n$) one-sided error.
  Membership testing for \DCFL We show that randomized algorithms as efficient
as the ones described above for \DLIN\ and $\LL(k)$ (which are subclasses of
\DCFL) cannot exist for all of \DCFL: there is a language in \VPL\ (a subclass
of \DCFL) for which any randomized p-pass algorithm with error bounded by
$\epsilon &lt; 1/2$ must use $\Omega(n/p)$ space.
  Degree sequence problem We study the problem of determining, given a sequence
$d_1, d_2,..., d_n$ and a graph $G$, whether the degree sequence of $G$ is
precisely $d_1, d_2,..., d_n$. We give a randomized one-pass $O(\log n)$ space
algorithm with inverse polynomial one-sided error probability. We show that our
algorithms are optimal.
  Our randomized algorithms are based on the recent work of Magniez et al.
\cite{MMN09}; our lower bounds are obtained by considering related
communication complexity problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0862</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0862</id><created>2011-04-05</created><updated>2012-06-06</updated><authors><author><keyname>Stavrou</keyname><forenames>Photios A.</forenames></author><author><keyname>Charalambous</keyname><forenames>Charalambos D.</forenames></author></authors><title>Causal Rate Distortion Function and Relations to Filtering Theory</title><categories>cs.IT math.IT</categories><comments>8 pages; 3 figures; Presented in 20th International Symposium on
  Mathematical Theory of Networks and Systems (MTNS 2012)</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A causal rate distortion function is defined, its solution is described, and
its relation to filtering theory is discussed. The relation to filtering is
obtained via a causal constraint imposed on the reconstruction kernel to be
realizable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0867</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0867</id><created>2011-04-05</created><authors><author><keyname>Olteanu</keyname><forenames>Dan</forenames></author><author><keyname>Zavodny</keyname><forenames>Jakub</forenames></author></authors><title>Factorised Representations of Query Results</title><categories>cs.DB cs.DS</categories><comments>44 pages, 13 figures</comments><acm-class>H.2.3; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Query tractability has been traditionally defined as a function of input
database and query sizes, or of both input and output sizes, where the query
result is represented as a bag of tuples. In this report, we introduce a
framework that allows to investigate tractability beyond this setting. The key
insight is that, although the cardinality of a query result can be exponential,
its structure can be very regular and thus factorisable into a nested
representation whose size is only polynomial in the size of both the input
database and query.
  For a given query result, there may be several equivalent representations,
and we quantify the regularity of the result by its readability, which is the
minimum over all its representations of the maximum number of occurrences of
any tuple in that representation. We give a characterisation of
select-project-join queries based on the bounds on readability of their results
for any input database. We complement it with an algorithm that can find
asymptotically optimal upper bounds and corresponding factorised
representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0871</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0871</id><created>2011-04-05</created><updated>2012-01-09</updated><authors><author><keyname>van Honschoten</keyname><forenames>Joost</forenames></author><author><keyname>de Jong</keyname><forenames>Henri</forenames></author><author><keyname>Koelmans</keyname><forenames>Wabe W.</forenames></author><author><keyname>Parnell</keyname><forenames>Thomas P.</forenames></author><author><keyname>Zaboronski</keyname><forenames>Oleg V.</forenames></author></authors><title>Information Storage and Retrieval for Probe Storage using Optical
  Diffraction Patterns</title><categories>cs.IT cs.IR math.IT physics.optics</categories><comments>14 pages, 11 figures. Version 2: minor misprints corrected,
  experimental section expanded</comments><journal-ref>Journal of Applied Physics, vol. 110, 104309 (2011)</journal-ref><doi>10.1063/1.3657945</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel method for fast information retrieval from a probe storage device is
considered. It is shown that information can be stored and retrieved using the
optical diffraction patterns obtained by the illumination of a large array of
cantilevers by a monochromatic light source. In thermo-mechanical probe
storage, the information is stored as a sequence of indentations on the polymer
medium. To retrieve the information, the array of probes is actuated by
applying a bending force to the cantilevers. Probes positioned over
indentations experience deflection by the depth of the indentation, probes over
the flat media remain un-deflected. Thus the array of actuated probes can be
viewed as an irregular optical grating, which creates a data-dependent
diffraction pattern when illuminated by laser light. We develop a low
complexity modulation scheme, which allows the extraction of information stored
in the pattern of indentations on the media from Fourier coefficients of the
intensity of the diffraction pattern. We then derive a low-complexity maximum
likelihood sequence detection algorithm for retrieving the user information
from the Fourier coefficients. The derivation of both the modulation and the
detection schemes is based on the Fraunhofer formula for data-dependent
diffraction patterns. We show that for as long as the Fresnel number F&lt;0.1, the
optimal channel detector derived from Fraunhofer diffraction theory does not
suffer any significant performance degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0872</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0872</id><created>2011-04-05</created><updated>2012-06-15</updated><authors><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>Possibilities and impossibilities in Kolmogorov complexity extraction</title><categories>cs.CC</categories><comments>Revised form of survey paper published in SIGACT News, Dec. 2010. A
  few corrections and references have been added</comments><msc-class>68Q30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomness extraction is the process of constructing a source of randomness
of high quality from one or several sources of randomness of lower quality. The
problem can be modeled using probability distributions and min-entropy to
measure their quality and also by using individual strings and Kolmogorov
complexity to measure their quality. Complexity theorists are more familiar
with the first approach. In this paper we survey the second approach. We
present the connection between extractors and Kolmogorov extractors and the
basic positive and negative results concerning Kolmogorov complexity
extraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0882</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0882</id><created>2011-04-05</created><authors><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>Xheal: Localized Self-healing using Expanders</title><categories>cs.DS cs.DC cs.NI</categories><comments>A shorter version of this to be presented at PODC, 2011, San Jose, CA</comments><acm-class>C.2.1; C.2.4; C.4; E.1; G.2.2; G.3; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of self-healing in reconfigurable networks (e.g.
peer-to-peer and wireless mesh networks) that are under repeated attack by an
omniscient adversary and propose a fully distributed algorithm, Xheal that
maintains good expansion and spectral properties of the network, also keeping
the network connected. Moreover, Xheal does this while allowing only low
stretch and degree increase per node. Thus, the algorithm heals global
properties while only doing local changes and using only local information.
  Our work improves over the self-healing algorithms 'Forgiving tree'[PODC
2008] and 'Forgiving graph'[PODC 2009] (using a similar model) in that we are
able to give guarantees on degree and stretch, while at the same time
preserving the expansion and spectral properties of the network. These repairs
preserve the invariants in the following sense. At any point in the algorithm,
the expansion of the graph will be either `better' than the expansion of the
graph formed by considering only the adversarial insertions (not the
adversarial deletions) or the expansion will be, at least, a constant. Also,
the stretch i.e. the distance between any pair of nodes in the healed graph is
no more than a $O(\log n)$ factor. Similarly, at any point, a node $v$ whose
degree would have been $d$ in the graph with adversarial insertions only, will
have degree at most $O(\kappa d)$ in the actual graph, for a small parameter
$\kappa$. We also provide bounds on the second smallest eigenvalue of the
Laplacian which captures key properties such as mixing time, conductance,
congestion in routing etc. Our distributed data structure has low amortized
latency and bandwidth requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0888</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0888</id><created>2011-04-05</created><authors><author><keyname>Bresler</keyname><forenames>Guy</forenames></author><author><keyname>Cartwright</keyname><forenames>Dustin</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Settling the feasibility of interference alignment for the MIMO
  interference channel: the symmetric square case</title><categories>cs.IT math.IT</categories><comments>13 pages, no figures</comments><report-no>Mittag-Leffler-2011spring</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining the feasibility conditions for vector space interference
alignment in the K-user MIMO interference channel with constant channel
coefficients has attracted much recent attention yet remains unsolved. The main
result of this paper is restricted to the symmetric square case where all
transmitters and receivers have N antennas, and each user desires d transmit
dimensions. We prove that alignment is possible if and only if the number of
antennas satisfies N&gt;= d(K+1)/2. We also show a necessary condition for
feasibility of alignment with arbitrary system parameters. An algebraic
geometry approach is central to the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0906</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0906</id><created>2011-04-05</created><updated>2011-07-26</updated><authors><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author></authors><title>Applications of Tauberian Theorem for High-SNR Analysis of Performance
  over Fading Channels</title><categories>cs.IT math.IT</categories><comments>22 pages, 4 figures, submitted to IEEE Transactions on Wireless
  Communications</comments><doi>10.1109/TWC.2011.110811.110613</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives high-SNR asymptotic average error rates over fading
channels by relating them to the outage probability, under mild assumptions.
The analysis is based on the Tauberian theorem for Laplace-Stieltjes transforms
which is grounded on the notion of regular variation, and applies to a wider
range of channel distributions than existing approaches. The theory of regular
variation is argued to be the proper mathematical framework for finding
sufficient and necessary conditions for outage events to dominate high-SNR
error rate performance. It is proved that the diversity order being $d$ and the
cumulative distribution function (CDF) of the channel power gain having
variation exponent $d$ at 0 imply each other, provided that the instantaneous
error rate is upper-bounded by an exponential function of the instantaneous
SNR. High-SNR asymptotic average error rates are derived for specific
instantaneous error rates. Compared to existing approaches in the literature,
the asymptotic expressions are related to the channel distribution in a much
simpler manner herein, and related with outage more intuitively. The high-SNR
asymptotic error rate is also characterized under diversity combining schemes
with the channel power gain of each branch having a regularly varying CDF.
Numerical results are shown to corroborate our theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0919</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0919</id><created>2011-04-05</created><updated>2013-04-02</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author><author><keyname>Hiron</keyname><forenames>Mathias</forenames></author></authors><title>Locating regions in a sequence under density constraints</title><categories>cs.DS</categories><comments>17 pages, 8 figures; v2: minor revisions, additional explanations; to
  appear in SIAM Journal on Computing</comments><journal-ref>SIAM Journal on Computing 42 (2013), no. 3, 1201-1215</journal-ref><doi>10.1137/110830605</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several biological problems require the identification of regions in a
sequence where some feature occurs within a target density range: examples
including the location of GC-rich regions, identification of CpG islands, and
sequence matching. Mathematically, this corresponds to searching a string of 0s
and 1s for a substring whose relative proportion of 1s lies between given lower
and upper bounds. We consider the algorithmic problem of locating the longest
such substring, as well as other related problems (such as finding the shortest
substring or a maximal set of disjoint substrings). For locating the longest
such substring, we develop an algorithm that runs in O(n) time, improving upon
the previous best-known O(n log n) result. For the related problems we develop
O(n log log n) algorithms, again improving upon the best-known O(n log n)
results. Practical testing verifies that our new algorithms enjoy significantly
smaller time and memory footprints, and can process sequences that are orders
of magnitude longer as a result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0923</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0923</id><created>2011-04-05</created><updated>2012-02-13</updated><authors><author><keyname>Gregory</keyname><forenames>Steve</forenames></author></authors><title>Ordered community structure in networks</title><categories>physics.soc-ph cs.SI</categories><comments>This is an extended preprint version that includes an extra example:
  the college football network as an ordered (spatial) network. Further
  improvements, not included here, appear in the journal version. Original
  title changed (from &quot;Ordered and continuous community structure in networks&quot;)
  to match journal version</comments><journal-ref>Physica A 391 (2012) 2752-2763</journal-ref><doi>10.1016/j.physa.2011.12.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure in networks is often a consequence of homophily, or
assortative mixing, based on some attribute of the vertices. For example,
researchers may be grouped into communities corresponding to their research
topic. This is possible if vertex attributes have discrete values, but many
networks exhibit assortative mixing by some continuous-valued attribute, such
as age or geographical location. In such cases, no discrete communities can be
identified. We consider how the notion of community structure can be
generalized to networks that are based on continuous-valued attributes: in
general, a network may contain discrete communities which are ordered according
to their attribute values. We propose a method of generating synthetic ordered
networks and investigate the effect of ordered community structure on the
spread of infectious diseases. We also show that community detection algorithms
fail to recover community structure in ordered networks, and evaluate an
alternative method using a layout algorithm to recover the ordering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0924</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0924</id><created>2011-04-05</created><updated>2011-05-31</updated><authors><author><keyname>Vlasov</keyname><forenames>Alexander Yu.</forenames></author></authors><title>ReveR: Software Simulator of Reversible Processor with Stack</title><categories>cs.ET cs.AR</categories><comments>LaTeX, 7 pages, no figures, 3 tables, v2: spelling and grammar
  corrected; project url http://friedmann.objectis.net/Members/vlasov/rever</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A software model of a reversible processor ReveR with the stack is discussed
in this paper. An architecture, the minimal set of elementary reversible
operations together with an implementation of the basic control flow structures
and procedures calls using simple assembler language are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0942</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0942</id><created>2011-04-05</created><authors><author><keyname>Guo</keyname><forenames>Stephen</forenames></author><author><keyname>Wang</keyname><forenames>Mengqiu</forenames></author><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author></authors><title>The Role of Social Networks in Online Shopping: Information Passing,
  Price of Trust, and Consumer Choice</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>ACM Conference on Electronic Commerce 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While social interactions are critical to understanding consumer behavior,
the relationship between social and commerce networks has not been explored on
a large scale. We analyze Taobao, a Chinese consumer marketplace that is the
world's largest e-commerce website. What sets Taobao apart from its competitors
is its integrated instant messaging tool, which buyers can use to ask sellers
about products or ask other buyers for advice. In our study, we focus on how an
individual's commercial transactions are embedded in their social graphs. By
studying triads and the directed closure process, we quantify the presence of
information passing and gain insights into when different types of links form
in the network.
  Using seller ratings and review information, we then quantify a price of
trust. How much will a consumer pay for transaction with a trusted seller? We
conclude by modeling this consumer choice problem: if a buyer wishes to
purchase a particular product, how does (s)he decide which store to purchase it
from? By analyzing the performance of various feature sets in an information
retrieval setting, we demonstrate how the social graph factors into
understanding consumer behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0954</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0954</id><created>2011-04-05</created><authors><author><keyname>Wang</keyname><forenames>Chenwei</forenames></author><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Multiple Unicast Capacity of 2-Source 2-Sink Networks</title><categories>cs.IT math.IT</categories><comments>6 pages, 7 figures, submitted to IEEE Globecom 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the sum capacity of multiple unicasts in wired and wireless multihop
networks. With 2 source nodes and 2 sink nodes, there are a total of 4
independent unicast sessions (messages), one from each source to each sink node
(this setting is also known as an X network). For wired networks with arbitrary
connectivity, the sum capacity is achieved simply by routing. For wireless
networks, we explore the degrees of freedom (DoF) of multihop X networks with a
layered structure, allowing arbitrary number of hops, and arbitrary
connectivity within each hop. For the case when there are no more than two
relay nodes in each layer, the DoF can only take values 1, 4/3, 3/2 or 2, based
on the connectivity of the network, for almost all values of channel
coefficients. When there are arbitrary number of relays in each layer, the DoF
can also take the value 5/3 . Achievability schemes incorporate linear
forwarding, interference alignment and aligned interference neutralization
principles. Information theoretic converse arguments specialized for the
connectivity of the network are constructed based on the intuition from linear
dimension counting arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0961</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0961</id><created>2011-04-05</created><updated>2011-09-26</updated><authors><author><keyname>Levine</keyname><forenames>Lionel</forenames></author><author><keyname>Stange</keyname><forenames>Katherine E.</forenames></author></authors><title>How to make the most of a shared meal: plan the last bite first</title><categories>cs.GT math.CO</categories><comments>AMS Latex, 20 pages, 5 figures (1 colour figure); v2 adds references,
  v3 incorporates referees' comments. To appear in American Math. Monthly</comments><msc-class>91A10, 91A18, 91A05, 91A50</msc-class><journal-ref>American Mathematical Monthly, 119-7 (2012), 550-565</journal-ref><doi>10.4169/amer.math.monthly.119.07.550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If you are sharing a meal with a companion, how best to make sure you get
your favourite mouthfuls? Ethiopian Dinner is a game in which two players take
turns eating morsels from a common plate. Each morsel comes with a pair of
utility values measuring its tastiness to the two players. Kohler and
Chandrasekaharan discovered a good strategy -- a subgame perfect equilibrium,
to be exact -- for this game. We give a new visual proof of their result. The
players arrive at the equilibrium by figuring out their last move first and
working backward. We conclude that it's never too early to start thinking about
dessert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0988</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0988</id><created>2011-04-05</created><authors><author><keyname>Kim</keyname><forenames>Dae San</forenames></author><author><keyname>Kim</keyname><forenames>Dong Chan</forenames></author><author><keyname>Hyun</keyname><forenames>Jong Yoon</forenames></author></authors><title>Simple proofs for duality of generalized minimum poset weights and
  weight distributions of (Near-)MDS poset codes</title><categories>cs.IT math.IT</categories><comments>No comments</comments><msc-class>94B99, 05B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1991, Wei introduced generalized minimum Hamming weights for linear codes
and showed their monotonicity and duality. Recently, several authors extended
these results to the case of generalized minimum poset weights by using
different methods. Here, we would like to prove the duality by using matroid
theory. This gives yet another and very simple proof of it. In particular, our
argument will make it clear that the duality follows from the well-known
relation between the rank function and the corank function of a matroid. In
addition, we derive the weight distributions of linear MDS and Near-MDS poset
codes in the same spirit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0991</identifier>
 <datestamp>2012-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0991</id><created>2011-04-05</created><updated>2012-06-16</updated><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Efficient Algorithm for Detection of Selfish Packet Dropping Nodes in
  Wireless Mesh Networks</title><categories>cs.CR cs.NI</categories><comments>This paper is withdrawn since the results presented in Figure 7 are
  not found to be holding good under certain network conditions. We have made a
  mathematical analysis of the false alarm rate and are trying to
  cross-correlate the simulation results with the mathematical model</comments><journal-ref>International Journal of Computer Information Systems and
  Industrial Management Applications, Vol 3 (2011), pp. 363 - 370</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a wireless mesh network (WMN), high speed routers equipped with advanced
antennas, communicate with each other in a multi-hop fashion over wireless
channels and form a broadband backhaul. WMNs provide reliable connectivity and
fault-tolerance, as each node is connected to several other nodes. If a node
fails due to hardware problems, its neighbors can find another route. Extra
capacity can be achieved by introducing additional nodes in the network.
However, the throughput of a WMN may be severely degraded due to presence of
some selfish routers that avoid forwarding packets for other nodes even as they
send their own traffic through the network. This paper presents an algorithm
for detection of selfish nodes in a WMN that uses statistical theory of
inference for reliable clustering of the nodes. Simulation results show that
the algorithm has a high detection rate and a low rate of false positives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.0992</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.0992</id><created>2011-04-05</created><updated>2011-09-02</updated><authors><author><keyname>Razaviyayn</keyname><forenames>Meisam</forenames></author><author><keyname>Lyubeznik</keyname><forenames>Gennady</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author></authors><title>On the Degrees of Freedom Achievable Through Interference Alignment in a
  MIMO Interference Channel</title><categories>cs.IT math.AG math.IT</categories><doi>10.1109/TSP.2011.2173683</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a K-user flat fading MIMO interference channel where the k-th
transmitter (or receiver) is equipped with M_k (respectively N_k) antennas. If
a large number of statistically independent channel extensions are allowed
either across time or frequency, the recent work [1] suggests that the total
achievable degrees of freedom (DoF) can be maximized via interference
alignment, resulting in a total DoF that grows linearly with K even if M_k and
N_k are bounded. In this work we consider the case where no channel extension
is allowed, and establish a general condition that must be satisfied by any
degrees of freedom tuple (d_1, d2, ..., d_K) achievable through linear
interference alignment. For a symmetric system with M_k = M, N_k = N, d_k = d
for all k, this condition implies that the total achievable DoF cannot grow
linearly with K, and is in fact no more than K(M + N)=(K + 1). We also show
that this bound is tight when the number of antennas at each transceiver is
divisible by the number of data streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1007</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1007</id><created>2011-04-06</created><updated>2012-08-01</updated><authors><author><keyname>Tsang</keyname><forenames>Y. Ming</forenames></author><author><keyname>Poon</keyname><forenames>Ada S. Y.</forenames></author><author><keyname>Addepalli</keyname><forenames>Sateesh</forenames></author></authors><title>Coding the Beams: Improving Beamforming Training in mmWave Communication
  System</title><categories>cs.NI</categories><comments>6 pages, 10 figures, in GLOBECOM 2011. (Figure 8 and 9 are updated)</comments><msc-class>94A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mmWave communication system is operating at a regime with high number of
antennas and very limited number of RF analog chains. Large number of antennas
are used to extend the communication range for recovering the high path loss
while fewer RF analog chains are designed to reduce transmit and processing
power and hardware complexity. In this regime, typical MIMO algorithms are not
applicable.
  Before any communication starts, devices are needed to align their beam
pointing angles towards each other. An efficient searching protocol to obtain
the best beam angle pair is therefore needed. It is called BeamForming (BF)
training protocol.
  This paper presents a new BF training technique called beam coding. Each beam
angle is assigned unique signature code. By coding multiple beam angles and
steering at their angles simultaneously in a training packet, the best beam
angle pair can be obtained in a few packets. The proposed BF training technique
not only shows the robustness in non-line-of-sight environment, but also
provides very flat power variations within a packet in contrast to the IEEE
802.11ad standard whose scheme may lead to large dynamic range of signals due
to beam angles varying across a training packet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1010</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1010</id><created>2011-04-06</created><authors><author><keyname>Galtsev</keyname><forenames>Aleksey A.</forenames></author><author><keyname>Sukhov</keyname><forenames>Andrei M.</forenames></author></authors><title>Network attack detection at flow level</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new method for detecting unauthorized network
intrusions, based on a traffic flow model and Cisco NetFlow protocol
application. The method developed allows us not only to detect the most common
types of network attack (DDoS and port scanning), but also to make a list of
trespassers' IP-addresses. Therefore, this method can be applied in intrusion
detection systems, and in those systems which lock these IP-addresses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1014</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1014</id><created>2011-04-06</created><updated>2012-01-21</updated><authors><author><keyname>Bashar</keyname><forenames>Shafi</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author><author><keyname>Xiao</keyname><forenames>Chengshan</forenames></author></authors><title>On Secrecy Rate Analysis of MIMO Wiretap Channels Driven by
  Finite-Alphabet Input</title><categories>cs.IT math.IT</categories><comments>21 pages, 5 figures, Submitted to IEEE Transactions on
  Communications, April 4, 2011. Revision submitted on December 21, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates the effect of finite-alphabet source input on the
secrecy rate of a multi-antenna wiretap system. Existing works have
characterized maximum achievable secrecy rate or secrecy capacity for single
and multiple antenna systems based on Gaussian source signals and secrecy code.
Despite the impracticality of Gaussian sources, the compact closed-form
expression of mutual information between linear channel Gaussian input and
corresponding output has led to broad application of Gaussian input assumption
in physical secrecy analysis. For practical considerations, we study the effect
of finite discrete-constellation on the achievable secrecy rate of
multiple-antenna wire-tap channels. Our proposed precoding scheme converts the
multi-antenna system into a bank of parallel channels. Based on this precoding
strategy, we propose a decentralized power allocation algorithm based on dual
decomposition for maximizing the achievable secrecy rate. In addition, we
analyze the achievable secrecy rate for finite-alphabet inputs in low and high
SNR cases. Our results demonstrate substantial difference in secrecy rate
between systems given finite-alphabet inputs and systems with Gaussian inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1031</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1031</id><created>2011-04-06</created><authors><author><keyname>Heikalabad</keyname><forenames>Saeed Rasouli</forenames></author><author><keyname>Rasouli</keyname><forenames>Hossein</forenames></author><author><keyname>Nematy</keyname><forenames>Farhad</forenames></author><author><keyname>Rahmani</keyname><forenames>Naeim</forenames></author></authors><title>QEMPAR: QoS and Energy Aware Multi-Path Routing Algorithm for Real-Time
  Applications in Wireless Sensor Networks</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Science Issues, Vol. 8, Issue 1,
  January 2011, 466-471</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Enabling real time applications in wireless sensor networks requires certain
delay and bandwidth which pose more challenges in the design of routing
protocols. The algorithm that is used for packet routing in such applications
should be able to establish a tradeoff between end to end delay parameter and
energy consumption. In this paper, we propose a new multi path routing
algorithm for real time applications in wireless sensor networks namely QEMPAR
which is QoS aware and can increase the network lifetime. Simulation results
show that the proposed algorithm is more efficient than previous algorithms in
providing quality of service requirements of real-time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1034</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1034</id><created>2011-04-06</created><updated>2012-01-27</updated><authors><author><keyname>Ebbing</keyname><forenames>Johannes</forenames></author><author><keyname>Lohmann</keyname><forenames>Peter</forenames></author></authors><title>Complexity of Model Checking for Modal Dependence Logic</title><categories>cs.LO cs.CC</categories><comments>25 pages</comments><acm-class>F.2.2; F.4.1; D.2.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Modal dependence logic (MDL) was introduced recently by V\&quot;a\&quot;an\&quot;anen. It
enhances the basic modal language by an operator =(). For propositional
variables p_1,...,p_n the atomic formula =(p_1,...,p_(n-1),p_n) intuitively
states that the value of p_n is determined solely by those of p_1,...,p_(n-1).
We show that model checking for MDL formulae over Kripke structures is
NP-complete and further consider fragments of MDL obtained by restricting the
set of allowed propositional and modal connectives. It turns out that several
fragments, e.g., the one without modalities or the one without propositional
connectives, remain NP-complete. We also consider the restriction of MDL where
the length of each single dependence atom is bounded by a number that is fixed
for the whole logic. We show that the model checking problem for this bounded
MDL is still NP-complete. We additionally extend MDL by allowing classical
disjunction - introduced by Sevenster - besides dependence disjunction and show
that classical disjunction is always at least as computationally bad as bounded
arity dependence atoms and in some cases even worse, e.g., the fragment with
nothing but the two disjunctions is NP-complete. Furthermore we almost
completely classifiy the computational complexity of the model checking problem
for all restrictions of propositional and modal operators for both unbounded as
well as bounded MDL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1041</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1041</id><created>2011-04-06</created><updated>2012-01-18</updated><authors><author><keyname>Li</keyname><forenames>Xiaodong</forenames></author></authors><title>Compressed Sensing and Matrix Completion with Constant Proportion of
  Corruptions</title><categories>cs.IT math.IT stat.ML</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve existing results in the field of compressed sensing and matrix
completion when sampled data may be grossly corrupted. We introduce three new
theorems. 1) In compressed sensing, we show that if the m \times n sensing
matrix has independent Gaussian entries, then one can recover a sparse signal x
exactly by tractable \ell1 minimimization even if a positive fraction of the
measurements are arbitrarily corrupted, provided the number of nonzero entries
in x is O(m/(log(n/m) + 1)). 2) In the very general sensing model introduced in
&quot;A probabilistic and RIPless theory of compressed sensing&quot; by Candes and Plan,
and assuming a positive fraction of corrupted measurements, exact recovery
still holds if the signal now has O(m/(log^2 n)) nonzero entries. 3) Finally,
we prove that one can recover an n \times n low-rank matrix from m corrupted
sampled entries by tractable optimization provided the rank is on the order of
O(m/(n log^2 n)); again, this holds when there is a positive fraction of
corrupted samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1044</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1044</id><created>2011-04-06</created><updated>2011-04-08</updated><authors><author><keyname>Leung</keyname><forenames>Ming Lam</forenames></author></authors><title>Fixed Parameter Tractable Algorithm for Firefighting Problem</title><categories>cs.DS</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The firefighter problem is defined as below. A fire initially breaks out at a
vertex r on a graph G. In each step, a firefighter chooses to protect one
vertex, which is not yet burnt. And the fire spreads out to its unprotected
neighboring vertices afterwards. The objective of the problem is to choose a
sequence of vertices to protect, in order to save maximum number of vertices
from the fire.
  In this paper, we will introduce a parameter k into the firefighter problem
and give several FPT algorithms using a random separation technique of Cai,
Chan and Chan. We will prove firefighter problem is FPT on general graph if we
take total number of vertices burnt to be a parameter. If we parameterize the
number of protected vertices, we discover several FPT algorithms of the
firefighter problem on degree bounded graph and unicyclic graph. Furthermore,
we also study the firefighter problem on weighted and valued graph, and the
problem with multiple fire sources on degree-bounded graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1045</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1045</id><created>2011-04-06</created><updated>2012-07-18</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Hils</keyname><forenames>Martin</forenames></author><author><keyname>Krimkevich</keyname><forenames>Alex</forenames></author></authors><title>Tractable Set Constraints</title><categories>cs.AI cs.CC cs.LO</categories><comments>An extended abstract of this paper appears in Proceedings of
  IJCAI-11. The third author left the author team for the preparation of the
  journal version. Several mistakes in the proofs have been removed</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many fundamental problems in artificial intelligence, knowledge
representation, and verification involve reasoning about sets and relations
between sets and can be modeled as set constraint satisfaction problems (set
CSPs). Such problems are frequently intractable, but there are several
important set CSPs that are known to be polynomial-time tractable. We introduce
a large class of set CSPs that can be solved in quadratic time. Our class,
which we call EI, contains all previously known tractable set CSPs, but also
some new ones that are of crucial importance for example in description logics.
The class of EI set constraints has an elegant universal-algebraic
characterization, which we use to show that every set constraint language that
properly contains all EI set constraints already has a finite sublanguage with
an NP-hard constraint satisfaction problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1057</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1057</id><created>2011-04-06</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Bounds on the Capacity of the Relay Channel with Noncausal State at
  Source</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory, 54 pages, 6
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a three-terminal state-dependent relay channel with the channel
state available non-causally at only the source. Such a model may be of
interest for node cooperation in the framework of cognition, i.e.,
collaborative signal transmission involving cognitive and non-cognitive radios.
We study the capacity of this communication model. One principal problem is
caused by the relay's not knowing the channel state. For the discrete
memoryless (DM) model, we establish two lower bounds and an upper bound on
channel capacity. The first lower bound is obtained by a coding scheme in which
the source describes the state of the channel to the relay and destination,
which then exploit the gained description for a better communication of the
source's information message. The coding scheme for the second lower bound
remedies the relay's not knowing the states of the channel by first computing,
at the source, the appropriate input that the relay would send had the relay
known the states of the channel, and then transmitting this appropriate input
to the relay. The relay simply guesses the sent input and sends it in the next
block. The upper bound is non trivial and it accounts for not knowing the state
at the relay and destination. For the general Gaussian model, we derive lower
bounds on the channel capacity by exploiting ideas in the spirit of those we
use for the DM model; and we show that these bounds are optimal for small and
large noise at the relay irrespective to the strength of the interference.
Furthermore, we also consider a special case model in which the source input
has two components one of which is independent of the state. We establish a
better upper bound for both DM and Gaussian cases and we also characterize the
capacity in a number of special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1070</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1070</id><created>2011-04-06</created><authors><author><keyname>Rad</keyname><forenames>Babak Bashari</forenames></author><author><keyname>Masrom</keyname><forenames>Maslin</forenames></author><author><keyname>Ibrahim</keyname><forenames>Suhaimi</forenames></author></authors><title>Evolution of Computer Virus Concealment and Anti-Virus Techniques: A
  Short Survey</title><categories>cs.CR</categories><journal-ref>International Journal of Computer Science Issues (IJCSI), Vol. 8,
  No. 1, 2011, pp. 113-121</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a general overview on evolution of concealment methods in
computer viruses and defensive techniques employed by anti-virus products. In
order to stay far from the anti-virus scanners, computer viruses gradually
improve their codes to make them invisible. On the other hand, anti-virus
technologies continually follow the virus tricks and methodologies to overcome
their threats. In this process, anti-virus experts design and develop new
methodologies to make them stronger, more and more, every day. The purpose of
this paper is to review these methodologies and outline their strengths and
weaknesses to encourage those are interested in more investigation on these
areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1071</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1071</id><created>2011-04-06</created><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>Analysis of Block OMP using Block RIP</title><categories>cs.IT math.IT</categories><comments>10 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Orthogonal matching pursuit (OMP) is a canonical greedy algorithm for sparse
signal reconstruction. When the signal of interest is block sparse, i.e., it
has nonzero coefficients occurring in clusters, the block version of OMP
algorithm (i.e., Block OMP) outperforms the conventional OMP. In this paper, we
demonstrate that a new notion of block restricted isometry property (Block
RIP), which is less stringent than standard restricted isometry property (RIP),
can be used for a very straightforward analysis of Block OMP. It is
demonstrated that Block OMP can exactly recover any block K-sparse signal in no
more than K steps if the Block RIP of order K+1 with a sufficiently small
isometry constant is satisfied. Using this result it can be proved that Block
OMP can yield better reconstruction properties than the conventional OMP when
the signal is block sparse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1074</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1074</id><created>2011-04-06</created><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Wang</keyname><forenames>Xiqin</forenames></author></authors><title>SAR Imaging of Moving Targets via Compressive Sensing</title><categories>cs.IT math.IT</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm based on compressive sensing (CS) is proposed for synthetic
aperture radar (SAR) imaging of moving targets. The received SAR echo is
decomposed into the sum of basis sub-signals, which are generated by
discretizing the target spatial domain and velocity domain and synthesizing the
SAR received data for every discretized spatial position and velocity
candidate. In this way, the SAR imaging problem is converted into sub-signal
selection problem. In the case that moving targets are sparsely distributed in
the observed scene, their reflectivities, positions and velocities can be
obtained by using the CS technique. It is shown that, compared with traditional
algorithms, the target image obtained by the proposed algorithm has higher
resolution and lower side-lobe while the required number of measurements can be
an order of magnitude less than that by sampling at Nyquist sampling rate.
Moreover, multiple targets with different speeds can be imaged simultaneously,
so the proposed algorithm has higher efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1075</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1075</id><created>2011-04-06</created><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>Super Critical and Sub Critical Regimes of Percolation with Secure
  Communication</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Percolation in an information-theoretically secure graph is considered where
both the legitimate and the eavesdropper nodes are distributed as Poisson point
processes. For both the path-loss and the path-loss plus fading model, upper
and lower bounds on the minimum density of the legitimate nodes (as a function
of the density of the eavesdropper nodes) required for non-zero probability of
having an unbounded cluster are derived. The lower bound is universal in
nature, i.e. the constant does not depend on the density of the eavesdropper
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1080</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1080</id><created>2011-04-06</created><authors><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author></authors><title>Approximating the Balanced Minimum Evolution Problem</title><categories>cs.DS cs.DM</categories><journal-ref>Operations Research Letters, 40/1:31--35, 2012</journal-ref><doi>10.1016/j.orl.2011.10.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a strong inapproximability result for the Balanced Minimum Evolution
Problem. Our proof also implies that the problem remains NP-hard even when
restricted to metric instances. Furthermore, we give a MST-based
2-approximation algorithm for the problem for such instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1132</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1132</id><created>2011-04-06</created><authors><author><keyname>Elhari</keyname><forenames>Kaoutar</forenames></author><author><keyname>Bounabat</keyname><forenames>Bouchaib</forenames></author></authors><title>Platform for Assessing Strategic Alignment Using Enterprise
  Architecture: Application to E-Government Process Assessment</title><categories>cs.SE</categories><comments>8 pages, 8 figures</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 1, January 2011 ISSN (Online): 1694-0814 www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an overview of S2AEA (v2) (Strategic Alignment Assessment
based on Enterprise Architecture (version2)), a platform for modelling
enterprise architecture and for assessing strategic alignment based on internal
enterprise architecture metrics. The idea of the platform is based on the fact
that enterprise architecture provides a structure for business processes and
information systems that supports them. This structure can be used to measure
the degree of consistency between business strategies and information systems.
In that sense, this paper presents a platform illustrating the role of
enterprise architecture in the strategic alignment assessment. This assessment
can be used in auditing information systems. The platform is applied to assess
an e-government process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1135</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1135</id><created>2011-04-06</created><updated>2011-05-15</updated><authors><author><keyname>Crowston</keyname><forenames>R.</forenames></author><author><keyname>Fellows</keyname><forenames>M.</forenames></author><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Jones</keyname><forenames>M.</forenames></author><author><keyname>Rosamond</keyname><forenames>F.</forenames></author><author><keyname>Thomasse</keyname><forenames>S.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>Simultaneously Satisfying Linear Equations Over $\mathbb{F}_2$: MaxLin2
  and Max-$r$-Lin2 Parameterized Above Average</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the parameterized problem \textsc{MaxLin2-AA}[$k$], we are given a system
with variables $x_1,...,x_n$ consisting of equations of the form $\prod_{i \in
I}x_i = b$, where $x_i,b \in \{-1, 1\}$ and $I\subseteq [n],$ each equation has
a positive integral weight, and we are to decide whether it is possible to
simultaneously satisfy equations of total weight at least $W/2+k$, where $W$ is
the total weight of all equations and $k$ is the parameter (if $k=0$, the
possibility is assured). We show that \textsc{MaxLin2-AA}[$k$] has a kernel
with at most $O(k^2\log k)$ variables and can be solved in time $2^{O(k\log
k)}(nm)^{O(1)}$. This solves an open problem of Mahajan et al. (2006).
  The problem \textsc{Max-$r$-Lin2-AA}[$k,r$] is the same as
\textsc{MaxLin2-AA}[$k$] with two differences: each equation has at most $r$
variables and $r$ is the second parameter. We prove a theorem on
\textsc{Max-$r$-Lin2-AA}[$k,r$] which implies that
\textsc{Max-$r$-Lin2-AA}[$k,r$] has a kernel with at most $(2k-1)r$ variables
improving a number of results including one by Kim and Williams (2010). The
theorem also implies a lower bound on the maximum of a function $f:\ \{-1,1\}^n
\rightarrow \mathbb{R}$ of degree $r$. We show applicability of the lower bound
by giving a new proof of the Edwards-Erd{\H o}s bound (each connected graph on
$n$ vertices and $m$ edges has a bipartite subgraph with at least $m/2 +
(n-1)/4$ edges) and obtaining a generalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1155</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1155</id><created>2011-04-06</created><authors><author><keyname>Mohammed</keyname><forenames>Saif Khan</forenames></author><author><keyname>Viterbo</keyname><forenames>Emanuele</forenames></author><author><keyname>Hong</keyname><forenames>Yi</forenames></author><author><keyname>Chockalingam</keyname><forenames>Ananthanarayanan</forenames></author></authors><title>Modulation Diversity in Fading Channels with Quantized Receiver</title><categories>cs.IT math.IT</categories><journal-ref>&quot;Modulation Diversity in Fading Channels with a Quantized
  Receiver,'' IEEE Transactions on Wireless Communications , vol. 11, no.1, pp.
  316-327, Jan. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the design of codes which achieve modulation
diversity in block fading single-input single-output (SISO) channels with
signal quantization at receiver and low-complexity decoding. With an
unquantized receiver, coding based on algebraic rotations is known to achieve
modulation coding diversity. On the other hand, with a quantized receiver,
algebraic rotations may not guarantee diversity. Through analysis, we propose
specific rotations which result in the codewords having equidistant
component-wise projections. We show that the proposed coding scheme achieves
maximum modulation diversity with a low-complexity minimum distance decoder and
perfect channel knowledge. Relaxing the perfect channel knowledge assumption we
propose a novel training/estimation and receiver control technique to estimate
the channel. We show that our coding/training/estimation scheme and minimum
distance decoding achieve an error probability performance similar to that
achieved with perfect channel knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1157</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1157</id><created>2011-04-06</created><authors><author><keyname>Zargham</keyname><forenames>M.</forenames></author><author><keyname>Ribeiro</keyname><forenames>A.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>A.</forenames></author><author><keyname>Ozdaglar</keyname><forenames>A.</forenames></author></authors><title>Accelerated Dual Descent for Network Optimization</title><categories>math.OC cs.SY</categories><comments>Full version of a paper of the same name to appear in the proceedings
  of American Control Conference, 2011. (8 pages, 4 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dual descent methods are commonly used to solve network optimization problems
because their implementation can be distributed through the network. However,
their convergence rates are typically very slow. This paper introduces a family
of dual descent algorithms that use approximate Newton directions to accelerate
the convergence rate of conventional dual descent. These approximate directions
can be computed using local information exchanges thereby retaining the
benefits of distributed implementations. The approximate Newton directions are
obtained through matrix splitting techniques and sparse Taylor approximations
of the inverse Hessian.We show that, similarly to conventional Newton methods,
the proposed algorithm exhibits superlinear convergence within a neighborhood
of the optimal value. Numerical analysis corroborates that convergence times
are between one to two orders of magnitude faster than existing distributed
optimization methods. A connection with recent developments that use consensus
iterations to compute approximate Newton directions is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1159</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1159</id><created>2011-04-06</created><updated>2011-04-07</updated><authors><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>LTL Control in Uncertain Environments with Probabilistic Satisfaction
  Guarantees</title><categories>math.OC cs.RO cs.SY</categories><comments>Technical Report accompanying IFAC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to generate a robot control strategy that maximizes the
probability to accomplish a task. The task is given as a Linear Temporal Logic
(LTL) formula over a set of properties that can be satisfied at the regions of
a partitioned environment. We assume that the probabilities with which the
properties are satisfied at the regions are known, and the robot can determine
the truth value of a proposition only at the current region. Motivated by
several results on partitioned-based abstractions, we assume that the motion is
performed on a graph. To account for noisy sensors and actuators, we assume
that a control action enables several transitions with known probabilities. We
show that this problem can be reduced to the problem of generating a control
policy for a Markov Decision Process (MDP) such that the probability of
satisfying an LTL formula over its states is maximized. We provide a complete
solution for the latter problem that builds on existing results from
probabilistic model checking. We include an illustrative case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1184</identifier>
 <datestamp>2016-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1184</id><created>2011-04-06</created><authors><author><keyname>Lagerstrom</keyname><forenames>Jill</forenames></author><author><keyname>Grothkopf</keyname><forenames>Uta</forenames></author></authors><title>Astronomy Librarians - Quo Vadis?</title><categories>astro-ph.IM cs.DL</categories><comments>To appear in: Future Professional Communication in Astronomy II
  (FPCA-II)</comments><doi>10.1007/978-1-4419-8369-5_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;You don't look like a librarian&quot; is a phrase we often hear in the astronomy
department or observatory library. Astronomy librarians are a breed apart, and
are taking on new and non-traditional roles as information technology evolves.
This talk will explore the future of librarians and librarianship through the
lens of the recent talks given at the sixth &quot;Libraries and Information Services
in Astronomy&quot; conference held in Pune, India in February 2010. We will explore
the librarian's universe, illustrating how librarians use new technologies to
perform such tasks as bibliometrics, how we are re-fashioning our library
spaces in an increasingly digital world and how we are confronting the brave
new world of open access, to name but a few topics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1186</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1186</id><created>2011-04-06</created><authors><author><keyname>Sedrati</keyname><forenames>Maamar</forenames></author><author><keyname>Bilami</keyname><forenames>Azeddine</forenames></author><author><keyname>Benmohamed</keyname><forenames>Mohamed</forenames></author></authors><title>M-AODV : AODV variant to improve quality of service in MANETs</title><categories>cs.NI</categories><comments>8 pages</comments><journal-ref>International Journal of Computer Science Issues (IJCSI) Volume 8,
  Issue 1, January 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, multimedia and real-time applications consume much network
resources and so, need high flow rates and very small transfer delay. The
current ad hoc networks (MANETs), in their original state, are not able to
satisfy the requirements of quality of service (QoS). Researches for improving
QoS in these networks are main topics and a subject of intensive researches. In
Adhoc networks, the routing phase plays an important role for improving QoS.
Numerous routing protocols (proactive, reactive and hybrid) were proposed. AODV
(Adhoc On demand Distance Vector) is probably the more treated in literature In
this article, we propose a new variant based on the AODV which gives better
results than the original AODV protocol with respect of a set of QoS parameters
and under different constraints, taking into account the limited resources of
mobile environments (bandwidth, energy, etc...). The proposed variant (M-AODV)
suggests that the discovering operation for paths reconstruction should be done
from the source. It also defines a new mechanism for determining multiple
disjoint (separated) routes. To validate our solution, simulations were made
under Network Simulator (NS2). We measure traffic control and packet loss rate
under diverse constraints (mobility, energy and scale).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1187</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1187</id><created>2011-04-06</created><authors><author><keyname>Blumenhagen</keyname><forenames>Ralph</forenames></author><author><keyname>Jurke</keyname><forenames>Benjamin</forenames></author><author><keyname>Rahn</keyname><forenames>Thorsten</forenames></author></authors><title>Computational Tools for Cohomology of Toric Varieties</title><categories>hep-th cs.MS math.AG</categories><comments>17 pages, 4 tables; prepared for the special issue &quot;Computational
  Algebraic Geometry in String and Gauge Theory&quot; of Advances in High Energy
  Physics, cohomCalg implementation available at
  http://wwwth.mppmu.mpg.de/members/blumenha/cohomcalg/</comments><report-no>MPI-2011-39</report-no><journal-ref>Adv.High Energy Phys.2011:152749</journal-ref><doi>10.1155/2011/152749</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this review, novel non-standard techniques for the computation of
cohomology classes on toric varieties are summarized. After an introduction of
the basic definitions and properties of toric geometry, we discuss a specific
computational algorithm for the determination of the dimension of line-bundle
valued cohomology groups on toric varieties. Applications to the computation of
chiral massless matter spectra in string compactifications are discussed and,
using the software package cohomCalg, its utility is highlighted on a new
target space dual pair of (0,2) heterotic string models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1190</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1190</id><created>2011-04-06</created><authors><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>IRCCyN, DIE</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author><author><keyname>Hu</keyname><forenames>Bo</forenames><affiliation>DIE</affiliation></author><author><keyname>Guillaume</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>A novel approach for determining fatigue resistances of different muscle
  groups in static cases</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>International Journal of Industrial Ergonomics 41, 1 (2011) 10-18</journal-ref><doi>10.1016/j.ergon.2010.11.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In ergonomics and biomechanics, muscle fatigue models based on maximum
endurance time (MET) models are often used to integrate fatigue effect into
ergonomic and biomechanical application. However, due to the empirical
principle of those MET models, the disadvantages of this method are: 1) the MET
models cannot reveal the muscle physiology background very well; 2) there is no
general formation for those MET models to predict MET. In this paper, a
theoretical MET model is extended from a simple muscle fatigue model with
consideration of the external load and maximum voluntary contraction in passive
static exertion cases. The universal availability of the extended MET model is
analyzed in comparison to 24 existing empirical MET models. Using mathematical
regression method, 21 of the 24 MET models have intraclass correlations over
0.9, which means the extended MET model could replace the existing MET models
in a general and computationally efficient way. In addition, an important
parameter, fatigability (or fatigue resistance) of different muscle groups,
could be calculated via the mathematical regression approach. Its mean value
and its standard deviation are useful for predicting MET values of a given
population during static operations. The possible reasons influencing the
fatigue resistance were classified and discussed, and it is still a very
challenging work to find out the quantitative relationship between the fatigue
resistance and the influencing factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1191</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1191</id><created>2011-04-06</created><authors><author><keyname>Hu</keyname><forenames>Bo</forenames><affiliation>DIE</affiliation></author><author><keyname>Ma</keyname><forenames>Liang</forenames><affiliation>DIE, IRCCyN</affiliation></author><author><keyname>Zhang</keyname><forenames>Wei</forenames><affiliation>DIE</affiliation></author><author><keyname>Salvendy</keyname><forenames>Gaverial</forenames><affiliation>DIE</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Can virtual reality predict body part discomfort and performance of
  people in realistic world for assembling tasks?</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>International Journal of Industrial Ergonomics 41, 1 (2011) 64-71</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents our work on relationship of evaluation results between
virtual environment (VE) and realistic environment (RE) for assembling tasks.
Evaluation results consist of subjective results (BPD and RPE) and objective
results (posture and physical performance). Same tasks were performed with same
experimental configurations and evaluation results were measured in RE and VE
respectively. Then these evaluation results were compared. Slight difference of
posture between VE and RE was found but not great difference of effect on
people according to conventional ergonomics posture assessment method.
Correlation of BPD and performance results between VE and RE are found by
linear regression method. Moreover, results of BPD, physical performance, and
RPE in VE are higher than that in RE with significant difference. Furthermore,
these results indicates that subjects feel more discomfort and fatigue in VE
than RE because of additional effort required in VE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1200</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1200</id><created>2011-04-06</created><authors><author><keyname>Grady</keyname><forenames>Daniel</forenames></author><author><keyname>Brune</keyname><forenames>Rafael</forenames></author><author><keyname>Thiemann</keyname><forenames>Christian</forenames></author><author><keyname>Theis</keyname><forenames>Fabian</forenames></author><author><keyname>Brockmann</keyname><forenames>Dirk</forenames></author></authors><title>Modularity maximization and tree clustering: Novel ways to determine
  effective geographic borders</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Territorial subdivisions and geographic borders are essential for
understanding phenomena in sociology, political science, history, and
economics. They influence the interregional flow of information and
cross-border trade and affect the diffusion of innovation and technology.
However, most existing administrative borders were determined by a variety of
historic and political circumstances along with some degree of arbitrariness.
Societies have changed drastically, and it is doubtful that currently existing
borders reflect the most logical divisions. Fortunately, at this point in
history we are in a position to actually measure some aspects of the geographic
structure of society through human mobility. Large-scale transportation systems
such as trains and airlines provide data about the number of people traveling
between geographic locations, and many promising human mobility proxies are
being discovered, such as cell phones, bank notes, and various online social
networks. In this chapter we apply two optimization techniques to a human
mobility proxy (bank note circulation) to investigate the effective geographic
borders that emerge from a direct analysis of human mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1204</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1204</id><created>2011-04-06</created><authors><author><keyname>Yarkony</keyname><forenames>Julian</forenames></author><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author><author><keyname>Fowlkes</keyname><forenames>Charless C.</forenames></author></authors><title>Planar Cycle Covering Graphs</title><categories>stat.ML cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new variational lower-bound on the minimum energy configuration
of a planar binary Markov Random Field (MRF). Our method is based on adding
auxiliary nodes to every face of a planar embedding of the graph in order to
capture the effect of unary potentials. A ground state of the resulting
approximation can be computed efficiently by reduction to minimum-weight
perfect matching. We show that optimization of variational parameters achieves
the same lower-bound as dual-decomposition into the set of all cycles of the
original graph. We demonstrate that our variational optimization converges
quickly and provides high-quality solutions to hard combinatorial problems
10-100x faster than competing algorithms that optimize the same bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1209</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1209</id><created>2011-04-06</created><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author></authors><title>A Small PRG for Polynomial Threshold Functions of Gaussians</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a pseudo-random generator to fool degree-$d$ polynomial threshold
functions with respect to the Gaussian distribution. For $c&gt;0$ any constant, we
construct a pseudo-random generator that fools such functions to within
$\epsilon$ and has seed length $\log(n) 2^{O(d)} \epsilon^{-4-c}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1217</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1217</id><created>2011-04-06</created><updated>2012-02-27</updated><authors><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Viswanatha</keyname><forenames>Kumar</forenames></author><author><keyname>Rose</keyname><forenames>Kenneth</forenames></author></authors><title>On Conditions for Linearity of Optimal Estimation</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory, accepted on Feb
  5, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When is optimal estimation linear? It is well known that, when a Gaussian
source is contaminated with Gaussian noise, a linear estimator minimizes the
mean square estimation error. This paper analyzes, more generally, the
conditions for linearity of optimal estimators. Given a noise (or source)
distribution, and a specified signal to noise ratio (SNR), we derive conditions
for existence and uniqueness of a source (or noise) distribution for which the
$L_p$ optimal estimator is linear. We then show that, if the noise and source
variances are equal, then the matching source must be distributed identically
to the noise. Moreover, we prove that the Gaussian source-channel pair is
unique in the sense that it is the only source-channel pair for which the mean
square error (MSE) optimal estimator is linear at more than one SNR values.
Further, we show the asymptotic linearity of MSE optimal estimators for low SNR
if the channel is Gaussian regardless of the source and, vice versa, for high
SNR if the source is Gaussian regardless of the channel. The extension to the
vector case is also considered where besides the conditions inherited from the
scalar case, additional constraints must be satisfied to ensure linearity of
the optimal estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1227</identifier>
 <datestamp>2011-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1227</id><created>2011-04-06</created><updated>2011-11-25</updated><authors><author><keyname>Xiao</keyname><forenames>Yuanzhang</forenames></author><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Intervention in Power Control Games With Selfish Users</title><categories>cs.IT cs.GT cs.NI math.IT</categories><comments>33 pages, 6 figures</comments><doi>10.1109/JSTSP.2011.2177811</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the power control problem in wireless ad hoc networks with selfish
users. Without incentive schemes, selfish users tend to transmit at their
maximum power levels, causing significant interference to each other. In this
paper, we study a class of incentive schemes based on intervention to induce
selfish users to transmit at desired power levels. An intervention scheme can
be implemented by introducing an intervention device that can monitor the power
levels of users and then transmit power to cause interference to users. We
mainly consider first-order intervention rules based on individual transmit
powers. We derive conditions on design parameters and the intervention
capability to achieve a desired outcome as a (unique) Nash equilibrium and
propose a dynamic adjustment process that the designer can use to guide users
and the intervention device to the desired outcome. The effect of using
intervention rules based on aggregate receive power is also analyzed. Our
results show that with perfect monitoring intervention schemes can be designed
to achieve any positive power profile while using interference from the
intervention device only as a threat. We also analyze the case of imperfect
monitoring and show that a performance loss can occur. Lastly, simulation
results are presented to illustrate the performance improvement from using
intervention rules and compare the performances of different intervention
rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1237</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1237</id><created>2011-04-06</created><authors><author><keyname>Bag</keyname><forenames>Soumen</forenames></author><author><keyname>Barik</keyname><forenames>Soumen</forenames></author><author><keyname>Sen</keyname><forenames>Prithwiraj</forenames></author><author><keyname>Sanyal</keyname><forenames>Gautam</forenames></author></authors><title>A Statistical Nonparametric Approach of Face Recognition: Combination of
  Eigenface &amp; Modified k-Means Clustering</title><categories>cs.CV</categories><comments>7 pages, 2 figures. In proceedings of the Second International
  Conference on Information Processing (ICIP), pp. 198-204, Bangalore, India,
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facial expressions convey non-verbal cues, which play an important role in
interpersonal relations. Automatic recognition of human face based on facial
expression can be an important component of natural human-machine interface. It
may also be used in behavioural science. Although human can recognize the face
practically without any effort, but reliable face recognition by machine is a
challenge. This paper presents a new approach for recognizing the face of a
person considering the expressions of the same human face at different
instances of time. This methodology is developed combining Eigenface method for
feature extraction and modified k-Means clustering for identification of the
human face. This method endowed the face recognition without using the
conventional distance measure classifiers. Simulation results show that
proposed face recognition using perception of k-Means clustering is useful for
face images with different facial expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1243</identifier>
 <datestamp>2011-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1243</id><created>2011-04-07</created><updated>2011-04-14</updated><authors><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>On the number of maximal independent sets in a graph</title><categories>math.CO cs.DM</categories><journal-ref>Discrete Maths. &amp; Theoretical Computer Science 13.3:17-20, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Miller and Muller (1960) and independently Moon and Moser (1965) determined
the maximum number of maximal independent sets in an $n$-vertex graph. We give
a new and simple proof of this result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1249</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1249</id><created>2011-04-07</created><authors><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Angeles</keyname><forenames>Jorge</forenames><affiliation>CIM</affiliation></author></authors><title>The Design of a Novel Prismatic Drive for a Three-DOF
  Parallel-Kinematics Machine</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Journal of Mechanical Design 128, 4 (2006) 710-718</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of a novel prismatic drive is reported in this paper. This
transmission is based on Slide-o-Cam, a cam mechanism with multiple rollers
mounted on a common translating follower. The design of Slide-o-Cam was
reported elsewhere. This drive thus provides pure-rolling motion, thereby
reducing the friction of rack-and-pinions and linear drives. Such properties
can be used to design new transmissions for parallel-kinematics machines. In
this paper, this transmission is intended to replace the ball-screws in
Orthoglide, a three-dof parallel robot intended for machining applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1268</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1268</id><created>2011-04-07</created><authors><author><keyname>Borri</keyname><forenames>Alessandro</forenames></author><author><keyname>Bopardikar</keyname><forenames>Shaunak D.</forenames></author><author><keyname>Hespanha</keyname><forenames>Joao P.</forenames></author><author><keyname>Di Benedetto</keyname><forenames>Maria D.</forenames></author></authors><title>Hide-and-Seek with Directional Sensing</title><categories>cs.GT</categories><comments>A short version of this paper (without proofs) will be presented at
  the 18th IFAC World Congress (IFAC 2011), Milan (Italy), August 28-September
  2, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a game played between a hider, who hides a static object in one
of several possible positions in a bounded planar region, and a searcher, who
wishes to reach the object by querying sensors placed in the plane. The
searcher is a mobile agent, and whenever it physically visits a sensor, the
sensor returns a random direction, corresponding to a half-plane in which the
hidden object is located. We first present a novel search heuristic and
characterize bounds on the expected distance covered before reaching the
object. Next, we model this game as a large-dimensional zero-sum dynamic game
and we apply a recently introduced randomized sampling technique that provides
a probabilistic level of security to the hider. We observe that, when the
randomized sampling approach is only allowed to select a very small number of
samples, the cost of the heuristic is comparable to the security level provided
by the randomized procedure. However, as we allow the number of samples to
increase, the randomized procedure provides a higher probabilistic security
level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1279</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1279</id><created>2011-04-07</created><authors><author><keyname>Sutagundar</keyname><forenames>Ashok V</forenames></author><author><keyname>Manvi</keyname><forenames>Sunilkumar S</forenames></author></authors><title>Context Aware Multisensor Image Fusion for Military Sensor Networks
  using Multi Agent System</title><categories>cs.MA</categories><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.2, No.1, March 2011</journal-ref><doi>10.5121/ijasuc.2011.2113</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper proposes a Context Aware Agent based Military Sensor Network
(CAMSN) to form an improved infrastructure for multi-sensor image fusion. It
considers contexts driven by a node and sink. The contexts such as general and
critical object detection are node driven where as sensing time (such as day or
night) is sink driven. The agencies used in the scheme are categorized as node
and sink agency. Each agency employs a set of static and mobile agents to
perform dedicated tasks. Node agency performs context sensing and context
interpretation based on the sensed image and sensing time. Node agency
comprises of node manager agent, context agent and node blackboard (NBB).
Context agent gathers the context from the target and updates the NBB, Node
manager agent interprets the context and passes the context information to sink
node by using flooding mechanism. Sink agency mainly comprises of sink manager
agent, fusing agent, and sink black board. A context at the sensor node
triggers the fusion process at the sink. Based on the context, sink manager
agent triggers the fusing agent. Fusing agent roams around the network, visits
active sensor node, fuses the relevant images and sends the fused image to
sink. The fusing agent uses wavelet transform for fusion. The scheme is
simulated for testing its operation effectiveness in terms of fusion time, mean
square error, throughput, dropping rate, bandwidth requirement, node battery
usage and agent overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1307</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1307</id><created>2011-04-07</created><updated>2013-03-13</updated><authors><author><keyname>Fulek</keyname><forenames>Radoslav</forenames></author><author><keyname>Neuwirth</keyname><forenames>Daniel</forenames></author></authors><title>On Sets of Lines Not-Supporting Trees</title><categories>cs.DM</categories><comments>a revised version, a correction of the abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the following problem introduced by Dujmovic et al. Given a tree $T
= (V,E)$, on $n$ vertices, a set of $n$ lines $\mathcal{L}$ in the plane and a
bijection $\iota: V \rightarrow \mathcal{L}$, we are asked to find a
crossing-free straight-line embedding of $T$ so that $v\in \iota(v)$, for all
$v\in V$. We say that a set of $n$ lines $\mathcal{L}$ is universal for trees
if for any tree $T$ and any bijection $\iota$ there exists such an embedding.
We prove that any sufficiently big set of lines is not universal for trees,
which solves an open problem asked by Dujmovic et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1309</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1309</id><created>2011-04-07</created><authors><author><keyname>Panagiotou</keyname><forenames>Konstantinos</forenames></author><author><keyname>Sp&#xf6;hel</keyname><forenames>Reto</forenames></author><author><keyname>Steger</keyname><forenames>Angelika</forenames></author><author><keyname>Thomas</keyname><forenames>Henning</forenames></author></authors><title>Explosive Percolation in Erd\&quot;os-R\'enyi-Like Random Graph Processes</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of the largest component has been studied intensely in a
variety of random graph processes, starting in 1960 with the Erd\&quot;os-R\'enyi
process. It is well known that this process undergoes a phase transition at n/2
edges when, asymptotically almost surely, a linear-sized component appears.
Moreover, this phase transition is continuous, i.e., in the limit the function
f(c) denoting the fraction of vertices in the largest component in the process
after cn edge insertions is continuous. A variation of the Erd\&quot;os-R\'enyi
process are the so-called Achlioptas processes in which in every step a random
pair of edges is drawn, and a fixed edge-selection rule selects one of them to
be included in the graph while the other is put back. Recently, Achlioptas,
D'Souza and Spencer (2009) gave strong numerical evidence that a variety of
edge-selection rules exhibit a discontinuous phase transition. However, Riordan
and Warnke (2011) very recently showed that all Achlioptas processes have a
continuous phase transition. In this work we prove discontinuous phase
transitions for a class of Erd\&quot;os-R\'enyi-like processes in which in every
step we connect two vertices, one chosen randomly from all vertices, and one
chosen randomly from a restricted set of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1311</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1311</id><created>2011-04-07</created><authors><author><keyname>Ramaswamy</keyname><forenames>Gowri Shankar</forenames></author><author><keyname>Francis</keyname><forenames>F Sagayaraj</forenames></author></authors><title>Latent table discovery by semantic relationship extraction between
  unrelated sets of entity sets of structured data sources</title><categories>cs.DB</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 2, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Querying is one of the basic functionality expected from a database system.
Query efficiency is adversely affected by increase in the number of
participating tables. Also, querying based on syntax largely limits the gamut
of queries a database system can process. Syntactic queries rely on the
database table structure, which is a cause of concern for large organisations
due to incompatibility between heterogeneous systems that store data
distributed across geographic locations. Solution to these problems is answered
to some extent by moving towards semantic technology by making data and the
database meaningful. In doing so, relationship between sets of entity sets will
not be limited only to syntactic constraints but would also permit semantic
connections nonetheless such relationships may be tacit, intangible and
invisible. The goal of this work is to extract such hidden relationships
between unrelated sets of entity sets and store them in a tangible form. A few
sample cases are provided to vindicate that the proposed work improves querying
significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1317</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1317</id><created>2011-04-07</created><authors><author><keyname>Carmona</keyname><forenames>Mikael</forenames></author><author><keyname>Michel</keyname><forenames>Olivier</forenames></author><author><keyname>Lacoume</keyname><forenames>Jean-Louis</forenames></author><author><keyname>Sprynski</keyname><forenames>Nathalie</forenames></author><author><keyname>Nicolas</keyname><forenames>Barbara</forenames></author></authors><title>Algorithm for Sensor Network Attitude Problem</title><categories>math.OC cs.SY</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensor network attitude problem consists in retrieving the attitude of each
sensor of a network knowing some relative orientations between pairs of
sensors. The attitude of a sensor is its orientation in an absolute axis
system. We present in this paper a method for solving the sensor network
attitude problem using quaternion formalism which allows to apply linear
algebra tools. The proposed algorithm solves the problem when all of the
relative attitudes are known. A complete characterisation of the algorithm is
established: spatial complexity, time complexity and robustness. Our algorithm
is validated in simulations and with real experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1320</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1320</id><created>2011-04-07</created><authors><author><keyname>Fontanari</keyname><forenames>Claudio</forenames></author><author><keyname>Marcolla</keyname><forenames>Chiara</forenames></author></authors><title>On the geometry of small weight codewords of dual algebraic geometric
  codes</title><categories>math.AG cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the geometry of the support of small weight codewords of dual
algebraic geometric codes on smooth complete intersections by applying the
powerful tools recently developed by Alain Couvreur. In particular, by
restricting ourselves to the case of Hermitian codes, we recover and extend
previous results obtained by the second named author joint with Marco
Pellegrini and Massimiliano Sala.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1330</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1330</id><created>2011-04-07</created><updated>2011-08-31</updated><authors><author><keyname>Even</keyname><forenames>Guy</forenames></author><author><keyname>Matsri</keyname><forenames>Yakov</forenames></author><author><keyname>Medina</keyname><forenames>Moti</forenames></author></authors><title>Multi-Hop Routing and Scheduling in Wireless Networks in the SINR model</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for multi-hop routing and scheduling of requests in
wireless networks in the \sinr\ model. The goal of our algorithm is to maximize
the throughput or maximize the minimum ratio between the flow and the demand.
  Our algorithm partitions the links into buckets. Every bucket consists of a
set of links that have nearly equivalent reception powers. We denote the number
of nonempty buckets by $\sigdiv$. Our algorithm obtains an approximation ratio
of $O(\sigdiv \cdot \log n)$, where $n$ denotes the number of nodes. For the
case of linear powers $\sigdiv =1$, hence the approximation ratio of the
algorithm is $O(\log n)$. This is the first practical approximation algorithm
for linear powers with an approximation ratio that depends only on $n$ (and not
on the max-to-min distance ratio).
  If the transmission power of each link is part of the input (and arbitrary),
then $\sigdiv = O(\log\Gamma + \log \Delta)$, where $\Gamma$ denotes the ratio
of the max-to-min power, and $\Delta$ denotes the ratio of the max-to-min
distance. Hence, the approximation ratio is $O(\log n \cdot (\log\Gamma + \log
\Delta))$.
  Finally, we consider the case that the algorithm needs to assign powers to
each link in a range $[\pmin,\pmax]$. An extension of the algorithm to this
case achieves an approximation ratio of $O[(\log n + \log \log \Gamma) \cdot
(\log\Gamma + \log \Delta)]$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1351</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1351</id><created>2011-04-07</created><authors><author><keyname>Salvaneschi</keyname><forenames>Guido</forenames></author><author><keyname>Ghezzi</keyname><forenames>Carlo</forenames></author><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author></authors><title>JavaCtx: Seamless Toolchain Integration for Context-Oriented Programming</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-oriented programming is an emerging paradigm addressing at the
language level the issue of dynamic software adaptation and modularization of
context-specific concerns. In this paper we propose JavaCtx, a tool which
employs coding conventions to generate the context-aware semantics for Java
programs and subsequently weave it into the application. The contribution of
JavaCtx is twofold: the design of a set of coding conventions which allow to
write context-oriented software in plain Java and the concept of
context-oriented semantics injection, which allows to introduce the
context-aware semantics without a source-to-source compilations process which
disrupts the structure of the code. Both these points allow to seamless
integrate JavaCtx in the existing industrial-strength appliances and by far
ease the development of context-oriented software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1355</identifier>
 <datestamp>2011-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1355</id><created>2011-04-07</created><authors><author><keyname>Ginestet</keyname><forenames>Cedric E.</forenames></author><author><keyname>Simmons</keyname><forenames>Andrew</forenames></author></authors><title>Recursive Shortest Path Algorithm with Application to
  Density-integration of Weighted Graphs</title><categories>q-bio.MN cs.DS q-bio.NC stat.CO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Graph theory is increasingly commonly utilised in genetics, proteomics and
neuroimaging. In such fields, the data of interest generally constitute
weighted graphs. Analysis of such weighted graphs often require the integration
of topological metrics with respect to the density of the graph. Here, density
refers to the proportion of the number of edges present in that graph. When
topological metrics based on shortest paths are of interest, such
density-integration usually necessitates the iterative application of
Dijkstra's algorithm in order to compute the shortest path matrix at each
density level. In this short note, we describe a recursive shortest path
algorithm based on single edge updating, which replaces the need for the
iterative use of Dijkstra's algorithm. Our proposed procedure is based on pairs
of breadth-first searches around each of the vertices incident to the edge
added at each recursion. An algorithmic analysis of the proposed technique is
provided. When the graph of interest is coded as an adjacency list, our
algorithm can be shown to be more efficient than an iterative use of Dijkstra's
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1362</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1362</id><created>2011-04-07</created><updated>2013-06-12</updated><authors><author><keyname>Kerber</keyname><forenames>Michael</forenames></author><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>Root Refinement for Real Polynomials</title><categories>cs.SC</categories><comments>This is a substantially extended version of the conference paper
  &quot;Efficient Real Root Approximation&quot;, appeared at the 36th International
  Symposium on Symbolic and Algebraic Computation (ISSAC 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of approximating all real roots of a square-free
polynomial $f$. Given isolating intervals, our algorithm refines each of them
to a width of $2^{-L}$ or less, that is, each of the roots is approximated to
$L$ bits after the binary point. Our method provides a certified answer for
arbitrary real polynomials, only considering finite approximations of the
polynomial coefficients and choosing a suitable working precision adaptively.
In this way, we get a correct algorithm that is simple to implement and
practically efficient. Our algorithm uses the quadratic interval refinement
method; we adapt that method to be able to cope with inaccuracies when
evaluating $f$, without sacrificing its quadratic convergence behavior. We
prove a bound on the bit complexity of our algorithm in terms of the degree of
the polynomial, the size and the separation of the roots, that is, parameters
exclusively related to the geometric location of the roots. Our bound is near
optimal and significantly improves previous work on integer polynomials.
Furthermore, it essentially matches the best known theoretical bounds on root
approximation which are obtained by very sophisticated algorithms. We also
investigate the practical behavior of the algorithm and demonstrate how closely
the practical performance matches our asymptotic bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1370</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1370</id><created>2011-04-07</created><authors><author><keyname>Greenwood</keyname><forenames>David</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author></authors><title>Expectations and Reality: Why an enterprise software system didn't work
  as planned</title><categories>cs.SE</categories><comments>At time of writing unpublished work submitted to &quot;The 20th
  International Conference on Information Systems Development&quot; Edinburgh</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over two decades, we and other research groups have found that ethnographic
and social analyses of work settings can provide insights useful to the process
of system analysis and design. Despite this, ethnographic and social analyses
have not been widely assimilated into industry practice. Practitioners tend to
address sociotechnical factors in an ad-hoc manner, often post-implementation,
once system use or outcome has become problematic. In response to this, we have
developed a lightweight qualitative approach to provide insights to ameliorate
problematic system deployments. Unlike typical ethnographies and social
analyses of work activity that inform systems analysis and design; we argue
that analysis of intentional and structural factors to inform system deployment
and integration can have a shorter time duration and yet can provide actionable
insights. We evaluate our approach using a case study of a problematic
enterprise document manage-ment system within a multinational systems
engineering organization. Our find-ings are of academic and practical
significance as our approach demonstrates that structural-intentional analysis
scales to enable the timely analysis of large-scale system deployments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1377</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1377</id><created>2011-04-07</created><authors><author><keyname>Rubinfeld</keyname><forenames>Ronitt</forenames></author><author><keyname>Tamir</keyname><forenames>Gil</forenames></author><author><keyname>Vardi</keyname><forenames>Shai</forenames></author><author><keyname>Xie</keyname><forenames>Ning</forenames></author></authors><title>Fast Local Computation Algorithms</title><categories>cs.DS</categories><comments>A preliminary version of this paper appeared in ICS 2011, pp. 223-238</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For input $x$, let $F(x)$ denote the set of outputs that are the &quot;legal&quot;
answers for a computational problem $F$. Suppose $x$ and members of $F(x)$ are
so large that there is not time to read them in their entirety. We propose a
model of {\em local computation algorithms} which for a given input $x$,
support queries by a user to values of specified locations $y_i$ in a legal
output $y \in F(x)$. When more than one legal output $y$ exists for a given
$x$, the local computation algorithm should output in a way that is consistent
with at least one such $y$. Local computation algorithms are intended to
distill the common features of several concepts that have appeared in various
algorithmic subfields, including local distributed computation, local
algorithms, locally decodable codes, and local reconstruction.
  We develop a technique, based on known constructions of small sample spaces
of $k$-wise independent random variables and Beck's analysis in his algorithmic
approach to the Lov{\'{a}}sz Local Lemma, which under certain conditions can be
applied to construct local computation algorithms that run in {\em
polylogarithmic} time and space. We apply this technique to maximal independent
set computations, scheduling radio network broadcasts, hypergraph coloring and
satisfying $k$-SAT formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1389</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1389</id><created>2011-04-07</created><authors><author><keyname>Enqvist</keyname><forenames>Per</forenames></author></authors><title>Generalizing the Markov and covariance interpolation problem using
  input-to-state filters</title><categories>math.OC cs.SY</categories><comments>CDC 2007 paper</comments><msc-class>93B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Markov and covariance interpolation problem a transfer function $W$ is
sought that match the first coefficients in the expansion of $W$ around zero
and the first coefficients of the Laurent expansion of the corresponding
spectral density $WW^\star$. Here we solve an interpolation problem where the
matched parameters are the coefficients of expansions of $W$ and $WW^\star$
around various points in the disc. The solution is derived using input-to-state
filters and is determined by simple calculations such as solving Lyapunov
equations and generalized eigenvalue problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1408</identifier>
 <datestamp>2011-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1408</id><created>2011-04-07</created><updated>2011-06-23</updated><authors><author><keyname>Fong</keyname><forenames>Wai Han</forenames></author></authors><title>Coding Bounds for Multiple Phased-Burst Correction and Single Burst
  Correction Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Globecom 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, two upper bounds on the achievable code rate of linear block
codes for multiple phased-burst correction (MPBC) are presented. One bound is
constrained to a maximum correctable cyclic burst length within every subblock,
or equivalently a constraint on the minimum error free length or gap within
every phased-burst. This bound, when reduced to the special case of a bound for
single burst correction (SBC), is shown to be the Abramson bound when the
cyclic burst length is less than half the block length. The second MPBC bound
is developed without the minimum error free gap constraint and is used as a
comparison to the first bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1410</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1410</id><created>2011-04-07</created><updated>2012-02-21</updated><authors><author><keyname>Schwarz</keyname><forenames>Martin</forenames></author><author><keyname>Temme</keyname><forenames>Kristan</forenames></author><author><keyname>Verstraete</keyname><forenames>Frank</forenames></author></authors><title>Preparing projected entangled pair states on a quantum computer</title><categories>quant-ph cond-mat.stat-mech cs.CC</categories><comments>5 pages, 1 figure. To be published in Physical Review Letters.
  Removed heuristics, refined run-time bound</comments><journal-ref>Phys. Rev. Lett. 108, 110502 (2012)</journal-ref><doi>10.1103/PhysRevLett.108.110502</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a quantum algorithm to prepare injective PEPS on a quantum
computer, a class of open tensor networks representing quantum states. The
run-time of our algorithm scales polynomially with the inverse of the minimum
condition number of the PEPS projectors and, essentially, with the inverse of
the spectral gap of the PEPS' parent Hamiltonian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1436</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1436</id><created>2011-04-07</created><authors><author><keyname>Argyriou</keyname><forenames>Andreas</forenames></author><author><keyname>Micchelli</keyname><forenames>Charles A.</forenames></author><author><keyname>Pontil</keyname><forenames>Massimiliano</forenames></author><author><keyname>Shen</keyname><forenames>Lixin</forenames></author><author><keyname>Xu</keyname><forenames>Yuesheng</forenames></author></authors><title>Efficient First Order Methods for Linear Composite Regularizers</title><categories>cs.LG math.OC stat.ME stat.ML</categories><comments>19 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wide class of regularization problems in machine learning and statistics
employ a regularization term which is obtained by composing a simple convex
function \omega with a linear transformation. This setting includes Group Lasso
methods, the Fused Lasso and other total variation methods, multi-task learning
methods and many more. In this paper, we present a general approach for
computing the proximity operator of this class of regularizers, under the
assumption that the proximity operator of the function \omega is known in
advance. Our approach builds on a recent line of research on optimal first
order optimization methods and uses fixed point iterations for numerically
computing the proximity operator. It is more general than current approaches
and, as we show with numerical simulations, computationally more efficient than
available first order methods which do not achieve the optimal rate. In
particular, our method outperforms state of the art O(1/T) methods for
overlapping Group Lasso and matches optimal O(1/T^2) methods for the Fused
Lasso and tree structured Group Lasso.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1448</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1448</id><created>2011-04-07</created><authors><author><keyname>Chizhik</keyname><forenames>Dmitry</forenames></author><author><keyname>Foschini</keyname><forenames>Gerard J.</forenames></author><author><keyname>Valenzuela</keyname><forenames>Reinaldo A.</forenames></author></authors><title>A Basic Unified Context for Evaluating the Beam Forming and MIMO Options
  in a Wireless Link</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For one isolated wireless link we take a unified look at simple beamforming
(BF) as contrasted with MIMO to see how both emerge and under which conditions
advantage goes to one or the other. Communication is from a high base array to
a user in clutter. The channel propagation model is derived from fundamentals.
The base knows the power angular spectrum, but not the channel instantiation.
Eigenstates of the field spatial autocorrelation are the preferred apodizations
(APODs) which are drivers of the natural modes for exciting lectric fields.
Preference for MIMO or BF depends on APOD spectra which are surveyed pointing
to various asymptotic effects, including the maximum BF gain. Performance is
studied under varying eigenmode power settings at 10% outage. We focus on (1,4)
driving the strongest mode for BF and (4,4) driving the 4 strongest for MIMO.
Results are obtained under representative parameter settings, e.g. an angular
spread of 8 deg, 2 GHz carrier, 0 dB SNR and an array aperture of 1.68m (4
field decorrelation lengths) with antenna elements spaced as close as lambda/2.
We find MIMO excelling for array apertures much larger than the decorrelation
length; BF does almost as well for smaller apertures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1450</identifier>
 <datestamp>2011-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1450</id><created>2011-04-07</created><updated>2011-11-01</updated><authors><author><keyname>Minsker</keyname><forenames>Stanislav</forenames></author></authors><title>Plug-in Approach to Active Learning</title><categories>math.ST cs.LG stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new active learning algorithm based on nonparametric estimators
of the regression function. Our investigation provides probabilistic bounds for
the rates of convergence of the generalization error achievable by proposed
method over a broad class of underlying distributions. We also prove minimax
lower bounds which show that the obtained rates are almost tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1457</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1457</id><created>2011-04-07</created><authors><author><keyname>Morero</keyname><forenames>Damian A.</forenames></author><author><keyname>Corral-Briones</keyname><forenames>Graciela</forenames></author><author><keyname>Rodriguez</keyname><forenames>Carmen</forenames></author><author><keyname>Hueda</keyname><forenames>Mario R.</forenames></author></authors><title>High-Rate Short-Block LDPC Codes for Iterative Decoding with
  Applications to High-Density Magnetic Recording Channels</title><categories>cs.IT math.IT</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the Triangle Single Parity Check (T/SPC) code, a
novel class of high-rate low-complexity LDPC codes. T/SPC is a regular, soft
decodable, linear-time encodable/decodable code. Compared to previous high-rate
and low-complexity LDPC codes, such as the well-known Turbo Product Code /
Single Parity Check (TPC/SPC), T/SPC provides higher code rates, shorter code
words, and lower complexity. This makes T/SPC very attractive for practical
implementation on integrated circuits.
  In addition, we analyze the performance of iterative decoders based on a
soft-input soft-output (SISO) equalizer using T/SPC over high-density
perpendicular magnetic recording channels. Computer simulations show that the
proposed scheme is able to achieve a gain of up to 0.3 dB over TPC/SPC codes
with a significant reduction of implementation complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1466</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1466</id><created>2011-04-07</created><authors><author><keyname>Burgin</keyname><forenames>Mark</forenames><affiliation>C.N.J.</affiliation></author><author><keyname>Kees</keyname><affiliation>C.N.J.</affiliation></author><author><keyname>Mestdagh</keyname><forenames>de Vey</forenames></author></authors><title>Logical Varieties in Normative Reasoning</title><categories>cs.LO math.LO</categories><msc-class>3B42</msc-class><acm-class>I.1.3; I.2.4; H.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although conventional logical systems based on logical calculi have been
successfully used in mathematics and beyond, they have definite limitations
that restrict their application in many cases. For instance, the principal
condition for any logical calculus is its consistency. At the same time,
knowledge about large object domains (in science or in practice) is essentially
inconsistent. Logical prevarieties and varieties were introduced to eliminate
these limitations in a logically correct way. In this paper, the Logic of
Reasonable Inferences is described. This logic has been applied successfully to
model legal reasoning with inconsistent knowledge. It is demonstrated that this
logic is a logical variety and properties of logical varieties related to legal
reasoning are developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1471</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1471</id><created>2011-04-07</created><updated>2012-09-03</updated><authors><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author></authors><title>New Techniques for Upper-Bounding the ML Decoding Performance of Binary
  Linear Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, new techniques are presented to either simplify or improve
most existing upper bounds on the maximum-likelihood (ML) decoding performance
of the binary linear codes over additive white Gaussian noise (AWGN) channels.
Firstly, the recently proposed union bound using truncated weight spectrums by
Ma {\em et al} is re-derived in a detailed way based on Gallager's first
bounding technique (GFBT), where the &quot;good region&quot; is specified by a
sub-optimal list decoding algorithm. The error probability caused by the bad
region can be upper-bounded by the tail-probability of a binomial distribution,
while the error probability caused by the good region can be upper-bounded by
most existing techniques. Secondly, we propose two techniques to tighten the
union bound on the error probability caused by the good region. The first
technique is based on pair-wise error probabilities, which can be further
tightened by employing the independence between the error events and certain
components of the received random vectors. The second technique is based on
triplet-wise error probabilities, which can be upper-bounded by proving that
any three bipolar vectors form a non-obtuse triangle. The proposed bounds
improve the conventional union bounds but have a similar complexity since they
involve only the $Q$-function. The proposed bounds can also be adapted to
bit-error probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1472</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1472</id><created>2011-04-07</created><authors><author><keyname>Xu</keyname><forenames>Xiaopeng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaochun</forenames></author></authors><title>Gaussian Affine Feature Detector</title><categories>cs.CV</categories><comments>A paper about two dimension image signal detection, including
  position, length, width, height, orentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method is proposed to get image features' geometric information. Using
Gaussian as an input signal, a theoretical optimal solution to calculate
feature's affine shape is proposed. Based on analytic result of a feature
model, the method is different from conventional iterative approaches. From the
model, feature's parameters such as position, orientation, background
luminance, contrast, area and aspect ratio can be extracted. Tested with
synthesized and benchmark data, the method achieves or outperforms existing
approaches in term of accuracy, speed and stability. The method can detect
small, long or thin objects precisely, and works well under general conditions,
such as for low contrast, blurred or noisy images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1477</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1477</id><created>2011-04-07</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author></authors><title>An Agent-based Architecture for a Knowledge-work Support System</title><categories>cs.HC cs.AI cs.MA</categories><comments>8 pages, ACM Compute 2011, Bangalore, India</comments><acm-class>H.4; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enhancement of technology-based system support for knowledge workers is an
issue of great importance. The &quot;Knowledge work Support System (KwSS)&quot; framework
analyzes this issue from a holistic perspective. KwSS proposes a set of design
principles for building a comprehensive IT-based support system, which enhances
the capability of a human agent for performing a set of complex and
interrelated knowledge-works relevant to one or more target task-types within a
domain of professional activities. In this paper, we propose a high-level,
software-agent based architecture for realizing a KwSS system that incorporates
these design principles. Here we focus on developing a number of crucial
enabling components of the architecture, including (1) an Activity Theory-based
novel modeling technique for knowledgeintensive activities; (2) a graph
theoretic formalism for representing these models in a knowledge base in
conjunction with relevant entity taxonomies/ontologies; and (3) an algorithm
for reasoning, using the knowledge base, about various aspects of possible
supports for activities at performance-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1479</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1479</id><created>2011-04-08</created><updated>2013-02-14</updated><authors><author><keyname>Aavani</keyname><forenames>Amir</forenames></author></authors><title>A Family of Encodings for Translating Pseudo-Boolean Constraints into
  SAT</title><categories>cs.LO cs.DS</categories><comments>Used as the reference for SAT-2013 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Pseudo-Boolean (PB) constraint is a linear arithmetic constraint over
Boolean variables. PB constraints are convenient and widely used in expressing
NP-complete problems.
  We introduce a new, two step, method for transforming PB constraints to
propositional CNF formulas. The first step involves re-writing each PB
constraint as a conjunction of PB-Mod constraints. The advantage is that PB-Mod
constraints are easier to transform to CNF. In the second step, we translate
each PB-Mod constraints, obtained in the previous step, into CNF. The resulting
CNF formulas are small, and unit propagation can derive facts that it cannot
derive using in the CNF formulas obtained by other commonly-used
transformations.
  We also characterize the constraints for which one can expect the SAT solvers
to perform well on the produced CNF. We show that there are many constraints
for which the proposed encoding has a good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1482</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1482</id><created>2011-04-08</created><authors><author><keyname>Duncan</keyname><forenames>Christian A.</forenames></author><author><keyname>Gansner</keyname><forenames>Emden R.</forenames></author><author><keyname>Hu</keyname><forenames>Yifan</forenames></author><author><keyname>Kaufmann</keyname><forenames>Michael</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author></authors><title>Optimal Polygonal Representation of Planar Graphs</title><categories>cs.CG math.CO</categories><comments>26 pages, 14 figures. A preliminary version appeared in LATIN 2010,
  Oaxaca, Mexico</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of representing graphs by polygons
whose sides touch. We show that at least six sides per polygon are necessary by
constructing a class of planar graphs that cannot be represented by pentagons.
We also show that the lower bound of six sides is matched by an upper bound of
six sides with a linear-time algorithm for representing any planar graph by
touching hexagons. Moreover, our algorithm produces convex polygons with edges
having at most three slopes and with all vertices lying on an O(n)xO(n) grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1485</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1485</id><created>2011-04-08</created><authors><author><keyname>Laha</keyname><forenames>Arijit</forenames></author><author><keyname>Das</keyname><forenames>J.</forenames></author></authors><title>Fuzzy Rules and Evidence Theory for Satellite Image Analysis</title><categories>cs.CV</categories><comments>5 pages, International Conference on Advances in Pattern Recognition
  2003 (ICAPR03)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Design of a fuzzy rule based classifier is proposed. The performance of the
classifier for multispectral satellite image classification is improved using
Dempster- Shafer theory of evidence that exploits information of the
neighboring pixels. The classifiers are tested rigorously with two known images
and their performance are found to be better than the results available in the
literature. We also demonstrate the improvement of performance while using D-S
theory along with fuzzy rule based classifiers over the basic fuzzy rule based
classifiers for all the test cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1493</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1493</id><created>2011-04-08</created><authors><author><keyname>Tanamoto</keyname><forenames>Tetsufumi</forenames></author><author><keyname>Sugiyama</keyname><forenames>Hideyuki</forenames></author><author><keyname>Inokuchi</keyname><forenames>Tomoaki</forenames></author><author><keyname>Marukame</keyname><forenames>Takao</forenames></author><author><keyname>Ishikawa</keyname><forenames>Mizue</forenames></author><author><keyname>Ikegami</keyname><forenames>Kazutaka</forenames></author><author><keyname>Saito</keyname><forenames>Yoshiaki</forenames></author></authors><title>Scalability of spin FPGA: A Reconfigurable Architecture based on spin
  MOSFET</title><categories>cond-mat.mes-hall cs.AR</categories><comments>3 pages, 7 figures</comments><journal-ref>J. Appl. Phys. 109, 07C312 (2011)</journal-ref><doi>10.1063/1.3537923</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scalability of Field Programmable Gate Array (FPGA) using spin MOSFET (spin
FPGA) with magnetocurrent (MC) ratio in the range of 100% to 1000% is discussed
for the first time. Area and speed of million-gate spin FPGA are numerically
benchmarked with CMOS FPGA for 22nm, 32nm and 45nm technologies including 20%
transistor size variation. We show that area is reduced and speed is increased
in spin FPGA owing to the nonvolatile memory function of spin MOSFET.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1506</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1506</id><created>2011-04-08</created><authors><author><keyname>Baumann</keyname><forenames>Michael</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bolla</keyname><forenames>Michel</forenames><affiliation>TIMC</affiliation></author><author><keyname>Daanen</keyname><forenames>Vincent</forenames><affiliation>TIMC</affiliation></author><author><keyname>Descotes</keyname><forenames>Jean-Luc</forenames><affiliation>TIMC</affiliation></author><author><keyname>Giraud</keyname><forenames>Jean-Yves</forenames><affiliation>TIMC</affiliation></author><author><keyname>Hungr</keyname><forenames>Nikolai</forenames><affiliation>TIMC</affiliation></author><author><keyname>Leroy</keyname><forenames>Antoine</forenames><affiliation>TIMC</affiliation></author><author><keyname>Long</keyname><forenames>Jean-Alexandre</forenames><affiliation>TIMC</affiliation></author><author><keyname>Martin</keyname><forenames>S&#xe9;bastien</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Prosper: image and robot-guided prostate brachytherapy</title><categories>cs.RO physics.med-ph</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brachytherapy for localized prostate cancer consists in destroying cancer by
introducing iodine radioactive seeds into the gland through hollow needles. The
planning of the position of the seeds and their introduction into the prostate
is based on intra-operative ultrasound (US) imaging. We propose to optimize the
global quality of the procedure by: i) using 3D US; ii) enhancing US data with
MRI registration; iii) using a specially designed needle-insertion robot,
connected to the imaging data. The imaging methods have been successfully
tested on patient data while the robot accuracy has been evaluated on a
realistic deformable phantom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1510</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1510</id><created>2011-04-08</created><authors><author><keyname>Kerber</keyname><forenames>Michael</forenames></author><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>A Worst-case Bound for Topology Computation of Algebraic Curves</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the topology of an algebraic plane curve $\mathcal{C}$ means to
compute a combinatorial graph that is isotopic to $\mathcal{C}$ and thus
represents its topology in $\mathbb{R}^2$. We prove that, for a polynomial of
degree $n$ with coefficients bounded by $2^\rho$, the topology of the induced
curve can be computed with $\tilde{O}(n^8(n+\rho^2))$ bit operations
deterministically, and with $\tilde{O}(n^8\rho^2)$ bit operations with a
randomized algorithm in expectation. Our analysis improves previous best known
complexity bounds by a factor of $n^2$. The improvement is based on new
techniques to compute and refine isolating intervals for the real roots of
polynomials, and by the consequent amortized analysis of the critical fibers of
the algebraic curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1528</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1528</id><created>2011-04-08</created><authors><author><keyname>Vinck</keyname><forenames>A. J. Han</forenames></author></authors><title>Coded Modulation for Power Line Communications</title><categories>cs.IT math.IT</categories><comments>7 pages; AE\&quot;U Journal, 2000, pp. 45-49, Jan 2000</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the application of coded modulation for power-line communications.
We combine M-ary FSK with diversity and coding to make the transmission robust
against permanent frequency disturbances and impulse noise. We give a
particular example of the coding/modulation scheme that is in agreement with
the existing CENELEC norms. The scheme can be considered as a form of coded
Frequency Hopping and is thus extendable to any frequency range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1533</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1533</id><created>2011-04-08</created><authors><author><keyname>Chung</keyname><forenames>Byungchun</forenames></author><author><keyname>Marcello</keyname><forenames>Sandra</forenames></author><author><keyname>Mirbaha</keyname><forenames>Amir-Pasha</forenames></author><author><keyname>Naccache</keyname><forenames>David</forenames></author><author><keyname>Sabeg</keyname><forenames>Karim</forenames></author></authors><title>Operand Folding Hardware Multipliers</title><categories>cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a new accumulate-and-add multiplication algorithm. The
method partitions one of the operands and re-combines the results of
computations done with each of the partitions. The resulting design turns-out
to be both compact and fast.
  When the operands' bit-length $m$ is 1024, the new algorithm requires only
$0.194m+56$ additions (on average), this is about half the number of additions
required by the classical accumulate-and-add multiplication algorithm
($\frac{m}2$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1540</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1540</id><created>2011-04-08</created><updated>2011-12-27</updated><authors><author><keyname>Herbreteau</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Srivathsan</keyname><forenames>B.</forenames></author><author><keyname>Walukiewicz</keyname><forenames>Igor</forenames></author></authors><title>Efficient Emptiness Check for Timed B\&quot;uchi Automata (Extended version)</title><categories>cs.LO</categories><comments>Published in the Special Issue on Computer Aided Verification - CAV
  2010; Formal Methods in System Design, 2011</comments><doi>10.1007/s10703-011-0133-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The B\&quot;uchi non-emptiness problem for timed automata refers to deciding if a
given automaton has an infinite non-Zeno run satisfying the B\&quot;uchi accepting
condition. The standard solution to this problem involves adding an auxiliary
clock to take care of the non-Zenoness. In this paper, it is shown that this
simple transformation may sometimes result in an exponential blowup. A
construction avoiding this blowup is proposed. It is also shown that in many
cases, non-Zenoness can be ascertained without extra construction. An
on-the-fly algorithm for the non-emptiness problem, using non-Zenoness
construction only when required, is proposed. Experiments carried out with a
prototype implementation of the algorithm are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1546</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1546</id><created>2011-04-08</created><authors><author><keyname>Claret</keyname><forenames>Guillaume</forenames></author><author><keyname>Mathieu</keyname><forenames>Micha&#xeb;l</forenames></author><author><keyname>Naccache</keyname><forenames>David</forenames></author><author><keyname>Seguin</keyname><forenames>Guillaume</forenames></author></authors><title>Physical Simulation of Inarticulate Robots</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we study the structure and the behavior of inarticulate robots.
We introduce a robot that moves by successive revolvings. The robot's structure
is analyzed, simulated and discussed in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1550</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1550</id><created>2011-04-08</created><updated>2011-12-22</updated><authors><author><keyname>Masmoudi</keyname><forenames>Khaled</forenames></author><author><keyname>Antonini</keyname><forenames>Marc</forenames></author><author><keyname>Kornprobst</keyname><forenames>Pierre</forenames></author></authors><title>A bio-inspired image coder with temporal scalability</title><categories>cs.CV cs.IT cs.NE math.IT</categories><comments>12 pages; Advanced Concepts for Intelligent Vision Systems (ACIVS
  2011)</comments><doi>10.1007/978-3-642-23687-7_41</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel bio-inspired and dynamic coding scheme for static images.
Our coder aims at reproducing the main steps of the visual stimulus processing
in the mammalian retina taking into account its time behavior. The main novelty
of this work is to show how to exploit the time behavior of the retina cells to
ensure, in a simple way, scalability and bit allocation. To do so, our main
source of inspiration will be the biologically plausible retina model called
Virtual Retina. Following a similar structure, our model has two stages. The
first stage is an image transform which is performed by the outer layers in the
retina. Here it is modelled by filtering the image with a bank of difference of
Gaussians with time-delays. The second stage is a time-dependent
analog-to-digital conversion which is performed by the inner layers in the
retina. Thanks to its conception, our coder enables scalability and bit
allocation across time. Also, our decoded images do not show annoying artefacts
such as ringing and block effects. As a whole, this article shows how to
capture the main properties of a biological system, here the retina, in order
to design a new efficient coder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1556</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1556</id><created>2011-04-08</created><updated>2011-05-09</updated><authors><author><keyname>Klein</keyname><forenames>Jan</forenames></author><author><keyname>Barbieri</keyname><forenames>Sebastiano</forenames></author><author><keyname>Bauer</keyname><forenames>Miriam H. A.</forenames></author><author><keyname>Nimsky</keyname><forenames>Christopher</forenames></author><author><keyname>Hahn</keyname><forenames>Horst K.</forenames></author></authors><title>Benchmarking the Quality of Diffusion-Weighted Images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel method that allows for measuring the quality of
diffusion-weighted MR images dependent on the image resolution and the image
noise. For this purpose, we introduce a new thresholding technique so that
noise and the signal can automatically be estimated from a single data set.
Thus, no user interaction as well as no double acquisition technique, which
requires a time-consuming proper geometrical registration, is needed. As a
coarser image resolution or slice thickness leads to a higher signal-to-noise
ratio (SNR), our benchmark determines a resolution-independent quality measure
so that images with different resolutions can be adequately compared. To
evaluate our method, a set of diffusion-weighted images from different vendors
is used. It is shown that the quality can efficiently be determined and that
the automatically computed SNR is comparable to the SNR which is measured
manually in a manually selected region of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1582</identifier>
 <datestamp>2011-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1582</id><created>2011-04-08</created><authors><author><keyname>Piancastelli</keyname><forenames>Luca</forenames></author><author><keyname>Frizziero</keyname><forenames>Leonardo</forenames></author><author><keyname>Marcoppido</keyname><forenames>Simone</forenames></author><author><keyname>Pezzuti</keyname><forenames>Eugenio</forenames></author></authors><title>A Fuzzy Control Algorithm for the Electronic Stability Program optimized
  for tyre burst control</title><categories>cs.SY math.OC</categories><comments>The problem of controlling cars is becoming difficult to be managed.
  Handling of cars on wet surfaces is becoming too hard. So, the
  car-manufacturers are adopting special systems to control stability. This
  paper wants to give a thrust to improve performances of these systems,
  integrating the conventional softwares with a Fuzzy Logic routine</comments><msc-class>93C42</msc-class><acm-class>C.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an improved Electronic Stability Program for cars that
can deal with the sudden burst of a tyre. The Improved Electronic Stability
Program (IESP) is based on a fuzzy logic algorithm. The IESP collects data from
the same sensors of a standard ESP and acts on brakes/throttle with the same
actuators. The IESP reads the driver steering angle and the dynamic condition
of the car and selectively acts on throttle and brakes in order to put the car
on the required direction even during a tyre burst.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1601</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1601</id><created>2011-04-08</created><updated>2012-10-04</updated><authors><author><keyname>Kucherov</keyname><forenames>Gregory</forenames></author></authors><title>On-line construction of position heaps</title><categories>cs.DS</categories><comments>to appear in Journal of Discrete Algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple linear-time on-line algorithm for constructing a position
heap for a string [Ehrenfeucht et al, 2011]. Our definition of position heap
differs slightly from the one proposed in [Ehrenfeucht et al, 2011] in that it
considers the suffixes ordered from left to right. Our construction is based on
classic suffix pointers and resembles the Ukkonen's algorithm for suffix trees
[Ukkonen, 1995]. Using suffix pointers, the position heap can be extended into
the augmented position heap that allows for a linear-time string matching
algorithm [Ehrenfeucht et al, 2011].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1605</identifier>
 <datestamp>2012-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1605</id><created>2011-04-08</created><updated>2012-10-05</updated><authors><author><keyname>Maniu</keyname><forenames>Silviu</forenames></author><author><keyname>Cautis</keyname><forenames>Bogdan</forenames></author></authors><title>Efficient Top-K Retrieval in Online Social Tagging Networks</title><categories>cs.IR cs.DB cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in this paper top-k query answering in social tagging systems,
also known as folksonomies. This problem requires a significant departure from
existing, socially agnostic techniques. In a network-aware context, one can
(and should) exploit the social links, which can indicate how users relate to
the seeker and how much weight their tagging actions should have in the result
build-up. We propose an algorithm that has the potential to scale to current
applications. While the problem has already been considered in previous
literature, this was done either under strong simplifying assumptions or under
choices that cannot scale to even moderate-size real world applications. We
first consider a key aspect of the problem, which is accessing the closest or
most relevant users for a given seeker. We describe how this can be done on the
fly (without any pre-computations) for several possible choices - arguably the
most natural ones - of proximity computation in a user network. Based on this,
our top-k algorithm is sound and complete, while addressing the scalability
issues of the existing ones. Importantly, our technique is instance optimal in
the case when the search relies exclusively on the social weight of tagging
actions. To further reduce response times, we then consider directions for
efficiency by approximation. Extensive experiments on real world data show that
our techniques can drastically improve the response time, without sacrificing
precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1653</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1653</id><created>2011-04-08</created><authors><author><keyname>Chinthapanti</keyname><forenames>Chakradhara Reddy</forenames></author></authors><title>Two Dimensional Random Patterns</title><categories>cs.CR</categories><comments>13 pages, 7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach to the generation of random sequences and two dimensional
random patterns is proposed in this paper in which random sequences are
generated by making use of either Delaunay triangulation or Voronoi diagrams
drawn from random points taken in a two dimensional plane. Both the random
sequences and two dimensional random patterns generated in this manner are
shown to be more random when compared to pseudo-random sequences and patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1672</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1672</id><created>2011-04-09</created><updated>2011-04-16</updated><authors><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Dimension-free tail inequalities for sums of random matrices</title><categories>math.PR cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive exponential tail inequalities for sums of random matrices with no
dependence on the explicit matrix dimensions. These are similar to the matrix
versions of the Chernoff bound and Bernstein inequality except with the
explicit matrix dimensions replaced by a trace quantity that can be small even
when the dimension is large or infinite. Some applications to principal
component analysis and approximate matrix multiplication are given to
illustrate the utility of the new bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1677</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1677</id><created>2011-04-09</created><updated>2011-12-03</updated><authors><author><keyname>Ahmad</keyname><forenames>Bashir</forenames></author><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author><author><keyname>Hussain</keyname><forenames>Shahid</forenames></author><author><keyname>Aslam</keyname><forenames>Muhammad Zaheer</forenames></author><author><keyname>Abbas</keyname><forenames>Zafar</forenames></author></authors><title>Automatic Vehicle Checking Agent (VCA)</title><categories>cs.AI</categories><comments>5 pages, 2 figures</comments><acm-class>I.2.1</acm-class><journal-ref>Control Theory and Informatics,ISSN 2224-5774 (print) ISSN
  2225-0492 (online),Vol 1, No.2, 2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A definition of intelligence is given in terms of performance that can be
quantitatively measured. In this study, we have presented a conceptual model of
Intelligent Agent System for Automatic Vehicle Checking Agent (VCA). To achieve
this goal, we have introduced several kinds of agents that exhibit intelligent
features. These are the Management agent, internal agent, External Agent,
Watcher agent and Report agent. Metrics and measurements are suggested for
evaluating the performance of Automatic Vehicle Checking Agent (VCA). Calibrate
data and test facilities are suggested to facilitate the development of
intelligent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1678</identifier>
 <datestamp>2012-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1678</id><created>2011-04-09</created><updated>2012-03-07</updated><authors><author><keyname>Aslam</keyname><forenames>Muhammad Zaheer</forenames></author><author><keyname>Nasimullah</keyname></author><author><keyname>Khan</keyname><forenames>Abdur Rashid</forenames></author></authors><title>A Proposed Decision Support System/Expert System for Guiding Fresh
  Students in Selecting a Faculty in Gomal University, Pakistan</title><categories>cs.AI</categories><comments>I have withdrawn for some changes</comments><acm-class>I.2.1</acm-class><journal-ref>Industrial Engineering Letters www.iiste.org ISSN 2224-6096
  (Print) ISSN 2225-0581(Online) Vol 1, No.4, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and development of a proposed rule based
Decision Support System that will help students in selecting the best suitable
faculty/major decision while taking admission in Gomal University, Dera Ismail
Khan, Pakistan. The basic idea of our approach is to design a model for testing
and measuring the student capabilities like intelligence, understanding,
comprehension, mathematical concepts plus his/her past academic record plus
his/her intelligence level, and applying the module results to a rule-based
decision support system to determine the compatibility of those capabilities
with the available faculties/majors in Gomal University. The result is shown as
a list of suggested faculties/majors with the student capabilities and
abilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1690</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1690</id><created>2011-04-09</created><authors><author><keyname>Petkovi&#x107;</keyname></author><author><keyname>D.</keyname><forenames>M.</forenames></author><author><keyname>Stanimirovi&#x107;</keyname></author><author><keyname>S.</keyname><forenames>P.</forenames></author><author><keyname>Tasi&#x107;</keyname></author><author><keyname>B</keyname><forenames>M.</forenames></author></authors><title>Effective partitioning method for computing weighted Moore-Penrose
  inverse</title><categories>cs.SC cs.DS math.FA</categories><msc-class>15A09, 68Q40</msc-class><journal-ref>Computers &amp; Mathematics with Applications, Volume 55, Issue 8,
  April 2008, Pages 1720-1734</journal-ref><doi>10.1016/j.camwa.2007.07.014</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We introduce a method and an algorithm for computing the weighted
Moore-Penrose inverse of multiple-variable polynomial matrix and the related
algorithm which is appropriated for sparse polynomial matrices. These methods
and algorithms are generalizations of algorithms developed in [M.B. Tasic, P.S.
Stanimirovic, M.D. Petkovic, Symbolic computation of weighted Moore-Penrose
inverse using partitioning method, Appl. Math. Comput. 189 (2007) 615-640] to
multiple-variable rational and polynomial matrices and improvements of these
algorithms on sparse matrices. Also, these methods are generalizations of the
partitioning method for computing the Moore-Penrose inverse of rational and
polynomial matrices introduced in [P.S. Stanimirovic, M.B. Tasic, Partitioning
method for rational and polynomial matrices, Appl. Math. Comput. 155 (2004)
137-163; M.D. Petkovic, P.S. Stanimirovic, Symbolic computation of the
Moore-Penrose inverse using partitioning method, Internat. J. Comput. Math. 82
(2005) 355-367] to the case of weighted Moore-Penrose inverse. Algorithms are
implemented in the symbolic computational package MATHEMATICA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1696</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1696</id><created>2011-04-09</created><authors><author><keyname>Tasi&#x107;</keyname></author><author><keyname>B.</keyname><forenames>M.</forenames></author><author><keyname>Stanimirovi&#x107;</keyname></author><author><keyname>S.</keyname><forenames>P.</forenames></author><author><keyname>Petkovi&#x107;</keyname></author><author><keyname>D</keyname><forenames>M.</forenames></author></authors><title>Symbolic computation of weighted Moore-Penrose inverse using
  partitioning method</title><categories>cs.SC cs.DS cs.MS math.FA</categories><msc-class>15A09, 68Q40</msc-class><journal-ref>Applied Mathematics and Computation, Volume 189, Issue 1, 1 June
  2007, Pages 615-640</journal-ref><doi>10.1016/j.amc.2006.11.114</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We propose a method and algorithm for computing the weighted Moore-Penrose
inverse of one-variable rational matrices. Continuing this idea, we develop an
algorithm for computing the weighted Moore-Penrose inverse of one-variable
polynomial matrix. These methods and algorithms are generalizations of the
method for computing the weighted Moore-Penrose inverse for constant matrices,
originated in Wang and Chen [G.R. Wang, Y.L. Chen, A recursive algorithm for
computing the weighted Moore-Penrose inverse AMN, J. Comput. Math. 4 (1986)
74-85], and the partitioning method for computing the Moore-Penrose inverse of
rational and polynomial matrices introduced in Stanimirovic and Tasic [P.S.
Stanimirovic, M.B. Tasic, Partitioning method for rational and polynomial
matrices, Appl. Math. Comput. 155 (2004) 137-163]. Algorithms are implemented
in the symbolic computational package MATHEMATICA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1697</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1697</id><created>2011-04-09</created><authors><author><keyname>Stanimirovi&#x107;</keyname></author><author><keyname>S.</keyname><forenames>P.</forenames></author><author><keyname>Tasi&#x107;</keyname></author><author><keyname>B</keyname><forenames>M.</forenames></author></authors><title>Computing generalized inverses using LU factorization of matrix product</title><categories>cs.SC cs.DS math.FA</categories><msc-class>15A09, 68Q40</msc-class><journal-ref>International Journal Of Computer Mathematics, Volume 85, Issue
  12, 2008, Pages 1865 - 1878</journal-ref><doi>10.1080/00207160701582077</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  An algorithm for computing {2, 3}, {2, 4}, {1, 2, 3}, {1, 2, 4} -inverses and
the Moore-Penrose inverse of a given rational matrix A is established. Classes
A(2, 3)s and A(2, 4)s are characterized in terms of matrix products (R*A)+R*
and T*(AT*)+, where R and T are rational matrices with appropriate dimensions
and corresponding rank. The proposed algorithm is based on these general
representations and the Cholesky factorization of symmetric positive matrices.
The algorithm is implemented in programming languages MATHEMATICA and DELPHI,
and illustrated via examples. Numerical results of the algorithm, corresponding
to the Moore-Penrose inverse, are compared with corresponding results obtained
by several known methods for computing the Moore-Penrose inverse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1698</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1698</id><created>2011-04-09</created><authors><author><keyname>Tasi&#xed;c</keyname><forenames>Milan B.</forenames></author><author><keyname>Stanimirovi&#x107;</keyname><forenames>Predrag S.</forenames></author><author><keyname>Pep&#xed;</keyname><forenames>Selver H.</forenames></author></authors><title>About the generalized LM-inverse and the weighted Moore-Penrose inverse</title><categories>cs.SC cs.DS cs.MS cs.NA math.FA</categories><msc-class>15A09, 68W30</msc-class><journal-ref>Applied Mathematics and Computation, Volume 216, Issue 1, 1 March
  2010, Pages 114-124</journal-ref><doi>10.1016/j.amc.2010.01.019</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The recursive method for computing the generalized LM-inverse of a constant
rectangular matrix augmented by a column vector is proposed in Udwadia and
Phohomsiri (2007) [16] and [17]. The corresponding algorithm for the sequential
determination of the generalized LM-inverse is established in the present
paper. We prove that the introduced algorithm for computing the generalized
LM-inverse and the algorithm for the computation of the weighted Moore-Penrose
inverse developed by Wang and Chen (1986) in [23] are equivalent algorithms.
Both of the algorithms are implemented in the present paper using the package
MATHEMATICA. Several rational test matrices and randomly generated constant
matrices are tested and the CPU time is compared and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1707</identifier>
 <datestamp>2011-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1707</id><created>2011-04-09</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Costello</keyname><forenames>Ben de Lacy</forenames></author><author><keyname>Holley</keyname><forenames>Julian</forenames></author><author><keyname>Gorecki</keyname><forenames>Jerzy</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Vesicle computers: Approximating Voronoi diagram on Voronoi automata</title><categories>cs.ET nlin.CG</categories><comments>Chaos, Solitons &amp; Fractals (2011), in press</comments><journal-ref>Chaos, Solitons &amp; Fractals Volume 44, Issue 7, July 2011, Pages
  480-489</journal-ref><doi>10.1016/j.chaos.2011.01.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Irregular arrangements of vesicles filled with excitable and precipitating
chemical systems are imitated by Voronoi automata --- finite-state machines
defined on a planar Voronoi diagram. Every Voronoi cell takes four states:
resting, excited, refractory and precipitate. A resting cell excites if it has
at least one excited neighbour; the cell precipitates if a ratio of excited
cells in its neighbourhood to its number of neighbours exceed certain
threshold. To approximate a Voronoi diagram on Voronoi automata we project a
planar set onto automaton lattice, thus cells corresponding to data-points are
excited. Excitation waves propagate across the Voronoi automaton, interact with
each other and form precipitate in result of the interaction. Configuration of
precipitate represents edges of approximated Voronoi diagram. We discover
relation between quality of Voronoi diagram approximation and precipitation
threshold, and demonstrate feasibility of our model in approximation Voronoi
diagram of arbitrary-shaped objects and a skeleton of a planar shape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1717</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1717</id><created>2011-04-09</created><authors><author><keyname>Alauzet</keyname><forenames>Frederic</forenames></author><author><keyname>Pironneau</keyname><forenames>Olivier</forenames></author></authors><title>Continuous and Discrete Adjoints to the Euler Equations for Fluids</title><categories>cs.CE math.NA physics.flu-dyn</categories><comments>30 pages 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adjoints are used in optimization to speed-up computations, simplify
optimality conditions or compute sensitivities. Because time is reversed in
adjoint equations with first order time derivatives, boundary conditions and
transmission conditions through shocks can be difficult to understand. In this
article we analyze the adjoint equations that arise in the context of
compressible flows governed by the Euler equations of fluid dynamics. We show
that the continuous adjoints and the discrete adjoints computed by automatic
differentiation agree numerically; in particular the adjoint is found to be
continuous at the shocks and usually discontinuous at contact discontinuities
by both.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1724</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1724</id><created>2011-04-09</created><authors><author><keyname>Hurley</keyname><forenames>Barry</forenames></author><author><keyname>Hurley</keyname><forenames>Ted</forenames></author></authors><title>Group ring cryptography</title><categories>math.GR cs.CR</categories><comments>This is to appear in Intl. J. Pure and Appl. Math</comments><msc-class>16S34, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptographic systems are derived using units in group rings. Combinations of
types of units in group rings give units not of any particular type. This
includes cases of taking powers of units and products of such powers and adds
the complexity of the {\em discrete logarithm} problem to the system.
  The method enables encryption and (error-correcting) coding to be combined
within one system. These group ring cryptographic systems may be combined in a
neat way with existing cryptographic systems, such as RSA, and a combination
has the combined strength of both systems. Examples are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1729</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1729</id><created>2011-04-09</created><authors><author><keyname>Iglberger</keyname><forenames>Klaus</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Ruede</keyname><forenames>Ulrich</forenames></author></authors><title>Expression Templates Revisited: A Performance Analysis of the Current ET
  Methodology</title><categories>cs.PF cs.PL</categories><comments>16 pages, 7 figures</comments><journal-ref>SIAM Journal on Scientific Computing 34(2), C42-C69 (2012)</journal-ref><doi>10.1137/110830125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last decade, Expression Templates (ET) have gained a reputation as an
efficient performance optimization tool for C++ codes. This reputation builds
on several ET-based linear algebra frameworks focused on combining both elegant
and high-performance C++ code. However, on closer examination the assumption
that ETs are a performance optimization technique cannot be maintained. In this
paper we demonstrate and explain the inability of current ET-based frameworks
to deliver high performance for dense and sparse linear algebra operations, and
introduce a new &quot;smart&quot; ET implementation that truly allows the combination of
high performance code with the elegance and maintainability of a
domain-specific language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1732</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1732</id><created>2011-04-09</created><updated>2012-01-04</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Sinop</keyname><forenames>Ali Kemal</forenames></author></authors><title>Optimal Column-Based Low-Rank Matrix Reconstruction</title><categories>cs.DS math.SP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that for any real-valued matrix $X \in \R^{m \times n}$, and
positive integers $r \ge k$, there is a subset of $r$ columns of $X$ such that
projecting $X$ onto their span gives a $\sqrt{\frac{r+1}{r-k+1}}$-approximation
to best rank-$k$ approximation of $X$ in Frobenius norm. We show that the
trade-off we achieve between the number of columns and the approximation ratio
is optimal up to lower order terms. Furthermore, there is a deterministic
algorithm to find such a subset of columns that runs in $O(r n m^{\omega} \log
m)$ arithmetic operations where $\omega$ is the exponent of matrix
multiplication. We also give a faster randomized algorithm that runs in $O(r n
m^2)$ arithmetic operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1738</identifier>
 <datestamp>2013-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1738</id><created>2011-04-09</created><updated>2013-03-05</updated><authors><author><keyname>Baeten</keyname><forenames>Jos C. M.</forenames></author><author><keyname>Luttik</keyname><forenames>Bas</forenames></author><author><keyname>van Tilburg</keyname><forenames>Paul</forenames></author></authors><title>Reactive Turing Machines</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose reactive Turing machines (RTMs), extending classical Turing
machines with a process-theoretical notion of interaction, and use it to define
a notion of executable transition system. We show that every computable
transition system with a bounded branching degree is simulated modulo
divergence-preserving branching bisimilarity by an RTM, and that every
effective transition system is simulated modulo the variant of branching
bisimilarity that does not require divergence preservation. We conclude from
these results that the parallel composition of (communicating) RTMs can be
simulated by a single RTM. We prove that there exist universal RTMs modulo
branching bisimilarity, but these essentially employ divergence to be able to
simulate an RTM of arbitrary branching degree. We also prove that modulo
divergence-preserving branching bisimilarity there are RTMs that are universal
up to their own branching degree. Finally, we establish a correspondence
between executability and finite definability in a simple process calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1742</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1742</id><created>2011-04-09</created><authors><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author></authors><title>Asymptotic Capacity Analysis for Adaptive Transmission Schemes under
  General Fading Distributions</title><categories>cs.IT math.IT</categories><comments>28 pages, 8 figures, submitted to IEEE Transactions on Information
  Theory</comments><doi>10.1109/TIT.2011.2173725</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymptotic comparisons of ergodic channel capacity at high and low
signal-to-noise ratios (SNRs) are provided for several adaptive transmission
schemes over fading channels with general distributions, including optimal
power and rate adaptation, rate adaptation only, channel inversion and its
variants. Analysis of the high-SNR pre-log constants of the ergodic capacity
reveals the existence of constant capacity difference gaps among the schemes
with a pre-log constant of ?1. Closed-form expressions for these high-SNR
capacity difference gaps are derived, which are proportional to the SNR loss
between these schemes in dB scale. The largest one of these gaps is found to be
between the optimal power and rate adaptation scheme and the channel inversion
scheme. Based on these expressions it is shown that the presence of space
diversity or multi-user diversity makes channel inversion arbitrarily close to
achieving optimal capacity at high SNR with sufficiently large number of
antennas or users. A low-SNR analysis also reveals that the presence of fading
provably always improves capacity at sufficiently low SNR, compared to the
additive white Gaussian noise (AWGN) case. Numerical results are shown to
corroborate our analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1745</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1745</id><created>2011-04-10</created><authors><author><keyname>Narasimhamurthy</keyname><forenames>Adarsh B.</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Zhang</keyname><forenames>Yuan</forenames></author></authors><title>Multi-User Diversity with Random Number of Users</title><categories>cs.IT math.IT</categories><comments>23 pages, 6 figures, submitted to IEEE Transactions on Wireless
  Communications</comments><doi>10.1109/TWC.2011.121911.111594</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-user diversity is considered when the number of users in the system is
random. The complete monotonicity of the error rate as a function of the
(deterministic) number of users is established and it is proved that
randomization of the number of users always leads to deterioration of average
system performance at any average SNR. Further, using stochastic ordering
theory, a framework for comparison of system performance for different user
distributions is provided. For Poisson distributed users, the difference in
error rate of the random and deterministic number of users cases is shown to
asymptotically approach zero as the average number of users goes to infinity
for any fixed average SNR. In contrast, for a finite average number of users
and high SNR, it is found that randomization of the number of users
deteriorates performance significantly, and the diversity order under fading is
dominated by the smallest possible number of users. For Poisson distributed
users communicating over Rayleigh faded channels, further closed-form results
are provided for average error rate, and the asymptotic scaling law for ergodic
capacity is also provided. Simulation results are provided to corroborate our
analytical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1770</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1770</id><created>2011-04-10</created><authors><author><keyname>Kerenidis</keyname><forenames>Iordanis</forenames></author><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>A quantum protocol for sampling correlated equilibria unconditionally
  and without a mediator</title><categories>cs.GT cs.CR quant-ph</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A correlated equilibrium is a fundamental solution concept in game theory
that enjoys many desirable properties. However, it requires a trusted mediator,
which is a major drawback in many practical applications. A computational
solution to this problem was proposed by Dodis, Halevi and Rabin. They extended
the original game by adding an initial communication stage and showed that any
correlated strategy for 2-player games can be achieved, provided that the
players are computationally bounded.
  In this paper, we show that if the players can communicate via a quantum
channel before the game, then any correlated equilibrium for 2-player games can
be achieved, without a trusted mediator and unconditionally. This provides
another example of a major advantage of quantum information processing. More
precisely, we prove that for any correlated equilibrium p of a strategic game
G, there exists an extended game (with a quantum communication initial stage) Q
with an efficiently computable approximate Nash equilibrium q, such that the
expected payoff for both players in q is at least as high as in p. The main
cryptographic tool used in the construction is the quantum weak coin flipping
protocol of Mochon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1789</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1789</id><created>2011-04-10</created><authors><author><keyname>Baek</keyname><forenames>Seung Ki</forenames></author><author><keyname>Bernhardsson</keyname><forenames>Sebastian</forenames></author><author><keyname>Minnhagen</keyname><forenames>Petter</forenames></author></authors><title>Zipf's law unzipped</title><categories>physics.soc-ph cs.SI</categories><comments>22 pages, 32 figures</comments><journal-ref>New J. Phys. 4, 043004 (2011)</journal-ref><doi>10.1088/1367-2630/13/4/043004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Why does Zipf's law give a good description of data from seemingly completely
unrelated phenomena? Here it is argued that the reason is that they can all be
described as outcomes of a ubiquitous random group division: the elements can
be citizens of a country and the groups family names, or the elements can be
all the words making up a novel and the groups the unique words, or the
elements could be inhabitants and the groups the cities in a country, and so
on. A Random Group Formation (RGF) is presented from which a Bayesian estimate
is obtained based on minimal information: it provides the best prediction for
the number of groups with $k$ elements, given the total number of elements,
groups, and the number of elements in the largest group. For each specification
of these three values, the RGF predicts a unique group distribution
$N(k)\propto \exp(-bk)/k^{\gamma}$, where the power-law index $\gamma$ is a
unique function of the same three values. The universality of the result is
made possible by the fact that no system specific assumptions are made about
the mechanism responsible for the group division. The direct relation between
$\gamma$ and the total number of elements, groups, and the number of elements
in the largest group, is calculated. The predictive power of the RGF model is
demonstrated by direct comparison with data from a variety of systems. It is
shown that $\gamma$ usually takes values in the interval $1\leq\gamma\leq 2$
and that the value for a given phenomena depends in a systematic way on the
total size of the data set. The results are put in the context of earlier
discussions on Zipf's and Gibrat's laws, $N(k)\propto k^{-2}$ and the
connection between growth models and RGF is elucidated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1806</identifier>
 <datestamp>2015-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1806</id><created>2011-04-10</created><authors><author><keyname>Brough</keyname><forenames>Tara</forenames></author></authors><title>Groups with poly-context-free word problem</title><categories>math.GR cs.FL</categories><comments>38 pages, no figures</comments><msc-class>20F10, 68Q45 (primary), 03D40 (secondary)</msc-class><journal-ref>Groups Complexity Cryptology, Volume 6, Issue 1, Pages 9-29 (2014)</journal-ref><doi>10.1515/gcc-2014-0002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the class of groups whose word problem is poly-context-free; that
is, an intersection of finitely many context-free languages. We show that any
group which is virtually a finitely generated subgroup of a direct product of
free groups has poly-context-free word problem, and conjecture that the
converse also holds. We prove our conjecture for several classes of soluble
groups, including metabelian groups and torsion-free soluble groups, and
present progress towards resolving the conjecture for soluble groups in
general. Some of the techniques introduced for proving languages not to be
poly-context-free may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1822</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1822</id><created>2011-04-10</created><authors><author><keyname>Hwang</keyname><forenames>Eduardo</forenames></author></authors><title>Dimensionality Decrease Heuristics for NP Complete Problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast majority of scientific community believes that P!=NP, with countless
supporting arguments. The number of people who believe otherwise probably
amounts to as few as those opposing the 2nd Law of Thermodynamics. But isn't
nature elegant enough, not to resource to brute-force search? In this article,
a novel concept of dimensionality is presented, which may lead to a more
efficient class of heuristic implementations to solve NP complete problems.
Thus, broadening the universe of man-machine tractable problems.
Dimensionality, as defined here, will be a closer analog of strain energy in
nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1823</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1823</id><created>2011-04-10</created><authors><author><keyname>Ba&#x161;i&#x107;</keyname><forenames>Milan</forenames></author></authors><title>Which weighted circulant networks have perfect state transfer?</title><categories>cs.DM cs.IT math.IT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question of perfect state transfer existence in quantum spin networks
based on weighted graphs has been recently presented by many authors. We give a
simple condition for characterizing weighted circulant graphs allowing perfect
state transfer in terms of their eigenvalues. This is done by extending the
results about quantum periodicity existence in the networks obtained by Saxena,
Severini and Shparlinski and characterizing integral graphs among weighted
circulant graphs. Finally, classes of weighted circulant graphs supporting
perfect state transfer are found. These classes completely cover the class of
circulant graphs having perfect state transfer in the unweighted case. In fact,
we show that there exists an weighted integral circulant graph with $n$
vertices having perfect state transfer if and only if $n$ is even. Moreover we
prove the non-existence of perfect state transfer for several other classes of
weighted integral circulant graphs of even order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1824</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1824</id><created>2011-04-10</created><authors><author><keyname>Cabarle</keyname><forenames>Francis</forenames></author><author><keyname>Adorna</keyname><forenames>Henry</forenames></author><author><keyname>Martinez-del-Amor</keyname><forenames>Miguel A.</forenames></author></authors><title>Simulating Spiking Neural P systems without delays using GPUs</title><categories>cs.DC cs.ET cs.FL cs.NE q-bio.NC</categories><comments>19 pages in total, 4 figures, listings/algorithms, submitted at the
  9th Brainstorming Week in Membrane Computing, University of Seville, Spain</comments><msc-class>68Q85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper our work regarding simulating a type of P system
known as a spiking neural P system (SNP system) using graphics processing units
(GPUs). GPUs, because of their architectural optimization for parallel
computations, are well-suited for highly parallelizable problems. Due to the
advent of general purpose GPU computing in recent years, GPUs are not limited
to graphics and video processing alone, but include computationally intensive
scientific and mathematical applications as well. Moreover P systems, including
SNP systems, are inherently and maximally parallel computing models whose
inspirations are taken from the functioning and dynamics of a living cell. In
particular, SNP systems try to give a modest but formal representation of a
special type of cell known as the neuron and their interactions with one
another. The nature of SNP systems allowed their representation as matrices,
which is a crucial step in simulating them on highly parallel devices such as
GPUs. The highly parallel nature of SNP systems necessitate the use of hardware
intended for parallel computations. The simulation algorithms, design
considerations, and implementation are presented. Finally, simulation results,
observations, and analyses using an SNP system that generates all numbers in
$\mathbb N$ - {1} are discussed, as well as recommendations for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1825</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1825</id><created>2011-04-10</created><authors><author><keyname>Ba&#x161;i&#x107;</keyname><forenames>Milan</forenames></author></authors><title>Characterization of circulant graphs having perfect state transfer</title><categories>cs.DM cs.IT math.IT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we answer the question of when circulant quantum spin networks
with nearest-neighbor couplings can give perfect state transfer. The network is
described by a circulant graph $G$, which is characterized by its circulant
adjacency matrix $A$. Formally, we say that there exists a {\it perfect state
transfer} (PST) between vertices $a,b\in V(G)$ if $|F(\tau)_{ab}|=1$, for some
positive real number $\tau$, where $F(t)=\exp(\i At)$. Saxena, Severini and
Shparlinski ({\it International Journal of Quantum Information} 5 (2007),
417--430) proved that $|F(\tau)_{aa}|=1$ for some $a\in V(G)$ and $\tau\in
\R^+$ if and only if all eigenvalues of $G$ are integer (that is, the graph is
integral). The integral circulant graph $\ICG_n (D)$ has the vertex set $Z_n =
\{0, 1, 2, ..., n - 1\}$ and vertices $a$ and $b$ are adjacent if
$\gcd(a-b,n)\in D$, where $D \subseteq \{d : d \mid n,\ 1\leq d&lt;n\}$. These
graphs are highly symmetric and have important applications in chemical graph
theory. We show that $\ICG_n (D)$ has PST if and only if $n\in 4\N$ and
$D=\widetilde{D_3}\cup D_2\cup 2D_2\cup 4D_2\cup \{n/2^a\}$, where
$\widetilde{D_3}=\{d\in D\ |\ n/d\in 8\N\}$, $D_2= \{d\in D\ |\ n/d\in
8\N+4\}\setminus \{n/4\}$ and $a\in\{1,2\}$. We have thus answered the question
of complete characterization of perfect state transfer in integral circulant
graphs raised in {\it Quantum Information and Computation}, Vol. 10, No. 3&amp;4
(2010) 0325--0342 by Angeles-Canul {\it et al.} Furthermore, we also calculate
perfect quantum communication distance (distance between vertices where PST
occurs) and describe the spectra of integral circulant graphs having PST. We
conclude by giving a closed form expression calculating the number of integral
circulant graphs of a given order having PST.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1852</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1852</id><created>2011-04-11</created><authors><author><keyname>Lee</keyname><forenames>Tony T.</forenames></author><author><keyname>Wan</keyname><forenames>Yujie</forenames></author><author><keyname>Guan</keyname><forenames>Hao</forenames></author></authors><title>Randomized $\Delta$-Edge-Coloring via Quaternion of Complex Colors</title><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper explores the application of a new algebraic method of color
exchanges to the edge coloring of simple graphs. Vizing's theorem states that
the edge coloring of a simple graph $G$ requires either $\Delta$ or $\Delta+1$
colors, where $\Delta$ is the maximum vertex degree of $G$. Holyer proved that
it is {\bf NP}-complete to decide whether $G$ is $\Delta$-edge-colorable even
for cubic graphs. By introducing the concept of complex colors, we show that
the color-exchange operation follows the same multiplication rules as
quaternion. An initially $\Delta$-edge-colored graph $G$ allows
variable-colored edges, which can be eliminated by color exchanges in a manner
similar to variable eliminations in solving systems of linear equations. The
problem is solved if all variables are eliminated and a properly
$\Delta$-edge-colored graph is reached. For a randomly generated graph $G$, we
prove that our algorithm returns a proper $\Delta$-edge-coloring with a
probability of at least 1/2 in $O(\Delta|V||E|^5)$ time if $G$ is
$\Delta$-edge-colorable. Otherwise, the algorithm halts in polynomial time and
signals the impossibility of a solution, meaning that the chromatic index of
$G$ probably equals $\Delta+1$. Animations of the edge-coloring algorithms
proposed in this paper are posted at YouTube
http://www.youtube.com/watch?v=KMnj4UMYl7k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1859</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1859</id><created>2011-04-11</created><authors><author><keyname>Amdouni</keyname><forenames>Ichrak</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Minet</keyname><forenames>Pascale</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Adjih</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Node coloring for dense wireless sensor networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><report-no>RR-7588</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coloring is used in wireless networks to improve communication efficiency,
mainly in terms of bandwidth, energy and possibly end-to-end delays. In this
research report, we define the h-hop node coloring problem, with h any positive
integer. We prove that the associated decision problem is NP-complete. We then
present a 3-hop distributed coloring algorithm that is optimized for dense
networks: a node does not need to exchange the priorities and colors of its
2-hop neighbors. Through simulation results, we highlight the impact of
priority assignment on the number of colors obtained for any network. We then
focus on grids and identify a color pattern that can be reproduced to color the
whole grid. We show how the coloring algorithm can use regularity properties to
obtain a periodic color pattern with the optimal number of colors. We then
consider grids with holes and study how to extend our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1872</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1872</id><created>2011-04-11</created><updated>2011-09-16</updated><authors><author><keyname>Mairal</keyname><forenames>Julien</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Jenatton</keyname><forenames>Rodolphe</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Obozinski</keyname><forenames>Guillaume</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Convex and Network Flow Optimization for Structured Sparsity</title><categories>math.OC cs.LG stat.ML</categories><comments>to appear in the Journal of Machine Learning Research (JMLR)</comments><proxy>ccsd</proxy><journal-ref>Journal of Machine Learning Research 12 (2011) 2681?2720</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of learning problems regularized by a structured
sparsity-inducing norm defined as the sum of l_2- or l_infinity-norms over
groups of variables. Whereas much effort has been put in developing fast
optimization techniques when the groups are disjoint or embedded in a
hierarchy, we address here the case of general overlapping groups. To this end,
we present two different strategies: On the one hand, we show that the proximal
operator associated with a sum of l_infinity-norms can be computed exactly in
polynomial time by solving a quadratic min-cost flow problem, allowing the use
of accelerated proximal gradient methods. On the other hand, we use proximal
splitting techniques, and address an equivalent formulation with
non-overlapping groups, but in higher dimension and with additional
constraints. We propose efficient and scalable algorithms exploiting these two
strategies, which are significantly faster than alternative approaches. We
illustrate these methods with several problems such as CUR matrix
factorization, multi-task learning of tree-structured dictionaries, background
subtraction in video sequences, image denoising with wavelets, and topographic
dictionary learning of natural image patches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1880</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1880</id><created>2011-04-11</created><authors><author><keyname>Enqvist</keyname><forenames>Per</forenames></author></authors><title>Approximative Covariance Interpolation</title><categories>math.OC cs.SY</categories><comments>MTNS 2010 paper</comments><msc-class>93B30 (Primary), 93B15 (Secondary)</msc-class><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When methods of moments are used for identification of power spectral
densities, a model is matched to estimated second order statistics such as,
e.g., covariance estimates. If the estimates are good there is an infinite
family of power spectra consistent with such an estimate and in applications,
such as identification, we want to single out the most representative spectrum.
We choose a prior spectral density to represent a priori information, and the
spectrum closest to it in a given quasi-distance is determined. However, if the
estimates are based on few data, or the model class considered is not
consistent with the process considered, it may be necessary to use an
approximative covariance interpolation. Two different types of regularizations
are considered in this paper that can be applied on many covariance
interpolation based estimation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1892</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1892</id><created>2011-04-11</created><authors><author><keyname>Suresh</keyname><forenames>K.</forenames></author></authors><title>&quot;Improved FCM algorithm for Clustering on Web Usage Mining&quot;</title><categories>cs.IR cs.CV</categories><comments>ISSN(Online):1694-0814.
  http://www.ijcsi.org/papers/IJCSI-8-1-42-45.pdf</comments><journal-ref>IJCSI International Journal of Computer Sciencec Issues, Vol.8
  Issue 1, January 2011, p42-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present clustering method is very sensitive to the initial
center values, requirements on the data set too high, and cannot handle noisy
data the proposal method is using information entropy to initialize the cluster
centers and introduce weighting parameters to adjust the location of cluster
centers and noise problems.The navigation datasets which are sequential in
nature, Clustering web data is finding the groups which share common interests
and behavior by analyzing the data collected in the web servers, this improves
clustering on web data efficiently using improved fuzzy c-means(FCM)
clustering. Web usage mining is the application of data mining techniques to
web log data repositories. It is used in finding the user access patterns from
web access log. Web data Clusters are formed using on MSNBC web navigation
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1905</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1905</id><created>2011-04-11</created><updated>2011-08-12</updated><authors><author><keyname>Lemmen</keyname><forenames>Carsten</forenames></author><author><keyname>Gronenborn</keyname><forenames>Detlef</forenames></author><author><keyname>Wirtz</keyname><forenames>Kai W.</forenames></author></authors><title>A simulation of the Neolithic transition in Western Eurasia</title><categories>cs.MA q-bio.PE</categories><comments>Accepted Author Manuscript version accepted for publication in
  Journal of Archaeological Science. A definitive version will be subsequently
  published in the Journal of Archaological Science</comments><journal-ref>Journal of Archaeological Science Vol 38 (12), pp. 3459-3470, 2011</journal-ref><doi>10.1016/j.jas.2011.08.008</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Farming and herding were introduced to Europe from the Near East and
Anatolia; there are, however, considerable arguments about the mechanisms of
this transition. Were it people who moved and outplaced the indigenous hunter-
gatherer groups or admixed with them? Or was it just material and information
that moved-the Neolithic Package-consisting of domesticated plants and animals
and the knowledge of its use? The latter process is commonly referred to as
cultural diffusion and the former as demic diffusion. Despite continuous and
partly combined efforts by archaeologists, anthropologists, linguists,
paleontologists and geneticists a final resolution of the debate has not yet
been reached. In the present contribution we interpret results from the Global
Land Use and technological Evolution Simulator (GLUES), a mathematical model
for regional sociocultural development embedded in the western Eurasian
geoenvironmental context during the Holocene. We demonstrate that the model is
able to realistically hindcast the expansion speed and the inhomogeneous
space-time evolution of the transition to agropastoralism in Europe. GLUES, in
contrast to models that do not resolve endogenous sociocultural dynamics, also
describes and explains how and why the Neolithic advanced in stages. In the
model analysis, we uncouple the mechanisms of migration and information
exchange. We find that (1) an indigenous form of agropastoralism could well
have arisen in certain Mediterranean landscapes, but not in Northern and
Central Europe, where it depended on imported technology and material, (2) both
demic diffusion by migration or cultural diffusion by trade may explain the
western European transition equally well, (3) [...]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1910</identifier>
 <datestamp>2011-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1910</id><created>2011-04-11</created><authors><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author></authors><title>Tails of Random Matrix Diagonal Elements: The Case of the Wishart
  Inverse</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>To appear in Acta Physica Polonica B</comments><journal-ref>Acta Physica Polonica B, vol 42, no 5, pp. 1105-1122, (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analytically compute the large-deviation probability of a diagonal matrix
element of two cases of random matrices, namely $\beta=[\vec H^\dagger\vec
H]^{-1}_{11}$ and $\gamma=[\vec I_N+\rho\vec H^\dagger\vec H]^{-1}_{11}$, where
$\vec H$ is a $M\times N$ complex Gaussian matrix with independent entries and
$M\geq N$. These diagonal entries are related to the &quot;signal to interference
and noise ratio&quot; (SINR) in multi-antenna communications. They depend not only
on the eigenvalues but also on the corresponding eigenfunction weights, which
we are able to evaluate on average constrained on the value of the SINR. We
also show that beyond a lower and upper critical value of $\beta$, $\gamma$,
the maximum and minimum eigenvalues, respectively, detach from the bulk.
Responsible for this detachment is the fact that the corresponding eigenvalue
weight becomes macroscopic (i.e. O(1)), and hence exerts a strong repulsion to
the eigenvalue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1924</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1924</id><created>2011-04-11</created><authors><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>Rational Deployment of CSP Heuristics</title><categories>cs.AI</categories><comments>7 pages, 2 figures, to appear in IJCAI-2011, http://www.ijcai.org/</comments><journal-ref>IJCAI-2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heuristics are crucial tools in decreasing search effort in varied fields of
AI. In order to be effective, a heuristic must be efficient to compute, as well
as provide useful information to the search algorithm. However, some well-known
heuristics which do well in reducing backtracking are so heavy that the gain of
deploying them in a search algorithm might be outweighed by their overhead.
  We propose a rational metareasoning approach to decide when to deploy
heuristics, using CSP backtracking search as a case study. In particular, a
value of information approach is taken to adaptive deployment of solution-count
estimation heuristics for value ordering. Empirical results show that indeed
the proposed mechanism successfully balances the tradeoff between decreasing
backtracking and heuristic computational overhead, resulting in a significant
overall search time reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1929</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1929</id><created>2011-04-11</created><authors><author><keyname>Ramezanpour</keyname><forenames>A.</forenames></author><author><keyname>Realpe-Gomez</keyname><forenames>J.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Statistical physics approach to graphical games: local and global
  interactions</title><categories>cond-mat.stat-mech cs.GT</categories><comments>32 pages, 11 figures, to be published in Eur. Phys. J. B</comments><journal-ref>Eur. Phys. J. B 81, 327 (2011)</journal-ref><doi>10.1140/epjb/e2011-10963-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a graphical game agents play with their neighbors on a graph to achieve an
appropriate state of equilibrium. Here relevant problems are characterizing the
equilibrium set and discovering efficient algorithms to find such an
equilibrium (solution). We consider a representation of games that extends over
graphical games to deal conveniently with both local a global interactions and
use the cavity method of statistical physics to study the geometrical structure
of the equilibria space. The method also provides a distributive and local
algorithm to find an equilibrium. For simplicity we consider only pure Nash
equilibria but the methods can as well be extended to deal with (approximated)
mixed Nash equilirbia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1945</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1945</id><created>2011-04-11</created><authors><author><keyname>Shirdhonkar</keyname><forenames>M. S.</forenames></author><author><keyname>Kokare</keyname><forenames>Manesh B.</forenames></author></authors><title>Off-Line Handwritten Signature Retrieval using Curvelet Transforms</title><categories>cs.CV</categories><comments>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol.8, No.8, 2010</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, a new method for offline handwritten signature retrieval is
based on curvelet transform is proposed. Many applications in image processing
require similarity retrieval of an image from a large collection of images. In
such cases, image indexing becomes important for efficient organization and
retrieval of images. This paper addresses this issue in the context of a
database of handwritten signature images and describes a system for similarity
retrieval. The proposed system uses a curvelet based texture features
extraction. The performance of the system has been tested with an image
database of 180 signatures. The results obtained indicate that the proposed
system is able to identify signatures with great with accuracy even when a part
of a signature is missing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1962</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1962</id><created>2011-04-11</created><authors><author><keyname>Ferdouse</keyname><forenames>Lilatul</forenames></author><author><keyname>Akhter</keyname><forenames>Nasrin</forenames></author><author><keyname>Nipa</keyname><forenames>Tamanna Haque</forenames></author><author><keyname>Jaigirdar</keyname><forenames>Fariha Tasmin</forenames></author></authors><title>Simulation and Performance Analysis of Adaptive Filtering Algorithms in
  Noise Cancellation</title><categories>cs.OH</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 1, January 2011, 185-192</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noise problems in signals have gained huge attention due to the need of
noise-free output signal in numerous communication systems. The principal of
adaptive noise cancellation is to acquire an estimation of the unwanted
interfering signal and subtract it from the corrupted signal. Noise
cancellation operation is controlled adaptively with the target of achieving
improved signal to noise ratio. This paper concentrates upon the analysis of
adaptive noise canceller using Recursive Least Square (RLS), Fast Transversal
Recursive Least Square (FTRLS) and Gradient Adaptive Lattice (GAL) algorithms.
The performance analysis of the algorithms is done based on convergence
behavior, convergence time, correlation coefficients and signal to noise ratio.
After comparing all the simulated results we observed that GAL performs the
best in noise cancellation in terms of Correlation Coefficient, SNR and
Convergence Time. RLS, FTRLS and GAL were never evaluated and compared before
on their performance in noise cancellation in terms of the criteria we
considered here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1964</identifier>
 <datestamp>2015-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1964</id><created>2011-04-11</created><updated>2015-02-19</updated><authors><author><keyname>Divroodi</keyname><forenames>Ali Rezaei</forenames></author><author><keyname>Nguyen</keyname><forenames>Linh Anh</forenames></author></authors><title>On Bisimulations for Description Logics</title><categories>cs.LO</categories><comments>42 pages</comments><journal-ref>Ali Rezaei Divroodi, Linh Anh Nguyen: On bisimulations for
  description logics. Information Sciences 295: 465-493 (2015)</journal-ref><doi>10.1016/j.ins.2014.10.022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study bisimulations for useful description logics. The simplest among the
considered logics is $\mathcal{ALC}_{reg}$ (a variant of PDL). The others
extend that logic with inverse roles, nominals, quantified number restrictions,
the universal role, and/or the concept constructor for expressing the local
reflexivity of a role. They also allow role axioms. We give results about
invariance of concepts, TBoxes and ABoxes, preservation of RBoxes and knowledge
bases, and the Hennessy-Milner property w.r.t. bisimulations in the considered
description logics. Using the invariance results we compare the expressiveness
of the considered description logics w.r.t. concepts, TBoxes and ABoxes. Our
results about separating the expressiveness of description logics are naturally
extended to the case when instead of $\mathcal{ALC}_{reg}$ we have any sublogic
of $\mathcal{ALC}_{reg}$ that extends $\mathcal{ALC}$. We also provide results
on the largest auto-bisimulations and quotient interpretations w.r.t. such
equivalence relations. Such results are useful for minimizing interpretations
and concept learning in description logics. To deal with minimizing
interpretations for the case when the considered logic allows quantified number
restrictions and/or the constructor for the local reflexivity of a role, we
introduce a new notion called QS-interpretation, which is needed for obtaining
expected results. By adapting Hopcroft's automaton minimization algorithm and
the Paige-Tarjan algorithm, we give efficient algorithms for computing the
partition corresponding to the largest auto-bisimulation of a finite
interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1970</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1970</id><created>2011-04-11</created><authors><author><keyname>Munuera</keyname><forenames>Carlos</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Barbier</keyname><forenames>Morgan</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>Wet paper codes and the dual distance in steganography</title><categories>cs.CR cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1998 Crandall introduced a method based on coding theory to secretly embed
a message in a digital support such as an image. Later Fridrich et al. improved
this method to minimize the distortion introduced by the embedding; a process
called wet paper. However, as previously emphasized in the literature, this
method can fail during the embedding step. Here we find sufficient and
necessary conditions to guarantee a successful embedding by studying the dual
distance of a linear code. Since these results are essentially of combinatorial
nature, they can be generalized to systematic codes, a large family containing
all linear codes. We also compute the exact number of solutions and point out
the relationship between wet paper codes and orthogonal arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1971</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1971</id><created>2011-04-11</created><updated>2011-05-24</updated><authors><author><keyname>Rogers</keyname><forenames>Tim</forenames></author><author><keyname>McKane</keyname><forenames>Alan J.</forenames></author></authors><title>A unified framework for Schelling's model of segregation</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>21 pages, 3 figures</comments><journal-ref>J. Stat. Mech. (2011) P07006</journal-ref><doi>10.1088/1742-5468/2011/07/P07006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schelling's model of segregation is one of the first and most influential
models in the field of social simulation. There are many variations of the
model which have been proposed and simulated over the last forty years, though
the present state of the literature on the subject is somewhat fragmented and
lacking comprehensive analytical treatments. In this article a unified
mathematical framework for Schelling's model and its many variants is
developed. This methodology is useful in two regards: firstly, it provides a
tool with which to understand the differences observed between models;
secondly, phenomena which appear in several model variations may be understood
in more depth through analytic studies of simpler versions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1987</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1987</id><created>2011-04-11</created><updated>2012-11-23</updated><authors><author><keyname>Platzer</keyname><forenames>Andre</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>The Structure of Differential Invariants and Differential Cut
  Elimination</title><categories>cs.LO math.CA math.DS math.LO</categories><proxy>LMCS</proxy><acm-class>math.CA</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 4 (November
  21, 2012) lmcs:809</journal-ref><doi>10.2168/LMCS-8(4:16)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The biggest challenge in hybrid systems verification is the handling of
differential equations. Because computable closed-form solutions only exist for
very simple differential equations, proof certificates have been proposed for
more scalable verification. Search procedures for these proof certificates are
still rather ad-hoc, though, because the problem structure is only understood
poorly. We investigate differential invariants, which define an induction
principle for differential equations and which can be checked for invariance
along a differential equation just by using their differential structure,
without having to solve them. We study the structural properties of
differential invariants. To analyze trade-offs for proof search complexity, we
identify more than a dozen relations between several classes of differential
invariants and compare their deductive power. As our main results, we analyze
the deductive power of differential cuts and the deductive power of
differential invariants with auxiliary differential variables. We refute the
differential cut elimination hypothesis and show that, unlike standard cuts,
differential cuts are fundamental proof principles that strictly increase the
deductive power. We also prove that the deductive power increases further when
adding auxiliary differential variables to the dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1990</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1990</id><created>2011-04-11</created><updated>2013-02-19</updated><authors><author><keyname>Xu</keyname><forenames>Kevin S.</forenames></author><author><keyname>Kliger</keyname><forenames>Mark</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames><suffix>III</suffix></author></authors><title>Adaptive Evolutionary Clustering</title><categories>cs.LG stat.ML</categories><comments>To appear in Data Mining and Knowledge Discovery, MATLAB toolbox
  available at http://tbayes.eecs.umich.edu/xukevin/affect</comments><acm-class>I.5.3; H.3.3; G.3</acm-class><journal-ref>Data Mining and Knowledge Discovery 28 (2014) 304-336</journal-ref><doi>10.1007/s10618-012-0302-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many practical applications of clustering, the objects to be clustered
evolve over time, and a clustering result is desired at each time step. In such
applications, evolutionary clustering typically outperforms traditional static
clustering by producing clustering results that reflect long-term trends while
being robust to short-term variations. Several evolutionary clustering
algorithms have recently been proposed, often by adding a temporal smoothness
penalty to the cost function of a static clustering method. In this paper, we
introduce a different approach to evolutionary clustering by accurately
tracking the time-varying proximities between objects followed by static
clustering. We present an evolutionary clustering framework that adaptively
estimates the optimal smoothing parameter using shrinkage estimation, a
statistical approach that improves a naive estimate using additional
information. The proposed framework can be used to extend a variety of static
clustering algorithms, including hierarchical, k-means, and spectral
clustering, into evolutionary clustering algorithms. Experiments on synthetic
and real data sets indicate that the proposed framework outperforms static
clustering and existing evolutionary clustering algorithms in many scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.1998</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.1998</id><created>2011-04-11</created><updated>2011-06-20</updated><authors><author><keyname>Atkey</keyname><forenames>Robert</forenames><affiliation>University of Strathclyde</affiliation></author></authors><title>Amortised Resource Analysis with Separation Logic</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>D.2.4, F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (June 23,
  2011) lmcs:685</journal-ref><doi>10.2168/LMCS-7(2:17)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Type-based amortised resource analysis following Hofmann and Jost---where
resources are associated with individual elements of data structures and doled
out to the programmer under a linear typing discipline---have been successful
in providing concrete resource bounds for functional programs, with good
support for inference. In this work we translate the idea of amortised resource
analysis to imperative pointer-manipulating languages by embedding a logic of
resources, based on the affine intuitionistic Logic of Bunched Implications,
within Separation Logic. The Separation Logic component allows us to assert the
presence and shape of mutable data structures on the heap, while the resource
component allows us to state the consumable resources associated with each
member of the structure. We present the logic on a small imperative language,
based on Java bytecode, with procedures and mutable heap. We have formalised
the logic and its soundness property within the Coq proof assistant and
extracted a certified verification condition generator. We also describe an
proof search procedure that allows generated verification conditions to be
discharged while using linear programming to infer consumable resource
annotations. We demonstrate the logic on some examples, including proving the
termination of in-place list reversal on lists with cyclic tails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2005</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2005</id><created>2011-04-11</created><authors><author><keyname>He</keyname><forenames>Huan</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Liu</keyname><forenames>Ying</forenames></author></authors><title>Internet Resource Pricing Models, Mechanisms, and Methods</title><categories>cs.NI</categories><comments>Submitted to Networking Science for peer review</comments><acm-class>C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the fast development of video and voice network applications, CDN
(Content Distribution Networks) and P2P (Peer-to-Peer) content distribution
technologies have gradually matured. How to effectively use Internet resources
thus has attracted more and more attentions. For the study of resource pricing,
a whole pricing strategy containing pricing models, mechanisms and methods
covers all the related topics. We first introduce three basic Internet resource
pricing models through an Internet cost analysis. Then, with the evolution of
service types, we introduce several corresponding mechanisms which can ensure
pricing implementation and resource allocation. On network resource pricing
methods, we discuss the utility optimization in economics, and emphasize two
classes of pricing methods (including system optimization and entities'
strategic optimizations). Finally, we conclude the paper and forecast the
research direction on pricing strategy which is applicable to novel service
situation in the near future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2018</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2018</id><created>2011-04-11</created><authors><author><keyname>Kakade</keyname><forenames>Sham</forenames></author><author><keyname>Kalai</keyname><forenames>Adam Tauman</forenames></author><author><keyname>Kanade</keyname><forenames>Varun</forenames></author><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author></authors><title>Efficient Learning of Generalized Linear and Single Index Models with
  Isotonic Regression</title><categories>cs.AI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized Linear Models (GLMs) and Single Index Models (SIMs) provide
powerful generalizations of linear regression, where the target variable is
assumed to be a (possibly unknown) 1-dimensional function of a linear
predictor. In general, these problems entail non-convex estimation procedures,
and, in practice, iterative local search heuristics are often used. Kalai and
Sastry (2009) recently provided the first provably efficient method for
learning SIMs and GLMs, under the assumptions that the data are in fact
generated under a GLM and under certain monotonicity and Lipschitz constraints.
However, to obtain provable performance, the method requires a fresh sample
every iteration. In this paper, we provide algorithms for learning GLMs and
SIMs, which are both computationally and statistically efficient. We also
provide an empirical study, demonstrating their feasibility in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2026</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2026</id><created>2011-04-11</created><authors><author><keyname>Dall'Asta</keyname><forenames>Luca</forenames></author><author><keyname>Marsili</keyname><forenames>Matteo</forenames></author><author><keyname>Pin</keyname><forenames>Paolo</forenames></author></authors><title>Collaboration in Social Networks</title><categories>physics.soc-ph cs.GT cs.SI</categories><doi>10.1073/pnas.1105757109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The very notion of social network implies that linked individuals interact
repeatedly with each other. This allows them not only to learn successful
strategies and adapt to them, but also to condition their own behavior on the
behavior of others, in a strategic forward looking manner. Game theory of
repeated games shows that these circumstances are conducive to the emergence of
collaboration in simple games of two players. We investigate the extension of
this concept to the case where players are engaged in a local contribution game
and show that rationality and credibility of threats identify a class of Nash
equilibria -- that we call &quot;collaborative equilibria&quot; -- that have a precise
interpretation in terms of sub-graphs of the social network. For large network
games, the number of such equilibria is exponentially large in the number of
players. When incentives to defect are small, equilibria are supported by local
structures whereas when incentives exceed a threshold they acquire a non-local
nature, which requires a &quot;critical mass&quot; of more than a given fraction of the
players to collaborate. Therefore, when incentives are high, an individual
deviation typically causes the collapse of collaboration across the whole
system. At the same time, higher incentives to defect typically support
equilibria with a higher density of collaborators. The resulting picture
conforms with several results in sociology and in the experimental literature
on game theory, such as the prevalence of collaboration in denser groups and in
the structural hubs of sparse networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2033</identifier>
 <datestamp>2011-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2033</id><created>2011-04-11</created><updated>2011-06-07</updated><authors><author><keyname>Saucan</keyname><forenames>Emil</forenames></author></authors><title>On the properties of the combinatorial Ricci flow for surfaces</title><categories>math.DG cs.CG</categories><comments>22 pages</comments><msc-class>Primary: 53C44, 52C26, 68U05, Secondary: 65D18, 51K10, 57R40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the properties of the combinatorial Ricci flow for surfaces,
both forward and backward -- existence, uniqueness and singularities formation.
We show that the positive results that exist for the smooth Ricci flow also
hold for the combinatorial one and that, moreover, the same results hold for a
more general, metric notion of curvature. Furthermore, using the metric
curvature approach, we show the existence of the Ricci flow for polyhedral
manifolds of piecewise constant curvature. We also study the problem of the
realizability of the said flow in $\mathbb{R}^3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2034</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2034</id><created>2011-04-11</created><authors><author><keyname>Parvanov</keyname><forenames>Yavor Angelov</forenames></author></authors><title>Materials to the Russian-Bulgarian Comparative Dictionary &quot;EAD&quot;</title><categories>cs.CL</categories><comments>Bulgarian Rusistics; Vol. 1 (2010)</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This article presents a fragment of a new comparative dictionary &quot;A
comparative dictionary of names of expansive action in Russian and Bulgarian
languages&quot;. Main features of the new web-based comparative dictionary are
placed, the principles of its formation are shown, primary links between the
word-matches are classified. The principal difference between translation
dictionaries and the model of double comparison is also shown. The
classification scheme of the pages is proposed. New concepts and keywords have
been introduced. The real prototype of the dictionary with a few key pages is
published. The broad debate about the possibility of this prototype to become a
version of Russian-Bulgarian comparative dictionary of a new generation is
available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2049</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2049</id><created>2011-04-11</created><authors><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Optimal Channel Training in Uplink Network MIMO Systems</title><categories>cs.IT math.IT</categories><comments>15 pages, 7 figures. To appear in the IEEE Transactions on Signal
  Processing</comments><doi>10.1109/TSP.2011.2129513</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-cell frequency-selective fading uplink channel (network
MIMO) from K single-antenna user terminals (UTs) to B cooperative base stations
(BSs) with M antennas each. The BSs, assumed to be oblivious of the applied
codebooks, forward compressed versions of their observations to a central
station (CS) via capacity limited backhaul links. The CS jointly decodes the
messages from all UTs. Since the BSs and the CS are assumed to have no prior
channel state information (CSI), the channel needs to be estimated during its
coherence time. Based on a lower bound of the ergodic mutual information, we
determine the optimal fraction of the coherence time used for channel training,
taking different path losses between the UTs and the BSs into account. We then
study how the optimal training length is impacted by the backhaul capacity.
Although our analytical results are based on a large system limit, we show by
simulations that they provide very accurate approximations for even small
system dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2059</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2059</id><created>2011-04-11</created><authors><author><keyname>Wong</keyname><forenames>Kwie Min</forenames></author></authors><title>Template-based matching using weight maps</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Template matching is one of the most prevalent pattern recognition methods
worldwide. It has found uses in most visual concept detection fields. In this
work, we investigate methods for improving template matching by adjusting the
weights of different regions of the template. We compare several weight maps
and test the methods using the FERET face test set in the context of human eye
detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2069</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2069</id><created>2011-04-11</created><authors><author><keyname>de Rooij</keyname><forenames>Alwin</forenames></author></authors><title>GEOMIR2K9 - A Similar Scene Finder</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main goal of the GEOMIR2K9 project is to create a software program that
is able to find similar scenic images clustered by geographical location and
sorted by similarity based only on their visual content. The user should be
able to input a query image, based on this given query image the program should
find relevant visual content and present this to the user in a meaningful way.
Technically the goal for the GEOMIR2K9 project is twofold. The first of these
two goals is to create a basic low level visual information retrieval system.
This includes feature extraction, post processing of the feature data and
classification/ clustering based on similarity with a strong focus on scenic
images. The second goal of this project is to provide the user with a novel and
suitable interface and visualization method so that the user may interact with
the retrieved images in a natural and meaningful way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2074</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2074</id><created>2011-04-11</created><authors><author><keyname>Ananth</keyname><forenames>Prabhanjan</forenames></author><author><keyname>Nasre</keyname><forenames>Meghana</forenames></author></authors><title>New Hardness Results in Rainbow Connectivity</title><categories>cs.CC cs.DM math.CO</categories><comments>15 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A path in an edge colored graph is said to be a rainbow path if no two edges
on the path have the same color. An edge colored graph is (strongly) rainbow
connected if there exists a (geodesic) rainbow path between every pair of
vertices. The (strong) rainbow connectivity of a graph $G$, denoted by
($src(G)$, respectively) $rc(G)$ is the smallest number of colors required to
edge color the graph such that the graph is (strong) rainbow connected. It is
known that for \emph{even} $k$ to decide whether the rainbow connectivity of a
graph is at most $k$ or not is NP-hard. It was conjectured that for all $k$, to
decide whether $rc(G) \leq k$ is NP-hard. In this paper we prove this
conjecture. We also show that it is NP-hard to decide whether $src(G) \leq k$
or not even when $G$ is a bipartite graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2076</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2076</id><created>2011-04-11</created><authors><author><keyname>Magdon-Ismail</keyname><forenames>Malik</forenames></author></authors><title>A Note On Estimating the Spectral Norm of A Matrix Efficiently</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an efficient algorithm which can obtain a relative error
approximation to the spectral norm of a matrix, combining the power iteration
method with some techniques from matrix reconstruction which use random
sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2079</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2079</id><created>2011-04-11</created><authors><author><keyname>Benzaken</keyname><forenames>V&#xe9;ronique</forenames></author><author><keyname>Castagna</keyname><forenames>Giuseppe</forenames></author><author><keyname>Colazzo</keyname><forenames>Dario</forenames></author><author><keyname>Nguyen</keyname><forenames>Kim</forenames></author></authors><title>Optimizing XML querying using type-based document projection</title><categories>cs.DB</categories><comments>65 pages A4 format</comments><acm-class>H.2.5; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  XML data projection (or pruning) is a natural optimization for main memory
query engines: given a query Q over a document D, the subtrees of D that are
not necessary to evaluate Q are pruned, thus producing a smaller document D';
the query Q is then executed on D', hence avoiding to allocate and process
nodes that will never be reached by Q. In this article, we propose a new
approach, based on types, that greatly improves current solutions. Besides
providing comparable or greater precision and far lesser pruning overhead, our
solution ---unlike current approaches--- takes into account backward axes,
predicates, and can be applied to multiple queries rather than just to single
ones. A side contribution is a new type system for XPath able to handle
backward axes. The soundness of our approach is formally proved. Furthermore,
we prove that the approach is also complete (i.e., yields the best possible
type-driven pruning) for a relevant class of queries and Schemas. We further
validate our approach using the XMark and XPathMark benchmarks and show that
pruning not only improves the main memory query engine's performances (as
expected) but also those of state of the art native XML databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2084</identifier>
 <datestamp>2012-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2084</id><created>2011-04-11</created><updated>2011-09-02</updated><authors><author><keyname>Dedieu</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Malajovich</keyname><forenames>Gregorio</forenames></author><author><keyname>Shub</keyname><forenames>Michael</forenames></author></authors><title>Adaptative Step Size Selection for Homotopy Methods to Solve Polynomial
  Equations</title><categories>math.NA cs.NA</categories><msc-class>Primary 65H10, 65H20. Secondary 58C35</msc-class><journal-ref>IMA Journal of Numerical Analysis 2012</journal-ref><doi>10.1093/imanum/drs007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a C^1 path of systems of homogeneous polynomial equations f_t, t in
[a,b] and an approximation x_a to a zero zeta_a of the initial system f_a, we
show how to adaptively choose the step size for a Newton based homotopy method
so that we approximate the lifted path (f_t,zeta_t) in the space of (problems,
solutions) pairs.
  The total number of Newton iterations is bounded in terms of the length of
the lifted path in the condition metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2086</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2086</id><created>2011-04-11</created><authors><author><keyname>Petrov</keyname><forenames>Slav</forenames></author><author><keyname>Das</keyname><forenames>Dipanjan</forenames></author><author><keyname>McDonald</keyname><forenames>Ryan</forenames></author></authors><title>A Universal Part-of-Speech Tagset</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To facilitate future research in unsupervised induction of syntactic
structure and to standardize best-practices, we propose a tagset that consists
of twelve universal part-of-speech categories. In addition to the tagset, we
develop a mapping from 25 different treebank tagsets to this universal set. As
a result, when combined with the original treebank data, this universal tagset
and mapping produce a dataset consisting of common parts-of-speech for 22
different languages. We highlight the use of this resource via two experiments,
including one that reports competitive accuracies for unsupervised grammar
induction without gold standard part-of-speech tags.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2097</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2097</id><created>2011-04-11</created><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>PAC learnability versus VC dimension: a footnote to a basic result of
  statistical learning</title><categories>cs.LG</categories><comments>Revised submission to IJCNN'2011</comments><msc-class>68T05</msc-class><acm-class>I.2.6</acm-class><journal-ref>Proc. 2011 International Joint Confernce on Neural Networks
  (IJCNN'2011), San Jose, CA (July 30 - Aug. 5, 2011), pp. 1141 - 1145</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental result of statistical learnig theory states that a concept
class is PAC learnable if and only if it is a uniform Glivenko-Cantelli class
if and only if the VC dimension of the class is finite. However, the theorem is
only valid under special assumptions of measurability of the class, in which
case the PAC learnability even becomes consistent. Otherwise, there is a
classical example, constructed under the Continuum Hypothesis by Dudley and
Durst and further adapted by Blumer, Ehrenfeucht, Haussler, and Warmuth, of a
concept class of VC dimension one which is neither uniform Glivenko-Cantelli
nor consistently PAC learnable. We show that, rather surprisingly, under an
additional set-theoretic hypothesis which is much milder than the Continuum
Hypothesis (Martin's Axiom), PAC learnability is equivalent to finite VC
dimension for every concept class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2108</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2108</id><created>2011-04-11</created><authors><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Stability of Modified-CS and LS-CS for Recursive Reconstruction of
  Sparse Signal Sequences</title><categories>cs.IT math.IT</categories><comments>16 pages, 3 figures. Submitted to IEEE Trans. Information Theory.
  Shorter version in Allerton 2010 (Stability (over time) of Modified-CS for
  Recursive Causal Sparse Reconstruction)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we obtain sufficient conditions for the &quot;stability&quot; of our
recently proposed algorithms, Least Squares Compressive Sensing residual
(LS-CS) and modified-CS, for recursively reconstructing sparse signal sequences
from noisy measurements. By &quot;stability&quot; we mean that the number of misses from
the current support estimate and the number of extras in it remain bounded by a
time-invariant value at all times. We show that, for a signal model with fixed
signal power and support set size; support set changes allowed at every time;
and gradual coefficient magnitude increase/decrease, &quot;stability&quot; holds under
mild assumptions -- bounded noise, high enough minimum nonzero coefficient
magnitude increase rate, and large enough number of measurements at every time.
A direct corollary is that the reconstruction error is also bounded by a
time-invariant value at all times. If the support set of the sparse signal
sequence changes slowly over time, our results hold under weaker assumptions
than what simple compressive sensing (CS) needs for the same error bound. Also,
our support error bounds are small compared to the support size. Our discussion
is backed up by Monte Carlo simulation based comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2110</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2110</id><created>2011-04-12</created><authors><author><keyname>Yun</keyname><forenames>Heechul</forenames></author><author><keyname>Kim</keyname><forenames>Cheolgi</forenames></author><author><keyname>Sha</keyname><forenames>Lui</forenames></author></authors><title>Deterministic Real-time Thread Scheduling</title><categories>cs.OS cs.SY</categories><comments>RTAS11 Work-In-Progress</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Race condition is a timing sensitive problem. A significant source of timing
variation comes from nondeterministic hardware interactions such as cache
misses. While data race detectors and model checkers can check races, the
enormous state space of complex software makes it difficult to identify all of
the races and those residual implementation errors still remain a big
challenge. In this paper, we propose deterministic real-time scheduling methods
to address scheduling nondeterminism in uniprocessor systems. The main idea is
to use timing insensitive deterministic events, e.g, an instruction counter, in
conjunction with a real-time clock to schedule threads. By introducing the
concept of Worst Case Executable Instructions (WCEI), we guarantee both
determinism and real-time performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2112</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2112</id><created>2011-04-12</created><updated>2011-09-25</updated><authors><author><keyname>Zlotnik</keyname><forenames>Anatoly</forenames></author><author><keyname>Li</keyname><forenames>Jr-Shin</forenames></author></authors><title>Optimal Asymptotic Entrainment of Phase-Reduced Oscillators</title><categories>nlin.CD cs.SY math.DS math.OC</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive optimal periodic controls for entrainment of a self-driven
oscillator to a desired frequency. The alternative objectives of minimizing
power and maximizing frequency range of entrainment are considered. A state
space representation of the oscillator is reduced to a linearized phase model,
and the optimal periodic control is computed from the phase response curve
using formal averaging and the calculus of variations. Computational methods
are used to calculate the periodic orbit and the phase response curve, and a
numerical method for approximating the optimal controls is introduced. Our
method is applied to asymptotically control the period of spiking neural
oscillators modeled using the Hodgkin-Huxley equations. This example
illustrates the optimality of entrainment controls derived using phase models
when applied to the original state space system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2116</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2116</id><created>2011-04-12</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Hanly</keyname><forenames>Stephen</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal</forenames></author></authors><title>Statistical Beamforming on the Grassmann Manifold for the Two-User
  Broadcast Channel</title><categories>cs.IT math.IT math.OC</categories><comments>44 pages, submitted to IEEE Trans. IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Rayleigh fading spatially correlated broadcast setting with M = 2 antennas
at the transmitter and two-users (each with a single antenna) is considered. It
is assumed that the users have perfect channel information about their links
whereas the transmitter has only statistical information of each user's link
(covariance matrix of the vector channel). A low-complexity linear beamforming
strategy that allocates equal power and one spatial eigen-mode to each user is
employed at the transmitter. Beamforming vectors on the Grassmann manifold that
depend only on statistical information are to be designed at the transmitter to
maximize the ergodic sum-rate delivered to the two users. Towards this goal,
the beamforming vectors are first fixed and a closed-form expression is
obtained for the ergodic sum-rate in terms of the covariance matrices of the
links. This expression is non-convex in the beamforming vectors ensuring that
the classical Lagrange multiplier technique is not applicable. Despite this
difficulty, the optimal solution to this problem is shown to be the solution to
the maximization of an appropriately-defined average signal-to-interference and
noise ratio (SINR) metric for each user. This solution is the dominant
generalized eigenvector of a pair of positive-definite matrices where the first
matrix is the covariance matrix of the forward link and the second is an
appropriately-designed &quot;effective&quot; interference covariance matrix. In this
sense, our work is a generalization of optimal signalling along the dominant
eigen-mode of the transmit covariance matrix in the single-user case. Finally,
the ergodic sum-rate for the general broadcast setting with M antennas at the
transmitter and M-users (each with a single antenna) is obtained in terms of
the covariance matrices of the links and the beamforming vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2124</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2124</id><created>2011-04-12</created><updated>2011-05-09</updated><authors><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX</affiliation></author><author><keyname>Join</keyname><forenames>C&#xe9;dric</forenames><affiliation>CRAN, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Hatt</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author></authors><title>Is a probabilistic modeling really useful in financial engineering? -
  A-t-on vraiment besoin d'un mod\`ele probabiliste en ing\'enierie
  financi\`ere ?</title><categories>q-fin.CP cs.CE q-fin.PM q-fin.RM</categories><comments>Conf\'erence M\'editerran\'eenne sur l'Ing\'enierie S\^ure des
  Syst\`emes Complexes, MISC 2011, Agadir : Maroc (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new standpoint on financial time series, without the use of any
mathematical model and of probabilistic tools, yields not only a rigorous
approach of trends and volatility, but also efficient calculations which were
already successfully applied in automatic control and in signal processing. It
is based on a theorem due to P. Cartier and Y. Perrin, which was published in
1995. The above results are employed for sketching a dynamical portfolio and
strategy management, without any global optimization technique. Numerous
computer simulations are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2132</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2132</id><created>2011-04-12</created><updated>2012-02-15</updated><authors><author><keyname>Perarnau</keyname><forenames>Guillem</forenames></author><author><keyname>Serra</keyname><forenames>Oriol</forenames></author></authors><title>On the tree-depth of Random Graphs</title><categories>math.CO cs.DM</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tree-depth is a parameter introduced under several names as a measure of
sparsity of a graph. We compute asymptotic values of the tree-depth of random
graphs. For dense graphs, p&gt;&gt; 1/n, the tree-depth of a random graph G is a.a.s.
td(G)=n-O(sqrt(n/p)). Random graphs with p=c/n, have a.a.s. linear tree-depth
when c&gt;1, the tree-depth is Theta (log n) when c=1 and Theta (loglog n) for
c&lt;1. The result for c&gt;1 is derived from the computation of tree-width and
provides a more direct proof of a conjecture by Gao on the linearity of
tree-width recently proved by Lee, Lee and Oum. We also show that, for c=1,
every width parameter is a.a.s. constant, and that random regular graphs have
linear tree-depth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2134</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2134</id><created>2011-04-12</created><authors><author><keyname>Ott</keyname><forenames>Maximilian</forenames></author><author><keyname>Shvartzshnaider</keyname><forenames>Yan</forenames></author></authors><title>A Case for a Global Information Network</title><categories>cs.NI</categories><report-no>TR-4783</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper argues for the adoption of a information centric system model
instead of the current service-oriented one. We present an architecture for a
global information storage and dissemination network which provides for
efficient interaction and coordination among autonomous actors through a shared
information space. We believe that the resulting, loosely coupled systems,
while probabilistic in nature, will lead to robust outcomes at large scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2156</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2156</id><created>2011-04-12</created><updated>2012-03-06</updated><authors><author><keyname>Wang</keyname><forenames>Zhe</forenames></author><author><keyname>Hu</keyname><forenames>Kai</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Yin</keyname><forenames>Baolin</forenames></author><author><keyname>Dong</keyname><forenames>Xiaowen</forenames></author></authors><title>Structural Analysis of Network Traffic Matrix via Relaxed Principal
  Component Pursuit</title><categories>cs.NI cs.IT cs.PF math.IT</categories><comments>Accepted to Elsevier Computer Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The network traffic matrix is widely used in network operation and
management. It is therefore of crucial importance to analyze the components and
the structure of the network traffic matrix, for which several mathematical
approaches such as Principal Component Analysis (PCA) were proposed. In this
paper, we first argue that PCA performs poorly for analyzing traffic matrix
that is polluted by large volume anomalies, and then propose a new
decomposition model for the network traffic matrix. According to this model, we
carry out the structural analysis by decomposing the network traffic matrix
into three sub-matrices, namely, the deterministic traffic, the anomaly traffic
and the noise traffic matrix, which is similar to the Robust Principal
Component Analysis (RPCA) problem previously studied in [13]. Based on the
Relaxed Principal Component Pursuit (Relaxed PCP) method and the Accelerated
Proximal Gradient (APG) algorithm, we present an iterative approach for
decomposing a traffic matrix, and demonstrate its efficiency and flexibility by
experimental results. Finally, we further discuss several features of the
deterministic and noise traffic. Our study develops a novel method for the
problem of structural analysis of the traffic matrix, which is robust against
pollution of large volume anomalies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2171</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2171</id><created>2011-04-12</created><authors><author><keyname>Tari</keyname><forenames>Sibel</forenames></author><author><keyname>Genctav</keyname><forenames>Murat</forenames></author></authors><title>From a Modified Ambrosio-Tortorelli to a Randomized Part Hierarchy Tree</title><categories>cs.CV</categories><comments>Scale Space and Variational Methods 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate the possibility of coding parts, features that are higher
level than boundaries, using a modified AT field after augmenting the
interaction term of the AT energy with a non-local term and weakening the
separation into boundary/not-boundary phases. The iteratively extracted parts
using the level curves with double point singularities are organized as a
proper binary tree. Inconsistencies due to non-generic configurations for level
curves as well as due to visual changes such as occlusion are successfully
handled once the tree is endowed with a probabilistic structure. The work is a
step in establishing the AT function as a bridge between low and high level
visual processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2175</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2175</id><created>2011-04-12</created><authors><author><keyname>Tari</keyname><forenames>Sibel</forenames></author></authors><title>Extracting Parts of 2D Shapes Using Local and Global Interactions
  Simultaneously</title><categories>cs.CV</categories><comments>invited book chapter, Handbook of Pattern Recognition and Computer
  Vision, 4th edition, C. Chen (ed) The presented surface is also related to
  Ambrosio-Tortorelli phase field</comments><journal-ref>Handbook of Pattern Recognition and Computer Vision, 4th edition,
  C. Chen (ed), Dec 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perception research provides strong evidence in favor of part based
representation of shapes in human visual system. Despite considerable
differences among different theories in terms of how part boundaries are found,
there is substantial agreement on that the process depends on many local and
global geometric factors. This poses an important challenge from the
computational point of view. In the first part of the chapter, I present a
novel decomposition method by taking both local and global interactions within
the shape domain into account. At the top of the partitioning hierarchy, the
shape gets split into two parts capturing, respectively, the gross structure
and the peripheral structure. The gross structure may be conceived as the least
deformable part of the shape which remains stable under visual transformations.
The peripheral structure includes limbs, protrusions, and boundary texture.
Such a separation is in accord with the behavior of the artists who start with
a gross shape and enrich it with details. The method is particularly
interesting from the computational point of view as it does not resort to any
geometric notions (e.g. curvature, convexity) explicitly. In the second part of
the chapter, I relate the new method to PDE based shape representation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2187</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2187</id><created>2011-04-12</created><updated>2011-05-10</updated><authors><author><keyname>Lopez-Ruiz</keyname><forenames>R.</forenames></author><author><keyname>Shivanian</keyname><forenames>E.</forenames></author><author><keyname>Abbasbandy</keyname><forenames>S.</forenames></author><author><keyname>Lopez</keyname><forenames>J. L.</forenames></author></authors><title>A Generalized Continuous Model for Random Markets</title><categories>q-fin.GN cs.MA nlin.AO</categories><comments>11 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalized continuous economic model is proposed for random markets. In
this model, agents interact by pairs and exchange their money in a random way.
A parameter controls the effectiveness of the transactions between the agents.
We show in a rigorous way that this type of markets reach their asymptotic
equilibrium on the exponential wealth distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2196</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2196</id><created>2011-04-12</created><authors><author><keyname>Groh</keyname><forenames>Georg</forenames></author><author><keyname>Straub</keyname><forenames>Florian</forenames></author><author><keyname>Donaubauer</keyname><forenames>Andreas</forenames></author><author><keyname>Koster</keyname><forenames>Benjamin</forenames></author></authors><title>Space and Time as a Primary Classification Criterion for Information
  Retrieval in Distributed Social Networking</title><categories>cs.IR cs.SI physics.soc-ph</categories><comments>Short Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss in a compact way how the implicit relations between spatiotemporal
relatedness of information items, spatiotemporal relatedness of users, social
relatedness of users and semantic relatedness of information items may be
exploited for an information retrieval architecture that operates along the
lines of human ways of searching. The decentralized and agent oriented
architecture mirrors emerging trends such as upcoming mobile and decentralized
social networking as a new paradigm in social computing and is targetted to
satisfy broader and more subtly interlinked information demands beyond
immediate information needs which can be readily satisfied with current IR
services. We briefly discuss why using spatio-temporal references as primary
information criterion implicitly conserves other relations and is thus suitable
for such an architecture. We finally shortly point to results from a large
evaluation study using Wikipedia articles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2215</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2215</id><created>2011-04-12</created><updated>2011-12-20</updated><authors><author><keyname>Shental</keyname><forenames>Ori</forenames></author></authors><title>Sparse Representation of White Gaussian Noise with Application to
  L0-Norm Decoding in Noisy Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>VER1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The achievable and converse regions for sparse representation of white
Gaussian noise based on an overcomplete dictionary are derived in the limit of
large systems. Furthermore, the marginal distribution of such sparse
representations is also inferred. The results are obtained via the Replica
method which stems from statistical mechanics. A direct outcome of these
results is the introduction of sharp threshold for $\ell_{0}$-norm decoding in
noisy compressed sensing, and its mean-square error for underdetermined
Gaussian vector channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2217</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2217</id><created>2011-04-12</created><updated>2011-12-19</updated><authors><author><keyname>Gonczarowski</keyname><forenames>Yannai A.</forenames></author><author><keyname>Friedgut</keyname><forenames>Ehud</forenames></author></authors><title>On Sisterhood in the Gale-Shapley Matching Algorithm</title><categories>cs.GT math.CO</categories><comments>Based upon an undergraduate thesis written in Hebrew in 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lying in order to manipulate the Gale-Shapley matching algorithm has been
studied by Dubins and Friedman and by Gale and Sotomayor and was shown to be
generally more appealing to the proposed-to side (denoted as the women in Gale
and Shapley's original paper) than to the proposing side (denoted as men
there). It can also be shown that in the case of lying women, for every woman
who is better-off due to lying, there exists a man who is worse-off.
  In this paper, we show that an even stronger dichotomy between the goals of
the sexes holds, namely, if no woman is worse-off then no man is better-off,
while a form of sisterhood between the lying and the &quot;innocent&quot; women also
holds, namely, if none of the former are worse-off, then neither is any of the
latter.
  This paper is based upon an undergraduate (&quot;Amirim&quot;) thesis of the first
author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2230</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2230</id><created>2011-04-12</created><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Villanger</keyname><forenames>Yngve</forenames></author></authors><title>Subexponential Parameterized Algorithm for Minimum Fill-in</title><categories>cs.DS</categories><comments>23 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Minimum Fill-in problem is to decide if a graph can be triangulated by
adding at most k edges. Kaplan, Shamir, and Tarjan [FOCS 1994] have shown that
the problem is solvable in time O(2^(O(k)) + k2 * nm) on graphs with n vertices
and m edges and thus is fixed parameter tractable. Here, we give the first
subexponential parameterized algorithm solving Minimum Fill-in in time
O(2^(O(\sqrt{k} log k)) + k2 * nm). This substantially lower the complexity of
the problem. Techniques developed for Minimum Fill-in can be used to obtain
subexponential parameterized algorithms for several related problems including
Minimum Chain Completion, Chordal Graph Sandwich, and Triangulating Colored
Graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2239</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2239</id><created>2011-04-12</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Pristavka</keyname><forenames>Pavel</forenames></author></authors><title>Experimental Investigation of Forecasting Methods Based on Universal
  Measures</title><categories>cs.IT math.IT physics.data-an</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe and experimentally investigate a method to construct forecasting
algorithms for stationary and ergodic processes based on universal measures (or
so-called universal data compressors). Using some geophysical and economical
time series as examples, we show that the precision of thus obtained
predictions is higher than that of known methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2251</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2251</id><created>2011-04-12</created><authors><author><keyname>Oriolo</keyname><forenames>Gianpaolo</forenames></author><author><keyname>Pietropaoli</keyname><forenames>Ugo</forenames></author><author><keyname>Stauffer</keyname><forenames>Gautier</forenames></author></authors><title>On the Recognition of Fuzzy Circular Interval Graphs</title><categories>cs.DM</categories><comments>12 pages, 2 figures</comments><msc-class>68R10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy circular interval graphs are a generalization of proper circular arc
graphs and have been recently introduced by Chudnovsky and Seymour as a
fundamental subclass of claw-free graphs. In this paper, we provide a
polynomial-time algorithm for recognizing such graphs, and more importantly for
building a suitable representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2262</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2262</id><created>2011-04-12</created><updated>2012-02-09</updated><authors><author><keyname>B&#xe1;r&#xe1;ny</keyname><forenames>Vince</forenames></author><author><keyname>Boja&#x144;czyk</keyname><forenames>Miko&#x142;aj</forenames></author></authors><title>Finite Satisfiability for Guarded Fixpoint Logic</title><categories>cs.LO math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The finite satisfiability problem for guarded fixpoint logic is decidable and
complete for 2ExpTime (resp. ExpTime for formulas of bounded width).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2265</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2265</id><created>2011-04-12</created><authors><author><keyname>Greenwood</keyname><forenames>David</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author></authors><title>Responsibility Modeling for the Sociotechnical Risk Analysis of
  Coalitions of Systems</title><categories>cs.SE</categories><comments>Submitted for consideration for the IEEE SMC2011 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Society is challenging systems engineers by demanding ever more complex and
integrated systems. With the rise of cloud computing and systems-of-systems
(including cyber-physical systems) we are entering an era where mission
critical services and applications will be dependent upon
'coalitions-of-systems'. Coalitions-of-systems (CoS) are a class of system
similar to systems-of-systems but they differ in that they interact to further
overlapping self-interests rather than an overarching mission. Assessing the
sociotechnical risks associated with CoS is an open research question of
societal importance as existing risk analysis techniques typically focus on the
technical aspects of systems and ignore risks associated with coalition
partners reneging on responsibilities or leaving the coalition. We demonstrate
that a responsibility modeling based risk analysis approach enables the
identification of sociotechnical risks associated with CoS. The approach
identifies hazards and associated risks that may arise when relying upon a
coalition of human/organizational/technical agents to provision a service or
application. Through a case study of a proposed cloud IT infrastructure
migration we show how the technique identifies vulnerabilities that may arise
because of human, organizational or technical agents failing to discharge
responsibilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2275</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2275</id><created>2011-04-12</created><updated>2015-11-15</updated><authors><author><keyname>Kammer</keyname><forenames>Frank</forenames></author><author><keyname>Tholey</keyname><forenames>Torsten</forenames></author></authors><title>Approximate Tree Decompositions of Planar Graphs in Linear Time</title><categories>cs.DS</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many algorithms have been developed for NP-hard problems on graphs with small
treewidth $k$. For example, all problems that are expressable in linear
extended monadic second order can be solved in linear time on graphs of bounded
treewidth. It turns out that the bottleneck of many algorithms for NP-hard
problems is the computation of a tree decomposition of width $O(k)$. In
particular, by the bidimensional theory, there are many linear extended monadic
second order problems that can be solved on $n$-vertex planar graphs with
treewidth $k$ in a time linear in $n$ and subexponential in $k$ if a tree
decomposition of width $O(k)$ can be found in such a time.
  We present the first algorithm that, on $n$-vertex planar graphs with
treewidth $k$, finds a tree decomposition of width $O(k)$ in such a time. In
more detail, our algorithm has a running time of $O(n k^2 \log k)$. We show the
result as a special case of a result on so-called weighted treewidth of
weighted graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2284</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2284</id><created>2011-04-12</created><authors><author><keyname>Ramya</keyname><forenames>C.</forenames></author><author><keyname>Shreedhara</keyname><forenames>K S</forenames></author><author><keyname>Kavitha</keyname><forenames>G</forenames></author></authors><title>Preprocessing: A Prerequisite for Discovering Patterns in WUM Process</title><categories>cs.DB</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web log data is usually diverse and voluminous. This data must be assembled
into a consistent, integrated and comprehensive view, in order to be used for
pattern discovery. Without properly cleaning, transforming and structuring the
data prior to the analysis, one cannot expect to find meaningful patterns. As
in most data mining applications, data preprocessing involves removing and
filtering redundant and irrelevant data, removing noise, transforming and
resolving any inconsistencies. In this paper, a complete preprocessing
methodology having merging, data cleaning, user/session identification and data
formatting and summarization activities to improve the quality of data by
reducing the quantity of data has been proposed. To validate the efficiency of
the proposed preprocessing methodology, several experiments are conducted and
the results show that the proposed methodology reduces the size of Web access
log files down to 73-82% of the initial size and offers richer logs that are
structured for further stages of Web Usage Mining (WUM). So preprocessing of
raw data in this WUM process is the central theme of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2285</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2285</id><created>2011-04-12</created><updated>2011-08-11</updated><authors><author><keyname>Das</keyname><forenames>Abhishek</forenames></author><author><keyname>Kar</keyname><forenames>Avijit</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Debasis</forenames></author></authors><title>Elimination of Specular reflection and Identification of ROI: The First
  Step in Automated Detection of Cervical Cancer using Digital Colposcopy</title><categories>cs.CV physics.med-ph</categories><comments>IEEE Imaging Systems and Techniques, 2011, Print ISBN:
  978-1-61284-894-5, pages 237 - 241</comments><journal-ref>http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5962218, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cervical Cancer is one of the most common forms of cancer in women worldwide.
Most cases of cervical cancer can be prevented through screening programs aimed
at detecting precancerous lesions. During Digital Colposcopy, Specular
Reflections (SR) appear as bright spots heavily saturated with white light.
These occur due to the presence of moisture on the uneven cervix surface, which
act like mirrors reflecting light from the illumination source. Apart from
camouflaging the actual features, the SR also affects subsequent segmentation
routines and hence must be removed. Our novel technique eliminates the SR and
makes the colposcopic images (cervigram) ready for segmentation algorithms. The
cervix region occupies about half of the cervigram image. Other parts of the
image contain irrelevant information, such as equipment, frames, text and
non-cervix tissues. This irrelevant information can confuse automatic
identification of the tissues within the cervix. The first step is, therefore,
focusing on the cervical borders, so that we have a geometric boundary on the
relevant image area. We have proposed a type of modified kmeans clustering
algorithm to evaluate the region of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2293</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2293</id><created>2011-04-12</created><authors><author><keyname>Demetrescu</keyname><forenames>Camil</forenames></author><author><keyname>Finocchi</keyname><forenames>Irene</forenames></author><author><keyname>Ribichini</keyname><forenames>Andrea</forenames></author></authors><title>Reactive Imperative Programming with Dataflow Constraints</title><categories>cs.PL</categories><msc-class>68N15</msc-class><acm-class>D.3.2; D.3.3; F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dataflow languages provide natural support for specifying constraints between
objects in dynamic applications, where programs need to react efficiently to
changes of their environment. Researchers have long investigated how to take
advantage of dataflow constraints by embedding them into procedural languages.
Previous mixed imperative/dataflow systems, however, require syntactic
extensions or libraries of ad hoc data types for binding the imperative program
to the dataflow solver. In this paper we propose a novel approach that smoothly
combines the two paradigms without placing undue burden on the programmer. In
our framework, programmers can define ordinary commands of the host imperative
language that enforce constraints between objects stored in &quot;reactive&quot; memory
locations. Reactive objects can be of any legal type in the host language,
including primitive data types, pointers, arrays, and structures. Constraints
are automatically re-executed every time their input memory locations change,
letting a program behave like a spreadsheet where the values of some variables
depend upon the values of other variables. The constraint solving mechanism is
handled transparently by altering the semantics of elementary operations of the
host language for reading and modifying objects. We provide a formal semantics
and describe a concrete embodiment of our technique into C/C++, showing how to
implement it efficiently in conventional platforms using off-the-shelf
compilers. We discuss relevant applications to reactive scenarios, including
incremental computation, observer design pattern, and data structure repair.
The performance of our implementation is compared to ad hoc problem-specific
change propagation algorithms and to language-centric approaches such as
self-adjusting computation and subject/observer communication mechanisms,
showing that the proposed approach is efficient in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2301</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2301</id><created>2011-04-12</created><authors><author><keyname>McCammond</keyname><forenames>Jon</forenames></author><author><keyname>Rhodes</keyname><forenames>John</forenames></author><author><keyname>Steinberg</keyname><forenames>Benjamin</forenames></author></authors><title>Geometric Semigroup Theory</title><categories>math.GR cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Geometric semigroup theory is the systematic investigation of
finitely-generated semigroups using the topology and geometry of their
associated automata. In this article we show how a number of easily-defined
expansions on finite semigroups and automata lead to simplifications of the
graphs on which the corresponding finite semigroups act. We show in particular
that every finite semigroup can be finitely expanded so that the expansion acts
on a labeled directed graph which resembles the right Cayley graph of a free
Burnside semigroup in many respects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2303</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2303</id><created>2011-04-12</created><updated>2011-12-12</updated><authors><author><keyname>Schaeffer</keyname><forenames>Luke</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>The Critical Exponent is Computable for Automatic Sequences</title><categories>cs.FL cs.DM math.NT</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 231-239</journal-ref><doi>10.4204/EPTCS.63.29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The critical exponent of an infinite word is defined to be the supremum of
the exponent of each of its factors. For k-automatic sequences, we show that
this critical exponent is always either a rational number or infinite, and its
value is computable. Our results also apply to variants of the critical
exponent, such as the initial critical exponent of Berthe, Holton, and Zamboni
and the Diophantine exponent of Adamczewski and Bugeaud. Our work generalizes
or recovers previous results of Krieger and others, and is applicable to other
situations; e.g., the computation of the optimal recurrence constant for a
linearly recurrent k-automatic sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2312</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2312</id><created>2011-04-12</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Schnoor</keyname><forenames>Henning</forenames></author></authors><title>Minimization for Generalized Boolean Formulas</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimization problem for propositional formulas is an important
optimization problem in the second level of the polynomial hierarchy. In
general, the problem is Sigma-2-complete under Turing reductions, but
restricted versions are tractable. We study the complexity of minimization for
formulas in two established frameworks for restricted propositional logic: The
Post framework allowing arbitrarily nested formulas over a set of Boolean
connectors, and the constraint setting, allowing generalizations of CNF
formulas. In the Post case, we obtain a dichotomy result: Minimization is
solvable in polynomial time or coNP-hard. This result also applies to Boolean
circuits. For CNF formulas, we obtain new minimization algorithms for a large
class of formulas, and give strong evidence that we have covered all
polynomial-time cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2315</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2315</id><created>2011-04-12</created><updated>2011-12-13</updated><authors><author><keyname>Ahn</keyname><forenames>Kook Jin</forenames></author><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author></authors><title>Linear Programming in the Semi-streaming Model with Application to the
  Maximum Matching Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study linear programming based approaches to the maximum
matching problem in the semi-streaming model. The semi-streaming model has
gained attention as a model for processing massive graphs as the importance of
such graphs has increased. This is a model where edges are streamed-in in an
adversarial order and we are allowed a space proportional to the number of
vertices in a graph.
  In recent years, there has been several new results in this semi-streaming
model. However broad techniques such as linear programming have not been
adapted to this model. We present several techniques to adapt and optimize
linear programming based approaches in the semi-streaming model with an
application to the maximum matching problem. As a consequence, we improve
(almost) all previous results on this problem, and also prove new results on
interesting variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2355</identifier>
 <datestamp>2011-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2355</id><created>2011-04-12</created><updated>2011-10-31</updated><authors><author><keyname>Nevat</keyname><forenames>Ido</forenames></author><author><keyname>Peters</keyname><forenames>Gareth W.</forenames></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames></author><author><keyname>Collings</keyname><forenames>Iain</forenames></author></authors><title>Cooperative Spectrum Sensing for Amplify-and-Forward Cognitive Networks</title><categories>cs.IT math.IT</categories><comments>30 pages, 9 figures, submitted to Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a framework for spectrum sensing in cooperative
amplify-and-forward cognitive radio networks. We consider a stochastic model
where relays are assigned in cognitive radio networks to transmit the primary
user's signal to a cognitive Secondary Base Station (SBS). We develop the
Bayesian optimal decision rule under various scenarios of Channel State
Information (CSI) varying from perfect to imperfect CSI. In order to obtain the
optimal decision rule based on a Likelihood Ratio Test (LRT), the marginal
likelihood under each hypothesis relating to presence or absence of
transmission needs to be evaluated pointwise. However, in some cases the
evaluation of the LRT can not be performed analytically due to the
intractability of the multi-dimensional integrals involved. In other cases, the
distribution of the test statistic can not be obtained exactly. To circumvent
these difficulties we design two algorithms to approximate the marginal
likelihood, and obtain the decision rule. The first is based on Gaussian
Approximation where we quantify the accuracy of the approximation via a
multivariate version of the Berry-Esseen bound. The second algorithm is based
on Laplace approximation for the marginal likelihood, which results in a
non-convex optimisation problem which is solved efficiently via Bayesian
Expectation-Maximisation method. We also utilise a Laguerre series expansion to
approximate the distribution of the test statistic in cases where its
distribution can not be derived exactly. Performance is evaluated via analytic
bounds and compared to numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2364</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2364</id><created>2011-04-12</created><authors><author><keyname>Tanimoto</keyname><forenames>Shinji</forenames></author></authors><title>Epidemic spreading with immunization rate on complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the spread of diseases, computer viruses or information on
complex networks and also immunization strategies to prevent or control the
spread. When an entire population cannot be immunized and the effect of
immunization is not perfect, we need the targeted immunization with
immunization rate. Under such a circumstance we calculate epidemic thresholds
for the SIR and SIS epidemic models. It is shown that, in scale-free networks,
the targeted immunization is effective only if the immunization rate is equal
to one. We analyze here epidemic spreading on directed complex networks, but
similar results are also valid for undirected ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2368</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2368</id><created>2011-04-12</created><updated>2011-04-14</updated><authors><author><keyname>Aslam</keyname><forenames>Muhammad Zaheer</forenames><affiliation>ICIT Department, Gomal University, DIkhan Pakistan</affiliation></author><author><keyname>Rashid</keyname><forenames>Abdur</forenames><affiliation>ICIT Department, Gomal University, DIkhan Pakistan</affiliation></author></authors><title>Comparison of Random Waypoint &amp; Random Walk Mobility Model under DSR,
  AODV &amp; DSDV MANET Routing Protocols</title><categories>cs.NI</categories><comments>10 pages 14 figures</comments><acm-class>C.2.1</acm-class><journal-ref>International Journal of Advanced Research in Computer Science
  (IJARCS) Volume 2 Issue1 Jan-Feb 2011 Page 381-386</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Adhoc Network is a kind of wireless ad hoc network where nodes are
connected wirelessly and the network is self configuring. MANET may work in a
standalone manner or may be a part of another network. In this paper we have
compared Random Walk Mobility Model and Random Waypoint Mobility Model over two
reactive routing protocols Dynamic Source Routing (DSR) and Adhoc On-Demand
Distance Vector Routing (AODV) protocol and one Proactive routing protocol
Distance Sequenced Distance Vector Routing (DSDV) Our analysis showed that DSR,
AODV &amp; DSDV under Random Walk and Random Way Point Mobility models have similar
results for similar inputs however as the pause time increases so does the
difference in performance rises. They show that their motion, direction, angle
of direction, speed is same under both mobility models. We have made their
analysis on packet delivery ratio, throughput and routing overhead. We have
tested them with different criteria like different number of nodes, speed and
different maximum number of connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2373</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2373</id><created>2011-04-13</created><updated>2013-02-09</updated><authors><author><keyname>Friedlander</keyname><forenames>Michael P.</forenames></author><author><keyname>Schmidt</keyname><forenames>Mark</forenames></author></authors><title>Hybrid Deterministic-Stochastic Methods for Data Fitting</title><categories>cs.NA cs.SY math.OC stat.ML</categories><comments>26 pages. Revised proofs of Theorems 2.6 and 3.1, results unchanged</comments><doi>10.1137/110830629</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many structured data-fitting applications require the solution of an
optimization problem involving a sum over a potentially large number of
measurements. Incremental gradient algorithms offer inexpensive iterations by
sampling a subset of the terms in the sum. These methods can make great
progress initially, but often slow as they approach a solution. In contrast,
full-gradient methods achieve steady convergence at the expense of evaluating
the full objective and gradient on each iteration. We explore hybrid methods
that exhibit the benefits of both approaches. Rate-of-convergence analysis
shows that by controlling the sample size in an incremental gradient algorithm,
it is possible to maintain the steady convergence rates of full-gradient
methods. We detail a practical quasi-Newton implementation based on this
approach. Numerical experiments illustrate its potential benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2380</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2380</id><created>2011-04-13</created><authors><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Efficient Distributed Medium Access</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a wireless network of n nodes represented by a graph G=(V, E) where
an edge (i,j) models the fact that transmissions of i and j interfere with each
other, i.e. simultaneous transmissions of i and j become unsuccessful. Hence it
is required that at each time instance a set of non-interfering nodes
(corresponding to an independent set in G) access the wireless medium. To
utilize wireless resources efficiently, it is required to arbitrate the access
of medium among interfering nodes properly. Moreover, to be of practical use,
such a mechanism is required to be totally distributed as well as simple. As
the main result of this paper, we provide such a medium access algorithm. It is
randomized, totally distributed and simple: each node attempts to access medium
at each time with probability that is a function of its local information. We
establish efficiency of the algorithm by showing that the corresponding network
Markov chain is positive recurrent as long as the demand imposed on the network
can be supported by the wireless network (using any algorithm). In that sense,
the proposed algorithm is optimal in terms of utilizing wireless resources. The
algorithm is oblivious to the network graph structure, in contrast with the
so-called `polynomial back-off' algorithm by Hastad-Leighton-Rogoff (STOC '87,
SICOMP '96) that is established to be optimal for the complete graph and
bipartite graphs (by Goldberg-MacKenzie (SODA '96, JCSS '99)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2385</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2385</id><created>2011-04-13</created><authors><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Kopecki</keyname><forenames>Steffen</forenames></author><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames></author></authors><title>On the regularity of iterated hairpin completion of a single word</title><categories>cs.FL</categories><comments>17 pages, 1 figure, submitted to Fundamenta Informaticae</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hairpin completion is an abstract operation modeling a DNA bio-operation
which receives as input a DNA strand $w = x\alpha y \calpha$, and outputs $w' =
x \alpha y \bar{\alpha} \bar{x}$, where $\bar{x}$ denotes the Watson-Crick
complement of $x$. In this paper, we focus on the problem of finding conditions
under which the iterated hairpin completion of a given word is regular.
According to the numbers of words $\alpha$ and $\calpha$ that initiate hairpin
completion and how they are scattered, we classify the set of all words $w$.
For some basic classes of words $w$ containing small numbers of occurrences of
$\alpha$ and $\calpha$, we prove that the iterated hairpin completion of $w$ is
regular. For other classes with higher numbers of occurrences of $\alpha$ and
$\calpha$, we prove a necessary and sufficient condition for the iterated
hairpin completion of a word in these classes to be regular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2409</identifier>
 <datestamp>2014-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2409</id><created>2011-04-13</created><updated>2014-03-21</updated><authors><author><keyname>Trahtman</keyname><forenames>A. N.</forenames></author></authors><title>Modifying the upper bound on the length of minimal synchronizing word</title><categories>cs.DM</categories><comments>This paper has been withdrawn by the author. Key Lemma 3 is wrong,
  the statement of the paper was not proved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A word $w$ is called synchronizing (recurrent, reset, magic, directable) word
of deterministic finite automaton (DFA) if $w$ sends all states of the
automaton to a unique state. In 1964 Jan \v{C}erny found a sequence of n-state
complete DFA possessing a minimal synchronizing word of length $(n-1)^2$. He
conjectured that it is an upper bound on the length of such words for complete
DFA. Nevertheless, the best upper bound $(n^3-n)/6$ was found almost 30 years
ago. We reduce the upper bound on the length of the minimal synchronizing word
to $n(7n^2+6n-16)/48$. An implemented algorithm for finding synchronizing word
with restricted upper bound is described. The work presents the distribution of
all synchronizing automata of small size according to the length of an almost
minimal synchronizing word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2444</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2444</id><created>2011-04-13</created><updated>2015-06-19</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>A Simplified and Improved Free-Variable Framework for Hilbert's epsilon
  as an Operator of Indefinite Committed Choice</title><categories>cs.AI math.LO</categories><comments>ii + 82 pages</comments><report-no>SEKI Report SR-2011-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Free variables occur frequently in mathematics and computer science with ad
hoc and altering semantics. We present the most recent version of our
free-variable framework for two-valued logics with properly improved
functionality, but only two kinds of free variables left (instead of three):
implicitly universally and implicitly existentially quantified ones, now simply
called &quot;free atoms&quot; and &quot;free variables&quot;, respectively. The quantificational
expressiveness and the problem-solving facilities of our framework exceed
standard first-order and even higher-order modal logics, and directly support
Fermat's descente infinie. With the improved version of our framework, we can
now model also Henkin quantification, neither using quantifiers (binders) nor
raising (Skolemization). We propose a new semantics for Hilbert's epsilon as a
choice operator with the following features: We avoid overspecification (such
as right-uniqueness), but admit indefinite choice, committed choice, and
classical logics. Moreover, our semantics for the epsilon supports reductive
proof search optimally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2470</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2470</id><created>2011-04-13</created><authors><author><keyname>Schicho</keyname><forenames>Josef</forenames></author><author><keyname>Sevilla</keyname><forenames>David</forenames></author></authors><title>Effective radical parametrization of trigonal curves</title><categories>math.AG cs.SC</categories><comments>11 pages, a previous extended abstract is arXiv:1103.4689</comments><msc-class>14H51, 68W30 (Primary) 17B45 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $C$ be a non-hyperelliptic algebraic curve. It is known that its
canonical image is the intersection of the quadrics that contain it, except
when $C$ is trigonal (that is, it has a linear system of degree 3 and dimension
1) or isomorphic to a plane quintic (genus 6). In this context, we present a
method to decide whether a given algebraic curve is trigonal, and in the
affirmative case to compute a map from $C$ to the projective line whose fibers
cut out the linear system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2477</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2477</id><created>2011-04-13</created><updated>2011-04-14</updated><authors><author><keyname>Ru&#xe9;</keyname><forenames>Juanjo</forenames></author><author><keyname>Sau</keyname><forenames>Ignasi</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Asymptotic Enumeration of Non-crossing Partitions on Surfaces</title><categories>math.CO cs.DM</categories><comments>17 pages, 9 figures</comments><msc-class>05A16</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalize the notion of non-crossing partition on a disk to general
surfaces with boundary. For this, we consider a surface $\Sigma$ and introduce
the number $C_{\Sigma}(n)$ of non-crossing partitions of a set of $n$ points
laying on the boundary of $\Sigma$. Our proofs use bijective techniques arising
from map enumeration, joint with the symbolic method and singularity analysis
on generating functions. An outcome of our results is that the exponential
growth of $C_{\Sigma}(n)$ is the same as the one of the $n$-th Catalan number,
i.e., does not change when we move from the case where $\Sigma$ is a disk to
general surfaces with boundary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2480</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2480</id><created>2011-04-13</created><authors><author><keyname>Roy</keyname><forenames>Shibdas</forenames></author></authors><title>Towards Normal Forms for GHZ/W Calculus</title><categories>cs.LO quant-ph</categories><comments>8 pages. AIP format. To appear in AIP proceedings of the
  International Symposium on &quot;75 Years of Quantum Entanglement: Foundations and
  Information Theoretic Applications&quot;, January 6-10, 2011, Kolkata, India</comments><journal-ref>AIP Conf. Proc. 1384, 112-119 (2011)</journal-ref><doi>10.1063/1.3635852</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a novel GHZ/W graphical calculus has been established to study and
reason more intuitively about interacting quantum systems. The compositional
structure of this calculus was shown to be well-equipped to sufficiently
express arbitrary mutlipartite quantum states equivalent under stochastic local
operations and classical communication (SLOCC). However, it is still not clear
how to explicitly identify which graphical properties lead to what states. This
can be achieved if we have well-behaved normal forms for arbitrary graphs
within this calculus. This article lays down a first attempt at realizing such
normal forms for a restricted class of such graphs, namely simple and regular
graphs. These results should pave the way for the most general cases as part of
future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2486</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2486</id><created>2011-04-13</created><updated>2011-04-25</updated><authors><author><keyname>Ru&#xe9;</keyname><forenames>Juanjo</forenames></author><author><keyname>Sau</keyname><forenames>Ignasi</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Dynamic Programming for Graphs on Surfaces</title><categories>cs.DS math.CO</categories><comments>28 pages, 3 figures</comments><msc-class>05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a framework for the design and analysis of dynamic programming
algorithms for surface-embedded graphs on n vertices and branchwidth at most k.
Our technique applies to general families of problems where standard dynamic
programming runs in 2^{O(k log k)} n steps. Our approach combines tools from
topological graph theory and analytic combinatorics. In particular, we
introduce a new type of branch decomposition called &quot;surface cut
decomposition&quot;, generalizing sphere cut decompositions of planar graphs
introduced by Seymour and Thomas, which has nice combinatorial properties.
Namely, the number of partial solutions that can be arranged on a surface cut
decomposition can be upper-bounded by the number of non-crossing partitions on
surfaces with boundary. It follows that partial solutions can be represented by
a single-exponential (in the branchwidth k) number of configurations. This
proves that, when applied on surface cut decompositions, dynamic programming
runs in 2^{O(k)} n steps. That way, we considerably extend the class of
problems that can be solved in running times with a single-exponential
dependence on branchwidth and unify/improve most previous results in this
direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2499</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2499</id><created>2011-04-13</created><updated>2012-10-08</updated><authors><author><keyname>&#x17b;abicki</keyname><forenames>Micha&#x142;</forenames></author></authors><title>OpenCL/OpenGL approach for studying active Brownian motion</title><categories>physics.comp-ph cs.PF physics.bio-ph</categories><comments>12 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a methodology for studying active Brownian dynamics on
ratchet potentials using interoperating OpenCL and OpenGL frameworks.
Programing details along with optimization issues are discussed, followed by a
com- parison of performance on different devices. Time of visualization using
OpenGL sharing buffer with OpenCL has been tested against another technique
which, while using OpenGL, does not share memory buffer with OpenCL. Both
methods have been compared with visualizing data to an external software -
gnuplot. OpenCL/OpenGL interoperating method has been found the most
appropriate to visualize any large set of data for which calculation itself is
not very long.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2502</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2502</id><created>2011-04-13</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Yao</keyname><forenames>Penghui</forenames></author></authors><title>A Parallel Approximation Algorithm for Positive Semidefinite Programming</title><categories>cs.CC quant-ph</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Positive semidefinite programs are an important subclass of semidefinite
programs in which all matrices involved in the specification of the problem are
positive semidefinite and all scalars involved are non-negative. We present a
parallel algorithm, which given an instance of a positive semidefinite program
of size N and an approximation factor eps &gt; 0, runs in (parallel) time
poly(1/eps) \cdot polylog(N), using poly(N) processors, and outputs a value
which is within multiplicative factor of (1 + eps) to the optimal. Our result
generalizes analogous result of Luby and Nisan [1993] for positive linear
programs and our algorithm is inspired by their algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2504</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2504</id><created>2011-04-13</created><updated>2013-12-30</updated><authors><author><keyname>Castrillon-Candas</keyname><forenames>Julio Enrique</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Eijkhout</keyname><forenames>Victor</forenames></author></authors><title>A Discrete Adapted Hierarchical Basis Solver For Radial Basis Function
  Interpolation</title><categories>cs.NA math.ST stat.TH</categories><journal-ref>BIT Numerical Mathematics March 2013, Volume 53, Issue 1, pp 57-86</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a discrete Hierarchical Basis (HB) to efficiently
solve the Radial Basis Function (RBF) interpolation problem with variable
polynomial order. The HB forms an orthogonal set and is adapted to the kernel
seed function and the placement of the interpolation nodes. Moreover, this
basis is orthogonal to a set of polynomials up to a given order defined on the
interpolating nodes. We are thus able to decouple the RBF interpolation problem
for any order of the polynomial interpolation and solve it in two steps: (1)
The polynomial orthogonal RBF interpolation problem is efficiently solved in
the transformed HB basis with a GMRES iteration and a diagonal, or block SSOR
preconditioner. (2) The residual is then projected onto an orthonormal
polynomial basis. We apply our approach on several test cases to study its
effectiveness, including an application to the Best Linear Unbiased Estimator
regression problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2515</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2515</id><created>2011-04-13</created><authors><author><keyname>Isella</keyname><forenames>L.</forenames></author><author><keyname>Romano</keyname><forenames>M.</forenames></author><author><keyname>Barrat</keyname><forenames>A.</forenames></author><author><keyname>Cattuto</keyname><forenames>C.</forenames></author><author><keyname>Colizza</keyname><forenames>V.</forenames></author><author><keyname>Broeck</keyname><forenames>W. Van den</forenames></author><author><keyname>Gesualdo</keyname><forenames>F.</forenames></author><author><keyname>Pandolfi</keyname><forenames>E.</forenames></author><author><keyname>Rav&#xe0;</keyname><forenames>L.</forenames></author><author><keyname>Rizzo</keyname><forenames>C.</forenames></author><author><keyname>Tozzi</keyname><forenames>A. E.</forenames></author></authors><title>Close encounters in a pediatric ward: measuring face-to-face proximity
  and mixing patterns with wearable sensors</title><categories>q-bio.QM cs.HC</categories><journal-ref>PLoS ONE 6(2): e17144 (2011)</journal-ref><doi>10.1371/journal.pone.0017144</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nosocomial infections place a substantial burden on health care systems and
represent a major issue in current public health, requiring notable efforts for
its prevention. Understanding the dynamics of infection transmission in a
hospital setting is essential for tailoring interventions and predicting the
spread among individuals. Mathematical models need to be informed with accurate
data on contacts among individuals. We used wearable active Radio-Frequency
Identification Devices to detect face-to-face contacts among individuals with a
spatial resolution of about 1.5 meters, and a time resolution of 20 seconds.
The study was conducted in a general pediatrics hospital ward, during a
one-week period, and included 119 participants. Nearly 16,000 contacts were
recorded during the study, with a median of approximately 20 contacts per
participants per day. Overall, 25% of the contacts involved a ward assistant,
23% a nurse, 22% a patient, 22% a caregiver, and 8% a physician. The majority
of contacts were of brief duration, but long and frequent contacts especially
between patients and caregivers were also found. In the setting under study,
caregivers do not represent a significant potential for infection spread to a
large number of individuals, as their interactions mainly involve the
corresponding patient. Nurses would deserve priority in prevention strategies
due to their central role in the potential propagation paths of infections. Our
study shows the feasibility of accurate and reproducible measures of the
pattern of contacts in a hospital setting. The results are particularly useful
for the study of the spread of respiratory infections, for monitoring critical
patterns, and for setting up tailored prevention strategies. Proximity-sensing
technology should be considered as a valuable tool for measuring such patterns
and evaluating nosocomial prevention strategies in specific settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2518</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2518</id><created>2011-04-13</created><authors><author><keyname>Ceschia</keyname><forenames>Sara</forenames></author><author><keyname>Di Gaspero</keyname><forenames>Luca</forenames></author><author><keyname>Schaerf</keyname><forenames>Andrea</forenames></author></authors><title>Design, Engineering, and Experimental Analysis of a Simulated Annealing
  Approach to the Post-Enrolment Course Timetabling Problem</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The post-enrolment course timetabling (PE-CTT) is one of the most studied
timetabling problems, for which many instances and results are available. In
this work we design a metaheuristic approach based on Simulated Annealing to
solve the PE-CTT. We consider all the different variants of the problem that
have been proposed in the literature and we perform a comprehensive
experimental analysis on all the public instances available. The outcome is
that our solver, properly engineered and tuned, performs very well on all
cases, providing the new best known results on many instances and
state-of-the-art values for the others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2524</identifier>
 <datestamp>2015-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2524</id><created>2011-04-13</created><updated>2012-03-10</updated><authors><author><keyname>Chaplick</keyname><forenames>Steven</forenames></author><author><keyname>Stacho</keyname><forenames>Juraj</forenames></author></authors><title>The vertex leafage of chordal graphs</title><categories>cs.DM cs.CC</categories><journal-ref>Journal of Discrete Applied Mathematics: Fifth Workshop on Graph
  Classes, Optimization, and Width Parameters (GROW 2011). 168: 14-25. 2014</journal-ref><doi>10.1016/j.dam.2012.12.006.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Every chordal graph $G$ can be represented as the intersection graph of a
collection of subtrees of a host tree, a so-called {\em tree model} of $G$. The
leafage $\ell(G)$ of a connected chordal graph $G$ is the minimum number of
leaves of the host tree of a tree model of $G$. The vertex leafage $\vl(G)$ is
the smallest number $k$ such that there exists a tree model of $G$ in which
every subtree has at most $k$ leaves. The leafage is a polynomially computable
parameter by the result of \cite{esa}. In this contribution, we study the
vertex leafage.
  We prove for every fixed $k\geq 3$ that deciding whether the vertex leafage
of a given chordal graph is at most $k$ is NP-complete by proving a stronger
result, namely that the problem is NP-complete on split graphs with vertex
leafage of at most $k+1$. On the other hand, for chordal graphs of leafage at
most $\ell$, we show that the vertex leafage can be calculated in time
$n^{O(\ell)}$. Finally, we prove that there exists a tree model that realizes
both the leafage and the vertex leafage of $G$. Notably, for every path graph
$G$, there exists a path model with $\ell(G)$ leaves in the host tree and it
can be computed in $O(n^3)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2527</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2527</id><created>2011-04-13</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Karger</keyname><forenames>David</forenames></author></authors><title>Faster Information Dissemination in Dynamic Networks via Network Coding</title><categories>cs.DS cs.DC</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use network coding to improve the speed of distributed computation in the
dynamic network model of Kuhn, Lynch and Oshman [STOC '10]. In this model an
adversary adaptively chooses a new network topology in every round, making even
basic distributed computations challenging.
  Kuhn et al. show that n nodes, each starting with a d-bit token, can
broadcast them to all nodes in time O(n^2) using b-bit messages, where b &gt; d +
log n. Their algorithms take the natural approach of {token forwarding}: in
every round each node broadcasts some particular token it knows. They prove
matching Omega(n^2) lower bounds for a natural class of token forwarding
algorithms and an Omega(n log n) lower bound that applies to all
token-forwarding algorithms.
  We use network coding, transmitting random linear combinations of tokens, to
break both lower bounds. Our algorithm's performance is quadratic in the
message size b, broadcasting the n tokens in roughly d/b^2 * n^2 rounds. For b
= d = O(log n) our algorithms use O(n^2/log n) rounds, breaking the first lower
bound, while for larger message sizes we obtain linear-time algorithms. We also
consider networks that change only every T rounds, and achieve an additional
factor T^2 speedup. This contrasts with related lower and upper bounds of Kuhn
et al. implying that for natural token-forwarding algorithms a speedup of T,
but not more, can be obtained. Lastly, we give a general way to derandomize
random linear network coding, that also leads to new deterministic information
dissemination algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2529</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2529</id><created>2011-04-13</created><authors><author><keyname>Paul-Henri</keyname><forenames>Tichit</forenames></author><author><keyname>Burokur</keyname><forenames>Shah Nawaz</forenames></author><author><keyname>Germain</keyname><forenames>Dylan</forenames></author><author><keyname>de Lustrac</keyname><forenames>Andre</forenames></author></authors><title>Design and experimental demonstration of a high-directive emission with
  optical transformations</title><categories>cond-mat.mtrl-sci cs.ET physics.optics</categories><comments>http://prb.aps.org/abstract/PRB/v83/i15/e155108</comments><journal-ref>Phys. Rev. B, American Physical Society, 2011, 83, 155108</journal-ref><doi>10.1103/PhysRevB.83.155108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the explosion of wireless networks and automotive radar systems, there
is an acute need for new materials and technologies that would not only
minimize the size of these devices, but also enhance their performances. The
technique of transformation optics-an innovative approach to produce artificial
metamaterials that control electromagnetic waves as if space itself was
transformed-provides unique opportunities to reach this goal. In this paper we
design, fabricate and characterize a new class of metamaterial capable of
transforming the source distribution and radiation pattern of an isotropic
microwave emitter. Our findings have considerable implications for the
development of new ultradirective antennas with superior performances and
compactness compared to conventional antennas operating in the same frequency
range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2538</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2538</id><created>2011-04-13</created><authors><author><keyname>Jaeger</keyname><forenames>Stefan</forenames></author></authors><title>Computational Complexity on Signed Numbers</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new representation of natural numbers and discusses its
consequences for computability and computational complexity. The paper argues
that the introduction of the first Peano axiom in the traditional definition of
natural numbers is not essential. It claims that natural numbers remain usable
in traditional ways without assuming the existence of at least one natural
number. However, the uncertainty about the existence of natural numbers
translates into every computation and introduces intrinsic uncertainty that
cannot be avoided. The uncertainty in the output of a computation can be
reduced, though, at the expense of a longer runtime and thus higher complexity.
For the new representation of natural numbers, the paper claims that, with the
first Peano axiom, P is equal to NP, and that without the first Peano axiom, P
becomes a proper subset of NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2541</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2541</id><created>2011-04-13</created><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Kernels for Global Constraints</title><categories>cs.AI cs.DS</categories><acm-class>F.2.2; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bessiere et al. (AAAI'08) showed that several intractable global constraints
can be efficiently propagated when certain natural problem parameters are
small. In particular, the complete propagation of a global constraint is
fixed-parameter tractable in k - the number of holes in domains - whenever
bound consistency can be enforced in polynomial time; this applies to the
global constraints AtMost-NValue and Extended Global Cardinality (EGC).
  In this paper we extend this line of research and introduce the concept of
reduction to a problem kernel, a key concept of parameterized complexity, to
the field of global constraints. In particular, we show that the consistency
problem for AtMost-NValue constraints admits a linear time reduction to an
equivalent instance on O(k^2) variables and domain values. This small kernel
can be used to speed up the complete propagation of NValue constraints. We
contrast this result by showing that the consistency problem for EGC
constraints does not admit a reduction to a polynomial problem kernel unless
the polynomial hierarchy collapses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2547</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2547</id><created>2011-04-13</created><updated>2012-08-24</updated><authors><author><keyname>Li</keyname><forenames>Mingqiang</forenames></author><author><keyname>Shu</keyname><forenames>Jiwu</forenames></author></authors><title>C-Codes: Cyclic Lowest-Density MDS Array Codes Constructed Using
  Starters for RAID 6</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>A revised version submitted to Designs, Codes and Cryptography for a
  second round of review. 22 pages; A revised version of IBM Research Report
  RC25218</comments><msc-class>05C70, 20K01, 94B05</msc-class><acm-class>E.4; D.4.2; H.1.1; B.8.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The distance-3 cyclic lowest-density MDS array code (called the C-Code) is a
good candidate for RAID 6 because of its optimal storage efficiency, optimal
update complexity, optimal length, and cyclic symmetry. In this paper, the
underlying connections between C-Codes (or quasi-C-Codes) and starters in group
theory are revealed. It is shown that each C-Code (or quasi-C-Code) of length
$2n$ can be constructed using an even starter (or even multi-starter) in
$(Z_{2n},+)$. It is also shown that each C-Code (or quasi-C-Code) has a twin
C-Code (or quasi-C-Code). Then, four infinite families (three of which are new)
of C-Codes of length $p-1$ are constructed, where $p$ is a prime. Besides the
family of length $p-1$, C-Codes for some sporadic even lengths are also
presented. Even so, there are still some even lengths (such as 8) for which
C-Codes do not exist. To cover this limitation, two infinite families (one of
which is new) of quasi-C-Codes of length $2(p-1)$ are constructed for these
even lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2562</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2562</id><created>2011-04-13</created><authors><author><keyname>Fischer</keyname><forenames>Mareike</forenames></author></authors><title>Mathematical aspects of phylogenetic groves</title><categories>q-bio.PE cs.DS math.CO</categories><comments>17 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The inference of new information on the relatedness of species by
phylogenetic trees based on DNA data is one of the main challenges of modern
biology. But despite all technological advances, DNA sequencing is still a
time-consuming and costly process. Therefore, decision criteria would be
desirable to decide a priori which data might contribute new information to the
supertree which is not explicitly displayed by any input tree. A new concept,
so-called groves, to identify taxon sets with the potential to construct such
informative supertrees was suggested by An\'e et al. in 2009. But the important
conjecture that maximal groves can easily be identified in a database remained
unproved and was published on the Isaac Newton Institute's list of open
phylogenetic problems. In this paper, we show that the conjecture does not
generally hold, but also introduce a new concept, namely 2-overlap groves,
which overcomes this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2565</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2565</id><created>2011-04-13</created><authors><author><keyname>Aileni</keyname><forenames>Anvesh Reddy</forenames></author></authors><title>Key Management in Mobile Sensor Networks</title><categories>cs.CR</categories><comments>11 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks consist of sensor nodes with limited computational
and communication capabilities. This paper deals with mobile sensors which are
divided into clusters based on their physical locations. Efficient ways of key
distribution among the sensors and inter and intra cluster communications are
examined. The security of the entire network is considered through efficient
key management by taking into consideration the network's power capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2566</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2566</id><created>2011-04-13</created><authors><author><keyname>Saule</keyname><forenames>Erik</forenames></author><author><keyname>Ba&#x15f;</keyname><forenames>Erdeniz &#xd6;.</forenames></author><author><keyname>&#xc7;ataly&#xfc;rek</keyname><forenames>&#xdc;mit V.</forenames></author></authors><title>Load-Balancing Spatially Located Computations using Rectangular
  Partitions</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributing spatially located heterogeneous workloads is an important
problem in parallel scientific computing. We investigate the problem of
partitioning such workloads (represented as a matrix of non-negative integers)
into rectangles, such that the load of the most loaded rectangle (processor) is
minimized. Since finding the optimal arbitrary rectangle-based partition is an
NP-hard problem, we investigate particular classes of solutions: rectilinear,
jagged and hierarchical. We present a new class of solutions called m-way
jagged partitions, propose new optimal algorithms for m-way jagged partitions
and hierarchical partitions, propose new heuristic algorithms, and provide
worst case performance analyses for some existing and new heuristics. Moreover,
the algorithms are tested in simulation on a wide set of instances. Results
show that two of the algorithms we introduce lead to a much better load balance
than the state-of-the-art algorithms. We also show how to design a two-phase
algorithm that reaches different time/quality tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2580</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2580</id><created>2011-04-13</created><updated>2011-08-15</updated><authors><author><keyname>Rother</keyname><forenames>Diego</forenames></author><author><keyname>Sch&#xfc;tz</keyname><forenames>Simon</forenames></author><author><keyname>Vidal</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>Hypothesize and Bound: A Computational Focus of Attention Mechanism for
  Simultaneous N-D Segmentation, Pose Estimation and Classification Using Shape
  Priors</title><categories>cs.CV cs.CG cs.GR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the ever increasing bandwidth of the visual information available to
many intelligent systems, it is becoming essential to endow them with a sense
of what is worthwhile their attention and what can be safely disregarded. This
article presents a general mathematical framework to efficiently allocate the
available computational resources to process the parts of the input that are
relevant to solve a given perceptual problem. By this we mean to find the
hypothesis H (i.e., the state of the world) that maximizes a function L(H),
representing how well each hypothesis &quot;explains&quot; the input. Given the large
bandwidth of the sensory input, fully evaluating L(H) for each hypothesis H is
computationally infeasible (e.g., because it would imply checking a large
number of pixels). To address this problem we propose a mathematical framework
with two key ingredients. The first one is a Bounding Mechanism (BM) to compute
lower and upper bounds of L(H), for a given computational budget. These bounds
are much cheaper to compute than L(H) itself, can be refined at any time by
increasing the budget allocated to a hypothesis, and are frequently enough to
discard a hypothesis. To compute these bounds, we develop a novel theory of
shapes and shape priors. The second ingredient is a Focus of Attention
Mechanism (FoAM) to select which hypothesis' bounds should be refined next,
with the goal of discarding non-optimal hypotheses with the least amount of
computation. The proposed framework: 1) is very efficient since most hypotheses
are discarded with minimal computation; 2) is parallelizable; 3) is guaranteed
to find the globally optimal hypothesis; and 4) its running time depends on the
problem at hand, not on the bandwidth of the input. We instantiate the proposed
framework for the problem of simultaneously estimating the class, pose, and a
noiseless version of a 2D shape in a 2D image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2581</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2581</id><created>2011-04-13</created><updated>2012-10-04</updated><authors><author><keyname>Nikitopoulos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Ascheid</keyname><forenames>Gerd</forenames></author></authors><title>Approximate MIMO Iterative Processing with Adjustable Complexity
  Requirements</title><categories>cs.IT math.IT</categories><comments>The final version of this paper appears in IEEE Transactions on
  Vehicular Technology</comments><journal-ref>IEEE Transactions on Vehicular Technology, vol. 61, no. 2, pp.
  639-650, Feb. 2012</journal-ref><doi>10.1109/TVT.2011.2179324</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Targeting always the best achievable bit error rate (BER) performance in
iterative receivers operating over multiple-input multiple-output (MIMO)
channels may result in significant waste of resources, especially when the
achievable BER is orders of magnitude better than the target performance (e.g.,
under good channel conditions and at high signal-to-noise ratio (SNR)). In
contrast to the typical iterative schemes, a practical iterative decoding
framework that approximates the soft-information exchange is proposed which
allows reduced complexity sphere and channel decoding, adjustable to the
transmission conditions and the required bit error rate. With the proposed
approximate soft information exchange the performance of the exact soft
information can still be reached with significant complexity gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2599</identifier>
 <datestamp>2012-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2599</id><created>2011-04-13</created><updated>2012-02-21</updated><authors><author><keyname>Alur</keyname><forenames>Rajeev</forenames></author><author><keyname>D'Antoni</keyname><forenames>Loris</forenames></author></authors><title>Streaming Tree Transducers</title><categories>cs.FL cs.DB</categories><comments>40 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theory of tree transducers provides a foundation for understanding
expressiveness and complexity of analysis problems for specification languages
for transforming hierarchically structured data such as XML documents. We
introduce streaming tree transducers as an analyzable, executable, and
expressive model for transforming unranked ordered trees in a single pass.
Given a linear encoding of the input tree, the transducer makes a single
left-to-right pass through the input, and computes the output in linear time
using a finite-state control, a visibly pushdown stack, and a finite number of
variables that store output chunks that can be combined using the operations of
string-concatenation and tree-insertion. We prove that the expressiveness of
the model coincides with transductions definable using monadic second-order
logic (MSO). Existing models of tree transducers either cannot implement all
MSO-definable transformations, or require regular look ahead that prohibits
single-pass implementation. We show a variety of analysis problems such as
type-checking and checking functional equivalence are solvable for our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2606</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2606</id><created>2011-04-13</created><updated>2012-05-23</updated><authors><author><keyname>Fronczak</keyname><forenames>Agata</forenames></author><author><keyname>Fronczak</keyname><forenames>Piotr</forenames></author></authors><title>Statistical mechanics of the international trade network</title><categories>q-fin.GN cs.SI physics.data-an physics.soc-ph</categories><comments>6 pages, 2 figures</comments><journal-ref>Phys. Rev. E 85, 056113 (2012)</journal-ref><doi>10.1103/PhysRevE.85.056113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing real data on international trade covering the time interval
1950-2000, we show that in each year over the analyzed period the network is a
typical representative of the ensemble of maximally random weighted networks,
whose directed connections (bilateral trade volumes) are only characterized by
the product of the trading countries' GDPs. It means that time evolution of
this network may be considered as a continuous sequence of equilibrium states,
i.e. quasi-static process. This, in turn, allows one to apply the linear
response theory to make (and also verify) simple predictions about the network.
In particular, we show that bilateral trade fulfills fluctuation-response
theorem, which states that the average relative change in import (export)
between two countries is a sum of relative changes in their GDPs. Yearly
changes in trade volumes prove that the theorem is valid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2630</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2630</id><created>2011-04-13</created><authors><author><keyname>Santos</keyname><forenames>Francisco</forenames></author><author><keyname>Stephen</keyname><forenames>Tamon</forenames></author><author><keyname>Thomas</keyname><forenames>Hugh</forenames></author></authors><title>Embedding a pair of graphs in a surface, and the width of 4-dimensional
  prismatoids</title><categories>math.CO cs.CG</categories><comments>This paper merges and supersedes the papers arXiv:1101.3050 (of the
  last two authors) and arXiv:1102.2645 (of the first author)</comments><msc-class>52B05</msc-class><journal-ref>Discrete Comput. Geom. 47:3 (2012), 569-576</journal-ref><doi>10.1007/s00454-011-9361-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A prismatoid is a polytope with all its vertices contained in two parallel
facets, called its bases. Its width is the number of steps needed to go from
one base to the other in the dual graph. The first author recently showed that
the existence of counter-examples to the Hirsch conjecture is equivalent to
that of $d$-prismatoids of width larger than $d$, and constructed such
prismatoids in dimension five. Here we show that the same is impossible in
dimension four. This is proved by looking at the pair of graph embeddings on a
2-sphere that arise from the normal fans of the two bases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2644</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2644</id><created>2011-04-13</created><authors><author><keyname>Lobo</keyname><forenames>Fernando G.</forenames></author></authors><title>Idealized Dynamic Population Sizing for Uniformly Scaled Problems</title><categories>cs.NE</categories><comments>14 pages, submitted to ACM GECCO-2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores an idealized dynamic population sizing strategy for
solving additive decomposable problems of uniform scale. The method is designed
on top of the foundations of existing population sizing theory for this class
of problems, and is carefully compared with an optimal fixed population sized
genetic algorithm. The resulting strategy should be close to a lower bound in
terms of what can be achieved, performance-wise, by self-adjusting population
sizing algorithms for this class of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2679</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2679</id><created>2011-04-14</created><updated>2012-01-10</updated><authors><author><keyname>Henrion</keyname><forenames>Didier</forenames><affiliation>LAAS, CTU/FEE</affiliation></author><author><keyname>Louembet</keyname><forenames>Christophe</forenames><affiliation>LAAS</affiliation></author></authors><title>Convex inner approximations of nonconvex semialgebraic sets applied to
  fixed-order controller design</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><report-no>Rapport LAAS No 11213</report-no><journal-ref>International Journal of Control 85, 8 (2012) pp. 1083-1092</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an elementary algorithm to build convex inner approximations of
nonconvex sets. Both input and output sets are basic semialgebraic sets given
as lists of defining multivariate polynomials. Even though no optimality
guarantees can be given (e.g. in terms of volume maximization for bounded
sets), the algorithm is designed to preserve convex boundaries as much as
possible, while removing regions with concave boundaries. In particular, the
algorithm leaves invariant a given convex set. The algorithm is based on
Gloptipoly 3, a public-domain Matlab package solving nonconvex polynomial
optimization problems with the help of convex semidefinite programming
(optimization over linear matrix inequalities, or LMIs). We illustrate how the
algorithm can be used to design fixed-order controllers for linear systems,
following a polynomial approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2681</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2681</id><created>2011-04-14</created><authors><author><keyname>Baelde</keyname><forenames>David</forenames><affiliation>LIX</affiliation></author><author><keyname>Beauxis</keyname><forenames>Romain</forenames><affiliation>LIX, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Mimram</keyname><forenames>Samuel</forenames><affiliation>CEA LIST</affiliation></author></authors><title>Liquidsoap: a High-Level Programming Language for Multimedia Streaming</title><categories>cs.PL cs.MM cs.SD</categories><proxy>ccsd</proxy><journal-ref>SOFSEM 2011: Theory and Practice of Computer Science 6543 (2011)
  99-110</journal-ref><doi>10.1007/978-3-642-18381-2_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generating multimedia streams, such as in a netradio, is a task which is
complex and difficult to adapt to every users' needs. We introduce a novel
approach in order to achieve it, based on a dedicated high-level functional
programming language, called Liquidsoap, for generating, manipulating and
broadcasting multimedia streams. Unlike traditional approaches, which are based
on configuration files or static graphical interfaces, it also allows the user
to build complex and highly customized systems. This language is based on a
model for streams and contains operators and constructions, which make it
adapted to the generation of streams. The interpreter of the language also
ensures many properties concerning the good execution of the stream generation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2689</identifier>
 <datestamp>2012-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2689</id><created>2011-04-14</created><updated>2011-12-09</updated><authors><author><keyname>Hamad&#xe8;ne</keyname><forenames>Said</forenames></author><author><keyname>Morlais</keyname><forenames>Marie-Am&#xe9;lie</forenames></author></authors><title>Viscosity solutions of systems of PDEs with interconnected obstacles and
  Multi modes switching problems</title><categories>math.OC cs.SY</categories><comments>36 pages</comments><msc-class>60G40, 62P20, 91B99, 91B28, 35B37, 49L25</msc-class><doi>10.1007/s00245-012-9184-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with existence and uniqueness, in viscosity sense, of a
solution for a system of m variational partial differential inequalities with
inter-connected obstacles. A particular case of this system is the
deterministic version of the Verification Theorem of the Markovian optimal
m-states switching problem. The switching cost functions are arbitrary. This
problem is connected with the valuation of a power plant in the energy market.
The main tool is the notion of systems of reflected BSDEs with oblique
reflection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2690</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2690</id><created>2011-04-14</created><updated>2011-07-13</updated><authors><author><keyname>Caragiannis</keyname><forenames>Ioannis</forenames></author><author><keyname>Fanelli</keyname><forenames>Angelo</forenames></author><author><keyname>Gravin</keyname><forenames>Nick</forenames></author><author><keyname>Skopalik</keyname><forenames>Alexander</forenames></author></authors><title>Efficient computation of approximate pure Nash equilibria in congestion
  games</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Congestion games constitute an important class of games in which computing an
exact or even approximate pure Nash equilibrium is in general {\sf
PLS}-complete. We present a surprisingly simple polynomial-time algorithm that
computes O(1)-approximate Nash equilibria in these games. In particular, for
congestion games with linear latency functions, our algorithm computes
$(2+\epsilon)$-approximate pure Nash equilibria in time polynomial in the
number of players, the number of resources and $1/\epsilon$. It also applies to
games with polynomial latency functions with constant maximum degree $d$;
there, the approximation guarantee is $d^{O(d)}$. The algorithm essentially
identifies a polynomially long sequence of best-response moves that lead to an
approximate equilibrium; the existence of such short sequences is interesting
in itself. These are the first positive algorithmic results for approximate
equilibria in non-symmetric congestion games. We strengthen them further by
proving that, for congestion games that deviate from our mild assumptions,
computing $\rho$-approximate equilibria is {\sf PLS}-complete for any
polynomial-time computable $\rho$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2702</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2702</id><created>2011-04-14</created><authors><author><keyname>Perarnau</keyname><forenames>Guillem</forenames></author><author><keyname>Serra</keyname><forenames>Oriol</forenames></author></authors><title>Rainbow Matchings: existence and counting</title><categories>math.CO cs.DM</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A perfect matching M in an edge-colored complete bipartite graph K_{n,n} is
rainbow if no pair of edges in M have the same color. We obtain asymptotic
enumeration results for the number of rainbow matchings in terms of the maximum
number of occurrences of a color. We also consider two natural models of random
edge-colored K_{n,n} and show that, if the number of colors is at least n, then
there is with high probability a random matching. This in particular shows that
almost every square matrix of order n in which every entry appears at most n
times has a Latin transversal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2721</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2721</id><created>2011-04-14</created><authors><author><keyname>AL-Hamami</keyname><forenames>Alaa H.</forenames></author><author><keyname>Hashem</keyname><forenames>Soukaena H.</forenames></author></authors><title>Optimal Cell Towers Distribution by using Spatial Mining and Geographic
  Information System</title><categories>cs.DB</categories><comments>5 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT) , ISSN: 2221-0741, Vol. 1, No. 2, 44-48, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The appearance of wireless communication is dramatically changing our life.
Mobile telecommunications emerged as a technological marvel allowing for access
to personal and other services, devices, computation and communication, in any
place and at any time through effortless plug and play. Setting up wireless
mobile networks often requires: Frequency Assignment, Communication Protocol
selection, Routing schemes selection, and cells towers distributions. This
research aims to optimize the cells towers distribution by using spatial mining
with Geographic Information System (GIS) as a tool. The distribution
optimization could be done by applying the Digital Elevation Model (DEM) on the
image of the area which must be covered with two levels of hierarchy. The
research will apply the spatial association rules technique on the second level
to select the best square in the cell for placing the antenna. From that the
proposal will try to minimize the number of installed towers, makes tower's
location feasible, and provides full area coverage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2724</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2724</id><created>2011-04-14</created><authors><author><keyname>Kaspar</keyname><forenames>Stefan</forenames></author></authors><title>Computing Border Bases without using a Term Ordering</title><categories>math.AC cs.SC</categories><comments>12 pages</comments><msc-class>13P10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Border bases, a generalization of Groebner bases, have actively been
researched during recent years due to their applicability to industrial
problems. A. Kehrein and M. Kreuzer formulated the so called Border Basis
Algorithm, an algorithm which allows the computation of border bases that
relate to a degree compatible term ordering. In this paper we extend the
original Border Basis Algorithm in such a way that also border bases that do
not relate to any term ordering can be computed by it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2732</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2732</id><created>2011-04-14</created><authors><author><keyname>Beliakov</keyname><forenames>Gleb</forenames></author></authors><title>Parallel calculation of the median and order statistics on GPUs with
  application to robust regression</title><categories>cs.DC cs.DS math.NA</categories><msc-class>65Y05, 65Y10, 90C25,</msc-class><acm-class>F.2.2; C.1.4; C.1.2; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and compare various approaches to a classical selection problem on
Graphics Processing Units (GPUs). The selection problem consists in selecting
the $k$-th smallest element from an array of size $n$, called $k$-th order
statistic. We focus on calculating the median of a sample, the $n/2$-th order
statistic. We introduce a new method based on minimization of a convex
function, and show its numerical superiority when calculating the order
statistics of very large arrays on GPUs. We outline an application of this
approach to efficient estimation of model parameters in high breakdown robust
regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2745</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2745</id><created>2011-04-14</created><authors><author><keyname>Aslan</keyname><forenames>Cagri</forenames></author><author><keyname>Tari</keyname><forenames>Sibel</forenames></author></authors><title>An Axis-Based Representation for Recognition</title><categories>cs.CV</categories><journal-ref>ICCV(2005) 1339-1346</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new axis-based shape representation scheme along with a
matching framework to address the problem of generic shape recognition. The
main idea is to define the relative spatial arrangement of local symmetry axes
and their metric properties in a shape centered coordinate frame. The resulting
descriptions are invariant to scale, rotation, small changes in viewpoint and
articulations. Symmetry points are extracted from a surface whose level curves
roughly mimic the motion by curvature. By increasing the amount of smoothing on
the evolving curve, only those symmetry axes that correspond to the most
prominent parts of a shape are extracted. The representation does not suffer
from the common instability problems of the traditional connected skeletons. It
captures the perceptual qualities of shapes well. Therefore finding the
similarities and the differences among shapes becomes easier. The matching
process gives highly successful results on a diverse database of 2D shapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2751</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2751</id><created>2011-04-14</created><authors><author><keyname>Aslan</keyname><forenames>C.</forenames></author><author><keyname>Erdem</keyname><forenames>A.</forenames></author><author><keyname>Erdem</keyname><forenames>E.</forenames></author><author><keyname>Tari</keyname><forenames>S.</forenames></author></authors><title>Disconnected Skeleton: Shape at its Absolute Scale</title><categories>cs.CV</categories><comments>The work excluding {\S}V and {\S}VI has first appeared in 2005 ICCV:
  Aslan, C., Tari, S.: An Axis-Based Representation for Recognition. In
  ICCV(2005) 1339- 1346.; Aslan, C., : Disconnected Skeletons for Shape
  Recognition. Masters thesis, Department of Computer Engineering, Middle East
  Technical University, May 2005</comments><journal-ref>T-PAMI vol. 30 no. 12, pp. 2188-2203, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new skeletal representation along with a matching framework to
address the deformable shape recognition problem. The disconnectedness arises
as a result of excessive regularization that we use to describe a shape at an
attainably coarse scale. Our motivation is to rely on the stable properties of
the shape instead of inaccurately measured secondary details. The new
representation does not suffer from the common instability problems of
traditional connected skeletons, and the matching process gives quite
successful results on a diverse database of 2D shapes. An important difference
of our approach from the conventional use of the skeleton is that we replace
the local coordinate frame with a global Euclidean frame supported by
additional mechanisms to handle articulations and local boundary deformations.
As a result, we can produce descriptions that are sensitive to any combination
of changes in scale, position, orientation and articulation, as well as
invariant ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2756</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2756</id><created>2011-04-14</created><authors><author><keyname>Hashem</keyname><forenames>Tanzima</forenames></author><author><keyname>Kulik</keyname><forenames>Lars</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Privacy Preserving Moving KNN Queries</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach that protects trajectory privacy of users who
access location-based services through a moving k nearest neighbor (MkNN)
query. An MkNN query continuously returns the k nearest data objects for a
moving user (query point). Simply updating a user's imprecise location such as
a region instead of the exact position to a location-based service provider
(LSP) cannot ensure privacy of the user for an MkNN query: continuous
disclosure of regions enables the LSP to follow a user's trajectory. We
identify the problem of trajectory privacy that arises from the overlap of
consecutive regions while requesting an MkNN query and provide the first
solution to this problem. Our approach allows a user to specify the confidence
level that represents a bound of how much more the user may need to travel than
the actual kth nearest data object. By hiding a user's required confidence
level and the required number of nearest data objects from an LSP, we develop a
technique to prevent the LSP from tracking the user's trajectory for MkNN
queries. We propose an efficient algorithm for the LSP to find k nearest data
objects for a region with a user's specified confidence level, which is an
essential component to evaluate an MkNN query in a privacy preserving manner;
this algorithm is at least two times faster than the state-of-the-art
algorithm. Extensive experimental studies validate the effectiveness of our
trajectory privacy protection technique and the efficiency of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2762</identifier>
 <datestamp>2013-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2762</id><created>2011-04-14</created><updated>2011-04-18</updated><authors><author><keyname>Szantai</keyname><forenames>Tamas</forenames></author><author><keyname>Kovacs</keyname><forenames>Edith</forenames></author></authors><title>Discovering a junction tree behind a Markov network by a greedy
  algorithm</title><categories>math.PR cs.DS</categories><comments>The paper was presented at VOCAL 2010 in Veszprem, Hungary</comments><msc-class>90C35, 90C59, 62B10, 94A17, 62H05, 62H30</msc-class><journal-ref>Optimization and Engineering, Vol. 14, Issue 4, 2013</journal-ref><doi>10.1007/s11081-013-9232-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In an earlier paper we introduced a special kind of k-width junction tree,
called k-th order t-cherry junction tree in order to approximate a joint
probability distribution. The approximation is the best if the Kullback-Leibler
divergence between the true joint probability distribution and the
approximating one is minimal. Finding the best approximating k-width junction
tree is NP-complete if k&gt;2. In our earlier paper we also proved that the best
approximating k-width junction tree can be embedded into a k-th order t-cherry
junction tree. We introduce a greedy algorithm resulting very good
approximations in reasonable computing time.
  In this paper we prove that if the Markov network underlying fullfills some
requirements then our greedy algorithm is able to find the true probability
distribution or its best approximation in the family of the k-th order t-cherry
tree probability distributions. Our algorithm uses just the k-th order marginal
probability distributions as input.
  We compare the results of the greedy algorithm proposed in this paper with
the greedy algorithm proposed by Malvestuto in 1991.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2773</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2773</id><created>2011-04-14</created><updated>2011-04-19</updated><authors><author><keyname>Bianchi</keyname><forenames>Pascal</forenames></author><author><keyname>Jakubowicz</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author></authors><title>Distributed Stochastic Approximation for Constrained and Unconstrained
  Optimization</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the convergence of a distributed Robbins-Monro
algorithm for both constrained and unconstrained optimization in multi-agent
systems. The algorithm searches for local minima of a (nonconvex) objective
function which is supposed to coincide with a sum of local utility functions of
the agents. The algorithm under study consists of two steps: a local stochastic
gradient descent at each agent and a gossip step that drives the network of
agents to a consensus. It is proved that i) an agreement is achieved between
agents on the value of the estimate, ii) the algorithm converges to the set of
Kuhn-Tucker points of the optimization problem. The proof relies on recent
results about differential inclusions. In the context of unconstrained
optimization, intelligible sufficient conditions are provided in order to
ensure the stability of the algorithm. In the latter case, we also provide a
central limit theorem which governs the asymptotic fluctuations of the
estimate. We illustrate our results in the case of distributed power allocation
for ad-hoc wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2784</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2784</id><created>2011-04-14</created><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>Diversity Analysis of Symbol-by-Symbol Linear Equalizers</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In frequency-selective channels linear receivers enjoy significantly-reduced
complexity compared with maximum likelihood receivers at the cost of
performance degradation which can be in the form of a loss of the inherent
frequency diversity order or reduced coding gain. This paper demonstrates that
the minimum mean-square error symbol-by-symbol linear equalizer incurs no
diversity loss compared to the maximum likelihood receivers. In particular, for
a channel with memory $\nu$, it achieves the full diversity order of ($\nu+1$)
while the zero-forcing symbol-by-symbol linear equalizer always achieves a
diversity order of one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2788</identifier>
 <datestamp>2014-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2788</id><created>2011-04-14</created><updated>2014-03-06</updated><authors><author><keyname>Fichte</keyname><forenames>Johannes Klaus</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Backdoors to Tractable Answer-Set Programming</title><categories>cs.CC cs.AI</categories><comments>This paper extends and updates papers that appeared in the
  proceedings of IJCAI'11 (arXiv:1104.2788) and ESSLLI'11 (arXiv:1205.3663). We
  provide a higher detail level, full proofs and more examples; present new
  results on preprocessing, a general method to lift parameters from normal
  programs to disjunctive programs, and a theoretical comparison of
  ASP-parameters; and provide some empirical data</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Answer Set Programming (ASP) is an increasingly popular framework for
declarative programming that admits the description of problems by means of
rules and constraints that form a disjunctive logic program. In particular,
many AI problems such as reasoning in a nonmonotonic setting can be directly
formulated in ASP. Although the main problems of ASP are of high computational
complexity, located at the second level of the Polynomial Hierarchy, several
restrictions of ASP have been identified in the literature, under which ASP
problems become tractable.
  In this paper we use the concept of backdoors to identify new restrictions
that make ASP problems tractable. Small backdoors are sets of atoms that
represent &quot;clever reasoning shortcuts&quot; through the search space and represent a
hidden structure in the problem input. The concept of backdoors is widely used
in the areas of propositional satisfiability and constraint satisfaction. We
show that it can be fruitfully adapted to ASP. We demonstrate how backdoors can
serve as a unifying framework that accommodates several tractable restrictions
of ASP known from the literature. Furthermore, we show how backdoors allow us
to deploy recent algorithmic results from parameterized complexity theory to
the domain of answer set programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2799</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2799</id><created>2011-04-14</created><authors><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>P&#x1ce;tra&#x15f;cu</keyname><forenames>Mihai</forenames></author></authors><title>Using Hashing to Solve the Dictionary Problem (In External Memory)</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the dictionary problem in external memory and improve the update
time of the well-known buffer tree by roughly a logarithmic factor. For any
\lambda &gt;= max {lg lg n, log_{M/B} (n/B)}, we can support updates in time
O(\lambda / B) and queries in sublogarithmic time, O(log_\lambda n). We also
present a lower bound in the cell-probe model showing that our data structure
is optimal.
  In the RAM, hash tables have been used to solve the dictionary problem faster
than binary search for more than half a century. By contrast, our data
structure is the first to beat the comparison barrier in external memory. Ours
is also the first data structure to depart convincingly from the indivisibility
paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2803</identifier>
 <datestamp>2014-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2803</id><created>2011-04-14</created><updated>2014-10-24</updated><authors><author><keyname>Bonsangue</keyname><forenames>Marcello M.</forenames></author><author><keyname>Milius</keyname><forenames>Stefan</forenames></author><author><keyname>Silva</keyname><forenames>Alexandra</forenames></author></authors><title>Sound and complete axiomatizations of coalgebraic language equivalence</title><categories>cs.LO math.CT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalgebras provide a uniform framework to study dynamical systems, including
several types of automata. In this paper, we make use of the coalgebraic view
on systems to investigate, in a uniform way, under which conditions calculi
that are sound and complete with respect to behavioral equivalence can be
extended to a coarser coalgebraic language equivalence, which arises from a
generalised powerset construction that determinises coalgebras. We show that
soundness and completeness are established by proving that expressions modulo
axioms of a calculus form the rational fixpoint of the given type functor. Our
main result is that the rational fixpoint of the functor $FT$, where $T$ is a
monad describing the branching of the systems (e.g. non-determinism, weights,
probability etc.), has as a quotient the rational fixpoint of the
&quot;determinised&quot; type functor $\bar F$, a lifting of $F$ to the category of
$T$-algebras. We apply our framework to the concrete example of weighted
automata, for which we present a new sound and complete calculus for weighted
language equivalence. As a special case, we obtain non-deterministic automata,
where we recover Rabinovich's sound and complete calculus for language
equivalence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2808</identifier>
 <datestamp>2012-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2808</id><created>2011-04-14</created><updated>2012-09-26</updated><authors><author><keyname>Hauser</keyname><forenames>Alain</forenames></author><author><keyname>B&#xfc;hlmann</keyname><forenames>Peter</forenames></author></authors><title>Characterization and Greedy Learning of Interventional Markov
  Equivalence Classes of Directed Acyclic Graphs</title><categories>stat.ME cs.DM math.ST stat.TH</categories><journal-ref>Journal of Machine Learning Research, 13:2409-2464, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The investigation of directed acyclic graphs (DAGs) encoding the same Markov
property, that is the same conditional independence relations of multivariate
observational distributions, has a long tradition; many algorithms exist for
model selection and structure learning in Markov equivalence classes. In this
paper, we extend the notion of Markov equivalence of DAGs to the case of
interventional distributions arising from multiple intervention experiments. We
show that under reasonable assumptions on the intervention experiments,
interventional Markov equivalence defines a finer partitioning of DAGs than
observational Markov equivalence and hence improves the identifiability of
causal models. We give a graph theoretic criterion for two DAGs being Markov
equivalent under interventions and show that each interventional Markov
equivalence class can, analogously to the observational case, be uniquely
represented by a chain graph called interventional essential graph (also known
as CPDAG in the observational case). These are key insights for deriving a
generalization of the Greedy Equivalence Search algorithm aimed at structure
learning from interventional data. This new algorithm is evaluated in a
simulation study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2809</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2809</id><created>2011-04-14</created><authors><author><keyname>Fu</keyname><forenames>Bin</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Schweller</keyname><forenames>Robert T.</forenames></author><author><keyname>Sheline</keyname><forenames>Bobby</forenames></author></authors><title>Self-Assembly with Geometric Tiles</title><categories>cs.CG cs.CC cs.DS cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose a generalization of Winfree's abstract Tile Assembly
Model (aTAM) in which tile types are assigned rigid shapes, or geometries,
along each tile face. We examine the number of distinct tile types needed to
assemble shapes within this model, the temperature required for efficient
assembly, and the problem of designing compact geometric faces to meet given
compatibility specifications. Our results show a dramatic decrease in the
number of tile types needed to assemble $n \times n$ squares to
$\Theta(\sqrt{\log n})$ at temperature 1 for the most simple model which meets
a lower bound from Kolmogorov complexity, and $O(\log\log n)$ in a model in
which tile aggregates must move together through obstacle free paths within the
plane. This stands in contrast to the $\Theta(\log n / \log\log n)$ tile types
at temperature 2 needed in the basic aTAM. We also provide a general method for
simulating a large and computationally universal class of temperature 2 aTAM
systems with geometric tiles at temperature 1. Finally, we consider the problem
of computing a set of compact geometric faces for a tile system to implement a
given set of compatibility specifications. We show a number of bounds on the
complexity of geometry size needed for various classes of compatibility
specifications, many of which we directly apply to our tile assembly results to
achieve non-trivial reductions in geometry size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2816</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2816</id><created>2011-04-14</created><authors><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>On the optimal compression of sets in PSPACE</title><categories>cs.CC</categories><msc-class>68Q30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that if DTIME[2^{O(n)}] is not included in DSPACE[2^{o(n)}], then,
for every set B in PSPACE, all strings x in B of length n can be represented by
a string compressed(x) of length at most log (|B^{=n}|) + O(log n), such that a
polynomial-time algorithm, given compressed(x), can distinguish x from all the
other strings in B^{=n}. Modulo the O(log n) additive trem, this achieves the
information-theoretical optimum for string compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2818</identifier>
 <datestamp>2012-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2818</id><created>2011-04-14</created><updated>2012-11-30</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Jones</keyname><forenames>Mark</forenames></author><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>A New Bound for 3-Satisfiable MaxSat and its Algorithmic Application</title><categories>cs.DM cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let F be a CNF formula with n variables and m clauses. F is 3-satisfiable if
for any 3 clauses in F, there is a truth assignment which satisfies all of
them. Lieberherr and Specker (1982) and, later, Yannakakis (1994) proved that
in each 3-satisfiable CNF formula at least 2/3 of its clauses can be satisfied
by a truth assignment. We improve this result by showing that every
3-satisfiable CNF formula F contains a subset of variables U, such that some
truth assignment $\tau$ will satisfy at least $2m/3+ m_U/3+\rho n'$ clauses,
where m is the number of clauses of F, m_U is the number of clauses of F
containing a variable from U, n' is the total number of variables in clauses
not containing a variable in U, and \rho is a positive absolute constant. Both
U and $\tau$ can be found in polynomial time. We use our result to show that
the following parameterized problem is fixed-parameter tractable and, moreover,
has a kernel with a linear number of variables. In 3-S-MAXSAT-AE, we are given
a 3-satisfiable CNF formula F with m clauses and asked to determine whether
there is an assignment which satisfies at least 2m/3 + k clauses, where k is
the parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2824</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2824</id><created>2011-04-14</created><authors><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>Pattern discovery for semi-structured web pages using bar-tree
  representation</title><categories>cs.IR cs.DS</categories><comments>9 pages</comments><report-no>FISIKALIPI-10040</report-no><journal-ref>Int. J. Comput. Theor. Eng. 3 (2011) 261-269</journal-ref><doi>10.7763/IJCTE.2011.V3.314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many websites with an underlying database containing structured data provide
the richest and most dense source of information relevant for topical data
integration. The real data integration requires sustainable and reliable
pattern discovery to enable accurate content retrieval and to recognize pattern
changes from time to time; yet, extracting the structured data from web
documents is still lacking from its accuracy. This paper proposes the bar-tree
representation to describe the whole pattern of web pages in an efficient way
based on the reverse algorithm. While previous algorithms always trace the
pattern and extract the region of interest from \textit{top root}, the reverse
algorithm recognizes the pattern from the region of interest to both top and
bottom roots simultaneously. The attributes are then extracted and labeled
reversely from the region of interest of targeted contents. Since using
conventional representations for the algorithm should require more
computational power, the bar-tree method is developed to represent the
generated patterns using bar graphs characterized by the depths and widths from
the document roots. We show that this representation is suitable for extracting
the data from the semi-structured web sources, and for detecting the template
changes of targeted pages. The experimental results show perfect recognition
rate for template changes in several web targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2825</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2825</id><created>2011-04-14</created><authors><author><keyname>Lutz</keyname><forenames>Carsten</forenames></author><author><keyname>Wolter</keyname><forenames>Frank</forenames></author></authors><title>Foundations for Uniform Interpolation and Forgetting in Expressive
  Description Logics</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study uniform interpolation and forgetting in the description logic ALC.
Our main results are model-theoretic characterizations of uniform inter-
polants and their existence in terms of bisimula- tions, tight complexity
bounds for deciding the existence of uniform interpolants, an approach to
computing interpolants when they exist, and tight bounds on their size. We use
a mix of model- theoretic and automata-theoretic methods that, as a by-product,
also provides characterizations of and decision procedures for conservative
extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2829</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2829</id><created>2011-04-14</created><authors><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author><author><keyname>Rosenblueth</keyname><forenames>David A.</forenames></author></authors><title>Self-organizing traffic lights at multiple-street intersections</title><categories>nlin.AO cs.AI nlin.CG</categories><comments>32 pages, 12 figures</comments><report-no>C3 Report, 2011.02</report-no><acm-class>I.2.11; I.6.3; J.2; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Summary: Traffic light coordination is a complex problem. In this paper, we
extend previous work on an abstract model of city traffic to allow for multiple
street intersections. We test a self-organizing method in our model, showing
that it is close to theoretical optima and superior to a traditional method of
traffic light coordination.
  Abstract: The elementary cellular automaton following rule 184 can mimic
particles flowing in one direction at a constant speed. This automaton can
therefore model highway traffic. In a recent paper, we have incorporated
intersections regulated by traffic lights to this model using exclusively
elementary cellular automata. In such a paper, however, we only explored a
rectangular grid. We now extend our model to more complex scenarios employing
an hexagonal grid. This extension shows first that our model can readily
incorporate multiple-way intersections and hence simulate complex scenarios. In
addition, the current extension allows us to study and evaluate the behavior of
two different kinds of traffic light controller for a grid of six-way streets
allowing for either two or three street intersections: a traffic light that
tries to adapt to the amount of traffic (which results in self-organizing
traffic lights) and a system of synchronized traffic lights with coordinated
rigid periods (sometimes called the &quot;green wave&quot; method). We observe a tradeoff
between system capacity and topological complexity. The green wave method is
unable to cope with the complexity of a higher-capacity scenario, while the
self-organizing method is scalable, adapting to the complexity of a scenario
and exploiting its maximum capacity. Additionally, in this paper we propose a
benchmark, independent of methods and models, to measure the performance of a
traffic light controller comparing it against a theoretical optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2842</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2842</id><created>2011-04-14</created><updated>2011-04-15</updated><authors><author><keyname>Ordyniak</keyname><forenames>Sebastian</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Augmenting Tractable Fragments of Abstract Argumentation</title><categories>cs.AI cs.CC</categories><comments>accepted for ijcai 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new and compelling approach to the efficient solution of
important computational problems that arise in the context of abstract
argumentation. Our approach makes known algorithms defined for restricted
fragments generally applicable, at a computational cost that scales with the
distance from the fragment. Thus, in a certain sense, we gradually augment
tractable fragments. Surprisingly, it turns out that some tractable fragments
admit such an augmentation and that others do not.
  More specifically, we show that the problems of credulous and skeptical
acceptance are fixed-parameter tractable when parameterized by the distance
from the fragment of acyclic argumentation frameworks. Other tractable
fragments such as the fragments of symmetrical and bipartite frameworks seem to
prohibit an augmentation: the acceptance problems are already intractable for
frameworks at distance 1 from the fragments.
  For our study we use a broad setting and consider several different
semantics. For the algorithmic results we utilize recent advances in
fixed-parameter tractability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2844</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2844</id><created>2011-04-14</created><updated>2011-04-15</updated><authors><author><keyname>Lutz</keyname><forenames>Carsten</forenames></author><author><keyname>Piro</keyname><forenames>Robert</forenames></author><author><keyname>Wolter</keyname><forenames>Frank</forenames></author></authors><title>Description Logic TBoxes: Model-theoretic Characterizations and
  Rewritability</title><categories>cs.LO math.LO</categories><comments>Submitted and accepted for IJCAI 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize the expressive power of description logic (DL) TBoxes, both
for expressive DLs such as ALC and ALCQIO and lightweight DLs such as DL-Lite
and EL. Our characterizations are relative to first-order logic, based on a
wide range of semantic notions such as bisimulation, equisimulation, disjoint
union, and direct product. We exemplify the use of the characterizations by a
first study of the following novel family of decision problems: given a TBox T
formulated in a DL L, decide whether T can be equivalently rewritten as a TBox
in the fragment L' of L.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2861</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2861</id><created>2011-04-14</created><updated>2012-04-11</updated><authors><author><keyname>Agrawal</keyname><forenames>Mayur</forenames></author><author><keyname>Chance</keyname><forenames>Zachary</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Balakrishnan</keyname><forenames>Venkataramanan</forenames></author></authors><title>Using Channel Output Feedback to Increase Throughput in Hybrid-ARQ</title><categories>cs.IT math.IT</categories><comments>30 pages</comments><doi>10.1109/TSP.2012.2213079</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hybrid-ARQ protocols have become common in many packet transmission systems
due to their incorporation in various standards. Hybrid-ARQ combines the normal
automatic repeat request (ARQ) method with error correction codes to increase
reliability and throughput. In this paper, we look at improving upon this
performance using feedback information from the receiver, in particular, using
a powerful forward error correction (FEC) code in conjunction with a proposed
linear feedback code for the Rayleigh block fading channels. The new hybrid-ARQ
scheme is initially developed for full received packet feedback in a
point-to-point link. It is then extended to various different multiple-antenna
scenarios (MISO/MIMO) with varying amounts of packet feedback information.
Simulations illustrate gains in throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2872</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2872</id><created>2011-04-14</created><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Gravin</keyname><forenames>Nick</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author></authors><title>Mechanism Design without Money via Stable Matching</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mechanism design without money has a rich history in social choice
literature. Due to the strong impossibility theorem by Gibbard and
Satterthwaite, exploring domains in which there exist dominant strategy
mechanisms is one of the central questions in the field. We propose a general
framework, called the generalized packing problem (\gpp), to study the
mechanism design questions without payment. The \gpp\ possesses a rich
structure and comprises a number of well-studied models as special cases,
including, e.g., matroid, matching, knapsack, independent set, and the
generalized assignment problem.
  We adopt the agenda of approximate mechanism design where the objective is to
design a truthful (or strategyproof) mechanism without money that can be
implemented in polynomial time and yields a good approximation to the socially
optimal solution. We study several special cases of \gpp, and give constant
approximation mechanisms for matroid, matching, knapsack, and the generalized
assignment problem. Our result for generalized assignment problem solves an
open problem proposed in \cite{DG10}.
  Our main technical contribution is in exploitation of the approaches from
stable matching, which is a fundamental solution concept in the context of
matching marketplaces, in application to mechanism design. Stable matching,
while conceptually simple, provides a set of powerful tools to manage and
analyze self-interested behaviors of participating agents. Our mechanism uses a
stable matching algorithm as a critical component and adopts other approaches
like random sampling and online mechanisms. Our work also enriches the stable
matching theory with a new knapsack constrained matching model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2882</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2882</id><created>2011-04-14</created><authors><author><keyname>Roditty</keyname><forenames>Liam</forenames></author><author><keyname>Williams</keyname><forenames>Virginia Vassilevska</forenames></author></authors><title>Minimum Weight Cycles and Triangles: Equivalences and Algorithms</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the fundamental algorithmic problem of finding a cycle of minimum
weight in a weighted graph. In particular, we show that the minimum weight
cycle problem in an undirected n-node graph with edge weights in {1,...,M} or
in a directed n-node graph with edge weights in {-M,..., M} and no negative
cycles can be efficiently reduced to finding a minimum weight triangle in an
Theta(n)-node undirected graph with weights in {1,...,O(M)}. Roughly speaking,
our reductions imply the following surprising phenomenon: a minimum cycle with
an arbitrary number of weighted edges can be &quot;encoded&quot; using only three edges
within roughly the same weight interval! This resolves a longstanding open
problem posed by Itai and Rodeh [SIAM J. Computing 1978 and STOC'77].
  A direct consequence of our efficient reductions are O (Mn^{omega})-time
algorithms using fast matrix multiplication (FMM) for finding a minimum weight
cycle in both undirected graphs with integral weights from the interval [1,M]
and directed graphs with integral weights from the interval [-M,M]. The latter
seems to reveal a strong separation between the all pairs shortest paths (APSP)
problem and the minimum weight cycle problem in directed graphs as the fastest
known APSP algorithm has a running time of O(M^{0.681}n^{2.575}) by Zwick [J.
ACM 2002].
  In contrast, when only combinatorial algorithms are allowed (that is, without
FMM) the only known solution to minimum weight cycle is by computing APSP.
Interestingly, any separation between the two problems in this case would be an
amazing breakthrough as by a recent paper by Vassilevska W. and Williams
[FOCS'10], any O(n^{3-eps})-time algorithm (eps&gt;0) for minimum weight cycle
immediately implies a O(n^{3-delta})-time algorithm (delta&gt;0) for APSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2909</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2909</id><created>2011-04-14</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author></authors><title>Energy and Mean-Payoff Parity Markov Decision Processes</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Markov Decision Processes (MDPs) with mean-payoff parity and
energy parity objectives. In system design, the parity objective is used to
encode \omega-regular specifications, and the mean-payoff and energy objectives
can be used to model quantitative resource constraints. The energy condition
requires that the resource level never drops below 0, and the mean-payoff
condition requires that the limit-average value of the resource consumption is
within a threshold. While these two (energy and mean-payoff) classical
conditions are equivalent for two-player games, we show that they differ for
MDPs. We show that the problem of deciding whether a state is almost-sure
winning (i.e., winning with probability 1) in energy parity MDPs is in NP \cap
coNP, while for mean-payoff parity MDPs, the problem is solvable in polynomial
time, improving a recent PSPACE bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2922</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2922</id><created>2011-04-14</created><authors><author><keyname>Newman</keyname><forenames>Alantha</forenames></author><author><keyname>Nikolov</keyname><forenames>Aleksandar</forenames></author></authors><title>A counterexample to Beck's conjecture on the discrepancy of three
  permutations</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given three permutations on the integers 1 through n, consider the set system
consisting of each interval in each of the three permutations. Jozsef Beck
conjectured (c. 1987) that the discrepancy of this set system is O(1). We give
a counterexample to this conjecture: for any positive integer n = 3^k, we
exhibit three permutations whose corresponding set system has discrepancy
Omega(log(n)). Our counterexample is based on a simple recursive construction,
and our proof of the discrepancy lower bound is by induction. This example also
disproves a generalization of Beck's conjecture due to Spencer, Srinivasan and
Tetali, who conjectured that a set system corresponding to l permutations has
discrepancy O(sqrt(l)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2925</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2925</id><created>2011-04-14</created><authors><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Albritton</keyname><forenames>Benjamin</forenames></author><author><keyname>Schwemmer</keyname><forenames>Rafael</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>SharedCanvas: A Collaborative Model for Medieval Manuscript Layout
  Dissemination</title><categories>cs.DL</categories><comments>10 pages; 10 figures; accepted to JCDL 2011</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we present a model based on the principles of Linked Data that
can be used to describe the interrelationships of images, texts and other
resources to facilitate the interoperability of repositories of medieval
manuscripts or other culturally important handwritten documents. The model is
designed from a set of requirements derived from the real world use cases of
some of the largest digitized medieval content holders, and instantiations of
the model are intended as the input to collection-independent page turning and
scholarly presentation interfaces. A canvas painting paradigm, such as in PDF
and SVG, was selected based on the lack of a one to one correlation between
image and page, and to fulfill complex requirements such as when the full text
of a page is known, but only fragments of the physical object remain. The model
is implemented using technologies such as OAI-ORE Aggregations and OAC
Annotations, as the fundamental building blocks of emerging Linked Digital
Libraries. The model and implementation are evaluated through prototypes of
both content providing and consuming applications. Although the system was
designed from requirements drawn from the medieval manuscript domain, it is
applicable to any layout-oriented presentation of images of text.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2930</identifier>
 <datestamp>2013-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2930</id><created>2011-04-14</created><updated>2013-05-23</updated><authors><author><keyname>Yan</keyname><forenames>Donghui</forenames></author><author><keyname>Chen</keyname><forenames>Aiyou</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>Cluster Forests</title><categories>stat.ME cs.LG stat.ML</categories><comments>23 pages, 6 figures</comments><report-no>COMSTA5571</report-no><journal-ref>Computational Statistics and Data Analysis 2013, Vol. 66, 178-192</journal-ref><doi>10.1016/j.csda.2013.04.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With inspiration from Random Forests (RF) in the context of classification, a
new clustering ensemble method---Cluster Forests (CF) is proposed.
Geometrically, CF randomly probes a high-dimensional data cloud to obtain &quot;good
local clusterings&quot; and then aggregates via spectral clustering to obtain
cluster assignments for the whole dataset. The search for good local
clusterings is guided by a cluster quality measure kappa. CF progressively
improves each local clustering in a fashion that resembles the tree growth in
RF. Empirical studies on several real-world datasets under two different
performance metrics show that CF compares favorably to its competitors.
Theoretical analysis reveals that the kappa measure makes it possible to grow
the local clustering in a desirable way---it is &quot;noise-resistant&quot;. A
closed-form expression is obtained for the mis-clustering rate of spectral
clustering under a perturbation model, which yields new insights into some
aspects of spectral clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2936</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2936</id><created>2011-04-14</created><authors><author><keyname>Goncharov</keyname><forenames>Sergey</forenames></author><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames></author></authors><title>A Coinductive Calculus for Asynchronous Side-effecting Processes</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an abstract framework for concurrent processes in which atomic
steps have generic side effects, handled according to the principle of monadic
encapsulation of effects. Processes in this framework are potentially infinite
resumptions, modelled using final coalgebras over the monadic base. As a
calculus for such processes, we introduce a concurrent extension of Moggi's
monadic metalanguage of effects. We establish soundness and completeness of a
natural equational axiomatisation of this calculus. Moreover, we identify a
corecursion scheme that is explicitly definable over the base language and
provides flexible expressive means for the definition of new operators on
processes, such as parallel composition. As a worked example, we prove the
safety of a generic mutual exclusion scheme using a verification logic built on
top of the equational calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2939</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2939</id><created>2011-04-14</created><authors><author><keyname>Kanoria</keyname><forenames>Yashodhan</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Subexponential convergence for information aggregation on regular trees</title><categories>cs.MA cs.IT math.IT math.ST stat.TH</categories><comments>8 pages, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the decentralized binary hypothesis testing problem on trees of
bounded degree and increasing depth. For a regular tree of depth t and
branching factor k&gt;=2, we assume that the leaves have access to independent and
identically distributed noisy observations of the 'state of the world' s.
Starting with the leaves, each node makes a decision in a finite alphabet M,
that it sends to its parent in the tree. Finally, the root decides between the
two possible states of the world based on the information it receives.
  We prove that the error probability vanishes only subexponentially in the
number of available observations, under quite general hypotheses. More
precisely the case of binary messages, decay is subexponential for any decision
rule. For general (finite) message alphabet M, decay is subexponential for
'node-oblivious' decision rules, that satisfy a mild irreducibility condition.
In the latter case, we propose a family of decision rules with close-to-optimal
asymptotic behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2941</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2941</id><created>2011-04-14</created><updated>2011-09-09</updated><authors><author><keyname>Rezaee</keyname><forenames>Arman</forenames></author><author><keyname>Zeger</keyname><forenames>Linda</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Speeding Multicast by Acknowledgment Reduction Technique (SMART)</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel feedback protocol for wireless broadcast networks that
utilize linear network coding. We consider transmission of packets from one
source to many receivers over a single-hop broadcast erasure channel. Our
method utilizes a predictive model to request feedback only when the
probability that all receivers have completed decoding is significant. In
addition, our proposed NACK-based feedback mechanism enables all receivers to
request, within a single time slot, the number of retransmissions needed for
successful decoding. We present simulation results as well as analytical
results that show the favorable scalability of our technique as the number of
receivers, file size, and packet erasure probability increase. We also show the
robustness of this scheme to uncertainty in the predictive model, including
uncertainty in the number of receiving nodes and the packet erasure
probability, as well as to losses of the feedback itself. Our scheme, SMART, is
shown to perform nearly as well as an omniscient transmitter that requires no
feedback. Furthermore, SMART, is shown to outperform current state of the art
methods at any given erasure probability, file size, and numbers of receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2944</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2944</id><created>2011-04-14</created><authors><author><keyname>Censor-Hillel</keyname><forenames>Keren</forenames></author><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Kelner</keyname><forenames>Jonathan A.</forenames></author><author><keyname>Maymounkov</keyname><forenames>Petar</forenames></author></authors><title>Global Computation in a Poorly Connected World: Fast Rumor Spreading
  with No Dependence on Conductance</title><categories>cs.DM cs.DC cs.SI physics.soc-ph</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the question of how efficiently a collection of
interconnected nodes can perform a global computation in the widely studied
GOSSIP model of communication. In this model, nodes do not know the global
topology of the network, and they may only initiate contact with a single
neighbor in each round. This model contrasts with the much less restrictive
LOCAL model, where a node may simultaneously communicate with all of its
neighbors in a single round. A basic question in this setting is how many
rounds of communication are required for the information dissemination problem,
in which each node has some piece of information and is required to collect all
others. In this paper, we give an algorithm that solves the information
dissemination problem in at most $O(D+\text{polylog}{(n)})$ rounds in a network
of diameter $D$, withno dependence on the conductance. This is at most an
additive polylogarithmic factor from the trivial lower bound of $D$, which
applies even in the LOCAL model. In fact, we prove that something stronger is
true: any algorithm that requires $T$ rounds in the LOCAL model can be
simulated in $O(T +\mathrm{polylog}(n))$ rounds in the GOSSIP model. We thus
prove that these two models of distributed computation are essentially
equivalent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2964</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2964</id><created>2011-04-14</created><authors><author><keyname>Bhalgat</keyname><forenames>Anand</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Social Welfare in One-sided Matching Markets without Money</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study social welfare in one-sided matching markets where the goal is to
efficiently allocate n items to n agents that each have a complete, private
preference list and a unit demand over the items. Our focus is on allocation
mechanisms that do not involve any monetary payments. We consider two natural
measures of social welfare: the ordinal welfare factor which measures the
number of agents that are at least as happy as in some unknown, arbitrary
benchmark allocation, and the linear welfare factor which assumes an agent's
utility linearly decreases down his preference lists, and measures the total
utility to that achieved by an optimal allocation. We analyze two matching
mechanisms which have been extensively studied by economists. The first
mechanism is the random serial dictatorship (RSD) where agents are ordered in
accordance with a randomly chosen permutation, and are successively allocated
their best choice among the unallocated items. The second mechanism is the
probabilistic serial (PS) mechanism of Bogomolnaia and Moulin [8], which
computes a fractional allocation that can be expressed as a convex combination
of integral allocations. The welfare factor of a mechanism is the infimum over
all instances. For RSD, we show that the ordinal welfare factor is
asymptotically 1/2, while the linear welfare factor lies in the interval [.526,
2/3]. For PS, we show that the ordinal welfare factor is also 1/2 while the
linear welfare factor is roughly 2/3. To our knowledge, these results are the
first non-trivial performance guarantees for these natural mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2970</identifier>
 <datestamp>2012-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2970</id><created>2011-04-15</created><updated>2012-02-19</updated><authors><author><keyname>Gao</keyname><forenames>David Y.</forenames></author><author><keyname>Wu</keyname><forenames>Changzhi</forenames></author></authors><title>On the Triality Theory in Global Optimization</title><categories>math.OC cs.CC math.AC</categories><comments>In this revised version, a new section 6 is added to response one of
  reviewers' comment on the difference between the canonical duality theory and
  the classical Lagrangian duality theory. An application to quartic
  polynomials was given in arXiv:1110.0293v1</comments><msc-class>90</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Triality theory is proved for a general unconstrained global optimization
problem. The method adopted is simple but mathematically rigorous. Results show
that if the primal problem and its canonical dual have the same dimension, the
triality theory holds strongly in the tri-duality form as it was originally
proposed. Otherwise, both the canonical min-max duality and the double-max
duality still hold strongly, but the double-min duality holds weakly in a
super-symmetrical form as it was expected. Additionally, a complementary weak
saddle min-max duality theorem is discovered. Therefore, an open problem on
this statement left in 2003 is solved completely. This theory can be used to
identify not only the global minimum, but also the largest local minimum,
maximum, and saddle points. Application is illustrated. Some fundamental
concepts in optimization and remaining challenging problems in canonical
duality theory are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2982</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2982</id><created>2011-04-15</created><authors><author><keyname>Arnoux</keyname><forenames>Mireille</forenames><affiliation>LIMI</affiliation></author><author><keyname>Despeyroux</keyname><forenames>Thierry</forenames><affiliation>INRIA Rocquencourt / INRIA Sophia Antipolis</affiliation></author></authors><title>Multi-representation d'une ontologie : OWL, bases de donnees, syst\`emes
  de types et d'objets</title><categories>cs.IR</categories><comments>ISBN: 978-1-60558-842-1</comments><proxy>ccsd</proxy><journal-ref>Journ\'ees Francophones sur les Ontologies (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the emergence of the semantic Web and the increasing need to formalize
human knowledge, ontologie engineering is now an important activity. But is
this activity very different from other ones like software engineering, for
example ? In this paper, we investigate analogies between ontologies on one
hand, types, objects and data bases on the other one, taking into account the
notion of evolution of an ontology. We represent a unique ontology using
different paradigms, and observe that the distance between these different
concepts is small. We deduce from this constatation that ontologies and more
specifically ontology description languages can take advantage of beeing
fertilizated with some other computer science domains and inherit important
characteristics as modularity, for example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.2998</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.2998</id><created>2011-04-15</created><authors><author><keyname>Lazzari</keyname><forenames>Barbara</forenames></author><author><keyname>Nibbi</keyname><forenames>Roberta</forenames></author></authors><title>On the exponential decay of the Euler-Bernoulli beam with boundary
  energy dissipation</title><categories>math-ph cs.SY math.MP math.OC</categories><comments>13 pages</comments><msc-class>74K10, 74H40, 93D15, 35B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymptotic behavior of the Euler-Bernoulli beam which is clamped
at one end and free at the other end. We apply a boundary control with memory
at the free end of the beam and prove that the &quot;exponential decay&quot; of the
memory kernel is a necessary and sufficient condition for the exponential decay
of the energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3007</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3007</id><created>2011-04-15</created><authors><author><keyname>Maletti</keyname><forenames>Andreas</forenames></author><author><keyname>Quernheim</keyname><forenames>Daniel</forenames></author></authors><title>Optimal Hyper-Minimization</title><categories>cs.FL</categories><comments>15 pages, 5 figures</comments><doi>10.1007/978-3-642-18098-9_22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimal deterministic finite automata (DFAs) can be reduced further at the
expense of a finite number of errors. Recently, such minimization algorithms
have been improved to run in time O(n log n), where n is the number of states
of the input DFA, by [Gawrychowski and Je\.z: Hyper-minimisation made
efficient. Proc. MFCS, LNCS 5734, 2009] and [Holzer and Maletti: An n log n
algorithm for hyper-minimizing a (minimized) deterministic automaton. Theor.
Comput. Sci. 411, 2010]. Both algorithms return a DFA that is as small as
possible, while only committing a finite number of errors. These algorithms are
further improved to return a DFA that commits the least number of errors at the
expense of an increased (quadratic) run-time. This solves an open problem of
[Badr, Geffert, and Shipman: Hyper-minimizing minimized deterministic finite
state automata. RAIRO Theor. Inf. Appl. 43, 2009]. In addition, an experimental
study on random automata is performed and the effects of the existing
algorithms and the new algorithm are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3025</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3025</id><created>2011-04-15</created><authors><author><keyname>Husain</keyname><forenames>Mohammad Iftekhar</forenames></author><author><keyname>Ko</keyname><forenames>Steve</forenames></author><author><keyname>Rudra</keyname><forenames>Atri</forenames></author><author><keyname>Uurtamo</keyname><forenames>Steve</forenames></author></authors><title>Storage Enforcement with Kolmogorov Complexity and List Decoding</title><categories>cs.CC</categories><acm-class>F.2; E.4; H.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following problem that arises in outsourced storage: a user
stores her data $x$ on a remote server but wants to audit the server at some
later point to make sure it actually did store $x$. The goal is to design a
(randomized) verification protocol that has the property that if the server
passes the verification with some reasonably high probability then the user can
rest assured that the server is storing $x$.
  In this work we present an optimal solution (in terms of the user's storage
and communication) while at the same time ensuring that a server that passes
the verification protocol with any reasonable probability will store, to within
a small \textit{additive} factor, $C(x)$ bits of information, where $C(x)$ is
the plain Kolmogorov complexity of $x$. (Since we cannot prevent the server
from compressing $x$, $C(x)$ is a natural upper bound.) The proof of security
of our protocol combines Kolmogorov complexity with list decoding and unlike
previous work that relies upon cryptographic assumptions, we allow the server
to have unlimited computational power. To the best of our knowledge, this is
the first work that combines Kolmogorov complexity and list decoding.
  Our framework is general enough to capture extensions where the user splits
up $x$ and stores the fragment across multiple servers and our verification
protocol can handle non-responsive servers and colluding servers. As a
by-product, we also get a proof of retrievability. Finally, our results also
have an application in `storage enforcement' schemes, which in turn have an
application in trying to update a remote server that is potentially infected
with a virus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3045</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3045</id><created>2011-04-15</created><authors><author><keyname>Collette</keyname><forenames>Sebastien</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author></authors><title>Confluent Persistence Revisited</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown how to enhance any data structure in the pointer model to make it
confluently persistent, with efficient query and update times and limited space
overhead. Updates are performed in $O(\log n)$ amortized time, and following a
pointer takes $O(\log c \log n)$ time where $c$ is the in-degree of a node in
the data structure. In particular, this proves that confluent persistence can
be achieved at a logarithmic cost in the bounded in-degree model used widely in
previous work. This is a $O(n/\log n)$-factor improvement over the previous
known transform to make a data structure confluently persistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3049</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3049</id><created>2011-04-15</created><authors><author><keyname>W&#xe4;stlund</keyname><forenames>Johan</forenames></author></authors><title>When only the last one will do</title><categories>cs.GT math.PR</categories><comments>24 pages</comments><msc-class>60G40, 62L15, 91A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An unknown positive number of items arrive at independent uniformly
distributed times in the interval [0,1] to a selector, whose task is to pick
online the last one. We show that under the assumption of an adversary
determining the number of items, there exists a game-theoretical equilibrium,
in other words the selector and the adversary both possess optimal strategies.
The probability of success of the selector with the optimal strategy is
estimated numerically to 0.352917000207196.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3054</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3054</id><created>2011-04-14</created><authors><author><keyname>Fijalkow</keyname><forenames>Nathana&#xeb;l</forenames><affiliation>ENS Cachan, LIAFA</affiliation></author><author><keyname>Gimbert</keyname><forenames>Hugo</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Oualhadj</keyname><forenames>Youssouf</forenames><affiliation>LaBRI</affiliation></author></authors><title>Pushing undecidability of the isolation problem for probabilistic
  automata</title><categories>cs.FL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note aims at proving that the isolation problem is undecidable for
probabilistic automata with only one probabilistic transition. This problem is
known to be undecidable for general probabilistic automata, without restriction
on the number of probabilistic transitions. In this note, we develop a
simulation technique that allows to simulate any probabilistic automaton with
one having only one probabilistic transition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3055</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3055</id><created>2011-04-14</created><updated>2012-01-26</updated><authors><author><keyname>Fijalkow</keyname><forenames>Nathana&#xeb;l</forenames><affiliation>ENS Cachan, LIAFA</affiliation></author><author><keyname>Gimbert</keyname><forenames>Hugo</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Oualhadj</keyname><forenames>Youssouf</forenames><affiliation>LaBRI</affiliation></author></authors><title>Deciding the Value 1 Problem of Probabilistic Leaktight Automata</title><categories>cs.FL cs.GT</categories><comments>arXiv admin note: significant text overlap with arXiv:1104.3054</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The value 1 problem is a decision problem for probabilistic automata over
finite words: given a probabilistic automaton A, are there words accepted by A
with probability arbitrarily close to 1? This problem was proved undecidable
recently. We sharpen this result, showing that the undecidability result holds
even if the probabilistic automata have only one probabilistic transition. Our
main contribution is to introduce a new class of probabilistic automata, called
leaktight automata, for which the value 1 problem is shown decidable (and
PSPACE-complete). We construct an algorithm based on the computation of a
monoid abstracting the behaviours of the automaton, and rely on algebraic
techniques developed by Simon for the correctness proof. The class of leaktight
automata is decidable in PSPACE, subsumes all subclasses of probabilistic
automata whose value 1 problem is known to be decidable (in particular
deterministic automata), and is closed under two natural composition operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3056</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3056</id><created>2011-04-15</created><authors><author><keyname>King</keyname><forenames>Ross D.</forenames></author></authors><title>Numbers as Data Structures: The Prime Successor Function as Primitive</title><categories>cs.CC</categories><comments>10 pages, 1 figure</comments><msc-class>11Y05 68Q17 05A17</msc-class><acm-class>F.2.1</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The symbolic representation of a number should be considered as a data
structure, and the choice of data structure depends on the arithmetic
operations that are to be performed. Numbers are almost universally represented
using position based notations based on exponential powers of a base number -
usually 10. This representations is computationally efficient for the standard
arithmetic operations, but it is not efficient for factorisation. This has led
to a common confusion that factorisation is inherently computationally hard. We
propose a new representation of the natural numbers based on bags and using the
prime successor function as a primitive - prime bags (PBs). This data structure
is more efficient for most arithmetic operations, and enables numbers can be
efficiently factored. However, it also has the interesting feature that
addition appears to be computationally hard. PBs have an interesting
alternative interpretation as partitions of numbers represented in the standard
way, and this reveals a novel relationship between prime numbers and the
partition function. The PB representation can be extended to rational and
irrational numbers, and this provides the most direct proof of the
irrationality of the square root of 2. I argue that what needs to be ultimately
understood is not the peculiar computation complexity properties of the decimal
system (e.g. factorisation), but rather what arithmetical operator trade-offs
are generally possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3057</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3057</id><created>2011-04-15</created><authors><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Problems parameterized by treewidth tractable in single exponential
  time: a logical approach</title><categories>cs.DS cs.LO</categories><comments>26 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a variant of modal logic, dubbed EXISTENTIAL COUNTING MODAL
LOGIC (ECML), which captures a vast majority of problems known to be tractable
in single exponential time when parameterized by treewidth. It appears that all
these results can be subsumed by the theorem that model checking of ECML admits
an algorithm with such complexity. We extend ECML by adding connectivity
requirements and, using the Cut&amp;Count technique introduced by Cygan et al. [4],
prove that problems expressible in the extension are also tractable in single
exponential time when parameterized by treewidth; however, using randomization.
The need for navigationality of the introduced logic is justified by a negative
result that two expository problems involving non-acyclic conditions, C_l
VERTEX DELETION and GIRTH&gt;l VERTEX DELETION for l&gt;=5, do not admit such a
robust algorithm unless Exponential Time Hypothesis fails.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3069</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3069</id><created>2011-04-15</created><authors><author><keyname>Selva</keyname><forenames>J.</forenames></author></authors><title>Efficient Maximum Likelihood Estimation of a 2-D Complex Sinusoidal
  Based on Barycentric Interpolation</title><categories>cs.IT math.IT</categories><comments>To appear in the International Conference on Acoustic, Speech, and
  Signal Processing, ICASSP-2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient method to compute the maximum likelihood
(ML) estimation of the parameters of a complex 2-D sinusoidal, with the
complexity order of the FFT. The method is based on an accurate barycentric
formula for interpolating band-limited signals, and on the fact that the ML
cost function can be viewed as a signal of this type, if the time and frequency
variables are switched. The method consists in first computing the DFT of the
data samples, and then locating the maximum of the cost function by means of
Newton's algorithm. The fact is that the complexity of the latter step is small
and independent of the data size, since it makes use of the barycentric formula
for obtaining the values of the cost function and its derivatives. Thus, the
total complexity order is that of the FFT. The method is validated in a
numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3076</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3076</id><created>2011-04-15</created><authors><author><keyname>De</keyname><forenames>Minati</forenames></author><author><keyname>Nandy</keyname><forenames>Subhas C.</forenames></author></authors><title>Inplace Algorithm for Priority Search Tree and its use in Computing
  Largest Empty Axis-Parallel Rectangle</title><categories>cs.CG</categories><comments>14 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a high demand of space-efficient algorithms in built-in or embedded
softwares. In this paper, we consider the problem of designing space-efficient
algorithms for computing the maximum area empty rectangle (MER) among a set of
points inside a rectangular region $\cal R$ in 2D. We first propose an inplace
algorithm for computing the priority search tree with a set of $n$ points in
$\cal R$ using $O(\log n)$ extra bit space in $O(n\log n)$ time. It supports
all the standard queries on priority search tree in $O(\log^2n)$ time. We also
show an application of this algorithm in computing the largest empty
axis-parallel rectangle. Our proposed algorithm needs $O(n\log^2n +m)$ time and
$O(\log n)$ work-space apart from the array used for storing $n$ input points.
Here $m$ is the number of maximal empty rectangles present in $\cal R$.
Finally, we consider the problem of locating the maximum area empty rectangle
of arbitrary orientation among a set of $n$ points, and propose an $O(n^3\log
n)$ time in-place algorithm for that problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3083</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3083</id><created>2011-04-15</created><updated>2011-08-01</updated><authors><author><keyname>Traag</keyname><forenames>V. A.</forenames></author><author><keyname>Van Dooren</keyname><forenames>P.</forenames></author><author><keyname>Nesterov</keyname><forenames>Y.</forenames></author></authors><title>Narrow scope for resolution-limit-free community detection</title><categories>physics.soc-ph cs.SI</categories><acm-class>G.2.2</acm-class><journal-ref>Phys. Rev. E 84, 016114 (2011)</journal-ref><doi>10.1103/PhysRevE.84.016114</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting communities in large networks has drawn much attention over the
years. While modularity remains one of the more popular methods of community
detection, the so-called resolution limit remains a significant drawback. To
overcome this issue, it was recently suggested that instead of comparing the
network to a random null model, as is done in modularity, it should be compared
to a constant factor. However, it is unclear what is meant exactly by
&quot;resolution-limit-free&quot;, that is, not suffering from the resolution limit.
Furthermore, the question remains what other methods could be classified as
resolution-limit-free. In this paper we suggest a rigorous definition and
derive some basic properties of resolution-limit-free methods. More
importantly, we are able to prove exactly which class of community detection
methods are resolution-limit-free. Furthermore, we analyze which methods are
not resolution-limit-free, suggesting there is only a limited scope for
resolution-limit-free community detection methods. Finally, we provide such a
natural formulation, and show it performs superbly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3084</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3084</id><created>2011-04-15</created><authors><author><keyname>Larsen</keyname><forenames>Kasper Green</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>I/O-Efficient Data Structures for Colored Range and Prefix Reporting</title><categories>cs.DS cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by information retrieval applications, we consider the
one-dimensional colored range reporting problem in rank space. The goal is to
build a static data structure for sets C_1,...,C_m \subseteq {1,...,sigma} that
supports queries of the kind: Given indices a,b, report the set Union_{a &lt;= i
&lt;= b} C_i.
  We study the problem in the I/O model, and show that there exists an optimal
linear-space data structure that answers queries in O(1+k/B) I/Os, where k
denotes the output size and B the disk block size in words. In fact, we obtain
the same bound for the harder problem of three-sided orthogonal range
reporting. In this problem, we are to preprocess a set of n two-dimensional
points in rank space, such that all points inside a query rectangle of the form
[x_1,x_2] x (-infinity,y] can be reported. The best previous bounds for this
problem is either O(n lg^2_B n) space and O(1+k/B) query I/Os, or O(n) space
and O(lg^(h)_B n +k/B) query I/Os, where lg^(h)_B n is the base B logarithm
iterated h times, for any constant integer h. The previous bounds are both
achieved under the indivisibility assumption, while our solution exploits the
full capabilities of the underlying machine. Breaking the indivisibility
assumption thus provides us with cleaner and optimal bounds.
  Our results also imply an optimal solution to the following colored prefix
reporting problem. Given a set S of strings, each O(1) disk blocks in length,
and a function c: S -&gt; 2^{1,...,sigma}, support queries of the kind: Given a
string p, report the set Union_{x in S intersection p*} c(x), where p* denotes
the set of strings with prefix p. Finally, we consider the possibility of top-k
extensions of this result, and present a simple solution in a model that allows
non-blocked I/O.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3090</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3090</id><created>2011-04-15</created><authors><author><keyname>M&#xf6;mke</keyname><forenames>Tobias</forenames></author><author><keyname>Svensson</keyname><forenames>Ola</forenames></author></authors><title>Approximating Graphic TSP by Matchings</title><categories>cs.DS</categories><comments>20 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework for approximating the metric TSP based on a novel use
of matchings. Traditionally, matchings have been used to add edges in order to
make a given graph Eulerian, whereas our approach also allows for the removal
of certain edges leading to a decreased cost.
  For the TSP on graphic metrics (graph-TSP), the approach yields a
1.461-approximation algorithm with respect to the Held-Karp lower bound. For
graph-TSP restricted to a class of graphs that contains degree three bounded
and claw-free graphs, we show that the integrality gap of the Held-Karp
relaxation matches the conjectured ratio 4/3. The framework allows for
generalizations in a natural way and also leads to a 1.586-approximation
algorithm for the traveling salesman path problem on graphic metrics where the
start and end vertices are prespecified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3098</identifier>
 <datestamp>2012-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3098</id><created>2011-04-15</created><updated>2012-07-18</updated><authors><author><keyname>Capraro</keyname><forenames>Valerio</forenames></author><author><keyname>Morrison</keyname><forenames>Kent</forenames></author></authors><title>Optimal strategies for a game on amenable semigroups</title><categories>cs.GT math.GR math.PR</categories><comments>17 pages. To appear in International Journal of Game Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The semigroup game is a two-person zero-sum game defined on a semigroup S as
follows: Players 1 and 2 choose elements x and y in S, respectively, and player
1 receives a payoff f(xy) defined by a function f from S to [-1,1]. If the
semigroup is amenable in the sense of Day and von Neumann, one can extend the
set of classical strategies, namely countably additive probability measures on
S, to include some finitely additive measures in a natural way. This extended
game has a value and the players have optimal strategies. This theorem extends
previous results for the multiplication game on a compact group or on the
positive integers with a specific payoff. We also prove that the procedure of
extending the set of allowed strategies preserves classical solutions: if a
semigroup game has a classical solution, this solution solves also the extended
game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3100</identifier>
 <datestamp>2011-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3100</id><created>2011-04-15</created><authors><author><keyname>Kiefer</keyname><forenames>Stefan</forenames></author><author><keyname>Murawski</keyname><forenames>Andrzej</forenames></author><author><keyname>Ouaknine</keyname><forenames>Jo&#xeb;l</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author><author><keyname>Zhang</keyname><forenames>Lijun</forenames></author></authors><title>On Stabilization in Herman's Algorithm</title><categories>cs.DS</categories><comments>Technical report accompanying an ICALP'11 paper with the same title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Herman's algorithm is a synchronous randomized protocol for achieving
self-stabilization in a token ring consisting of N processes. The interaction
of tokens makes the dynamics of the protocol very difficult to analyze. In this
paper we study the expected time to stabilization in terms of the initial
configuration. It is straightforward that the algorithm achieves stabilization
almost surely from any initial configuration, and it is known that the
worst-case expected time to stabilization (with respect to the initial
configuration) is Theta(N^2). Our first contribution is to give an upper bound
of 0.64 N^2 on the expected stabilization time, improving on previous upper
bounds and reducing the gap with the best existing lower bound. We also
introduce an asynchronous version of the protocol, showing a similar O(N^2)
convergence bound in this case. Assuming that errors arise from the corruption
of some number k of bits, where k is fixed independently of the size of the
ring, we show that the expected time to stabilization is O(N). This reveals a
hitherto unknown and highly desirable property of Herman's algorithm: it
recovers quickly from bounded errors. We also show that if the initial
configuration arises by resetting each bit independently and uniformly at
random, then stabilization is significantly faster than in the worst case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3103</identifier>
 <datestamp>2011-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3103</id><created>2011-04-15</created><authors><author><keyname>Vorobeychik</keyname><forenames>Yevgeniy</forenames></author><author><keyname>Mayo</keyname><forenames>Jackson</forenames></author><author><keyname>Armstrong</keyname><forenames>Robert</forenames></author><author><keyname>Ruthruff</keyname><forenames>Joseph</forenames></author></authors><title>Noncooperatively Optimized Tolerance: Decentralized Strategic
  Optimization in Complex Systems</title><categories>cs.GT physics.soc-ph</categories><journal-ref>Physical Review Letters, 107:108702, 2011</journal-ref><doi>10.1103/PhysRevLett.107.108702</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We introduce noncooperatively optimized tolerance (NOT), a generalization of
highly optimized tolerance (HOT) that involves strategic (game theoretic)
interactions between parties in a complex system. We illustrate our model in
the forest fire (percolation) framework. As the number of players increases,
our model retains features of HOT, such as robustness, high yield combined with
high density, and self-dissimilar landscapes, but also develops features of
self-organized criticality (SOC) when the number of players is large enough.
For example, the forest landscape becomes increasingly homogeneous and
protection from adverse events (lightning strikes) becomes less closely
correlated with the spatial distribution of these events. While HOT is a
special case of our model, the resemblance to SOC is only partial; for example,
the distribution of cascades, while becoming increasingly heavy-tailed as the
number of players increases, also deviates more significantly from a power law
in this regime. Surprisingly, the system retains considerable robustness even
as it becomes fractured, due in part to emergent cooperation between
neighboring players. At the same time, increasing homogeneity promotes
resilience against changes in the lightning distribution, giving rise to
intermediate regimes where the system is robust to a particular distribution of
adverse events, yet not very fragile to changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3116</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3116</id><created>2011-04-15</created><updated>2013-08-12</updated><authors><author><keyname>Gottlieb</keyname><forenames>Eli</forenames></author></authors><title>Simple, Decidable Type Inference with Subtyping</title><categories>cs.PL</categories><comments>This paper has been withdrawn, due to abundant errors in this version
  of the paper, and due to ongoing efforts to improve the paper and bring it to
  real publication</comments><acm-class>D.3.1; D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate a method to infer polymorphically principal and
subtyping-minimal types for an ML-like core language by assigning ranges within
a lattice to type variables. We demonstrate the termination and completeness of
this algorithm, and proceed to show that it solves a broad special-case of the
generally-undecidable semi-unification problem. Our procedure requires no type
annotations, leaves no subtyping constraints in the inferred types, and
produces no proof obligations. We demonstrate the practical utility of our
technique by showing a type-preserving encoding of Featherweight Java into the
expression calculus over which we infer types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3117</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3117</id><created>2011-04-15</created><updated>2011-04-18</updated><authors><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Estimating the State of AC Power Systems using Semidefinite Programming</title><categories>cs.SY math.OC</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3119</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3119</id><created>2011-04-15</created><updated>2011-05-14</updated><authors><author><keyname>Laarman</keyname><forenames>Alfons</forenames></author><author><keyname>van de Pol</keyname><forenames>Jaco</forenames></author><author><keyname>Weber</keyname><forenames>Michael</forenames></author></authors><title>Parallel Recursive State Compression for Free</title><categories>cs.DS</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on reducing memory usage in enumerative model checking,
while maintaining the multi-core scalability obtained in earlier work. We
present a tree-based multi-core compression method, which works by leveraging
sharing among sub-vectors of state vectors.
  An algorithmic analysis of both worst-case and optimal compression ratios
shows the potential to compress even large states to a small constant on
average (8 bytes). Our experiments demonstrate that this holds up in practice:
the median compression ratio of 279 measured experiments is within 17% of the
optimum for tree compression, and five times better than the median compression
ratio of SPIN's COLLAPSE compression.
  Our algorithms are implemented in the LTSmin tool, and our experiments show
that for model checking, multi-core tree compression pays its own way: it comes
virtually without overhead compared to the fastest hash table-based methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3128</identifier>
 <datestamp>2012-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3128</id><created>2011-04-15</created><updated>2012-08-29</updated><authors><author><keyname>Ahmadian</keyname><forenames>Sara</forenames></author><author><keyname>Swamy</keyname><forenames>Chaitanya</forenames></author></authors><title>Improved Approximation Guarantees for Lower-Bounded Facility Location</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the {\em lower-bounded facility location} (\lbfl) problem (also
sometimes called {\em load-balanced facility location}), which is a
generalization of {\em uncapacitated facility location} (\ufl), where each open
facility is required to serve a certain {\em minimum} amount of demand. More
formally, an instance $\I$ of \lbfl is specified by a set $\F$ of facilities
with facility-opening costs $\{f_i\}$, a set $\D$ of clients, and connection
costs $\{c_{ij}\}$ specifying the cost of assigning a client $j$ to a facility
$i$, where the $c_{ij}$s form a metric. A feasible solution specifies a subset
$F$ of facilities to open, and assigns each client $j$ to an open facility
$i(j)\in F$ so that each open facility serves {\em at least $M$ clients}, where
$M$ is an input parameter. The cost of such a solution is $\sum_{i\in
F}f_i+\sum_j c_{i(j)j}$, and the goal is to find a feasible solution of minimum
cost. The current best approximation ratio for \lbfl is 448 \cite{Svitkina08}.
We substantially advance the state-of-the-art for \lbfl by devising an
approximation algorithm for \lbfl that achieves a significantly-improved
approximation guarantee of 82.6. Our improvement comes from a variety of ideas
in algorithm design and analysis, which also yield new insights into \lbfl.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3131</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3131</id><created>2011-04-15</created><updated>2011-08-13</updated><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Krstic</keyname><forenames>Miroslav</forenames></author></authors><title>Global stabilization of feedforward systems under perturbations in
  sampling schedule</title><categories>math.OC cs.SY</categories><comments>27 pages, 5 figures, submitted for possible publication to SIAM
  Journal Control and Optimization. Second version with added remarks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For nonlinear systems that are known to be globally asymptotically
stabilizable, control over networks introduces a major challenge because of the
asynchrony in the transmission schedule. Maintaining global asymptotic
stabilization in sampled-data implementations with zero-order hold and with
perturbations in the sampling schedule is not achievable in general but we show
in this paper that it is achievable for the class of feedforward systems. We
develop sampled-data feedback stabilizers which are not approximations of
continuous-time designs but are discontinuous feedback laws that are
specifically developed for maintaining global asymptotic stabilizability under
any sequence of sampling periods that is uniformly bounded by a certain
&quot;maximum allowable sampling period&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3148</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3148</id><created>2011-04-15</created><authors><author><keyname>Kontinen</keyname><forenames>Juha</forenames></author><author><keyname>Kuusisto</keyname><forenames>Antti</forenames></author><author><keyname>Lohmann</keyname><forenames>Peter</forenames></author><author><keyname>Virtema</keyname><forenames>Jonni</forenames></author></authors><title>Complexity of two-variable Dependence Logic and IF-Logic</title><categories>cs.LO cs.CC</categories><comments>27 pages, extended version of LICS 2011 paper</comments><acm-class>F.4.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the two-variable fragments D^2 and IF^2 of dependence logic and
independence-friendly logic. We consider the satisfiability and finite
satisfiability problems of these logics and show that for D^2, both problems
are NEXPTIME-complete, whereas for IF^2, the problems are undecidable. We also
show that D^2 is strictly less expressive than IF^2 and that already in D^2,
equicardinality of two unary predicates and infinity can be expressed (the
latter in the presence of a constant symbol). This is an extended version of a
publication in the proceedings of the 26th Annual IEEE Symposium on Logic in
Computer Science (LICS 2011).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3152</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3152</id><created>2011-04-15</created><authors><author><keyname>Marriott</keyname><forenames>Chris</forenames></author><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author></authors><title>Polyethism in a colony of artificial ants</title><categories>cs.AI nlin.AO q-bio.PE</categories><comments>8 pages, 4 figures, submitted to ECAL 11</comments><report-no>C3 Report 2011.03</report-no><journal-ref>Advances in Artificial Life, ECAL 2011: Proceedings of the
  Eleventh European Conference on the Synthesis and Simulation of Living
  Systems, pp. 498-505, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore self-organizing strategies for role assignment in a foraging task
carried out by a colony of artificial agents. Our strategies are inspired by
various mechanisms of division of labor (polyethism) observed in eusocial
insects like ants, termites, or bees. Specifically we instantiate models of
caste polyethism and age or temporal polyethism to evaluated the benefits to
foraging in a dynamic environment. Our experiment is directly related to the
exploration/exploitation trade of in machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3153</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3153</id><created>2011-04-15</created><authors><author><keyname>Christou</keyname><forenames>Michalis</forenames></author><author><keyname>Crochemore</keyname><forenames>Maxime</forenames></author><author><keyname>Iliopoulos</keyname><forenames>Costas S.</forenames></author><author><keyname>Kubica</keyname><forenames>Marcin</forenames></author><author><keyname>Pissis</keyname><forenames>Solon P.</forenames></author><author><keyname>Radoszewski</keyname><forenames>Jakub</forenames></author><author><keyname>Rytter</keyname><forenames>Wojciech</forenames></author><author><keyname>Szreder</keyname><forenames>Bartosz</forenames></author><author><keyname>Walen</keyname><forenames>Tomasz</forenames></author></authors><title>Efficient Seeds Computation Revisited</title><categories>cs.DS</categories><comments>14 pages, accepted to CPM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of the cover is a generalization of a period of a string, and
there are linear time algorithms for finding the shortest cover. The seed is a
more complicated generalization of periodicity, it is a cover of a superstring
of a given string, and the shortest seed problem is of much higher algorithmic
difficulty. The problem is not well understood, no linear time algorithm is
known. In the paper we give linear time algorithms for some of its versions ---
computing shortest left-seed array, longest left-seed array and checking for
seeds of a given length. The algorithm for the last problem is used to compute
the seed array of a string (i.e., the shortest seeds for all the prefixes of
the string) in $O(n^2)$ time. We describe also a simpler alternative algorithm
computing efficiently the shortest seeds. As a by-product we obtain an
$O(n\log{(n/m)})$ time algorithm checking if the shortest seed has length at
least $m$ and finding the corresponding seed. We also correct some important
details missing in the previously known shortest-seed algorithm (Iliopoulos et
al., 1996).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3160</identifier>
 <datestamp>2015-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3160</id><created>2011-04-15</created><updated>2015-11-03</updated><authors><author><keyname>Jacques</keyname><forenames>Laurent</forenames></author><author><keyname>Laska</keyname><forenames>Jason N.</forenames></author><author><keyname>Boufounos</keyname><forenames>Petros T.</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Robust 1-Bit Compressive Sensing via Binary Stable Embeddings of Sparse
  Vectors</title><categories>cs.IT math.IT</categories><comments>40 pages, 17 figures. This last minor revision corrects a few typos
  in Appendix G</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Compressive Sensing (CS) framework aims to ease the burden on
analog-to-digital converters (ADCs) by reducing the sampling rate required to
acquire and stably recover sparse signals. Practical ADCs not only sample but
also quantize each measurement to a finite number of bits; moreover, there is
an inverse relationship between the achievable sampling rate and the bit depth.
In this paper, we investigate an alternative CS approach that shifts the
emphasis from the sampling rate to the number of bits per measurement. In
particular, we explore the extreme case of 1-bit CS measurements, which capture
just their sign. Our results come in two flavors. First, we consider ideal
reconstruction from noiseless 1-bit measurements and provide a lower bound on
the best achievable reconstruction error. We also demonstrate that i.i.d.
random Gaussian matrices describe measurement mappings achieving, with
overwhelming probability, nearly optimal error decay. Next, we consider
reconstruction robustness to measurement errors and noise and introduce the
Binary $\epsilon$-Stable Embedding (B$\epsilon$SE) property, which
characterizes the robustness measurement process to sign changes. We show the
same class of matrices that provide almost optimal noiseless performance also
enable such a robust mapping. On the practical side, we introduce the Binary
Iterative Hard Thresholding (BIHT) algorithm for signal reconstruction from
1-bit measurements that offers state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3161</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3161</id><created>2011-04-15</created><authors><author><keyname>Huang</keyname><forenames>Jing</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Robust Secure Transmission in MISO Channels Based on Worst-Case
  Optimization</title><categories>cs.IT math.IT</categories><comments>28 pages, 5 figures</comments><doi>10.1109/TSP.2011.2182344</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies robust transmission schemes for multiple-input
single-output (MISO) wiretap channels. Both the cases of direct transmission
and cooperative jamming with a helper are investigated with imperfect channel
state information (CSI) for the eavesdropper links. Robust transmit covariance
matrices are obtained based on worst-case secrecy rate maximization, under both
individual and global power constraints. For the case of an individual power
constraint, we show that the non-convex maximin optimization problem can be
transformed into a quasiconvex problem that can be efficiently solved with
existing methods. For a global power constraint, the joint optimization of the
transmit covariance matrices and power allocation between the source and the
helper is studied via geometric programming. We also study the robust wiretap
transmission problem for the case with a quality-of-service constraint at the
legitimate receiver. Numerical results show the advantage of the proposed
robust design. In particular, for the global power constraint scenario,
although cooperative jamming is not necessary for optimal transmission with
perfect eavesdropper's CSI, we show that robust jamming support can increase
the worst-case secrecy rate and lower the signal to interference-plus-noise
ratio at Eve in the presence of channel mismatches between the transmitters and
the eavesdropper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3162</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3162</id><created>2011-04-15</created><updated>2011-10-24</updated><authors><author><keyname>&#x160;ubelj</keyname><forenames>Lovro</forenames></author><author><keyname>Bajec</keyname><forenames>Marko</forenames></author></authors><title>Ubiquitousness of link-density and link-pattern communities in
  real-world networks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><journal-ref>Eur. Phys. J. B 85(1), 32 (2012)</journal-ref><doi>10.1140/epjb/e2011-20448-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure appears to be an intrinsic property of many complex
real-world networks. However, recent work shows that real-world networks reveal
even more sophisticated modules than classical cohesive (link-density)
communities. In particular, networks can also be naturally partitioned
according to similar patterns of connectedness among the nodes, revealing
link-pattern communities. We here propose a propagation based algorithm that
can extract both link-density and link-pattern communities, without any prior
knowledge of the true structure. The algorithm was first validated on different
classes of synthetic benchmark networks with community structure, and also on
random networks. We have further applied the algorithm to different social,
information, technological and biological networks, where it indeed reveals
meaningful (composites of) link-density and link-pattern communities. The
results thus seem to imply that, similarly as link-density counterparts,
link-pattern communities appear ubiquitous in nature and design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3165</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3165</id><created>2011-04-15</created><authors><author><keyname>Al-Zubaidy</keyname><forenames>Hussein</forenames></author><author><keyname>Huang</keyname><forenames>Changcheng</forenames></author><author><keyname>Yan</keyname><forenames>James</forenames></author></authors><title>Dynamic Packet Scheduler Optimization in Wireless Relay Networks</title><categories>cs.NI cs.SY math.OC</categories><comments>30 pages, one figure, submitted to JSAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate the optimal dynamic packet scheduling policy in
a wireless relay network (WRN). We model this network by two sets of parallel
queues, that represent the subscriber stations (SS) and the relay stations
(RS), with random link connectivity. An optimal policy minimizes, in stochastic
ordering sense, the process of cost function of the SS and RS queue sizes. We
prove that, in a system with symmetrical connectivity and arrival
distributions, a policy that tries to balance the lengths of all the system
queues, at every time slot, is optimal. We use stochastic dominance and
coupling arguments in our proof. We also provide a low-overhead algorithm for
optimal policy implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3179</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3179</id><created>2011-04-15</created><authors><author><keyname>Wu</keyname><forenames>Lingfei</forenames></author><author><keyname>Wang</keyname><forenames>Chengjun</forenames></author></authors><title>Heterogeneity and Allometric Growth of Human Collaborative Tagging
  Behavior</title><categories>cs.IR cs.SI physics.soc-ph</categories><comments>7 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Allometric growth is found in many tagging systems online. That is, the
number of new tags (T) is a power law function of the active population (P), or
T P^gamma (gamma!=1). According to previous studies, it is the heterogeneity in
individual tagging behavior that gives rise to allometric growth. These studies
consider the power-law distribution model with an exponent beta, regarding
1/beta as an index for heterogeneity. However, they did not discuss whether
power-law is the only distribution that leads to allometric growth, or
equivalently, whether the positive correlation between heterogeneity and
allometric growth holds in systems of distributions other than power-law. In
this paper, the authors systematically examine the growth pattern of systems of
six different distributions, and find that both power-law distribution and
log-normal distribution lead to allometric growth. Furthermore, by introducing
Shannon entropy as an indicator for heterogeneity instead of 1/beta, the
authors confirm that the positive relationship between heterogeneity and
allometric growth exists in both cases of power-law and log-normal
distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3184</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3184</id><created>2011-04-15</created><updated>2011-08-24</updated><authors><author><keyname>Kitsak</keyname><forenames>Maksim</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author></authors><title>Hidden Variables in Bipartite Networks</title><categories>physics.data-an cond-mat.dis-nn cond-mat.stat-mech cs.SI physics.soc-ph</categories><journal-ref>Phys. Rev. E 84, 026114 (2011)</journal-ref><doi>10.1103/PhysRevE.84.026114</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and study random bipartite networks with hidden variables. Nodes
in these networks are characterized by hidden variables which control the
appearance of links between node pairs. We derive analytic expressions for the
degree distribution, degree correlations, the distribution of the number of
common neighbors, and the bipartite clustering coefficient in these networks.
We also establish the relationship between degrees of nodes in original
bipartite networks and in their unipartite projections. We further demonstrate
how hidden variable formalism can be applied to analyze topological properties
of networks in certain bipartite network models, and verify our analytical
results in numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3207</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3207</id><created>2011-04-16</created><updated>2012-06-18</updated><authors><author><keyname>Razenshteyn</keyname><forenames>Ilya</forenames></author></authors><title>Common information revisited</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>11 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main notions of information theory is the notion of mutual
information in two messages (two random variables in Shannon information theory
or two binary strings in algorithmic information theory). The mutual
information in $x$ and $y$ measures how much the transmission of $x$ can be
simplified if both the sender and the recipient know $y$ in advance. G\'acs and
K\&quot;orner gave an example where mutual information cannot be presented as common
information (a third message easily extractable from both $x$ and $y$). Then
this question was studied in the framework of algorithmic information theory by
An. Muchnik and A. Romashchenko who found many other examples of this type. K.
Makarychev and Yu. Makarychev found a new proof of G\'acs--K\&quot;orner results by
means of conditionally independent random variables. The question about the
difference between mutual and common information can be studied quantitatively:
for a given $x$ and $y$ we look for three messages $a$, $b$, $c$ such that $a$
and $c$ are enough to reconstruct $x$, while $b$ and $c$ are enough to
reconstruct $y$. In this paper: We state and prove (using hypercontractivity of
product spaces) a quantitative version of G\'acs--K\&quot;orner theorem; We study
the tradeoff between $\abs{a}, \abs{b}, \abs{c}$ for a random pair $(x, y)$
such that Hamming distance between $x$ and $y$ is $\eps n$ (our bounds are
almost tight); We construct &quot;the worst possible&quot; distribution on $(x, y)$ in
terms of the tradeoff between $\abs{a}, \abs{b}, \abs{c}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3208</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3208</id><created>2011-04-16</created><authors><author><keyname>c</keyname><forenames>Aleksandar Ili\'</forenames></author><author><keyname>c</keyname><forenames>Dragan Stevanovi\'</forenames></author></authors><title>Constructions of hamiltonian graphs with bounded degree and diameter O
  (log n)</title><categories>cs.DM</categories><comments>6 pages, 3 figures</comments><report-no>A. Ili\' , D. Stevanovi\' c, Constructions of Hamiltonian graphs
  with bounded degree and diameter O(log n), Appl. Math. Letters 22 (2009)
  1715-1720</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Token ring topology has been frequently used in the design of distributed
loop computer networks and one measure of its performance is the diameter. We
propose an algorithm for constructing hamiltonian graphs with $n$ vertices and
maximum degree $\Delta$ and diameter $O (\log n)$, where $n$ is an arbitrary
number. The number of edges is asymptotically bounded by $(2 - \frac{1}{\Delta
- 1} - \frac{(\Delta - 2)^2}{(\Delta - 1)^3}) n$. In particular, we construct a
family of hamiltonian graphs with diameter at most $2 \lfloor \log_2 n
\rfloor$, maximum degree 3 and at most $1+11n/8$ edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3209</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3209</id><created>2011-04-16</created><authors><author><keyname>Capar</keyname><forenames>Cagatay</forenames></author><author><keyname>Goeckel</keyname><forenames>Dennis</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author></authors><title>Broadcast Analysis for Large Cooperative Wireless Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capability of nodes to broadcast their message to the entire wireless
network when nodes employ cooperation is considered. We employ an asymptotic
analysis using an extended random network setting and show that the broadcast
performance strongly depends on the path loss exponent of the medium. In
particular, as the size of the random network grows, the probability of
broadcast in a one-dimensional network goes to zero for path loss exponents
larger than one, and goes to a nonzero value for path loss exponents less than
one. In two-dimensional networks, the same behavior is observed for path loss
exponents above and below two, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3211</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3211</id><created>2011-04-16</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Singh</keyname><forenames>Rohit</forenames></author></authors><title>On Memoryless Quantitative Objectives</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two-player games on graph, the players construct an infinite path through
the game graph and get a reward computed by a payoff function over infinite
paths. Over weighted graphs, the typical and most studied payoff functions
compute the limit-average or the discounted sum of the rewards along the path.
Beside their simple definition, these two payoff functions enjoy the property
that memoryless optimal strategies always exist.
  In an attempt to construct other simple payoff functions, we define a class
of payoff functions which compute an (infinite) weighted average of the
rewards. This new class contains both the limit-average and discounted sum
functions, and we show that they are the only members of this class which
induce memoryless optimal strategies, showing that there is essentially no
other simple payoff functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3212</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3212</id><created>2011-04-16</created><authors><author><keyname>Lee</keyname><forenames>Hongrae</forenames><affiliation>University of British Columbia</affiliation></author><author><keyname>Ng</keyname><forenames>Raymond T.</forenames><affiliation>University of British Columbia</affiliation></author><author><keyname>Shim</keyname><forenames>Kyuseok</forenames><affiliation>Seoul National University</affiliation></author></authors><title>Similarity Join Size Estimation using Locality Sensitive Hashing</title><categories>cs.DB cs.DS</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 6, pp.
  338-349 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity joins are important operations with a broad range of applications.
In this paper, we study the problem of vector similarity join size estimation
(VSJ). It is a generalization of the previously studied set similarity join
size estimation (SSJ) problem and can handle more interesting cases such as
TF-IDF vectors. One of the key challenges in similarity join size estimation is
that the join size can change dramatically depending on the input similarity
threshold.
  We propose a sampling based algorithm that uses the
Locality-Sensitive-Hashing (LSH) scheme. The proposed algorithm LSH-SS uses an
LSH index to enable effective sampling even at high thresholds. We compare the
proposed technique with random sampling and the state-of-the-art technique for
SSJ (adapted to VSJ) and demonstrate LSH-SS offers more accurate estimates at
both high and low similarity thresholds and small variance using real-world
data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3213</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3213</id><created>2011-04-16</created><authors><author><keyname>Liu</keyname><forenames>Ziyang</forenames><affiliation>Arizona State University</affiliation></author><author><keyname>Natarajan</keyname><forenames>Sivaramakrishnan</forenames><affiliation>Arizona State University</affiliation></author><author><keyname>Chen</keyname><forenames>Yi</forenames><affiliation>ASU</affiliation></author></authors><title>Query Expansion Based on Clustered Results</title><categories>cs.IR</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 6, pp.
  350-361 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Query expansion is a functionality of search engines that suggests a set of
related queries for a user-issued keyword query. Typical corpus-driven keyword
query expansion approaches return popular words in the results as expanded
queries. Using these approaches, the expanded queries may correspond to a
subset of possible query semantics, and thus miss relevant results. To handle
ambiguous queries and exploratory queries, whose result relevance is difficult
to judge, we propose a new framework for keyword query expansion: we start with
clustering the results according to user specified granularity, and then
generate expanded queries, such that one expanded query is generated for each
cluster whose result set should ideally be the corresponding cluster. We
formalize this problem and show its APX-hardness. Then we propose two efficient
algorithms named iterative single-keyword refinement and partial elimination
based convergence, respectively, which effectively generate a set of expanded
queries from clustered results that provide a classification of the original
query results. We believe our study of generating an optimal query based on the
ground truth of the query results not only has applications in query expansion,
but has significance for studying keyword search quality in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3214</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3214</id><created>2011-04-16</created><authors><author><keyname>Dash</keyname><forenames>Debabrata</forenames><affiliation>ArcSight</affiliation></author><author><keyname>Polyzotis</keyname><forenames>Neoklis</forenames><affiliation>UC Santa Cruz</affiliation></author><author><keyname>Ailamaki</keyname><forenames>Anastasia</forenames><affiliation>EPFL</affiliation></author></authors><title>CoPhy: A Scalable, Portable, and Interactive Index Advisor for Large
  Workloads</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 6, pp.
  362-372 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Index tuning, i.e., selecting the indexes appropriate for a workload, is a
crucial problem in database system tuning. In this paper, we solve index tuning
for large problem instances that are common in practice, e.g., thousands of
queries in the workload, thousands of candidate indexes and several hard and
soft constraints. Our work is the first to reveal that the index tuning problem
has a well structured space of solutions, and this space can be explored
efficiently with well known techniques from linear optimization. Experimental
results demonstrate that our approach outperforms state-of-the-art commercial
and research techniques by a significant margin (up to an order of magnitude).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3216</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3216</id><created>2011-04-16</created><authors><author><keyname>Niu</keyname><forenames>Feng</forenames><affiliation>University of Wisconsin-Madison</affiliation></author><author><keyname>R&#xe9;</keyname><forenames>Christopher</forenames><affiliation>University of Wisconsin-Madison</affiliation></author><author><keyname>Doan</keyname><forenames>AnHai</forenames><affiliation>University of Wisconsin-Madison</affiliation></author><author><keyname>Shavlik</keyname><forenames>Jude</forenames><affiliation>University of Wisconsin-Madison</affiliation></author></authors><title>Tuffy: Scaling up Statistical Inference in Markov Logic Networks using
  an RDBMS</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 6, pp.
  373-384 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov Logic Networks (MLNs) have emerged as a powerful framework that
combines statistical and logical reasoning; they have been applied to many data
intensive problems including information extraction, entity resolution, and
text mining. Current implementations of MLNs do not scale to large real-world
data sets, which is preventing their wide-spread adoption. We present Tuffy
that achieves scalability via three novel contributions: (1) a bottom-up
approach to grounding that allows us to leverage the full power of the
relational optimizer, (2) a novel hybrid architecture that allows us to perform
AI-style local search efficiently using an RDBMS, and (3) a theoretical insight
that shows when one can (exponentially) improve the efficiency of stochastic
local search. We leverage (3) to build novel partitioning, loading, and
parallel algorithms. We show that our approach outperforms state-of-the-art
implementations in both quality and speed on several publicly available
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3217</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3217</id><created>2011-04-16</created><authors><author><keyname>Jahani</keyname><forenames>Eaman</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Cafarella</keyname><forenames>Michael J.</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>R&#xe9;</keyname><forenames>Christopher</forenames><affiliation>University of Wisconsin-Madison</affiliation></author></authors><title>Automatic Optimization for MapReduce Programs</title><categories>cs.DB cs.DC</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 6, pp.
  385-396 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MapReduce distributed programming framework has become popular, despite
evidence that current implementations are inefficient, requiring far more
hardware than a traditional relational databases to complete similar tasks.
MapReduce jobs are amenable to many traditional database query optimizations
(B+Trees for selections, column-store- style techniques for projections, etc),
but existing systems do not apply them, substantially because free-form user
code obscures the true data operation being performed. For example, a selection
in SQL is easily detected, but a selection in a MapReduce program is embedded
in Java code along with lots of other program logic. We could ask the
programmer to provide explicit hints about the program's data semantics, but
one of MapReduce's attractions is precisely that it does not ask the user for
such information. This paper covers Manimal, which automatically analyzes
MapReduce programs and applies appropriate data- aware optimizations, thereby
requiring no additional help at all from the programmer. We show that Manimal
successfully detects optimization opportunities across a range of data
operations, and that it yields speedups of up to 1,121% on previously-written
MapReduce programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3219</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3219</id><created>2011-04-16</created><authors><author><keyname>Yang</keyname><forenames>De-Nian</forenames><affiliation>Academia Sinica</affiliation></author><author><keyname>Chen</keyname><forenames>Yi-Ling</forenames><affiliation>National Taiwan University</affiliation></author><author><keyname>Lee</keyname><forenames>Wang-Chien</forenames><affiliation>The Penn State University</affiliation></author><author><keyname>Chen</keyname><forenames>Ming-Syan</forenames><affiliation>National Taiwan University</affiliation></author></authors><title>On Social-Temporal Group Query with Acquaintance Constraint</title><categories>cs.SI</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 6, pp.
  397-408 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Three essential criteria are important for activity planning, including: (1)
finding a group of attendees familiar with the initiator, (2) ensuring each
attendee in the group to have tight social relations with most of the members
in the group, and (3) selecting an activity period available for all attendees.
Therefore, this paper proposes Social-Temporal Group Query to find the activity
time and attendees with the minimum total social distance to the initiator.
Moreover, this query incorporates an acquaintance constraint to avoid finding a
group with mutually unfamiliar attendees. Efficient processing of the
social-temporal group query is very challenging. We show that the problem is
NP-hard via a proof and formulate the problem with Integer Programming. We then
propose two efficient algorithms, SGSelect and STGSelect, which include
effective pruning techniques and employ the idea of pivot time slots to
substantially reduce the running time, for finding the optimal solutions.
Experimental results indicate that the proposed algorithms are much more
efficient and scalable. In the comparison of solution quality, we show that
STGSelect outperforms the algorithm that represents manual coordination by the
initiator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3221</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3221</id><created>2011-04-16</created><authors><author><keyname>Colombo</keyname><forenames>Leonardo</forenames></author><author><keyname>de Diego</keyname><forenames>David Martin</forenames></author></authors><title>On the geometry of higher-order variational problems on Lie groups</title><categories>math-ph cs.SY math.DG math.MP math.OC</categories><comments>20 pages, 4 figures</comments><msc-class>17B66, 22A22, 70G45, 70Hxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe a geometric setting for higher-order lagrangian
problems on Lie groups. Using left-trivialization of the higher-order tangent
bundle of a Lie group and an adaptation of the classical Skinner-Rusk
formalism, we deduce an intrinsic framework for this type of dynamical systems.
Interesting applications as, for instance, a geometric derivation of the
higher-order Euler-Poincar\'e equations, optimal control of underactuated
control systems whose configuration space is a Lie group are shown, among
others, along the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3228</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3228</id><created>2011-04-16</created><authors><author><keyname>Rad</keyname><forenames>Babak Bashari</forenames></author><author><keyname>Masrom</keyname><forenames>Maslin</forenames></author></authors><title>Metamorphic Virus Variants Classification Using Opcode Frequency
  Histogram</title><categories>cs.CR</categories><comments>Latest Trends on Computers (Volume I), 14th WSEAS International
  Conference on COMPUTERS</comments><journal-ref>Rad, B. B. and Masrom, M. (2010). Metamorphic Virus Variants
  Classification Using Opcode Frequency Histogram. Proceedings of the 14th
  WSEAS International Conference on COMPUTERS. July 23-25, 2010. Corfu Island,
  Greece, pp. 147-155</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to prevent detection and evade signature-based scanning methods,
which are normally exploited by antivirus software, metamorphic viruses use
several various obfuscation approaches. They transform their code in new
instances as look entirely or partly different and contain dissimilar sequences
of string, but their behavior and function remain unchanged. This obfuscation
process allows them to stay away from the string based signature detection. In
this research, we use a statistical technique to compare the similarity between
two files infected by two morphed versions of a given metamorphic virus. Our
proposed solution based on static analysis and it uses the histogram of machine
instructions frequency in various offspring of obfuscated viruses. We use
Euclidean histogram distance metric to compare a pair of portable executable
(PE) files. The aim of this study is to show that for some particular
obfuscation methods, the presented solution can be exploited to detect morphed
varieties of a file. Hence, it can be utilized by non-string based signature
scanning to identify whether a file is a version of a metamorphic virus or not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3229</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3229</id><created>2011-04-16</created><authors><author><keyname>Rad</keyname><forenames>Babak Bashari</forenames></author><author><keyname>Masrom</keyname><forenames>Maslin</forenames></author></authors><title>Metamorphic Virus Detection in Portable Executables Using Opcodes
  Statistical Feature</title><categories>cs.CR</categories><comments>Proceeding of the International Conference on Advance Science,
  Engineering and Information Technology 2011, Hotel Equatorial
  Bangi-Putrajaya, Malaysia, 14 - 15 January 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metamorphic viruses engage different mutation techniques to escape from
string signature based scanning. They try to change their code in new offspring
so that the variants appear non-similar and have no common sequences of string
as signature. However, all versions of a metamorphic virus have similar task
and performance. This obfuscation process helps to keep them safe from the
string based signature detection. In this study, we make use of instructions
statistical features to compare the similarity of two hosted files probably
occupied by two mutated forms of a specific metamorphic virus. The introduced
solution in this paper is relied on static analysis and employs the frequency
histogram of machine opcodes in different instances of obfuscated viruses. We
use Minkowski-form histogram distance measurements in order to check the
likeness of portable executables (PE). The purpose of this research is to
present an idea that for a number of special obfuscation approaches the
presented solution can be used to identify morphed copies of a file. Thus, it
can be applied by antivirus scanner to recognize different versions of a
metamorphic virus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3248</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3248</id><created>2011-04-16</created><authors><author><keyname>Neff</keyname><forenames>M.</forenames></author><author><keyname>Anton</keyname><forenames>G.</forenames></author><author><keyname>Enzenh&#xf6;fer</keyname><forenames>A.</forenames></author><author><keyname>Graf</keyname><forenames>K.</forenames></author><author><keyname>H&#xf6;&#xdf;l</keyname><forenames>J.</forenames></author><author><keyname>Katz</keyname><forenames>U.</forenames></author><author><keyname>Lahmann</keyname><forenames>R.</forenames></author><author><keyname>Richardt</keyname><forenames>C.</forenames></author></authors><title>Signal Classification for Acoustic Neutrino Detection</title><categories>astro-ph.IM cs.LG physics.data-an</categories><comments>8 Pages, 6 Figures, ARENA 2010 Conference Proceedings</comments><doi>10.1016/j.nima.2010.11.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article focuses on signal classification for deep-sea acoustic neutrino
detection. In the deep sea, the background of transient signals is very
diverse. Approaches like matched filtering are not sufficient to distinguish
between neutrino-like signals and other transient signals with similar
signature, which are forming the acoustic background for neutrino detection in
the deep-sea environment. A classification system based on machine learning
algorithms is analysed with the goal to find a robust and effective way to
perform this task. For a well-trained model, a testing error on the level of
one percent is achieved for strong classifiers like Random Forest and Boosting
Trees using the extracted features of the signal as input and utilising dense
clusters of sensors instead of single sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3250</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3250</id><created>2011-04-16</created><authors><author><keyname>Rifai</keyname><forenames>Salah</forenames></author><author><keyname>Glorot</keyname><forenames>Xavier</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames></author></authors><title>Adding noise to the input of a model trained with a regularized
  objective</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regularization is a well studied problem in the context of neural networks.
It is usually used to improve the generalization performance when the number of
input samples is relatively small or heavily contaminated with noise. The
regularization of a parametric model can be achieved in different manners some
of which are early stopping (Morgan and Bourlard, 1990), weight decay, output
smoothing that are used to avoid overfitting during the training of the
considered model. From a Bayesian point of view, many regularization techniques
correspond to imposing certain prior distributions on model parameters (Krogh
and Hertz, 1991). Using Bishop's approximation (Bishop, 1995) of the objective
function when a restricted type of noise is added to the input of a parametric
function, we derive the higher order terms of the Taylor expansion and analyze
the coefficients of the regularization terms induced by the noisy input. In
particular we study the effect of penalizing the Hessian of the mapping
function with respect to the input in terms of generalization performance. We
also show how we can control independently this coefficient by explicitly
penalizing the Jacobian of the mapping function on corrupted inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3270</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3270</id><created>2011-04-16</created><updated>2011-05-29</updated><authors><author><keyname>Pham</keyname><forenames>Quang-Cuong</forenames></author></authors><title>Affine trajectory correction for nonholonomic mobile robots</title><categories>cs.RO</categories><comments>14 pages, 11 figures. A preliminary version (8 pages) was accepted
  for presentation at RSS 2011. Main changes with respect to v1: - Added a
  section on the application of affine corrections to gap filling for PRMs -
  Corrected some minor errors - Put into IEEE format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planning trajectories for nonholonomic systems is difficult and
computationally expensive. When facing unexpected events, it may therefore be
preferable to deform in some way the initially planned trajectory rather than
to re-plan entirely a new one. We suggest here a method based on affine
transformations to make such deformations. This method is exact and fast: the
deformations and the resulting trajectories can be computed algebraically, in
one step, and without any trajectory re-integration. To demonstrate the
possibilities offered by this new method, we use it to derive position and
orientation correction algorithms for the general class of planar wheeled
robots and for a tridimensional underwater vehicle. These algorithms allow in
turn achieving more complex applications, including obstacle avoidance,
feedback control or gap filling for sampling-based kinodynamic planners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3283</identifier>
 <datestamp>2012-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3283</id><created>2011-04-17</created><updated>2012-10-31</updated><authors><author><keyname>Gioan</keyname><forenames>Emeric</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Tedder</keyname><forenames>Marc</forenames></author><author><keyname>Corneil</keyname><forenames>Derek</forenames></author></authors><title>Practical and Efficient Split Decomposition via Graph-Labelled Trees</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Split decomposition of graphs was introduced by Cunningham (under the name
join decomposition) as a generalization of the modular decomposition. This
paper undertakes an investigation into the algorithmic properties of split
decomposition. We do so in the context of graph-labelled trees (GLTs), a new
combinatorial object designed to simplify its consideration. GLTs are used to
derive an incremental characterization of split decomposition, with a simple
combinatorial description, and to explore its properties with respect to
Lexicographic Breadth-First Search (LBFS). Applying the incremental
characterization to an LBFS ordering results in a split decomposition algorithm
that runs in time $O(n+m)\alpha(n+m)$, where $\alpha$ is the inverse Ackermann
function, whose value is smaller than 4 for any practical graph. Compared to
Dahlhaus' linear-time split decomposition algorithm [Dahlhaus'00], which does
not rely on an incremental construction, our algorithm is just as fast in all
but the asymptotic sense and full implementation details are given in this
paper. Also, our algorithm extends to circle graph recognition, whereas no such
extension is known for Dahlhaus' algorithm. The companion paper [Gioan et al.]
uses our algorithm to derive the first sub-quadratic circle graph recognition
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3284</identifier>
 <datestamp>2012-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3284</id><created>2011-04-17</created><updated>2012-10-31</updated><authors><author><keyname>Gioan</keyname><forenames>Emeric</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Tedder</keyname><forenames>Marc</forenames></author><author><keyname>Corneil</keyname><forenames>Derek</forenames></author></authors><title>Practical and Efficient Circle Graph Recognition</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Circle graphs are the intersection graphs of chords in a circle. This paper
presents the first sub-quadratic recognition algorithm for the class of circle
graphs. Our algorithm is O(n + m) times the inverse Ackermann function,
{\alpha}(n + m), whose value is smaller than 4 for any practical graph. The
algorithm is based on a new incremental Lexicographic Breadth-First Search
characterization of circle graphs, and a new efficient data-structure for
circle graphs, both developed in the paper. The algorithm is an extension of a
Split Decomposition algorithm with the same running time developed by the
authors in a companion paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3300</identifier>
 <datestamp>2015-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3300</id><created>2011-04-17</created><updated>2015-01-22</updated><authors><author><keyname>Kang</keyname><forenames>Wei</forenames></author><author><keyname>Liu</keyname><forenames>Nan</forenames></author><author><keyname>Chong</keyname><forenames>Weiwei</forenames></author></authors><title>The Gaussian Multiple Access Diamond Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the capacity of the diamond channel. We focus on the
special case where the channel between the source node and the two relay nodes
are two separate links with finite capacities and the link from the two relay
nodes to the destination node is a Gaussian multiple access channel. We call
this model the Gaussian multiple access diamond channel. We first propose an
upper bound on the capacity. This upper bound is a single-letterization of an
$n$-letter upper bound proposed by Traskov and Kramer, and is tighter than the
cut-set bound. As for the lower bound, we propose an achievability scheme based
on sending correlated codes through the multiple access channel with
superposition structure. We then specialize this achievable rate to the
Gaussian multiple access diamond channel. Noting the similarity between the
upper and lower bounds, we provide sufficient and necessary conditions that a
Gaussian multiple access diamond channel has to satisfy such that the proposed
upper and lower bounds meet. Thus, for a Gaussian multiple access diamond
channel that satisfies these conditions, we have found its capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3310</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3310</id><created>2011-04-17</created><authors><author><keyname>Dolev</keyname><forenames>Shlomi</forenames></author><author><keyname>Frenkel</keyname><forenames>Sergey</forenames></author><author><keyname>Tamir</keyname><forenames>Dan</forenames></author></authors><title>Computer Arithmetic Preserving Hamming Distance of Operands in Operation
  Result</title><categories>cs.AR</categories><comments>9 pages, 4 figures</comments><report-no>Technical Report 08-05,13 January, The Lynne and William Frankel
  Center of Computer Science of Ben-Gurion University of the Negev</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional approach to fault tolerant computing involves replicating
computation units and applying a majority vote operation on individual result
bits. This approach, however, has several limitations; the most severe is the
resource requirement. This paper presents a new method for fault tolerant
computing where for a given error rate, the hamming distance between correct
inputs and faulty inputs as well as the hamming distance between a correct
result and a faulty result is preserved throughout processing thereby enabling
correction of up to transient faults per computation cycle. The new method is
compared and contrasted with current protection methods and its cost /
performance is analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3314</identifier>
 <datestamp>2013-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3314</id><created>2011-04-17</created><updated>2013-03-17</updated><authors><author><keyname>Hu</keyname><forenames>Zino H.</forenames></author></authors><title>On Direct Product and Quotient of Strongly Connected Automata</title><categories>cs.FL math.GR</categories><comments>11 pages including examples</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An automaton is isomorphic to the direct product of a permutation strongly
connected automaton and a synchronizing strongly connected automaton if and
only if all of the following conditions are met: (i) it is strongly connected;
(ii) the minimal ideal of its transition semigroup is a right group and (iii)
the ranges of the idempotent elements of the minimal ideal of its transition
semigroup form a partition on its set of states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3333</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3333</id><created>2011-04-17</created><authors><author><keyname>Fraczek</keyname><forenames>Wojciech</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Hiding Information in a Stream Control Transmission Protocol</title><categories>cs.CR</categories><comments>12 pages, 17 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The STCP (Stream Control Transmission Protocol) is a candidate for a new
transport layer protocol that may replace the TCP (Transmission Control
Protocol) and the UDP (User Datagram Protocol) protocols in future IP networks.
Currently, the SCTP is implemented in, or can be added to, many popular
operating systems (Windows, BSD, Linux, HPUX or Sun Solaris). This paper
identifies and presents all possible &quot;places&quot; where hidden information can be
exchanged using an SCTP. The paper focuses mostly on proposing new
steganographic methods that can be applied to an SCTP and that can utilise new,
characteristic SCTP features, such as multi-homing and multi-streaming.
Moreover, for each method, the countermeasure is covered. When used with
malicious intent, a method may pose a threat to network security. Knowledge
about potential SCTP steganographic methods may be used as a supplement to
RFC5062, which describes security attacks in an SCTP protocol. Presented in
this paper is a complete analysis of information hiding in an SCTP, and this
analysis can be treated as a &quot;guide&quot; when developing steganalysis (detection)
tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3335</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3335</id><created>2011-04-17</created><updated>2013-08-12</updated><authors><author><keyname>Hatami</keyname><forenames>Hamed</forenames></author><author><keyname>Lovett</keyname><forenames>Shachar</forenames></author></authors><title>Correlation Testing for Affine Invariant Properties on $\mathbb{F}_p^n$
  in the High Error Regime</title><categories>cs.CC</categories><comments>43 pages. A preliminary version of this work appeared in STOC' 2011</comments><msc-class>12Y05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there has been much interest in Gowers uniformity norms from the
perspective of theoretical computer science. This is mainly due to the fact
that these norms provide a method for testing whether the maximum correlation
of a function $f:\mathbb{F}_p^n \rightarrow \mathbb{F}_p$ with polynomials of
degree at most $d \le p$ is non-negligible, while making only a constant number
of queries to the function. This is an instance of {\em correlation testing}.
In this framework, a fixed test is applied to a function, and the acceptance
probability of the test is dependent on the correlation of the function from
the property. This is an analog of {\em proximity oblivious testing}, a notion
coined by Goldreich and Ron, in the high error regime. In this work, we study
general properties which are affine invariant and which are correlation
testable using a constant number of queries. We show that any such property (as
long as the field size is not too small) can in fact be tested by Gowers
uniformity tests, and hence having correlation with the property is equivalent
to having correlation with degree $d$ polynomials for some fixed $d$. We stress
that our result holds also for non-linear properties which are affine
invariant. This completely classifies affine invariant properties which are
correlation testable. The proof is based on higher-order Fourier analysis.
Another ingredient is a nontrivial extension of a graph theoretical theorem of
Erd\&quot;os, Lov\'asz and Spencer to the context of additive number theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3344</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3344</id><created>2011-04-17</created><authors><author><keyname>Aerts</keyname><forenames>Diederik</forenames></author><author><keyname>Gabora</keyname><forenames>Liane</forenames></author><author><keyname>Sozzo</keyname><forenames>Sandro</forenames></author><author><keyname>Veloz</keyname><forenames>Tomas</forenames></author></authors><title>Quantum Structure in Cognition: Fundamentals and Applications</title><categories>cs.AI cs.IR quant-ph</categories><comments>9 pages</comments><journal-ref>In V. Privman and V. Ovchinnikov (Eds.), IARIA, Proceedings of the
  Fifth International Conference on Quantum, Nano and Micro Technologies, pp.
  57-62, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experiments in cognitive science and decision theory show that the ways in
which people combine concepts and make decisions cannot be described by
classical logic and probability theory. This has serious implications for
applied disciplines such as information retrieval, artificial intelligence and
robotics. Inspired by a mathematical formalism that generalizes quantum
mechanics the authors have constructed a contextual framework for both concept
representation and decision making, together with quantum models that are in
strong alignment with experimental data. The results can be interpreted by
assuming the existence in human thought of a double-layered structure, a
'classical logical thought' and a 'quantum conceptual thought', the latter
being responsible of the above paradoxes and nonclassical effects. The presence
of a quantum structure in cognition is relevant, for it shows that quantum
mechanics provides not only a useful modeling tool for experimental data but
also supplies a structural model for human and artificial thought processes.
This approach has strong connections with theories formalizing meaning, such as
semantic analysis, and has also a deep impact on computer science, information
retrieval and artificial intelligence. More specifically, the links with
information retrieval are discussed in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3345</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3345</id><created>2011-04-17</created><authors><author><keyname>Aerts</keyname><forenames>Diederik</forenames></author><author><keyname>Czachor</keyname><forenames>Marek</forenames></author><author><keyname>Sozzo</keyname><forenames>Sandro</forenames></author></authors><title>Quantum Interaction Approach in Cognition, Artificial Intelligence and
  Robotics</title><categories>cs.AI cs.RO quant-ph</categories><comments>10 pages</comments><journal-ref>In V. Privman and V. Ovchinnikov (Eds.), IARIA, Proceedings of the
  Fifth International Conference on Quantum, Nano and Micro Technologies, pp.
  35-40, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mathematical formalism of quantum mechanics has been successfully
employed in the last years to model situations in which the use of classical
structures gives rise to problematical situations, and where typically quantum
effects, such as 'contextuality' and 'entanglement', have been recognized. This
'Quantum Interaction Approach' is briefly reviewed in this paper focusing, in
particular, on the quantum models that have been elaborated to describe how
concepts combine in cognitive science, and on the ensuing identification of a
quantum structure in human thought. We point out that these results provide
interesting insights toward the development of a unified theory for meaning and
knowledge formalization and representation. Then, we analyze the technological
aspects and implications of our approach, and a particular attention is devoted
to the connections with symbolic artificial intelligence, quantum computation
and robotics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3348</identifier>
 <datestamp>2014-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3348</id><created>2011-04-17</created><updated>2014-11-19</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Monika</forenames></author><author><keyname>Joglekar</keyname><forenames>Manas</forenames></author><author><keyname>Shah</keyname><forenames>Nisarg</forenames></author></authors><title>Symbolic Algorithms for Qualitative Analysis of Markov Decision
  Processes with B\&quot;uchi Objectives</title><categories>cs.GT</categories><journal-ref>In Formal Methods in System Design, 42(3):301-327, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Markov decision processes (MDPs) with \omega-regular
specifications given as parity objectives. We consider the problem of computing
the set of almost-sure winning states from where the objective can be ensured
with probability 1. The algorithms for the computation of the almost-sure
winning set for parity objectives iteratively use the solutions for the
almost-sure winning set for B\&quot;uchi objectives (a special case of parity
objectives). Our contributions are as follows: First, we present the first
subquadratic symbolic algorithm to compute the almost-sure winning set for MDPs
with B\&quot;uchi objectives; our algorithm takes O(n \sqrt{m}) symbolic steps as
compared to the previous known algorithm that takes O(n^2) symbolic steps,
where $n$ is the number of states and $m$ is the number of edges of the MDP. In
practice MDPs have constant out-degree, and then our symbolic algorithm takes
O(n \sqrt{n}) symbolic steps, as compared to the previous known $O(n^2)$
symbolic steps algorithm. Second, we present a new algorithm, namely win-lose
algorithm, with the following two properties: (a) the algorithm iteratively
computes subsets of the almost-sure winning set and its complement, as compared
to all previous algorithms that discover the almost-sure winning set upon
termination; and (b) requires O(n \sqrt{K}) symbolic steps, where K is the
maximal number of edges of strongly connected components (scc's) of the MDP.
The win-lose algorithm requires symbolic computation of scc's. Third, we
improve the algorithm for symbolic scc computation; the previous known
algorithm takes linear symbolic steps, and our new algorithm improves the
constants associated with the linear number of steps. In the worst case the
previous known algorithm takes 5n symbolic steps, whereas our new algorithm
takes 4n symbolic steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3353</identifier>
 <datestamp>2013-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3353</id><created>2011-04-17</created><updated>2012-08-05</updated><authors><author><keyname>Grusea</keyname><forenames>Simona</forenames></author><author><keyname>Labarre</keyname><forenames>Anthony</forenames></author></authors><title>The distribution of cycles in breakpoint graphs of signed permutations</title><categories>cs.DM</categories><doi>10.1016/j.dam.2013.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Breakpoint graphs are ubiquitous structures in the field of genome
rearrangements. Their cycle decomposition has proved useful in computing and
bounding many measures of (dis)similarity between genomes, and studying the
distribution of those cycles is therefore critical to gaining insight on the
distributions of the genomic distances that rely on it. We extend here the work
initiated by Doignon and Labarre, who enumerated unsigned permutations whose
breakpoint graph contains $k$ cycles, to signed permutations, and prove
explicit formulas for computing the expected value and the variance of the
corresponding distributions, both in the unsigned case and in the signed case.
We also compare these distributions to those of several well-studied distances,
emphasising the cases where approximations obtained in this way stand out.
Finally, we show how our results can be used to derive simpler proofs of other
previously known results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3419</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3419</id><created>2011-04-18</created><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir R.</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor V.</forenames></author></authors><title>Optimal Threshold-Based Multi-Trial Error/Erasure Decoding with the
  Guruswami-Sudan Algorithm</title><categories>cs.IT math.IT</categories><comments>Accepted for the 2011 IEEE International Symposium on Information
  Theory, St. Petersburg, Russia, July 31 - August 05, 2011. 5 pages, 2 figures</comments><doi>10.1109/ISIT.2011.6034255</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, multi-trial error/erasure decoding of Reed-Solomon (RS) codes
is based on Bounded Minimum Distance (BMD) decoders with an erasure option.
Such decoders have error/erasure tradeoff factor L=2, which means that an error
is twice as expensive as an erasure in terms of the code's minimum distance.
The Guruswami-Sudan (GS) list decoder can be considered as state of the art in
algebraic decoding of RS codes. Besides an erasure option, it allows to adjust
L to values in the range 1&lt;L&lt;=2. Based on previous work, we provide formulae
which allow to optimally (in terms of residual codeword error probability)
exploit the erasure option of decoders with arbitrary L, if the decoder can be
used z&gt;=1 times. We show that BMD decoders with z_BMD decoding trials can
result in lower residual codeword error probability than GS decoders with z_GS
trials, if z_BMD is only slightly larger than z_GS. This is of practical
interest since BMD decoders generally have lower computational complexity than
GS decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3421</identifier>
 <datestamp>2011-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3421</id><created>2011-04-18</created><updated>2011-06-23</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author><author><keyname>Soler-Toscano</keyname><forenames>Fernando</forenames></author><author><keyname>Joosten</keyname><forenames>Joost J.</forenames></author></authors><title>Empirical Encounters with Computational Irreducibility and
  Unpredictability</title><categories>cs.CC</categories><comments>18 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are several forms of irreducibility in computing systems, ranging from
undecidability to intractability to nonlinearity. This paper is an exploration
of the conceptual issues that have arisen in the course of investigating
speed-up and slowdown phenomena in small Turing machines. We present the
results of a test that may spur experimental approaches to the notion of
computational irreducibility. The test involves a systematic attempt to outrun
the computation of a large number of small Turing machines (all 3 and 4 state,
2 symbol) by means of integer sequence prediction using a specialized function
finder program. This massive experiment prompts an investigation into rates of
convergence of decision procedures and the decidability of sets in addition to
a discussion of the (un)predictability of deterministic computing systems in
practice. We think this investigation constitutes a novel approach to the
discussion of an epistemological question in the context of a computer
simulation, and thus represents an interesting exploration at the boundary
between philosophical concerns and computational experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3463</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3463</id><created>2011-04-18</created><updated>2011-04-25</updated><authors><author><keyname>Shalu</keyname><forenames>M. A.</forenames></author><author><keyname>Vijayakumar</keyname><forenames>S.</forenames></author></authors><title>The Two Bicliques Problem is in NP intersection coNP</title><categories>cs.CC cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the problem of deciding whether the vertex set of a graph can be
covered with at most two bicliques is in NP$\cap$coNP. We thus almost determine
the computational complexity of a problem whose status has remained open for
quite some time. Our result implies that a polynomial time algorithm for the
problem is more likely than it being NP-complete unless P = NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3466</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3466</id><created>2011-04-18</created><authors><author><keyname>Popa</keyname><forenames>Gabriel</forenames></author></authors><title>Characterization of Random Linear Network Coding with Application to
  Broadcast Optimization in Intermittently Connected Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>7 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of optimizing the throughput of network coded traffic
in mobile networks operating in challenging environments where connectivity is
intermittent and locally available memory space is limited. Random linear
network coding (RLNC) is shown to be equivalent (across all possible initial
conditions) to a random message selection strategy where nodes are able to
exchange buffer occupancy information during contacts. This result creates the
premises for a tractable analysis of RLNC packet spread, which is in turn used
for enhancing its throughput under broadcast. By exploiting the similarity
between channel coding and RLNC in intermittently connected networks, we show
that quite surprisingly, network coding, when not used properly, is still
significantly underutilizing network resources. We propose an enhanced
forwarding protocol that increases considerably the throughput for practical
cases, with negligible additional delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3469</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3469</id><created>2011-04-18</created><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author><author><keyname>Lee</keyname><forenames>Dongman</forenames></author></authors><title>Probabilistic Analysis of Loss in Interface Adapter Chaining</title><categories>cs.SE</categories><comments>20 pages, 2 figures</comments><acm-class>D.2.12; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interface adapters allow applications written for one interface to be reused
with another interface without having to rewrite application code, and chaining
interface adapters can significantly reduce the development effort required to
create the adapters. However, interface adapters will often be unable to
convert interfaces perfectly, so there must be a way to analyze the loss from
interface adapter chains in order to improve the quality of interface
adaptation. This paper describes a probabilistic approach to analyzing loss in
interface adapter chains, which not only models whether a method can be adapted
but also how well methods can be adapted. We also show that probabilistic
optimal adapter chaining is an NP-complete problem, so we describe a greedy
algorithm which can construct an optimal interface adapter chain with
exponential time in the worst case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3489</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3489</id><created>2011-04-18</created><updated>2014-02-12</updated><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames><affiliation>Faculty of Informatics, Masaryk University</affiliation></author><author><keyname>Bro&#x17e;ek</keyname><forenames>V&#xe1;clav</forenames><affiliation>Faculty of Informatics, Masaryk University</affiliation></author><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames><affiliation>IST Austria</affiliation></author><author><keyname>Forejt</keyname><forenames>Vojt&#x11b;ch</forenames><affiliation>Department of Computer Science, Oxford University</affiliation></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames><affiliation>Faculty of Informatics, Masaryk University</affiliation></author></authors><title>Markov Decision Processes with Multiple Long-run Average Objectives</title><categories>cs.GT</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 1 (February
  14, 2014) lmcs:1156</journal-ref><doi>10.2168/LMCS-10(1:13)2014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Markov decision processes (MDPs) with multiple limit-average (or
mean-payoff) functions. We consider two different objectives, namely,
expectation and satisfaction objectives. Given an MDP with k limit-average
functions, in the expectation objective the goal is to maximize the expected
limit-average value, and in the satisfaction objective the goal is to maximize
the probability of runs such that the limit-average value stays above a given
vector. We show that under the expectation objective, in contrast to the case
of one limit-average function, both randomization and memory are necessary for
strategies even for epsilon-approximation, and that finite-memory randomized
strategies are sufficient for achieving Pareto optimal values. Under the
satisfaction objective, in contrast to the case of one limit-average function,
infinite memory is necessary for strategies achieving a specific value (i.e.
randomized finite-memory strategies are not sufficient), whereas memoryless
randomized strategies are sufficient for epsilon-approximation, for all
epsilon&gt;0. We further prove that the decision problems for both expectation and
satisfaction objectives can be solved in polynomial time and the trade-off
curve (Pareto curve) can be epsilon-approximated in time polynomial in the size
of the MDP and 1/epsilon, and exponential in the number of limit-average
functions, for all epsilon&gt;0. Our analysis also reveals flaws in previous work
for MDPs with multiple mean-payoff functions under the expectation objective,
corrects the flaws, and allows us to obtain improved results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3497</identifier>
 <datestamp>2012-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3497</id><created>2011-04-18</created><authors><author><keyname>Lin</keyname><forenames>Pin-Hsun</forenames></author><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author><author><keyname>Hong</keyname><forenames>Y. -W. Peter</forenames></author></authors><title>Clean relaying aided cognitive radio under the coexistence constraint</title><categories>cs.IT math.IT</categories><comments>30 pages</comments><doi>10.1109/TWC.2012.092712.120005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the interference-mitigation based cognitive radio where the
primary and secondary users can coexist at the same time and frequency bands,
under the constraint that the rate of the primary user (PU) must remain the
same with a single-user decoder. To meet such a coexistence constraint, the
relaying from the secondary user (SU) can help the PU's transmission under the
interference from the SU. However, the relayed signal in the known dirty paper
coding (DPC) based scheme is interfered by the SU's signal, and is not &quot;clean&quot;.
In this paper, under the half-duplex constraints, we propose two new
transmission schemes aided by the clean relaying from the SU's transmitter and
receiver without interference from the SU. We name them as the clean
transmitter relaying (CT) and clean transmitter-receiver relaying (CTR) aided
cognitive radio, respectively. The rate and multiplexing gain performances of
CT and CTR in fading channels with various availabilities of the channel state
information at the transmitters (CSIT) are studied. Our CT generalizes the
celebrated DPC based scheme proposed previously. With full CSIT, the
multiplexing gain of the CTR is proved to be better (or no less) than that of
the previous DPC based schemes. This is because the silent period for decoding
the PU's messages for the DPC may not be necessary in the CTR. With only the
statistics of CSIT, we further prove that the CTR outperforms the rate
performance of the previous scheme in fast Rayleigh fading channels. The
numerical examples also show that in a large class of channels, the proposed CT
and CTR provide significant rate gains over the previous scheme with small
complexity penalties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3500</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3500</id><created>2011-04-18</created><updated>2011-08-18</updated><authors><author><keyname>Rampersad</keyname><forenames>Narad</forenames><affiliation>Department of Mathematics, University of Li&#xe8;ge</affiliation></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames><affiliation>School of Computer Science, University of Waterloo</affiliation></author><author><keyname>Shur</keyname><forenames>Arseny</forenames><affiliation>Department of Algebra and Discrete Mathematics, Ural Federal University</affiliation></author></authors><title>Fife's Theorem for (7/3)-Powers</title><categories>cs.FL cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 189-198</journal-ref><doi>10.4204/EPTCS.63.25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a Fife-like characterization of the infinite binary (7/3)-power-free
words, by giving a finite automaton of 15 states that encodes all such words.
As a consequence, we characterize all such words that are 2-automatic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3503</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3503</id><created>2011-04-18</created><authors><author><keyname>Chakraborty</keyname><forenames>Arnab</forenames></author></authors><title>RESID: A Practical Stochastic Model for Software Reliability</title><categories>stat.AP cs.SE</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach called RESID is proposed in this paper for estimating
reliability of a software allowing for imperfect debugging. Unlike earlier
approaches based on counting number of bugs or modelling inter-failure time
gaps, RESID focuses on the probability of &quot;bugginess&quot; of different parts of a
program buggy. This perspective allows an easy way to incorporate the structure
of the software under test, as well as imperfect debugging. One main design
objective behind RESID is ease of implementation in practical scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3510</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3510</id><created>2011-03-29</created><authors><author><keyname>Nam</keyname><forenames>Wooseok</forenames></author><author><keyname>Kong</keyname><forenames>Seung-Hyun</forenames></author></authors><title>Least-squares based iterative multipath super-resolution technique</title><categories>cs.IT cs.SY math.IT</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of multipath channel estimation for
direct sequence spread spectrum signals. To resolve multipath components
arriving within a short interval, we propose a new algorithm called the
least-squares based iterative multipath super-resolution (LIMS). Compared to
conventional super-resolution techniques, such as the multiple signal
classification (MUSIC) and the estimation of signal parameters via rotation
invariance techniques (ESPRIT), our algorithm has several appealing features.
In particular, even in critical situations where the conventional
super-resolution techniques are not very powerful due to limited data or the
correlation between path coefficients, the LIMS algorithm can produce
successful results. In addition, due to its iterative nature, the LIMS
algorithm is suitable for recursive multipath tracking, whereas the
conventional super-resolution techniques may not be. Through numerical
simulations, we show that the LIMS algorithm can resolve the first arrival path
among closely arriving independently faded multipaths with a much lower mean
square error than can conventional early-late discriminator based techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3513</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3513</id><created>2011-03-28</created><authors><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author></authors><title>An Effect of Spatial Filtering in Visualization of Coronary Arteries
  Imaging</title><categories>cs.CV cs.CE</categories><comments>06 Pages, 18 figures</comments><acm-class>I.4; I.5</acm-class><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT), Vol. 2, No. 1, 2009, PP: 35-40</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present, coronary angiography is the well known standard for the diagnosis
of coronary artery disease. Conventional coronary angiography is an invasive
procedure with a small, yet inherent risk of myocardial infarction, stroke,
potential arrhythmias, and death. Other noninvasive diagnostic tools, such as
electrocardiography, echocardiography, and nuclear imaging are now widely
available but are limited by their inability to directly visualize and quantify
coronary artery stenoses and predict the stability of plaques. Coronary
magnetic resonance angiography (MRA) is a technique that allows visualization
of the coronary arteries by noninvasive means; however, it has not yet reached
a stage where it can be used in routine clinical practice. Although coronary
MRA is a potentially useful diagnostic tool, it has limitations. Further
research should focus on improving the diagnostic resolution and accuracy of
coronary MRA. This paper will helps to cardiologists to take the clear look of
spatial filtered imaging of coronary arteries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3523</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3523</id><created>2011-04-18</created><authors><author><keyname>Regnier</keyname><forenames>Paul</forenames></author><author><keyname>Lima</keyname><forenames>George</forenames></author><author><keyname>Massa</keyname><forenames>Ernesto</forenames></author></authors><title>An Optimal Real-Time Scheduling Approach: From Multiprocessor to
  Uniprocessor</title><categories>cs.OS</categories><comments>10 pages - rejected for publication by ECRTS 2011</comments><msc-class>98B35, 68M20</msc-class><acm-class>C.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An optimal solution to the problem of scheduling real-time tasks on a set of
identical processors is derived. The described approach is based on solving an
equivalent uniprocessor real-time scheduling problem. Although there are other
scheduling algorithms that achieve optimality, they usually impose prohibitive
preemption costs. Unlike these algorithms, it is observed through simulation
that the proposed approach produces no more than three preemptions points per
job.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3525</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3525</id><created>2011-03-23</created><authors><author><keyname>Tuncer</keyname><forenames>Ruhi</forenames></author></authors><title>Evolutionary Foundations of Mathematics</title><categories>cs.OH</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple cognitive model where qualitative and quantitative com-
parisons enable animals to identify objects, associate them with their
properties held in memory and make naive inference. Simple notions like
equivalence re- lations, order relations are used. We then show that such
processes are at the root of human mathematical reasoning by showing that the
elements of totally ordered sets satisfy the Peano axioms. The process through
which children learn counting is then formalized. Finally association is
modeled as a Markov process leading to a stationary distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3544</identifier>
 <datestamp>2013-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3544</id><created>2011-03-29</created><updated>2013-07-17</updated><authors><author><keyname>Felber</keyname><forenames>Franklin</forenames></author></authors><title>An automatic volume control for preserving intelligibility</title><categories>cs.SD</categories><comments>5 pages, 3 figures, published in Proceedings of 34th IEEE Sarnoff
  Symposium, Princeton, NJ, 3-4 May 2011. Version 2 has typographical changes
  only</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method has been developed to adjust volume automatically on all audio
devices equipped with at least one microphone, including mobile phones,
personal media players, headsets, and car radios, that might be used in noisy
environments, such as crowds, cars, and outdoors. The method uses a patented
set of algorithms, implemented on the chips in such devices, to preserve
constant intelligibility of speech in noisy environments, rather than constant
signal-to-noise ratio. The algorithms analyze the noise background in real time
and compensate only for fluctuating noise in the frequency domain and the time
domain that interferes with intelligibility of speech. Advantages of this
method of controlling volume include: Controlling volume without sacrificing
clarity; adjusting only for persistent speech-interference noise; smoothing
volume fluctuations; and eliminating static-like bursts caused by noise spikes.
Practical human-factors approaches to implementing these algorithms in mobile
phones are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3556</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3556</id><created>2011-04-18</created><authors><author><keyname>Wyrembelski</keyname><forenames>Rafael F.</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>How to Achieve Privacy in Bidirectional Relay Networks</title><categories>cs.IT math.IT</categories><comments>Proc. IEEE International Symposium on Information Theory (ISIT 2011),
  Saint Petersburg, Russia, July/August 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research developments show that the concept of bidirectional relaying
significantly improves the performance in wireless networks. This applies to
three-node networks, where a half-duplex relay node establishes a bidirectional
communication between two other nodes using a decode-and-forward protocol. In
this work we consider the scenario when in the broadcast phase the relay
transmits additional confidential information to one node, which should be kept
as secret as possible from the other, non-intended node. This is the
bidirectional broadcast channel with confidential messages for which we derive
the capacityequivocation region and the secrecy capacity region. The latter
characterizes the communication scenario with perfect secrecy, where the
confidential message is completely hidden from the non-legitimated node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3561</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3561</id><created>2011-04-18</created><updated>2011-04-19</updated><authors><author><keyname>Jeong</keyname><forenames>Seongwook</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>Soft-In Soft-Out DFE and Bi-directional DFE</title><categories>cs.IT math.IT</categories><comments>22 pages, 13 figures. The material in this paper was presented in
  part at ICC 2010, Cape Town, South Africa, May 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a soft-in soft-out (SISO) decision feedback equalizer (DFE) that
performs better than its linear counterpart in turbo equalizer (TE) setting.
Unlike previously developed SISO-DFEs, the present DFE scheme relies on
extrinsic information formulation that directly takes into account the error
propagation effect. With this new approach, both error rate simulation and the
extrinsic information transfer (EXIT) chart analysis indicate that the proposed
SISO-DFE is superior to the well-known SISO linear equalizer (LE). This result
is in contrast with the general understanding today that the error propagation
effect of the DFE degrades the overall TE performance below that of the TE
based on a LE. We also describe a new extrinsic information combining strategy
involving the outputs of two DFEs running in opposite directions, that explores
error correlation between the two sets of DFE outputs. When this method is
combined with the new DFE extrinsic information formulation, the resulting
&quot;bidirectional&quot; turbo-DFE achieves excellent performance-complexity tradeoffs
compared to the TE based on the BCJR algorithm or on the LE. Unlike turbo LE or
turbo DFE, the turbo BiDFE's performance does not degrade significantly as the
feedforward and feedback filter taps are constrained to be time-invariant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3571</identifier>
 <datestamp>2012-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3571</id><created>2011-03-28</created><updated>2012-05-11</updated><authors><author><keyname>Kodge</keyname><forenames>B. G.</forenames></author><author><keyname>Hiremath</keyname><forenames>P. S.</forenames></author></authors><title>Visualization techniques for data mining of Latur district satellite
  imagery</title><categories>cs.CE cs.CV</categories><comments>This paper has been withdrawn by the author</comments><acm-class>D.1.7; H.2.8; I.4.6</acm-class><journal-ref>Advances in Computational Research, Volume 2, Issue 1, 2010,
  pp-21-24</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents a new visualization tool for classification of satellite
imagery. Visualization of feature space allows exploration of patterns in the
image data and insight into the classification process and related uncertainty.
Visual Data Mining provides added value to image classifications as the user
can be involved in the classification process providing increased confidence in
and understanding of the results. In this study, we present a prototype
visualization tool for visual data mining (VDM) of satellite imagery. The
visualization tool is showcased in a classification study of highresolution
imageries of Latur district in Maharashtra state of India.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3590</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3590</id><created>2011-04-18</created><authors><author><keyname>Ball</keyname><forenames>Brian</forenames></author><author><keyname>Karrer</keyname><forenames>Brian</forenames></author><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>An efficient and principled method for detecting communities in networks</title><categories>cs.SI cond-mat.stat-mech physics.soc-ph</categories><comments>14 pages, 5 figures, 1 table</comments><journal-ref>Phys. Rev. E 84, 036103 (2011)</journal-ref><doi>10.1103/PhysRevE.84.036103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in the analysis of network data is the detection of
network communities, groups of densely interconnected nodes, which may be
overlapping or disjoint. Here we describe a method for finding overlapping
communities based on a principled statistical approach using generative network
models. We show how the method can be implemented using a fast, closed-form
expectation-maximization algorithm that allows us to analyze networks of
millions of nodes in reasonable running times. We test the method both on
real-world networks and on synthetic benchmarks and find that it gives results
competitive with previous methods. We also show that the same approach can be
used to extract nonoverlapping community divisions via a relaxation method, and
demonstrate that the algorithm is competitively fast and accurate for the
nonoverlapping problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3602</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3602</id><created>2011-04-18</created><authors><author><keyname>Dougherty</keyname><forenames>Randall</forenames></author><author><keyname>Freiling</keyname><forenames>Chris</forenames></author><author><keyname>Zeger</keyname><forenames>Kenneth</forenames></author></authors><title>Non-Shannon Information Inequalities in Four Random Variables</title><categories>cs.IT math.IT</categories><comments>40 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Any unconstrained information inequality in three or fewer random variables
can be written as a linear combination of instances of Shannon's inequality
I(A;B|C) &gt;= 0 . Such inequalities are sometimes referred to as &quot;Shannon&quot;
inequalities. In 1998, Zhang and Yeung gave the first example of a
&quot;non-Shannon&quot; information inequality in four variables. Their technique was to
add two auxiliary variables with special properties and then apply Shannon
inequalities to the enlarged list. Here we will show that the Zhang-Yeung
inequality can actually be derived from just one auxiliary variable. Then we
use their same basic technique of adding auxiliary variables to give many other
non-Shannon inequalities in four variables. Our list includes the inequalities
found by Xu, Wang, and Sun, but it is by no means exhaustive. Furthermore, some
of the inequalities obtained may be superseded by stronger inequalities that
have yet to be found. Indeed, we show that the Zhang-Yeung inequality is one of
those that is superseded. We also present several infinite families of
inequalities. This list includes some, but not all of the infinite families
found by Matus. Then we will give a description of what additional information
these inequalities tell us about entropy space. This will include a conjecture
on the maximum possible failure of Ingleton's inequality. Finally, we will
present an application of non-Shannon inequalities to network coding. We will
demonstrate how these inequalities are useful in finding bounds on the
information that can flow through a particular network called the Vamos
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3609</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3609</id><created>2011-04-18</created><authors><author><keyname>Mangler</keyname><forenames>Juergen</forenames></author><author><keyname>Rinderle-Ma</keyname><forenames>Stefanie</forenames></author></authors><title>IUPC: Identification and Unification of Process Constraints</title><categories>cs.FL</categories><comments>13 pages, 4 figures, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Business Process Compliance (BPC) has gained significant momentum in research
and practice during the last years. Although many approaches address BPC, they
mostly assume the existence of some kind of unified base of process constraints
and focus on their verification over the business processes. However, it
remains unclear how such an inte- grated process constraint base can be built
up, even though this con- stitutes the essential prerequisite for all further
compliance checks. In addition, the heterogeneity of process constraints has
been neglected so far. Without identification and separation of process
constraints from domain rules as well as unification of process constraints,
the success- ful IT support of BPC will not be possible. In this technical
report we introduce a unified representation framework that enables the
identifica- tion of process constraints from domain rules and their later
unification within a process constraint base. Separating process constraints
from domain rules can lead to significant reduction of compliance checking
effort. Unification enables consistency checks and optimizations as well as
maintenance and evolution of the constraint base on the other side.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3631</identifier>
 <datestamp>2011-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3631</id><created>2011-04-18</created><updated>2011-09-12</updated><authors><author><keyname>Xiao</keyname><forenames>Jing-Qing</forenames></author><author><keyname>Zhou</keyname><forenames>Haijun</forenames></author></authors><title>Partition function loop series for a general graphical model: free
  energy corrections and message-passing equations</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC</categories><comments>12 pages with 1 figure included. Extensive revision on structure of
  the paper (no change in results). Accepted by Journal of Physica A</comments><journal-ref>J. Phys. A: Math. Theor. 44 (2011) 425001</journal-ref><doi>10.1088/1751-8113/44/42/425001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A loop series expansion for the partition function of a general statistical
model on a graph is carried out. If the auxiliary probability distributions of
the expansion are chosen to be a fixed point of the belief-propagation
equation, the first term of the loop series gives the Bethe-Peierls free energy
functional at the replica-symmetric level of the mean-field spin glass theory,
and corrections are contributed only by subgraphs that are free of dangling
edges. This result generalize the early work of Chertkov and Chernyak on binary
statistical models. If the belief-propagation equation has multiple fixed
points, a loop series expansion is performed for the grand partition function.
The first term of this series gives the Bethe-Peierls free energy functional at
the first-step replica-symmetry-breaking (RSB) level of the mean-field
spin-glass theory, and corrections again come only from subgraphs that are free
of dangling edges, provided that the auxiliary probability distributions of the
expansion are chosen to be a fixed point of the survey-propagation equation.
The same loop series expansion can be performed for higher-level partition
functions, obtaining the higher-level RSB Bethe-Peierls free energy functionals
(and the correction terms) and message-passing equations without using the
Bethe-Peierls approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3636</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3636</id><created>2011-04-19</created><authors><author><keyname>Liu</keyname><forenames>Ying</forenames></author><author><keyname>Liu</keyname><forenames>Hongying</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author><author><keyname>Shen</keyname><forenames>Meng</forenames></author><author><keyname>Zhong</keyname><forenames>Yifeng</forenames></author></authors><title>A Large Family of Multi-path Dual Congestion Control Algorithms</title><categories>cs.NI</categories><comments>11 page</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of traffic management is efficiently utilizing network resources via
adapting of source sending rates and routes selection. Traditionally, this
problem is formulated into a utilization maximization problem. The single-path
routing scheme fails to react to instantaneous network congestion. Multi-path
routing schemes thus have been proposed aiming at improving network efficiency.
Unfortunately, the natural optimization problem to consider is concave but not
strictly concave. It thus brings a huge challenge to design stable multi-path
congestion control algorithms.
  In this paper, we propose a generalized multi-path utility maximization model
to consider the problem of routes selection and flow control, and derive a
family of multi-path dual congestion control algorithms. We show that the
proposed algorithms are stable in the absence of delays. We also derive
decentralized and scalable sufficient conditions for a particular scheme when
propagation delays exist in networks. Simulations are implemented using both
Matlab and NS2, on which evaluation of the proposed multi-path dual algorithms
is exerted. The comparison results, between the proposed algorithms and the
other two existing algorithms, show that the proposed multi-path dual
algorithms with appropriate parameter settings can achieve a stable aggregated
throughput while maintaining fairness among the involved users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3661</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3661</id><created>2011-04-19</created><updated>2012-04-12</updated><authors><author><keyname>Zhang</keyname><forenames>Lili</forenames></author><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Interference Channel with State Information</title><categories>cs.IT math.IT</categories><comments>32 pages, 8 figures, submitted to IEEE Transaction on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the state-dependent two-user interference channel,
where the state information is non-causally known at both transmitters but
unknown to either of the receivers. We first propose two coding schemes for the
discrete memoryless case: simultaneous encoding for the sub-messages in the
first one and superposition encoding in the second one, both with rate
splitting and Gel'fand-Pinsker coding. The corresponding achievable rate
regions are established. Moreover, for the Gaussian case, we focus on the
simultaneous encoding scheme and propose an \emph{active interference
cancellation} mechanism, which is a generalized dirty-paper coding technique,
to partially eliminate the state effect at the receivers. The corresponding
achievable rate region is then derived. We also propose several heuristic
schemes for some special cases: the strong interference case, the mixed
interference case, and the weak interference case. For the strong and mixed
interference case, numerical results are provided to show that active
interference cancellation significantly enlarges the achievable rate region.
For the weak interference case, flexible power splitting instead of active
interference cancellation improves the performance significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3662</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3662</id><created>2011-04-19</created><authors><author><keyname>Huang</keyname><forenames>Chuan</forenames></author><author><keyname>Jiang</keyname><forenames>Jinhua</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Asymptotic Capacity of Large Relay Networks with Conferencing Links</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, we consider a half-duplex large relay network, which
consists of one source-destination pair and $N$ relay nodes, each of which is
connected with a subset of the other relays via signal-to-noise ratio
(SNR)-limited out-of-band conferencing links. The asymptotic achievable rates
of two basic relaying schemes with the &quot;$p$-portion&quot; conferencing strategy are
studied: For the decode-and-forward (DF) scheme, we prove that the DF rate
scales as $\mathcal{O} (\log (N))$; for the amplify-and-forward (AF) scheme, we
prove that it asymptotically achieves the capacity upper bound in some
interesting scenarios as $N$ goes to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3677</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3677</id><created>2011-04-19</created><authors><author><keyname>Heggernes</keyname><forenames>Pinar</forenames></author><author><keyname>Hof</keyname><forenames>Pim van 't</forenames></author><author><keyname>L&#xe9;v&#xea;que</keyname><forenames>Benjamin</forenames></author><author><keyname>Lokshtanov</keyname><forenames>Daniel</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author></authors><title>Contracting Graphs to Paths and Trees</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vertex deletion and edge deletion problems play a central role in
Parameterized Complexity. Examples include classical problems like Feedback
Vertex Set, Odd Cycle Transversal, and Chordal Deletion. Interestingly, the
study of edge contraction problems of this type from a parameterized
perspective has so far been left largely unexplored. We consider two basic edge
contraction problems, which we call Path-Contractibility and
Tree-Contractibility. Both problems take an undirected graph $G$ and an integer
$k$ as input, and the task is to determine whether we can obtain a path or an
acyclic graph, respectively, by contracting at most $k$ edges of $G$. Our main
contribution is an algorithm with running time $4^{k+O(\log^2 k)} + n^{O(1)}$
for Path-Contractibility and an algorithm with running time $4.88^k n^{O(1)}$
for Tree-Contractibility, based on a novel application of the color coding
technique of Alon, Yuster and Zwick. Furthermore, we show that
Path-Contractibility has a kernel with at most $5k+3$ vertices, while
Tree-Contractibility does not have a polynomial kernel unless coNP $\subseteq$
NP/poly. We find the latter result surprising, because of the strong connection
between Tree-Contractibility and Feedback Vertex Set, which is known to have a
vertex kernel with size $O(k^2)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3681</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3681</id><created>2011-04-19</created><authors><author><keyname>Chingtham</keyname><forenames>Tejbanta Singh</forenames></author><author><keyname>Sahoo</keyname><forenames>G.</forenames></author><author><keyname>Ghose</keyname><forenames>M. K.</forenames></author></authors><title>An Unmanned Aerial Vehicle as Human-Assistant Robotics System</title><categories>cs.RO</categories><journal-ref>2010 IEEE International Conference on Computational Intelligence
  and Computing Research</journal-ref><doi>10.1109/ICCIC.2010.5705731</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the American Heritage Dictionary [1],Robotics is the science or
study of the technology associated with the design, fabrication, theory, and
application of Robots. The term Hoverbot is also often used to refer to
sophisticated mechanical devices that are remotely controlled by human beings
even though these devices are not autonomous. This paper describes a remotely
controlled hoverbot by installing a transmitter and receiver on both sides that
is the control computer (PC) and the hoverbot respectively. Data is transmitted
as signal or instruction via a infrastructure network which is converted into a
command for the hoverbot that operates at a remote site.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3694</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3694</id><created>2011-04-19</created><authors><author><keyname>Benamara</keyname><forenames>Lamia</forenames><affiliation>LIP6</affiliation></author><author><keyname>Magnien</keyname><forenames>Cl&#xe9;mence</forenames><affiliation>LIP6</affiliation></author></authors><title>Removing bias due to finite measurement of dynamic systems: case study
  on P2P systems</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>13es Rencontres Francophones sur les Aspects Algorithmiques de
  T\'el\'ecommunications (AlgoTel) (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mesurer avec pr\'ecision la dynamique des graphes de terrain est une t\^ache
difficile, car les propri\'et\'es observ\'ees peuvent \^etre biais\'ees pour
diff\'erentes raisons, en particulier le fait que la p\'eriode de mesure soit
finie. Dans ce papier, nous introduisons une m\'ethodologie g\'en\'erale qui
nous permet de savoir si la fen\^etre d'observation est suffisamment longue
pour caract\'eriser une propri\'et\'e donn\'ee dans n'importe quel syst\`eme
dynamique. Nous appliquons cette m\'ethodologie \`a l'\'etude des dur\'ees de
sessions et des dur\'ees de vie des fichiers sur deux jeux de donn\'ees P2P.
Nous montrons que le comportement des propri\'et\'es est diff\'erent : pour les
dur\'ees de sessions, notre m\'ethodologie nous permet de caract\'eriser avec
pr\'ecision la forme de leur distribution. Par contre, pour les dur\'ees de vie
des fichiers, nous montrons que cette propri\'et\'e ne peut pas \^etre
caract\'eris\'ee, soit parce qu'elle n'est pas stationnaire, soit parce que la
dur\'ee de notre mesure est trop courte.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3720</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3720</id><created>2011-04-19</created><updated>2011-09-26</updated><authors><author><keyname>Bl&#xf6;mer</keyname><forenames>Johannes</forenames></author><author><keyname>Naewe</keyname><forenames>Stefanie</forenames></author></authors><title>Solving the Closest Vector Problem with respect to l_p Norms</title><categories>cs.DS cs.CC cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a deterministic algorithm for the closest vector
problem for all l_p-norms, 1 &lt; p &lt; \infty, and all polyhedral norms, especially
for the l_1-norm and the l_{\infty}-norm. We achieve our results by introducing
a new lattice problem, the lattice membership problem. We describe a
deterministic algorithm for the lattice membership problem, which is a
generalization of Lenstra's algorithm for integer programming. We also describe
a polynomial time reduction from the closest vector problem to the lattice
membership problem. This approach leads to a deterministic algorithm that
solves the closest vector problem for all l_p-norms, 1 &lt; p &lt; \infty, in time p
log_2 (r)^{O (1)} n^{(5/2+o(1))n} and for all polyhedral norms in time (s log_2
(r))^{O (1)} n^{(2+o(1))n}, where s is the number of constraints defining the
polytope and r is an upper bound on the coefficients used to describe the
convex body.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3722</identifier>
 <datestamp>2015-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3722</id><created>2011-04-19</created><authors><author><keyname>Malone</keyname><forenames>David</forenames></author><author><keyname>Maher</keyname><forenames>Kevin</forenames></author></authors><title>Investigating the Distribution of Password Choices</title><categories>cs.CR</categories><doi>10.1145/2187836.2187878</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we will look at the distribution with which passwords are
chosen. Zipf's Law is commonly observed in lists of chosen words. Using
password lists from four different on-line sources, we will investigate if
Zipf's law is a good candidate for describing the frequency with which
passwords are chosen. We look at a number of standard statistics, used to
measure the security of password distributions, and see if modelling the data
using Zipf's Law produces good estimates of these statistics. We then look at
the the similarity of the password distributions from each of our sources,
using guessing as a metric. This shows that these distributions provide
effective tools for cracking passwords. Finally, we will show how to shape the
distribution of passwords in use, by occasionally asking users to choose a
different password.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3727</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3727</id><created>2011-04-19</created><updated>2012-11-12</updated><authors><author><keyname>Betsumiya</keyname><forenames>Koichi</forenames></author><author><keyname>Harada</keyname><forenames>Masaaki</forenames></author><author><keyname>Munemasa</keyname><forenames>Akihiro</forenames></author></authors><title>A complete classification of doubly even self-dual codes of length 40</title><categories>math.CO cs.IT math.IT</categories><comments>corrected typo</comments><journal-ref>Electronic J. Combin. 19 (2012), #P18</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete classification of binary doubly even self-dual codes of length 40
is given. As a consequence, a classification of binary extremal self-dual codes
of length 38 is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3739</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3739</id><created>2011-04-19</created><updated>2011-04-21</updated><authors><author><keyname>Ernvall-Hyt&#xf6;nen</keyname><forenames>Anne-Maria</forenames></author></authors><title>On a conjecture by Belfiore and Sol\'e on some lattices</title><categories>cs.IT math.IT math.NT</categories><comments>Abstract corrected, the case of a 16-dimensional lattice added, and
  several typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The point of this note is to prove that the secrecy function attains its
maximum at y=1 on all known extremal even unimodular lattices. This is a
special case of a conjecture by Belfiore and Sol\'e. Further, we will give a
very simple method to verify or disprove the conjecture on any given unimodular
lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3742</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3742</id><created>2011-04-19</created><authors><author><keyname>Souza</keyname><forenames>Fillipe</forenames></author><author><keyname>Valle</keyname><forenames>Eduardo</forenames></author><author><keyname>Ch&#xe1;vez</keyname><forenames>Guillermo</forenames></author><author><keyname>Ara&#xfa;jo</keyname><forenames>Arnaldo</forenames></author></authors><title>Hue Histograms to Spatiotemporal Local Features for Action Recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the recent developments in spatiotemporal local features for action
recognition in video sequences, local color information has so far been
ignored. However, color has been proved an important element to the success of
automated recognition of objects and scenes. In this paper we extend the
space-time interest point descriptor STIP to take into account the color
information on the features' neighborhood. We compare the performance of our
color-aware version of STIP (which we have called HueSTIP) with the original
one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3760</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3760</id><created>2011-04-19</created><authors><author><keyname>Austrin</keyname><forenames>Per</forenames></author><author><keyname>Braverman</keyname><forenames>Mark</forenames></author><author><keyname>Chlamtac</keyname><forenames>Eden</forenames></author></authors><title>Inapproximability of NP-Complete Variants of Nash Equilibrium</title><categories>cs.CC cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent work of Hazan and Krauthgamer (SICOMP 2011), it was shown that
finding an $\eps$-approximate Nash equilibrium with near-optimal value in a
two-player game is as hard as finding a hidden clique of size $O(\log n)$ in
the random graph $G(n,1/2)$. This raises the question of whether a similar
intractability holds for approximate Nash equilibrium without such constraints.
We give evidence that the constraint of near-optimal value makes the problem
distinctly harder: a simple algorithm finds an optimal 1/2-approximate
equilibrium, while finding strictly better than 1/2-approximate equilibria is
as hard as the Hidden Clique problem. This is in contrast to the unconstrained
problem where more sophisticated algorithms, achieving better approximations,
are known.
  Unlike general Nash equilibrium, which is in PPAD, optimal (maximum value)
Nash equilibrium is NP-hard. We proceed to show that optimal Nash equilibrium
is just one of several known NP-hard problems related to Nash equilibrium, all
of which have approximate variants which are as hard as finding a planted
clique. In particular, we show this for approximate variants of the following
problems: finding a Nash equilibrium with value greater than $\eta$ (for any
$\eta&gt;0$, even when the best Nash equilibrium has value $1-\eta$), finding a
second Nash equilibrium, and finding a Nash equilibrium with small support.
  Finally, we consider the complexity of approximate pure Bayes Nash equilibria
in two-player games. Here we show that for general Bayesian games the problem
is NP-hard. For the special case where the distribution over types is uniform,
we give a quasi-polynomial time algorithm matched by a hardness result based on
the Hidden Clique problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3791</identifier>
 <datestamp>2012-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3791</id><created>2011-04-19</created><authors><author><keyname>Bonchi</keyname><forenames>Francesco</forenames></author><author><keyname>Esfandiar</keyname><forenames>Pooya</forenames></author><author><keyname>Gleich</keyname><forenames>David F.</forenames></author><author><keyname>Greif</keyname><forenames>Chen</forenames></author><author><keyname>Lakshmanan</keyname><forenames>Laks V. S.</forenames></author></authors><title>Fast matrix computations for pair-wise and column-wise commute times and
  Katz scores</title><categories>cs.SI cs.NA physics.soc-ph</categories><comments>35 pages, journal version of
  http://dx.doi.org/10.1007/978-3-642-18009-5_13 which has been submitted for
  publication. Please see
  http://www.cs.purdue.edu/homes/dgleich/publications/2011/codes/fast-katz/ for
  supplemental codes</comments><doi>10.1080/15427951.2012.625256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We first explore methods for approximating the commute time and Katz score
between a pair of nodes. These methods are based on the approach of matrices,
moments, and quadrature developed in the numerical linear algebra community.
They rely on the Lanczos process and provide upper and lower bounds on an
estimate of the pair-wise scores. We also explore methods to approximate the
commute times and Katz scores from a node to all other nodes in the graph.
Here, our approach for the commute times is based on a variation of the
conjugate gradient algorithm, and it provides an estimate of all the diagonals
of the inverse of a matrix. Our technique for the Katz scores is based on
exploiting an empirical localization property of the Katz matrix. We adopt
algorithms used for personalized PageRank computing to these Katz scores and
theoretically show that this approach is convergent. We evaluate these methods
on 17 real world graphs ranging in size from 1000 to 1,000,000 nodes. Our
results show that our pair-wise commute time method and column-wise Katz
algorithm both have attractive theoretical properties and empirical
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3792</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3792</id><created>2011-04-19</created><authors><author><keyname>Duan</keyname><forenames>J.</forenames></author><author><keyname>Soussen</keyname><forenames>Charles</forenames></author><author><keyname>Brie</keyname><forenames>David</forenames></author><author><keyname>Idier</keyname><forenames>Jerome</forenames></author><author><keyname>Wang</keyname><forenames>Y. -P.</forenames></author></authors><title>A sufficient condition on monotonic increase of the number of nonzero
  entry in the optimizer of L1 norm penalized least-square problem</title><categories>stat.ML cs.LG math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $\ell$-1 norm based optimization is widely used in signal processing,
especially in recent compressed sensing theory. This paper studies the solution
path of the $\ell$-1 norm penalized least-square problem, whose constrained
form is known as Least Absolute Shrinkage and Selection Operator (LASSO). A
solution path is the set of all the optimizers with respect to the evolution of
the hyperparameter (Lagrange multiplier). The study of the solution path is of
great significance in viewing and understanding the profile of the tradeoff
between the approximation and regularization terms. If the solution path of a
given problem is known, it can help us to find the optimal hyperparameter under
a given criterion such as the Akaike Information Criterion. In this paper we
present a sufficient condition on $\ell$-1 norm penalized least-square problem.
Under this sufficient condition, the number of nonzero entries in the optimizer
or solution vector increases monotonically when the hyperparameter decreases.
We also generalize the result to the often used total variation case, where the
$\ell$-1 norm is taken over the first order derivative of the solution vector.
We prove that the proposed condition has intrinsic connections with the
condition given by Donoho, et al \cite{Donoho08} and the positive cone
condition by Efron {\it el al} \cite{Efron04}. However, the proposed condition
does not need to assume the sparsity level of the signal as required by Donoho
et al's condition, and is easier to verify than Efron, et al's positive cone
condition when being used for practical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3801</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3801</id><created>2011-04-19</created><authors><author><keyname>Miki</keyname><forenames>Masaaki</forenames></author></authors><title>Extended force density method and its expressions</title><categories>cs.CE math-ph math.MP</categories><comments>Revised version of already published paper for J. IASS, submitted for
  Elsevier Engineering Structures but rejected</comments><journal-ref>M. Miki, K. Kawaguchi, Extended Force Density Method for
  Form-Finding of Tension Structures, J. of IASS. 51 (2010) 291-303</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this work can be divided into two parts. The first one is to
propose an extension of the force density method (FDM)(H.J. Schek, 1974), a
form-finding method for prestressed cable-net structures. The second one is to
present a review of various form-finding methods for tension structures, in the
relation with the extended FDM. In the first part, it is pointed out that the
original FDM become useless when it is applied to the prestressed structures
that consist of combinations of both tension and compression members, while the
FDM is usually advantageous in form-finding analysis of cable-nets. To
eliminate the limitation, a functional whose stationary problem simply
represents the FDM is firstly proposed. Additionally, the existence of a
variational principle in the FDM is also indicated. Then, the FDM is
extensively redefined by generalizing the formulation of the functional. As the
result, the generalized functionals enable us to find the forms of tension
structures that consist of combinations of both tension and compression
members, such as tensegrities and suspended membranes with compression struts.
In the second part, it is indicated the important role of three expressions
used by the description of the extended FDM, such as stationary problems of
functionals, the principle of virtual work and stationary conditions using
Nabla symbol. They can be commonly found in general problems of statics,
whereas the original FDM only provides a particular form of equilibrium
equation. Then, to demonstrate the advantage of such expressions, various
form-finding methods are reviewed and compared. As the result, the common
features and the differences over various form-finding methods are examined.
Finally, to give an overview of the reviewed methods, the corresponding
expressions are shown in the form of three tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3802</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3802</id><created>2011-04-19</created><updated>2011-06-12</updated><authors><author><keyname>Agarwal</keyname><forenames>Tarun</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Noncooperative Games for Autonomous Consumer Load Balancing over Smart
  Grid</title><categories>cs.GT</categories><comments>14 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, most consumers of electricity pay for their consumptions
according to a fixed rate. With the advancement of Smart Grid technologies,
large-scale implementation of variable-rate metering becomes more practical. As
a result, consumers will be able to control their electricity consumption in an
automated fashion, where one possible scheme is to have each individual
maximize its own utility as a noncooperative game. In this paper,
noncooperative games are formulated among the electricity consumers in Smart
Grid with two real-time pricing schemes, where the Nash equilibrium operation
points are investigated for their uniqueness and load balancing properties. The
first pricing scheme charges a price according to the average cost of
electricity borne by the retailer and the second one charges according to a
time-variant increasing-block price, where for each scheme, a zero-revenue
model and a constant-rate revenue model are considered. In addition, the
relationship between the studied games and certain competitive routing games
from the computer networking community, known as atomic flow games, is
established, for which it is shown that the proposed noncooperative game
formulation falls under the class of atomic splittable flow games. The Nash
equilibrium is shown to exist for four different combined cases corresponding
to the two pricing schemes and the two revenue models, and is unique for three
of the cases under certain conditions. It is further shown that both pricing
schemes lead to similar electricity loading patterns when consumers are only
interested in minimizing the electricity costs without any other profit
considerations. Finally, the conditions under which the increasing-block
pricing scheme is preferred over the average-cost based pricing scheme are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3806</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3806</id><created>2011-04-19</created><authors><author><keyname>Kolla</keyname><forenames>Alexandra</forenames></author><author><keyname>Makarychev</keyname><forenames>Konstantin</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author></authors><title>How to Play Unique Games against a Semi-Random Adversary</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the average case complexity of the Unique Games
problem. We propose a natural semi-random model, in which a unique game
instance is generated in several steps. First an adversary selects a completely
satisfiable instance of Unique Games, then she chooses an epsilon-fraction of
all edges, and finally replaces (&quot;corrupts&quot;) the constraints corresponding to
these edges with new constraints. If all steps are adversarial, the adversary
can obtain any (1-epsilon) satisfiable instance, so then the problem is as hard
as in the worst case. In our semi-random model, one of the steps is random, and
all other steps are adversarial. We show that known algorithms for unique games
(in particular, all algorithms that use the standard SDP relaxation) fail to
solve semi-random instances of Unique Games.
  We present an algorithm that with high probability finds a solution
satisfying a (1-delta) fraction of all constraints in semi-random instances (we
require that the average degree of the graph is Omega(log k). To this end, we
consider a new non-standard SDP program for Unique Games, which is not a
relaxation for the problem, and show how to analyze it. We present a new
rounding scheme that simultaneously uses SDP and LP solutions, which we believe
is of independent interest.
  Our result holds only for epsilon less than some absolute constant. We prove
that if epsilon &gt; 1/2, then the problem is hard in one of the models, the
result assumes the 2-to-2 conjecture.
  Finally, we study semi-random instances of Unique Games that are at most
(1-epsilon) satisfiable. We present an algorithm that with high probability,
distinguishes between the case when the instance is a semi-random instance and
the case when the instance is an (arbitrary) (1-delta) satisfiable instance if
epsilon &gt; c delta.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3808</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3808</id><created>2011-04-19</created><authors><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author><author><keyname>Tazari</keyname><forenames>Siamak</forenames></author></authors><title>Directed Nowhere Dense Classes of Graphs</title><categories>cs.DM cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of shallow directed minors and based on this a new
classification of classes of directed graphs which is diametric to existing
directed graph decompositions and width measures proposed in the literature.
  We then study in depth one type of classes of directed graphs which we call
nowhere crownful. The classes are very general as they include, on one hand,
all classes of directed graphs whose underlying undirected class is nowhere
dense, such as planar, bounded-genus, and $H$-minor-free graphs; and on the
other hand, also contain classes of high edge density whose underlying class is
not nowhere dense. Yet we are able to show that problems such as directed
dominating set and many others become fixed-parameter tractable on nowhere
crownful classes of directed graphs. This is of particular interest as these
problems are not tractable on any existing digraph measure for sparse classes.
  The algorithmic results are established via proving a structural equivalence
of nowhere crownful classes and classes of graphs which are directed uniformly
quasi-wide. This rather surprising result is inspired by Nesetril and Ossana de
Mendez (2008) and yet a different and more delicate proof is needed, which is a
significant part of our contribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3810</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3810</id><created>2011-04-19</created><authors><author><keyname>K&#xe4;rkk&#xe4;inen</keyname><forenames>Juha</forenames></author><author><keyname>Puglisi</keyname><forenames>Simon J.</forenames></author></authors><title>Fixed Block Compression Boosting in FM-Indexes</title><categories>cs.DS cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A compressed full-text self-index occupies space close to that of the
compressed text and simultaneously allows fast pattern matching and random
access to the underlying text. Among the best compressed self-indexes, in
theory and in practice, are several members of the FM-index family. In this
paper, we describe new FM-index variants that combine nice theoretical
properties, simple implementation and improved practical performance. Our main
result is a new technique called fixed block compression boosting, which is a
simpler and faster alternative to optimal compression boosting and implicit
compression boosting used in previous FM-indexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3833</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3833</id><created>2011-04-19</created><authors><author><keyname>Arias-Castro</keyname><forenames>Ery</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Noise Folding in Compressed Sensing</title><categories>cs.IT math.IT math.ST stat.TH</categories><doi>10.1109/LSP.2011.2159837</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The literature on compressed sensing has focused almost entirely on settings
where the signal is noiseless and the measurements are contaminated by noise.
In practice, however, the signal itself is often subject to random noise prior
to measurement. We briefly study this setting and show that, for the vast
majority of measurement schemes employed in compressed sensing, the two models
are equivalent with the important difference that the signal-to-noise ratio is
divided by a factor proportional to p/n, where p is the dimension of the signal
and n is the number of observations. Since p/n is often large, this leads to
noise folding which can have a severe impact on the SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3847</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3847</id><created>2011-04-19</created><authors><author><keyname>Fitzsimmons</keyname><forenames>Zachary</forenames></author><author><keyname>Flatland</keyname><forenames>Robin</forenames></author></authors><title>Collective Construction of 2D Block Structures with Holes</title><categories>cs.CG cs.RO</categories><comments>13 pages, 3 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present algorithms for collective construction systems in
which a large number of autonomous mobile robots trans- port modular building
elements to construct a desired structure. We focus on building block
structures subject to some physical constraints that restrict the order in
which the blocks may be attached to the structure. Specifically, we determine a
partial ordering on the blocks such that if they are attached in accordance
with this ordering, then (i) the structure is a single, connected piece at all
intermediate stages of construction, and (ii) no block is attached between two
other previously attached blocks, since such a space is too narrow for a robot
to maneuver a block into it. Previous work has consider this problem for
building 2D structures without holes. Here we extend this work to 2D structures
with holes. We accomplish this by modeling the problem as a graph orientation
problem and describe an O(n^2) algorithm for solving it. We also describe how
this partial ordering may be used in a distributed fashion by the robots to
coordinate their actions during the building process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3876</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3876</id><created>2011-04-19</created><authors><author><keyname>van Tol</keyname><forenames>Michiel W.</forenames></author><author><keyname>Koivisto</keyname><forenames>Juha</forenames></author></authors><title>Extending and Implementing the Self-adaptive Virtual Processor for
  Distributed Memory Architectures</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many-core architectures of the future are likely to have distributed memory
organizations and need fine grained concurrency management to be used
effectively. The Self-adaptive Virtual Processor (SVP) is an abstract
concurrent programming model which can provide this, but the model and its
current implementations assume a single address space shared memory. We
investigate and extend SVP to handle distributed environments, and discuss a
prototype SVP implementation which transparently supports execution on
heterogeneous distributed memory clusters over TCP/IP connections, while
retaining the original SVP programming model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3882</identifier>
 <datestamp>2012-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3882</id><created>2011-04-19</created><updated>2012-04-23</updated><authors><author><keyname>Ahmadi</keyname><forenames>Omran</forenames></author><author><keyname>Granger</keyname><forenames>Robert</forenames></author></authors><title>An efficient deterministic test for Kloosterman sum zeros</title><categories>math.NT cs.CR</categories><comments>17 pages, accepted to Mathematics of Computation. This is the final
  version with many improvements upon the first version. We also include new
  records for the computation of Kloosterman zeros</comments><msc-class>11L05, 14H52, 20D20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple deterministic test for deciding whether or not an element
$a \in \F_{2^n}^{\times}$ or $\F_{3^n}^{\times}$ is a zero of the corresponding
Kloosterman sum over these fields, and rigorously analyse its runtime. The test
seems to have been overlooked in the literature. The expected cost of the test
for binary fields is a single point-halving on an associated elliptic curve,
while for ternary fields the expected cost is one half of a point-thirding on
an associated elliptic curve. For binary fields of practical interest, this
represents an O(n) speedup over the previous fastest test. By repeatedly
invoking the test on random elements of $\F_{2^n}^{\times}$ we obtain the most
efficient probabilistic method to date to find non-trivial Kloosterman sum
zeros. The analysis depends on the distribution of Sylow $p$-subgroups in the
two families of associated elliptic curves, which we ascertain using a theorem
due to Howe.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3886</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3886</id><created>2011-04-19</created><authors><author><keyname>Xie</keyname><forenames>Hongmei</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Suter</keyname><forenames>Bruce W.</forenames></author></authors><title>General Linearized Polynomial Interpolation and Its Applications</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first propose a general interpolation algorithm in a free
module of a linearized polynomial ring, and then apply this algorithm to decode
several important families of codes, Gabidulin codes, KK codes and MV codes.
Our decoding algorithm for Gabidulin codes is different from the polynomial
reconstruction algorithm by Loidreau. When applied to decode KK codes, our
interpolation algorithm is equivalent to the Sudan-style list-1 decoding
algorithm proposed by K/&quot;otter and Kschischang for KK codes. The general
interpolation approach is also capable of solving the interpolation problem for
the list decoding of MV codes proposed by Mahdavifar and Vardy, and has a lower
complexity than solving linear equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3904</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3904</id><created>2011-04-19</created><authors><author><keyname>&#x160;ubelj</keyname><forenames>Lovro</forenames></author><author><keyname>Furlan</keyname><forenames>&#x160;tefan</forenames></author><author><keyname>Bajec</keyname><forenames>Marko</forenames></author></authors><title>An expert system for detecting automobile insurance fraud using social
  network analysis</title><categories>cs.AI cs.SI physics.soc-ph stat.ML</categories><journal-ref>Expert Syst. Appl. 38(1), 1039-1052 (2011)</journal-ref><doi>10.1016/j.eswa.2010.07.143</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article proposes an expert system for detection, and subsequent
investigation, of groups of collaborating automobile insurance fraudsters. The
system is described and examined in great detail, several technical
difficulties in detecting fraud are also considered, for it to be applicable in
practice. Opposed to many other approaches, the system uses networks for
representation of data. Networks are the most natural representation of such a
relational domain, allowing formulation and analysis of complex relations
between entities. Fraudulent entities are found by employing a novel assessment
algorithm, \textit{Iterative Assessment Algorithm} (\textit{IAA}), also
presented in the article. Besides intrinsic attributes of entities, the
algorithm explores also the relations between entities. The prototype was
evaluated and rigorously analyzed on real world data. Results show that
automobile insurance fraud can be efficiently detected with the proposed system
and that appropriate data representation is vital.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3905</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3905</id><created>2011-04-19</created><authors><author><keyname>Kneis</keyname><forenames>Joachim</forenames></author><author><keyname>Langer</keyname><forenames>Alexander</forenames></author><author><keyname>Rossmanith</keyname><forenames>Peter</forenames></author></authors><title>Courcelle's Theorem - A Game-Theoretic Approach</title><categories>cs.DS cs.GT cs.LO</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Courcelle's Theorem states that every problem definable in Monadic
Second-Order logic can be solved in linear time on structures of bounded
treewidth, for example, by constructing a tree automaton that recognizes or
rejects a tree decomposition of the structure. Existing, optimized software
like the MONA tool can be used to build the corresponding tree automata, which
for bounded treewidth are of constant size. Unfortunately, the constants
involved can become extremely large - every quantifier alternation requires a
power set construction for the automaton. Here, the required space can become a
problem in practical applications.
  In this paper, we present a novel, direct approach based on model checking
games, which avoids the expensive power set construction. Experiments with an
implementation are promising, and we can solve problems on graphs where the
automata-theoretic approach fails in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3911</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3911</id><created>2011-04-19</created><updated>2011-04-20</updated><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Information Exchange Limits in Cooperative MIMO Networks</title><categories>cs.IT math.IT</categories><comments>35 pages, 5 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concurrent presence of inter-cell and intra-cell interferences constitutes a
major impediment to reliable downlink transmission in multi-cell multiuser
networks. Harnessing such interferences largely hinges on two levels of
information exchange in the network: one from the users to the base-stations
(feedback) and the other one among the base-stations (cooperation). We
demonstrate that exchanging a finite number of bits across the network, in the
form of feedback and cooperation, is adequate for achieving the optimal
capacity scaling. We also show that the average level of information exchange
is independent of the number of users in the network. This level of information
exchange is considerably less than that required by the existing coordination
strategies which necessitate exchanging infinite bits across the network for
achieving the optimal sum-rate capacity scaling. The results provided rely on a
constructive proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3913</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3913</id><created>2011-04-19</created><updated>2011-11-28</updated><authors><author><keyname>Dwork</keyname><forenames>Cynthia</forenames></author><author><keyname>Hardt</keyname><forenames>Moritz</forenames></author><author><keyname>Pitassi</keyname><forenames>Toniann</forenames></author><author><keyname>Reingold</keyname><forenames>Omer</forenames></author><author><keyname>Zemel</keyname><forenames>Rich</forenames></author></authors><title>Fairness Through Awareness</title><categories>cs.CC cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study fairness in classification, where individuals are classified, e.g.,
admitted to a university, and the goal is to prevent discrimination against
individuals based on their membership in some group, while maintaining utility
for the classifier (the university). The main conceptual contribution of this
paper is a framework for fair classification comprising (1) a (hypothetical)
task-specific metric for determining the degree to which individuals are
similar with respect to the classification task at hand; (2) an algorithm for
maximizing utility subject to the fairness constraint, that similar individuals
are treated similarly. We also present an adaptation of our approach to achieve
the complementary goal of &quot;fair affirmative action,&quot; which guarantees
statistical parity (i.e., the demographics of the set of individuals receiving
any classification are the same as the demographics of the underlying
population), while treating similar individuals as similarly as possible.
Finally, we discuss the relationship of fairness to privacy: when fairness
implies privacy, and how tools developed in the context of differential privacy
may be applied to fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3917</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3917</id><created>2011-04-19</created><authors><author><keyname>Hung</keyname><forenames>Ling-Ju</forenames></author><author><keyname>Kloks</keyname><forenames>Ton</forenames></author><author><keyname>Villaamil</keyname><forenames>Fernando</forenames></author></authors><title>Black-and-white threshold graphs</title><categories>math.CO cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let k be a natural number. We introduce k-threshold graphs. We show that
there exists an O(n^3) algorithm for the recognition of k-threshold graphs for
each natural number k. k-Threshold graphs are characterized by a finite
collection of forbidden induced subgraphs. For the case k=2 we characterize the
partitioned 2-threshold graphs by forbidden induced subgraphs. We introduce
restricted -, and special 2-threshold graphs. We characterize both classes by
forbidden induced subgraphs. The restricted 2-threshold graphs coincide with
the switching class of threshold graphs. This provides a decomposition theorem
for the switching class of threshold graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3923</identifier>
 <datestamp>2013-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3923</id><created>2011-04-19</created><updated>2013-01-17</updated><authors><author><keyname>Laekhanukit</keyname><forenames>Bundit</forenames></author></authors><title>An improved approximation algorithm for the minimum-cost subset
  k-connected subgraph problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum-cost subset $k$-connected subgraph problem is a cornerstone
problem in the area of network design with vertex connectivity requirements. In
this problem, we are given a graph $G=(V,E)$ with costs on edges and a set of
terminals $T$. The goal is to find a minimum cost subgraph such that every pair
of terminals are connected by $k$ openly (vertex) disjoint paths. In this
paper, we present an approximation algorithm for the subset $k$-connected
subgraph problem which improves on the previous best approximation guarantee of
$O(k^2\log{k})$ by Nutov (FOCS 2009). Our approximation guarantee,
$\alpha(|T|)$, depends upon the number of terminals: [\alpha(|T|) \ \ =\ \
O(|T|^2) &amp; if |T| &lt; 2k O(k \log^2 k) &amp; if 2k\le |T| &lt; k^2 O(k \log k) &amp; if |T|
\ge k^2]
  So, when the number of terminals is {\em large enough}, the approximation
guarantee improves significantly. Moreover, we show that, given an
approximation algorithm for $|T|=k$, we can obtain almost the same
approximation guarantee for any instances with $|T|&gt; k$. This suggests that the
hardest instances of the problem are when $|T|\approx k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3925</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3925</id><created>2011-04-19</created><authors><author><keyname>Harada</keyname><forenames>Masaaki</forenames></author></authors><title>On the Residue Codes of Extremal Type II Z4-Codes of Lengths 32 and 40</title><categories>math.CO cs.IT math.IT</categories><comments>19 pages</comments><journal-ref>Discrete Math. 311 (2011), 2148-2157</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we determine the dimensions of the residue codes of extremal
Type II Z4-codes for lengths 32 and 40. We demonstrate that every binary doubly
even self-dual code of length 32 can be realized as the residue code of some
extremal Type II Z4-code. It is also shown that there is a unique extremal Type
II Z4-code of length 32 whose residue code has the smallest dimension 6 up to
equivalence. As a consequence, many new extremal Type II Z4-codes of lengths 32
and 40 are constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3927</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3927</id><created>2011-04-19</created><authors><author><keyname>Drescher</keyname><forenames>Christian</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Translation-based Constraint Answer Set Solving</title><categories>cs.AI</categories><comments>Self-archived version for IJCAI'11 Best Paper Track submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve constraint satisfaction problems through translation to answer set
programming (ASP). Our reformulations have the property that unit-propagation
in the ASP solver achieves well defined local consistency properties like arc,
bound and range consistency. Experiments demonstrate the computational value of
this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3929</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3929</id><created>2011-04-19</created><authors><author><keyname>Shen</keyname><forenames>Libin</forenames></author></authors><title>Understanding Exhaustive Pattern Learning</title><categories>cs.AI cs.LG</categories><comments>15 pages, 3 figures</comments><acm-class>I.2.7; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pattern learning in an important problem in Natural Language Processing
(NLP). Some exhaustive pattern learning (EPL) methods (Bod, 1992) were proved
to be flawed (Johnson, 2002), while similar algorithms (Och and Ney, 2004)
showed great advantages on other tasks, such as machine translation. In this
article, we first formalize EPL, and then show that the probability given by an
EPL model is constant-factor approximation of the probability given by an
ensemble method that integrates exponential number of models obtained with
various segmentations of the training data. This work for the first time
provides theoretical justification for the widely used EPL algorithm in NLP,
which was previously viewed as a flawed heuristic method. Better understanding
of EPL may lead to improved pattern learning algorithms in future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3931</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3931</id><created>2011-04-19</created><authors><author><keyname>Drescher</keyname><forenames>Christian</forenames></author><author><keyname>Eiter</keyname><forenames>Thomas</forenames></author><author><keyname>Fink</keyname><forenames>Michael</forenames></author><author><keyname>Krennwallner</keyname><forenames>Thomas</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Symmetry Breaking for Distributed Multi-Context Systems</title><categories>cs.LO</categories><comments>Self-archived version of LPNMR'11 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous nonmonotonic multi-context systems (MCS) permit different
logics to be used in different contexts, and link them via bridge rules. We
investigate the role of symmetry detection and symmetry breaking in such
systems to eliminate symmetric parts of the search space and, thereby, simplify
the evaluation process. We propose a distributed algorithm that takes a local
stance, i.e., computes independently the partial symmetries of a context and,
in order to construct potential symmetries of the whole, combines them with
those partial symmetries returned by neighbouring contexts. We prove the
correctness of our methods. We instantiate such symmetry detection and symmetry
breaking in a multi-context system with contexts that use answer set programs,
and demonstrate computational benefit on some recently proposed benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3947</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3947</id><created>2011-04-20</created><authors><author><keyname>Dolev</keyname><forenames>Shlomi</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, INRIA Saclay - Ile de France</affiliation></author></authors><title>Communication Optimalement Stabilisante sur Canaux non Fiables et non
  FIFO</title><categories>cs.DC</categories><proxy>ccsd</proxy><journal-ref>13es Rencontres Francophones sur les Aspects Algorithmiques de
  T\'el\'ecommunications (AlgoTel) (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A self-stabilizing protocol has the capacity to recover a legitimate behavior
whatever is its initial state. The majority of works in self-stabilization
assume a shared memory model or a communication using reliable and FIFO
channels. In this article, we interest in self-stabilizing systems using
bounded but non reliable and non FIFO channels. We propose a stabilizing
communication protocol with optimal fault resilience. In more details, this
protocol simulates a reliable and FIFO channel and ensures a minimal number of
looses, duplications, creations, and re-ordering of messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.3953</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.3953</id><created>2011-04-20</created><authors><author><keyname>Leung</keyname><forenames>Ming Lam</forenames></author></authors><title>Classical vs Quantum Games: Continuous-time Evolutionary Strategy
  Dynamics</title><categories>quant-ph cs.GT cs.IT math.IT</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper unifies the concepts of evolutionary games and quantum strategies.
First, we state the formulation and properties of classical evolutionary
strategies, with focus on the destinations of evolution in 2-player 2-strategy
games. We then introduce a new formalism of quantum evolutionary dynamics, and
give an example where an evolving quantum strategy gives reward if played
against its classical counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4013</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4013</id><created>2011-04-20</created><authors><author><keyname>Krotov</keyname><forenames>Denis S.</forenames></author><author><keyname>&#xd6;sterg&#xe5;rd</keyname><forenames>Patric R. J.</forenames></author><author><keyname>Pottonen</keyname><forenames>Olli</forenames></author></authors><title>On Optimal Binary One-Error-Correcting Codes of Lengths $2^m-4$ and
  $2^m-3$</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory.
  Data available at http://www.iki.fi/opottone/codes</comments><journal-ref>IEEE Trans. Inf. Theory 57(10) 2011, 6771-6779</journal-ref><doi>10.1109/TIT.2011.2147758</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Best and Brouwer [Discrete Math. 17 (1977), 235-245] proved that
triply-shortened and doubly-shortened binary Hamming codes (which have length
$2^m-4$ and $2^m-3$, respectively) are optimal. Properties of such codes are
here studied, determining among other things parameters of certain subcodes. A
utilization of these properties makes a computer-aided classification of the
optimal binary one-error-correcting codes of lengths 12 and 13 possible; there
are 237610 and 117823 such codes, respectively (with 27375 and 17513
inequivalent extensions). This completes the classification of optimal binary
one-error-correcting codes for all lengths up to 15. Some properties of the
classified codes are further investigated. Finally, it is proved that for any
$m \geq 4$, there are optimal binary one-error-correcting codes of length
$2^m-4$ and $2^m-3$ that cannot be lengthened to perfect codes of length
$2^m-1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4022</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4022</id><created>2011-04-20</created><authors><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Masuzawa</keyname><forenames>Toshimitsu</forenames><affiliation>Department of Information and Computer sciences Osaka University</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, INRIA Saclay - Ile de France</affiliation></author></authors><title>Auto-Stabilisation et Confinement de Fautes Malicieuses : Optimalit\'e
  du Protocole min+1</title><categories>cs.DC</categories><comments>13es Rencontres Francophones sur les Aspects Algorithmiques de
  T\'el\'ecommunications (AlgoTel) (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A self-stabilizing is naturally resilient to transients faults (that is,
faults of finite duration). Recently, a new class of protocol appears. These
protocols are self-stabilizing and are moreover resilient to a limited number
of permanent faults. In this article, we interest in self-stabilizing protocols
that tolerate very hard permanent faults: Byzantine faults. We introduce two
new scheme of Byzantine containment in self-stabilizing systems. We show that,
for the problem of BFS spanning tree construction, the well known
self-stabilizing protocol min+1 provides without significant modification the
best Byzantine containment with respect to these new schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4024</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4024</id><created>2011-04-20</created><authors><author><keyname>Pelizzola</keyname><forenames>Alessandro</forenames></author><author><keyname>Pretti</keyname><forenames>Marco</forenames></author><author><keyname>van Mourik</keyname><forenames>Jort</forenames></author></authors><title>Palette-colouring: a belief-propagation approach</title><categories>cond-mat.stat-mech cs.AI cs.DS math.CO</categories><comments>22 pages, 7 figures</comments><doi>10.1088/1742-5468/2011/05/P05010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a variation of the prototype combinatorial-optimisation problem
known as graph-colouring. Our optimisation goal is to colour the vertices of a
graph with a fixed number of colours, in a way to maximise the number of
different colours present in the set of nearest neighbours of each given
vertex. This problem, which we pictorially call &quot;palette-colouring&quot;, has been
recently addressed as a basic example of problem arising in the context of
distributed data storage. Even though it has not been proved to be NP complete,
random search algorithms find the problem hard to solve. Heuristics based on a
naive belief propagation algorithm are observed to work quite well in certain
conditions. In this paper, we build upon the mentioned result, working out the
correct belief propagation algorithm, which needs to take into account the
many-body nature of the constraints present in this problem. This method
improves the naive belief propagation approach, at the cost of increased
computational effort. We also investigate the emergence of a satisfiable to
unsatisfiable &quot;phase transition&quot; as a function of the vertex mean degree, for
different ensembles of sparse random graphs in the large size (&quot;thermodynamic&quot;)
limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4025</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4025</id><created>2011-04-20</created><authors><author><keyname>G&#xf6;kta&#x15f;</keyname><forenames>&#xdc;nal</forenames></author><author><keyname>Kapadia</keyname><forenames>Devendra</forenames></author></authors><title>Methods in Mathematica for Solving Ordinary Differential Equations</title><categories>cs.SC math.CA math.DS</categories><comments>13 pages</comments><journal-ref>Mathematical and Computational Applications, 16, 784-796, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An overview of the solution methods for ordinary differential equations in
the Mathematica function DSolve is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4026</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4026</id><created>2011-04-20</created><authors><author><keyname>G&#xf6;kta&#x15f;</keyname><forenames>&#xdc;nal</forenames></author><author><keyname>Hereman</keyname><forenames>Willy</forenames></author></authors><title>Symbolic Computation of Recursion Operators for Nonlinear
  Differential-Difference equations</title><categories>cs.SC math-ph math.MP nlin.SI</categories><journal-ref>Mathematical and Computational Applications, 16, 1-12, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm for the symbolic computation of recursion operators for systems
of nonlinear differential-difference equations (DDEs) is presented. Recursion
operators allow one to generate an infinite sequence of generalized symmetries.
The existence of a recursion operator therefore guarantees the complete
integrability of the DDE. The algo-rithm is based in part on the concept of
dilation invariance and uses our earlier algorithms for the symbolic
computation of conservation laws and generalized symmetries.
  The algorithm has been applied to a number of well-known DDEs, including the
Kac-van Moerbeke (Volterra), Toda, and Ablowitz-Ladik lattices, for which
recursion opera-tors are shown. The algorithm has been implemented in
Mathematica, a leading com-puter algebra system. The package
DDERecursionOperator.m is briefly discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4035</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4035</id><created>2011-04-20</created><authors><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Wireless MIMO Switching</title><categories>cs.IT cs.NI math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a generic switching problem, a switching pattern consists of a one-to-one
mapping from a set of inputs to a set of outputs (i.e., a permutation). We
propose and investigate a wireless switching framework in which a multi-antenna
relay is responsible for switching traffic among a set of $N$ stations. We
refer to such a relay as a MIMO switch. With beamforming and linear detection,
the MIMO switch controls which stations are connected to which stations. Each
beamforming matrix realizes a permutation pattern among the stations. We refer
to the corresponding permutation matrix as a switch matrix. By scheduling a set
of different switch matrices, full connectivity among the stations can be
established. In this paper, we focus on &quot;fair switching&quot; in which equal amounts
of traffic are to be delivered for all $N(N-1)$ ordered pairs of stations. In
particular, we investigate how the system throughput can be maximized. In
general, for large $N$ the number of possible switch matrices (i.e.,
permutations) is huge, making the scheduling problem combinatorially
challenging. We show that for N=4 and 5, only a subset of $N-1$ switch matrices
need to be considered in the scheduling problem to achieve good throughput. We
conjecture that this will be the case for large $N$ as well. This conjecture,
if valid, implies that for practical purposes, fair-switching scheduling is not
an intractable problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4039</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4039</id><created>2011-04-20</created><updated>2012-12-31</updated><authors><author><keyname>Noual</keyname><forenames>Mathilde</forenames></author></authors><title>Synchronism vs Asynchronism in Boolean networks</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that synchronism can significantly impact on network behaviours, in
particular by filtering unstable attractors induced by a constraint of
asynchronism. We investigate and classify the different possible impacts that
an addition of synchronism may have on the behaviour of a Boolean automata
network. We show how these relate to some strong specific structural
properties, thus supporting the idea that for most networks, synchronism only
shortcuts asynchronous trajectories. We end with a discussion on the close
relation that apparently exists between sensitivity to synchronism and
non-monotony.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4044</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4044</id><created>2011-04-20</created><authors><author><keyname>Noual</keyname><forenames>Mathilde</forenames></author></authors><title>General Iteration graphs and Boolean automata circuits</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is set in the field of regulation networks modeled by discrete
dynamical systems. It focuses on Boolean automata networks. In such networks,
there are many ways to update the states of every element. When this is done
deterministically, at each time step of a discretised time flow and according
to a predefined order, we say that the network is updated according to
block-sequential update schedule (blocks of elements are updated sequentially
while, within each block, the elements are updated synchronously). Many
studies, for the sake of simplicity and with some biologically motivated
reasons, have concentrated on networks updated with one particular
block-sequential update schedule (more often the synchronous/parallel update
schedule or the sequential update schedules). The aim of this paper is to give
an argument formally proven and inspired by biological considerations in favour
of the fact that the choice of a particular update schedule does not matter so
much in terms of the possible and likely dynamical behaviours that networks may
display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4053</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4053</id><created>2011-04-20</created><authors><author><keyname>Lenzerini</keyname><forenames>Maurizio</forenames></author><author><keyname>Savo</keyname><forenames>Domenico Fabio</forenames></author></authors><title>On the evolution of the instance level of DL-lite knowledge bases</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent papers address the issue of updating the instance level of knowledge
bases expressed in Description Logic following a model-based approach. One of
the outcomes of these papers is that the result of updating a knowledge base K
is generally not expressible in the Description Logic used to express K. In
this paper we introduce a formula-based approach to this problem, by revisiting
some research work on formula-based updates developed in the '80s, in
particular the WIDTIO (When In Doubt, Throw It Out) approach. We show that our
operator enjoys desirable properties, including that both insertions and
deletions according to such operator can be expressed in the DL used for the
original KB. Also, we present polynomial time algorithms for the evolution of
the instance level knowledge bases expressed in the most expressive Description
Logics of the DL-lite family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4056</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4056</id><created>2011-04-20</created><authors><author><keyname>Wang</keyname><forenames>Tao</forenames></author></authors><title>Cram\'er-Rao Bound for Localization with A Priori Knowledge on Biased
  Range Measurements</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>This paper has been accepted for publication in IEEE Transactions on
  Aerospace and Electronic Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives a general expression for the Cram\'er-Rao bound (CRB) of
wireless localization algorithms using range measurements subject to bias
corruption. Specifically, the a priori knowledge about which range measurements
are biased, and the probability density functions (PDF) of the biases are
assumed to be available. For each range measurement, the error due to
estimating the time-of-arrival of the detected signal is modeled as a Gaussian
distributed random variable with zero mean and known variance. In general, the
derived CRB expression can be evaluated numerically. An approximate CRB
expression is also derived when the bias PDF is very informative. Using these
CRB expressions, we study the impact of the bias distribution on the mean
square error (MSE) bound corresponding to the CRB. The analysis is corroborated
by numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4058</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4058</id><created>2011-04-20</created><authors><author><keyname>Ahn</keyname><forenames>Kook Jin</forenames></author><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author></authors><title>Laminar Families and Metric Embeddings: Non-bipartite Maximum Matching
  Problem in the Semi-Streaming Model</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the non-bipartite maximum matching problem in the
semi-streaming model. The maximum matching problem in the semi-streaming model
has received a significant amount of attention lately. While the problem has
been somewhat well solved for bipartite graphs, the known algorithms for
non-bipartite graphs use $2^{\frac1\epsilon}$ passes or $n^{\frac1\epsilon}$
time to compute a $(1-\epsilon)$ approximation. In this paper we provide the
first FPTAS (polynomial in $n,\frac1\epsilon$) for the problem which is
efficient in both the running time and the number of passes. We also show that
we can estimate the size of the matching in $O(\frac1\epsilon)$ passes using
slightly superlinear space.
  To achieve both results, we use the structural properties of the matching
polytope such as the laminarity of the tight sets and total dual integrality.
The algorithms are iterative, and are based on the fractional packing and
covering framework. However the formulations herein require exponentially many
variables or constraints. We use laminarity, metric embeddings and graph
sparsification to reduce the space required by the algorithms in between and
across the iterations. This is the first use of these ideas in the
semi-streaming model to solve a combinatorial optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4063</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4063</id><created>2011-04-20</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Contreras</keyname><forenames>Pedro</forenames></author></authors><title>Fast redshift clustering with the Baire (ultra) metric</title><categories>cs.IR astro-ph.IM stat.ML</categories><comments>14 pages, 6 figures</comments><msc-class>62H30, 85-08, 11S82</msc-class><acm-class>E.5; H.3; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Baire metric induces an ultrametric on a dataset and is of linear
computational complexity, contrasted with the standard quadratic time
agglomerative hierarchical clustering algorithm. We apply the Baire distance to
spectrometric and photometric redshifts from the Sloan Digital Sky Survey
using, in this work, about half a million astronomical objects. We want to know
how well the (more cos\ tly to determine) spectrometric redshifts can predict
the (more easily obtained) photometric redshifts, i.e. we seek to regress the
spectrometric on the photometric redshifts, and we develop a clusterwise
nearest neighbor regression procedure for this.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4078</identifier>
 <datestamp>2011-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4078</id><created>2011-04-20</created><authors><author><keyname>Gunther</keyname><forenames>Neil J.</forenames></author></authors><title>A Note on Parallel Algorithmic Speedup Bounds</title><categories>cs.DC cs.PF</categories><comments>5 pages, 1 figure</comments><acm-class>B.8; C.4; C.5.5; D.4.8; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A parallel program can be represented as a directed acyclic graph. An
important performance bound is the time to execute the critical path through
the graph. We show how this performance metric is related to Amdahl speedup and
the degree of average parallelism. These bounds formally exclude superlinear
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4081</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4081</id><created>2011-04-20</created><updated>2011-12-11</updated><authors><author><keyname>Gharan</keyname><forenames>Shayan Oveis</forenames></author><author><keyname>Vondr&#xe1;k</keyname><forenames>Jan</forenames></author></authors><title>On Variants of the Matroid Secretary Problem</title><categories>cs.DS cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a number of positive and negative results for variants of the
matroid secretary problem. Most notably, we design a constant-factor
competitive algorithm for the &quot;random assignment&quot; model where the weights are
assigned randomly to the elements of a matroid, and then the elements arrive
on-line in an adversarial order (extending a result of Soto \cite{Soto11}).
This is under the assumption that the matroid is known in advance. If the
matroid is unknown in advance, we present an $O(\log r \log n)$-approximation,
and prove that a better than $O(\log n / \log \log n)$ approximation is
impossible. This resolves an open question posed by Babaioff et al.
\cite{BIK07}.
  As a natural special case, we also consider the classical secretary problem
where the number of candidates $n$ is unknown in advance. If $n$ is chosen by
an adversary from $\{1,...,N\}$, we provide a nearly tight answer, by providing
an algorithm that chooses the best candidate with probability at least
$1/(H_{N-1}+1)$ and prove that a probability better than $1/H_N$ cannot be
achieved (where $H_N$ is the $N$-th harmonic number).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4107</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4107</id><created>2011-04-20</created><updated>2011-09-29</updated><authors><author><keyname>Krapivsky</keyname><forenames>P. L.</forenames></author><author><keyname>Redner</keyname><forenames>S.</forenames></author><author><keyname>Volovik</keyname><forenames>D.</forenames></author></authors><title>Reinforcement-Driven Spread of Innovations and Fads</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>4 pages, 2 columns, 5 figures, revtex 4-1 format; revised version has
  been expanded and put into iop format, with one figure added</comments><journal-ref>J. Stat. Mech. P12003, (2011)</journal-ref><doi>10.1088/1742-5468/2011/12/P12003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose kinetic models for the spread of permanent innovations and
transient fads by the mechanism of social reinforcement. Each individual can be
in one of M+1 states of awareness 0,1,2,...,M, with state M corresponding to
adopting an innovation. An individual with awareness k&lt;M increases to k+1 by
interacting with an adopter. Starting with a single adopter, the time for an
initially unaware population of size N to adopt a permanent innovation grows as
ln(N) for M=1, and as N^{1-1/M} for M&gt;1. The fraction of the population that
remains clueless about a transient fad after it has come and gone changes
discontinuously as a function of the fad abandonment rate lambda for M&gt;1. The
fad dies out completely in a time that varies non-monotonically with lambda.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4131</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4131</id><created>2011-04-20</created><updated>2012-04-23</updated><authors><author><keyname>Schmidt</keyname><forenames>Renate A.</forenames><affiliation>University of Manchester</affiliation></author><author><keyname>Tishkovsky</keyname><forenames>Dmitry</forenames><affiliation>University of Manchester</affiliation></author></authors><title>Automated Synthesis of Tableau Calculi</title><categories>cs.LO cs.SC</categories><comments>32 pages</comments><proxy>LMCS</proxy><acm-class>cs.SC</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 7,
  2011) lmcs:970</journal-ref><doi>10.2168/LMCS-7(2:6)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for synthesising sound and complete tableau
calculi. Given a specification of the formal semantics of a logic, the method
generates a set of tableau inference rules that can then be used to reason
within the logic. The method guarantees that the generated rules form a
calculus which is sound and constructively complete. If the logic can be shown
to admit finite filtration with respect to a well-defined first-order semantics
then adding a general blocking mechanism provides a terminating tableau
calculus. The process of generating tableau rules can be completely automated
and produces, together with the blocking mechanism, an automated procedure for
generating tableau decision procedures. For illustration we show the
workability of the approach for a description logic with transitive roles and
propositional intuitionistic logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4137</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4137</id><created>2011-04-20</created><updated>2011-12-20</updated><authors><author><keyname>Viglietta</keyname><forenames>Giovanni</forenames></author></authors><title>Searching Polyhedra by Rotating Half-Planes</title><categories>cs.CG</categories><comments>45 pages, 26 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Searchlight Scheduling Problem was first studied in 2D polygons, where
the goal is for point guards in fixed positions to rotate searchlights to catch
an evasive intruder. Here the problem is extended to 3D polyhedra, with the
guards now boundary segments who rotate half-planes of illumination. After
carefully detailing the 3D model, several results are established. The first is
a nearly direct extension of the planar one-way sweep strategy using what we
call exhaustive guards, a generalization that succeeds despite there being no
well-defined notion in 3D of planar &quot;clockwise rotation&quot;. Next follow two
results: every polyhedron with r&gt;0 reflex edges can be searched by at most r^2
suitably placed guards, whereas just r guards suffice if the polyhedron is
orthogonal. (Minimizing the number of guards to search a given polyhedron is
easily seen to be NP-hard.) Finally we show that deciding whether a given set
of guards has a successful search schedule is strongly NP-hard, and that
deciding if a given target area is searchable at all is strongly PSPACE-hard,
even for orthogonal polyhedra. A number of peripheral results are proved en
route to these central theorems, and several open problems remain for future
work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4141</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4141</id><created>2011-04-20</created><updated>2012-04-26</updated><authors><author><keyname>Goudarzi</keyname><forenames>Alireza</forenames></author><author><keyname>Teuscher</keyname><forenames>Christof</forenames></author><author><keyname>Gulbahce</keyname><forenames>Natali</forenames></author><author><keyname>Rohlf</keyname><forenames>Thimo</forenames></author></authors><title>Emergent Criticality Through Adaptive Information Processing in Boolean
  Networks</title><categories>cond-mat.dis-nn cs.NE nlin.AO</categories><comments>5 pages, 4 figures</comments><journal-ref>Physical Review Letters, 108(12):128702 (2012)</journal-ref><doi>10.1103/PhysRevLett.108.128702</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study information processing in populations of Boolean networks with
evolving connectivity and systematically explore the interplay between the
learning capability, robustness, the network topology, and the task complexity.
We solve a long-standing open question and find computationally that, for large
system sizes $N$, adaptive information processing drives the networks to a
critical connectivity $K_{c}=2$. For finite size networks, the connectivity
approaches the critical value with a power-law of the system size $N$. We show
that network learning and generalization are optimized near criticality, given
task complexity and the amount of information provided threshold values. Both
random and evolved networks exhibit maximal topological diversity near $K_{c}$.
We hypothesize that this supports efficient exploration and robustness of
solutions. Also reflected in our observation is that the variance of the values
is maximal in critical network populations. Finally, we discuss implications of
our results for determining the optimal topology of adaptive dynamical networks
that solve computational tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4153</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4153</id><created>2011-04-20</created><authors><author><keyname>Rifai</keyname><forenames>Salah</forenames></author><author><keyname>Muller</keyname><forenames>Xavier</forenames></author><author><keyname>Glorot</keyname><forenames>Xavier</forenames></author><author><keyname>Mesnil</keyname><forenames>Gregoire</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames></author></authors><title>Learning invariant features through local space contraction</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper a novel approach for training deterministic
auto-encoders. We show that by adding a well chosen penalty term to the
classical reconstruction cost function, we can achieve results that equal or
surpass those attained by other regularized auto-encoders as well as denoising
auto-encoders on a range of datasets. This penalty term corresponds to the
Frobenius norm of the Jacobian matrix of the encoder activations with respect
to the input. We show that this penalty term results in a localized space
contraction which in turn yields robust features on the activation layer.
Furthermore, we show how this penalty term is related to both regularized
auto-encoders and denoising encoders and how it can be seen as a link between
deterministic and non-deterministic auto-encoders. We find empirically that
this penalty helps to carve a representation that better captures the local
directions of variation dictated by the data, corresponding to a
lower-dimensional non-linear manifold, while being more invariant to the vast
majority of directions orthogonal to the manifold. Finally, we show that by
using the learned features to initialize a MLP, we achieve state of the art
classification error on a range of datasets, surpassing other methods of
pre-training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4154</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4154</id><created>2011-04-20</created><authors><author><keyname>Khabbazibasmenj</keyname><forenames>Arash</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author></authors><title>Power Allocation Based on SEP Minimization in Two-Hop Decode-and-Forward
  Relay Networks</title><categories>cs.IT math.IT</categories><comments>27 pages, 5 figures, submitted to the IEEE Trans. Signal Processing
  in Feb. 2011</comments><journal-ref>A. Khabbazibasmenj and S.A. Vorobyov, &quot;Power allocation based on
  SEP minimization in two-hop decode-and-forward relay networks,&quot; IEEE Trans.
  Signal Processing, vol. 59, no. 8, pp. 3954-3963, Aug. 2011</journal-ref><doi>10.1109/TSP.2011.2150221</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of optimal power allocation among the relays in a two-hop
decode-and-forward cooperative relay network with independent Rayleigh fading
channels is considered. It is assumed that only the relays that decode the
source message correctly contribute in data transmission. Moreover, only the
knowledge of statistical channel state information is available. A new simple
closed-form expression for the average symbol error probability is derived.
Based on this expression, a new power allocation method that minimizes the
average symbol error probability and takes into account the constraints on the
total average power of all the relay nodes and maximum instant power of each
relay node is developed. The corresponding optimization problem is shown to be
a convex problem that can be solved using interior point methods. However, an
approximate closed-form solution is obtained and shown to be practically more
appealing due to significant complexity reduction. The accuracy of the
approximation is discussed. Moreover, the so obtained closed-form solution
gives additional insights into the optimal power allocation problem. Simulation
results confirm the improved performance of the proposed power allocation
scheme as compared to other schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4155</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4155</id><created>2011-04-20</created><authors><author><keyname>Chen</keyname><forenames>Zengmao</forenames></author><author><keyname>Wang</keyname><forenames>Cheng-Xiang</forenames></author><author><keyname>Hong</keyname><forenames>Xuemin</forenames></author><author><keyname>Thompson</keyname><forenames>John</forenames></author><author><keyname>Vorobyov</keyname><forenames>Sergiy A.</forenames></author><author><keyname>Zhao</keyname><forenames>Feng</forenames></author><author><keyname>Xiao</keyname><forenames>Hailin</forenames></author><author><keyname>Ge</keyname><forenames>Xiaohu</forenames></author></authors><title>Interference Mitigation for Cognitive Radio MIMO Systems Based on
  Practical Precoding</title><categories>cs.IT math.IT</categories><comments>12 pages, 4 figures, submitted to the IEEE Trans. Wireless
  Communications in April 2011</comments><journal-ref>Z. Chen, C.-X. Wang, X. Hong, J. Thompson, S.A. Vorobyov, and et
  al, &quot;Interference mitigation for cognitive radio MIMO systems based on
  practical precoding,&quot; Invited Paper, Physical Communication, vol. 9, pp.
  308-315, Dec. 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose two subspace-projection-based precoding schemes,
namely, full-projection (FP)- and partial-projection (PP)-based precoding, for
a cognitive radio multiple-input multiple-output (CR-MIMO) network to mitigate
its interference to a primary time-division-duplexing (TDD) system. The
proposed precoding schemes are capable of estimating interference channels
between CR and primary networks, and incorporating the interference from the
primary to the CR system into CR precoding via a novel sensing approach. Then,
the CR performance and resulting interference of the proposed precoding schemes
are analyzed and evaluated. By fully projecting the CR transmission onto a null
space of the interference channels, the FP-based precoding scheme can
effectively avoid interfering the primary system with boosted CR throughput.
While, the PP-based scheme is able to further improve the CR throughput by
partially projecting its transmission onto the null space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4160</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4160</id><created>2011-04-20</created><authors><author><keyname>Xiao</keyname><forenames>Mingyu</forenames></author><author><keyname>Kloks</keyname><forenames>Ton</forenames></author><author><keyname>Poon</keyname><forenames>Sheung-Hung</forenames></author></authors><title>New parameterized algorithms for edge dominating set</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An edge dominating set of a graph G=(V,E) is a subset M of edges in the graph
such that each edge in E-M is incident with at least one edge in M. In an
instance of the parameterized edge dominating set problem we are given a graph
G=(V,E) and an integer k and we are asked to decide whether G has an edge
dominating set of size at most k. In this paper we show that the parameterized
edge dominating set problem can be solved in O^*(2.3147^k) time and polynomial
space. We show that this problem can be reduced to a quadratic kernel with
O(k^3) edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4163</identifier>
 <datestamp>2012-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4163</id><created>2011-04-20</created><authors><author><keyname>Pandey</keyname><forenames>Umesh Kumar</forenames></author><author><keyname>Pal</keyname><forenames>Saurabh</forenames></author></authors><title>Data Mining : A prediction of performer or underperformer using
  classification</title><categories>cs.DB cs.IR</categories><comments>5 pages, 1 figure</comments><journal-ref>(IJCSIT) International Journal of Computer Science and Information
  Technology, Vol. 2(2), 2011, 686-690</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now a day's students have a large set of data having precious information
hidden. Data mining technique can help to find this hidden information. In this
paper, data mining techniques name Byes classification method is used on these
data to help an institution. Institutions can find those students who are
consistently perform well. This study will help to institution reduce the drop
put ratio to a significant level and improve the performance level of the
institution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4164</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4164</id><created>2011-04-20</created><authors><author><keyname>Pandey</keyname><forenames>Umesh Kumar</forenames></author><author><keyname>Pal</keyname><forenames>Saurabh</forenames></author></authors><title>A Data Mining view on Class Room Teaching Language</title><categories>cs.DB cs.IR</categories><comments>6 pages, 3 figures</comments><journal-ref>(IJCSI) International Journal of Computer Science Issue, Vol. 8,
  Issue 2, March -2011, 277-282, ISSN:1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From ancient period in India, educational institution embarked to use class
room teaching. Where a teacher explains the material and students understand
and learn the lesson. There is no absolute scale for measuring knowledge but
examination score is one scale which shows the performance indicator of
students. So it is important that appropriate material is taught but it is
vital that while teaching which language is chosen, class notes must be
prepared and attendance. This study analyses the impact of language on the
presence of students in class room. The main idea is to find out the support,
confidence and interestingness level for appropriate language and attendance in
the classroom. For this purpose association rule is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4168</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4168</id><created>2011-04-21</created><authors><author><keyname>Liu</keyname><forenames>Wei</forenames></author><author><keyname>Ribeiro</keyname><forenames>Eraldo</forenames></author></authors><title>A Meshless Method for Variational Nonrigid 2-D Shape Registration</title><categories>cs.CV</categories><comments>60 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for nonrigid registration of 2-D geometric shapes. Our
contribution is twofold. First, we extend the classic chamfer-matching energy
to a variational functional. Secondly, we introduce a meshless deformation
model that can handle significant high-curvature deformations. We represent 2-D
shapes implicitly using distance transforms, and registration error is defined
based on the shape contours' mutual distances. In addition, we model global
shape deformation as an approximation blended from local deformation fields
using partition-of-unity. The global deformation field is regularized by
penalizing inconsistencies between local fields. The representation can be made
adaptive to shape's contour, leading to registration that is both flexible and
efficient. Finally, registration is achieved by minimizing a variational
chamfer-energy functional combined with the consistency regularizer. We
demonstrate the effectiveness of our method on a number of experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4190</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4190</id><created>2011-04-21</created><updated>2011-07-22</updated><authors><author><keyname>Basavaraju</keyname><forenames>Manu</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Rajendraprasad</keyname><forenames>Deepak</forenames></author><author><keyname>Ramaswamy</keyname><forenames>Arunselvan</forenames></author></authors><title>Rainbow Connection Number of Graph Power and Graph Products</title><categories>math.CO cs.DM</categories><comments>15 pages. This is a revised (journal-ready) version</comments><msc-class>05C15, 05C40, 05C76 (Primary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rainbow connection number, rc(G), of a connected graph G is the minimum
number of colors needed to color its edges so that every pair of vertices is
connected by at least one path in which no two edges are colored the same (Note
that the coloring need not be proper). In this paper we study the rainbow
connection number with respect to three important graph product operations
(namely cartesian product, lexicographic product and strong product) and the
operation of taking the power of a graph. In this direction, we show that if G
is a graph obtained by applying any of the operations mentioned above on
non-trivial graphs, then rc(G) &lt;= 2r(G)+c, where r(G) denotes the radius of G
and c \in {0,1,2}. In general the rainbow connection number of a bridgeless
graph can be as high as the square of its radius [Basavaraju et. al, 2010].
This is an attempt to identify some graph classes which have rainbow connection
number very close to the obvious lower bound of diameter (and thus the radius).
The bounds reported are tight upto additive constants. The proofs are
constructive and hence yield polynomial time (2 + 2/r(G))-factor approximation
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4203</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4203</id><created>2011-04-21</created><authors><author><keyname>Gawrychowski</keyname><forenames>Pawel</forenames></author></authors><title>Pattern matching in Lempel-Ziv compressed strings: fast, simple, and
  deterministic</title><categories>cs.DS</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Countless variants of the Lempel-Ziv compression are widely used in many
real-life applications. This paper is concerned with a natural modification of
the classical pattern matching problem inspired by the popularity of such
compression methods: given an uncompressed pattern s[1..m] and a Lempel-Ziv
representation of a string t[1..N], does s occur in t? Farach and Thorup gave a
randomized O(nlog^2(N/n)+m) time solution for this problem, where n is the size
of the compressed representation of t. We improve their result by developing a
faster and fully deterministic O(nlog(N/n)+m) time algorithm with the same
space complexity. Note that for highly compressible texts, log(N/n) might be of
order n, so for such inputs the improvement is very significant. A (tiny)
fragment of our method can be used to give an asymptotically optimal solution
for the substring hashing problem considered by Farach and Muthukrishnan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4204</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4204</id><created>2011-04-21</created><authors><author><keyname>Kumar</keyname><forenames>Snehasish</forenames></author><author><keyname>Rai</keyname><forenames>S. C.</forenames></author><author><keyname>Mall</keyname><forenames>Rajib</forenames></author><author><keyname>Pradhan</keyname><forenames>Sateesh K.</forenames></author></authors><title>MiCi: A Novel Micro-Level Temporal Channel Imploration for Mobile Hosts</title><categories>cs.NI</categories><comments>7 pages, 14 figures</comments><journal-ref>InterJRI Computer Science and Networking , Volume 2 , Issue 1 ,
  august 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exponential increase of multimedia services by the mobile users requires
seamless connectivity with cost effective Quality of Service QoS provisioning.
For providing such on-demand QoS, the network needs to utilize the radio
channels among the Mobile Hosts (MHs) effectively. We use vector genetic
algorithm VGA for temporal imploration of sharable channel(s) from the
neighbouring cells to fulfill the needs of a cell. We propose a new micro-level
temporal channel imploration mechanism MiCi, which promptly allocates available
borrowing channel s of the neighbouring cell(s) to the needy cell. The novelty
of MiCi is scalability, high availability, and on demand allocation of the
channels to the desired cells. The performance of our model has been tested by
simulation against a standard FCA scheme as well as a Greedy Borrowing
Heuristic. In all the test cases MiCi shows promising results in comparison to
both the schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4208</identifier>
 <datestamp>2012-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4208</id><created>2011-04-21</created><updated>2012-01-09</updated><authors><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author><author><keyname>Lehrenfeld</keyname><forenames>Christoph</forenames></author><author><keyname>Schoeberl</keyname><forenames>Joachim</forenames></author></authors><title>Computer Algebra meets Finite Elements: an Efficient Implementation for
  Maxwell's Equations</title><categories>math.NA cs.SC</categories><comments>16 pages, 1 figure, 1 table; Springer Wien, ISBN 978-3-7091-0793-5</comments><journal-ref>Numerical and Symbolic Scientific Computing: Progress and
  Prospects (Texts &amp; Monographs in Symbolic Computation, Volume 1) pp. 105-121,
  2012</journal-ref><doi>10.1007/978-3-7091-0794-2_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the numerical discretization of the time-domain Maxwell's
equations with an energy-conserving discontinuous Galerkin finite element
formulation. This particular formulation allows for higher order approximations
of the electric and magnetic field. Special emphasis is placed on an efficient
implementation which is achieved by taking advantage of recurrence properties
and the tensor-product structure of the chosen shape functions. These
recurrences have been derived symbolically with computer algebra methods
reminiscent of the holonomic systems approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4209</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4209</id><created>2011-04-21</created><updated>2012-02-24</updated><authors><author><keyname>Ren</keyname><forenames>Fu-Xin</forenames></author><author><keyname>Cheng</keyname><forenames>Xue-Qi</forenames></author><author><keyname>Shen</keyname><forenames>Hua-Wei</forenames></author></authors><title>Modeling the clustering in citation networks</title><categories>physics.soc-ph cs.DL cs.SI</categories><journal-ref>Physica A: Statistical Mechanics and its Applications, 391:
  3533-3539, (2012)</journal-ref><doi>10.1016/j.physa.2012.02.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the study of citation networks, a challenging problem is modeling the
high clustering. Existing studies indicate that the promising way to model the
high clustering is a copying strategy, i.e., a paper copies the references of
its neighbour as its own references. However, the line of models highly
underestimates the number of abundant triangles observed in real citation
networks and thus cannot well model the high clustering. In this paper, we
point out that the failure of existing models lies in that they do not capture
the connecting patterns among existing papers. By leveraging the knowledge
indicated by such connecting patterns, we further propose a new model for the
high clustering in citation networks. Experiments on two real world citation
networks, respectively from a special research area and a multidisciplinary
research area, demonstrate that our model can reproduce not only the power-law
degree distribution as traditional models but also the number of triangles, the
high clustering coefficient and the size distribution of co-citation clusters
as observed in these real networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4217</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4217</id><created>2011-04-21</created><updated>2013-09-26</updated><authors><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>Preprocessing for Treewidth: A Combinatorial Analysis through
  Kernelization</title><categories>cs.DS cs.CC</categories><comments>An extended abstract of this paper appeared in the proceedings of
  ICALP 2011. This is the full version containing all proofs, along with some
  improvements to the results of the extended abstract. This paper will appear
  in the SIAM Journal on Discrete Mathematics. The SIAM version will contain
  slight improvements to this arXiv version; for example, revised figures and
  typesetting</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of treewidth plays an important role in theoretical and practical
studies of graph problems. It has been recognized that, especially in practical
environments, when computing the treewidth of a graph it is invaluable to first
apply an array of preprocessing rules that simplify and shrink it. This work
seeks to prove rigorous performance guarantees for such preprocessing rules,
both known and new ones, by studying them in the framework of kernelization
from parameterized complexity.
  It is known that the NP-complete problem of determining whether a given graph
G has treewidth at most k admits no polynomial-time preprocessing algorithm
that reduces any input instance to size polynomial in k, unless NP is in
coNP/poly and the polynomial hierarchy collapses to its third level. In this
paper we therefore consider structural graph measures larger than treewidth,
and determine whether efficient preprocessing can shrink the instance size to a
polynomial in such a parameter value.
  We prove that given an instance (G,k) of treewidth we can efficiently reduce
its size to O(fvs(G)^4) vertices, where fvs(G) is the size of a minimum
feedback vertex set in G. We can also prove a size reduction to O(vc(G)^3)
vertices, where vc(G) is the size of a minimum vertex cover. Phrased in the
language of parameterized complexity, we show that Treewidth has a polynomial
kernel when parameterized by the size of a given feedback vertex set, and also
by the size of a vertex cover. In contrast we show that Treewidth parameterized
by the vertex-deletion distance to a single clique, and Weighted Treewidth
parameterized by the size of a vertex cover, do not admit polynomial
kernelizations unless NP is in coNP/poly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4229</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4229</id><created>2011-04-21</created><updated>2013-09-27</updated><authors><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>Data Reduction for Graph Coloring Problems</title><categories>cs.DS cs.CC</categories><comments>Author-accepted manuscript of the article that will appear in the FCT
  2011 special issue of Information &amp; Computation</comments><acm-class>F.2.2; G.2.2</acm-class><doi>10.1016/j.ic.2013.08.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the kernelization complexity of graph coloring problems
with respect to certain structural parameterizations of the input instances. We
are interested in how well polynomial-time data reduction can provably shrink
instances of coloring problems, in terms of the chosen parameter. It is well
known that deciding 3-colorability is already NP-complete, hence parameterizing
by the requested number of colors is not fruitful. Instead, we pick up on a
research thread initiated by Cai (DAM, 2003) who studied coloring problems
parameterized by the modification distance of the input graph to a graph class
on which coloring is polynomial-time solvable; for example parameterizing by
the number k of vertex-deletions needed to make the graph chordal. We obtain
various upper and lower bounds for kernels of such parameterizations of
q-Coloring, complementing Cai's study of the time complexity with respect to
these parameters.
  Our results show that the existence of polynomial kernels for q-Coloring
parameterized by the vertex-deletion distance to a graph class F is strongly
related to the existence of a function f(q) which bounds the number of vertices
which are needed to preserve the NO-answer to an instance of q-List-Coloring on
F.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4247</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4247</id><created>2011-04-21</created><authors><author><keyname>Du</keyname><forenames>Qinghe</forenames></author><author><keyname>Zhang</keyname><forenames>Xi</forenames></author></authors><title>QoS-Aware Base-Station Selections for Distributed MIMO Links in
  Broadband Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the QoS-aware BS-selection schemes for the distributed wireless
MIMO links, which aim at minimizing the BS usages and reducing the interfering
range, while satisfying diverse statistical delay-QoS constraints characterized
by the delay-bound violation probability and the effective capacity technique.
In particular, based on the channel state information (CSI) and QoS
requirements, a subset of BS with variable cardinality for the distributed MIMO
transmission is dynamically selected, where the selections are controlled by a
central server. For the single-user scenario, we develop two optimization
frameworks, respectively, to derive the efficient BS-selection schemes and the
corresponding resource allocation algorithms. One framework uses the
incremental BS-selection and time-sharing (IBS-TS) strategies, and the other
employs the ordered-gain based BS-selection and probabilistic transmissions
(OGBS-PT). The IBS-TS framework can yield better performance, while the scheme
developed under the OGBS-PT framework is easier to implement. For the
multi-user scenario, we propose the optimization framework applying the
priority BS-selection, block-diagonalization precoding, and probabilistic
transmission (PBS-BD-PT) techniques. We also propose the optimization framework
applying the priority BS-selection, time-division-multiple-access, and
probabilistic transmission (PBS-TDMA-PT) techniques. We derive the optimal
transmission schemes for all the aforementioned frameworks, respectively. Also
conducted is a set of simulation evaluations which compare our proposed schemes
with several baseline schemes and show the impact of the delay-QoS
requirements, transmit power, and traffic loads on the performances of BS
selections for distributed MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4249</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4249</id><created>2011-04-21</created><updated>2011-07-07</updated><authors><author><keyname>Dette</keyname><forenames>Tilman</forenames></author><author><keyname>Pauls</keyname><forenames>Scott</forenames></author><author><keyname>Rockmore</keyname><forenames>Daniel N.</forenames></author></authors><title>Robustness and Contagion in the International Financial Network</title><categories>q-fin.GN cs.SI physics.soc-ph</categories><comments>18 pages, 7 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent financial crisis of 2008 and the 2011 indebtedness of Greece
highlight the importance of understanding the structure of the global financial
network. In this paper we set out to analyze and characterize this network, as
captured by the IMF Coordinated Portfolio Investment Survey (CPIS), in two
ways. First, through an adaptation of the &quot;error and attack&quot; methodology [1],
we show that the network is of the &quot;robust-yet-fragile&quot; type, a topology found
in a wide variety of evolved networks. We compare these results against four
common null-models, generated only from first-order statistics of the empirical
data. In addition, we suggest a fifth, log-normal model, which generates
networks that seem to match the empirical one more closely. Still, this model
does not account for several higher order network statistics, which reenforces
the added value of the higher-order analysis. Second, using loss-given-default
dynamics [2], we model financial interdependence and potential cascading of
financial distress through the network. Preliminary simulations indicate that
default by a single relatively small country like Greece can be absorbed by the
network, but that default in combination with defaults of other PIGS countries
(Portugal, Ireland, and Spain) could lead to a massive extinction cascade in
the global economy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4251</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4251</id><created>2011-04-21</created><authors><author><keyname>Chattopadhyay</keyname><forenames>Ishanu</forenames></author></authors><title>Distributed Self-Organization Of Swarms To Find Globally
  $\epsilon$-Optimal Routes To Locally Sensed Targets</title><categories>cs.RO cs.MA cs.SY math.OC</categories><comments>38 pages 10 Figures</comments><acm-class>I.2.9; G.1.6; F.1.1; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of near-optimal distributed path planning to locally sensed
targets is investigated in the context of large swarms. The proposed algorithm
uses only information that can be locally queried, and rigorous theoretical
results on convergence, robustness, scalability are established, and effect of
system parameters such as the agent-level communication radius and agent
velocities on global performance is analyzed. The fundamental philosophy of the
proposed approach is to percolate local information across the swarm, enabling
agents to indirectly access the global context. A gradient emerges, reflecting
the performance of agents, computed in a distributed manner via local
information exchange between neighboring agents. It is shown that to follow
near-optimal routes to a target which can be only sensed locally, and whose
location is not known a priori, the agents need to simply move towards its
&quot;best&quot; neighbor, where the notion of &quot;best&quot; is obtained by computing the
state-specific language measure of an underlying probabilistic finite state
automata. The theoretical results are validated in high-fidelity simulation
experiments, with excess of $10^4$ agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4260</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4260</id><created>2011-04-21</created><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author></authors><title>A Robust Artificial Noise Aided Transmit Design for Miso Secrecy</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in ICASSP 2011, May 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers an artificial noise (AN) aided secrecy rate maximization
(SRM) problem for a multi-input single-output (MISO) channel overheard by
multiple single-antenna eavesdroppers. We assume that the transmitter has
perfect knowledge about the channel to the desired user but imperfect knowledge
about the channels to the eavesdroppers. Therefore, the resultant SRM problem
is formulated in the way that we maximize the worst-case secrecy rate by
jointly designing the signal covariance ${\bf W}$ and the AN covariance ${\bf
\Sigma}$. However, such a worst-case SRM problem turns out to be hard to
optimize, since it is nonconvex in ${\bf W}$ and ${\bf \Sigma}$ jointly.
Moreover, it falls into the class of semi-infinite optimization problems.
Through a careful reformulation, we show that the worst-case SRM problem can be
handled by performing a one-dimensional line search in which a sequence of
semidefinite programs (SDPs) are involved. Moreover, we also show that the
optimal ${\bf W}$ admits a rank-one structure, implying that transmit
beamforming is secrecy rate optimal under the considered scenario. Simulation
results are provided to demonstrate the robustness and effectiveness of the
proposed design compared to a non-robust AN design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4266</identifier>
 <datestamp>2011-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4266</id><created>2011-04-21</created><updated>2011-11-30</updated><authors><author><keyname>De Lara</keyname><forenames>Michel</forenames><affiliation>CERMICS</affiliation></author><author><keyname>Anaya</keyname><forenames>Eladio Ocana</forenames><affiliation>IMCA</affiliation></author><author><keyname>Oliveros--Ramos</keyname><forenames>Ricardo</forenames></author><author><keyname>Tam</keyname><forenames>Jorge</forenames></author></authors><title>Ecosystem Viable Yields</title><categories>math.OC cs.SY q-bio.PE</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The World Summit on Sustainable Development (Johannesburg, 2002) encouraged
the application of the ecosystem approach by 2010. However, at the same Summit,
the signatory States undertook to restore and exploit their stocks at maximum
sustainable yield (MSY), a concept and practice without ecosystemic dimension,
since MSY is computed species by species, on the basis of a monospecific model.
Acknowledging this gap, we propose a definition of &quot;ecosystem viable yields&quot;
(EVY) as yields compatible i) with guaranteed biological safety levels for all
time and ii) with an ecosystem dynamics. To the difference of MSY, this notion
is not based on equilibrium, but on viability theory, which offers advantages
for robustness. For a generic class of multispecies models with harvesting, we
provide explicit expressions for the EVY. We apply our approach to the
anchovy--hake couple in the Peruvian upwelling ecosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4279</identifier>
 <datestamp>2013-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4279</id><created>2011-04-21</created><updated>2013-04-03</updated><authors><author><keyname>Ordyniak</keyname><forenames>Sebastian</forenames></author><author><keyname>Paulusma</keyname><forenames>Daniel</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Satisfiability of Acyclic and Almost Acyclic CNF Formulas</title><categories>cs.DS</categories><comments>Extended abstracts appeared in the Proceedings of FSTTCS 2010 and SAT
  2011. The latter corresponds to revision 1 of this arXiv paper
  (arXiv:1104.4279v1)</comments><journal-ref>Theoretical Computer Science, vol. 481, pp. 85-99, 2013</journal-ref><doi>10.1016/j.tcs.2012.12.039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Satisfiability (SAT) problem for CNF formulas with
{\beta}-acyclic hypergraphs can be solved in polynomial time by using a special
type of Davis-Putnam resolution in which each resolvent is a subset of a parent
clause. We extend this class to CNF formulas for which this type of
Davis-Putnam resolution still applies and show that testing membership in this
class is NP-complete. We compare the class of {\beta}-acyclic formulas and this
superclass with a number of known polynomial formula classes. We then study the
parameterized complexity of SAT for &quot;almost&quot; {\beta}-acyclic instances, using
as parameter the formula's distance from being {\beta}-acyclic. As distance we
use the size of a smallest strong backdoor set and the {\beta}-hypertree width.
As a by-product we obtain the W[1]-hardness of SAT parameterized by the
(undirected) clique-width of the incidence graph, which disproves a conjecture
by Fischer, Makowsky, and Ravve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4285</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4285</id><created>2011-04-21</created><updated>2011-10-03</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author></authors><title>Universally Attainable Error and Information Exponents, and Equivocation
  Rate for the Broadcast Channels with Confidential Messages</title><categories>cs.IT cs.CR math.IT</categories><comments>IEEEtran.sty, 6 pages, resubmitted to Allerton Conference. Ver. 1
  incorrectly stated \exp(\psi) is concave in Prop. 7, which is corrected in
  V2. V3 changed the title and the proof argument. The results are the same in
  all versions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show universally attainable exponents for the decoding error and the
mutual information and universally attainable equivocation rates for the
conditional entropy for the broadcast channels with confidential messages. The
error exponents are the same as ones given by Korner and Sgarro for the
broadcast channels with degraded message sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4290</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4290</id><created>2011-04-21</created><authors><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Ordyniak</keyname><forenames>Sebastian</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Algorithms and Complexity Results for Persuasive Argumentation</title><categories>cs.AI</categories><journal-ref>Artificial Intelligence 175 (2011) pp. 1722-1736</journal-ref><doi>10.1016/j.artint.2011.03.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of arguments as abstract entities and their interaction as
introduced by Dung (Artificial Intelligence 177, 1995) has become one of the
most active research branches within Artificial Intelligence and Reasoning. A
main issue for abstract argumentation systems is the selection of acceptable
sets of arguments. Value-based argumentation, as introduced by Bench-Capon (J.
Logic Comput. 13, 2003), extends Dung's framework. It takes into account the
relative strength of arguments with respect to some ranking representing an
audience: an argument is subjectively accepted if it is accepted with respect
to some audience, it is objectively accepted if it is accepted with respect to
all audiences. Deciding whether an argument is subjectively or objectively
accepted, respectively, are computationally intractable problems. In fact, the
problems remain intractable under structural restrictions that render the main
computational problems for non-value-based argumentation systems tractable. In
this paper we identify nontrivial classes of value-based argumentation systems
for which the acceptance problems are polynomial-time tractable. The classes
are defined by means of structural restrictions in terms of the underlying
graphical structure of the value-based system. Furthermore we show that the
acceptance problems are intractable for two classes of value-based systems that
where conjectured to be tractable by Dunne (Artificial Intelligence 171, 2007).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4295</identifier>
 <datestamp>2011-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4295</id><created>2011-04-21</created><authors><author><keyname>Pianykh</keyname><forenames>Oleg S.</forenames></author></authors><title>Improving digital signal interpolation: L2-optimal kernels with
  kernel-invariant interpolation speed</title><categories>cs.CV math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interpolation is responsible for digital signal resampling and can
significantly degrade the original signal quality if not done properly. For
many years, optimal interpolation algorithms were sought within constrained
classes of interpolation kernel functions. We derive a new family of
unconstrained L2-optimal interpolation kernels, and compare their properties to
the previously known. Although digital images are used to illustrate this work,
our L2-optimal kernels can be applied to interpolate any digital signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4296</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4296</id><created>2011-04-21</created><authors><author><keyname>Franceschet</keyname><forenames>Massimo</forenames></author></authors><title>Collaboration in computer science: a network science approach. Part II</title><categories>cs.SI cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We represent collaboration of authors in computer science papers in terms of
both affiliation and collaboration networks and observe how these networks
evolved over time since 1960. We investigate the temporal evolution of
bibliometric properties, like size of the discipline, productivity of scholars,
and collaboration level in papers, as well as of large-scale network
properties, like reachability and average separation distance among scientists,
distribution of the number of scholar collaborators, network clustering and
network assortativity by number of collaborators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4298</identifier>
 <datestamp>2014-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4298</id><created>2011-04-21</created><updated>2014-07-25</updated><authors><author><keyname>Gottschlich</keyname><forenames>Carsten</forenames></author></authors><title>Curved Gabor Filters for Fingerprint Image Enhancement</title><categories>cs.CV</categories><journal-ref>IEEE Transactions on Image Processing, vol. 21, no. 4, pp.
  2220-2227, Apr. 2012</journal-ref><doi>10.1109/TIP.2011.2170696</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gabor filters play an important role in many application areas for the
enhancement of various types of images and the extraction of Gabor features.
For the purpose of enhancing curved structures in noisy images, we introduce
curved Gabor filters which locally adapt their shape to the direction of flow.
These curved Gabor filters enable the choice of filter parameters which
increase the smoothing power without creating artifacts in the enhanced image.
In this paper, curved Gabor filters are applied to the curved ridge and valley
structure of low-quality fingerprint images. First, we combine two orientation
field estimation methods in order to obtain a more robust estimation for very
noisy images. Next, curved regions are constructed by following the respective
local orientation and they are used for estimating the local ridge frequency.
Lastly, curved Gabor filters are defined based on curved regions and they are
applied for the enhancement of low-quality fingerprint images. Experimental
results on the FVC2004 databases show improvements of this approach in
comparison to state-of-the-art enhancement methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4300</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4300</id><created>2011-04-21</created><authors><author><keyname>Morgenshtern</keyname><forenames>Veniamin I.</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>A Short Course on Frame Theory</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Short Course on Frame Theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4302</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4302</id><created>2011-04-21</created><updated>2011-12-01</updated><authors><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Balzano</keyname><forenames>Laura</forenames></author><author><keyname>Draper</keyname><forenames>Stark C.</forenames></author></authors><title>Rank Minimization over Finite Fields: Fundamental Limits and
  Coding-Theoretic Interpretations</title><categories>cs.IT math.IT stat.ML</categories><comments>Accepted to the IEEE Transactions on Information Theory; Presented at
  IEEE International Symposium on Information Theory (ISIT) 2011</comments><doi>10.1109/TIT.2011.2178017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper establishes information-theoretic limits in estimating a finite
field low-rank matrix given random linear measurements of it. These linear
measurements are obtained by taking inner products of the low-rank matrix with
random sensing matrices. Necessary and sufficient conditions on the number of
measurements required are provided. It is shown that these conditions are sharp
and the minimum-rank decoder is asymptotically optimal. The reliability
function of this decoder is also derived by appealing to de Caen's lower bound
on the probability of a union. The sufficient condition also holds when the
sensing matrices are sparse - a scenario that may be amenable to efficient
decoding. More precisely, it is shown that if the n\times n-sensing matrices
contain, on average, \Omega(nlog n) entries, the number of measurements
required is the same as that when the sensing matrices are dense and contain
entries drawn uniformly at random from the field. Analogies are drawn between
the above results and rank-metric codes in the coding theory literature. In
fact, we are also strongly motivated by understanding when minimum rank
distance decoding of random rank-metric codes succeeds. To this end, we derive
distance properties of equiprobable and sparse rank-metric codes. These
distance properties provide a precise geometric interpretation of the fact that
the sparse ensemble requires as few measurements as the dense one. Finally, we
provide a non-exhaustive procedure to search for the unknown low-rank matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4306</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4306</id><created>2011-04-21</created><authors><author><keyname>Cerny</keyname><forenames>Pavol</forenames></author><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas</forenames></author><author><keyname>Radhakrishna</keyname><forenames>Arjun</forenames></author><author><keyname>Singh</keyname><forenames>Rohit</forenames></author></authors><title>Quantitative Synthesis for Concurrent Programs</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithmic method for the quantitative, performance-aware
synthesis of concurrent programs. The input consists of a nondeterministic
partial program and of a parametric performance model. The nondeterminism
allows the programmer to omit which (if any) synchronization construct is used
at a particular program location. The performance model, specified as a
weighted automaton, can capture system architectures by assigning different
costs to actions such as locking, context switching, and memory and cache
accesses. The quantitative synthesis problem is to automatically resolve the
nondeterminism of the partial program so that both correctness is guaranteed
and performance is optimal. As is standard for shared memory concurrency,
correctness is formalized &quot;specification free&quot;, in particular as race freedom
or deadlock freedom. For worst-case (average-case) performance, we show that
the problem can be reduced to 2-player graph games (with probabilistic
transitions) with quantitative objectives. While we show, using game-theoretic
methods, that the synthesis problem is NEXP-complete, we present an algorithmic
method and an implementation that works efficiently for concurrent programs and
performance models of practical interest. We have implemented a prototype tool
and used it to synthesize finite-state concurrent programs that exhibit
different programming patterns, for several performance models representing
different architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4308</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4308</id><created>2011-04-21</created><updated>2012-07-14</updated><authors><author><keyname>Zahavi</keyname><forenames>Daniel</forenames></author><author><keyname>Dabora</keyname><forenames>Ron</forenames></author></authors><title>Capacity Theorems for the Fading Interference Channel with a Relay and
  Feedback Links</title><categories>cs.IT math.IT</categories><comments>Accepted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handling interference is one of the main challenges in the design of wireless
networks. One of the key approaches to interference management is node
cooperation, which can be classified into two main types: relaying and
feedback. In this work we consider simultaneous application of both cooperation
types in the presence of interference. We obtain exact characterization of the
capacity regions for Rayleigh fading and phase fading interference channels
with a relay and with feedback links, in the strong and very strong
interference regimes. Four feedback configurations are considered: (1) feedback
from both receivers to the relay, (2) feedback from each receiver to the relay
and to one of the transmitters (either corresponding or opposite), (3) feedback
from one of the receivers to the relay, (4) feedback from one of the receivers
to the relay and to one of the transmitters. Our results show that there is a
strong motivation for incorporating relaying and feedback into wireless
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4321</identifier>
 <datestamp>2011-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4321</id><created>2011-04-21</created><authors><author><keyname>Haralambous</keyname><forenames>Yannis</forenames></author></authors><title>Seeking Meaning in a Space Made out of Strokes, Radicals, Characters and
  Compounds</title><categories>cs.CL</categories><comments>13 pages, 5 figures</comments><msc-class>68T50</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chinese characters can be compared to a molecular structure: a character is
analogous to a molecule, radicals are like atoms, calligraphic strokes
correspond to elementary particles, and when characters form compounds, they
are like molecular structures. In chemistry the conjunction of all of these
structural levels produces what we perceive as matter. In language, the
conjunction of strokes, radicals, characters, and compounds produces meaning.
But when does meaning arise? We all know that radicals are, in some sense, the
basic semantic components of Chinese script, but what about strokes?
Considering the fact that many characters are made by adding individual strokes
to (combinations of) radicals, we can legitimately ask the question whether
strokes carry meaning, or not. In this talk I will present my project of
extending traditional NLP techniques to radicals and strokes, aiming to obtain
a deeper understanding of the way ideographic languages model the world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4353</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4353</id><created>2011-04-21</created><authors><author><keyname>Belazzougui</keyname><forenames>D.</forenames></author><author><keyname>Kaporis</keyname><forenames>A. C.</forenames></author><author><keyname>Spirakis</keyname><forenames>P. G.</forenames></author></authors><title>Random input helps searching predecessors</title><categories>cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the dynamic Predecessor Problem with high probability (whp) in
constant time, using only $n^{1+\delta}$ bits of memory, for any constant
$\delta &gt; 0$. The input keys are random wrt a wider class of the well studied
and practically important class of $(f_1, f_2)$-smooth distributions introduced
in \cite{and:mat}. It achieves O(1) whp amortized time. Its worst-case time is
$O(\sqrt{\frac{\log n}{\log \log n}})$. Also, we prove whp $O(\log \log \log
n)$ time using only $n^{1+ \frac{1}{\log \log n}}= n^{1+o(1)}$ bits. Finally,
we show whp $O(\log \log n)$ time using O(n) space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4356</identifier>
 <datestamp>2012-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4356</id><created>2011-04-21</created><updated>2012-10-01</updated><authors><author><keyname>Loebenberger</keyname><forenames>Daniel</forenames></author><author><keyname>N&#xfc;sken</keyname><forenames>Michael</forenames></author></authors><title>Notions for RSA integers</title><categories>cs.CR math.NT</categories><msc-class>94A60, 11A51, 11N25, 94A17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key-generation algorithm for the RSA cryptosystem is specified in several
standards, such as PKCS#1, IEEE 1363-2000, FIPS 186-3, ANSI X9.44, or ISO/IEC
18033-2. All of them substantially differ in their requirements. This indicates
that for computing a &quot;secure&quot; RSA modulus it does not matter how exactly one
generates RSA integers. In this work we show that this is indeed the case to a
large extend: First, we give a theoretical framework that will enable us to
easily compute the entropy of the output distribution of the considered
standards and show that it is comparatively high. To do so, we compute for each
standard the number of integers they define (up to an error of very small
order) and discuss different methods of generating integers of a specific form.
Second, we show that factoring such integers is hard, provided factoring a
product of two primes of similar size is hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4370</identifier>
 <datestamp>2012-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4370</id><created>2011-04-21</created><authors><author><keyname>Wu</keyname><forenames>Bang Ye</forenames></author></authors><title>The maximum disjoint paths problem on multi-relations social networks</title><categories>cs.DS cs.SI</categories><doi>10.1016/j.disopt.2012.01.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications to social network analysis (SNA), we study the
problem of finding the maximum number of disjoint uni-color paths in an
edge-colored graph. We show the NP-hardness and the approximability of the
problem, and both approximation and exact algorithms are proposed. Since short
paths are much more significant in SNA, we also study the length-bounded
version of the problem, in which the lengths of paths are required to be upper
bounded by a fixed integer $l$. It is shown that the problem can be solved in
polynomial time for $l=3$ and is NP-hard for $l\geq 4$. We also show that the
problem can be approximated with ratio $(l-1)/2+\epsilon$ in polynomial time
for any $\epsilon &gt;0$. Particularly, for $l=4$, we develop an efficient
2-approximation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4375</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4375</id><created>2011-04-21</created><authors><author><keyname>Yao</keyname><forenames>Yuan</forenames></author><author><keyname>Zheng</keyname><forenames>Jianfeng</forenames></author><author><keyname>Feng</keyname><forenames>Zhenghe</forenames></author></authors><title>Array independent MIMO channel models with analytical characteristics</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, 4 tables, submitted to IEEE Transactions on
  Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conventional analytical channel models for multiple-input multiple-output
(MIMO) wireless radio channels are array dependent. In this paper, we present
several array independent MIMO channel models that inherit the essence of
analytical models. The key idea is to decompose the physical scattering channel
into two parts using the manifold decomposition technique: one is the wavefield
independent sampling matrices depending on the antenna arrays only; the other
is the array independent physical channel that can be individually modeled in
an analytical manner. Based on the framework, we firstly extend the
conventional virtual channel representation (VCR), which is restricted to
uniform linear arrays (ULAs) so far, to a general version applicable to
arbitrary array configurations. Then, we present two array independent
stochastic MIMO channel models based on the proposed new VCR as well as the
Weichselberger model. These two models are good at angular power spectrum (APS)
estimation and capacity prediction, respectively. Finally, the impact of array
characteristics on channel capacity is separately investigated by studying the
condition number of the array steering matrix at fixed angles, and the results
agree well with existing conclusions. Numerical results are presented for model
validation and comparison.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4376</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4376</id><created>2011-04-21</created><authors><author><keyname>Wang</keyname><forenames>Alex</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Vikram</forenames></author><author><keyname>Balaji</keyname><forenames>Bhashyam</forenames></author></authors><title>Intent Inference and Syntactic Tracking with GMTI Measurements</title><categories>stat.ME cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In conventional target tracking systems, human operators use the estimated
target tracks to make higher level inference of the target behaviour/intent.
This paper develops syntactic filtering algorithms that assist human operators
by extracting spatial patterns from target tracks to identify
suspicious/anomalous spatial trajectories. The targets' spatial trajectories
are modeled by a stochastic context free grammar (SCFG) and a switched mode
state space model. Bayesian filtering algorithms for stochastic context free
grammars are presented for extracting the syntactic structure and illustrated
for a ground moving target indicator (GMTI) radar example. The performance of
the algorithms is tested with the experimental data collected using DRDC
Ottawa's X-band Wideband Experimental Airborne Radar (XWEAR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4379</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4379</id><created>2011-04-21</created><authors><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Sukumar</keyname><forenames>Karthik</forenames></author></authors><title>Platforms for Building and Deploying Applications for Cloud Computing</title><categories>cs.DC</categories><comments>6 pages, 4 figures</comments><acm-class>C.1.4</acm-class><journal-ref>CSI Communications, Vol.35, No. 1, Pages: 6-11, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing is rapidly emerging as a new paradigm for delivering IT
services as utlity-oriented services on subscription-basis. The rapid
development of applications and their deployment in Cloud computing
environments in efficient manner is a complex task. In this article, we give a
brief introduction to Cloud computing technology and Platform as a Service, we
examine the offerings in this category, and provide the basis for helping
readers to understand basic application platform opportunities in Cloud by
technologies such as Microsoft Azure, Sales Force, Google App, and Aneka for
Cloud computing. We demonstrate that Manjrasoft Aneka is a Cloud Application
Platform (CAP) leveraging these concepts and allowing an easy development of
Cloud ready applications on a Private/Public/Hybrid Cloud. Aneka CAP offers
facilities for quickly developing Cloud applications and a modular platform
where additional services can be easily integrated to extend the system
capabilities, thus being at pace with the rapidly evolution of Cloud computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4381</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4381</id><created>2011-04-21</created><authors><author><keyname>Chen</keyname><forenames>Yanguang</forenames></author></authors><title>Unraveling the Rank-Size Rule with Self-Similar Hierarchies</title><categories>physics.soc-ph cs.SI</categories><comments>22 pages, 5 figures, 2 tables</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many scientists are interested in but puzzled by the various inverse power
laws with a negative exponent 1 such as the rank-size rule. The rank-size rule
is a very simple scaling law followed by many observations of the ubiquitous
empirical patterns in physical and social systems. Where there is a rank-size
distribution, there will be a hierarchy with cascade structure. However, the
equivalence relation between the rank-size rule and the hierarchical scaling
law remains to be mathematically demonstrated and empirically testified. In
this paper, theoretical derivation, mathematical experiments, and empirical
analysis are employed to show that the rank-size rule is equivalent in theory
to the hierarchical scaling law (the Nn principle). Abstracting an ordered set
of quantities in the form {1, 1/2,..., 1/k,...} from the rank-size rule, I
prove a geometric subdivision theorem of the harmonic sequence (k=1, 2, 3,...).
By the theorem, the rank-size distribution can be transformed into a
self-similar hierarchy, thus a power law can be decomposed as a pair of
exponential laws, and further the rank-size power law can be reconstructed as a
hierarchical scaling law. A number of ubiquitous empirical observations and
rules, including Zipf's law, Pareto's distribution, fractals, allometric
scaling, 1/f noise, can be unified into the hierarchical framework. The
self-similar hierarchy can provide us with a new perspective of looking at the
inverse power law of nature or even how nature works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4384</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4384</id><created>2011-04-21</created><authors><author><keyname>Gupta</keyname><forenames>Nitin</forenames></author></authors><title>EMBANKS: Towards Disk Based Algorithms For Keyword-Search In Structured
  Databases</title><categories>cs.DB</categories><comments>45 pages, 15 figures, Bachelors Thesis submission to IIT Bombay</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been a lot of interest in the field of keyword
querying relational databases. A variety of systems such as DBXplorer [ACD02],
Discover [HP02] and ObjectRank [BHP04] have been proposed. Another such system
is BANKS, which enables data and schema browsing together with keyword-based
search for relational databases. It models tuples as nodes in a graph,
connected by links induced by foreign key and other relationships. The size of
the database graph that BANKS uses is proportional to the sum of the number of
nodes and edges in the graph. Systems such as SPIN, which search on Personal
Information Networks and use BANKS as the backend, maintain a lot of
information about the users' data. Since these systems run on the user
workstation which have other demands of memory, such a heavy use of memory is
unreasonable and if possible, should be avoided. In order to alleviate this
problem, we introduce EMBANKS (acronym for External Memory BANKS), a framework
for an optimized disk-based BANKS system. The complexity of this framework
poses many questions, some of which we try to answer in this thesis. We
demonstrate that the cluster representation proposed in EMBANKS enables
in-memory processing of very large database graphs. We also present detailed
experiments that show that EMBANKS can significantly reduce database load time
and query execution times when compared to the original BANKS algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4385</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4385</id><created>2011-04-22</created><authors><author><keyname>Rao</keyname><forenames>Nikhil S</forenames></author><author><keyname>Nowak</keyname><forenames>Robert D.</forenames></author><author><keyname>Wright</keyname><forenames>Stephen J.</forenames></author><author><keyname>Kingsbury</keyname><forenames>Nick G.</forenames></author></authors><title>Convex Approaches to Model Wavelet Sparsity Patterns</title><categories>cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical dependencies among wavelet coefficients are commonly represented
by graphical models such as hidden Markov trees(HMTs). However, in linear
inverse problems such as deconvolution, tomography, and compressed sensing, the
presence of a sensing or observation matrix produces a linear mixing of the
simple Markovian dependency structure. This leads to reconstruction problems
that are non-convex optimizations. Past work has dealt with this issue by
resorting to greedy or suboptimal iterative reconstruction methods. In this
paper, we propose new modeling approaches based on group-sparsity penalties
that leads to convex optimizations that can be solved exactly and efficiently.
We show that the methods we develop perform significantly better in
deconvolution and compressed sensing applications, while being as
computationally efficient as standard coefficient-wise approaches such as
lasso.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4406</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4406</id><created>2011-04-22</created><authors><author><keyname>Shechtman</keyname><forenames>Yoav</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Szameit</keyname><forenames>Alexander</forenames></author><author><keyname>Segev</keyname><forenames>Mordechai</forenames></author></authors><title>Sparsity based sub-wavelength imaging with partially incoherent light
  via quadratic compressed sensing</title><categories>cs.IT math.IT physics.optics</categories><comments>16 pages</comments><doi>10.1364/OE.19.014807</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that sub-wavelength optical images borne on
partially-spatially-incoherent light can be recovered, from their far-field or
from the blurred image, given the prior knowledge that the image is sparse, and
only that. The reconstruction method relies on the recently demonstrated
sparsity-based sub-wavelength imaging. However, for
partially-spatially-incoherent light, the relation between the measurements and
the image is quadratic, yielding non-convex measurement equations that do not
conform to previously used techniques. Consequently, we demonstrate new
algorithmic methodology, referred to as quadratic compressed sensing, which can
be applied to a range of other problems involving information recovery from
partial correlation measurements, including when the correlation function has
local dependencies. Specifically for microscopy, this method can be readily
extended to white light microscopes with the additional knowledge of the light
source spectrum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4418</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4418</id><created>2011-04-22</created><updated>2011-10-27</updated><authors><author><keyname>Allali</keyname><forenames>Oussama</forenames></author><author><keyname>Tabourier</keyname><forenames>Lionel</forenames></author><author><keyname>Magnien</keyname><forenames>Cl&#xe9;mence</forenames></author><author><keyname>Latapy</keyname><forenames>Matthieu</forenames></author></authors><title>Internal links and pairs as a new tool for the analysis of bipartite
  complex networks</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world complex networks are best modeled as bipartite (or 2-mode)
graphs, where nodes are divided into two sets with links connecting one side to
the other. However, there is currently a lack of methods to analyze properly
such graphs as most existing measures and methods are suited to classical
graphs. A usual but limited approach consists in deriving 1-mode graphs (called
projections) from the underlying bipartite structure, though it causes
important loss of information and data storage issues. We introduce here
internal links and pairs as a new notion useful for such analysis: it gives
insights on the information lost by projecting the bipartite graph. We
illustrate the relevance of theses concepts on several real-world instances
illustrating how it enables to discriminate behaviors among various cases when
we compare them to a benchmark of random networks. Then, we show that we can
draw benefit from this concept for both modeling complex networks and storing
them in a compact format.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4419</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4419</id><created>2011-04-22</created><authors><author><keyname>Iv&#xe1;nyi</keyname><forenames>Antal</forenames></author><author><keyname>K&#xe1;tai</keyname><forenames>Imre</forenames></author></authors><title>Testing of random matrices</title><categories>cs.DM</categories><msc-class>68R15, 68M20, 05B15</msc-class><acm-class>G.2.2</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 3, 1 (2011) 99--126</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $n$ be a positive integer and $X = [x_{ij}]_{1 \leq i, j \leq n}$ be an
$n \times n$\linebreak \noindent sized matrix of independent random variables
having joint uniform distribution $$\hbox{Pr} {x_{ij} = k \hbox{for} 1 \leq k
\leq n} = \frac{1}{n} \quad (1 \leq i, j \leq n) \koz. $$ A realization
$\mathcal{M} = [m_{ij}]$ of $X$ is called \textit{good}, if its each row and
each column contains a permutation of the numbers $1, 2,..., n$. We present and
analyse four typical algorithms which decide whether a given realization is
good.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4423</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4423</id><created>2011-04-22</created><updated>2011-07-11</updated><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Caragiannis</keyname><forenames>Ioannis</forenames></author><author><keyname>Fanelli</keyname><forenames>Angelo</forenames></author><author><keyname>Kalaitzis</keyname><forenames>Christos</forenames></author></authors><title>Enforcing efficient equilibria in network design games via subsidies</title><categories>cs.GT cs.CC</categories><comments>30 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficient design of networks has been an important engineering task that
involves challenging combinatorial optimization problems. Typically, a network
designer has to select among several alternatives which links to establish so
that the resulting network satisfies a given set of connectivity requirements
and the cost of establishing the network links is as low as possible. The
Minimum Spanning Tree problem, which is well-understood, is a nice example.
  In this paper, we consider the natural scenario in which the connectivity
requirements are posed by selfish users who have agreed to share the cost of
the network to be established according to a well-defined rule. The design
proposed by the network designer should now be consistent not only with the
connectivity requirements but also with the selfishness of the users.
Essentially, the users are players in a so-called network design game and the
network designer has to propose a design that is an equilibrium for this game.
As it is usually the case when selfishness comes into play, such equilibria may
be suboptimal. In this paper, we consider the following question: can the
network designer enforce particular designs as equilibria or guarantee that
efficient designs are consistent with users' selfishness by appropriately
subsidizing some of the network links? In an attempt to understand this
question, we formulate corresponding optimization problems and present positive
and negative results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4424</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4424</id><created>2011-04-22</created><authors><author><keyname>K&#xe1;sa</keyname><forenames>Zolt&#xe1;n</forenames></author></authors><title>Super-d-complexity of finite words</title><categories>cs.DM</categories><msc-class>68R15</msc-class><acm-class>G.2.1; F.2.2</acm-class><journal-ref>8th Joint Conf. on Math. and Comp. Sci. July 14--17, 2010,
  Kom\'arno, Slovakia, Selected papers, 2011. pp. 251--261</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce and study a new complexity measure for finite
words. For positive integer $d$ special scattered subwords, called
super-$d$-subwords, in which the gaps are of length at least $(d-1)$, are
defined. We give methods to compute super-$d$-complexity (the total number of
different super-$d$-subwords) in the case of rainbow words (with pairwise
different letters) by recursive algorithms, by mahematical formulas and by
graph algorithms. In the case of general words, with letters from a given
alphabet without any restriction, the problem of the maximum value of the
super-$d$-complexity of all words of length $n$ is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4425</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4425</id><created>2011-04-22</created><authors><author><keyname>K&#xe1;sa</keyname><forenames>Zolt&#xe1;n</forenames></author></authors><title>On scattered subword complexity</title><categories>cs.DM</categories><msc-class>68R15</msc-class><acm-class>G.2.1; F.2.2</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica 3, 1 (2011) 127--136</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Special scattered subwords, in which the gaps are of length from a given set,
are defined. The scattered subword complexity, which is the number of such
scattered subwords, is computed for rainbow words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4426</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4426</id><created>2011-04-22</created><updated>2011-04-29</updated><authors><author><keyname>Serva</keyname><forenames>Maurizio</forenames></author></authors><title>Phylogeny and geometry of languages from normalized Levenshtein distance</title><categories>cs.CL q-bio.PE</categories><comments>Review paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea that the distance among pairs of languages can be evaluated from
lexical differences seems to have its roots in the work of the French explorer
Dumont D'Urville. He collected comparative words lists of various languages
during his voyages aboard the Astrolabe from 1826 to 1829 and, in his work
about the geographical division of the Pacific, he proposed a method to measure
the degree of relation between languages.
  The method used by the modern lexicostatistics, developed by Morris Swadesh
in the 1950s, measures distances from the percentage of shared cognates, which
are words with a common historical origin. The weak point of this method is
that subjective judgment plays a relevant role.
  Recently, we have proposed a new automated method which is motivated by the
analogy with genetics. The new approach avoids any subjectivity and results can
be easily replicated by other scholars. The distance between two languages is
defined by considering a renormalized Levenshtein distance between pair of
words with the same meaning and averaging on the words contained in a list. The
renormalization, which takes into account the length of the words, plays a
crucial role, and no sensible results can be found without it.
  In this paper we give a short review of our automated method and we
illustrate it by considering the cluster of Malagasy dialects. We show that it
sheds new light on their kinship relation and also that it furnishes a lot of
new information concerning the modalities of the settlement of Madagascar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4427</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4427</id><created>2011-04-22</created><authors><author><keyname>Lischke</keyname><forenames>Gerhard</forenames></author></authors><title>Primitive words and roots of words</title><categories>cs.FL</categories><msc-class>03-2, 68-02, 68Q45, 68R15, 03D15</msc-class><acm-class>F.4.3</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica 3, 1 (2011) 5-34</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the algebraic theory of codes and formal languages, the set $Q$ of all
primitive words over some alphabet $\zi $ has received special interest. With
this survey article we give an overview about relevant research to this topic
during the last twenty years including own investigations and some new results.
In Section 1 after recalling the most important notions from formal language
theory we illustrate the connection between coding theory and primitive words
by some facts. We define primitive words as words having only a trivial
representation as the power of another word. Nonprimitive words (without the
empty word) are exactly the periodic words. Every nonempty word is a power of
an uniquely determined primitive word which is called the root of the former
one. The set of all roots of nonempty words of a language is called the root of
the language. The primitive words have interesting combinatorial properties
which we consider in Section 2. In Section 3 we investigate the relationship
between the set $Q$ of all primitive words over some fixed alphabet and the
language classes of the Chomsky Hierarchy and the contextual languages over the
same alphabet. The computational complexity of the set $Q$ and of the roots of
languages are considered in Section 4. The set of all powers of the same degree
of all words from a language is the power of this language. We examine the
powers of languages for different sets of exponents, and especially their
regularity and context-freeness, in Section 5, and the decidability of
appropriate questions in Section 6. Section 7 is dedicated to several
generalizations of the notions of periodicity and primitivity of words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4433</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4433</id><created>2011-04-22</created><authors><author><keyname>Popov</keyname><forenames>Vladimir Yu.</forenames></author></authors><title>Arc-preserving subsequences of arc-annotated sequences</title><categories>cs.CC</categories><msc-class>68Q15</msc-class><acm-class>F.1.3</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica 3, 1 (2011) 35--47</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Arc-annotated sequences are useful in representing the structural information
of RNA and protein sequences. The longest arc-preserving common subsequence
problem has been introduced as a framework for studying the similarity of
arc-annotated sequences. In this paper, we consider arc-annotated sequences
with various arc structures. We consider the longest arc preserving common
subsequence problem. In particular, we show that the decision version of the
1-{\sc fragment LAPCS(crossing,chain)} and the decision version of the 0-{\sc
diagonal LAPCS(crossing,chain)} are {\bf NP}-complete for some fixed alphabet
$\Sigma$ such that $|\Sigma| = 2$. Also we show that if $|\Sigma| = 1$, then
the decision version of the 1-{\sc fragment LAPCS(unlimited, plain)} and the
decision version of the 0-{\sc diagonal LAPCS(unlimited, plain)} are {\bf
NP}-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4465</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4465</id><created>2011-04-22</created><updated>2014-04-07</updated><authors><author><keyname>Brattka</keyname><forenames>Vasco</forenames></author><author><keyname>Miller</keyname><forenames>Joseph S.</forenames></author><author><keyname>Nies</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Randomness and Differentiability</title><categories>math.LO cs.LO</categories><comments>39 pages</comments><msc-class>03D32, 03F60, 26A27, 26A48, 26A45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize some major algorithmic randomness notions via
differentiability of effective functions.
  (1) As the main result we show that a real number z in [0,1] is computably
random if and only if each nondecreasing computable function [0,1]-&gt;R is
differentiable at z.
  (2) We prove that a real number z in [0,1] is weakly 2-random if and only if
each almost everywhere differentiable computable function [0,1]-&gt;R is
differentiable at z.
  (3) Recasting in classical language results dating from 1975 of the
constructivist Demuth, we show that a real z is ML random if and only if every
computable function of bounded variation is differentiable at z, and similarly
for absolutely continuous functions.
  We also use our analytic methods to show that computable randomness of a real
is base invariant, and to derive other preservation results for randomness
notions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4468</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4468</id><created>2011-04-22</created><updated>2011-07-08</updated><authors><author><keyname>Lee</keyname><forenames>Troy</forenames></author><author><keyname>Roland</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author></authors><title>A strong direct product theorem for quantum query complexity</title><categories>quant-ph cs.CC</categories><comments>V2: 19 pages (various additions and improvements, in particular:
  improved parameters in the main theorems due to a finer analysis of the
  output condition, and addition of an XOR lemma and a threshold direct product
  theorem in the boolean case). V3: 19 pages (added grant information)</comments><journal-ref>27th IEEE Conference on Computational Complexity (CCC'12), pages
  236-246, 2012</journal-ref><doi>10.1109/CCC.2012.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that quantum query complexity satisfies a strong direct product
theorem. This means that computing $k$ copies of a function with less than $k$
times the quantum queries needed to compute one copy of the function implies
that the overall success probability will be exponentially small in $k$. For a
boolean function $f$ we also show an XOR lemma---computing the parity of $k$
copies of $f$ with less than $k$ times the queries needed for one copy implies
that the advantage over random guessing will be exponentially small.
  We do this by showing that the multiplicative adversary method, which
inherently satisfies a strong direct product theorem, is always at least as
large as the additive adversary method, which is known to characterize quantum
query complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4471</identifier>
 <datestamp>2011-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4471</id><created>2011-04-22</created><authors><author><keyname>B&#xf6;cker</keyname><forenames>Sebastian</forenames></author></authors><title>Towards a Data Reduction for the Minimum Flip Supertree Problem</title><categories>cs.DS</categories><msc-class>68W99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In computational phylogenetics, the problem of constructing a supertree of a
given set of rooted input trees can be formalized in different ways, to cope
with contradictory information in the input. We consider the Minimum Flip
Supertree problem, where the input trees are transformed into a 0/1/?-matrix,
such that each row represents a taxon, and each column represents an inner node
of one of the input trees. Our goal is to find a perfect phylogeny for the
input matrix requiring a minimum number of 0/1-flips, that is, corrections of
0/1-entries in the matrix. The problem is known to be NP-complete. Here, we
present a parameterized data reduction with polynomial running time. The data
reduction guarantees that the reduced instance has a solution if and only if
the original instance has a solution. We then make our data reduction
parameter-independent by using upper bounds. This allows us to preprocess an
instance, and to solve the reduced instance with an arbitrary method. Different
from an existing data reduction for the consensus tree problem, our reduction
allows us to draw conclusions about certain entries in the matrix. We have
implemented and evaluated our data reduction. Unfortunately, we find that the
Minimum Flip Supertree problem is also hard in practice: The amount of
information that can be derived during data reduction diminishes as instances
get more &quot;complicated&quot;, and running times for &quot;complicated&quot; instances quickly
become prohibitive. Still, our method offers another route of attack for this
relevant phylogenetic problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4475</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4475</id><created>2011-04-22</created><authors><author><keyname>Bouwmeester</keyname><forenames>Henricus</forenames></author><author><keyname>Jacquelin</keyname><forenames>Mathias</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author><author><keyname>Robert</keyname><forenames>Yves</forenames></author></authors><title>Tiled QR factorization algorithms</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work revisits existing algorithms for the QR factorization of
rectangular matrices composed of p-by-q tiles, where p &gt;= q. Within this
framework, we study the critical paths and performance of algorithms such as
Sameh and Kuck, Modi and Clarke, Greedy, and those found within PLASMA.
Although neither Modi and Clarke nor Greedy is optimal, both are shown to be
asymptotically optimal for all matrices of size p = q^2 f(q), where f is any
function such that \lim_{+\infty} f= 0. This novel and important complexity
result applies to all matrices where p and q are proportional, p = \lambda q,
with \lambda &gt;= 1, thereby encompassing many important situations in practice
(least squares). We provide an extensive set of experiments that show the
superiority of the new algorithms for tall matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4490</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4490</id><created>2011-04-22</created><updated>2012-01-05</updated><authors><author><keyname>Mukherjee</keyname><forenames>Amar</forenames></author></authors><title>The 3-satisfiability problem</title><categories>cs.CC</categories><comments>This paper is withdrawn by the author because a revision has been
  developed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deterministic polynomial-time algorithm that solves the
3-satisfiability problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4491</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4491</id><created>2011-04-22</created><authors><author><keyname>Abouelseoud</keyname><forenames>Mohamed</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Opportunistic Wireless Relay Networks: Diversity-Multiplexing Tradeoff</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic analysis has traditionally relied on independence assumptions
that break down in many interesting and useful network topologies. This paper
develops techniques that expand opportunistic analysis to a broader class of
networks, proposes new opportunistic methods for several network geometries,
and analyzes them in the high-SNR regime. For each of the geometries studied in
the paper, we analyze the opportunistic DMT of several relay protocols,
including amplify-and-forward, decode-and-forward, compress-and-forward,
non-orthogonal amplify-forward, and dynamic decode-forward. Among the
highlights of the results: in a variety of multi-user single-relay networks,
simple selection strategies are developed and shown to be DMT-optimal. It is
shown that compress-forward relaying achieves the DMT upper bound in the
opportunistic multiple-access relay channel as well as in the opportunistic nxn
user network with relay. Other protocols, e.g. dynamic decode-forward, are
shown to be near optimal in several cases. Finite-precision feedback is
analyzed for the opportunistic multiple-access relay channel, the opportunistic
broadcast relay channel, and the opportunistic gateway channel, and is shown to
be almost as good as full channel state information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4503</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4503</id><created>2011-04-22</created><authors><author><keyname>Baumeister</keyname><forenames>Barbara</forenames></author><author><keyname>de Wiljes</keyname><forenames>Jan</forenames></author></authors><title>Aperiodic logarithmic signatures</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a method to construct logarithmic signatures which
are not amalgamated transversal and further do not even have a periodic block.
The latter property was crucial for the successful attack on the system MST3 by
Blackburn et al. [1]. The idea for our construction is based on the theory in
Szab\'o's book about group factorizations [12].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4506</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4506</id><created>2011-04-22</created><authors><author><keyname>Junosza-Szaniawski</keyname><forenames>Konstanty</forenames></author><author><keyname>Rz\ka\zewski</keyname><forenames>Pawe&#x142;</forenames></author></authors><title>Determining L(2,1)-Span in Polynomial Space</title><categories>cs.DM cs.DS math.CO</categories><msc-class>68R10, 05C15, 05C85</msc-class><acm-class>G.2.2</acm-class><doi>10.1016/j.dam.2013.03.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $k$-L(2,1)-labeling of a graph is a function from its vertex set into the
set $\{0,...,k\}$, such that the labels assigned to adjacent vertices differ by
at least 2, and labels assigned to vertices of distance 2 are different. It is
known that finding the smallest $k$ admitting the existence of a
$k$-L(2,1)-labeling of any given graph is NP-Complete.
  In this paper we present an algorithm for this problem, which works in time
$O(\complexity ^n)$ and polynomial memory, where $\eps$ is an arbitrarily small
positive constant. This is the first exact algorithm for L(2,1)-labeling
problem with time complexity $O(c^n)$ for some constant $c$ and polynomial
space complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4512</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4512</id><created>2011-04-22</created><authors><author><keyname>Forero</keyname><forenames>Pedro A.</forenames></author><author><keyname>Kekatos</keyname><forenames>Vassilis</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Robust Clustering Using Outlier-Sparsity Regularization</title><categories>stat.ML cs.LG</categories><comments>Submitted to IEEE Trans. on PAMI</comments><doi>10.1109/TSP.2012.2196696</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Notwithstanding the popularity of conventional clustering algorithms such as
K-means and probabilistic clustering, their clustering results are sensitive to
the presence of outliers in the data. Even a few outliers can compromise the
ability of these algorithms to identify meaningful hidden structures rendering
their outcome unreliable. This paper develops robust clustering algorithms that
not only aim to cluster the data, but also to identify the outliers. The novel
approaches rely on the infrequent presence of outliers in the data which
translates to sparsity in a judiciously chosen domain. Capitalizing on the
sparsity in the outlier domain, outlier-aware robust K-means and probabilistic
clustering approaches are proposed. Their novelty lies on identifying outliers
while effecting sparsity in the outlier domain through carefully chosen
regularization. A block coordinate descent approach is developed to obtain
iterative algorithms with convergence guarantees and small excess computational
complexity with respect to their non-robust counterparts. Kernelized versions
of the robust clustering algorithms are also developed to efficiently handle
high-dimensional data, identify nonlinearly separable clusters, or even cluster
objects that are not represented by vectors. Numerical tests on both synthetic
and real datasets validate the performance and applicability of the novel
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4518</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4518</id><created>2011-04-22</created><updated>2011-10-13</updated><authors><author><keyname>Buluc</keyname><forenames>Aydin</forenames></author><author><keyname>Madduri</keyname><forenames>Kamesh</forenames></author></authors><title>Parallel Breadth-First Search on Distributed Memory Systems</title><categories>cs.DC cs.MS cs.PF</categories><msc-class>05C85, 68R10, 68W05, 68W10, 68W15</msc-class><journal-ref>Proceedings of The International Conference for High Performance
  Computing, Networking, Storage, and Analysis (SC 2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data-intensive, graph-based computations are pervasive in several scientific
applications, and are known to to be quite challenging to implement on
distributed memory systems. In this work, we explore the design space of
parallel algorithms for Breadth-First Search (BFS), a key subroutine in several
graph algorithms. We present two highly-tuned parallel approaches for BFS on
large parallel systems: a level-synchronous strategy that relies on a simple
vertex-based partitioning of the graph, and a two-dimensional sparse
matrix-partitioning-based approach that mitigates parallel communication
overhead. For both approaches, we also present hybrid versions with intra-node
multithreading. Our novel hybrid two-dimensional algorithm reduces
communication times by up to a factor of 3.5, relative to a common vertex based
approach. Our experimental study identifies execution regimes in which these
approaches will be competitive, and we demonstrate extremely high performance
on leading distributed-memory parallel systems. For instance, for a 40,000-core
parallel execution on Hopper, an AMD Magny-Cours based system, we achieve a BFS
performance rate of 17.8 billion edge visits per second on an undirected graph
of 4.3 billion vertices and 68.7 billion edges with skewed degree distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4521</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4521</id><created>2011-04-22</created><updated>2011-09-06</updated><authors><author><keyname>Vidyasagar</keyname><forenames>Mathukumalli</forenames></author></authors><title>A Metric Between Probability Distributions on Finite Sets of Different
  Cardinalities and Applications to Order Reduction</title><categories>cs.SY cs.IT math.IT math.OC</categories><comments>32 pages, no figures</comments><msc-class>93E99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With increasing use of digital control it is natural to view control inputs
and outputs as stochastic processes assuming values over finite alphabets
rather than in a Euclidean space. As control over networks becomes increasingly
common, data compression by reducing the size of the input and output alphabets
without losing the fidelity of representation becomes relevant. This requires
us to define a notion of distance between two stochastic processes assuming
values in distinct sets, possibly of different cardinalities. If the two
processes are i.i.d., then the problem becomes one of defining a metric between
two probability distributions over distinct finite sets of possibly different
cardinalities. This is the problem addressed in the present paper. A metric is
defined in terms of a joint distribution on the product of the two sets, which
has the two given distributions as its marginals, and has minimum entropy.
Computing the metric exactly turns out to be NP-hard. Therefore an efficient
greedy algorithm is presented for finding an upper bound on the distance. This
problem also turns out to be NP-hard, so again a greedy algorithm is
constructed for finding a suboptimal reduced order approximation. Taken
together, all the results presented here permit the approximation of an i.i.d.
process over a set of large cardinality by another i.i.d. process over a set of
smaller cardinality. In future work, attempts will be made to extend this work
to Markov processes over finite sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4532</identifier>
 <datestamp>2015-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4532</id><created>2011-04-23</created><authors><author><keyname>Brede</keyname><forenames>M.</forenames></author></authors><title>Playing against the fittest: A simple strategy that promotes the
  emergence of cooperation</title><categories>cs.GT physics.bio-ph physics.soc-ph q-bio.PE</categories><comments>6 pages, 5 figures, in press</comments><journal-ref>Europhysics Letters, 2011</journal-ref><doi>10.1209/0295-5075/94/30003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the emergence and sustainability of cooperation is a
fundamental problem in evolutionary biology and is frequently studied by the
framework of evolutionary game theory. A very powerful mechanism to promote
cooperation is network reciprocity, where the interaction patterns and
opportunities for strategy spread of agents are constrained to limited sets of
permanent interactions partners. Cooperation survives because it is possible
for close-knit communities of cooperation to be shielded from invasion by
defectors. Here we show that parameter ranges in which cooperation can survive
are strongly expanded if game play on networks is skewed towards more frequent
interactions with more successful neighbours. In particular, if agents
exclusively select neighbors for game play that are more successful than
themselves, cooperation can even dominate in situations in which it would die
out if interaction neighbours were chosen without a bias or with a preference
for less successful opponents. We demonstrate that the &quot;selecting fitter
neighbours&quot; strategy is evolutionarily stable. Moreover, it will emerge as the
dominant strategy out of an initially random population of agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4544</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4544</id><created>2011-04-23</created><authors><author><keyname>Esmaili</keyname><forenames>H. A.</forenames></author><author><keyname>Shoja</keyname><forenames>M. R. Khalili</forenames></author><author><keyname>gharaee</keyname><forenames>Hossein</forenames></author></authors><title>Performance Analysis of AODV under Black Hole Attack through Use of
  OPNET Simulator</title><categories>cs.CR</categories><comments>4 pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT) , ISSN: 2221-0741, Vol. 1, No. 2, 49-52, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile ad hoc networks (MANETs) are dynamic wireless networks without any
infrastructure. These networks are weak against many types of attacks. One of
these attacks is the black hole. In this attack, a malicious node advertises
itself as having freshest or shortest path to specific node to absorb packets
to itself. The effect of black hole attack on ad hoc network using AODV as a
routing protocol will be examined in this research. Furthermore, we investigate
solution for increasing security in these networks. Simulation results using
OPNET simulator depict that packet delivery ratio in the presence of malicious
nodes, reduces notably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4552</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4552</id><created>2011-04-23</created><authors><author><keyname>Ganguly</keyname><forenames>Sumit</forenames></author></authors><title>Polynomial Estimators for High Frequency Moments</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for computing $F_p$, the $p$th moment of an
$n$-dimensional frequency vector of a data stream, for $2 &lt; p &lt; \log (n) $, to
within $1\pm \epsilon$ factors, $\epsilon \in [n^{-1/p},1]$ with high constant
probability. Let $m$ be the number of stream records and $M$ be the largest
magnitude of a stream update.
  The algorithm uses space in bits $$ O(p^2\epsilon^{-2}n^{1-2/p}E(p,n) \log
(n) \log (nmM)/\min(\log (n),\epsilon^{4/p-2}))$$ where, $E(p,n) =
(1-2/p)^{-1}(1-n^{-4(1-2/p})$. Here $E(p,n)$ is $ O(1)$ for $p = 2+\Omega(1)$
and $ O(\log n)$ for $p = 2 + O(1/\log (n)$. This improves upon the space
required by current algorithms
\cite{iw:stoc05,bgks:soda06,ako:arxiv10,bo:arxiv10} by a factor of at least
$\Omega(\epsilon^{-4/p} \min(\log (n), \epsilon^{4/p-2}))$. The update time is
$O(\log (n))$. We use a new technique for designing estimators for functions of
the form $\psi(\expect{X})$, where, $X$ is a random variable and $\psi$ is a
smooth function, based on a low-degree Taylor polynomial expansion of
$\psi(\expect{X})$ around an estimate of $\expect{X}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4557</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4557</id><created>2011-04-23</created><authors><author><keyname>Forbes</keyname><forenames>Michael</forenames></author><author><keyname>Kayal</keyname><forenames>Neeraj</forenames></author><author><keyname>Mittal</keyname><forenames>Rajat</forenames></author><author><keyname>Saha</keyname><forenames>Chandan</forenames></author></authors><title>Square root Bound on the Least Power Non-residue using a
  Sylvester-Vandermonde Determinant</title><categories>math.NT cs.SC</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new elementary proof of the fact that the value of the least
$k^{th}$ power non-residue in an arithmetic progression $\{bn+c\}_{n=0,1...}$,
over a prime field $\F_p$, is bounded by $7/\sqrt{5} \cdot b \cdot \sqrt{p/k} +
4b + c$. Our proof is inspired by the so called \emph{Stepanov method}, which
involves bounding the size of the solution set of a system of equations by
constructing a non-zero low degree auxiliary polynomial that vanishes with high
multiplicity on the solution set. The proof uses basic algebra and number
theory along with a determinant identity that generalizes both the Sylvester
and the Vandermonde determinant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4558</identifier>
 <datestamp>2011-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4558</id><created>2011-04-23</created><updated>2011-10-05</updated><authors><author><keyname>Pfitzner</keyname><forenames>Ren&#xe9;</forenames></author><author><keyname>Turitsyn</keyname><forenames>Konstantin</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Controlled Tripping of Overheated Lines Mitigates Power Outages</title><categories>physics.soc-ph cs.SY math.OC</categories><comments>7 pages, 6 figures, 1 diagram, revision of earlier version, included
  &quot;load shedding&quot; into the model, main message unchanged, manuscript enhanced</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the evolution of fast blackout cascades in the model of the Polish
(transmission) power grid (2700 nodes and 3504 transmission lines). The cascade
is initiated by a sufficiently severe initial contingency tripping. It
propagates via sequential trippings of many more overheated lines, islanding
loads and generators and eventually arriving at a fixed point with the
surviving part of the system being power-flow-balanced and the rest of the
system being outaged. Utilizing an improved form of the quasi-static model for
cascade propagation introduced in our earlier study (Statistical Classification
of Cascading Failures in Power Grids, IEEE PES GM 2011), we analyze how the
severity of the cascade depends on the order of tripping overheated lines. Our
main observation is that the order of tripping has a tremendous effect on the
size of the resulting outage. Finding the &quot;best&quot; tripping, defined as causing
the least damage, constitutes a difficult dynamical optimization problem, whose
solution is most likely computationally infeasible. Instead, here we study
performance of a number of natural heuristics, resolving the next switching
decision based on the current state of the grid. Overall, we conclude that
controlled intentional tripping is advantageous in the situation of a fast
developing extreme emergency, as it provides significant mitigation of the
resulting damage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4578</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4578</id><created>2011-04-23</created><updated>2011-08-05</updated><authors><author><keyname>Jiang</keyname><forenames>Bin</forenames></author><author><keyname>Jia</keyname><forenames>Tao</forenames></author></authors><title>Exploring Human Mobility Patterns Based on Location Information of US
  Flights</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>20 pages, 11 figures, 1 table, structural change from draft to this
  revision and more details on data processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A range of early studies have been conducted to illustrate human mobility
patterns using different tracking data, such as dollar notes, cell phones and
taxicabs. Here, we explore human mobility patterns based on massive tracking
data of US flights. Both topological and geometric properties are examined in
detail. We found that topological properties, such as traffic volume (between
airports) and degree of connectivity (of individual airports), including both
in- and outdegrees, follow a power law distribution but not a geometric
property like travel lengths. The travel lengths exhibit an exponential
distribution rather than a power law with an exponential cutoff as previous
studies illustrated. We further simulated human mobility on the established
topologies of airports with various moving behaviors and found that the
mobility patterns are mainly attributed to the underlying binary topology of
airports and have little to do with other factors, such as moving behaviors and
geometric distances. Apart from the above findings, this study adopts the
head/tail division rule, which is regularity behind any heavy-tailed
distribution for extracting individual airports. The adoption of this rule for
data processing constitutes another major contribution of this paper.
  Keywords: scaling of geographic space, head/tail division rule, power law,
geographic information, agent-based simulations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4582</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4582</id><created>2011-04-23</created><authors><author><keyname>G&#xf6;kta&#x15f;</keyname><forenames>&#xdc;nal</forenames></author><author><keyname>Hereman</keyname><forenames>Willy</forenames></author></authors><title>Symbolic Computation of Conservation Laws, Generalized Symmetries, and
  Recursion Operators for Nonlinear Differential-Difference Equations</title><categories>math-ph cs.SC math.AP math.MP nlin.SI</categories><comments>16 pages, will appear as Chapter 7 in a Springer Book entitled
  &quot;Nonlinear Systems and Methods For Mechanical, Electrical and Biosystems&quot;
  with editors: Albert Luo, J.A. Tenreiro Machado and Dumitru Baleanu, expected
  to be published in 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithms for the symbolic computation of polynomial conservation laws,
generalized symmetries, and recursion operators for systems of nonlinear
differential-difference equations (DDEs) are presented. The algorithms can be
used to test the complete integrability of nonlinear DDEs. The ubiquitous Toda
lattice illustrates the steps of the algorithms, which have been implemented in
{\em Mathematica}. The codes {\sc InvariantsSymmetries.m} and {\sc
DDERecursionOperator.m} can aid researchers interested in properties of
nonlinear DDEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4586</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4586</id><created>2011-04-23</created><authors><author><keyname>Alicea</keyname><forenames>Bradly</forenames></author></authors><title>Relativistic virtual worlds: an emerging framework</title><categories>cs.HC cs.CG q-bio.NC</categories><comments>14 pages, 5 figures</comments><acm-class>I.3.5; H.1.2; H.5.1; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, I will attempt to establish a framework for representation in
virtual worlds that may allow for input data from many different scales and
virtual physics to be merged. For example, a typical virtual environment must
effectively handle user input, sensor data, and virtual world physics all in
real- time. Merging all of these data into a single interactive system requires
that we adapt approaches from topological methods such as n-dimensional
relativistic representation. A number of hypothetical examples will be provided
throughout the paper to clarify technical challenges that need to be overcome
to realize this vision.
  The long-term goal of this work is that truly invariant representations will
ultimately result from establishing formal, inclusive relationships between
these different domains. Using this framework, incomplete information in one or
more domains can be compensated for by parallelism and mappings within the
virtual world representation. To introduce this approach, I will review recent
developments in embodiment, virtual world technology, and neuroscience relevant
to the control of virtual worlds. The next step will be to borrow ideas from
fields such as brain science, applied mathematics, and cosmology to give proper
perspective to this approach. A simple demonstration will then be given using
an intuitive example of physical relativism. Finally, future directions for the
application of this method will be considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4597</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4597</id><created>2011-04-23</created><authors><author><keyname>Rothvoss</keyname><forenames>Thomas</forenames></author></authors><title>The Entropy Rounding Method in Approximation Algorithms</title><categories>cs.DS math.CO</categories><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let A be a matrix, c be any linear objective function and x be a fractional
vector, say an LP solution to some discrete optimization problem. Then a
recurring task in theoretical computer science (and in approximation algorithms
in particular) is to obtain an integral vector y such that Ax is roughly Ay and
c*y exceeds c*x by only a moderate factor.
  We give a new randomized rounding procedure for this task, provided that A
has bounded Delta-approximate entropy. This property means that for uniformly
chosen random signs chi(j) in {-1,+1} on any subset of the columns, the outcome
A*chi can be approximately described using a sub-linear number of bits in
expectation.
  To achieve this result, we modify well-known techniques from the field of
discrepancy theory, especially we rely on Beck's entropy method, which to the
best of our knowledge has never been used before in the context of
approximation algorithms. Our result can be made constructive using the Bansal
framework based on semidefinite programming.
  We demonstrate the versatility of our procedure by rounding fractional
solutions to column-based linear programs for some generalizations of Bin
Packing. For example we obtain a polynomial time OPT + O(log^2 OPT)
approximation for Bin Packing With Rejection and the first AFPTAS for the Train
Delivery problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4601</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4601</id><created>2011-04-23</created><updated>2011-04-28</updated><authors><author><keyname>Lahiri</keyname><forenames>Shibamouli</forenames></author><author><keyname>Ram&#xed;rez</keyname><forenames>Juan Pablo Fern&#xe1;ndez</forenames></author><author><keyname>Nangia</keyname><forenames>Shikha</forenames></author><author><keyname>Mitra</keyname><forenames>Prasenjit</forenames></author><author><keyname>Giles</keyname><forenames>C. Lee</forenames></author><author><keyname>Mueller</keyname><forenames>Karl T.</forenames></author></authors><title>ChemXSeer Digital Library Gaussian Search</title><categories>cs.DL</categories><comments>4 pages, 6 figures, 2 tables</comments><acm-class>H.3.7; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on the Gaussian file search system designed as part of the
ChemXSeer digital library. Gaussian files are produced by the Gaussian software
[4], a software package used for calculating molecular electronic structure and
properties. The output files are semi-structured, allowing relatively easy
access to the Gaussian attributes and metadata. Our system is currently capable
of searching Gaussian documents using a boolean combination of atoms (chemical
elements) and attributes. We have also implemented a faceted browsing feature
on three important Gaussian attribute types - Basis Set, Job Type and Method
Used. The faceted browsing feature enables a user to view and process a
smaller, filtered subset of documents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4605</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4605</id><created>2011-04-24</created><authors><author><keyname>Jiang</keyname><forenames>Xiaoye</forenames></author><author><keyname>Yao</keyname><forenames>Yuan</forenames></author><author><keyname>Liu</keyname><forenames>Han</forenames></author><author><keyname>Guibas</keyname><forenames>Leonidas</forenames></author></authors><title>Compressive Network Analysis</title><categories>stat.ML cs.DM cs.LG cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern data acquisition routinely produces massive amounts of network data.
Though many methods and models have been proposed to analyze such data, the
research of network data is largely disconnected with the classical theory of
statistical learning and signal processing. In this paper, we present a new
framework for modeling network data, which connects two seemingly different
areas: network data analysis and compressed sensing. From a nonparametric
perspective, we model an observed network using a large dictionary. In
particular, we consider the network clique detection problem and show
connections between our formulation with a new algebraic tool, namely Randon
basis pursuit in homogeneous spaces. Such a connection allows us to identify
rigorous recovery conditions for clique detection problems. Though this paper
is mainly conceptual, we also develop practical approximation algorithms for
solving empirical problems and demonstrate their usefulness on real-world
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4606</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4606</id><created>2011-04-24</created><authors><author><keyname>Luo</keyname><forenames>Zhaohua</forenames></author></authors><title>Universal Algebra and Mathematical Logic</title><categories>math.LO cs.FL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, first-order logic is interpreted in the framework of universal
algebra, using the clone theory developed in three previous papers. We first
define the free clone T(L, C) of terms of a first order language L over a set C
of parameters in a standard way. The free right algebra F(L, C) of formulas
over T(L, C) is then generated by atomic formulas. Structures for L over C are
represented as perfect valuations of F(L, C), and theories of L are represented
as filters of F(L). Finally Godel's completeness theorem and first
incompleteness theorem are stated as expected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4607</identifier>
 <datestamp>2015-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4607</id><created>2011-04-24</created><updated>2011-07-07</updated><authors><author><keyname>Santipach</keyname><forenames>Wiroonsak</forenames></author><author><keyname>Mamat</keyname><forenames>Kritsada</forenames></author></authors><title>Tree-Structured Random Vector Quantization for Limited-Feedback Wireless
  Channels</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Wireless Communications, vol. 10, no. 9, pp.
  3012-3019, Sep. 2011</journal-ref><doi>10.1109/TWC.2011.072511.101916</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the quantization of a transmit beamforming vector in multiantenna
channels and of a signature vector in code division multiple access (CDMA)
systems. Assuming perfect channel knowledge, the receiver selects for a
transmitter the vector that maximizes the performance from a random vector
quantization (RVQ) codebook, which consists of independent isotropically
distributed unit-norm vectors. The quantized vector is then relayed to the
transmitter via a rate-limited feedback channel. The RVQ codebook requires an
exhaustive search to locate the selected entry. To reduce the search
complexity, we apply generalized Lloyd or $k$-dimensional (kd)-tree algorithms
to organize RVQ entries into a tree. In examples shown, the search complexity
of tree-structured (TS) RVQ can be a few orders of magnitude less than that of
the unstructured RVQ for the same performance. We also derive the performance
approximation for TS-RVQ in a large system limit, which predicts the
performance of a moderate-size system very well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4612</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4612</id><created>2011-04-24</created><authors><author><keyname>Nashtaali</keyname><forenames>Damoun</forenames></author><author><keyname>Mashayekhi</keyname><forenames>Omid</forenames></author><author><keyname>Pad</keyname><forenames>Pedram</forenames></author><author><keyname>Moghadasi</keyname><forenames>Seyed Reza</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>New Power Estimation Methods for Highly Overloaded Synchronous CDMA
  Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In CDMA systems, the received user powers vary due to moving distance of
users. Thus, the CDMA receivers consist of two stages. The first stage is the
power estimator and the second one is a Multi-User Detector (MUD). Conventional
methods for estimating the user powers are suitable for underor fully-loaded
cases (when the number of users is less than or equal to the spreading gain).
These methods fail to work for overloaded CDMA systems because of high
interference among the users. Since the bandwidth is becoming more and more
valuable, it is worth considering overloaded CDMA systems. In this paper, an
optimum user power estimation for over-loaded CDMA systems with Gaussian inputs
is proposed. We also introduce a suboptimum method with lower complexity whose
performance is very close to the optimum one. We shall show that the proposed
methods work for highly over-loaded systems (up to m(m + 1) =2 users for a
system with only m chips). The performance of the proposed methods is
demonstrated by simulations. In addition, a class of signature sets is proposed
that seems to be optimum from a power estimation point of view. Additionally,
an iterative estimation for binary input CDMA systems is proposed which works
more accurately than the optimal Gaussian input method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4617</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4617</id><created>2011-04-24</created><authors><author><keyname>Metodi</keyname><forenames>Amit</forenames></author><author><keyname>Codish</keyname><forenames>Michael</forenames></author><author><keyname>Lagoon</keyname><forenames>Vitaly</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author></authors><title>Boolean Equi-propagation for Optimized SAT Encoding</title><categories>cs.AI cs.DS cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach to propagation based solving, Boolean
equi-propagation, where constraints are modelled as propagators of information
about equalities between Boolean literals. Propagation based solving applies
this information as a form of partial evaluation resulting in optimized SAT
encodings. We demonstrate for a variety of benchmarks that our approach results
in smaller CNF encodings and leads to speed-ups in solving times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4618</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4618</id><created>2011-04-24</created><updated>2011-06-19</updated><authors><author><keyname>Alt</keyname><forenames>Helmut</forenames></author><author><keyname>Cabello</keyname><forenames>Sergio</forenames></author><author><keyname>Giannopoulos</keyname><forenames>Panos</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author></authors><title>Minimum cell connection and separation in line segment arrangements</title><categories>cs.CG cs.DS</categories><comments>21 pages, 9 figures. About half of the results have appeared in the
  abstracts of EuroCG'11</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of the following cell connection and separation
problems in segment arrangements. Given a set of straight-line segments in the
plane and two points $a$ and $b$ in different cells of the induced arrangement:
  (i) compute the minimum number of segments one needs to remove so that there
is a path connecting $a$ to $b$ that does not intersect any of the remaining
segments; (ii) compute the minimum number of segments one needs to remove so
that the arrangement induced by the remaining segments has a single cell; (iii)
compute the minimum number of segments one needs to retain so that any path
connecting $a$ to $b$ intersects some of the retained segments.
  We show that problems (i) and (ii) are NP-hard and discuss some special,
tractable cases. Most notably, we provide a linear-time algorithm for a variant
of problem (i) where the path connecting $a$ to $b$ must stay inside a given
polygon $P$ with a constant number of holes, the segments are contained in $P$,
and the endpoints of the segments are on the boundary of $P$. For problem (iii)
we provide a cubic-time algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4646</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4646</id><created>2011-04-24</created><authors><author><keyname>Halabi</keyname><forenames>Nissim</forenames></author><author><keyname>Even</keyname><forenames>Guy</forenames></author></authors><title>Local Optimality Certificates for LP Decoding of Tanner Codes</title><categories>cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new combinatorial characterization for local optimality of a
codeword in an irregular Tanner code. The main novelty in this characterization
is that it is based on a linear combination of subtrees in the computation
trees. These subtrees may have any degree in the local code nodes and may have
any height (even greater than the girth). We expect this new characterization
to lead to improvements in bounds for successful decoding.
  We prove that local optimality in this new characterization implies
ML-optimality and LP-optimality, as one would expect. Finally, we show that is
possible to compute efficiently a certificate for the local optimality of a
codeword given an LLR vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4656</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4656</id><created>2011-04-24</created><updated>2011-09-12</updated><authors><author><keyname>Fulek</keyname><forenames>Radoslav</forenames></author><author><keyname>Saeedi</keyname><forenames>Noushin</forenames></author><author><keyname>Sarioz</keyname><forenames>Deniz</forenames></author></authors><title>Convex obstacle numbers of outerplanar graphs and bipartite permutation
  graphs</title><categories>cs.DM cs.CG math.CO</categories><comments>11 pages, 6 figures</comments><msc-class>68R10, 05C10, 05C62</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The disjoint convex obstacle number of a graph G is the smallest number h
such that there is a set of h pairwise disjoint convex polygons (obstacles) and
a set of n points in the plane (corresponding to V(G)) so that a vertex pair uv
is an edge if and only if the corresponding segment uv does not meet any
obstacle.
  We show that the disjoint convex obstacle number of an outerplanar graph is
always at most 5, and of a bipartite permutation graph at most 4. The former
answers a question raised by Alpert, Koch, and Laison. We complement the upper
bound for outerplanar graphs with the lower bound of 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4657</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4657</id><created>2011-04-24</created><updated>2011-07-19</updated><authors><author><keyname>Ren</keyname><forenames>Shaolei</forenames></author><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Business Mode Selection in Digital Content Markets</title><categories>cs.SI</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NA
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4664</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4664</id><created>2011-04-24</created><authors><author><keyname>Bloch</keyname><forenames>Mitchell Keith</forenames></author></authors><title>Temporal Second Difference Traces</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Q-learning is a reliable but inefficient off-policy temporal-difference
method, backing up reward only one step at a time. Replacing traces, using a
recency heuristic, are more efficient but less reliable. In this work, we
introduce model-free, off-policy temporal difference methods that make better
use of experience than Watkins' Q(\lambda). We introduce both Optimistic
Q(\lambda) and the temporal second difference trace (TSDT). TSDT is
particularly powerful in deterministic domains. TSDT uses neither recency nor
frequency heuristics, storing (s,a,r,s',\delta) so that off-policy updates can
be performed after apparently suboptimal actions have been taken. There are
additional advantages when using state abstraction, as in MAXQ. We demonstrate
that TSDT does significantly better than both Q-learning and Watkins'
Q(\lambda) in a deterministic cliff-walking domain. Results in a noisy
cliff-walking domain are less advantageous for TSDT, but demonstrate the
efficacy of Optimistic Q(\lambda), a replacing trace with some of the
advantages of TSDT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4668</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4668</id><created>2011-04-24</created><authors><author><keyname>Ceriotti</keyname><forenames>Matteo</forenames></author><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author></authors><title>MGA trajectory planning with an ACO-inspired algorithm</title><categories>cs.CE cs.NE cs.SY math.OC</categories><journal-ref>Acta Astronautica, 67 (9-10). pp. 1202-1217, ISSN 0094-5765, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of celestial bodies, the problem of finding an optimal sequence
of swing-bys, deep space manoeuvres (DSM) and transfer arcs connecting the
elements of the set is combinatorial in nature. The number of possible paths
grows exponentially with the number of celestial bodies. Therefore, the design
of an optimal multiple gravity assist (MGA) trajectory is a NP-hard mixed
combinatorial-continuous problem. Its automated solution would greatly improve
the design of future space missions, allowing the assessment of a large number
of alternative mission options in a short time. This work proposes to formulate
the complete automated design of a multiple gravity assist trajectory as an
autonomous planning and scheduling problem. The resulting scheduled plan will
provide the optimal planetary sequence and a good estimation of the set of
associated optimal trajectories. The trajectory model consists of a sequence of
celestial bodies connected by twodimensional transfer arcs containing one DSM.
For each transfer arc, the position of the planet and the spacecraft, at the
time of arrival, are matched by varying the pericentre of the preceding
swing-by, or the magnitude of the launch excess velocity, for the first arc.
For each departure date, this model generates a full tree of possible transfers
from the departure to the destination planet. Each leaf of the tree represents
a planetary encounter and a possible way to reach that planet. An algorithm
inspired by Ant Colony Optimization (ACO) is devised to explore the space of
possible plans. The ants explore the tree from departure to destination adding
one node at the time: every time an ant is at a node, a probability function is
used to select a feasible direction. This approach to automatic trajectory
planning is applied to the design of optimal transfers to Saturn and among the
Galilean moons of Jupiter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4669</identifier>
 <datestamp>2012-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4669</id><created>2011-04-24</created><updated>2012-08-12</updated><authors><author><keyname>Grigni</keyname><forenames>Michelangelo</forenames></author><author><keyname>Hung</keyname><forenames>Hao-Hsiang</forenames></author></authors><title>Finding Light Spanners in Bounded Pathwidth Graphs</title><categories>cs.DS</categories><comments>10 pages, 3 figures; 37th International Symposium on Mathematical
  Foundations of Computer Science (MFCS 2012)</comments><acm-class>F.2.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Given an edge-weighted graph $G$ and $\epsilon&gt;0$, a $(1+\epsilon)$-spanner
is a spanning subgraph $G'$ whose shortest path distances approximate those of
$G$ within a $(1+\epsilon)$ factor. If $G$ is from certain minor-closed graph
families (at least bounded genus graphs and apex graphs), then we know that
light spanners exist. That is, we can compute a $(1+\epsilon)$-spanner $G'$
with total edge weight at most a constant times the weight of a minimum
spanning tree. This constant may depend on $\epsilon$ and the graph family, but
not on the particular graph $G$ nor on its edge weighting. For weighted graphs
from several minor-closed graph families, the existence of light spanners has
been essential in the design of approximation schemes for the metric TSP (the
traveling salesman problem) and some similar problems. In this paper we make
some progress towards the conjecture that light spanners exist for every
minor-closed graph family. In particular, we show that they exist for graphs
with bounded pathwidth. We do this via the construction of light enough
monotone spanning trees in such graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4670</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4670</id><created>2011-04-24</created><authors><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author><author><keyname>Colombo</keyname><forenames>Camilla</forenames></author></authors><title>Optimal impact strategies for asteroid deflection</title><categories>math.OC cs.NE cs.SY</categories><journal-ref>Journal of Guidance, Control and Dynamics, 31 (4). pp. 858-872.
  ISSN 0731-5090, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analysis of optimal impact strategies to deflect
potentially dangerous asteroids. To compute the increase in the minimum orbit
intersection distance of the asteroid due to an impact with a spacecraft,
simple analytical formulas are derived from proximal motion equations. The
proposed analytical formulation allows for an analysis of the optimal direction
of the deviating impulse transferred to the asteroid. This ideal optimal
direction cannot be achieved for every asteroid at any time; therefore, an
analysis of the optimal launch opportunities for deviating a number of selected
asteroids was performed through the use of a global optimization procedure. The
results in this paper demonstrate that the proximal motion formulation has very
good accuracy in predicting the actual deviation and can be used with any
deviation method because it has general validity. Furthermore, the
characterization of optimal launch opportunities shows that a significant
deviation can be obtained even with a small spacecraft.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4674</identifier>
 <datestamp>2012-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4674</id><created>2011-04-24</created><updated>2012-10-11</updated><authors><author><keyname>Indyk</keyname><forenames>Piotr</forenames></author><author><keyname>Price</keyname><forenames>Eric</forenames></author></authors><title>K-Median Clustering, Model-Based Compressive Sensing, and Sparse
  Recovery for Earth Mover Distance</title><categories>cs.DS cs.IT math.IT</categories><comments>21 pages. Appeared in STOC 2011. This version corrects a bug in the
  proof of Theorem B.5</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We initiate the study of sparse recovery problems under the Earth-Mover
Distance (EMD). Specifically, we design a distribution over m x n matrices A
such that for any x, given Ax, we can recover a k-sparse approximation to x
under the EMD distance. One construction yields m = O(k log(n/k)) and a 1 +
epsilon approximation factor, which matches the best achievable bound for other
error measures, such as the L_1 norm. Our algorithms are obtained by exploiting
novel connections to other problems and areas, such as streaming algorithms for
k-median clustering and model-based compressive sensing. We also provide novel
algorithms and results for the latter problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4680</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4680</id><created>2011-04-25</created><authors><author><keyname>Barak</keyname><forenames>Boaz</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author><author><keyname>Steurer</keyname><forenames>David</forenames></author></authors><title>Rounding Semidefinite Programming Hierarchies via Global Correlation</title><categories>cs.DS cs.CC</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a new way to round vector solutions of semidefinite programming (SDP)
hierarchies into integral solutions, based on a connection between these
hierarchies and the spectrum of the input graph. We demonstrate the utility of
our method by providing a new SDP-hierarchy based algorithm for constraint
satisfaction problems with 2-variable constraints (2-CSP's).
  More concretely, we show for every 2-CSP instance I a rounding algorithm for
r rounds of the Lasserre SDP hierarchy for I that obtains an integral solution
that is at most \eps worse than the relaxation's value (normalized to lie in
[0,1]), as long as r &gt; k\cdot\rank_{\geq \theta}(\Ins)/\poly(\e) \;, where k is
the alphabet size of I, $\theta=\poly(\e/k)$, and $\rank_{\geq \theta}(\Ins)$
denotes the number of eigenvalues larger than $\theta$ in the normalized
adjacency matrix of the constraint graph of $\Ins$.
  In the case that $\Ins$ is a \uniquegames instance, the threshold $\theta$ is
only a polynomial in $\e$, and is independent of the alphabet size. Also in
this case, we can give a non-trivial bound on the number of rounds for
\emph{every} instance. In particular our result yields an SDP-hierarchy based
algorithm that matches the performance of the recent subexponential algorithm
of Arora, Barak and Steurer (FOCS 2010) in the worst case, but runs faster on a
natural family of instances, thus further restricting the set of possible hard
instances for Khot's Unique Games Conjecture.
  Our algorithm actually requires less than the $n^{O(r)}$ constraints
specified by the $r^{th}$ level of the Lasserre hierarchy, and in some cases
$r$ rounds of our program can be evaluated in time $2^{O(r)}\poly(n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4681</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4681</id><created>2011-04-25</created><authors><author><keyname>Rao</keyname><forenames>R. Rajeswara</forenames></author><author><keyname>Prasad</keyname><forenames>V. Kamakshi</forenames></author><author><keyname>Nagesh</keyname><forenames>A.</forenames></author></authors><title>Performance Evaluation of Statistical Approaches for Text Independent
  Speaker Recognition Using Source Feature</title><categories>cs.CL</categories><comments>8 pages, 7 figures, International Journal</comments><journal-ref>InterJRI Computer Science and Networking, Volume 2, Issue 1 August
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the performance evaluation of statistical approaches
for TextIndependent speaker recognition system using source feature. Linear
prediction LP residual is used as a representation of excitation information in
speech. The speaker-specific information in the excitation of voiced speech is
captured using statistical approaches such as Gaussian Mixture Models GMMs and
Hidden Markov Models HMMs. The decrease in the error during training and
recognizing speakers during testing phase close to 100 percent accuracy
demonstrates that the excitation component of speech contains speaker-specific
information and is indeed being effectively captured by continuous Ergodic HMM
than GMM. The performance of the speaker recognition system is evaluated on GMM
and 2 state ergodic HMM with different mixture components and test speech
duration. We demonstrate the speaker recognition studies on TIMIT database for
both GMM and Ergodic HMM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4687</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4687</id><created>2011-04-25</created><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author></authors><title>Class two 1-planar graphs with maximum degree six or seven</title><categories>math.CO cs.DM</categories><comments>3 pages, 2 figures</comments><msc-class>05C10, 05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is 1-planar if it can be drawn on the plane so that each edge is
crossed by at most one other edge. In this note we give examples of class two
1-planar graphs with maximum degree six or seven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4690</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4690</id><created>2011-04-25</created><authors><author><keyname>Anitha</keyname><forenames>V.</forenames></author><author><keyname>Akilandeswari</keyname><forenames>Dr. J.</forenames></author></authors><title>Secured Message Transmission in Mobile AD HOC Networks through
  Identification and Removal of Byzantine Failures</title><categories>cs.NI cs.PF</categories><comments>5 pages, 6 figures</comments><journal-ref>InterJRI Computer Science and Networking Volume 1 Issue 1, pp 14-
  18 August 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emerging need for mobile ad hoc networks and secured data transmission
phase is of crucial importance depending upon the environments like military.
In this paper, a new way to improve the reliability of message transmission is
presented. In the open collaborative MANET environment, any node can
maliciously or selfishly disrupt and deny communication of other nodes. Dynamic
changing topology makes it hard to determine the adversary nodes that affect
the communication in MANET. An SMT protocol provides a way to secure message
transmission by dispersing the message among several paths with minimal
redundancy. The multiple routes selected are known as APS -Active Path Set.
This paper describes a technique for fault discovery process to identify
Byzantine failures which include nodes that drop, modify, or mis-route packets
in an attempt to disrupt the routing service. An adaptive probing technique
detects a malicious link through binary search and according to the nodes
behavior, these links are avoided in the active path by multiplicatively
increasing their weights. The proposed scheme provides secure communication
even with increased number of adversaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4696</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4696</id><created>2011-04-25</created><authors><author><keyname>Biswas</keyname><forenames>Soham</forenames></author><author><keyname>Sen</keyname><forenames>Parongama</forenames></author><author><keyname>Ray</keyname><forenames>Purusattam</forenames></author></authors><title>Opinion dynamics model with domain size dependent dynamics: novel
  features and new universality class</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>12 pages, 10 figures. To be published in &quot;Journal of Physics :
  Conference Series&quot; (2011)</comments><journal-ref>Journal of Physics : Conference series 297, 012003 (2011)</journal-ref><doi>10.1088/1742-6596/297/1/012003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model for opinion dynamics (Model I) has been recently introduced in which
the binary opinions of the individuals are determined according to the size of
their neighboring domains (population having the same opinion). The coarsening
dynamics of the equivalent Ising model shows power law behavior and has been
found to belong to a new universality class with the dynamic exponent $z=1.0
\pm 0.01$ and persistence exponent $\theta \simeq 0.235$ in one dimension. The
critical behavior has been found to be robust for a large variety of annealed
disorder that has been studied. Further, by mapping Model I to a system of
random walkers in one dimension with a tendency to walk towards their nearest
neighbour with probability $\epsilon$, we find that for any $\epsilon &gt; 0.5$,
the Model I dynamical behaviour is prevalent at long times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4702</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4702</id><created>2011-04-25</created><updated>2011-04-30</updated><authors><author><keyname>Wang</keyname><forenames>Tao</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Sum Rate Maximized Resource Allocation in Multiple DF Relays Aided OFDM
  Transmission</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>13 pages in two-column format, 10 figures, to appear in IEEE Journal
  on Selected Areas in Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In relay-aided wireless transmission systems, one of the key issues is how to
decide assisting relays and manage the energy resource at the source and each
individual relay, to maximize a certain objective related to system
performance. This paper addresses the sum rate maximized resource allocation
(RA) problem in a point to point orthogonal frequency division modulation
(OFDM) transmission system assisted by multiple decode-and-forward (DF) relays,
subject to the individual sum power constraints of the source and the relays.
In particular, the transmission at each subcarrier can be in either the direct
mode without any relay assisting, or the relay-aided mode with one or several
relays assisting. We propose two RA algorithms which optimize the assignment of
transmission mode and source power for every subcarrier, as well as the
assisting relays and the power allocation to them for every {relay-aided}
subcarrier. First, it is shown that the considered RA problem has zero
Lagrangian duality gap when there is a big number of subcarriers. In this case,
a duality based algorithm that finds a globally optimum RA is developed.
Second, a coordinate-ascent based iterative algorithm, which finds a suboptimum
RA but is always applicable regardless of the duality gap of the RA problem, is
developed. The effectiveness of these algorithms has been illustrated by
numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4704</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4704</id><created>2011-04-25</created><updated>2012-04-12</updated><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Kim</keyname><forenames>Junae</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author></authors><title>Positive Semidefinite Metric Learning Using Boosting-like Algorithms</title><categories>cs.CV</categories><comments>30 pages, appearing in Journal of Machine Learning Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success of many machine learning and pattern recognition methods relies
heavily upon the identification of an appropriate distance metric on the input
data. It is often beneficial to learn such a metric from the input training
data, instead of using a default one such as the Euclidean distance. In this
work, we propose a boosting-based technique, termed BoostMetric, for learning a
quadratic Mahalanobis distance metric. Learning a valid Mahalanobis distance
metric requires enforcing the constraint that the matrix parameter to the
metric remains positive definite. Semidefinite programming is often used to
enforce this constraint, but does not scale well and easy to implement.
BoostMetric is instead based on the observation that any positive semidefinite
matrix can be decomposed into a linear combination of trace-one rank-one
matrices. BoostMetric thus uses rank-one positive semidefinite matrices as weak
learners within an efficient and scalable boosting-based learning process. The
resulting methods are easy to implement, efficient, and can accommodate various
types of constraints. We extend traditional boosting algorithms in that its
weak learner is a positive semidefinite matrix with trace and rank being one
rather than a classifier or regressor. Experiments on various datasets
demonstrate that the proposed algorithms compare favorably to those
state-of-the-art methods in terms of classification accuracy and running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4711</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4711</id><created>2011-04-25</created><authors><author><keyname>Barbu</keyname><forenames>Viorel</forenames></author></authors><title>Internal stabilization of the Oseen-Stokes equations by Stratonovich
  noise</title><categories>math.OC cs.SY</categories><msc-class>35Q30, 60H15, 35B40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One designs an internal Stratonovich noise feedback controller which
exponentially stabilizes the staedy state solutions to Oseen-Stokes equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4720</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4720</id><created>2011-04-25</created><authors><author><keyname>Tusserkani</keyname><forenames>Ruzbeh</forenames></author><author><keyname>Eslahchi</keyname><forenames>Changiz</forenames></author><author><keyname>Poormohammadi</keyname><forenames>Hadi</forenames></author><author><keyname>Azadi</keyname><forenames>Azin</forenames></author></authors><title>TripNet: A Method for Constructing Phylogenetic Networks from Triplets</title><categories>cs.CE q-bio.PE q-bio.QM</categories><comments>12 pages, 14 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present TripNet, a method for constructing phylogenetic networks from
triplets. We will present the motivations behind our approach and its
theoretical and empirical justification. To demonstrate the accuracy and
efficiency of TripNet, we performed two simulations and also applied the method
to five published data sets: Kreitman's data, a set of triplets from real yeast
data obtained from the Fungal Biodiversity Center in Utrecht, a collection of
110 highly recombinant Salmonella multi-locus sequence typing sequences, and
nrDNA ITS and cpDNA JSA sequence data of New Zealand alpine buttercups of
Ranunculus sect. Pseudadonis. Finally, we compare our results with those
already obtained by other authors using alternative methods. TripNet, data
sets, and supplementary files are freely available for download at
(www.bioinf.cs.ipm.ir/softwares/tripnet).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4723</identifier>
 <datestamp>2011-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4723</id><created>2011-04-25</created><authors><author><keyname>Bueno</keyname><forenames>Lucas Moutinho</forenames></author><author><keyname>Valle</keyname><forenames>Eduardo</forenames></author><author><keyname>Torres</keyname><forenames>Ricardo da Silva</forenames></author></authors><title>Bayesian approach for near-duplicate image detection</title><categories>cs.CV cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a bayesian approach for near-duplicate image
detection, and investigate how different probabilistic models affect the
performance obtained. The task of identifying an image whose metadata are
missing is often demanded for a myriad of applications: metadata retrieval in
cultural institutions, detection of copyright violations, investigation of
latent cross-links in archives and libraries, duplicate elimination in storage
management, etc. The majority of current solutions are based either on voting
algorithms, which are very precise, but expensive; either on the use of visual
dictionaries, which are efficient, but less precise. Our approach, uses local
descriptors in a novel way, which by a careful application of decision theory,
allows a very fine control of the compromise between precision and efficiency.
In addition, the method attains a great compromise between those two axes, with
more than 99% accuracy with less than 10 database operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4725</identifier>
 <datestamp>2011-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4725</id><created>2011-04-25</created><updated>2011-07-05</updated><authors><author><keyname>Shi</keyname><forenames>Yufeng</forenames></author><author><keyname>Wang</keyname><forenames>Tianxiao</forenames></author><author><keyname>Yong</keyname><forenames>Jiongmin</forenames></author></authors><title>Mean-Field Backward Stochastic Volterra Integral Equations</title><categories>math.PR cs.SY math.OC</categories><comments>54 pages</comments><msc-class>60H20, 93E20, 35Q83</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean-field backward stochastic Volterra integral equations (MF-BSVIEs, for
short) are introduced and studied. Well-posedness of MF-BSVIEs in the sense of
introduced adapted M-solutions is established. Two duality principles between
linear mean-field (forward) stochastic Volterra integral equations (MF-FSVIEs,
for short) and MF-BSVIEs are obtained. As applications, a multi-dimensional
comparison theorem is proved for adapted M-solutions of MF-BSVIEs and a maximum
principle is established for an optimal control of MF-FSVIEs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4728</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4728</id><created>2011-04-25</created><updated>2011-05-10</updated><authors><author><keyname>Klein</keyname><forenames>Philip N.</forenames></author><author><keyname>Mozes</keyname><forenames>Shay</forenames></author></authors><title>Multiple-Source Single-Sink Maximum Flow in Directed Planar Graphs in
  O(diameter*n*log(n)) Time</title><categories>cs.DM cs.DS</categories><comments>proofs included. preliminary version to appear in WADS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new technique for computing maximum flow in directed planar
graphs with multiple sources and a single sink that significantly deviates from
previously known techniques for flow problems. This gives rise to an
O(diameter*n*log(n)) algorithm for the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4731</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4731</id><created>2011-04-25</created><authors><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author><author><keyname>Minisci</keyname><forenames>Edmondo</forenames></author><author><keyname>Locatelli</keyname><forenames>Marco</forenames></author></authors><title>An inflationary differential evolution algorithm for space trajectory
  optimization</title><categories>cs.CE cs.NA cs.NE cs.SY math.OC nlin.CD</categories><comments>IEEE Transactions on Evolutionary Computation 2011. ISSN 1089-778X</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we define a discrete dynamical system that governs the
evolution of a population of agents. From the dynamical system, a variant of
Differential Evolution is derived. It is then demonstrated that, under some
assumptions on the differential mutation strategy and on the local structure of
the objective function, the proposed dynamical system has fixed points towards
which it converges with probability one for an infinite number of generations.
This property is used to derive an algorithm that performs better than standard
Differential Evolution on some space trajectory optimization problems. The
novel algorithm is then extended with a guided restart procedure that further
increases the performance, reducing the probability of stagnation in deceptive
local minima.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4746</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4746</id><created>2011-04-25</created><updated>2011-05-17</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Sinop</keyname><forenames>Ali Kemal</forenames></author></authors><title>Lasserre Hierarchy, Higher Eigenvalues, and Approximation Schemes for
  Quadratic Integer Programming with PSD Objectives</title><categories>cs.CC cs.DS</categories><comments>43 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approximation scheme for optimizing certain Quadratic Integer
Programming problems with positive semidefinite objective functions and global
linear constraints. This framework includes well known graph problems such as
Minimum graph bisection, Edge expansion, Uniform sparsest cut, and Small Set
expansion, as well as the Unique Games problem. These problems are notorious
for the existence of huge gaps between the known algorithmic results and
NP-hardness results. Our algorithm is based on rounding semidefinite programs
from the Lasserre hierarchy, and the analysis uses bounds for low-rank
approximations of a matrix in Frobenius norm using columns of the matrix.
  For all the above graph problems, we give an algorithm running in time
$n^{O(r/\epsilon^2)}$ with approximation ratio
$\frac{1+\epsilon}{\min\{1,\lambda_r\}}$, where $\lambda_r$ is the $r$'th
smallest eigenvalue of the normalized graph Laplacian $\mathcal{L}$. In the
case of graph bisection and small set expansion, the number of vertices in the
cut is within lower-order terms of the stipulated bound. Our results imply
$(1+O(\epsilon))$ factor approximation in time $n^{O(r^\ast/\epsilon^2)}$ where
$r^\ast$ is the number of eigenvalues of $\mathcal{L}$ smaller than
$1-\epsilon$.
  For Unique Games, we give a factor $(1+\frac{2+\epsilon}{\lambda_r})$
approximation for minimizing the number of unsatisfied constraints in
$n^{O(r/\epsilon)}$ time. This improves an earlier bound for solving Unique
Games on expanders, and also shows that Lasserre SDPs are powerful enough to
solve well-known integrality gap instances for the basic SDP.
  We also give an algorithm for independent sets in graphs that performs well
when the Laplacian does not have too many eigenvalues bigger than $1+o(1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4779</identifier>
 <datestamp>2014-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4779</id><created>2011-04-25</created><updated>2014-10-29</updated><authors><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author><author><keyname>Paulusma</keyname><forenames>Daniel</forenames></author></authors><title>The Computational Complexity of Disconnected Cut and 2K2-Partition</title><categories>cs.CC</categories><comments>Conference version appeared at CP 2011. To appear JCTB (DOI:
  10.1016/j.jctb.2014.09.002)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a connected graph G=(V,E), a subset U of V is called a disconnected cut
if U disconnects the graph and the subgraph induced by U is disconnected as
well. We show that the problem to test whether a graph has a disconnected cut
is NP-complete. This problem is polynomially equivalent to the following
problems: testing if a graph has a 2K2-partition, testing if a graph allows a
vertex-surjective homomorphism to the reflexive 4-cycle and testing if a graph
has a spanning subgraph that consists of at most two bicliques. Hence, as an
immediate consequence, these three decision problems are NP-complete as well.
This settles an open problem frequently posed in each of the four settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4803</identifier>
 <datestamp>2014-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4803</id><created>2011-04-25</created><updated>2014-07-23</updated><authors><author><keyname>Chen</keyname><forenames>Yudong</forenames></author><author><keyname>Jalali</keyname><forenames>Ali</forenames></author><author><keyname>Sanghavi</keyname><forenames>Sujay</forenames></author><author><keyname>Xu</keyname><forenames>Huan</forenames></author></authors><title>Clustering Partially Observed Graphs via Convex Optimization</title><categories>cs.LG stat.ML</categories><comments>This is the final version published in Journal of Machine Learning
  Research (JMLR). Partial results appeared in International Conference on
  Machine Learning (ICML) 2011</comments><journal-ref>Journal of Machine Learning Research, vol. 15, pp. 2213-2238, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of clustering a partially observed
unweighted graph---i.e., one where for some node pairs we know there is an edge
between them, for some others we know there is no edge, and for the remaining
we do not know whether or not there is an edge. We want to organize the nodes
into disjoint clusters so that there is relatively dense (observed)
connectivity within clusters, and sparse across clusters.
  We take a novel yet natural approach to this problem, by focusing on finding
the clustering that minimizes the number of &quot;disagreements&quot;---i.e., the sum of
the number of (observed) missing edges within clusters, and (observed) present
edges across clusters. Our algorithm uses convex optimization; its basis is a
reduction of disagreement minimization to the problem of recovering an
(unknown) low-rank matrix and an (unknown) sparse matrix from their partially
observed sum. We evaluate the performance of our algorithm on the classical
Planted Partition/Stochastic Block Model. Our main theorem provides sufficient
conditions for the success of our algorithm as a function of the minimum
cluster size, edge density and observation probability; in particular, the
results characterize the tradeoff between the observation probability and the
edge density gap. When there are a constant number of clusters of equal size,
our results are optimal up to logarithmic factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4805</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4805</id><created>2011-04-25</created><updated>2013-01-25</updated><authors><author><keyname>Sahai</keyname><forenames>Achaleshwar</forenames></author><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Capacity of All Nine Models of Channel Output Feedback for the Two-user
  Interference Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory, results
  improved by deriving capacity region of all 9 canonical feedback models in
  two-user interference channel</comments><journal-ref>IEEE Transactions on Information Theory, vol.59, no.11,
  pp.6957,6979, Nov. 2013</journal-ref><doi>10.1109/TIT.2013.2278691</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the impact of different channel output feedback
architectures on the capacity of the two-user interference channel. For a
two-user interference channel, a feedback link can exist between receivers and
transmitters in 9 canonical architectures (see Fig. 2), ranging from only one
feedback link to four feedback links. We derive the exact capacity region for
the symmetric deterministic interference channel and the constant-gap capacity
region for the symmetric Gaussian interference channel for all of the 9
architectures. We show that for a linear deterministic symmetric interference
channel, in the weak interference regime, all models of feedback, except the
one, which has only one of the receivers feeding back to its own transmitter,
have the identical capacity region. When only one of the receivers feeds back
to its own transmitter, the capacity region is a strict subset of the capacity
region of the rest of the feedback models in the weak interference regime.
However, the sum-capacity of all feedback models is identical in the weak
interference regime. Moreover, in the strong interference regime all models of
feedback with at least one of the receivers feeding back to its own transmitter
have the identical sum-capacity. For the Gaussian interference channel, the
results of the linear deterministic model follow, where capacity is replaced
with approximate capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4824</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4824</id><created>2011-04-25</created><updated>2012-07-25</updated><authors><author><keyname>Agarwal</keyname><forenames>Alekh</forenames></author><author><keyname>Negahban</keyname><forenames>Sahand N.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Fast global convergence of gradient methods for high-dimensional
  statistical recovery</title><categories>stat.ML cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many statistical $M$-estimators are based on convex optimization problems
formed by the combination of a data-dependent loss function with a norm-based
regularizer. We analyze the convergence rates of projected gradient and
composite gradient methods for solving such problems, working within a
high-dimensional framework that allows the data dimension $\pdim$ to grow with
(and possibly exceed) the sample size $\numobs$. This high-dimensional
structure precludes the usual global assumptions---namely, strong convexity and
smoothness conditions---that underlie much of classical optimization analysis.
We define appropriately restricted versions of these conditions, and show that
they are satisfied with high probability for various statistical models. Under
these conditions, our theory guarantees that projected gradient descent has a
globally geometric rate of convergence up to the \emph{statistical precision}
of the model, meaning the typical distance between the true unknown parameter
$\theta^*$ and an optimal solution $\hat{\theta}$. This result is substantially
sharper than previous convergence results, which yielded sublinear convergence,
or linear convergence only up to the noise level. Our analysis applies to a
wide range of $M$-estimators and statistical models, including sparse linear
regression using Lasso ($\ell_1$-regularized regression); group Lasso for block
sparsity; log-linear models with regularization; low-rank matrix recovery using
nuclear norm regularization; and matrix decomposition. Overall, our analysis
reveals interesting connections between statistical precision and computational
efficiency in high-dimensional estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4842</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4842</id><created>2011-04-26</created><updated>2012-05-30</updated><authors><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author><author><keyname>Laska</keyname><forenames>Jason N.</forenames></author><author><keyname>Treichler</keyname><forenames>John R.</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>The Pros and Cons of Compressive Sensing for Wideband Signal
  Acquisition: Noise Folding vs. Dynamic Range</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2012.2201149</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing (CS) exploits the sparsity present in many signals to
reduce the number of measurements needed for digital acquisition. With this
reduction would come, in theory, commensurate reductions in the size, weight,
power consumption, and/or monetary cost of both signal sensors and any
associated communication links. This paper examines the use of CS in the design
of a wideband radio receiver in a noisy environment. We formulate the problem
statement for such a receiver and establish a reasonable set of requirements
that a receiver should meet to be practically useful. We then evaluate the
performance of a CS-based receiver in two ways: via a theoretical analysis of
its expected performance, with a particular emphasis on noise and dynamic
range, and via simulations that compare the CS receiver against the performance
expected from a conventional implementation. On the one hand, we show that
CS-based systems that aim to reduce the number of acquired measurements are
somewhat sensitive to signal noise, exhibiting a 3dB SNR loss per octave of
subsampling, which parallels the classic noise-folding phenomenon. On the other
hand, we demonstrate that since they sample at a lower rate, CS-based systems
can potentially attain a significantly larger dynamic range. Hence, we conclude
that while a CS-based system has inherent limitations that do impose some
restrictions on its potential applications, it also has attributes that make it
highly desirable in a number of important practical settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4843</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4843</id><created>2011-04-26</created><authors><author><keyname>Simmons</keyname><forenames>Patrick</forenames></author></authors><title>Security Through Amnesia: A Software-Based Solution to the Cold Boot
  Attack on Disk Encryption</title><categories>cs.CR</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Disk encryption has become an important security measure for a multitude of
clients, including governments, corporations, activists, security-conscious
professionals, and privacy-conscious individuals. Unfortunately, recent
research has discovered an effective side channel attack against any disk
mounted by a running machine\cite{princetonattack}. This attack, known as the
cold boot attack, is effective against any mounted volume using
state-of-the-art disk encryption, is relatively simple to perform for an
attacker with even rudimentary technical knowledge and training, and is
applicable to exactly the scenario against which disk encryption is primarily
supposed to defend: an adversary with physical access. To our knowledge, no
effective software-based countermeasure to this attack supporting multiple
encryption keys has yet been articulated in the literature. Moreover, since no
proposed solution has been implemented in publicly available software, all
general-purpose machines using disk encryption remain vulnerable. We present
Loop-Amnesia, a kernel-based disk encryption mechanism implementing a novel
technique to eliminate vulnerability to the cold boot attack. We offer
theoretical justification of Loop-Amnesia's invulnerability to the attack,
verify that our implementation is not vulnerable in practice, and present
measurements showing our impact on I/O accesses to the encrypted disk is
limited to a slowdown of approximately 2x. Loop-Amnesia is written for x86-64,
but our technique is applicable to other register-based architectures. We base
our work on loop-AES, a state-of-the-art open source disk encryption package
for Linux.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4874</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4874</id><created>2011-04-26</created><updated>2013-01-07</updated><authors><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>LIKWID: Lightweight Performance Tools</title><categories>cs.DC cs.PF</categories><comments>12 pages</comments><doi>10.1109/ICPPW.2010.38</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exploiting the performance of today's microprocessors requires intimate
knowledge of the microarchitecture as well as an awareness of the ever-growing
complexity in thread and cache topology. LIKWID is a set of command line
utilities that addresses four key problems: Probing the thread and cache
topology of a shared-memory node, enforcing thread-core affinity on a program,
measuring performance counter metrics, and microbenchmarking for reliable upper
performance bounds. Moreover, it includes a mpirun wrapper allowing for
portable thread-core affinity in MPI and hybrid MPI/threaded applications. To
demonstrate the capabilities of the tool set we show the influence of thread
affinity on performance using the well-known OpenMP STREAM triad benchmark, use
hardware counter tools to study the performance of a stencil code, and finally
show how to detect bandwidth problems on ccNUMA-based compute nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4887</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4887</id><created>2011-04-26</created><authors><author><keyname>del R&#xed;o</keyname><forenames>Ana Fern&#xe1;ndez</forenames></author></authors><title>Coupled Ising models and interdependent discrete choices under social
  influence in homogeneous populations</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>Master thesis, 100 pages, 39 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of statistical physics to study problems of social sciences is
motivated and its current state of the art briefly reviewed, in particular for
the case of discrete choice making. The coupling of two binary choices is
studied in some detail, using an Ising model for each of the decision variables
(the opinion or choice moments or spins, socioeconomic equivalents to the
magnetic moments or spins). Toy models for two different types of coupling are
studied analytically and numerically in the mean field (infinite range)
approximation. This is equivalent to considering a social influence effect
proportional to the fraction of adopters or average magnetisation. In the
nonlocal case, the two spin variables are coupled through a Weiss mean field
type term. In a socioeconomic context, this can be useful when studying
individuals of two different groups, making the same decision under social
influence of their own group, when their outcome is affected by the fraction of
adopters of the other group. In the local case, the two spin variables are
coupled only through each individual. This accounts to considering individuals
of a single group each making two different choices which affect each other. In
both cases, only constant (intra- and inter-) couplings and external fields are
considered, i.e., only completely homogeneous populations. Most of the results
presented are for the zero field case, i.e. no externalities or private
utilities. Phase diagrams and their interpretation in a socioeconomic context
are discussed and compared to the uncoupled case. The two systems share many
common features including the existence of both first and second order phase
transitions, metastability and hysteresis. To conclude, some general remarks,
pointing out the limitations of these models and suggesting further
improvements are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4890</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4890</id><created>2011-04-26</created><authors><author><keyname>&#x141;\kacki</keyname><forenames>Jakub</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author></authors><title>Min-cuts and Shortest Cycles in Planar Graphs in O(n log log n) Time</title><categories>cs.DS</categories><msc-class>05C85, 05C10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a deterministic O(n log log n) time algorithm for finding shortest
cycles and minimum cuts in planar graphs. The algorithm improves the previously
known fastest algorithm by Italiano et al. in STOC'11 by a factor of log n.
This speedup is obtained through the use of dense distance graphs combined with
a divide-and-conquer approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4892</identifier>
 <datestamp>2015-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4892</id><created>2011-04-26</created><updated>2013-04-26</updated><authors><author><keyname>Chang</keyname><forenames>Hsien-Chih</forenames></author><author><keyname>Lu</keyname><forenames>Hsueh-I</forenames></author></authors><title>Computing the Girth of a Planar Graph in Linear Time</title><categories>cs.DS</categories><comments>20 pages, 7 figures, accepted to SIAM Journal on Computing</comments><journal-ref>SIAM Journal on Computing 42(3): 1077-1094 (2013)</journal-ref><doi>10.1137/110832033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The girth of a graph is the minimum weight of all simple cycles of the graph.
We study the problem of determining the girth of an n-node unweighted
undirected planar graph. The first non-trivial algorithm for the problem, given
by Djidjev, runs in O(n^{5/4} log n) time. Chalermsook, Fakcharoenphol, and
Nanongkai reduced the running time to O(n log^2 n). Weimann and Yuster further
reduced the running time to O(n log n). In this paper, we solve the problem in
O(n) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4899</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4899</id><created>2011-04-26</created><authors><author><keyname>Majkic</keyname><forenames>Zoran</forenames></author></authors><title>Data Base Mappings and Theory of Sketches</title><categories>cs.DB</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we will present the two basic operations for database schemas
used in database mapping systems (separation and Data Federation), and we will
explain why the functorial semantics for database mappings needed a new base
category instead of usual Set category. Successively, it is presented a
definition of the graph G for a schema database mapping system, and the
definition of its sketch category Sch(G). Based on this framework we presented
functorial semantics for database mapping systems with the new base category
DB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4904</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4904</id><created>2011-04-26</created><authors><author><keyname>Mathieu</keyname><forenames>Fabien</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>On Using Seeders for P2P Live Streaming</title><categories>cs.NI</categories><proxy>ccsd</proxy><report-no>RR-7608</report-no><journal-ref>N&amp;deg; RR-7608 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seeders (peers that do not request anything but contribute to the system) are
a powerful concept in peer-to-peer (P2P). They allow to leverage the capacities
of a P2P system. While seeding is a natural idea for filesharing or
video-on-demand applications, it seems somehow counter-intuitive in the context
of live streaming. This paper aims at describing the feasibility and
performance of P2P live seeding. After a formal definition of &quot;live seeding&quot;
and efficiency, we consider the theoretical performance of systems where the
overhead is neglected. We then propose a linear overhead model and extend the
results for this model, for a single seeder and for a set of seeders as well
(it is not always possible to perfectly aggregate individual efficiencies in a
given system).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4905</identifier>
 <datestamp>2012-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4905</id><created>2011-04-26</created><updated>2012-02-02</updated><authors><author><keyname>Henrion</keyname><forenames>Didier</forenames><affiliation>LAAS, CTU/FEE</affiliation></author><author><keyname>Lasserre</keyname><forenames>Jean Bernard</forenames><affiliation>LAAS</affiliation></author></authors><title>Inner approximations for polynomial matrix inequalities and robust
  stability regions</title><categories>math.OC cs.SY</categories><comments>A mistake is fixed in the proof of Lemma 1. It does not affect the
  remainder of the paper</comments><proxy>ccsd</proxy><report-no>Rapport LAAS no. 11210</report-no><journal-ref>IEEE Transactions on Automatic Control 57, 6 (2012) p.1456-1467</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following a polynomial approach, many robust fixed-order controller design
problems can be formulated as optimization problems whose set of feasible
solutions is modelled by parametrized polynomial matrix inequalities (PMI).
These feasibility sets are typically nonconvex. Given a parametrized PMI set,
we provide a hierarchy of linear matrix inequality (LMI) problems whose optimal
solutions generate inner approximations modelled by a single polynomial
sublevel set. Those inner approximations converge in a strong analytic sense to
the nonconvex original feasible set, with asymptotically vanishing
conservatism. One may also impose the hierarchy of inner approximations to be
nested or convex. In the latter case they do not converge any more to the
feasible set, but they can be used in a convex optimization framework at the
price of some conservatism. Finally, we show that the specific geometry of
nonconvex polynomial stability regions can be exploited to improve convergence
of the hierarchy of inner approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4910</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4910</id><created>2011-04-26</created><authors><author><keyname>Gao</keyname><forenames>Jian</forenames></author><author><keyname>Yin</keyname><forenames>Minghao</forenames></author><author><keyname>Zhou</keyname><forenames>Junping</forenames></author></authors><title>Hybrid Tractable Classes of Binary Quantified Constraint Satisfaction
  Problems</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the hybrid tractability of binary Quantified
Constraint Satisfaction Problems (QCSPs). First, a basic tractable class of
binary QCSPs is identified by using the broken-triangle property. In this
class, the variable ordering for the broken-triangle property must be same as
that in the prefix of the QCSP. Second, we break this restriction to allow that
existentially quantified variables can be shifted within or out of their
blocks, and thus identify some novel tractable classes by introducing the
broken-angle property. Finally, we identify a more generalized tractable class,
i.e., the min-of-max extendable class for QCSPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4911</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4911</id><created>2011-04-26</created><authors><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author></authors><title>Asymptotic Moments for Interference Mitigation in Correlated Fading
  Channels</title><categories>cs.IT math.IT</categories><comments>7 pages, 2 figures, to be presented at IEEE International Symposium
  on Information Theory (ISIT), Saint Petersburg, Russia, July 31 - August 5,
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a certain class of large random matrices, composed of independent
column vectors with zero mean and different covariance matrices, and derive
asymptotically tight deterministic approximations of their moments. This random
matrix model arises in several wireless communication systems of recent
interest, such as distributed antenna systems or large antenna arrays.
Computing the linear minimum mean square error (LMMSE) detector in such systems
requires the inversion of a large covariance matrix which becomes prohibitively
complex as the number of antennas and users grows. We apply the derived moment
results to the design of a low-complexity polynomial expansion detector which
approximates the matrix inverse by a matrix polynomial and study its asymptotic
performance. Simulation results corroborate the analysis and evaluate the
performance for finite system dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4927</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4927</id><created>2011-04-26</created><authors><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Zhang</keyname><forenames>Kai</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaoyi</forenames></author></authors><title>Serial Concatenation of RS Codes with Kite Codes: Performance Analysis,
  Iterative Decoding and Design</title><categories>cs.IT cs.PF math.IT</categories><comments>34 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new ensemble of rateless forward error correction
(FEC) codes. The proposed codes are serially concatenated codes with
Reed-Solomon (RS) codes as outer codes and Kite codes as inner codes. The inner
Kite codes are a special class of prefix rateless low-density parity-check
(PRLDPC) codes, which can generate potentially infinite (or as many as
required) random-like parity-check bits. The employment of RS codes as outer
codes not only lowers down error-floors but also ensures (with high
probability) the correctness of successfully decoded codewords. In addition to
the conventional two-stage decoding, iterative decoding between the inner code
and the outer code are also implemented to improve the performance further. The
performance of the Kite codes under maximum likelihood (ML) decoding is
analyzed by applying a refined Divsalar bound to the ensemble weight
enumerating functions (WEF). We propose a simulation-based optimization method
as well as density evolution (DE) using Gaussian approximations (GA) to design
the Kite codes. Numerical results along with semi-analytic bounds show that the
proposed codes can approach Shannon limits with extremely low error-floors. It
is also shown by simulation that the proposed codes performs well within a wide
range of signal-to-noise-ratios (SNRs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4950</identifier>
 <datestamp>2012-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4950</id><created>2011-04-26</created><authors><author><keyname>Hassanzadeh</keyname><forenames>Hamed</forenames></author><author><keyname>Keyvanpour</keyname><forenames>MohammadReza</forenames></author></authors><title>A Machine Learning Based Analytical Framework for Semantic Annotation
  Requirements</title><categories>cs.AI cs.CL</categories><journal-ref>International Journal of Web &amp; Semantic Technology (IJWesT), Vol.
  2, No. 2, pp. 27-38, Aprill 2011</journal-ref><doi>10.5121/ijwest.2011.2203</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Semantic Web is an extension of the current web in which information is
given well-defined meaning. The perspective of Semantic Web is to promote the
quality and intelligence of the current web by changing its contents into
machine understandable form. Therefore, semantic level information is one of
the cornerstones of the Semantic Web. The process of adding semantic metadata
to web resources is called Semantic Annotation. There are many obstacles
against the Semantic Annotation, such as multilinguality, scalability, and
issues which are related to diversity and inconsistency in content of different
web pages. Due to the wide range of domains and the dynamic environments that
the Semantic Annotation systems must be performed on, the problem of automating
annotation process is one of the significant challenges in this domain. To
overcome this problem, different machine learning approaches such as supervised
learning, unsupervised learning and more recent ones like, semi-supervised
learning and active learning have been utilized. In this paper we present an
inclusive layered classification of Semantic Annotation challenges and discuss
the most important issues in this field. Also, we review and analyze machine
learning applications for solving semantic annotation problems. For this goal,
the article tries to closely study and categorize related researches for better
understanding and to reach a framework that can map machine learning techniques
into the Semantic Annotation challenges and requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4954</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4954</id><created>2011-04-26</created><authors><author><keyname>Emeliyanenko</keyname><forenames>Pavel</forenames></author><author><keyname>Sagraloff</keyname><forenames>Michael</forenames></author></authors><title>On the Complexity of Solving a Bivariate Polynomial System</title><categories>cs.SC cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of computing the real solutions of a bivariate
polynomial system using the recently proposed algorithm BISOLVE. BISOLVE is a
classical elimination method which first projects the solutions of a system
onto the $x$- and $y$-axes and, then, selects the actual solutions from the so
induced candidate set. However, unlike similar algorithms, BISOLVE requires no
genericity assumption on the input nor it needs any change of the coordinate
system. Furthermore, extensive benchmarks from \cite{bes-bisolve-2011} confirm
that the algorithm outperforms state of the art approaches by a large factor.
In this work, we show that, for two polynomials $f,g\in\mathbb{Z}[x,y]$ of
total degree at most $n$ with integer coefficients bounded by $2^\tau$, BISOLVE
computes isolating boxes for all real solutions of the system $f=g=0$ using
$\Otilde(n^8\tau^{2})$ bit operations, thereby improving the previous record
bound by a factor of at least $n^{2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4959</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4959</id><created>2011-04-26</created><authors><author><keyname>Sagatov</keyname><forenames>Evgeny S.</forenames></author><author><keyname>Sukhov</keyname><forenames>Andrei M.</forenames></author></authors><title>Duplication of Key Frames of Video Streams in Wireless Networks</title><categories>cs.NI cs.MM</categories><comments>10 pages, 3 figures 11th International Conference on Next Generation
  Wired/Wireless Advanced Networking http://www.new2an.org/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper technological solutions for improving the quality of video
transfer along wireless networks are investigated. Tools have been developed to
allow packets to be duplicated with key frames data. In the paper we tested
video streams with duplication of all frames, with duplication of key frames,
and without duplication. The experiments showed that the best results are
obtained by duplication of packages which contain key frames. The paper also
provides an overview of the coefficients describing the dependence of video
quality on packet loss and delay variation (network jitter).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4966</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4966</id><created>2011-04-26</created><authors><author><keyname>Dombeu</keyname><forenames>Jean Vincent Fonou</forenames></author><author><keyname>Huisman</keyname><forenames>Magda</forenames></author></authors><title>Combining Ontology Development Methodologies and Semantic Web Platforms
  for E-government Domain Ontology Development</title><categories>cs.AI cs.CY</categories><comments>14 pages</comments><journal-ref>International Journal of Web &amp; Semantic Technology (IJWesT), Vol.
  2, No. 2, April 2011</journal-ref><doi>10.5121/ijwest.2011.2202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the key challenges in electronic government (e-government) is the
development of systems that can be easily integrated and interoperated to
provide seamless services delivery to citizens. In recent years, Semantic Web
technologies based on ontology have emerged as promising solutions to the above
engineering problems. However, current research practicing semantic development
in e-government does not focus on the application of available methodologies
and platforms for developing government domain ontologies. Furthermore, only a
few of these researches provide detailed guidelines for developing semantic
ontology models from a government service domain. This research presents a case
study combining an ontology building methodology and two state-of-the-art
Semantic Web platforms namely Protege and Java Jena ontology API for semantic
ontology development in e-government. Firstly, a framework adopted from the
Uschold and King ontology building methodology is employed to build a domain
ontology describing the semantic content of a government service domain.
Thereafter, UML is used to semi-formally represent the domain ontology.
Finally, Protege and Jena API are employed to create the Web Ontology Language
(OWL) and Resource Description Framework (RDF) representations of the domain
ontology respectively to enable its computer processing. The study aims at: (1)
providing e-government developers, particularly those from the developing world
with detailed guidelines for practicing semantic content development in their
e-government projects and (2), strengthening the adoption of semantic
technologies in e-government. The study would also be of interest to novice
Semantic Web developers who might used it as a starting point for further
investigations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4978</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4978</id><created>2011-04-26</created><updated>2011-07-20</updated><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Bro&#x17e;ek</keyname><forenames>V&#xe1;clav</forenames></author><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames></author></authors><title>Approximating the Termination Value of One-Counter MDPs and Stochastic
  Games</title><categories>cs.GT</categories><comments>35 pages, 1 figure, full version of a paper presented at ICALP 2011,
  invited for submission to Information and Computation</comments><acm-class>G.3; F.1.1; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-counter MDPs (OC-MDPs) and one-counter simple stochastic games (OC-SSGs)
are 1-player, and 2-player turn-based zero-sum, stochastic games played on the
transition graph of classic one-counter automata (equivalently, pushdown
automata with a 1-letter stack alphabet). A key objective for the analysis and
verification of these games is the termination objective, where the players aim
to maximize (minimize, respectively) the probability of hitting counter value
0, starting at a given control state and given counter value. Recently, we
studied qualitative decision problems (&quot;is the optimal termination value = 1?&quot;)
for OC-MDPs (and OC-SSGs) and showed them to be decidable in P-time (in NP and
coNP, respectively). However, quantitative decision and approximation problems
(&quot;is the optimal termination value ? p&quot;, or &quot;approximate the termination value
within epsilon&quot;) are far more challenging. This is so in part because optimal
strategies may not exist, and because even when they do exist they can have a
highly non-trivial structure. It thus remained open even whether any of these
quantitative termination problems are computable. In this paper we show that
all quantitative approximation problems for the termination value for OC-MDPs
and OC-SSGs are computable. Specifically, given a OC-SSG, and given epsilon &gt;
0, we can compute a value v that approximates the value of the OC-SSG
termination game within additive error epsilon, and furthermore we can compute
epsilon-optimal strategies for both players in the game. A key ingredient in
our proofs is a subtle martingale, derived from solving certain LPs that we can
associate with a maximizing OC-MDP. An application of Azuma's inequality on
these martingales yields a computable bound for the &quot;wealth&quot; at which a &quot;rich
person's strategy&quot; becomes epsilon-optimal for OC-MDPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4983</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4983</id><created>2011-04-26</created><updated>2012-06-27</updated><authors><author><keyname>Zhang</keyname><forenames>Lijun</forenames><affiliation>Technical University of Denmark, DTU Informatics, Denmark</affiliation></author><author><keyname>Jansen</keyname><forenames>David N.</forenames><affiliation>Radboud Universiteit, Model-based system design, Nijmegen, The Netherlands</affiliation></author><author><keyname>Nielson</keyname><forenames>Flemming</forenames><affiliation>Technical University of Denmark, DTU Informatics, Denmark</affiliation></author><author><keyname>Hermanns</keyname><forenames>Holger</forenames><affiliation>Saarland University, Computer Science, Saarbr</affiliation></author></authors><title>Efficient CSL Model Checking Using Stratification</title><categories>cs.LO</categories><comments>18 pages, preprint for LMCS. An extended abstract appeared in ICALP
  2011</comments><proxy>LMCS</proxy><acm-class>G.3, F.4.1, F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 2 (July 31,
  2012) lmcs:1085</journal-ref><doi>10.2168/LMCS-8(2:17)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For continuous-time Markov chains, the model-checking problem with respect to
continuous-time stochastic logic (CSL) has been introduced and shown to be
decidable by Aziz, Sanwal, Singhal and Brayton in 1996. Their proof can be
turned into an approximation algorithm with worse than exponential complexity.
In 2000, Baier, Haverkort, Hermanns and Katoen presented an efficient
polynomial-time approximation algorithm for the sublogic in which only binary
until is allowed. In this paper, we propose such an efficient polynomial-time
approximation algorithm for full CSL. The key to our method is the notion of
stratified CTMCs with respect to the CSL property to be checked. On a
stratified CTMC, the probability to satisfy a CSL path formula can be
approximated by a transient analysis in polynomial time (using uniformization).
We present a measure-preserving, linear-time and -space transformation of any
CTMC into an equivalent, stratified one. This makes the present work the
centerpiece of a broadly applicable full CSL model checker. Recently, the
decision algorithm by Aziz et al. was shown to work only for stratified CTMCs.
As an additional contribution, our measure-preserving transformation can be
used to ensure the decidability for general CTMCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4987</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4987</id><created>2011-04-26</created><updated>2012-09-03</updated><authors><author><keyname>Zahl</keyname><forenames>Joshua</forenames></author></authors><title>An improved bound on the number of point-surface incidences in three
  dimensions</title><categories>math.CO cs.CG</categories><comments>17 pages, revised based on referee comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that $m$ points and $n$ smooth algebraic surfaces of bounded degree
in $\mathbb{R}^3$ satisfying suitable nondegeneracy conditions can have at most
$O(m^{\frac{2k}{3k-1}}n^{\frac{3k-3}{3k-1}}+m+n)$ incidences, provided that any
collection of $k$ points have at most O(1) surfaces passing through all of
them, for some $k\geq 3$. In the case where the surfaces are spheres and no
three spheres meet in a common circle, this implies there are $O((mn)^{3/4} + m
+n)$ point-sphere incidences. This is a slight improvement over the previous
bound of $O((mn)^{3/4} \beta(m,n)+ m +n)$ for $\beta(m,n)$ an (explicit) very
slowly growing function. We obtain this bound by using the discrete polynomial
ham sandwich theorem to cut $\mathbb{R}^3$ into open cells adapted to the set
of points, and within each cell of the decomposition we apply a Turan-type
theorem to obtain crude control on the number of point-surface incidences. We
then perform a second polynomial ham sandwich decomposition on the irreducible
components of the variety defined by the first decomposition. As an
application, we obtain a new bound on the maximum number of unit distances
amongst $m$ points in $\mathbb{R}^3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4989</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4989</id><created>2011-04-26</created><updated>2011-08-11</updated><authors><author><keyname>Das</keyname><forenames>Abhishek</forenames></author><author><keyname>Kar</keyname><forenames>Avijit</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Debasis</forenames></author></authors><title>Preprocessing: A Step in Automating Early Detection of Cervical Cancer</title><categories>cs.CV</categories><comments>wrong conference name mentioned (This paper has been withdrawn)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4993</identifier>
 <datestamp>2011-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4993</id><created>2011-04-26</created><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author><author><keyname>Dalmau</keyname><forenames>Victor</forenames></author><author><keyname>Gru&#xdf;ien</keyname><forenames>Berit</forenames></author></authors><title>Arc Consistency and Friends</title><categories>cs.AI cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural and established way to restrict the constraint satisfaction problem
is to fix the relations that can be used to pose constraints; such a family of
relations is called a constraint language. In this article, we study arc
consistency, a heavily investigated inference method, and three extensions
thereof from the perspective of constraint languages. We conduct a comparison
of the studied methods on the basis of which constraint languages they solve,
and we present new polynomial-time tractability results for singleton arc
consistency, the most powerful method studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.4997</identifier>
 <datestamp>2012-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.4997</id><created>2011-04-26</created><updated>2012-06-08</updated><authors><author><keyname>Schudy</keyname><forenames>Warren</forenames></author><author><keyname>Sviridenko</keyname><forenames>Maxim</forenames></author></authors><title>Concentration and Moment Inequalities for Polynomials of Independent
  Random Variables</title><categories>math.PR cs.DM</categories><comments>46 pages</comments><acm-class>G.3; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we design a general method for proving moment inequalities for
polynomials of independent random variables. Our method works for a wide range
of random variables including Gaussian, Boolean, exponential, Poisson and many
others. We apply our method to derive general concentration inequalities for
polynomials of independent random variables. We show that our method implies
concentration inequalities for some previously open problems, e.g. permanent of
a random symmetric matrices. We show that our concentration inequality is
stronger than the well-known concentration inequality due to Kim and Vu. The
main advantage of our method in comparison with the existing ones is a wide
range of random variables we can handle and bounds for previously intractable
regimes of high degree polynomials and small expectations. On the negative side
we show that even for boolean random variables each term in our concentration
inequality is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5007</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5007</id><created>2011-04-26</created><updated>2012-04-13</updated><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author><author><keyname>Kyncl</keyname><forenames>Jan</forenames></author></authors><title>Tight bounds on the maximum size of a set of permutations with bounded
  VC-dimension</title><categories>math.CO cs.DM</categories><comments>22 pages, 4 figures, correction of the bound on r_3 in the abstract
  and other minor changes</comments><journal-ref>Journal of Combinatorial Theory, Series A 119 (7), 1461-1478
  (2012)</journal-ref><doi>10.1016/j.jcta.2012.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The VC-dimension of a family P of n-permutations is the largest integer k
such that the set of restrictions of the permutations in P on some k-tuple of
positions is the set of all k! permutation patterns. Let r_k(n) be the maximum
size of a set of n-permutations with VC-dimension k. Raz showed that r_2(n)
grows exponentially in n. We show that r_3(n)=2^Theta(n log(alpha(n))) and for
every s &gt;= 4, we have almost tight upper and lower bounds of the form 2^{n
poly(alpha(n))}. We also study the maximum number p_k(n) of 1-entries in an n x
n (0,1)-matrix with no (k+1)-tuple of columns containing all (k+1)-permutation
matrices. We determine that p_3(n) = Theta(n alpha(n)) and that p_s(n) can be
bounded by functions of the form n 2^poly(alpha(n)) for every fixed s &gt;= 4. We
also show that for every positive s there is a slowly growing function
zeta_s(m) (of the form 2^poly(alpha(m)) for every fixed s &gt;= 5) satisfying the
following. For all positive integers n and B and every n x n (0,1)-matrix M
with zeta_s(n)Bn 1-entries, the rows of M can be partitioned into s intervals
so that at least B columns contain at least B 1-entries in each of the
intervals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5009</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5009</id><created>2011-04-26</created><updated>2011-05-03</updated><authors><author><keyname>Enright</keyname><forenames>Jessica</forenames></author><author><keyname>Stewart</keyname><forenames>Lorna</forenames></author></authors><title>3-List Colouring Permutation Graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  3-list colouring is an NP-complete decision problem. It is hard even on
planar bipartite graphs. We give a polynomial-time algorithm for solving 3-list
colouring on permutation graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5039</identifier>
 <datestamp>2015-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5039</id><created>2011-04-26</created><updated>2015-05-05</updated><authors><author><keyname>Chimani</keyname><forenames>Markus</forenames></author><author><keyname>Hlineny</keyname><forenames>Petr</forenames></author></authors><title>A Tighter Insertion-based Approximation of the Crossing Number</title><categories>cs.DM</categories><comments>Full extended version of a conference paper from ICALP2011</comments><msc-class>68R10, 05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a planar graph and F a set of additional edges not yet in G. The
multiple edge insertion problem (MEI) asks for a drawing of G+F with the
minimum number of pairwise edge crossings, such that the subdrawing of G is
plane. Finding an exact solution to MEI is NP-hard for general F. We present
the first polynomial time algorithm for MEI that achieves an additive
approximation guarantee -- depending only on the size of F and the maximum
degree of G, in the case of connected G. Our algorithm seems to be the first
directly implementable one in that realm, too, next to the single edge
insertion. It is also known that an (even approximate) solution to the MEI
problem would approximate the crossing number of the F-almost-planar graph G+F,
while computing the crossing number of G+F exactly is NP-hard already when
|F|=1. Hence our algorithm induces new, improved approximation bounds for the
crossing number problem of F-almost-planar graphs, achieving constant-factor
approximation for the large class of such graphs of bounded degrees and bounded
size of F.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5043</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5043</id><created>2011-04-26</created><updated>2011-05-19</updated><authors><author><keyname>Gibson</keyname><forenames>Matt</forenames></author><author><keyname>Kanade</keyname><forenames>Gaurav</forenames></author><author><keyname>Varadarajan</keyname><forenames>Kasturi</forenames></author></authors><title>On Isolating Points Using Disks</title><categories>cs.CG</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of choosing disks (that we can think
of as corresponding to wireless sensors) so that given a set of input points in
the plane, there exists no path between any pair of these points that is not
intercepted by some disk. We try to achieve this separation using a minimum
number of a given set of unit disks. We show that a constant factor
approximation to this problem can be found in polynomial time using a greedy
algorithm. To the best of our knowledge we are the first to study this
optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5044</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5044</id><created>2011-04-26</created><authors><author><keyname>Moulton</keyname><forenames>Vincent</forenames></author><author><keyname>Steel</keyname><forenames>Mike</forenames></author></authors><title>The 'Butterfly effect' in Cayley graphs, and its relevance for
  evolutionary genomics</title><categories>q-bio.QM cs.DM q-bio.PE</categories><comments>17 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose a finite set $X$ is repeatedly transformed by a sequence of
permutations of a certain type acting on an initial element $x$ to produce a
final state $y$. We investigate how 'different' the resulting state $y'$ to $y$
can be if a slight change is made to the sequence, either by deleting one
permutation, or replacing it with another. Here the 'difference' between $y$
and $y'$ might be measured by the minimum number of permutations of the
permitted type required to transform $y$ to $y'$, or by some other metric. We
discuss this first in the general setting of sensitivity to perturbation of
walks in Cayley graphs of groups with a specified set of generators. We then
investigate some permutation groups and generators arising in computational
genomics, and the statistical implications of the findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5059</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5059</id><created>2011-04-26</created><authors><author><keyname>Bloch</keyname><forenames>Mitchell Keith</forenames></author></authors><title>Reducing Commitment to Tasks with Off-Policy Hierarchical Reinforcement
  Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In experimenting with off-policy temporal difference (TD) methods in
hierarchical reinforcement learning (HRL) systems, we have observed unwanted
on-policy learning under reproducible conditions. Here we present modifications
to several TD methods that prevent unintentional on-policy learning from
occurring. These modifications create a tension between exploration and
learning. Traditional TD methods require commitment to finishing subtasks
without exploration in order to update Q-values for early actions with high
probability. One-step intra-option learning and temporal second difference
traces (TSDT) do not suffer from this limitation. We demonstrate that our HRL
system is efficient without commitment to completion of subtasks in a
cliff-walking domain, contrary to a widespread claim in the literature that it
is critical for efficiency of learning. Furthermore, decreasing commitment as
exploration progresses is shown to improve both online performance and the
resultant policy in the taxicab domain, opening a new avenue for research into
when it is more beneficial to continue with the current subtask or to replan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5061</identifier>
 <datestamp>2014-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5061</id><created>2011-04-26</created><updated>2014-03-12</updated><authors><author><keyname>Tulabandhula</keyname><forenames>Theja</forenames></author><author><keyname>Rudin</keyname><forenames>Cynthia</forenames></author></authors><title>On Combining Machine Learning with Decision Making</title><categories>math.OC cs.LG stat.ML</categories><comments>35 pages, 16 figures, longer version of a paper appearing in
  Algorithmic Decision Theory 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new application and covering number bound for the framework of
&quot;Machine Learning with Operational Costs (MLOC),&quot; which is an exploratory form
of decision theory. The MLOC framework incorporates knowledge about how a
predictive model will be used for a subsequent task, thus combining machine
learning with the decision that is made afterwards. In this work, we use the
MLOC framework to study a problem that has implications for power grid
reliability and maintenance, called the Machine Learning and Traveling
Repairman Problem ML&amp;TRP. The goal of the ML&amp;TRP is to determine a route for a
&quot;repair crew,&quot; which repairs nodes on a graph. The repair crew aims to minimize
the cost of failures at the nodes, but as in many real situations, the failure
probabilities are not known and must be estimated. The MLOC framework allows us
to understand how this uncertainty influences the repair route. We also present
new covering number generalization bounds for the MLOC framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5069</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5069</id><created>2011-04-27</created><authors><author><keyname>Nguyen</keyname><forenames>Tuan</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author><author><keyname>Do</keyname><forenames>Minh</forenames></author></authors><title>Synthesizing Robust Plans under Incomplete Domain Models</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most current planners assume complete domain models and focus on generating
correct plans. Unfortunately, domain modeling is a laborious and error-prone
task. While domain experts cannot guarantee completeness, often they are able
to circumscribe the incompleteness of the model by providing annotations as to
which parts of the domain model may be incomplete. In such cases, the goal
should be to generate plans that are robust with respect to any known
incompleteness of the domain. In this paper, we first introduce annotations
expressing the knowledge of the domain incompleteness, and formalize the notion
of plan robustness with respect to an incomplete domain model. We then propose
an approach to compiling the problem of finding robust plans to the conformant
probabilistic planning problem. We present experimental results with
Probabilistic-FF, a state-of-the-art planner, showing the promise of our
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5070</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5070</id><created>2011-04-27</created><authors><author><keyname>Rakhlin</keyname><forenames>Alexander</forenames></author><author><keyname>Sridharan</keyname><forenames>Karthik</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author></authors><title>Online Learning: Stochastic and Constrained Adversaries</title><categories>stat.ML cs.GT cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning theory has largely focused on two main learning scenarios. The first
is the classical statistical setting where instances are drawn i.i.d. from a
fixed distribution and the second scenario is the online learning, completely
adversarial scenario where adversary at every time step picks the worst
instance to provide the learner with. It can be argued that in the real world
neither of these assumptions are reasonable. It is therefore important to study
problems with a range of assumptions on data. Unfortunately, theoretical
results in this area are scarce, possibly due to absence of general tools for
analysis. Focusing on the regret formulation, we define the minimax value of a
game where the adversary is restricted in his moves. The framework captures
stochastic and non-stochastic assumptions on data. Building on the sequential
symmetrization approach, we define a notion of distribution-dependent
Rademacher complexity for the spectrum of problems ranging from i.i.d. to
worst-case. The bounds let us immediately deduce variation-type bounds. We then
consider the i.i.d. adversary and show equivalence of online and batch
learnability. In the supervised setting, we consider various hybrid assumptions
on the way that x and y variables are chosen. Finally, we consider smoothed
learning problems and show that half-spaces are online learnable in the
smoothed model. In fact, exponentially small noise added to adversary's
decisions turns this problem with infinite Littlestone's dimension into a
learnable problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5071</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5071</id><created>2011-04-27</created><authors><author><keyname>Crespi</keyname><forenames>Valentino</forenames></author><author><keyname>Cybenko</keyname><forenames>George</forenames></author><author><keyname>Giani</keyname><forenames>Annarita</forenames></author></authors><title>Attacking and Defending Covert Channels and Behavioral Models</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present methods for attacking and defending $k$-gram
statistical analysis techniques that are used, for example, in network traffic
analysis and covert channel detection. The main new result is our demonstration
of how to use a behavior's or process' $k$-order statistics to build a
stochastic process that has those same $k$-order stationary statistics but
possesses different, deliberately designed, $(k+1)$-order statistics if
desired. Such a model realizes a &quot;complexification&quot; of the process or behavior
which a defender can use to monitor whether an attacker is shaping the
behavior. By deliberately introducing designed $(k+1)$-order behaviors, the
defender can check to see if those behaviors are present in the data. We also
develop constructs for source codes that respect the $k$-order statistics of a
process while encoding covert information. One fundamental consequence of these
results is that certain types of behavior analyses techniques come down to an
{\em arms race} in the sense that the advantage goes to the party that has more
computing resources applied to the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5076</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5076</id><created>2011-04-27</created><authors><author><keyname>Chalopin</keyname><forenames>J&#xe9;r&#xe9;mie</forenames><affiliation>LIF</affiliation></author><author><keyname>Das</keyname><forenames>Shantanu</forenames><affiliation>LIF</affiliation></author><author><keyname>Labourel</keyname><forenames>Arnaud</forenames><affiliation>LIF</affiliation></author><author><keyname>Markou</keyname><forenames>Euripides</forenames><affiliation>Athens</affiliation></author></authors><title>Tight Bounds for Black Hole Search with Scattered Agents in Synchronous
  Rings</title><categories>cs.MA</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of locating a particularly dangerous node, the so-called
black hole in a synchronous anonymous ring network with mobile agents. A black
hole is a harmful stationary process residing in a node of the network and
destroying destroys all mobile agents visiting that node without leaving any
trace. We consider the more challenging scenario when the agents are identical
and initially scattered within the network. Moreover, we solve the problem with
agents that have constant-sized memory and carry a constant number of identical
tokens, which can be placed at nodes of the network. In contrast, the only
known solutions for the case of scattered agents searching for a black hole,
use stronger models where the agents have non-constant memory, can write
messages in whiteboards located at nodes or are allowed to mark both the edges
and nodes of the network with tokens. This paper solves the problem for ring
networks containing a single black hole. We are interested in the minimum
resources (number of agents and tokens) necessary for locating all links
incident to the black hole. We present deterministic algorithms for ring
topologies and provide matching lower and upper bounds for the number of agents
and the number of tokens required for deterministic solutions to the black hole
search problem, in oriented or unoriented rings, using movable or unmovable
tokens.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5097</identifier>
 <datestamp>2012-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5097</id><created>2011-04-27</created><updated>2011-05-11</updated><authors><author><keyname>Hedtke</keyname><forenames>Ivo</forenames></author><author><keyname>Murthy</keyname><forenames>Sandeep</forenames></author></authors><title>Search and test algorithms for Triple Product Property triples</title><categories>math.GR cs.SC math.CO</categories><comments>14 pages, 2 figures, 4 tables; ISSN (Online) 1869-6104, ISSN (Print)
  1867-1144</comments><msc-class>20-04, 68Q25, 20D60, 68Q17, 68R05</msc-class><journal-ref>Groups - Complexity - Cryptology, Volume 4, Issue 1, Pages
  111-133, May 2012</journal-ref><doi>10.1515/gcc-2012-0006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2003 COHN and UMANS introduced a group-theoretic approach to fast matrix
multiplication. This involves finding large subsets of a group $G$ satisfying
the Triple Product Property (TPP) as a means to bound the exponent $\omega$ of
matrix multiplication. We present two new characterizations of the TPP, which
are useful for theoretical considerations and for TPP test algorithms. With
this we describe all known TPP tests and implement them in GAP algorithms. We
also compare their runtime. Furthermore we show that the search for subgroup
TPP triples of nontrivial size in a nonabelian group can be restricted to the
set of all nonnormal subgroups of that group. Finally we describe brute-force
search algorithms for maximal subgroup and subset TPP triples. In addition we
present the results of the subset brute-force search for all groups of order
less than 25 and selected results of the subgroup brute-force search for
2-groups, $SL(n,q)$ and $PSL(2,q)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5098</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5098</id><created>2011-04-27</created><authors><author><keyname>Gerbner</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>Keszegh</keyname><forenames>Bal&#xe1;zs</forenames></author></authors><title>Path-search in the pyramid and in other graphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given an acyclic directed graph with one source, and a subset of its
edges which contains exactly one outgoing edge for every non-sink vertex. These
edges determine a unique path from the source to a sink. We can think of it as
a switch in every vertex, which determines which way the water arriving to that
vertex flows further. We are interested in determining either the sink the flow
arrives, or the whole path, with as few questions as possible. The questions we
can ask correspond to the vertices of the graph, and the answer describes the
switch, i.e. tells which outgoing edge is in our given subset. Originally the
problem was proposed by Soren Riis (who posed the question for pyramid graphs)
in the following more general form. We are given a natural number k, and k
questions can be asked in a round. The goal is to minimize the number of
rounds. We completely solve this problem for complete t-ary trees. Also, for
pyramid graphs we present some non-trivial partial results.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="20000" completeListSize="102538">1122234|21001</resumptionToken>
</ListRecords>
</OAI-PMH>
