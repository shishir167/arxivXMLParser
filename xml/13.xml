<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:42:53Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|12001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1179</identifier>
 <datestamp>2010-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1179</id><created>2010-03-04</created><authors><author><keyname>Calvanese</keyname><forenames>Diego</forenames></author><author><keyname>De Giacomo</keyname><forenames>Giuseppe</forenames></author><author><keyname>Lenzerini</keyname><forenames>Maurizio</forenames></author><author><keyname>Vardi</keyname><forenames>Moshe Y.</forenames></author></authors><title>View Synthesis from Schema Mappings</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In data management, and in particular in data integration, data exchange,
query optimization, and data privacy, the notion of view plays a central role.
In several contexts, such as data integration, data mashups, and data
warehousing, the need arises of designing views starting from a set of known
correspondences between queries over different schemas. In this paper we deal
with the issue of automating such a design process. We call this novel problem
&quot;view synthesis from schema mappings&quot;: given a set of schema mappings, each
relating a query over a source schema to a query over a target schema,
automatically synthesize for each source a view over the target schema in such
a way that for each mapping, the query over the source is a rewriting of the
query over the target wrt the synthesized views. We study view synthesis from
schema mappings both in the relational setting, where queries and views are
(unions of) conjunctive queries, and in the semistructured data setting, where
queries and views are (two-way) regular path queries, as well as unions of
conjunctions thereof. We provide techniques and complexity upper bounds for
each of these cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1239</identifier>
 <datestamp>2010-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1239</id><created>2010-03-05</created><authors><author><keyname>T</keyname><forenames>Panduranga H.</forenames></author><author><keyname>K</keyname><forenames>Naveen Kumar S.</forenames></author></authors><title>Hybrid approach for Image Encryption Using SCAN Patterns and Carrier
  Images</title><categories>cs.CR</categories><comments>4 Pages IEEE format, International Journal on Computer Science and
  Engineering, IJCSE 2010, ISSN 0975-3397, Impact Factor 0.583</comments><report-no>IJCSE10-02-02-33</report-no><journal-ref>International Journal on Computer Science and Engineering, IJCSE,
  Vol. 2, No. 2 March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a hybrid technique for image encryption which employs the concept
of carrier image and SCAN patterns generated by SCAN methodology. Although it
involves existing method like SCAN methodology, the novelty of the work lies in
hybridizing and carrier image creation for encryption. Here the carrier image
is created with the help of alphanumeric keyword. Each alphanumeric key will be
having a unique 8bit value generated by 4 out of 8-code. This newly generated
carrier image is added with original image to obtain encrypted image. The scan
methodology is applied to either original image or carrier image, after the
addition of original image and carrier image to obtain highly distorted
encrypted image. The resulting image is found to be more distorted in hybrid
technique. By applying the reverse process we get the decrypted image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1251</identifier>
 <datestamp>2010-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1251</id><created>2010-03-05</created><updated>2010-05-21</updated><authors><author><keyname>Gunturi</keyname><forenames>Viswanath</forenames></author><author><keyname>Shekhar</keyname><forenames>Shashi</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author></authors><title>Minimum Spanning Tree on Spatio-Temporal Networks</title><categories>cs.DS cs.DB</categories><acm-class>E.1; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a spatio-temporal network (ST network) where edge properties vary with
time, a time-sub-interval minimum spanning tree (TSMST) is a collection of
minimum spanning trees of the ST network, where each tree is associated with a
time interval. During this time interval, the total cost of tree is least among
all the spanning trees. The TSMST problem aims to identify a collection of
distinct minimum spanning trees and their respective time-sub-intervals under
the constraint that the edge weight functions are piecewise linear. This is an
important problem in ST network application domains such as wireless sensor
networks (e.g., energy efficient routing). Computing TSMST is challenging
because the ranking of candidate spanning trees is non-stationary over a given
time interval. Existing methods such as dynamic graph algorithms and kinetic
data structures assume separable edge weight functions. In contrast, we propose
novel algorithms to find TSMST for large ST networks by accounting for both
separable and non-separable piecewise linear edge weight functions. The
algorithms are based on the ordering of edges in edge-order-intervals and
intersection points of edge weight functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1256</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1256</id><created>2010-03-05</created><authors><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Integrating Innate and Adaptive Immunity for Intrusion Detection</title><categories>cs.AI cs.CR cs.NE</categories><comments>10 pages, 3 figures, 1 table</comments><journal-ref>Proceedings of the 5th International Conference on Artificial
  Immune Systems (ICARIS2006), Lecture Notes in Computer Science 4163, 193-202,
  2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network Intrusion Detection Systems (NDIS) monitor a network with the aim of
discerning malicious from benign activity on that network. While a wide range
of approaches have met varying levels of success, most IDS's rely on having
access to a database of known attack signatures which are written by security
experts. Nowadays, in order to solve problems with false positive alters,
correlation algorithms are used to add additional structure to sequences of IDS
alerts. However, such techniques are of no help in discovering novel attacks or
variations of known attacks, something the human immune system (HIS) is capable
of doing in its own specialised domain. This paper presents a novel immune
algorithm for application to an intrusion detection problem. The goal is to
discover packets containing novel variations of attacks covered by an existing
signature base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1257</identifier>
 <datestamp>2015-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1257</id><created>2010-03-05</created><authors><author><keyname>Agrell</keyname><forenames>Erik</forenames></author><author><keyname>Karlsson</keyname><forenames>Magnus</forenames></author></authors><title>On the symbol error probability of regular polytopes</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 6, pp.
  3411-3415, June 2011</journal-ref><doi>10.1109/TIT.2011.2134290</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An exact expression for the symbol error probability of the four-dimensional
24-cell in Gaussian noise is derived. Corresponding expressions for other
regular convex polytopes are summarized. Numerically stable versions of these
error probabilities are also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1260</identifier>
 <datestamp>2010-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1260</id><created>2010-03-05</created><authors><author><keyname>Marx</keyname><forenames>D&#xe1;niel</forenames></author><author><keyname>Schlotter</keyname><forenames>Ildik&#xf3;</forenames></author></authors><title>Cleaning Interval Graphs</title><categories>cs.DS</categories><comments>40 pages, 7 eps figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a special case of the Induced Subgraph Isomorphism problem,
where both input graphs are interval graphs. We show the NP-hardness of this
problem, and we prove fixed-parameter tractability of the problem with
non-standard parameterization, where the parameter is the difference
|V(G)|-|V(H)|, with G and H being the larger and the smaller input graph,
respectively. Intuitively, we can interpret this problem as &quot;cleaning&quot; the
graph G, regarded as a pattern containing extra vertices indicating errors, in
order to obtain the graph H representing the original pattern. We also prove
W[1]-hardness for the standard parameterization where the parameter is |V(H)|.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1266</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1266</id><created>2010-03-05</created><updated>2011-05-26</updated><authors><author><keyname>von Luxburg</keyname><forenames>Ulrike</forenames></author><author><keyname>Radl</keyname><forenames>Agnes</forenames></author><author><keyname>Hein</keyname><forenames>Matthias</forenames></author></authors><title>Hitting and commute times in large graphs are often misleading</title><categories>cs.DS cs.LG math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next to the shortest path distance, the second most popular distance function
between vertices in a graph is the commute distance (resistance distance). For
two vertices u and v, the hitting time H_{uv} is the expected time it takes a
random walk to travel from u to v. The commute time is its symmetrized version
C_{uv} = H_{uv} + H_{vu}. In our paper we study the behavior of hitting times
and commute distances when the number n of vertices in the graph is very large.
We prove that as n converges to infinty, hitting times and commute distances
converge to expressions that do not take into account the global structure of
the graph at all. Namely, the hitting time H_{uv} converges to 1/d_v and the
commute time to 1/d_u + 1/d_v where d_u and d_v denote the degrees of vertices
u and v. In these cases, the hitting and commute times are misleading in the
sense that they do not provide information about the structure of the graph. We
focus on two major classes of random graphs: random geometric graphs (k-nearest
neighbor graphs, epsilon-graphs, Gaussian similarity graphs) and random graphs
with given expected degrees (in particular, Erdos-Renyi graphs with and without
planted partitions)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1291</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1291</id><created>2010-03-05</created><authors><author><keyname>Lorca</keyname><forenames>Alejandro</forenames></author><author><keyname>Huedo</keyname><forenames>Eduardo</forenames></author><author><keyname>Llorente</keyname><forenames>Ignacio M.</forenames></author></authors><title>The Grid[Way] Job Template Manager, a tool for parameter sweeping</title><categories>cs.DC</categories><comments>26 pages, 1 figure,</comments><acm-class>C.1.4</acm-class><doi>10.1016/j.cpc.2010.12.041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parameter sweeping is a widely used algorithmic technique in computational
science. It is specially suited for high-throughput computing since the jobs
evaluating the parameter space are loosely coupled or independent.
  A tool that integrates the modeling of a parameter study with the control of
jobs in a distributed architecture is presented. The main task is to facilitate
the creation and deletion of job templates, which are the elements describing
the jobs to be run. Extra functionality relies upon the GridWay Metascheduler,
acting as the middleware layer for job submission and control. It supports
interesting features like multi-dimensional sweeping space, wildcarding of
parameters, functional evaluation of ranges, value-skipping and job template
automatic indexation.
  The use of this tool increases the reliability of the parameter sweep study
thanks to the systematic bookkeping of job templates and respective job
statuses. Furthermore, it simplifies the porting of the target application to
the grid reducing the required amount of time and effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1295</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1295</id><created>2010-03-05</created><authors><author><keyname>Byrka</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Srinivasan</keyname><forenames>Aravind</forenames></author><author><keyname>Swamy</keyname><forenames>Chaitanya</forenames></author></authors><title>Fault-Tolerant Facility Location: a randomized dependent LP-rounding
  algorithm</title><categories>cs.DS cs.DM</categories><comments>conference paper + proofs in appendices</comments><doi>10.1007/978-3-642-13036-6_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new randomized LP-rounding 1.725-approximation algorithm for the
metric Fault-Tolerant Uncapacitated Facility Location problem. This improves on
the previously best known 2.076-approximation algorithm of Swamy &amp; Shmoys. To
the best of our knowledge, our work provides the first application of a
dependent-rounding technique in the domain of facility location. The analysis
of our algorithm benefits from, and extends, methods developed for
Uncapacitated Facility Location; it also helps uncover new properties of the
dependent-rounding approach. An important concept that we develop is a novel,
hierarchical clustering scheme. Typically, LP-rounding approximation algorithms
for facility location problems are based on partitioning facilities into
disjoint clusters and opening at least one facility in each cluster. We extend
this approach and construct a laminar family of clusters, which then guides the
rounding procedure. It allows to exploit properties of dependent rounding, and
provides a quite tight analysis resulting in the improved approximation ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1319</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1319</id><created>2010-03-05</created><updated>2010-03-09</updated><authors><author><keyname>Pirzada</keyname><forenames>Shariefuddin</forenames></author><author><keyname>Zhou</keyname><forenames>Guofei</forenames></author></authors><title>On k-hypertournament losing scores</title><categories>cs.DM</categories><acm-class>G.2.2; F.2.m</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica 2,1 (2010) 5-9</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new and short proof of a theorem on k-hypertournament losing scores
due to Zhou et al. [G. Zhou, T. Yao, K. Zhang, On score sequences of
k-tournaments, European J. Comb., 21, 8 (2000) 993-1000.]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1320</identifier>
 <datestamp>2013-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1320</id><created>2010-03-05</created><updated>2013-10-09</updated><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames></author><author><keyname>Sankowski</keyname><forenames>Piotr</forenames></author><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Min st-Cut Oracle for Planar Graphs with Near-Linear Preprocessing Time</title><categories>cs.DM cs.DS</categories><comments>This is the final version submitted for journal publication and has
  improved the running time of an earlier version by a log n factor. This
  version includes the bibliography</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an undirected $n$-vertex planar graph $G$ with non-negative edge-weights,
we consider the following type of query: given two vertices $s$ and $t$ in $G$,
what is the weight of a min $st$-cut in $G$? We show how to answer such queries
in constant time with $O(n\log^4n)$ preprocessing time and $O(n\log n)$ space.
We use a Gomory-Hu tree to represent all the pairwise min cuts implicitly.
Previously, no subquadratic time algorithm was known for this problem. Since
all-pairs min cut and the minimum cycle basis are dual problems in planar
graphs, we also obtain an implicit representation of a minimum cycle basis in
$O(n\log^4n)$ time and $O(n\log n)$ space. Additionally, an explicit
representation can be obtained in $O(C)$ time and space where $C$ is the size
of the basis.
  These results require that shortest paths are unique. This can be guaranteed
either by using randomization without overhead, or deterministically with an
additional $\log^2 n$ factor in the preprocessing times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1336</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1336</id><created>2010-03-05</created><updated>2010-03-09</updated><authors><author><keyname>Fornai</keyname><forenames>Peter</forenames></author><author><keyname>Ivanyi</keyname><forenames>Antal</forenames></author></authors><title>FIFO anomaly is unbounded</title><categories>cs.OS</categories><acm-class>G.2.2</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 2,1 (2010) 80-89</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual memory of computers is usually implemented by demand paging. For some
page replacement algorithms the number of page faults may increase as the
number of page frames increases. Belady, Nelson and Shedler constructed
reference strings for which page replacement algorithm FIFO produces near twice
more page faults in a larger memory than in a smaller one. They formulated the
conjecture that 2 is a general bound. We prove that this ratio can be
arbitrarily large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1343</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1343</id><created>2010-03-05</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Benford</keyname><forenames>Gregory</forenames></author></authors><title>What does Newcomb's paradox teach us?</title><categories>cs.GT cs.AI math.OC math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Newcomb's paradox you choose to receive either the contents of a
particular closed box, or the contents of both that closed box and another one.
Before you choose, a prediction algorithm deduces your choice, and fills the
two boxes based on that deduction. Newcomb's paradox is that game theory
appears to provide two conflicting recommendations for what choice you should
make in this scenario. We analyze Newcomb's paradox using a recent extension of
game theory in which the players set conditional probability distributions in a
Bayes net. We show that the two game theory recommendations in Newcomb's
scenario have different presumptions for what Bayes net relates your choice and
the algorithm's prediction. We resolve the paradox by proving that these two
Bayes nets are incompatible. We also show that the accuracy of the algorithm's
prediction, the focus of much previous work, is irrelevant. In addition we show
that Newcomb's scenario only provides a contradiction between game theory's
expected utility and dominance principles if one is sloppy in specifying the
underlying Bayes net. We also show that Newcomb's paradox is time-reversal
invariant; both the paradox and its resolution are unchanged if the algorithm
makes its `prediction' after you make your choice rather than before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1345</identifier>
 <datestamp>2011-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1345</id><created>2010-03-05</created><authors><author><keyname>Warner</keyname><forenames>Simeon</forenames><affiliation>Cornell Information Science and Cornell University Library</affiliation></author></authors><title>Author Identifiers in Scholarly Repositories</title><categories>cs.DL</categories><comments>10 pages. Based on a presentation given at Open Repositories 2009</comments><journal-ref>Journal of Digital Information, Vol 11, No 1 (2010)</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Bibliometric and usage-based analyses and tools highlight the value of
information about scholarship contained within the network of authors, articles
and usage data. Less progress has been made on populating and using the author
side of this network than the article side, in part because of the difficulty
of unambiguously identifying authors. I briefly review a sample of author
identifier schemes, and consider use in scholarly repositories. I then describe
preliminary work at arXiv to implement public author identifiers, services
based on them, and plans to make this information useful beyond the boundaries
of arXiv.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1354</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1354</id><created>2010-03-06</created><authors><author><keyname>Zhang</keyname><forenames>Xinhua</forenames><affiliation>Purdue University</affiliation></author><author><keyname>Saha</keyname><forenames>Ankan</forenames><affiliation>University of Chicago</affiliation></author><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames><affiliation>Purdue University</affiliation></author></authors><title>Faster Rates for training Max-Margin Markov Networks</title><categories>cs.LG cs.CC</categories><comments>14 pages Submitted to COLT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured output prediction is an important machine learning problem both in
theory and practice, and the max-margin Markov network (\mcn) is an effective
approach. All state-of-the-art algorithms for optimizing \mcn\ objectives take
at least $O(1/\epsilon)$ number of iterations to find an $\epsilon$ accurate
solution. Recent results in structured optimization suggest that faster rates
are possible by exploiting the structure of the objective function. Towards
this end \citet{Nesterov05} proposed an excessive gap reduction technique based
on Euclidean projections which converges in $O(1/\sqrt{\epsilon})$ iterations
on strongly convex functions. Unfortunately when applied to \mcn s, this
approach does not admit graphical model factorization which, as in many
existing algorithms, is crucial for keeping the cost per iteration tractable.
In this paper, we present a new excessive gap reduction technique based on
Bregman projections which admits graphical model factorization naturally, and
converges in $O(1/\sqrt{\epsilon})$ iterations. Compared with existing
algorithms, the convergence rate of our method has better dependence on
$\epsilon$ and other parameters of the problem, and can be easily kernelized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1364</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1364</id><created>2010-03-06</created><authors><author><keyname>Ghaderi</keyname><forenames>Javad</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>On the Design of Efficient CSMA Algorithms for Wireless Networks</title><categories>cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that CSMA algorithms which use queue length-based
link weights can achieve throughput optimality in wireless networks. In
particular, a key result by Rajagopalan, Shah, and Shin (2009) shows that, if
the link weights are chosen to be of the form log(log(q)) (where q is the
queue-length), then throughput optimality is achieved. In this paper, we
tighten their result by showing that throughput optimality is preserved even
with weight functions of the form log(q)/g(q), where g(q) can be a function
that increases arbitrarily slowly. The significance of the result is due to the
fact that weight functions of the form log(q)/g(q) seem to achieve the best
delay performance in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1385</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1385</id><created>2010-03-06</created><authors><author><keyname>Bege</keyname><forenames>Antal</forenames></author><author><keyname>K&#xe1;sa</keyname><forenames>Zolt&#xe1;n</forenames></author></authors><title>Coding objects related to Catalan numbers</title><categories>cs.DM</categories><msc-class>11B75, 68P30, 68R05</msc-class><acm-class>G.2.1</acm-class><journal-ref>Studia Univ. Babes-Bolyai, Informatica, 46, 1 (2001) 31-41</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coding method using binary sequences is presented for different computation
problems related to Catalan numbers. This method proves in a very easy way the
equivalence of these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1387</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1387</id><created>2010-03-06</created><authors><author><keyname>M&#xe1;rton</keyname><forenames>Gy&#xf6;ngyv&#xe9;r</forenames></author></authors><title>Public-key cryptography in functional programming context</title><categories>cs.CR</categories><msc-class>68N18</msc-class><acm-class>D.1.1</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 2, 1 (2010) 99-112</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Up to now, for efficiency reasons cryptographic algorithm has been written in
an imperative language. But to get acquaintance with a functional programming
language a question arises: functional programming offers some new for secure
communication or not? This article investigates this question giving an
overview on some cryptography algorithms and presents how the RSA encryption in
the functional language Clean can be implemented and how can be measured the
efficiency of a certain application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1395</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1395</id><created>2010-03-06</created><updated>2010-03-09</updated><authors><author><keyname>Burcsi</keyname><forenames>Peter</forenames></author><author><keyname>Kov&#xe1;cs</keyname><forenames>Attila</forenames></author><author><keyname>T&#xe1;trai</keyname><forenames>Antal</forenames></author></authors><title>Start-phase control of distributed systems written in Erlang/OTP</title><categories>cs.DC</categories><msc-class>68M20</msc-class><acm-class>C.4</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 2, 1 (2010) 10-27</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a realization for the reliable and fast startup of
distributed systems written in Erlang. The traditional startup provided by the
Erlang/OTP library is sequential, parallelization usually requires unsafe and
ad-hoc solutions. The proposed method calls only for slight modifications in
the Erlang/OTP stdlib by applying a system dependency graph. It makes the
startup safe, quick, and it is equally easy to use in newly developed and
legacy systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1397</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1397</id><created>2010-03-06</created><authors><author><keyname>Korecko</keyname><forenames>Stefan</forenames></author><author><keyname>Sobota</keyname><forenames>Branislav</forenames></author></authors><title>Using Coloured Petri Nets for design of parallel raytracing environment</title><categories>cs.DC</categories><msc-class>68U20, 68U05</msc-class><acm-class>I.6.3</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 2,1 (2010) 28-39</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the parallel raytracing part of virtual-reality system
PROLAND, developed at the home institution of authors. It describes an actual
implementation of the raytracing part and introduces a Coloured Petri Nets
model of the implementation. The model is used for an evaluation of the
implementation by means of simulation-based performance analysis and also forms
the basis for future improvements of its parallelization strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1399</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1399</id><created>2010-03-06</created><authors><author><keyname>Vaclavik</keyname><forenames>Peter</forenames></author><author><keyname>Poruban</keyname><forenames>Jaroslav</forenames></author><author><keyname>Mezei</keyname><forenames>Marek</forenames></author></authors><title>Automatic derivation of domain terms and concept location based on the
  analysis of the identifiers</title><categories>cs.CL</categories><msc-class>68N99</msc-class><acm-class>D.2.8</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 2,1 (2010) 40-50</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developers express the meaning of the domain ideas in specifically selected
identifiers and comments that form the target implemented code. Software
maintenance requires knowledge and understanding of the encoded ideas. This
paper presents a way how to create automatically domain vocabulary. Knowledge
of domain vocabulary supports the comprehension of a specific domain for later
code maintenance or evolution. We present experiments conducted in two selected
domains: application servers and web frameworks. Knowledge of domain terms
enables easy localization of chunks of code that belong to a certain term. We
consider these chunks of code as &quot;concepts&quot; and their placement in the code as
&quot;concept location&quot;. Application developers may also benefit from the obtained
domain terms. These terms are parts of speech that characterize a certain
concept. Concepts are encoded in &quot;classes&quot; (OO paradigm) and the obtained
vocabulary of terms supports the selection and the comprehension of the class'
appropriate identifiers. We measured the following software products with our
tool: JBoss, JOnAS, GlassFish, Tapestry, Google Web Toolkit and Echo2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1401</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1401</id><created>2010-03-06</created><authors><author><keyname>Sobota</keyname><forenames>Branislav</forenames></author><author><keyname>Guzan</keyname><forenames>Milan</forenames></author></authors><title>Macro and micro view on steady states in state space</title><categories>cs.GR</categories><msc-class>94C99, 68U05</msc-class><acm-class>B.7.2</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 2,1 (2010) 90-98</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes visualization of chaotic attractor and elements of the
singularities in 3D space. 3D view of these effects enables to create a
demonstrative projection about relations of chaos generated by physical
circuit, the Chua's circuit. Via macro views on chaotic attractor is obtained
not only visual space illustration of representative point motion in state
space, but also its relation to planes of singularity elements. Our created
program enables view on chaotic attractor both in 2D and 3D space together with
plane objects visualization -- elements of singularities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1410</identifier>
 <datestamp>2013-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1410</id><created>2010-03-06</created><updated>2013-08-08</updated><authors><author><keyname>Kim</keyname><forenames>Seungyeon</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author></authors><title>Local Space-Time Smoothing for Version Controlled Documents</title><categories>cs.GR cs.CL cs.LG</categories><comments>9 pages, 6 figures</comments><journal-ref>Proceedings of the 23rd International Conference on Computational
  Linguistics (Coling 2010); 2010 Aug 23-27; Beijing, CN</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike static documents, version controlled documents are continuously edited
by one or more authors. Such collaborative revision process makes traditional
modeling and visualization techniques inappropriate. In this paper we propose a
new representation based on local space-time smoothing that captures important
revision patterns. We demonstrate the applicability of our framework using
experiments on synthetic and real-world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1412</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1412</id><created>2010-03-06</created><authors><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Network conduciveness with application to the graph-coloring and
  independent-set optimization transitions</title><categories>cond-mat.stat-mech cs.DS</categories><journal-ref>PLoS ONE 5 (2010), e11232</journal-ref><doi>10.1371/journal.pone.0011232</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of a network's conduciveness, a probabilistically
interpretable measure of how the network's structure allows it to be conducive
to roaming agents, in certain conditions, from one portion of the network to
another. We exemplify its use through an application to the two problems in
combinatorial optimization that, given an undirected graph, ask that its
so-called chromatic and independence numbers be found. Though NP-hard, when
solved on sequences of expanding random graphs there appear marked transitions
at which optimal solutions can be obtained substantially more easily than right
before them. We demonstrate that these phenomena can be understood by resorting
to the network that represents the solution space of the problems for each
graph and examining its conduciveness between the non-optimal solutions and the
optimal ones. At the said transitions, this network becomes strikingly more
conducive in the direction of the optimal solutions than it was just before
them, while at the same time becoming less conducive in the opposite direction.
We believe that, besides becoming useful also in other areas in which network
theory has a role to play, network conduciveness may become instrumental in
helping clarify further issues related to NP-hardness that remain poorly
understood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1422</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1422</id><created>2010-03-06</created><authors><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>Polar Coding for Secure Transmission and Key Agreement</title><categories>cs.IT cs.CR math.IT</categories><comments>Proceedings of the 21st Annual IEEE International Symposium on
  Personal, Indoor, and Mobile Radio Communications (PIMRC 2010), Sept. 2010,
  Istanbul, Turkey</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wyner's work on wiretap channels and the recent works on information
theoretic security are based on random codes. Achieving information theoretical
security with practical coding schemes is of definite interest. In this note,
the attempt is to overcome this elusive task by employing the polar coding
technique of Ar{\i}kan. It is shown that polar codes achieve non-trivial
perfect secrecy rates for binary-input degraded wiretap channels while enjoying
their low encoding-decoding complexity. In the special case of symmetric main
and eavesdropper channels, this coding technique achieves the secrecy capacity.
Next, fading erasure wiretap channels are considered and a secret key agreement
scheme is proposed, which requires only the statistical knowledge of the
eavesdropper channel state information (CSI). The enabling factor is the
creation of advantage over Eve, by blindly using the proposed scheme over each
fading block, which is then exploited with privacy amplification techniques to
generate secret keys.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1426</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1426</id><created>2010-03-06</created><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames></author><author><keyname>Lee</keyname><forenames>James R.</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>Randomly removing g handles at once</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indyk and Sidiropoulos (2007) proved that any orientable graph of genus $g$
can be probabilistically embedded into a graph of genus $g-1$ with constant
distortion. Viewing a graph of genus $g$ as embedded on the surface of a sphere
with $g$ handles attached, Indyk and Sidiropoulos' method gives an embedding
into a distribution over planar graphs with distortion $2^{O(g)}$, by
iteratively removing the handles. By removing all $g$ handles at once, we
present a probabilistic embedding with distortion $O(g^2)$ for both orientable
and non-orientable graphs. Our result is obtained by showing that the nimum-cut
graph of Erickson and Har Peled (2004) has low dilation, and then randomly
cutting this graph out of the surface using the Peeling Lemma of Lee and
Sidiropoulos (2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1443</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1443</id><created>2010-03-07</created><authors><author><keyname>Lee</keyname><forenames>Troy</forenames></author><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>Composition theorems in communication complexity</title><categories>quant-ph cs.CC</categories><comments>19 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A well-studied class of functions in communication complexity are composed
functions of the form $(f \comp g^n)(x,y)=f(g(x^1, y^1),..., g(x^n,y^n))$. This
is a rich family of functions which encompasses many of the important examples
in the literature. It is thus of great interest to understand what properties
of $f$ and $g$ affect the communication complexity of $(f \comp g^n)$, and in
what way.
  Recently, Sherstov \cite{She09b} and independently Shi-Zhu \cite{SZ09b}
developed conditions on the inner function $g$ which imply that the quantum
communication complexity of $f \comp g^n$ is at least the approximate
polynomial degree of $f$. We generalize both of these frameworks. We show that
the pattern matrix framework of Sherstov works whenever the inner function $g$
is {\em strongly balanced}---we say that $g: X \times Y \to \{-1,+1\}$ is
strongly balanced if all rows and columns in the matrix $M_g=[g(x,y)]_{x,y}$
sum to zero. This result strictly generalizes the pattern matrix framework of
Sherstov \cite{She09b}, which has been a very useful idea in a variety of
settings \cite{She08b,RS08,Cha07,LS09,CA08,BHN09}.
  Shi-Zhu require that the inner function $g$ has small {\em spectral
discrepancy}, a somewhat awkward condition to verify. We relax this to the
usual notion of discrepancy. We also enhance the framework of composed
functions studied so far by considering functions $F(x,y) = f(g(x,y))$, where
the range of $g$ is a group $G$. When $G$ is Abelian, the analogue of the
strongly balanced condition becomes a simple group invariance property of $g$.
We are able to formulate a general lower bound on $F$ whenever $g$ satisfies
this property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1449</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1449</id><created>2010-03-07</created><authors><author><keyname>Meenakshi</keyname><forenames>V. S.</forenames></author><author><keyname>Padmavathi</keyname><forenames>G.</forenames></author></authors><title>Securing Iris Templates using Combined User and Soft Biometric based
  Password Hardened Fuzzy Vault</title><categories>cs.CR</categories><comments>Pages IEEE format, Computer Science ISSN 19475500, International
  Journal of Computer Science and Information Security, IJCSIS February 2010,
  ISSN 1947 5500, http://sites.google.com/site/ijcsis/</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 001-008, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Personal identification and authentication is very crucial in the current
scenario. Biometrics plays an important role in this area. Biometric based
authentication has proved superior compared to traditional password based
authentication. Anyhow biometrics is permanent feature of a person and cannot
be reissued when compromised as passwords. To over come this problem, instead
of storing the original biometric templates transformed templates can be
stored. Whenever the transformation function is changed new
revocable/cancelable templates are generated. Soft biometrics is ancillary
information that can be combined with primary biometrics to identify a person
in a better way. Iris has certain advantage compared to other biometric traits
like fingerprint. Iris is an internal part that is less prone to damage.
Moreover is very difficult for an attacker to capture an iris. The key
advantage of iris biometrics is its stability or template longevity. Biometric
systems are vulnerable to a variety of attacks. This work generates cancelable
iris templates by applying user and soft biometric based password
transformations and further secures the templates by biometric cryptographic
construct fuzzy vault.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1450</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1450</id><created>2010-03-07</created><authors><author><keyname>Mamosian</keyname><forenames>Heidar</forenames></author><author><keyname>Rahmani</keyname><forenames>Amir Masoud</forenames></author><author><keyname>Dezfouli</keyname><forenames>Mashalla Abbasi</forenames></author></authors><title>A New Clustering Approach based on Page's Path Similarity for Navigation
  Patterns Mining</title><categories>cs.LG</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 009-014, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent years, predicting the user's next request in web navigation has
received much attention. An information source to be used for dealing with such
problem is the left information by the previous web users stored at the web
access log on the web servers. Purposed systems for this problem work based on
this idea that if a large number of web users request specific pages of a
website on a given session, it can be concluded that these pages are satisfying
similar information needs, and therefore they are conceptually related. In this
study, a new clustering approach is introduced that employs logical path
storing of a website pages as another parameter which is regarded as a
similarity parameter and conceptual relation between web pages. The results of
simulation have shown that the proposed approach is more than others precise in
determining the clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1455</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1455</id><created>2010-03-07</created><authors><author><keyname>N.</keyname><forenames>Rama</forenames></author><author><keyname>Lakshmanan</keyname><forenames>Meenakshi</forenames></author></authors><title>A Computational Algorithm based on Empirical Analysis, that Composes
  Sanskrit Poetry</title><categories>cs.CL</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 056-062, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Poetry-writing in Sanskrit is riddled with problems for even those who know
the language well. This is so because the rules that govern Sanskrit prosody
are numerous and stringent. We propose a computational algorithm that converts
prose given as E-text into poetry in accordance with the metrical rules of
Sanskrit prosody, simultaneously taking care to ensure that sandhi or euphonic
conjunction, which is compulsory in verse, is handled. The algorithm is
considerably speeded up by a novel method of reducing the target search
database. The algorithm further gives suggestions to the poet in case what
he/she has given as the input prose is impossible to fit into any allowed
metrical format. There is also an interactive component of the algorithm by
which the algorithm interacts with the poet to resolve ambiguities. In
addition, this unique work, which provides a solution to a problem that has
never been addressed before, provides a simple yet effective speech recognition
interface that would help the visually impaired dictate words in E-text, which
is in turn versified by our Poetry Composer Engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1456</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1456</id><created>2010-03-07</created><authors><author><keyname>Soni</keyname><forenames>Devpriya</forenames></author><author><keyname>Shrivastava</keyname><forenames>Namita</forenames></author><author><keyname>Kumar</keyname><forenames>M.</forenames></author></authors><title>A Methodology for Empirical Quality Assessment of Object-Oriented Design</title><categories>cs.SE</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 047-055, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The direct measurement of quality is difficult because there is no way we can
measure quality factors. For measuring these factors, we have to express them
in terms of metrics or models. Researchers have developed quality models that
attempt to measure quality in terms of attributes, characteristics and metrics.
In this work we have proposed the methodology of controlled experimentation
coupled with power of Logical Scoring of Preferences to evaluate global quality
of four object-oriented designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1457</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1457</id><created>2010-03-07</created><updated>2010-03-14</updated><authors><author><keyname>Ahangar</keyname><forenames>Reza Gharoie</forenames></author><author><keyname>Yahyazadehfar</keyname><forenames>Mahmood</forenames></author><author><keyname>Pournaghshband</keyname><forenames>Hassan</forenames></author></authors><title>The Comparison of Methods Artificial Neural Network with Linear
  Regression Using Specific Variables for Prediction Stock Price in Tehran
  Stock Exchange</title><categories>cs.NE</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 038-046, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, researchers estimated the stock price of activated companies
in Tehran (Iran) stock exchange. It is used Linear Regression and Artificial
Neural Network methods and compared these two methods. In Artificial Neural
Network, of General Regression Neural Network method (GRNN) for architecture is
used. In this paper, first, researchers considered 10 macro economic variables
and 30 financial variables and then they obtained seven final variables
including 3 macro economic variables and 4 financial variables to estimate the
stock price using Independent components Analysis (ICA). So, we presented an
equation for two methods and compared their results which shown that artificial
neural network method is more efficient than linear regression method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1458</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1458</id><created>2010-03-07</created><authors><author><keyname>Jagadeesan</keyname><forenames>A.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>Secured Cryptographic Key Generation From Multimodal Biometrics: Feature
  Level Fusion of Fingerprint and Iris</title><categories>cs.CR cs.CV</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 028-037, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Human users have a tough time remembering long cryptographic keys. Hence,
researchers, for so long, have been examining ways to utilize biometric
features of the user instead of a memorable password or passphrase, in an
effort to generate strong and repeatable cryptographic keys. Our objective is
to incorporate the volatility of the user's biometric features into the
generated key, so as to make the key unguessable to an attacker lacking
significant knowledge of the user's biometrics. We go one step further trying
to incorporate multiple biometric modalities into cryptographic key generation
so as to provide better security. In this article, we propose an efficient
approach based on multimodal biometrics (Iris and fingerprint) for generation
of secure cryptographic key. The proposed approach is composed of three modules
namely, 1) Feature extraction, 2) Multimodal biometric template generation and
3) Cryptographic key generation. Initially, the features, minutiae points and
texture properties are extracted from the fingerprint and iris images
respectively. Subsequently, the extracted features are fused together at the
feature level to construct the multi-biometric template. Finally, a 256-bit
secure cryptographic key is generated from the multi-biometric template. For
experimentation, we have employed the fingerprint images obtained from publicly
available sources and the iris images from CASIA Iris Database. The
experimental results demonstrate the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1460</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1460</id><created>2010-03-07</created><authors><author><keyname>Barathi</keyname><forenames>M.</forenames></author><author><keyname>Valli</keyname><forenames>S.</forenames></author></authors><title>Ontology Based Query Expansion Using Word Sense Disambiguation</title><categories>cs.IR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 022-027, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The existing information retrieval techniques do not consider the context of
the keywords present in the user's queries. Therefore, the search engines
sometimes do not provide sufficient information to the users. New methods based
on the semantics of user keywords must be developed to search in the vast web
space without incurring loss of information. The semantic based information
retrieval techniques need to understand the meaning of the concepts in the user
queries. This will improve the precision-recall of the search results.
Therefore, this approach focuses on the concept based semantic information
retrieval. This work is based on Word sense disambiguation, thesaurus WordNet
and ontology of any domain for retrieving information in order to capture the
context of particular concept(s) and discover semantic relationships between
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1462</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1462</id><created>2010-03-07</created><authors><author><keyname>Choukse</keyname><forenames>Dharmendra</forenames></author><author><keyname>Singh</keyname><forenames>Umesh Kumar</forenames></author><author><keyname>Sukheja</keyname><forenames>Deepak</forenames></author><author><keyname>Shahapurkar</keyname><forenames>Rekha</forenames></author></authors><title>Implementing New-age Authentication Techniques using OpenID for Security
  Automation</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 015-021, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Security of any software can be enhanced manifolds if multiple factors for
authorization and authentication are used .The main aim of this work was to
design and implement an Academy Automation Software for IPS Academy which uses
OpenID and Windows CardSpace as Authentication Techniques in addition to Role
Based Authentication (RBA) System to ensure that only authentic users can
access the predefined roles as per their Authorization level. The Automation
covers different computing hardware and software that can be used to digitally
create, manipulate, collect, store, and relay Academy information needed for
accomplishing basic Operation like admissions and registration, student and
faculty interaction, online library, medical and business development. Raw data
storage, electronic transfer, and the management of electronic business
information comprise the basic activities of the Academy automation system.
Further Transport Layer Security (TLS) protocol has been implemented to provide
security and data integrity for communications over networks. TLS encrypts the
segments of network connections at the Transport
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1470</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1470</id><created>2010-03-07</created><authors><author><keyname>Rafat</keyname><forenames>Khan Farhan</forenames></author><author><keyname>Sher</keyname><forenames>Muhammad</forenames></author></authors><title>State Of The Art In Digital Steganography Focusing ASCII Text Documents</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 063-072, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Digitization of analogue signals has opened up new avenues for information
hiding and the recent advancements in the telecommunication field has taken up
this desire even further. From copper wire to fiber optics, technology has
evolved and so are ways of covert channel communication. By &quot;Covert&quot; we mean
&quot;anything not meant for the purpose for which it is being used&quot;. Investigation
and detection of existence of such cover channel communication has always
remained a serious concern of information security professionals which has now
been evolved into a motivating source of an adversary to communicate secretly
in &quot;open&quot; without being allegedly caught or noticed. This paper presents a
survey report on steganographic techniques which have been evolved over the
years to hide the existence of secret information inside some cover (Text)
object. The introduction of the subject is followed by the discussion which is
narrowed down to the area where digital ASCII Text documents are being used as
cover. Finally, the conclusion sums up the proceedings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1472</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1472</id><created>2010-03-07</created><authors><author><keyname>Babaie</keyname><forenames>Shahram</forenames></author><author><keyname>Zade</keyname><forenames>Ahmad Khadem</forenames></author><author><keyname>Hosseinalipour</keyname><forenames>Ali</forenames></author></authors><title>New clustering method to decrease probability of failure nodes and
  increasing the lifetime in WSNs</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>International Journal of Computer Science and Information
  Security, IJCSIS, Vol. 7, No. 2, pp. 073-076, February 2010, USA</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Clustering in wireless sensor networks is one of the crucial methods for
increasing of network lifetime. There are many algorithms for clustering. One
of the important cluster based algorithm in wireless sensor networks is LEACH
algorithm. In this paper we proposed a new clustering method for increasing of
network lifetime. We distribute several sensors with a high-energy for managing
the cluster head and to decrease their responsibilities in network. The
performance of the proposed algorithm via computer simulation was evaluated and
compared with other clustering algorithms. The simulation results show the high
performance of the proposed clustering algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1473</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1473</id><created>2010-03-07</created><authors><author><keyname>Roopamala</keyname><forenames>T. D.</forenames></author><author><keyname>Katti</keyname><forenames>S. K.</forenames></author></authors><title>Comments on &quot;Routh Stability Criterion&quot;</title><categories>cs.NA</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this note, we have shown special case on Routh stability criterion, which
is not discussed, in previous literature. This idea can be useful in computer
science applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1476</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1476</id><created>2010-03-07</created><authors><author><keyname>Veerasamy</keyname><forenames>Bala Dhandayuthapani</forenames></author></authors><title>Concurrent Approach to Flynn's SPMD Classification through Java</title><categories>cs.SE</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Parallel programming models exist as an abstraction of hardware and memory
architectures. There are several parallel programming models in commonly use;
they are shared memory model, thread model, message passing model, data
parallel model, hybrid model, Flynn's models, embarrassingly parallel
computations model, pipelined computations model. These models are not specific
to a particular type of machine or memory architecture. This paper focuses the
concurrent approach to Flynn's SPMD classification in single processing
environment through java program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1477</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1477</id><created>2010-03-07</created><authors><author><keyname>Ojha</keyname><forenames>A. K.</forenames></author><author><keyname>Biswal</keyname><forenames>K. K.</forenames></author></authors><title>Multi-objective Geometric Programming Problem With Weighted Mean Method</title><categories>cs.NA</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Geometric programming is an important class of optimization problems that
enable practitioners to model a large variety of real-world applications,
mostly in the field of engineering design. In many real life optimization
problem multi-objective programming plays a vital role in socio-economical and
industrial optimizing problems. In this paper we have discussed the basic
concepts and principle of multiple objective optimization problems and
developed geometric programming (GP) technique to solve this optimization
problem using weighted method to obtain the non-inferior solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1478</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1478</id><created>2010-03-07</created><authors><author><keyname>Dutta</keyname><forenames>Nitul</forenames></author><author><keyname>Misra</keyname><forenames>Iti Saha</forenames></author></authors><title>Use of Service Curve for Resource Reservation in Wired-cum-Wireless
  Scenario</title><categories>cs.NI</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS February 2010, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In a network, arrival process is converted into departure process through
network elements. The departure process suffer propagation delay in the link,
processing delay at the network elements like router and data loss due to
buffer overflow or congestion. For providing guaranteed service resources need
to be reserved before conversation takes place. To reserve such resources
estimation of them are indispensable. The idea of service curve gives
beforehand deterministic value of these parameters. In this paper, we aim to
minimum and maximum buffer space required in the router, minimum link capacity
required to guarantee a pre-specified end-to-end delay for an ongoing session
in a wired-cum-wireless scenario by analyzing minimum and maximum service
curve. We assume that the network we are analyzing is an IP based mobile
network. The findings of the work are presented in the form of tables which can
be used for resource reservation to offer quality service to end-users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1479</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1479</id><created>2010-03-07</created><authors><author><keyname>Ravichandiran</keyname><forenames>C.</forenames></author><author><keyname>Raj</keyname><forenames>C. Pethuru</forenames></author><author><keyname>Vaidhyanathan</keyname><forenames>V.</forenames></author></authors><title>Analysis, Modification, and Implementation (AMI) of Scheduling Algorithm
  for the IEEE 802.116e (Mobile WiMAX)</title><categories>cs.NI</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Mobile WiMAX (Worldwide Interoperability for Microwave Access) is being
touted as the most promising and potential broadband wireless technology. And
the popularity rate has been surging to newer heights as the knowledge-backed
service era unfolds steadily. Especially Mobile WiMAX is being projected as a
real and strategic boon for developing counties such as India due to its
wireless coverage acreage is phenomenally high. Mobile WiMAX has spurred
tremendous interest from operators seeking to deploy high-performance yet
cost-effective broadband wireless networks. The IEEE 802.16e standard based
Mobile WiMAX system will be investigated for the purpose of Quality of Service
provisioning. As a technical challenge, radio resource management will be
primarily considered and main is the costly spectrum and the increasingly more
demanding applications with ever growing number of subscribers. It is necessary
to provide Quality of Service (QoS) guaranteed with different characteristics.
As a possible solution the scheduling algorithms will be taken into main
consideration and the present well known algorithms will be described. In this
paper, we have highlighted the following critical issues for Mobile WiMAX
technologies. This paper specifically discussed about the below mentioned in
detail. - QoS Requirements For IEEE 802.16 Service Classes, Achieving efficient
radio resource management. - Deficit Round Robin (DRR) Scheduling algorithm. -
Modified Deficit Round Robin (MDRR) scheduling algorithm's attributes,
properties and architecture. System Model And Scenarios Using OPNET Modeler
Software. - Simulation Limitations And Constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1491</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1491</id><created>2010-03-07</created><authors><author><keyname>Kumar</keyname><forenames>Manish</forenames></author><author><keyname>Srivastava</keyname><forenames>M. C.</forenames></author><author><keyname>Kumar</keyname><forenames>Umesh</forenames></author></authors><title>Current Conveyor Based Multifunction Filter</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper presents a current conveyor based multifunction filter. The
proposed circuit can be realized as low pass, high pass, band pass and
elliptical notch filter. The circuit employs two balanced output current
conveyors, four resistors and two grounded capacitors, ideal for integration.
It has only one output terminal and the number of input terminals may be used.
Further, there is no requirement for component matching in the circuit. The
parameter resonance frequency (\omega_0) and bandwidth (\omega_0 /Q) enjoy
orthogonal tuning. The complementary metal oxide semiconductor (CMOS)
realization of the current conveyor is given for the simulation of the proposed
circuit. A HSPICE simulation of circuit is also studied for the verification of
theoretical results. The non-ideal analysis of CCII is also studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1492</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1492</id><created>2010-03-07</created><authors><author><keyname>Tiwari</keyname><forenames>Harshvardhan</forenames></author><author><keyname>Asawa</keyname><forenames>Dr. Krishna</forenames></author></authors><title>A Secure Hash Function MD-192 With Modified Message Expansion</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cryptographic hash functions play a central role in cryptography. Hash
functions were introduced in cryptology to provide message integrity and
authentication. MD5, SHA1 and RIPEMD are among the most commonly used message
digest algorithm. Recently proposed attacks on well known and widely used hash
functions motivate a design of new stronger hash function. In this paper a new
approach is presented that produces 192 bit message digest and uses a modified
message expansion mechanism which generates more bit difference in each working
variable to make the algorithm more secure. This hash function is collision
resistant and assures a good compression and preimage resistance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1493</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1493</id><created>2010-03-07</created><authors><author><keyname>Cabrera</keyname><forenames>Mariana Maceiras</forenames></author><author><keyname>Edye</keyname><forenames>Ernesto Ocampo</forenames></author></authors><title>Integration of Rule Based Expert Systems and Case Based Reasoning in an
  Acute Bacterial Meningitis Clinical Decision Support System</title><categories>cs.AI</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This article presents the results of the research carried out on the
development of a medical diagnostic system applied to the Acute Bacterial
Meningitis, using the Case Based Reasoning methodology. The research was
focused on the implementation of the adaptation stage, from the integration of
Case Based Reasoning and Rule Based Expert Systems. In this adaptation stage we
use a higher level RBC that stores and allows reutilizing change experiences,
combined with a classic rule-based inference engine. In order to take into
account the most evident clinical situation, a pre-diagnosis stage is
implemented using a rule engine that, given an evident situation, emits the
corresponding diagnosis and avoids the complete process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1494</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1494</id><created>2010-03-07</created><authors><author><keyname>Qadi</keyname><forenames>Abderrahim El</forenames></author><author><keyname>Aboutajedine</keyname><forenames>Driss</forenames></author><author><keyname>Ennouary</keyname><forenames>Yassine</forenames></author></authors><title>Formal Concept Analysis for Information Retrieval</title><categories>cs.IR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we describe a mechanism to improve Information Retrieval (IR)
on the web. The method is based on Formal Concepts Analysis (FCA) that it is
makes semantical relations during the queries, and allows a reorganizing, in
the shape of a lattice of concepts, the answers provided by a search engine. We
proposed for the IR an incremental algorithm based on Galois lattice. This
algorithm allows a formal clustering of the data sources, and the results which
it turns over are classified by order of relevance. The control of relevance is
exploited in clustering, we improved the result by using ontology in field of
image processing, and reformulating the user queries which make it possible to
give more relevant documents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1497</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1497</id><created>2010-03-07</created><authors><author><keyname>Veerasamy</keyname><forenames>Bala Dhandayuthapani</forenames></author></authors><title>Creating A Model HTTP Server Program Using java</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  HTTP Server is a computer programs that serves webpage content to clients. A
webpage is a document or resource of information that is suitable for the World
Wide Web and can be accessed through a web browser and displayed on a computer
screen. This information is usually in HTML format, and may provide navigation
to other webpage's via hypertext links. WebPages may be retrieved from a local
computer or from a remote HTTP Server. WebPages are requested and served from
HTTP Servers using Hypertext Transfer Protocol (HTTP). WebPages may consist of
files of static or dynamic text stored within the HTTP Server's file system.
Client-side scripting can make WebPages more responsive to user input once in
the client browser. This paper encompasses the creation of HTTP server program
using java language, which is basically supporting for HTML and JavaScript.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1499</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1499</id><created>2010-03-07</created><authors><author><keyname>Hogo</keyname><forenames>Mofreh A.</forenames></author></authors><title>Evaluation of E-Learners Behaviour using Different Fuzzy Clustering
  Models: A Comparative Study</title><categories>cs.CY cs.LG</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper introduces an evaluation methodologies for the e-learners'
behaviour that will be a feedback to the decision makers in e-learning system.
Learner's profile plays a crucial role in the evaluation process to improve the
e-learning process performance. The work focuses on the clustering of the
e-learners based on their behaviour into specific categories that represent the
learner's profiles. The learners' classes named as regular, workers, casual,
bad, and absent. The work may answer the question of how to return bad students
to be regular ones. The work presented the use of different fuzzy clustering
techniques as fuzzy c-means and kernelized fuzzy c-means to find the learners'
categories and predict their profiles. The paper presents the main phases as
data description, preparation, features selection, and the experiments design
using different fuzzy clustering models. Analysis of the obtained results and
comparison with the real world behavior of those learners proved that there is
a match with percentage of 78%. Fuzzy clustering reflects the learners'
behavior more than crisp clustering. Comparison between FCM and KFCM proved
that the KFCM is much better than FCM in predicting the learners' behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1500</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1500</id><created>2010-03-07</created><authors><author><keyname>Saradhi</keyname><forenames>M . V. Vijaya</forenames></author><author><keyname>Sastry</keyname><forenames>B. R.</forenames></author><author><keyname>Satish</keyname><forenames>P.</forenames></author></authors><title>Hierarchical Approach for Online Mining--Emphasis towards Software
  Metrics</title><categories>cs.DB</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Several multi-pass algorithms have been proposed for Association Rule Mining
from static repositories. However, such algorithms are incapable of online
processing of transaction streams. In this paper we introduce an efficient
single-pass algorithm for mining association rules, given a hierarchical
classification amongest items. Processing efficiency is achieved by utilizing
two optimizations, hierarchy aware counting and transaction reduction, which
become possible in the context of hierarchical classification. This paper
considers the problem of integrating constraints that are Boolean expression
over the presence or absence of items into the association discovery algorithm.
This paper present three integrated algorithms for mining association rules
with item constraints and discuss their tradeoffs. It is concluded that the
variation of complexity depends on the measure of DIT (Depth of Inheritance
Tree) and NOC (Number of Children) in the context of Hierarchical
Classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1502</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1502</id><created>2010-03-07</created><authors><author><keyname>Khan</keyname><forenames>Farhan Hassan</forenames></author><author><keyname>Bashir</keyname><forenames>Saba</forenames></author><author><keyname>Javed</keyname><forenames>M. Younus</forenames></author><author><keyname>Khan</keyname><forenames>Aihab</forenames></author><author><keyname>Khiyal</keyname><forenames>Malik Sikandar Hayat</forenames></author></authors><title>QoS Based Dynamic Web Services Composition &amp; Execution</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The use of web services has dominated software industry. Existing
technologies of web services are extended to give value added customized
services to customers through composition. Automated web service composition is
a very challenging task. This paper proposed the solution of existing problems
and proposed a technique by combination of interface based and functionality
based rules. The proposed framework also solves the issues related to
unavailability of updated information and inaccessibility of web services from
repository/databases due to any fault/failure. It provides updated information
problem by adding aging factor in repository/WSDB (Web Services Database) and
inaccessibility is solved by replication of WSDB. We discussed data
distribution techniques and proposed our framework by using one of these
strategies by considering quality of service issues. Finally, our algorithm
eliminates the dynamic service composition and execution issues, supports web
service composition considering QoS (Quality of Service), efficient data
retrieval and updation, fast service distribution and fault tolerance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1504</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1504</id><created>2010-03-07</created><authors><author><keyname>Bashir</keyname><forenames>Saba</forenames></author><author><keyname>Khan</keyname><forenames>Farhan Hassan</forenames></author><author><keyname>Javed</keyname><forenames>M. Younus</forenames></author><author><keyname>Khan</keyname><forenames>Aihab</forenames></author><author><keyname>Khiyal</keyname><forenames>Malik Sikandar Hayat</forenames></author></authors><title>Indexer Based Dynamic Web Services Discovery</title><categories>cs.AI</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recent advancement in web services plays an important role in business to
business and business to consumer interaction. Discovery mechanism is not only
used to find a suitable service but also provides collaboration between service
providers and consumers by using standard protocols. A static web service
discovery mechanism is not only time consuming but requires continuous human
interaction. This paper proposed an efficient dynamic web services discovery
mechanism that can locate relevant and updated web services from service
registries and repositories with timestamp based on indexing value and
categorization for faster and efficient discovery of service. The proposed
prototype focuses on quality of service issues and introduces concept of local
cache, categorization of services, indexing mechanism, CSP (Constraint
Satisfaction Problem) solver, aging and usage of translator. Performance of
proposed framework is evaluated by implementing the algorithm and correctness
of our method is shown. The results of proposed framework shows greater
performance and accuracy in dynamic discovery mechanism of web services
resolving the existing issues of flexibility, scalability, based on quality of
service, and discovers updated and most relevant services with ease of usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1507</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1507</id><created>2010-03-07</created><authors><author><keyname>Chakrabarty</keyname><forenames>Deeparnab</forenames></author><author><keyname>Grant</keyname><forenames>Elyot</forenames></author><author><keyname>Koenemann</keyname><forenames>Jochen</forenames></author></authors><title>On Column-restricted and Priority Covering Integer Programs</title><categories>cs.DS</categories><comments>28 pages, 6 figures, extended abstract to appear in proceedings of
  IPCO 2010.</comments><doi>10.1007/978-3-642-13036-6_27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a column-restricted covering integer program (CCIP), all the non-zero
entries of any column of the constraint matrix are equal. Such programs capture
capacitated versions of covering problems. In this paper, we study the
approximability of CCIPs, in particular, their relation to the integrality gaps
of the underlying 0,1-CIP.
  If the underlying 0,1-CIP has an integrality gap O(gamma), and assuming that
the integrality gap of the priority version of the 0,1-CIP is O(omega), we give
a factor O(gamma + omega) approximation algorithm for the CCIP. Priority
versions of 0,1-CIPs (PCIPs) naturally capture quality of service type
constraints in a covering problem.
  We investigate priority versions of the line (PLC) and the (rooted) tree
cover (PTC) problems. Apart from being natural objects to study, these problems
fall in a class of fundamental geometric covering problems. We bound the
integrality of certain classes of this PCIP by a constant. Algorithmically, we
give a polytime exact algorithm for PLC, show that the PTC problem is APX-hard,
and give a factor 2-approximation algorithm for it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1509</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1509</id><created>2010-03-07</created><authors><author><keyname>Babu</keyname><forenames>P.</forenames></author><author><keyname>Krishnan</keyname><forenames>A.</forenames></author></authors><title>A New Variable Threshold and Dynamic Step Size Based Active Noise
  Control System for Improving Performance</title><categories>cs.OH cs.SD</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Several approaches have been introduced in literature for active noise
control (ANC) systems. Since FxLMS algorithm appears to be the best choice as a
controller filter, researchers tend to improve performance of ANC systems by
enhancing and modifying this algorithm. In this paper, modification is done in
the existing FxLMS algorithm that provides a new structure for improving the
tracking performance and convergence rate. The secondary signal y(n) is dynamic
thresholded by Wavelet transform to improve tracking. The convergence rate is
improved by dynamically varying the step size of the error signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1510</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1510</id><created>2010-03-07</created><authors><author><keyname>Sriurai</keyname><forenames>Wongkot</forenames></author><author><keyname>Meesad</keyname><forenames>Phayung</forenames></author><author><keyname>Haruechaiyasak</keyname><forenames>Choochart</forenames></author></authors><title>Hierarchical Web Page Classification Based on a Topic Model and
  Neighboring Pages Integration</title><categories>cs.LG</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Most Web page classification models typically apply the bag of words (BOW)
model to represent the feature space. The original BOW representation, however,
is unable to recognize semantic relationships between terms. One possible
solution is to apply the topic model approach based on the Latent Dirichlet
Allocation algorithm to cluster the term features into a set of latent topics.
Terms assigned into the same topic are semantically related. In this paper, we
propose a novel hierarchical classification method based on a topic model and
by integrating additional term features from neighboring pages. Our
hierarchical classification method consists of two phases: (1) feature
representation by using a topic model and integrating neighboring pages, and
(2) hierarchical Support Vector Machines (SVM) classification model constructed
from a confusion matrix. From the experimental results, the approach of using
the proposed hierarchical SVM model by integrating current page with
neighboring pages via the topic model yielded the best performance with the
accuracy equal to 90.33% and the F1 measure of 90.14%; an improvement of 5.12%
and 5.13% over the original SVM model, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1511</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1511</id><created>2010-03-07</created><authors><author><keyname>Katiyar</keyname><forenames>Rohit</forenames></author><author><keyname>Pathak</keyname><forenames>Dr. Vinay Kumar</forenames></author></authors><title>Clinical gait data analysis based on Spatio-Temporal features</title><categories>cs.CV</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Analysing human gait has found considerable interest in recent computer
vision research. So far, however, contributions to this topic exclusively dealt
with the tasks of person identification or activity recognition. In this paper,
we consider a different application for gait analysis and examine its use as a
means of deducing the physical well-being of people. The proposed method is
based on transforming the joint motion trajectories using wavelets to extract
spatio-temporal features which are then fed as input to a vector quantiser; a
self-organising map for classification of walking patterns of individuals with
and without pathology. We show that our proposed algorithm is successful in
extracting features that successfully discriminate between individuals with and
without locomotion impairment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1514</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1514</id><created>2010-03-07</created><authors><author><keyname>Thulasimani</keyname><forenames>L.</forenames></author><author><keyname>Madheswaran</keyname><forenames>M.</forenames></author></authors><title>Design and Performance Analysis of Unified Reconfigurable Data Integrity
  Unit for Mobile Terminals</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Security has become one of the major issue in mobile services. In the
development of recent mobile devices like Software Defined Radio (SDR) secure
method of software downloading is found necessary for reconfiguration. Hash
functions are the important security primitives used for authentication and
data integrity. In this paper, VLSI architecture for implementation of
integrity unit in SDR is proposed. The proposed architecture is reconfigurable
in the sense it operates in two different modes: SHA-192 and MD-5.Due to
applied design technique the proposed architecture achieves multi-mode
operation, which keeps the allocated area resource at minimized level. The
proposed architecture also achieves highspeed performance with pipelined
designed structure. Comparison with related hash function implementation have
been done in terms of operating frequency, allocated-area and area-delay
product. The proposed Integrity Unity can be integrated in security systems for
implementation of network for wireless protocol, with special needs of
integrity in data transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1515</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1515</id><created>2010-03-07</created><authors><author><keyname>Lingareddy</keyname><forenames>S. C.</forenames></author><author><keyname>Charles</keyname><forenames>Dr B Stephen</forenames></author><author><keyname>Babu</keyname><forenames>Dr Vinaya</forenames></author><author><keyname>Dhruve</keyname><forenames>Kashyap</forenames></author></authors><title>Soft Computing - A step towards building Secure Cognitive WLAN</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Wireless Networks rendering varied services has not only become the order of
the day but the demand of a large pool of customers as well. Thus, security of
wireless networks has become a very essential design criterion. This paper
describes our research work focused towards creating secure cognitive wireless
local area networks using soft computing approaches. The present dense Wireless
Local Area Networks (WLAN) pose a huge threat to network integrity and are
vulnerable to attacks. In this paper we propose a secure Cognitive Framework
Architecture (CFA). The Cognitive Security Manager (CSM) is the heart of CFA.
The CSM incorporates access control using Physical Architecture Description
Layer (PADL) and analyzes the operational matrices of the terminals using multi
layer neural networks, acting accordingly to identify authorized access and
unauthorized usage patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1517</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1517</id><created>2010-03-07</created><updated>2010-10-05</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Schoenebeck</keyname><forenames>Grant</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author></authors><title>Constrained Non-Monotone Submodular Maximization: Offline and Secretary
  Algorithms</title><categories>cs.DS cs.GT</categories><comments>In the Proceedings of WINE 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constrained submodular maximization problems have long been studied, with
near-optimal results known under a variety of constraints when the submodular
function is monotone. The case of non-monotone submodular maximization is less
understood: the first approximation algorithms even for the unconstrainted
setting were given by Feige et al. (FOCS '07). More recently, Lee et al. (STOC
'09, APPROX '09) show how to approximately maximize non-monotone submodular
functions when the constraints are given by the intersection of p matroid
constraints; their algorithm is based on local-search procedures that consider
p-swaps, and hence the running time may be n^Omega(p), implying their algorithm
is polynomial-time only for constantly many matroids. In this paper, we give
algorithms that work for p-independence systems (which generalize constraints
given by the intersection of p matroids), where the running time is poly(n,p).
Our algorithm essentially reduces the non-monotone maximization problem to
multiple runs of the greedy algorithm previously used in the monotone case.
  Our idea of using existing algorithms for monotone functions to solve the
non-monotone case also works for maximizing a submodular function with respect
to a knapsack constraint: we get a simple greedy-based constant-factor
approximation for this problem.
  With these simpler algorithms, we are able to adapt our approach to
constrained non-monotone submodular maximization to the (online) secretary
setting, where elements arrive one at a time in random order, and the algorithm
must make irrevocable decisions about whether or not to select each element as
it arrives. We give constant approximations in this secretary setting when the
algorithm is constrained subject to a uniform matroid or a partition matroid,
and give an O(log k) approximation when it is constrained by a general matroid
of rank k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1520</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1520</id><created>2010-03-07</created><updated>2013-12-30</updated><authors><author><keyname>K&#xe1;sa</keyname><forenames>Zolt&#xe1;n</forenames></author></authors><title>On arc-disjoint Hamiltonian cycles in De Bruijn graphs</title><categories>cs.DM</categories><msc-class>68R10, 90B10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give two equivalent formulations of a conjecture [2,4] on the number of
arc-disjoint Hamiltonian cycles in De Bruijn graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1550</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1550</id><created>2010-03-07</created><authors><author><keyname>Mishra</keyname><forenames>Debasis</forenames></author><author><keyname>Sen</keyname><forenames>Arunava</forenames></author></authors><title>Roberts' Theorem with Neutrality: A Social Welfare Ordering Approach</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider dominant strategy implementation in private values settings, when
agents have multi-dimensional types, the set of alternatives is finite,
monetary transfers are allowed, and agents have quasi-linear utilities. We show
that any implementable and neutral social choice function must be a weighted
welfare maximizer if the type space of every agent is an $m$-dimensional open
interval, where $m$ is the number of alternatives. When the type space of every
agent is unrestricted, Roberts' theorem with neutrality \cite{Roberts79}
becomes a corollary to our result. Our proof technique uses a {\em social
welfare ordering} approach, commonly used in aggregation literature in social
choice theory. We also prove the general (affine maximizer) version of Roberts'
theorem for unrestricted type spaces of agents using this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1572</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1572</id><created>2010-03-08</created><authors><author><keyname>Schroevers</keyname><forenames>Stephan</forenames></author></authors><title>Expressiveness and Extensions of an Instruction Sequence Semigroup</title><categories>cs.PL</categories><comments>Master's thesis - Master of Logic - University of Amsterdam</comments><acm-class>D.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PGA, short for ProGram Algebra, describes sequential programs as finite or
infinite (repeating) sequences of instructions. The semigroup C of finite
instruction sequences was introduced as an equally expressive alternative to
PGA. PGA instructions are executed from left to right; most C instructions come
in a left-to-right as well as a right-to-left flavor. This thesis builds on C
by introducing an alternative semigroup Cg which employs label and goto
instructions instead of relative jump instructions as control structures. Cg
can be translated to C and vice versa (and is thus equally expressive). It is
shown that restricting the instruction sets of C and Cg to contain only
finitely many distinct jump, goto or label instructions in either or both
directions reduces their expressiveness. Instruction sets with an infinite
number of these instructions in both directions (not necessarily all such
instructions) do not suffer a loss of expressiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1588</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1588</id><created>2010-03-08</created><authors><author><keyname>Bobillo</keyname><forenames>Fernando</forenames></author><author><keyname>Bou</keyname><forenames>Felix</forenames></author><author><keyname>Straccia</keyname><forenames>Umberto</forenames></author></authors><title>On the Failure of the Finite Model Property in some Fuzzy Description
  Logics</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fuzzy Description Logics (DLs) are a family of logics which allow the
representation of (and the reasoning with) structured knowledge affected by
vagueness. Although most of the not very expressive crisp DLs, such as ALC,
enjoy the Finite Model Property (FMP), this is not the case once we move into
the fuzzy case. In this paper we show that if we allow arbitrary knowledge
bases, then the fuzzy DLs ALC under Lukasiewicz and Product fuzzy logics do not
verify the FMP even if we restrict to witnessed models; in other words, finite
satisfiability and witnessed satisfiability are different for arbitrary
knowledge bases. The aim of this paper is to point out the failure of FMP
because it affects several algorithms published in the literature for reasoning
under fuzzy ALC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1598</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1598</id><created>2010-03-08</created><authors><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Information Fusion in the Immune System</title><categories>cs.AI cs.NE</categories><comments>10 pages, 6 tables, 6 figures, Information Fusion</comments><journal-ref>Information Fusion, 11 (1), 35-44, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biologically-inspired methods such as evolutionary algorithms and neural
networks are proving useful in the field of information fusion. Artificial
Immune Systems (AISs) are a biologically-inspired approach which take
inspiration from the biological immune system. Interestingly, recent research
has show how AISs which use multi-level information sources as input data can
be used to build effective algorithms for real time computer intrusion
detection. This research is based on biological information fusion mechanisms
used by the human immune system and as such might be of interest to the
information fusion community. The aim of this paper is to present a summary of
some of the biological information fusion mechanisms seen in the human immune
system, and of how these mechanisms have been implemented as AISs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1608</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1608</id><created>2010-03-08</created><authors><author><keyname>Barenboim</keyname><forenames>Leonid</forenames></author><author><keyname>Elkin</keyname><forenames>Michael</forenames></author></authors><title>Deterministic Distributed Vertex Coloring in Polylogarithmic Time</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an n-vertex graph G = (V,E) of maximum degree Delta, and suppose
that each vertex v \in V hosts a processor. The processors are allowed to
communicate only with their neighbors in G. The communication is synchronous,
i.e., it proceeds in discrete rounds. In the distributed vertex coloring
problem the objective is to color G with Delta + 1, or slightly more than Delta
+ 1, colors using as few rounds of communication as possible. (The number of
rounds of communication will be henceforth referred to as running time.)
Efficient randomized algorithms for this problem are known for more than twenty
years \cite{L86, ABI86}. Specifically, these algorithms produce a (Delta +
1)-coloring within O(log n) time, with high probability. On the other hand, the
best known deterministic algorithm that requires polylogarithmic time employs
O(Delta^2) colors. This algorithm was devised in a seminal FOCS'87 paper by
Linial \cite{L87}. Its running time is O(log^* n). In the same paper Linial
asked whether one can color with significantly less than Delta^2 colors in
deterministic polylogarithmic time. By now this question of Linial became one
of the most central long-standing open questions in this area. In this paper we
answer this question in the affirmative, and devise a deterministic algorithm
that employs \Delta^{1 +o(1)} colors, and runs in polylogarithmic time.
Specifically, the running time of our algorithm is O(f(Delta) log Delta log n),
for an arbitrarily slow-growing function f(Delta) = \omega(1). We can also
produce O(Delta^{1 + \eta})-coloring in O(log Delta log n)-time, for an
arbitrarily small constant \eta &gt; 0, and O(Delta)-coloring in
O(Delta^{\epsilon} log n) time, for an arbitrarily small constant \epsilon &gt; 0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1628</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1628</id><created>2010-03-08</created><authors><author><keyname>Veberic</keyname><forenames>Darko</forenames></author></authors><title>Having Fun with Lambert W(x) Function</title><categories>cs.MS cs.NA math.NA</categories><comments>15 pages, 11 figures, 4 tables</comments><report-no>GAP-2009-114</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This short note presents the Lambert W(x) function and its possible
application in the framework of physics related to the Pierre Auger
Observatory. The actual numerical implementation in C++ consists of Halley's
and Fritsch's iteration with branch-point expansion, asymptotic series and
rational fits as initial approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1632</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1632</id><created>2010-03-08</created><authors><author><keyname>Gasc&#xf3;n</keyname><forenames>Adri&#xe0;</forenames></author><author><keyname>Godoy</keyname><forenames>Guillem</forenames></author><author><keyname>Schmidt-Schau&#xdf;</keyname><forenames>Manfred</forenames></author></authors><title>Unification and Matching on Compressed Terms</title><categories>cs.LO</categories><comments>This paper is posted at the Computing Research Repository (CoRR) as
  part of the process of submission to the journal ACM Transactions on
  Computational Logic (TOCL).</comments><acm-class>F.4.1; F.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Term unification plays an important role in many areas of computer science,
especially in those related to logic. The universal mechanism of grammar-based
compression for terms, in particular the so-called Singleton Tree Grammars
(STG), have recently drawn considerable attention. Using STGs, terms of
exponential size and height can be represented in linear space. Furthermore,
the term representation by directed acyclic graphs (dags) can be efficiently
simulated. The present paper is the result of an investigation on term
unification and matching when the terms given as input are represented using
different compression mechanisms for terms such as dags and Singleton Tree
Grammars. We describe a polynomial time algorithm for context matching with
dags, when the number of different context variables is fixed for the problem.
For the same problem, NP-completeness is obtained when the terms are
represented using the more general formalism of Singleton Tree Grammars. For
first-order unification and matching polynomial time algorithms are presented,
each of them improving previous results for those problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1655</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1655</id><created>2010-03-08</created><authors><author><keyname>Zhong</keyname><forenames>Yangfan</forenames></author><author><keyname>Wang</keyname><forenames>Yadong</forenames></author><author><keyname>Alajaji</keyname><forenames>Fady</forenames></author><author><keyname>Linder</keyname><forenames>Tamas</forenames></author></authors><title>Inner and Outer Bounds for the Public Information Embedding Capacity
  Region Under Multiple Access Attacks</title><categories>cs.IT math.IT</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a public multi-user information embedding (watermarking) system
in which two messages (watermarks) are independently embedded into two
correlated covertexts and are transmitted through a multiple-access attack
channel. The tradeoff between the achievable embedding rates and the average
distortions for the two embedders is studied. For given distortion levels,
inner and outer bounds for the embedding capacity region are obtained in
single-letter form. Tighter bounds are also given for independent covertexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1658</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1658</id><created>2010-03-08</created><updated>2010-03-21</updated><authors><author><keyname>Achs</keyname><forenames>Agnes</forenames></author></authors><title>A multivalued knowledge-base model</title><categories>cs.AI</categories><msc-class>68T30</msc-class><acm-class>I.2.4</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 2,1(2010) 51-79</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The basic aim of our study is to give a possible model for handling uncertain
information. This model is worked out in the framework of DATALOG. At first the
concept of fuzzy Datalog will be summarized, then its extensions for
intuitionistic- and interval-valued fuzzy logic is given and the concept of
bipolar fuzzy Datalog is introduced. Based on these ideas the concept of
multivalued knowledge-base will be defined as a quadruple of any background
knowledge; a deduction mechanism; a connecting algorithm, and a function set of
the program, which help us to determine the uncertainty levels of the results.
At last a possible evaluation strategy is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1682</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1682</id><created>2010-03-08</created><authors><author><keyname>Barringer</keyname><forenames>Howard</forenames></author><author><keyname>Groce</keyname><forenames>Alex</forenames></author><author><keyname>Havelund</keyname><forenames>Klaus</forenames></author><author><keyname>Smith</keyname><forenames>Margaret</forenames></author></authors><title>An Entry Point for Formal Methods: Specification and Analysis of Event
  Logs</title><categories>cs.SE</categories><journal-ref>EPTCS 20, 2010, pp. 16-21</journal-ref><doi>10.4204/EPTCS.20.2</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Formal specification languages have long languished, due to the grave
scalability problems faced by complete verification methods. Runtime
verification promises to use formal specifications to automate part of the more
scalable art of testing, but has not been widely applied to real systems, and
often falters due to the cost and complexity of instrumentation for online
monitoring. In this paper we discuss work in progress to apply an event-based
specification system to the logging mechanism of the Mars Science Laboratory
mission at JPL. By focusing on log analysis, we exploit the &quot;instrumentation&quot;
already implemented and required for communicating with the spacecraft. We
argue that this work both shows a practical method for using formal
specifications in testing and opens interesting research avenues, including a
challenging specification learning problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1684</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1684</id><created>2010-03-08</created><updated>2010-12-22</updated><authors><author><keyname>Ehlers</keyname><forenames>Ruediger</forenames></author></authors><title>Generalised Rabin(1) synthesis</title><categories>cs.LO</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel method for the synthesis of finite state systems that is a
generalisation of the generalised reactivity(1) synthesis approach by Piterman,
Pnueli and Sa'ar. In particular, we describe an efficient method to synthesize
systems from linear-time temporal logic specifications for which all
assumptions and guarantees have a Rabin index of one. We show how to build a
parity game with at most five colours that captures all solutions to the
synthesis problem from such a specification. This parity game has a structure
that is amenable to symbolic implementations. We furthermore show that the
results obtained are in some sense tight, i.e., that there does not exist a
similar synthesis method for assumptions and specifications of higher Rabin
index, unless P=NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1738</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1738</id><created>2010-03-08</created><updated>2011-01-18</updated><authors><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>MISO Capacity with Per-Antenna Power Constraint</title><categories>cs.IT math.IT</categories><comments>7 pages double-column, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish in closed-form the capacity and the optimal signaling scheme for
a MISO channel with per-antenna power constraint. Two cases of channel state
information are considered: constant channel known at both the transmitter and
receiver, and Rayleigh fading channel known only at the receiver. For the first
case, the optimal signaling scheme is beamforming with the phases of the beam
weights matched to the phases of the channel coefficients, but the amplitudes
independent of the channel coefficients and dependent only on the constrained
powers. For the second case, the optimal scheme is to send independent signals
from the antennas with the constrained powers. In both cases, the capacity with
per-antenna power constraint is usually less than that with sum power
constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1741</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1741</id><created>2010-03-08</created><updated>2012-06-27</updated><authors><author><keyname>Cimatti</keyname><forenames>Alessandro</forenames></author><author><keyname>Roveri</keyname><forenames>Marco</forenames></author><author><keyname>Susi</keyname><forenames>Angelo</forenames></author><author><keyname>Tonetta</keyname><forenames>Stefano</forenames></author></authors><title>Formalization and Validation of Safety-Critical Requirements</title><categories>cs.SE</categories><journal-ref>EPTCS 20, 2010, pp. 68-75</journal-ref><doi>10.4204/EPTCS.20.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The validation of requirements is a fundamental step in the development
process of safety-critical systems. In safety critical applications such as
aerospace, avionics and railways, the use of formal methods is of paramount
importance both for requirements and for design validation. Nevertheless, while
for the verification of the design, many formal techniques have been conceived
and applied, the research on formal methods for requirements validation is not
yet mature. The main obstacles are that, on the one hand, the correctness of
requirements is not formally defined; on the other hand that the formalization
and the validation of the requirements usually demands a strong involvement of
domain experts. We report on a methodology and a series of techniques that we
developed for the formalization and validation of high-level requirements for
safety-critical applications. The main ingredients are a very expressive formal
language and automatic satisfiability procedures. The language combines
first-order, temporal, and hybrid logic. The satisfiability procedures are
based on model checking and satisfiability modulo theory. We applied this
technology within an industrial project to the validation of railways
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1775</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1775</id><created>2010-03-08</created><authors><author><keyname>Doty</keyname><forenames>Nick</forenames></author><author><keyname>Mulligan</keyname><forenames>Deirdre K.</forenames></author><author><keyname>Wilde</keyname><forenames>Erik</forenames></author></authors><title>Privacy Issues of the W3C Geolocation API</title><categories>cs.CY cs.HC</categories><report-no>UC Berkeley School of Information Report 2010-038</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The W3C's Geolocation API may rapidly standardize the transmission of
location information on the Web, but, in dealing with such sensitive
information, it also raises serious privacy concerns. We analyze the manner and
extent to which the current W3C Geolocation API provides mechanisms to support
privacy. We propose a privacy framework for the consideration of location
information and use it to evaluate the W3C Geolocation API, both the
specification and its use in the wild, and recommend some modifications to the
API as a result of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1787</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1787</id><created>2010-03-09</created><updated>2010-11-01</updated><authors><author><keyname>Shioji</keyname><forenames>Eitaro</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author></authors><title>Vulnerability of MRD-Code-based Universal Secure Network Coding against
  Stronger Eavesdroppers</title><categories>cs.IT math.IT</categories><comments>7 pages, no figure, ieice.cls, a part of this paper was presented in
  2010 IEEE International Symposium on Information Theory. The proofs in V2
  became more readable than V1, but the results unchanged</comments><journal-ref>IEICE Trans. Fundamentals, vol. 93, no. 11, pp. 2026-2033, Nov.
  2010</journal-ref><doi>10.1587/transfun.E93.A.2026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Silva et al. proposed a universal secure network coding scheme based on MRD
codes, which can be applied to any underlying network code. This paper
considers a stronger eavesdropping model where the eavesdroppers possess the
ability to re-select the tapping links during the transmission. We give a proof
for the impossibility of attaining universal security against such adversaries
using Silva et al.'s code for all choices of code parameters, even with
restricted number of tapped links. We also consider the cases with restricted
tapping duration and derive some conditions for this code to be secure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1792</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1792</id><created>2010-03-09</created><authors><author><keyname>Kularbphettong</keyname><forenames>Kobkul</forenames></author><author><keyname>Clayton</keyname><forenames>Gareth</forenames></author><author><keyname>Meesad</keyname><forenames>Phayung</forenames></author></authors><title>A Hybrid System based on Multi-Agent System in the Data Preprocessing
  Stage</title><categories>cs.MA</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We describe the usage of the Multi-agent system in the data preprocessing
stage of an on-going project, called e-Wedding. The aim of this project is to
utilize MAS and various approaches, like Web services, Ontology, and Data
mining techniques, in e-Business that want to improve responsiveness and
efficiency of systems so as to extract customer behavior model on Wedding
Businesses. However, in this paper, we propose and implement the
multi-agent-system, based on JADE, to only cope data preprocessing stage
specified on handle with missing value techniques. JADE is quite easy to learn
and use. Moreover, it supports many agent approaches such as agent
communication, protocol, behavior and ontology. This framework has been
experimented and evaluated in the realization of a simple, but realistic. The
results, though still preliminary, are quite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1794</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1794</id><created>2010-03-09</created><authors><author><keyname>Roopamala</keyname><forenames>D.</forenames></author><author><keyname>Katti</keyname><forenames>S. K.</forenames></author></authors><title>New Approach to Identify Common Eigenvalues of real matrices using
  Gerschgorin Theorem and Bisection method</title><categories>cs.NA</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, a new approach is presented to determine common eigenvalues of
two matrices. It is based on Gerschgorin theorem and Bisection method. The
proposed approach is simple and can be useful in image processing and noise
estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1795</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1795</id><created>2010-03-09</created><authors><author><keyname>A</keyname><forenames>Vidhya. K.</forenames></author><author><keyname>Aghila</keyname><forenames>G.</forenames></author></authors><title>A Survey of Na\&quot;ive Bayes Machine Learning approach in Text Document
  Classification</title><categories>cs.LG cs.IR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Text Document classification aims in associating one or more predefined
categories based on the likelihood suggested by the training set of labeled
documents. Many machine learning algorithms play a vital role in training the
system with predefined categories among which Na\&quot;ive Bayes has some intriguing
facts that it is simple, easy to implement and draws better accuracy in large
datasets in spite of the na\&quot;ive dependence. The importance of Na\&quot;ive Bayes
Machine learning approach has felt hence the study has been taken up for text
document classification and the statistical event models available. This survey
the various feature selection methods has been discussed and compared along
with the metrics related to text document classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1796</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1796</id><created>2010-03-09</created><authors><author><keyname>Jalil</keyname><forenames>Zunera</forenames></author><author><keyname>Mirza</keyname><forenames>Anwar M.</forenames></author><author><keyname>Sabir</keyname><forenames>Maria</forenames></author></authors><title>Content based Zero-Watermarking Algorithm for Authentication of Text
  Documents</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Copyright protection and authentication of digital contents has become a
significant issue in the current digital epoch with efficient communication
mediums such as internet. Plain text is the rampantly used medium used over the
internet for information exchange and it is very crucial to verify the
authenticity of information. There are very limited techniques available for
plain text watermarking and authentication. This paper presents a novel
zero-watermarking algorithm for authentication of plain text. The algorithm
generates a watermark based on the text contents and this watermark can later
be extracted using extraction algorithm to prove the authenticity of text
document. Experimental results demonstrate the effectiveness of the algorithm
against tampering attacks identifying watermark accuracy and distortion rate on
10 different text samples of varying length and attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1799</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1799</id><created>2010-03-09</created><authors><author><keyname>SuganyaDevi</keyname><forenames>D.</forenames></author><author><keyname>Padmavathi</keyname><forenames>G.</forenames></author></authors><title>Secure Multicast Key Distribution for Mobile Ad Hoc Networks</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Many emerging applications in mobile adhoc networks involve group-oriented
communication. Multicast is an efficient way of supporting group oriented
applications, mainly in mobile environment with limited bandwidth and limited
power. For using such applications in an adversarial environment as military,
it is necessary to provide secure multicast communication. Key management is
the fundamental challenge in designing secure multicast communications. In many
multicast interactions, new member can join and current members can leave at
any time and existing members must communicate securely using multicast key
distribution within constrained energy for mobile adhoc networks. This has to
overcome the challenging element of &quot;1 affects n&quot; problem which is due to high
dynamicity of groups. Thus this paper shows the specific challenges towards
multicast key management protocols for securing multicast key distribution in
mobile ad hoc networks, and present relevant multicast key management protocols
in mobile ad hoc networks. A comparison is done against some pertinent
performance criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1803</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1803</id><created>2010-03-09</created><authors><author><keyname>Thivakaran</keyname><forenames>T. K.</forenames></author><author><keyname>Chandrasekaran</keyname><forenames>RM.</forenames></author></authors><title>Nonlinear Filter Based Image Denoising Using AMF Approach</title><categories>cs.CV</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper proposes a new technique based on nonlinear Adaptive Median filter
(AMF) for image restoration. Image denoising is a common procedure in digital
image processing aiming at the removal of noise, which may corrupt an image
during its acquisition or transmission, while retaining its quality. This
procedure is traditionally performed in the spatial or frequency domain by
filtering. The aim of image enhancement is to reconstruct the true image from
the corrupted image. The process of image acquisition frequently leads to
degradation and the quality of the digitized image becomes inferior to the
original image. Filtering is a technique for enhancing the image. Linear filter
is the filtering in which the value of an output pixel is a linear combination
of neighborhood values, which can produce blur in the image. Thus a variety of
smoothing techniques have been developed that are non linear. Median filter is
the one of the most popular non-linear filter. When considering a small
neighborhood it is highly efficient but for large window and in case of high
noise it gives rise to more blurring to image. The Centre Weighted Median (CWM)
filter has got a better average performance over the median filter [8]. However
the original pixel corrupted and noise reduction is substantial under high
noise condition. Hence this technique has also blurring affect on the image. To
illustrate the superiority of the proposed approach by overcoming the existing
problem, the proposed new scheme (AMF) Adaptive Median Filter has been
simulated along with the standard ones and various performance measures have
been compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1806</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1806</id><created>2010-03-09</created><authors><author><keyname>Rathika</keyname><forenames>Ms. A.</forenames></author><author><keyname>Saranya</keyname><forenames>Ms. R.</forenames></author><author><keyname>Iswarya</keyname><forenames>Ms. R.</forenames></author></authors><title>Securing Our Bluetooth Mobiles From Intruder Attack Using Enhanced
  Authentication Scheme And Plausible Exchange Algorithm</title><categories>cs.CR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  When Bluetooth devices come within the range of another, an electronic
conversation takes place to determine whether the devices in range are known or
whether one needs to control the other. Most Bluetooth devices do not require
any form of user interaction for this to occur. If devices within range are
known to one another, the devices automatically form a network known as a
pairing. Authentication addresses the identity of each communicating device.
The sender sends an encrypted authentication request frame to the receiver. The
receiver sends an encrypted challenge frame back to the sender. Both perform a
predefined algorithm. The sender sends its findings back to the receiver, which
in turn either allows or denies the connection. There are three different
functions for authentication in Bluetooth-E1, E2, and E3. E1 is used when
encrypting the authorization challenge-response values.E2 is for generating
different link keys.E3 is used when creating the encryption key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1807</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1807</id><created>2010-03-09</created><authors><author><keyname>Gerami</keyname><forenames>Mohsen</forenames></author></authors><title>Knowledge Management</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper discusses the important process of knowledge and its management,
and differences between tacit and explicit knowledge and understanding the
culture as a key issue for the successful implementation of knowledge
management, in addition to, this paper is concerned with the four-stage model
for the evolution of information technology (IT) support for knowledge
management in law firms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1809</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1809</id><created>2010-03-09</created><authors><author><keyname>Gerami</keyname><forenames>Mohsen</forenames></author></authors><title>Wireless IP Telephony</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The convergence of traditional telecommunications and the Internet is
creating new network-based service delivery opportunities for
telecommunications companies carriers, service providers, and network equipment
providers. Voice over Wireless IP is one of the most exciting new developments
emerging within the telephony market. It is set to revolutionize the delivery
of mobile voice Services and provide exciting new opportunities for operators
and service providers alike. This survey discusses principal of Wireless IP
Telephony.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1810</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1810</id><created>2010-03-09</created><authors><author><keyname>Naji</keyname><forenames>Hamid Reza</forenames></author></authors><title>Reconfigurable Parallel Data Flow Architecture</title><categories>cs.MA</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents a reconfigurable parallel data flow architecture. This
architecture uses the concepts of multi-agent paradigm in reconfigurable
hardware systems. The utilization of this new paradigm has the potential to
greatly increase the flexibility, efficiency, expandability of data flow
systems and to provide an attractive alternative to the current set of disjoint
approaches that are currently applied to this problem domain. The ability of
methodology to implement data flow type processing with different models is
presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1811</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1811</id><created>2010-03-09</created><authors><author><keyname>Elmougy</keyname><forenames>Samir</forenames></author><author><keyname>El-Henawy</keyname><forenames>Ibrahim</forenames></author><author><keyname>El-Azab</keyname><forenames>Ahmed</forenames></author></authors><title>Model Based Ceramic tile inspection using Discrete Wavelet Transform and
  Euclidean Distance</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Visual inspection of industrial products is used to determine the control
quality for these products. This paper deals with the problem of visual
inspection of ceramic tiles industry using Wavelet Transform. The third level
the coefficients of two dimensions Haar Discrete Wavelet Transform (HDWT) is
used in this paper to process the images and feature extraction. The proposed
algorithm consists of two main phases. The first phase is to compute the
wavelet transform for an image free of defects which known as reference image,
and the image to be inspected which known as test image. The second phase is
used to decide whether the tested image is defected or not using the Euclidean
distance similarity measure. The experimentation results of the proposed
algorithm give 97% for correct detection of ceramic defects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1814</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1814</id><created>2010-03-09</created><authors><author><keyname>Ranjan</keyname><forenames>Alok</forenames></author><author><keyname>Verma</keyname><forenames>Harish</forenames></author><author><keyname>Kandpal</keyname><forenames>Eatesh</forenames></author><author><keyname>Dhar</keyname><forenames>Joydip</forenames></author></authors><title>An Analytical Approach to Document Clustering Based on Internal
  Criterion Function</title><categories>cs.IR</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Fast and high quality document clustering is an important task in organizing
information, search engine results obtaining from user query, enhancing web
crawling and information retrieval. With the large amount of data available and
with a goal of creating good quality clusters, a variety of algorithms have
been developed having quality-complexity trade-offs. Among these, some
algorithms seek to minimize the computational complexity using certain
criterion functions which are defined for the whole set of clustering solution.
In this paper, we are proposing a novel document clustering algorithm based on
an internal criterion function. Most commonly used partitioning clustering
algorithms (e.g. k-means) have some drawbacks as they suffer from local optimum
solutions and creation of empty clusters as a clustering solution. The proposed
algorithm usually does not suffer from these problems and converge to a global
optimum, its performance enhances with the increase in number of clusters. We
have checked our algorithm against three different datasets for four different
values of k (required number of clusters).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1816</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1816</id><created>2010-03-09</created><authors><author><keyname>Pattanaik</keyname><forenames>Sabyasachi</forenames></author><author><keyname>Ghosh</keyname><forenames>Partha Pratim</forenames></author></authors><title>Role of Data Mining in E-Payment systems</title><categories>cs.DB</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Data Mining deals extracting hidden knowledge, unexpected pattern and new
rules from large database. Various customized data mining tools have been
developed for domain specific applications such as Biomedicine, DNA analysis
and telecommunication. Trends in data mining include further efforts towards
the exploration of new application areas and methods for handling complex data
types, algorithm scalability, constraint based data mining and visualization
methods. In this paper we will present domain specific Secure Multiparty
computation technique and applications. Data mining has matured as a field of
basic and applied research in computer science in general. In this paper, we
survey some of the recent approaches and architectures where data mining has
been applied in the fields of e-payment systems. In this paper we limit our
discussion to data mining in the context of e-payment systems. We also mention
a few directions for further work in this domain, based on the survey.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1819</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1819</id><created>2010-03-09</created><authors><author><keyname>Kapoor</keyname><forenames>Supriya</forenames></author><author><keyname>Khanna</keyname><forenames>Shruti</forenames></author><author><keyname>Bhatia</keyname><forenames>Rahul</forenames></author></authors><title>Facial Gesture Recognition Using Correlation And Mahalanobis Distance</title><categories>cs.CV</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Augmenting human computer interaction with automated analysis and synthesis
of facial expressions is a goal towards which much research effort has been
devoted recently. Facial gesture recognition is one of the important component
of natural human-machine interfaces; it may also be used in behavioural
science, security systems and in clinical practice. Although humans recognise
facial expressions virtually without effort or delay, reliable expression
recognition by machine is still a challenge. The face expression recognition
problem is challenging because different individuals display the same
expression differently. This paper presents an overview of gesture recognition
in real time using the concepts of correlation and Mahalanobis distance.We
consider the six universal emotional categories namely joy, anger, fear,
disgust, sadness and surprise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1821</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1821</id><created>2010-03-09</created><authors><author><keyname>Shrivastava</keyname><forenames>Virendra Kumar</forenames></author><author><keyname>Kumar</keyname><forenames>Parveen</forenames></author><author><keyname>Pardasani</keyname><forenames>K. R.</forenames></author></authors><title>FP-tree and COFI Based Approach for Mining of Multiple Level Association
  Rules in Large Databases</title><categories>cs.OH</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent years, discovery of association rules among itemsets in a large
database has been described as an important database-mining problem. The
problem of discovering association rules has received considerable research
attention and several algorithms for mining frequent itemsets have been
developed. Many algorithms have been proposed to discover rules at single
concept level. However, mining association rules at multiple concept levels may
lead to the discovery of more specific and concrete knowledge from data. The
discovery of multiple level association rules is very much useful in many
applications. In most of the studies for multiple level association rule
mining, the database is scanned repeatedly which affects the efficiency of
mining process. In this research paper, a new method for discovering multilevel
association rules is proposed. It is based on FP-tree structure and uses
cooccurrence frequent item tree to find frequent items in multilevel concept
hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1826</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1826</id><created>2010-03-09</created><authors><author><keyname>Ali</keyname><forenames>Syed Amjad</forenames></author><author><keyname>Vathsal</keyname><forenames>Srinivasan</forenames></author><author><keyname>kishore</keyname><forenames>K. Lal</forenames></author></authors><title>A GA based Window Selection Methodology to Enhance Window based Multi
  wavelet transformation and thresholding aided CT image denoising technique</title><categories>cs.CV</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Image denoising is getting more significance, especially in Computed
Tomography (CT), which is an important and most common modality in medical
imaging. This is mainly due to that the effectiveness of clinical diagnosis
using CT image lies on the image quality. The denoising technique for CT images
using window-based Multi-wavelet transformation and thresholding shows the
effectiveness in denoising, however, a drawback exists in selecting the closer
windows in the process of window-based multi-wavelet transformation and
thresholding. Generally, the windows of the duplicate noisy image that are
closer to each window of original noisy image are obtained by the checking them
sequentially. This leads to the possibility of missing out very closer windows
and so enhancement is required in the aforesaid process of the denoising
technique. In this paper, we propose a GA-based window selection methodology to
include the denoising technique. With the aid of the GA-based window selection
methodology, the windows of the duplicate noisy image that are very closer to
every window of the original noisy image are extracted in an effective manner.
By incorporating the proposed GA-based window selection methodology, the
denoising the CT image is performed effectively. Eventually, a comparison is
made between the denoising technique with and without the proposed GA-based
window selection methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1827</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1827</id><created>2010-03-09</created><authors><author><keyname>Rawat</keyname><forenames>Vidhi</forenames></author><author><keyname>jain</keyname><forenames>Alok</forenames></author><author><keyname>shrimali</keyname><forenames>Vibhakar</forenames></author></authors><title>Investigation and Assessment of Disorder of Ultrasound B-mode Images</title><categories>cs.CV</categories><comments>Pages IEEE format, International Journal of Computer Science and
  Information Security, IJCSIS, Vol. 7 No. 2, February 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Digital image plays a vital role in the early detection of cancers, such as
prostate cancer, breast cancer, lungs cancer, cervical cancer. Ultrasound
imaging method is also suitable for early detection of the abnormality of
fetus. The accurate detection of region of interest in ultrasound image is
crucial. Since the result of reflection, refraction and deflection of
ultrasound waves from different types of tissues with different acoustic
impedance. Usually, the contrast in ultrasound image is very low and weak edges
make the image difficult to identify the fetus region in the ultrasound image.
So the analysis of ultrasound image is more challenging one. We try to develop
a new algorithmic approach to solve the problem of non clarity and find
disorder of it. Generally there is no common enhancement approach for noise
reduction. This paper proposes different filtering techniques based on
statistical methods for the removal of various noise. The quality of the
enhanced images is measured by the statistical quantity measures:
Signal-to-Noise Ratio (SNR), Peak Signal-to-Noise Ratio (PSNR), and Root Mean
Square Error (RMSE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1833</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1833</id><created>2010-03-09</created><authors><author><keyname>Zhang</keyname><forenames>Da</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Yang</keyname><forenames>Zhuo</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Zhao</keyname><forenames>Wenhong</forenames></author></authors><title>Localization Technologies for Indoor Human Tracking</title><categories>cs.NI cs.DC</categories><comments>To appear in The 5th International Conference on Future Information
  Technology (FutureTech), May 2010, Busan, Korea.</comments><msc-class>68M10</msc-class><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The proliferation of wireless localization technologies provides a promising
future for serving human beings in indoor scenarios. Their applications include
real-time tracking, activity recognition, health care, navigation, emergence
detection, and target-of-interest monitoring, among others. Additionally,
indoor localization technologies address the inefficiency of GPS (Global
Positioning System) inside buildings. Since people spend most of their time in
indoor environments, indoor tracking service is in great public demand. Based
on this observation, this paper aims to provide a better understanding of
state-of-the-art technologies and stimulate new research efforts in this field.
For these purposes, existing localization technologies that can be used for
tracking individuals in indoor environments are reviewed, along with some
further discussions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1888</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1888</id><created>2010-03-09</created><authors><author><keyname>Yang</keyname><forenames>Xin-She</forenames></author></authors><title>Biology-Derived Algorithms in Engineering Optimization</title><categories>math.OC cs.CE cs.NE q-bio.QM</categories><msc-class>Comptuational science</msc-class><journal-ref>Yang X.-S., Biology-derived algorithms in engineering optimization
  (chapter 32), in: Handbook of Bioinspired Algorithms and Applications (Eds.
  S. Olarius and A. Y. Zomaya), Chapman &amp; Hall/CRC Press, pp. 589-600 (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biology-derived algorithms are an important part of computational sciences,
which are essential to many scientific disciplines and engineering
applications. Many computational methods are derived from or based on the
analogy to natural evolution and biological activities, and these biologically
inspired computations include genetic algorithms, neural networks, cellular
automata, and other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1891</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1891</id><created>2010-03-09</created><authors><author><keyname>Das</keyname><forenames>Nibaran</forenames></author><author><keyname>Mollah</keyname><forenames>Ayatullah Faruk</forenames></author><author><keyname>Saha</keyname><forenames>Sudip</forenames></author><author><keyname>Haque</keyname><forenames>Syed Sahidul</forenames></author></authors><title>Handwritten Arabic Numeral Recognition using a Multi Layer Perceptron</title><categories>cs.CV</categories><comments>Proc. National Conference on Recent Trends in Information Systems
  (ReTIS-06), July 14-15, 2006, Kolkata, India, pp 200-203</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handwritten numeral recognition is in general a benchmark problem of Pattern
Recognition and Artificial Intelligence. Compared to the problem of printed
numeral recognition, the problem of handwritten numeral recognition is
compounded due to variations in shapes and sizes of handwritten characters.
Considering all these, the problem of handwritten numeral recognition is
addressed under the present work in respect to handwritten Arabic numerals.
Arabic is spoken throughout the Arab World and the fifth most popular language
in the world slightly before Portuguese and Bengali. For the present work, we
have developed a feature set of 88 features is designed to represent samples of
handwritten Arabic numerals for this work. It includes 72 shadow and 16 octant
features. A Multi Layer Perceptron (MLP) based classifier is used here for
recognition handwritten Arabic digits represented with the said feature set. On
experimentation with a database of 3000 samples, the technique yields an
average recognition rate of 94.93% evaluated after three-fold cross validation
of results. It is useful for applications related to OCR of handwritten Arabic
Digit and can also be extended to include OCR of handwritten characters of
Arabic alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1894</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1894</id><created>2010-03-09</created><authors><author><keyname>Das</keyname><forenames>Nibaran</forenames></author><author><keyname>Mollah</keyname><forenames>Ayatullah Faruk</forenames></author><author><keyname>Sarkar</keyname><forenames>Ram</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author></authors><title>A comparative study of different feature sets for recognition of
  handwritten Arabic numerals using a Multi Layer Perceptron</title><categories>cs.CV</categories><comments>Proc. National Conference on Recent Trends in Intelligent Computing
  (ReTIC-06), Nov 17-19, 2006, Kalyani, India, pp. 86-92</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work presents a comparative assessment of seven different feature sets
for recognition of handwritten Arabic numerals using a Multi Layer Perceptron
(MLP) based classifier. The seven feature sets employed here consist of shadow
features, octant centroids, longest runs, angular distances, effective spans,
dynamic centers of gravity, and some of their combinations. On experimentation
with a database of 3000 samples, the maximum recognition rate of 95.80% is
observed with both of two separate combinations of features. One of these
combinations consists of shadow and centriod features, i. e. 88 features in
all, and the other shadow, centroid and longest run features, i. e. 124
features in all. Out of these two, the former combination having a smaller
number of features is finally considered effective for applications related to
Optical Character Recognition (OCR) of handwritten Arabic numerals. The work
can also be extended to include OCR of handwritten characters of Arabic
alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1910</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1910</id><created>2010-03-09</created><authors><author><keyname>Peppas</keyname><forenames>K. P.</forenames></author><author><keyname>Mansour</keyname><forenames>A.</forenames></author><author><keyname>Tombras</keyname><forenames>G. S.</forenames></author></authors><title>Dual-hop transmissions with fixed-gain relays over Generalized-Gamma
  fading channels</title><categories>cs.OH</categories><comments>Journal of Telecommunications,Volume 1, Issue 1, pp87-93, February
  2010</comments><journal-ref>K. P. Peppas, A. Mansour and G. S. Tombras, &quot;Dual-hop
  transmissions with fixed-gain relays over Generalized-Gamma fading channels
  &quot;, Journal of Telecommunications, Volume 1, Issue 1, pp87-93, February 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a study on the end-to-end performance of dual-hop wireless
communication systems equipped with fixed-gain relays and operating over
Generalized-Gamma (GG) fading channels is presented. A novel closed form
expression for the moments of the end-to-end signal-to-noise ratio (SNR) is
derived. The average bit error probability for coherent and non-coherent
modulation schemes as well as the end-to-end outage probability of the
considered system are also studied. Extensive numerically evaluated and
computer simulations results are presented that verify the accuracy of the
proposed mathematical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1930</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1930</id><created>2010-03-09</created><authors><author><keyname>Ningtyas</keyname><forenames>D. K.</forenames></author><author><keyname>Mutiara</keyname><forenames>A. B.</forenames></author></authors><title>Simulating Grover's Quantum Search in a Classical Computer</title><categories>cs.OH</categories><comments>24 pages, no figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The rapid progress of computer science has been accompanied by a
corresponding evolution of computation, from classical computation to quantum
computation. As quantum computing is on its way to becoming an established
discipline of computing science, much effort is being put into the development
of new quantum algorithms. One of quantum algorithms is Grover algorithm, which
is used for searching an element in an unstructured list of N elements with
quadratic speed-up over classical algorithms. In this work, Quantum Computer
Language (QCL) is used to make a Grover's quantum search simulation in a
classical computer
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1931</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1931</id><created>2010-03-09</created><authors><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Liu</keyname><forenames>Chuang</forenames></author></authors><title>Hypergraph model of social tagging networks</title><categories>physics.soc-ph cs.IR</categories><comments>7 pages,7 figures, 32 references</comments><journal-ref>J. Stat. Mech. (2010) P100005</journal-ref><doi>10.1088/1742-5468/2010/10/P10005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past few years have witnessed the great success of a new family of
paradigms, so-called folksonomy, which allows users to freely associate tags to
resources and efficiently manage them. In order to uncover the underlying
structures and user behaviors in folksonomy, in this paper, we propose an
evolutionary hypergrah model to explain the emerging statistical properties.
The present model introduces a novel mechanism that one can not only assign
tags to resources, but also retrieve resources via collaborative tags. We then
compare the model with a real-world dataset: \emph{Del.icio.us}. Indeed, the
present model shows considerable agreement with the empirical data in following
aspects: power-law hyperdegree distributions, negtive correlation between
clustering coefficients and hyperdegrees, and small average distances.
Furthermore, the model indicates that most tagging behaviors are motivated by
labeling tags to resources, and tags play a significant role in effectively
retrieving interesting resources and making acquaintance with congenial
friends. The proposed model may shed some light on the in-depth understanding
of the structure and function of folksonomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1940</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1940</id><created>2010-03-09</created><authors><author><keyname>Kundeti</keyname><forenames>Vamsi</forenames></author><author><keyname>Rajasekaran</keyname><forenames>Sanguthevar</forenames></author><author><keyname>Dinh</keyname><forenames>Hieu</forenames></author></authors><title>Efficient Parallel and Out of Core Algorithms for Constructing Large
  Bi-directed de Bruijn Graphs</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assembling genomic sequences from a set of overlapping reads is one of the
most fundamental problems in computational biology. Algorithms addressing the
assembly problem fall into two broad categories -- based on the data structures
which they employ. The first class uses an overlap/string graph and the second
type uses a de Bruijn graph. However with the recent advances in short read
sequencing technology, de Bruijn graph based algorithms seem to play a vital
role in practice.
  Efficient algorithms for building these massive de Bruijn graphs are very
essential in large sequencing projects based on short reads. In Jackson et. al.
ICPP-2008, an $O(n/p)$ time parallel algorithm has been given for this problem.
Here $n$ is the size of the input and $p$ is the number of processors. This
algorithm enumerates all possible bi-directed edges which can overlap with a
node and ends up generating $\Theta(n\Sigma)$ messages.
  In this paper we present a $\Theta(n/p)$ time parallel algorithm with a
communication complexity equal to that of parallel sorting and is not sensitive
to $\Sigma$. The generality of our algorithm makes it very easy to extend it
even to the out-of-core model and in this case it has an optimal I/O complexity
of $\Theta(\frac{n\log(n/B)}{B\log(M/B)})$. We demonstrate the scalability of
our parallel algorithm on a SGI/Altix computer. A comparison of our algorithm
with that of Jackson et. al. ICPP-2008 reveals that our algorithm is faster. We
also provide efficient algorithms for the bi-directed chain compaction problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1954</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1954</id><created>2010-03-09</created><updated>2010-10-25</updated><authors><author><keyname>P&#xe1;l</keyname><forenames>D&#xe1;vid</forenames></author><author><keyname>P&#xf3;czos</keyname><forenames>Barnab&#xe1;s</forenames></author><author><keyname>Szepesv&#xe1;ri</keyname><forenames>Csaba</forenames></author></authors><title>Estimation of R\'enyi Entropy and Mutual Information Based on
  Generalized Nearest-Neighbor Graphs</title><categories>stat.ML cs.AI</categories><comments>to appear at NIPS 2010 (Neural Information Processing Systems)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present simple and computationally efficient nonparametric estimators of
R\'enyi entropy and mutual information based on an i.i.d. sample drawn from an
unknown, absolutely continuous distribution over $\R^d$. The estimators are
calculated as the sum of $p$-th powers of the Euclidean lengths of the edges of
the `generalized nearest-neighbor' graph of the sample and the empirical copula
of the sample respectively. For the first time, we prove the almost sure
consistency of these estimators and upper bounds on their rates of convergence,
the latter of which under the assumption that the density underlying the sample
is Lipschitz continuous. Experiments demonstrate their usefulness in
independent subspace analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1967</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1967</id><created>2010-03-09</created><authors><author><keyname>Borgne</keyname><forenames>Yann-A&#xeb;l Le</forenames></author><author><keyname>Raybaud</keyname><forenames>Sylvain</forenames></author><author><keyname>Bontempi</keyname><forenames>Gianluca</forenames></author></authors><title>Distributed Principal Component Analysis for Wireless Sensor Networks</title><categories>cs.NI</categories><journal-ref>Sensors 2008, 8(8), 4821-4850</journal-ref><doi>10.3390/s8084821</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Principal Component Analysis (PCA) is a data dimensionality reduction
technique well-suited for processing data from sensor networks. It can be
applied to tasks like compression, event detection, and event recognition. This
technique is based on a linear transform where the sensor measurements are
projected on a set of principal components. When sensor measurements are
correlated, a small set of principal components can explain most of the
measurements variability. This allows to significantly decrease the amount of
radio communication and of energy consumption. In this paper, we show that the
power iteration method can be distributed in a sensor network in order to
compute an approximation of the principal components. The proposed
implementation relies on an aggregation service, which has recently been shown
to provide a suitable framework for distributing the computation of a linear
transform within a sensor network. We also extend this previous work by
providing a detailed analysis of the computational, memory, and communication
costs involved. A compression experiment involving real data validates the
algorithm and illustrates the tradeoffs between accuracy and communication
costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.1991</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.1991</id><created>2010-03-09</created><updated>2010-11-05</updated><authors><author><keyname>Jiang</keyname><forenames>Minghui</forenames></author></authors><title>The zero exemplar distance problem</title><categories>cs.CC math.CO</categories><comments>Strengthened and reorganized</comments><doi>10.1007/978-3-642-16181-0_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two genomes with duplicate genes, \textsc{Zero Exemplar Distance} is
the problem of deciding whether the two genomes can be reduced to the same
genome without duplicate genes by deleting all but one copy of each gene in
each genome. Blin, Fertin, Sikora, and Vialette recently proved that
\textsc{Zero Exemplar Distance} for monochromosomal genomes is NP-hard even if
each gene appears at most two times in each genome, thereby settling an
important open question on genome rearrangement in the exemplar model. In this
paper, we give a very simple alternative proof of this result. We also study
the problem \textsc{Zero Exemplar Distance} for multichromosomal genomes
without gene order, and prove the analogous result that it is also NP-hard even
if each gene appears at most two times in each genome. For the positive
direction, we show that both variants of \textsc{Zero Exemplar Distance} admit
polynomial-time algorithms if each gene appears exactly once in one genome and
at least once in the other genome. In addition, we present a polynomial-time
algorithm for the related problem \textsc{Exemplar Longest Common Subsequence}
in the special case that each mandatory symbol appears exactly once in one
input sequence and at least once in the other input sequence. This answers an
open question of Bonizzoni et al. We also show that \textsc{Zero Exemplar
Distance} for multichromosomal genomes without gene order is fixed-parameter
tractable if the parameter is the maximum number of chromosomes in each genome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2005</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2005</id><created>2010-03-09</created><updated>2011-09-09</updated><authors><author><keyname>Lee</keyname><forenames>Taeyoung</forenames></author><author><keyname>Leok</keyname><forenames>Melvin</forenames></author><author><keyname>McClamroch</keyname><forenames>N. Harris</forenames></author></authors><title>Control of Complex Maneuvers for a Quadrotor UAV using Geometric Methods
  on SE(3)</title><categories>math.OC cs.SY</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides new results for control of complex flight maneuvers for a
quadrotor unmanned aerial vehicle (UAV). The flight maneuvers are defined by a
concatenation of flight modes or primitives, each of which is achieved by a
nonlinear controller that solves an output tracking problem. A mathematical
model of the quadrotor UAV rigid body dynamics, defined on the configuration
space $\SE$, is introduced as a basis for the analysis. The quadrotor UAV has
four input degrees of freedom, namely the magnitudes of the four rotor thrusts;
each flight mode is defined by solving an asymptotic optimal tracking problem.
Although many flight modes can be studied, we focus on three output tracking
problems, namely (1) outputs given by the vehicle attitude, (2) outputs given
by the three position variables for the vehicle center of mass, and (3) output
given by the three velocity variables for the vehicle center of mass. A
nonlinear tracking controller is developed on the special Euclidean group $\SE$
for each flight mode, and the closed loop is shown to have desirable closed
loop properties that are almost global in each case. Several numerical
examples, including one example in which the quadrotor recovers from being
initially upside down and another example that includes switching and
transitions between different flight modes, illustrate the versatility and
generality of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2022</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2022</id><created>2010-03-10</created><updated>2011-09-13</updated><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author><author><keyname>Munoz-Barrutia</keyname><forenames>Arrate</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Fast space-variant elliptical filtering using box splines</title><categories>cs.CV cs.CE cs.IT cs.NA math.IT</categories><comments>12 figures; IEEE Transactions on Image Processing, vol. 19, 2010</comments><journal-ref>IEEE Transactions on Image Processing, vol. 19(9), pp. 2290 -
  2306, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficient realization of linear space-variant (non-convolution) filters
is a challenging computational problem in image processing. In this paper, we
demonstrate that it is possible to filter an image with a Gaussian-like
elliptic window of varying size, elongation and orientation using a fixed
number of computations per pixel. The associated algorithm, which is based on a
family of smooth compactly supported piecewise polynomials, the
radially-uniform box splines, is realized using pre-integration and local
finite-differences. The radially-uniform box splines are constructed through
the repeated convolution of a fixed number of box distributions, which have
been suitably scaled and distributed radially in an uniform fashion. The
attractive features of these box splines are their asymptotic behavior, their
simple covariance structure, and their quasi-separability. They converge to
Gaussians with the increase of their order, and are used to approximate
anisotropic Gaussians of varying covariance simply by controlling the scales of
the constituent box distributions. Based on the second feature, we develop a
technique for continuously controlling the size, elongation and orientation of
these Gaussian-like functions. Finally, the quasi-separable structure, along
with a certain scaling property of box distributions, is used to efficiently
realize the associated space-variant elliptical filtering, which requires O(1)
computations per pixel irrespective of the shape and size of the filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2084</identifier>
 <datestamp>2011-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2084</id><created>2010-03-10</created><updated>2011-06-07</updated><authors><author><keyname>Bakhshi</keyname><forenames>Rena</forenames></author><author><keyname>Endrullis</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author><author><keyname>Pang</keyname><forenames>Jun</forenames></author></authors><title>Asynchronous Bounded Expected Delay Networks</title><categories>cs.DC cs.DS cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The commonly used asynchronous bounded delay (ABD) network models assume a
fixed bound on message delay. We propose a probabilistic network model, called
asynchronous bounded expected delay (ABE) model. Instead of a strict bound, the
ABE model requires only a bound on the expected message delay. While the
conditions of ABD networks restrict the set of possible executions, in ABE
networks all asynchronous executions are possible, but executions with
extremely long delays are less probable. In contrast to ABD networks, ABE
networks cannot be synchronised efficiently. At the example of an election
algorithm, we show that the minimal assumptions of ABE networks are sufficient
for the development of efficient algorithms. For anonymous, unidirectional ABE
rings of known size N we devise a probabilistic leader election algorithm
having average message and time complexity O(N).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2113</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2113</id><created>2010-03-10</created><authors><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Thed N.</forenames></author><author><keyname>Visser</keyname><forenames>Martijn S.</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author></authors><title>Rivals for the crown: Reply to Opthof and Leydesdorff</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reply to the criticism of Opthof and Leydesdorff [arXiv:1002.2769] on the
way in which our institute applies journal and field normalizations to citation
counts. We point out why we believe most of the criticism is unjustified, but
we also indicate where we think Opthof and Leydesdorff raise a valid point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2123</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2123</id><created>2010-03-10</created><authors><author><keyname>van Son</keyname><forenames>R. J. J. H.</forenames></author></authors><title>Quantifying Shannon's Work Function for Cryptanalytic Attacks</title><categories>cs.CR</categories><comments>19 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Attacks on cryptographic systems are limited by the available computational
resources. A theoretical understanding of these resource limitations is needed
to evaluate the security of cryptographic primitives and procedures. This study
uses an Attacker versus Environment game formalism based on computability logic
to quantify Shannon's work function and evaluate resource use in cryptanalysis.
A simple cost function is defined which allows to quantify a wide range of
theoretical and real computational resources. With this approach the use of
custom hardware, e.g., FPGA boards, in cryptanalysis can be analyzed. Applied
to real cryptanalytic problems, it raises, for instance, the expectation that
the computer time needed to break some simple 90 bit strong cryptographic
primitives might theoretically be less than two years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2138</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2138</id><created>2010-03-10</created><authors><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author></authors><title>Need-based Communication for Smart Grid: When to Inquire Power Price?</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE 2010'Globecom</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In smart grid, a home appliance can adjust its power consumption level
according to the realtime power price obtained from communication channels.
Most studies on smart grid do not consider the cost of communications which
cannot be ignored in many situations. Therefore, the total cost in smart grid
should be jointly optimized with the communication cost. In this paper, a
probabilistic mechanism of locational margin price (LMP) is applied and a model
for the stochastic evolution of the underlying load which determines the power
price is proposed. Based on this framework of power price, the problem of
determining when to inquire the power price is formulated as a Markov decision
process and the corresponding elements, namely the action space, system state
and reward function, are defined. Dynamic programming is then applied to obtain
the optimal strategy. A simpler myopic approach is proposed by comparing the
cost of communications and the penalty incurred by using the old value of power
price. Numerical results show the significant performance gain of the optimal
strategy of price inquiry, as well as the near-optimality of the myopic
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2142</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2142</id><created>2010-03-10</created><authors><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Zhang</keyname><forenames>Weiyi</forenames></author></authors><title>QoS Routing in Smart Grid</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE 2010'Globecom</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart grid is an emerging technology which is able to control the power load
via price signaling. The communication between the power supplier and power
customers is a key issue in smart grid. Performance degradation like delay or
outage may cause significant impact on the stability of the pricing based
control and thus the reward of smart grid. Therefore, a QoS mechanism is
proposed for the communication system in smart grid, which incorporates the
derivation of QoS requirement and applies QoS routing in the communication
network. For deriving the QoS requirement, the dynamics of power load and the
load-price mapping are studied. The corresponding impacts of different QoS
metrics like delay are analyzed. Then, the QoS is derived via an optimization
problem that maximizes the total revenue. Based on the derived QoS requirement,
a simple greedy QoS routing algorithm is proposed for the requirement of high
speed routing in smart grid. It is also proven that the proposed greedy
algorithm is a $K$-approximation. Numerical simulation shows that the proposed
mechanism and algorithm can effectively derive and secure the communication QoS
in smart grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2165</identifier>
 <datestamp>2012-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2165</id><created>2010-03-10</created><updated>2012-02-17</updated><authors><author><keyname>Loebenberger</keyname><forenames>Daniel</forenames></author><author><keyname>N&#xfc;sken</keyname><forenames>Michael</forenames></author></authors><title>Coarse-grained integers - Smooth? Rough? Both!</title><categories>math.NT cs.CR</categories><msc-class>11Axx, 11N05, 11N25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We count ]B, C]-grained, k-factor integers which are simultaneously B-rough
and C-smooth and have a fixed number k of prime factors. Our aim is to exploit
explicit versions of the prime number theorem as much as possible to get good
explicit bounds for the count of such integers. This analysis was inspired by
certain inner procedures in the general number field sieve. The result should
at least provide some insight in what happens there.
  We estimate the given count in terms of some recursively defined functions.
Since they are still difficult to handle, only another approximation step
reveals their orders.
  Finally, we use the obtained bounds to perform numerical experiments that
show how good the desired count can be approximated for the parameters of the
general number field sieve in the mentioned inspiring application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2167</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2167</id><created>2010-03-10</created><updated>2010-08-16</updated><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Thed N.</forenames></author><author><keyname>Visser</keyname><forenames>Martijn S.</forenames></author><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author></authors><title>Towards a new crown indicator: Some theoretical considerations</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The crown indicator is a well-known bibliometric indicator of research
performance developed by our institute. The indicator aims to normalize
citation counts for differences among fields. We critically examine the
theoretical basis of the normalization mechanism applied in the crown
indicator. We also make a comparison with an alternative normalization
mechanism. The alternative mechanism turns out to have more satisfactory
properties than the mechanism applied in the crown indicator. In particular,
the alternative mechanism has a so-called consistency property. The mechanism
applied in the crown indicator lacks this important property. As a consequence
of our findings, we are currently moving towards a new crown indicator, which
relies on the alternative normalization mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2198</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2198</id><created>2010-03-10</created><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author></authors><title>The relation between Eigenfactor, audience factor, and influence weight</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theoretical and empirical analysis of a number of bibliometric
indicators of journal performance. We focus on three indicators in particular,
namely the Eigenfactor indicator, the audience factor, and the influence weight
indicator. Our main finding is that the last two indicators can be regarded as
a kind of special cases of the first indicator. We also find that the three
indicators can be nicely characterized in terms of two properties. We refer to
these properties as the property of insensitivity to field differences and the
property of insensitivity to insignificant journals. The empirical results that
we present illustrate our theoretical findings. We also show empirically that
the differences between various indicators of journal performance are quite
substantial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2218</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2218</id><created>2010-03-10</created><authors><author><keyname>Chernov</keyname><forenames>Alexey</forenames></author><author><keyname>Kalnishkan</keyname><forenames>Yuri</forenames></author><author><keyname>Zhdanov</keyname><forenames>Fedor</forenames></author><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Supermartingales in Prediction with Expert Advice</title><categories>cs.LG</categories><comments>37 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply the method of defensive forecasting, based on the use of
game-theoretic supermartingales, to prediction with expert advice. In the
traditional setting of a countable number of experts and a finite number of
outcomes, the Defensive Forecasting Algorithm is very close to the well-known
Aggregating Algorithm. Not only the performance guarantees but also the
predictions are the same for these two methods of fundamentally different
nature. We discuss also a new setting where the experts can give advice
conditional on the learner's future decision. Both the algorithms can be
adapted to the new setting and give the same performance guarantees as in the
traditional setting. Finally, we outline an application of defensive
forecasting to a setting with several loss functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2226</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2226</id><created>2010-03-10</created><updated>2010-04-30</updated><authors><author><keyname>Ghozlan</keyname><forenames>Hassan</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Interference Focusing for Mitigating Cross-Phase Modulation in a
  Simplified Optical Fiber Model</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in ISIT'10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A memoryless interference network model is introduced that is based on
non-linear phenomena observed when transmitting information over optical fiber
using wavelength division multiplexing. The main characteristic of the model is
that amplitude variations on one carrier wave are converted to phase variations
on another carrier wave, i.e., the carriers interfere with each other through
amplitude-to-phase conversion. For the case of two carriers, a new technique
called interference focusing is proposed where each carrier achieves the
capacity pre-log 1, thereby doubling the pre-log of 1/2 achieved by using
conventional methods. The technique requires neither channel time variations
nor global channel state information. Generalizations to more than two carriers
are outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2255</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2255</id><created>2010-03-11</created><authors><author><keyname>Fischer</keyname><forenames>Ulrich H. P.</forenames></author><author><keyname>Just</keyname><forenames>Jens-Uwe</forenames></author><author><keyname>Reinboth</keyname><forenames>Christian</forenames></author></authors><title>Automated selection of LEDs by luminance and chromaticity coordinate</title><categories>cs.OH</categories><comments>Published at the 2009 International Students and Young Scientists
  Workshop &quot;Photonics and Microsystems&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increased use of LEDs for lighting purposes has led to the development of
numerous applications requiring a pre-selection of LEDs by their luminance and
/ or their chromaticity coordinate. This paper demonstrates how a manual
pre-selection process can be realized using a relatively simple configuration.
Since a manual selection service can only be commercially viable as long as
only small quantities of LEDs need to be sorted, an automated solution suggests
itself. This paper introduces such a solution, which has been developed by
Harzoptics in close cooperation with Rundfunk Gernrode. The paper also
discusses current challenges in measurement technology as well as market
trends.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2257</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2257</id><created>2010-03-11</created><updated>2011-02-14</updated><authors><author><keyname>Khoshnevis</keyname><forenames>Behrouz</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Bit Allocation Law for Multi-Antenna Channel Feedback Quantization:
  Single-User Case</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing, March 2010</comments><doi>10.1109/TSP.2011.2113178</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the design and optimization of a limited feedback
single-user system with multiple-antenna transmitter and single-antenna
receiver. The design problem is cast in form of the minimizing the average
transmission power at the base station subject to the user's outage probability
constraint. The optimization is over the user's channel quantization codebook
and the transmission power control function at the base station. Our approach
is based on fixing the outage scenarios in advance and transforming the design
problem into a robust system design problem. We start by showing that uniformly
quantizing the channel magnitude in dB scale is asymptotically optimal,
regardless of the magnitude distribution function. We derive the optimal
uniform (in dB) channel magnitude codebook and combine it with a spatially
uniform channel direction codebook to arrive at a product channel quantization
codebook. We then optimize such a product structure in the asymptotic regime of
$B\rightarrow \infty$, where $B$ is the total number of quantization feedback
bits. The paper shows that for channels in the real space, the asymptotically
optimal number of direction quantization bits should be ${(M{-}1)}/{2}$ times
the number of magnitude quantization bits, where $M$ is the number of base
station antennas. We also show that the performance of the designed system
approaches the performance of the perfect channel state information system as
$2^{-\frac{2B}{M+1}}$. For complex channels, the number of magnitude and
direction quantization bits are related by a factor of $(M{-}1)$ and the system
performance scales as $2^{-\frac{B}{M}}$ as $B\rightarrow\infty$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2259</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2259</id><created>2010-03-11</created><updated>2011-12-27</updated><authors><author><keyname>Khoshnevis</keyname><forenames>Behrouz</forenames></author><author><keyname>Yu</keyname><forenames>Wei</forenames></author></authors><title>Bit Allocation Laws for Multi-Antenna Channel Feedback Quantization:
  Multi-User Case</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the optimal design of limited-feedback downlink
multi-user spatial multiplexing systems. A multiple-antenna base-station is
assumed to serve multiple single-antenna users, who quantize and feed back
their channel state information (CSI) through a shared rate-limited feedback
channel. The optimization problem is cast in the form of minimizing the average
transmission power at the base-station subject to users' target
signal-to-interference-plus-noise ratios (SINR) and outage probability
constraints. The goal is to derive the feedback bit allocations among the users
and the corresponding channel magnitude and direction quantization codebooks in
a high-resolution quantization regime. Toward this end, this paper develops an
optimization framework using approximate analytical closed-form solutions, the
accuracy of which is then verified by numerical results. The results show that,
for channels in the real space, the number of channel direction quantization
bits should be $(M-1)$ times the number of channel magnitude quantization bits,
where $M$ is the number of base-station antennas. Moreover, users with higher
requested quality-of-service (QoS), i.e. lower target outage probabilities, and
higher requested downlink rates, i.e. higher target SINR's, should use larger
shares of the feedback rate. It is also shown that, for the target QoS
parameters to be feasible, the total feedback bandwidth should scale
logarithmically with the geometric mean of the target SINR values and the
geometric mean of the inverse target outage probabilities. In particular, the
minimum required feedback rate is shown to increase if the users' target
parameters deviate from the corresponding geometric means. Finally, the paper
shows that, as the total number of feedback bits $B$ increases, the performance
of the limited-feedback system approaches the perfect-CSI system as
${2^{-{B}/{M^2}}}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2281</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2281</id><created>2010-03-11</created><authors><author><keyname>Schifanella</keyname><forenames>Rossano</forenames></author><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Markines</keyname><forenames>Benjamin</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Folks in Folksonomies: Social Link Prediction from Shared Metadata</title><categories>cs.CY physics.soc-ph</categories><comments>http://portal.acm.org/citation.cfm?doid=1718487.1718521</comments><journal-ref>Proceedings of the third ACM international conference on Web
  search and data mining WSDM2010, New York, Feb 4-6 2010, p. 271</journal-ref><doi>10.1145/1718487.1718521</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web 2.0 applications have attracted a considerable amount of attention
because their open-ended nature allows users to create light-weight semantic
scaffolding to organize and share content. To date, the interplay of the social
and semantic components of social media has been only partially explored. Here
we focus on Flickr and Last.fm, two social media systems in which we can relate
the tagging activity of the users with an explicit representation of their
social network. We show that a substantial level of local lexical and topical
alignment is observable among users who lie close to each other in the social
network. We introduce a null model that preserves user activity while removing
local correlations, allowing us to disentangle the actual local alignment
between users from statistical effects due to the assortative mixing of user
activity and centrality in the social network. This analysis suggests that
users with similar topical interests are more likely to be friends, and
therefore semantic similarity measures among users based solely on their
annotation metadata should be predictive of social links. We test this
hypothesis on the Last.fm data set, confirming that the social network
constructed from semantic similarity captures actual friendship more accurately
than Last.fm's suggestions based on listening patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2291</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2291</id><created>2010-03-11</created><authors><author><keyname>Ekstein</keyname><forenames>Jan</forenames></author><author><keyname>Fiala</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Holub</keyname><forenames>P&#x159;emysl</forenames></author><author><keyname>Lidick&#xfd;</keyname><forenames>Bernard</forenames></author></authors><title>The packing chromatic number of the square lattice is at least 12</title><categories>cs.DM</categories><comments>3 pages</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The packing chromatic number $\chi_\rho(G)$ of a graph $G$ is the smallest
integer $k$ such that the vertex set $V(G)$ can be partitioned into disjoint
classes $X_1, ..., X_k$, where vertices in $X_i$ have pairwise distance greater
than $i$. For the 2-dimensional square lattice $\mathbb{Z}^2$ it is proved that
$\chi_\rho(\mathbb{Z}^2) \geq 12$, which improves the previously known lower
bound 10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2372</identifier>
 <datestamp>2010-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2372</id><created>2010-03-11</created><authors><author><keyname>Li</keyname><forenames>Jiangyuan</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author></authors><title>On Ergodic Secrecy Capacity for Gaussian MISO Wiretap Channels</title><categories>cs.IT math.IT</categories><comments>27 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Gaussian multiple-input single-output (MISO) wiretap channel model is
considered, where there exists a transmitter equipped with multiple antennas, a
legitimate receiver and an eavesdropper each equipped with a single antenna. We
study the problem of finding the optimal input covariance that achieves ergodic
secrecy capacity subject to a power constraint where only statistical
information about the eavesdropper channel is available at the transmitter.
This is a non-convex optimization problem that is in general difficult to
solve. Existing results address the case in which the eavesdropper or/and
legitimate channels have independent and identically distributed Gaussian
entries with zero-mean and unit-variance, i.e., the channels have trivial
covariances. This paper addresses the general case where eavesdropper and
legitimate channels have nontrivial covariances. A set of equations describing
the optimal input covariance matrix are proposed along with an algorithm to
obtain the solution. Based on this framework, we show that when full
information on the legitimate channel is available to the transmitter, the
optimal input covariance has always rank one. We also show that when only
statistical information on the legitimate channel is available to the
transmitter, the legitimate channel has some general non-trivial covariance,
and the eavesdropper channel has trivial covariance, the optimal input
covariance has the same eigenvectors as the legitimate channel covariance.
Numerical results are presented to illustrate the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2424</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2424</id><created>2010-03-11</created><authors><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>Huttenlocher</keyname><forenames>Daniel</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author></authors><title>Signed Networks in Social Media</title><categories>physics.soc-ph cs.CY cs.HC</categories><acm-class>H.5.3</acm-class><journal-ref>CHI 2010: 28th ACM Conference on Human Factors in Computing
  Systems</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relations between users on social media sites often reflect a mixture of
positive (friendly) and negative (antagonistic) interactions. In contrast to
the bulk of research on social networks that has focused almost exclusively on
positive interpretations of links between people, we study how the interplay
between positive and negative relationships affects the structure of on-line
social networks. We connect our analyses to theories of signed networks from
social psychology. We find that the classical theory of structural balance
tends to capture certain common patterns of interaction, but that it is also at
odds with some of the fundamental phenomena we observe --- particularly related
to the evolving, directed nature of these on-line networks. We then develop an
alternate theory of status that better explains the observed edge signs and
provides insights into the underlying social mechanisms. Our work provides one
of the first large-scale evaluations of theories of signed networks using
on-line datasets, as well as providing a perspective for reasoning about social
media sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2429</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2429</id><created>2010-03-11</created><authors><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>Huttenlocher</keyname><forenames>Daniel</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author></authors><title>Predicting Positive and Negative Links in Online Social Networks</title><categories>physics.soc-ph cs.AI cs.CY</categories><acm-class>H.2.8</acm-class><journal-ref>WWW 2010: ACM WWW International conference on World Wide Web, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study online social networks in which relationships can be either positive
(indicating relations such as friendship) or negative (indicating relations
such as opposition or antagonism). Such a mix of positive and negative links
arise in a variety of online settings; we study datasets from Epinions,
Slashdot and Wikipedia. We find that the signs of links in the underlying
social networks can be predicted with high accuracy, using models that
generalize across this diverse range of sites. These models provide insight
into some of the fundamental principles that drive the formation of signed
links in networks, shedding light on theories of balance and status from social
psychology; they also suggest social computing applications by which the
attitude of one user toward another can be estimated from evidence provided by
their relationships with other members of the surrounding social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2440</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2440</id><created>2010-03-11</created><authors><author><keyname>Nguyen</keyname><forenames>Kien C.</forenames></author><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>Stochastic Games for Security in Networks with Interdependent Nodes</title><categories>cs.CR cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a stochastic game theoretic approach to security and
intrusion detection in communication and computer networks. Specifically, an
Attacker and a Defender take part in a two-player game over a network of nodes
whose security assets and vulnerabilities are correlated. Such a network can be
modeled using weighted directed graphs with the edges representing the
influence among the nodes. The game can be formulated as a non-cooperative
zero-sum or nonzero-sum stochastic game. However, due to correlation among the
nodes, if some nodes are compromised, the effective security assets and
vulnerabilities of the remaining ones will not stay the same in general, which
leads to complex system dynamics. We examine existence, uniqueness, and
structure of the solution and also provide numerical examples to illustrate our
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2441</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2441</id><created>2010-03-11</created><authors><author><keyname>Nguyen</keyname><forenames>Kien C.</forenames></author><author><keyname>Sarwate</keyname><forenames>Dilip V.</forenames></author></authors><title>Up-sampling and Natural Sample Value Computation for Digital Pulse Width
  Modulators</title><categories>cs.SD cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital pulse width modulation has been considered for high-fidelity and
high-efficiency audio amplifiers for several years. It has been shown that the
distortion can be reduced and the implementation of the system can be
simplified if the switching frequency is much higher than the Nyquist rate of
the modulating waveform. Hence, the input digital source is normally upsampled
to a higher frequency. It was also proved that converting uniform samples to
natural samples will decrease the harmonic distortion. Thus, in this paper, we
examine a new approach that combines upsampling, digital interpolation and
natural sampling conversion. This approach uses poly-phase implementation of
the digital interpolation filter and digital differentiators. We will show that
the structure consists of an FIR-type linear stage and a nonlinear stage. Some
spectral simulation results of a pulse width modulation system based on this
approach will also be presented. Finally, we will discuss the improvement of
the new approach over old algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2454</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2454</id><created>2010-03-11</created><updated>2010-03-24</updated><authors><author><keyname>Raina</keyname><forenames>Manik</forenames></author><author><keyname>Spasojevic</keyname><forenames>Predrag</forenames></author></authors><title>Decoding Complexity of Irregular LDGM-LDPC Codes Over the BISOM Channels</title><categories>cs.IT math.IT</categories><journal-ref>M. Raina, P. Spasojevic, &quot;Decoding Complexity of Irregular
  LDGM-LDPC Codes Over the BISOM Channels,'' IEEE Conference on Information
  Sciences and Systems, March 2010, Princeton, NJ.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An irregular LDGM-LDPC code is studied as a sub-code of an LDPC code with
some randomly \emph{punctured} output-bits. It is shown that the LDGM-LDPC
codes achieve rates arbitrarily close to the channel-capacity of the
binary-input symmetric-output memoryless (BISOM) channel with bounded
\emph{complexity}. The measure of complexity is the average-degree (per
information-bit) of the check-nodes for the factor-graph of the code. A
lower-bound on the average degree of the check-nodes of the irregular LDGM-LDPC
codes is obtained. The bound does not depend on the decoder used at the
receiver. The stability condition for decoding the irregular LDGM-LDPC codes
over the binary-erasure channel (BEC) under iterative-decoding with
message-passing is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2456</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2456</id><created>2010-03-11</created><authors><author><keyname>Seth</keyname><forenames>Rolly</forenames></author><author><keyname>Kapoor</keyname><forenames>Rishi</forenames></author><author><keyname>Al-Qaheri</keyname><forenames>Hameed</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Piecemeal Journey To 'HALCYON' World Of Pervasive Computing : From past
  progress to future challenges</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although 'Halcyon' means serene environment which pervasive computing aims
at, we have tried to present a different interpretation of this word. Through
our approach, we look at it in context of achieving future 'calm technology'.
The paper gives a general overview of the state of pervasive computing today,
proposes the 'HALCYON Model' and outlines the 'social' challenges faced by
system designers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2458</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2458</id><created>2010-03-11</created><authors><author><keyname>Gollapudi</keyname><forenames>Sreenivas</forenames></author><author><keyname>Panigrahy</keyname><forenames>Rina</forenames></author></authors><title>Revisiting the Examination Hypothesis with Query Specific Position Bias</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Click through rates (CTR) offer useful user feedback that can be used to
infer the relevance of search results for queries. However it is not very
meaningful to look at the raw click through rate of a search result because the
likelihood of a result being clicked depends not only on its relevance but also
the position in which it is displayed. One model of the browsing behavior, the
{\em Examination Hypothesis} \cite{RDR07,Craswell08,DP08}, states that each
position has a certain probability of being examined and is then clicked based
on the relevance of the search snippets. This is based on eye tracking studies
\cite{Claypool01, GJG04} which suggest that users are less likely to view
results in lower positions. Such a position dependent variation in the
probability of examining a document is referred to as {\em position bias}. Our
main observation in this study is that the position bias tends to differ with
the kind of information the user is looking for. This makes the position bias
{\em query specific}. In this study, we present a model for analyzing a query
specific position bias from the click data and use these biases to derive
position independent relevance values of search results. Our model is based on
the assumption that for a given query, the positional click through rate of a
document is proportional to the product of its relevance and a {\em query
specific} position bias. We compare our model with the vanilla examination
hypothesis model (EH) on a set of queries obtained from search logs of a
commercial search engine. We also compare it with the User Browsing Model (UBM)
\cite{DP08} which extends the cascade model of Craswell et al\cite{Craswell08}
by incorporating multiple clicks in a query session. We show that the our
model, although much simpler to implement, consistently outperforms both EH and
UBM on well-used measures such as relative error and cross entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2469</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2469</id><created>2010-03-11</created><authors><author><keyname>Romero</keyname><forenames>Daniel M.</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author></authors><title>The Directed Closure Process in Hybrid Social-Information Networks, with
  an Analysis of Link Formation on Twitter</title><categories>stat.ML cs.CY physics.soc-ph stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has often been taken as a working assumption that directed links in
information networks are frequently formed by &quot;short-cutting&quot; a two-step path
between the source and the destination -- a kind of implicit &quot;link copying&quot;
analogous to the process of triadic closure in social networks. Despite the
role of this assumption in theoretical models such as preferential attachment,
it has received very little direct empirical investigation. Here we develop a
formalization and methodology for studying this type of directed closure
process, and we provide evidence for its important role in the formation of
links on Twitter. We then analyze a sequence of models designed to capture the
structural phenomena related to directed closure that we observe in the Twitter
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2471</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2471</id><created>2010-03-11</created><authors><author><keyname>Fu</keyname><forenames>Fangwen</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Structure-Aware Stochastic Control for Transmission Scheduling</title><categories>cs.LG cs.IT cs.MM math.IT</categories><comments>41pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of real-time transmission scheduling
over time-varying channels. We first formulate the transmission scheduling
problem as a Markov decision process (MDP) and systematically unravel the
structural properties (e.g. concavity in the state-value function and
monotonicity in the optimal scheduling policy) exhibited by the optimal
solutions. We then propose an online learning algorithm which preserves these
structural properties and achieves -optimal solutions for an arbitrarily small
. The advantages of the proposed online method are that: (i) it does not
require a priori knowledge of the traffic arrival and channel statistics and
(ii) it adaptively approximates the state-value functions using piece-wise
linear functions and has low storage and computation complexity. We also extend
the proposed low-complexity online learning solution to the prioritized data
transmission. The simulation results demonstrate that the proposed method
achieves significantly better utility (or delay)-energy trade-offs when
comparing to existing state-of-art online optimization methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2547</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2547</id><created>2010-03-12</created><authors><author><keyname>Deniau</keyname><forenames>Laurent</forenames></author></authors><title>The C Object System: Using C as a High-Level Object-Oriented Language</title><categories>cs.PL</categories><comments>18p</comments><acm-class>D.3.3; D.1.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The C Object System (Cos) is a small C library which implements high-level
concepts available in Clos, Objc and other object-oriented programming
languages: uniform object model (class, meta-class and property-metaclass),
generic functions, multi-methods, delegation, properties, exceptions, contracts
and closures. Cos relies on the programmable capabilities of the C programming
language to extend its syntax and to implement the aforementioned concepts as
first-class objects. Cos aims at satisfying several general principles like
simplicity, extensibility, reusability, efficiency and portability which are
rarely met in a single programming language. Its design is tuned to provide
efficient and portable implementation of message multi-dispatch and message
multi-forwarding which are the heart of code extensibility and reusability.
With COS features in hand, software should become as flexible and extensible as
with scripting languages and as efficient and portable as expected with C
programming. Likewise, Cos concepts should significantly simplify adaptive and
aspect-oriented programming as well as distributed and service-oriented
computing
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2551</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2551</id><created>2010-03-12</created><authors><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>Dekker</keyname><forenames>Rommert</forenames></author><author><keyname>Berg</keyname><forenames>Jan van den</forenames></author></authors><title>A comparison of two techniques for bibliometric mapping:
  Multidimensional scaling and VOS</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  VOS is a new mapping technique that can serve as an alternative to the
well-known technique of multidimensional scaling. We present an extensive
comparison between the use of multidimensional scaling and the use of VOS for
constructing bibliometric maps. In our theoretical analysis, we show the
mathematical relation between the two techniques. In our experimental analysis,
we use the techniques for constructing maps of authors, journals, and keywords.
Two commonly used approaches to bibliometric mapping, both based on
multidimensional scaling, turn out to produce maps that suffer from artifacts.
Maps constructed using VOS turn out not to have this problem. We conclude that
in general maps constructed using VOS provide a more satisfactory
representation of a data set than maps constructed using well-known
multidimensional scaling approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2554</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2554</id><created>2010-03-12</created><updated>2010-06-09</updated><authors><author><keyname>Mastroeni</keyname><forenames>Loretta</forenames></author><author><keyname>Naldi</keyname><forenames>Maurizio</forenames></author></authors><title>Spectrum Trading: An Abstracted Bibliography</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document contains a bibliographic list of major papers on spectrum
trading and their abstracts. The aim of the list is to offer researchers
entering this field a fast panorama of the current literature. The list is
continually updated on the webpage
\url{http://www.disp.uniroma2.it/users/naldi/Ricspt.html}. Omissions and papers
suggested for inclusion may be pointed out to the authors through e-mail
(\textit{naldi@disp.uniroma2.it}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2586</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2586</id><created>2010-03-12</created><authors><author><keyname>Lisi</keyname><forenames>Francesca A.</forenames></author></authors><title>Inductive Logic Programming in Databases: from Datalog to DL+log</title><categories>cs.LO cs.AI cs.DB cs.LG</categories><comments>30 pages, 3 figures, 2 tables.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address an issue that has been brought to the attention of
the database community with the advent of the Semantic Web, i.e. the issue of
how ontologies (and semantics conveyed by them) can help solving typical
database problems, through a better understanding of KR aspects related to
databases. In particular, we investigate this issue from the ILP perspective by
considering two database problems, (i) the definition of views and (ii) the
definition of constraints, for a database whose schema is represented also by
means of an ontology. Both can be reformulated as ILP problems and can benefit
from the expressive and deductive power of the KR framework DL+log. We
illustrate the application scenarios by means of examples. Keywords: Inductive
Logic Programming, Relational Databases, Ontologies, Description Logics, Hybrid
Knowledge Representation and Reasoning Systems. Note: To appear in Theory and
Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2606</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2606</id><created>2010-03-12</created><updated>2010-08-20</updated><authors><author><keyname>Natarajan</keyname><forenames>Lakshmi Prasad</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Asymptotically-Optimal, Fast-Decodable, Full-Diversity STBCs</title><categories>cs.IT math.IT</categories><comments>16 pages, 3 tables. The title has been changed.The class of
  asymptotically-good multigroup ML decodable codes has been extended to a
  broader class of number of antennas. New fast-group-decodable codes and
  asymptotically-optimal, fast-decodable codes have been included</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a family/sequence of STBCs $\mathcal{C}_1,\mathcal{C}_2,\dots$, with
increasing number of transmit antennas $N_i$, with rates $R_i$ complex symbols
per channel use (cspcu), the asymptotic normalized rate is defined as $\lim_{i
\to \infty}{\frac{R_i}{N_i}}$. A family of STBCs is said to be
asymptotically-good if the asymptotic normalized rate is non-zero, i.e., when
the rate scales as a non-zero fraction of the number of transmit antennas, and
the family of STBCs is said to be asymptotically-optimal if the asymptotic
normalized rate is 1, which is the maximum possible value. In this paper, we
construct a new class of full-diversity STBCs that have the least ML decoding
complexity among all known codes for any number of transmit antennas $N&gt;1$ and
rates $R&gt;1$ cspcu. For a large set of $\left(R,N\right)$ pairs, the new codes
have lower ML decoding complexity than the codes already available in the
literature. Among the new codes, the class of full-rate codes ($R=N$) are
asymptotically-optimal and fast-decodable, and for $N&gt;5$ have lower ML decoding
complexity than all other families of asymptotically-optimal, fast-decodable,
full-diversity STBCs available in the literature. The construction of the new
STBCs is facilitated by the following further contributions of this paper:(i)
For $g &gt; 1$, we construct $g$-group ML-decodable codes with rates greater than
one cspcu. These codes are asymptotically-good too. For $g&gt;2$, these are the
first instances of $g$-group ML-decodable codes with rates greater than $1$
cspcu presented in the literature. (ii) We construct a new class of
fast-group-decodable codes for all even number of transmit antennas and rates
$1 &lt; R \leq 5/4$.(iii) Given a design with full-rank linear dispersion
matrices, we show that a full-diversity STBC can be constructed from this
design by encoding the real symbols independently using only regular PAM
constellations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2614</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2614</id><created>2010-03-12</created><authors><author><keyname>Ojha</keyname><forenames>Alok</forenames></author><author><keyname>Deng</keyname><forenames>Hongmei</forenames></author><author><keyname>Agrawal</keyname><forenames>Dharma P.</forenames></author><author><keyname>Sanyal</keyname><forenames>S.</forenames></author></authors><title>Forming the COUNCIL Based Clusters in Securing Wireless Ad Hoc Networks</title><categories>cs.CR</categories><comments>4 Pages, 5 Figures, International Conference on Computers and Device
  Communication, CODEC-2004, Jan 1-3, 2004, Kolkata, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cluster-based routing protocol (CBRP), two-level hierarchical structure is
successfully used to reduce over-flooding in wireless Ad Hoc networks. As it is
vulnerable to a single point of failure, we propose a new adaptive distributed
threshold scheme to replace the cluster head by a group of cluster heads within
each cluster, called COUNCIL, and distribute the service of single cluster head
to multiple cluster heads using (k,n) threshold secret sharing scheme. An Ad
Hoc network formed by COUNCIL based clusters can work correctly when the number
of compromised cluster heads is smaller than k. To implement this adaptive
threshold scheme in wireless Ad Hoc Networks, membership of the clusters should
be defined in an adaptive way. In this paper, we mainly discuss our algorithm
for forming COUNCIL based clusters using the concept of dominating set from
graph theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2616</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2616</id><created>2010-03-12</created><authors><author><keyname>Goyal</keyname><forenames>Vipul</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author><author><keyname>Agrawal</keyname><forenames>Dharma P.</forenames></author></authors><title>Vcache: Caching Dynamic Documents</title><categories>cs.CR</categories><comments>4 Pages, 3 Figures, 6th International Conference on Information
  Technology (CIT-2003), India, Dec 2003, pp. 338-342</comments><report-no>Proceedings of the 6th International Conference on Information
  Technology (CIT-2003), India, Dec 2003, pp. 338-342.</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional web caching is currently limited to static documents only. A
page generated on the fly from a server side script may have different contents
on different accesses and hence cannot be cached. A number of proposals for
attacking the problem have emerged based on the observation that different
instances of a dynamic document are usually quite similar in most cases, i.e.
they have a lot of common HTML code. In this paper, we first review these
related techniques and show their inadequacy for practical use. We then present
a general and fully automatic technique called Vcache based on the
decomposition of dynamic documents into a hierarchy of templates and bindings.
The technique is designed keeping in mind languages like Perl and C etc that
generate the documents using low-level print like statements. These languages
together, account for the largest number of dynamic documents on the web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2641</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2641</id><created>2010-03-12</created><authors><author><keyname>Dambreville</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author></authors><title>Release ZERO.0.1 of package RefereeToolbox</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RefereeToolbox is a java package implementing combination operators for
fusing evidences. It is downloadable from:
http://refereefunction.fredericdambreville.com/releases RefereeToolbox is based
on an interpretation of the fusion rules by means of Referee Functions. This
approach implies a dissociation between the definition of the combination and
its actual implementation, which is common to all referee-based combinations.
As a result, RefereeToolbox is designed with the aim to be generic and
evolutive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2643</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2643</id><created>2010-03-12</created><updated>2010-03-19</updated><authors><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Making Web Annotations Persistent over Time</title><categories>cs.DL</categories><comments>10 pages, 8 figures, accepted to JCDL 2010</comments><acm-class>H.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As Digital Libraries (DL) become more aligned with the web architecture,
their functional components need to be fundamentally rethought in terms of URIs
and HTTP. Annotation, a core scholarly activity enabled by many DL solutions,
exhibits a clearly unacceptable characteristic when existing models are applied
to the web: due to the representations of web resources changing over time, an
annotation made about a web resource today may no longer be relevant to the
representation that is served from that same resource tomorrow. We assume the
existence of archived versions of resources, and combine the temporal features
of the emerging Open Annotation data model with the capability offered by the
Memento framework that allows seamless navigation from the URI of a resource to
archived versions of that resource, and arrive at a solution that provides
guarantees regarding the persistence of web annotations over time. More
specifically, we provide theoretical solutions and proof-of-concept
experimental evaluations for two problems: reconstructing an existing
annotation so that the correct archived version is displayed for all resources
involved in the annotation, and retrieving all annotations that involve a given
archived version of a web resource.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2649</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2649</id><created>2010-03-12</created><authors><author><keyname>Chestnut</keyname><forenames>Stephen</forenames></author><author><keyname>Lladser</keyname><forenames>Manuel</forenames></author></authors><title>Occupancy distributions in Markov chains via Doeblin's ergodicity
  coefficient</title><categories>math.PR cs.DM q-bio.GN</categories><comments>12 pages, 2 tables</comments><msc-class>60J10, 60J22, 65C40, 37A25, 37A30, 37M25, 60C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply Doeblin's ergodicity coefficient as a computational tool to
approximate the occupancy distribution of a set of states in a homogeneous but
possibly non-stationary finite Markov chain. Our approximation is based on new
properties satisfied by this coefficient, which allow us to approximate a chain
of duration n by independent and short-lived realizations of an auxiliary
homogeneous Markov chain of duration of order ln(n). Our approximation may be
particularly useful when exact calculations via first-step methods or transfer
matrices are impractical, and asymptotic approximations may not be yet
reliable. Our findings may find applications to pattern problems in Markovian
and non-Markovian sequences that are treatable via embedding techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2660</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2660</id><created>2010-03-12</created><authors><author><keyname>Sorudeykin</keyname><forenames>Kirill A.</forenames></author></authors><title>An Educative Brain-Computer Interface</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we will describe all necessary parts of Brain-Computer
Interface (BCI), such as source of signals, hardware, software, analysis,
architectures of complete system. We also will go along various applications of
BCI, view some subject fields and their specifics. After preface we will
consider the main point of this work-concepts of using BCI in education.
Represented direction of BCI development has not been reported prior. In this
work a computer system, currently being elaborated in author's laboratory, will
be specified. A purpose of it is to determine a degree of clearness of studied
information for certain user according to their indications of brain electrical
signals. On the basis of this information the system is able to find an optimal
approach to interact with each single user. Feedback individualization leads to
learning effectiveness increasing. Stated investigations will be supplemented
by author's analytical reasoning on the nature of thinking process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2664</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2664</id><created>2010-03-12</created><authors><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author></authors><title>Information Contagion: an Empirical Study of the Spread of News on Digg
  and Twitter Social Networks</title><categories>cs.CY physics.soc-ph</categories><comments>Proceedings of 4th International Conference on Weblogs and Social
  Media (ICWSM-10)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social networks have emerged as a critical factor in information
dissemination, search, marketing, expertise and influence discovery, and
potentially an important tool for mobilizing people. Social media has made
social networks ubiquitous, and also given researchers access to massive
quantities of data for empirical analysis. These data sets offer a rich source
of evidence for studying dynamics of individual and group behavior, the
structure of networks and global patterns of the flow of information on them.
However, in most previous studies, the structure of the underlying networks was
not directly visible but had to be inferred from the flow of information from
one individual to another. As a result, we do not yet understand dynamics of
information spread on networks or how the structure of the network affects it.
We address this gap by analyzing data from two popular social news sites.
Specifically, we extract social networks of active users on Digg and Twitter,
and track how interest in news stories spreads among them. We show that social
networks play a crucial role in the spread of information on these sites, and
that network structure affects dynamics of information flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2675</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2675</id><created>2010-03-13</created><updated>2010-04-21</updated><authors><author><keyname>Li</keyname><forenames>Chih-ping</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Exploiting Channel Memory for Multi-User Wireless Scheduling without
  Channel Measurement: Capacity Regions and Algorithms</title><categories>cs.IT cs.NI math.DS math.IT math.OC</categories><comments>17 pages, 8 figures. Submitted to IEEE Transactions on Information
  Theory. The whole paper is revised and the title is changed for better
  clarification.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the fundamental network capacity of a multi-user wireless downlink
under two assumptions: (1) Channels are not explicitly measured and thus
instantaneous states are unknown, (2) Channels are modeled as ON/OFF Markov
chains. This is an important network model to explore because channel probing
may be costly or infeasible in some contexts. In this case, we can use channel
memory with ACK/NACK feedback from previous transmissions to improve network
throughput. Computing in closed form the capacity region of this network is
difficult because it involves solving a high dimension partially observed
Markov decision problem. Instead, in this paper we construct an inner and outer
bound on the capacity region, showing that the bound is tight when the number
of users is large and the traffic is symmetric. For the case of heterogeneous
traffic and any number of users, we propose a simple queue-dependent policy
that can stabilize the network with any data rates strictly within the inner
capacity bound. The stability analysis uses a novel frame-based Lyapunov drift
argument. The outer-bound analysis uses stochastic coupling and state
aggregation to bound the performance of a restless bandit problem using a
related multi-armed bandit system. Our results are useful in cognitive radio
networks, opportunistic scheduling with delayed/uncertain channel state
information, and restless bandit problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2677</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2677</id><created>2010-03-13</created><authors><author><keyname>Doomun</keyname><forenames>Razvi</forenames></author><author><keyname>N.</keyname><forenames>Lollmahamod</forenames></author><author><keyname>Nadeem</keyname><forenames>Auleear</forenames></author><author><keyname>Aukin</keyname><forenames>Mozafar</forenames></author></authors><title>Classified Ads Harvesting Agent and Notification System</title><categories>cs.IR</categories><comments>International Conference on Information and Communication Technology
  for the Muslim World (ICT4M 2006), 21-23 November 2006, Kuala Lumpur,
  Malaysia</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The shift from an information society to a knowledge society require rapid
information harvesting, reliable search and instantaneous on demand delivery.
Information extraction agents are used to explore and collect data available
from Web, in order to effectively exploit such data for business purposes, such
as automatic news filtering, advertisement or product searching and price
comparing. In this paper, we develop a real-time automatic harvesting agent for
adverts posted on Servihoo web portal and an SMS-based notification system. It
uses the URL of the web portal and the object model, i.e., the fields of
interests and a set of rules written using the HTML parsing functions to
extract latest adverts information. The extraction engine executes the
extraction rules and stores the information in a database to be processed for
automatic notification. This intelligent system helps to tremendously save
time. It also enables users or potential product buyers to react more quickly
to changes and newly posted sales adverts, paving the way to real-time best buy
deals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2681</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2681</id><created>2010-03-13</created><authors><author><keyname>Han</keyname><forenames>Chenggao</forenames></author><author><keyname>Suehiro</keyname><forenames>Naoki</forenames></author><author><keyname>Hashimoto</keyname><forenames>Takeshi</forenames></author></authors><title>A Systematic Framework for the Construction of Optimal Complete
  Complementary Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complete complementary code (CCC) is a sequence family with ideal
correlation sums which was proposed by Suehiro and Hatori. Numerous literatures
show its applications to direct-spread code-division multiple access (DS-CDMA)
systems for inter-channel interference (ICI)-free communication with improved
spectral efficiency. In this paper, we propose a systematic framework for the
construction of CCCs based on $N$-shift cross-orthogonal sequence families
($N$-CO-SFs). We show theoretical bounds on the size of $N$-CO-SFs and CCCs,
and give a set of four algorithms for their generation and extension. The
algorithms are optimal in the sense that the size of resulted sequence families
achieves theoretical bounds and, with the algorithms, we can construct an
optimal CCC consisting of sequences whose lengths are not only almost arbitrary
but even variable between sequence families. We also discuss the family size,
alphabet size, and lengths of constructible CCCs based on the proposed
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2682</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2682</id><created>2010-03-13</created><authors><author><keyname>Spivak</keyname><forenames>David I.</forenames></author></authors><title>Table manipulation in simplicial databases</title><categories>cs.DB cs.IR</categories><comments>8 pages.</comments><acm-class>H.2; H.5</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In \cite{Spi}, we developed a category of databases in which the schema of a
database is represented as a simplicial set. Each simplex corresponds to a
table in the database. There, our main concern was to find a categorical
formulation of databases; the simplicial nature of the schemas was to some
degree unexpected and unexploited.
  In the present note, we show how to use this geometric formulation
effectively on a computer. If we think of each simplex as a polygonal tile, we
can imagine assembling custom databases by mixing and matching tiles. Queries
on this database can be performed by drawing paths through the resulting tile
formations, selecting records at the start-point of this path and retrieving
corresponding records at its end-point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2700</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2700</id><created>2010-03-13</created><updated>2010-04-01</updated><authors><author><keyname>Jozefowska</keyname><forenames>Joanna</forenames></author><author><keyname>Lawrynowicz</keyname><forenames>Agnieszka</forenames></author><author><keyname>Lukaszewski</keyname><forenames>Tomasz</forenames></author></authors><title>The role of semantics in mining frequent patterns from knowledge bases
  in description logics with rules</title><categories>cs.LO cs.AI</categories><comments>40 pages, 6 figures, 6 tables</comments><report-no>RA-01/09</report-no><msc-class>68T27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for mining frequent patterns in a language that
combines both Semantic Web ontologies and rules. In particular we consider the
setting of using a language that combines description logics with DL-safe
rules. This setting is important for the practical application of data mining
to the Semantic Web. We focus on the relation of the semantics of the
representation formalism to the task of frequent pattern discovery, and for the
core of our method, we propose an algorithm that exploits the semantics of the
combined knowledge base. We have developed a proof-of-concept data mining
implementation of this. Using this we have empirically shown that using the
combined knowledge base to perform semantic tests can make data mining faster
by pruning useless candidate patterns before their evaluation. We have also
shown that the quality of the set of patterns produced may be improved: the
patterns are more compact, and there are fewer patterns. We conclude that
exploiting the semantics of a chosen representation formalism is key to the
design and application of (onto-)relational frequent pattern discovery methods.
Note: To appear in Theory and Practice of Logic Programming (TPLP)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2724</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2724</id><created>2010-03-13</created><authors><author><keyname>Abraham</keyname><forenames>Siby</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author><author><keyname>Sanglikar</keyname><forenames>Mukund</forenames></author></authors><title>Particle Swarm Optimization Based Diophantine Equation Solver</title><categories>cs.NE cs.NA</categories><comments>15 Pages, 12 Figures, 5 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces particle swarm optimization as a viable strategy to find
numerical solution of Diophantine equation, for which there exists no general
method of finding solutions. The proposed methodology uses a population of
integer particles. The candidate solutions in the feasible space are optimized
to have better positions through particle best and global best positions. The
methodology, which follows fully connected neighborhood topology, can offer
many solutions of such equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2749</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2749</id><created>2010-03-13</created><authors><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author></authors><title>Efficient Queue-based CSMA with Collisions</title><categories>cs.IT cs.NI math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there has been considerable interest in the design of efficient
carrier sense multiple access(CSMA) protocol for wireless network. The basic
assumption underlying recent results is availability of perfect carrier sense
information. This allows for design of continuous time algorithm under which
collisions are avoided. The primary purpose of this note is to show how these
results can be extended in the case when carrier sense information may not be
perfect, or equivalently delayed. Specifically, an adaptation of algorithm in
Rajagopalan, Shah, Shin (2009) is presented here for time slotted setup with
carrier sense information available only at the end of the time slot. To
establish its throughput optimality, in additon to method developed in
Rajagopalan, Shah, Shin (2009), understanding properties of stationary
distribution of a certain non-reversible Markov chain as well as bound on its
mixing time is essential. This note presents these key results. A longer
version of this note will provide detailed account of how this gets
incorporated with methods of Rajagopalan, Shah, Shin (2009) to provide the
positive recurrence of underlying network Markov process. In addition, these
results will help design optimal rate control in conjunction with CSMA in
presence of collision building upon the method of Jiang, Shah, Shin, Walrand
(2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2751</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2751</id><created>2010-03-13</created><authors><author><keyname>Nelson</keyname><forenames>Blaine</forenames></author><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Huang</keyname><forenames>Ling</forenames></author><author><keyname>Joseph</keyname><forenames>Anthony D.</forenames></author><author><keyname>Lau</keyname><forenames>Shing-hon</forenames></author><author><keyname>Lee</keyname><forenames>Steven J.</forenames></author><author><keyname>Rao</keyname><forenames>Satish</forenames></author><author><keyname>Tran</keyname><forenames>Anthony</forenames></author><author><keyname>Tygar</keyname><forenames>J. D.</forenames></author></authors><title>Near-Optimal Evasion of Convex-Inducing Classifiers</title><categories>cs.LG cs.CR</categories><comments>8 pages; to appear at AISTATS'2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifiers are often used to detect miscreant activities. We study how an
adversary can efficiently query a classifier to elicit information that allows
the adversary to evade detection at near-minimal cost. We generalize results of
Lowd and Meek (2005) to convex-inducing classifiers. We present algorithms that
construct undetected instances of near-minimal cost using only polynomially
many queries in the dimension of the space and without reverse engineering the
decision boundary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2760</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2760</id><created>2010-03-14</created><authors><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Baricz</keyname><forenames>Arpad</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author></authors><title>On the monotonicity, log-concavity and tight bounds of the generalized
  Marcum and Nuttall Q-functions</title><categories>cs.IT math.IT math.PR</categories><comments>21 pages, 12 figures</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 56, no. 3, pp. 1166-1186, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a comprehensive study of the monotonicity and
log-concavity of the generalized Marcum and Nuttall Q-functions. More
precisely, a simple probabilistic method is firstly given to prove the
monotonicity of these two functions. Then, the log-concavity of the generalized
Marcum Q-function and its deformations is established with respect to each of
the three parameters. Since the Nuttall Q-function has similar probabilistic
interpretations as the generalized Marcum Q-function, we deduce the
log-concavity of the Nuttall Q-function. By exploiting the log-concavity of
these two functions, we propose new tight lower and upper bounds for the
generalized Marcum and Nuttall Q-functions. Our proposed bounds are much
tighter than the existing bounds in the literature in most of the cases. The
relative errors of our proposed bounds converge to 0 as b tends to infinity.
The numerical results show that the absolute relative errors of the proposed
bounds are less than 5% in most of the cases. The proposed bounds can be
effectively applied to the outage probability analysis of interference-limited
systems such as cognitive radio and wireless sensor network, in the study of
error performance of various wireless communication systems operating over
fading channels and extracting the log-likelihood ratio for differential
phase-shift keying (DPSK) signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2767</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2767</id><created>2010-03-14</created><authors><author><keyname>Nguyen</keyname><forenames>Kien C.</forenames></author><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>Security Games with Decision and Observation Errors</title><categories>cs.GT cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two-player security games which can be viewed as sequences of
nonzero-sum matrix games played by an Attacker and a Defender. The evolution of
the game is based on a stochastic fictitious play process. Players do not have
access to each other's payoff matrix. Each has to observe the other's actions
up to present and plays the action generated based on the best response to
these observations. However, when the game is played over a communication
network, there are several practical issues that need to be taken into account:
First, the players may make random decision errors from time to time. Second,
the players' observations of each other's previous actions may be incorrect.
The players will try to compensate for these errors based on the information
they have. We examine convergence property of the game in such scenarios, and
establish convergence to the equilibrium point under some mild assumptions when
both players are restricted to two actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2782</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2782</id><created>2010-03-14</created><authors><author><keyname>Srinath</keyname><forenames>K. Pavan</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Reduced ML-Decoding Complexity, Full-Rate STBCs for $2^a$ Transmit
  Antenna Systems</title><categories>cs.IT math.IT</categories><comments>21 pages, 3 figures, one column format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an $n_t$ transmit, $n_r$ receive antenna system ($n_t \times n_r$
system), a {\it{full-rate}} space time block code (STBC) transmits $n_{min} =
min(n_t,n_r)$ complex symbols per channel use and in general, has an
ML-decoding complexity of the order of $M^{n_tn_{min}}$ (considering square
designs), where $M$ is the constellation size. In this paper, a scheme to
obtain a full-rate STBC for $2^a$ transmit antennas and any $n_r$, with reduced
ML-decoding complexity of the order of $M^{n_t(n_{min}-3/4)}$, is presented.
The weight matrices of the proposed STBC are obtained from the unitary matrix
representations of a Clifford Algebra. For any value of $n_r$, the proposed
design offers a reduction from the full ML-decoding complexity by a factor of
$M^{3n_t/4}}$. The well known Silver code for 2 transmit antennas is a special
case of the proposed scheme. Further, it is shown that the codes constructed
using the scheme have higher ergodic capacity than the well known punctured
Perfect codes for $n_r &lt; n_t$. Simulation results of the symbol error rates are
shown for $8 \times 2$ systems, where the comparison of the proposed code is
with the punctured Perfect code for 8 transmit antennas. The proposed code
matches the punctured perfect code in error performance, while having reduced
ML-decoding complexity and higher ergodic capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2790</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2790</id><created>2010-03-14</created><authors><author><keyname>Demey</keyname><forenames>Lorenz</forenames></author></authors><title>Some Remarks on the Model Theory of Epistemic Plausibility Models</title><categories>cs.LO</categories><comments>19 pages, 3 figures</comments><msc-class>03B42</msc-class><acm-class>F.4.1</acm-class><doi>10.3166/jancl.21.375-395</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical logics of knowledge and belief are usually interpreted on Kripke
models, for which a mathematically well-developed model theory is available.
However, such models are inadequate to capture dynamic phenomena. Therefore,
epistemic plausibility models have been introduced. Because these are much
richer structures than Kripke models, they do not straightforwardly inherit the
model-theoretical results of modal logic. Therefore, while epistemic
plausibility structures are well-suited for modeling purposes, an extensive
investigation of their model theory has been lacking so far. The aim of the
present paper is to fill exactly this gap, by initiating a systematic
exploration of the model theory of epistemic plausibility models. Like in
'ordinary' modal logic, the focus will be on the notion of bisimulation. We
define various notions of bisimulations (parametrized by a language L) and show
that L-bisimilarity implies L-equivalence. We prove a Hennesy-Milner type
result, and also two undefinability results. However, our main point is a
negative one, viz. that bisimulations cannot straightforwardly be generalized
to epistemic plausibility models if conditional belief is taken into account.
We present two ways of coping with this issue: (i) adding a modality to the
language, and (ii) putting extra constraints on the models. Finally, we make
some remarks about the interaction between bisimulation and dynamic model
changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2801</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2801</id><created>2010-03-14</created><authors><author><keyname>Durand</keyname><forenames>Bruno</forenames></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>Fixed point theorem and aperiodic tilings</title><categories>cs.LO cs.DM math.CO</categories><comments>8 pages, 5 figures</comments><journal-ref>Published in Bulletin of the EATCS (The Logic in Computer Science
  Column by Yuri Gurevich) no. 97 (2009) pp. 126-136:
  http://www.eatcs.org/images/bulletin/beatcs97.pdf</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new simple construction of an aperiodic tile set based on
self-referential (fixed point) argument. People often say about some discovery
that it appeared &quot;ahead of time&quot;, meaning that it could be fully understood
only in the context of ideas developed later. For the topic of this note, the
construction of an aperiodic tile set based on the fixed-point
(self-referential) approach, the situation is exactly the opposite. It should
have been found in 1960s when the question about aperiodic tile sets was first
asked: all the tools were quite standard and widely used at that time. However,
the history had chosen a different path and many nice geometric ad hoc
constructions were developed instead (by Berger, Robinson, Penrose, Ammann and
many others. In this note we try to correct this error and present a
construction that should have been discovered first but seemed to be unnoticed
for more that forty years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2813</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2813</id><created>2010-03-14</created><updated>2010-10-14</updated><authors><author><keyname>Salehkaleybar</keyname><forenames>Saber</forenames></author><author><keyname>Majd</keyname><forenames>Arash</forenames></author><author><keyname>Pakravan</keyname><forenames>Mohammad Reza</forenames></author></authors><title>A New Framework for Cognitive Medium Access Control: POSG Approach</title><categories>cs.GT</categories><comments>This paper has been withdrawn by the author due to minor
  contributions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new analytical framework to solve medium access
problem for secondary users (SUs) in cognitive radio networks. Partially
Observable Stochastic Games (POSG) and Decentralized Markov Decision Process
(Dec-POMDP) are two multi-agent Markovian decision processes which are used to
present a solution. A primary network with two SUs is considered as an example
to demonstrate our proposed framework. Two different scenarios are assumed. In
the first scenario, SUs compete to acquire the licensed channel which is
modeled using POSG framework. In the second one, SUs cooperate to access
channel for which the solution is based on Dec-POMDP. Besides, the dominant
strategy for both of the above mentioned scenarios is presented for a three
slot horizon length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2822</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2822</id><created>2010-03-14</created><updated>2011-01-05</updated><authors><author><keyname>Tur</keyname><forenames>Ronen</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Friedman</keyname><forenames>Zvi</forenames></author></authors><title>Innovation Rate Sampling of Pulse Streams with Application to Ultrasound
  Imaging</title><categories>cs.IT math.IT</categories><comments>14 pages, 13 figures</comments><doi>10.1109/TSP.2011.2105480</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signals comprised of a stream of short pulses appear in many applications
including bio-imaging and radar. The recent finite rate of innovation
framework, has paved the way to low rate sampling of such pulses by noticing
that only a small number of parameters per unit time are needed to fully
describe these signals. Unfortunately, for high rates of innovation, existing
sampling schemes are numerically unstable. In this paper we propose a general
sampling approach which leads to stable recovery even in the presence of many
pulses. We begin by deriving a condition on the sampling kernel which allows
perfect reconstruction of periodic streams from the minimal number of samples.
We then design a compactly supported class of filters, satisfying this
condition. The periodic solution is extended to finite and infinite streams,
and is shown to be numerically stable even for a large number of pulses. High
noise robustness is also demonstrated when the delays are sufficiently
separated. Finally, we process ultrasound imaging data using our techniques,
and show that substantial rate reduction with respect to traditional ultrasound
sampling schemes can be achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2836</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2836</id><created>2010-03-14</created><authors><author><keyname>Raginsky</keyname><forenames>Maxim</forenames></author><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author><author><keyname>Willett</keyname><forenames>Rebecca</forenames></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author></authors><title>Fishing in Poisson streams: focusing on the whales, ignoring the minnows</title><categories>cs.IT math.IT</categories><comments>6 pages, 6 pdf figures; invited paper to appear in CISS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a low-complexity approach for reconstructing average
packet arrival rates and instantaneous packet counts at a router in a
communication network, where the arrivals of packets in each flow follow a
Poisson process. Assuming that the rate vector of this Poisson process is
sparse or approximately sparse, the goal is to maintain a compressed summary of
the process sample paths using a small number of counters, such that at any
time it is possible to reconstruct both the total number of packets in each
flow and the underlying rate vector. We show that these tasks can be
accomplished efficiently and accurately using compressed sensing with expander
graphs. In particular, the compressive counts are a linear transformation of
the underlying counting process by the adjacency matrix of an unbalanced
expander. Such a matrix is binary and sparse, which allows for efficient
incrementing when new packets arrive. We describe, analyze, and compare two
methods that can be used to estimate both the current vector of total packet
counts and the underlying vector of arrival rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2839</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2839</id><created>2010-03-14</created><updated>2010-03-15</updated><authors><author><keyname>Kundeti</keyname><forenames>Vamsi</forenames></author><author><keyname>Rajasekaran</keyname><forenames>Sanguthevar</forenames></author><author><keyname>Dinh</keyname><forenames>Hieu</forenames></author></authors><title>On the Border Length Minimization Problem (BLMP) on a Square Array</title><categories>cs.DS cs.CC q-bio.QM</categories><acm-class>F.2; G.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protein/Peptide microarrays are rapidly gaining momentum in the diagnosis of
cancer. High-density and highthroughput peptide arrays are being extensively
used to detect tumor biomarkers, examine kinase activity, identify antibodies
having low serum titers and locate antibody signatures. Improving the yield of
microarray fabrication involves solving a hard combinatorial optimization
problem called the Border Length Minimization Problem (BLMP). An important
question that remained open for the past seven years is if the BLMP is
tractable or not. We settle this open problem by proving that the BLMP is
NP-hard. We also present a hierarchical refinement algorithm which can refine
any heuristic solution for the BLMP problem. We also prove that the
TSP+1-threading heuristic is an O(N)- approximation. The hierarchical
refinement solver is available as an opensource code at
http://launchpad.net/blm-solve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2851</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2851</id><created>2010-03-15</created><updated>2013-12-02</updated><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Harvey</keyname><forenames>Nicholas J. A.</forenames></author><author><keyname>Uehara</keyname><forenames>Ryuhei</forenames></author><author><keyname>Uno</keyname><forenames>Takeaki</forenames></author><author><keyname>Uno</keyname><forenames>Yushi</forenames></author></authors><title>The complexity of UNO</title><categories>cs.DM cs.CC</categories><comments>13 body pages, 2 appendix pages, 1 table, 7 figures</comments><acm-class>G.2; F.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the popular card game UNO from the viewpoint of
algorithmic combinatorial game theory. We define simple and concise
mathematical models for the game, including both cooperative and uncooperative
versions, and analyze their computational complexity. In particular, we prove
that even a single-player version of UNO is NP-complete, although some
restricted cases are in P. Surprisingly, we show that the uncooperative
two-player version is also in P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2871</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2871</id><created>2010-03-15</created><authors><author><keyname>Forget</keyname><forenames>Julien</forenames><affiliation>ONERA, Toulouse, France and</affiliation></author><author><keyname>Boniol</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>ONERA, Toulouse, France and</affiliation></author><author><keyname>Lesens</keyname><forenames>David</forenames><affiliation>EADS Astrium Space Transportation, Les Mureaux, France</affiliation></author><author><keyname>Pagetti</keyname><forenames>Claire</forenames><affiliation>ONERA, Toulouse, France and</affiliation></author></authors><title>Implementing Multi-Periodic Critical Systems: from Design to Code
  Generation</title><categories>cs.PL</categories><comments>15 pages, published in Workshop on Formal Methods for Aerospace
  (FMA'09), part of Formal Methods Week 2009.</comments><msc-class>68N15</msc-class><journal-ref>EPTCS 20, 2010, pp. 34-48</journal-ref><doi>10.4204/EPTCS.20.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a complete scheme for the development of Critical
Embedded Systems with Multiple Real-Time Constraints. The system is programmed
with a language that extends the synchronous approach with high-level real-time
primitives. It enables to assemble in a modular and hierarchical manner several
locally mono-periodic synchronous systems into a globally multi-periodic
synchronous system. It also allows to specify flow latency constraints. A
program is translated into a set of real-time tasks. The generated code (\C\
code) can be executed on a simple real-time platform with a dynamic-priority
scheduler (EDF). The compilation process (each algorithm of the process, not
the compiler itself) is formally proved correct, meaning that the generated
code respects the real-time semantics of the original program (respect of
periods, deadlines, release dates and precedences) as well as its functional
semantics (respect of variable consumption).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2880</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2880</id><created>2010-03-15</created><updated>2010-06-25</updated><authors><author><keyname>Selva</keyname><forenames>J.</forenames></author></authors><title>Regularized sampling of multiband signals</title><categories>cs.IT math.IT</categories><comments>The title and introduction have changed. Submitted to the IEEE
  Transactions on Signal Processing</comments><doi>10.1109/TSP.2010.2057248</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a regularized sampling method for multiband signals, that
makes it possible to approach the Landau limit, while keeping the sensitivity
to noise at a low level. The method is based on band-limited windowing,
followed by trigonometric approximation in consecutive time intervals. The key
point is that the trigonometric approximation &quot;inherits&quot; the multiband
property, that is, its coefficients are formed by bursts of non-zero elements
corresponding to the multiband components. It is shown that this method can be
well combined with the recently proposed synchronous multi-rate sampling (SMRS)
scheme, given that the resulting linear system is sparse and formed by ones and
zeroes. The proposed method allows one to trade sampling efficiency for noise
sensitivity, and is specially well suited for bounded signals with unbounded
energy like those in communications, navigation, audio systems, etc. Besides,
it is also applicable to finite energy signals and periodic band-limited
signals (trigonometric polynomials). The paper includes a subspace method for
blindly estimating the support of the multiband signal as well as its
components, and the results are validated through several numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2883</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2883</id><created>2010-03-15</created><updated>2010-09-12</updated><authors><author><keyname>Ksairi</keyname><forenames>Nassar</forenames></author><author><keyname>Bianchi</keyname><forenames>Pascal</forenames></author><author><keyname>Ciblat</keyname><forenames>Philippe</forenames></author></authors><title>Nearly Optimal Resource Allocation for Downlink OFDMA in 2-D Cellular
  Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a resource allocation algorithm for the downlink of
sectorized two-dimensional (2-D) OFDMA cellular networks assuming statistical
Channel State Information (CSI) and fractional frequency reuse. The proposed
algorithm can be implemented in a distributed fashion without the need to any
central controlling units. Its performance is analyzed assuming fast fading
Rayleigh channels and Gaussian distributed multicell interference. We show that
the transmit power of this simple algorithm tends, as the number of users grows
to infinity, to the same limit as the minimal power required to satisfy all
users' rate requirements i.e., the proposed resource allocation algorithm is
asymptotically optimal. As a byproduct of this asymptotic analysis, we
characterize a relevant value of the reuse factor that only depends on an
average state of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2914</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2914</id><created>2010-03-15</created><authors><author><keyname>Villard</keyname><forenames>Joffrey</forenames></author><author><keyname>Bianchi</keyname><forenames>Pascal</forenames></author><author><keyname>Moulines</keyname><forenames>Eric</forenames></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author></authors><title>High-Rate Quantization for the Neyman-Pearson Detection of Hidden Markov
  Processes</title><categories>cs.IT math.IT</categories><comments>11 pages, 2 figures, presented at ITW 2010</comments><doi>10.1109/ITWKSPS.2010.5503209</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the decentralized detection of Hidden Markov
Processes using the Neyman-Pearson test. We consider a network formed by a
large number of distributed sensors. Sensors' observations are noisy snapshots
of a Markov process to be detected. Each (real) observation is quantized on
log2(N) bits before being transmitted to a fusion center which makes the final
decision. For any false alarm level, it is shown that the miss probability of
the Neyman-Pearson test converges to zero exponentially as the number of
sensors tends to infinity. The error exponent is provided using recent results
on Hidden Markov Models. In order to obtain informative expressions of the
error exponent as a function of the quantization rule, we further investigate
the case where the number N of quantization levels tends to infinity, following
the approach developed in [Gupta &amp; Hero, 2003]. In this regime, we provide the
quantization rule maximizing the error exponent. Illustration of our results is
provided in the case of the detection of a Gauss-Markov signal in noise. In
terms of error exponent, the proposed quantization rule significantly
outperforms the one proposed by [Gupta &amp; Hero, 2003] for i.i.d. observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2941</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2941</id><created>2010-03-15</created><updated>2010-08-03</updated><authors><author><keyname>Ramirez</keyname><forenames>Ignacio</forenames></author><author><keyname>Sapiro</keyname><forenames>Guillermo</forenames></author></authors><title>Universal Regularizers For Robust Sparse Coding and Modeling</title><categories>cs.IT math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse data models, where data is assumed to be well represented as a linear
combination of a few elements from a dictionary, have gained considerable
attention in recent years, and their use has led to state-of-the-art results in
many signal and image processing tasks. It is now well understood that the
choice of the sparsity regularization term is critical in the success of such
models. Based on a codelength minimization interpretation of sparse coding, and
using tools from universal coding theory, we propose a framework for designing
sparsity regularization terms which have theoretical and practical advantages
when compared to the more standard l0 or l1 ones. The presentation of the
framework and theoretical foundations is complemented with examples that show
its practical advantages in image denoising, zooming and classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2958</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2958</id><created>2010-03-15</created><updated>2010-08-03</updated><authors><author><keyname>Koutis</keyname><forenames>Ioannis</forenames></author><author><keyname>Miller</keyname><forenames>Gary L.</forenames></author><author><keyname>Peng</keyname><forenames>Richard</forenames></author></authors><title>Approaching optimality for solving SDD systems</title><categories>cs.DS</categories><comments>To appear in FOCS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm that on input of an $n$-vertex $m$-edge weighted
graph $G$ and a value $k$, produces an {\em incremental sparsifier} $\hat{G}$
with $n-1 + m/k$ edges, such that the condition number of $G$ with $\hat{G}$ is
bounded above by $\tilde{O}(k\log^2 n)$, with probability $1-p$. The algorithm
runs in time
  $$\tilde{O}((m \log{n} + n\log^2{n})\log(1/p)).$$
  As a result, we obtain an algorithm that on input of an $n\times n$ symmetric
diagonally dominant matrix $A$ with $m$ non-zero entries and a vector $b$,
computes a vector ${x}$ satisfying $||{x}-A^{+}b||_A&lt;\epsilon ||A^{+}b||_A $,
in expected time
  $$\tilde{O}(m\log^2{n}\log(1/\epsilon)).$$
  The solver is based on repeated applications of the incremental sparsifier
that produces a chain of graphs which is then used as input to a recursive
preconditioned Chebyshev iteration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2976</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2976</id><created>2010-03-15</created><authors><author><keyname>Fearnley</keyname><forenames>John</forenames></author></authors><title>Non-oblivious Strategy Improvement</title><categories>cs.GT</categories><doi>10.1007/978-3-642-17511-4_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study strategy improvement algorithms for mean-payoff and parity games. We
describe a structural property of these games, and we show that these
structures can affect the behaviour of strategy improvement. We show how
awareness of these structures can be used to accelerate strategy improvement
algorithms. We call our algorithms non-oblivious because they remember
properties of the game that they have discovered in previous iterations. We
show that non-oblivious strategy improvement algorithms perform well on
examples that are known to be hard for oblivious strategy improvement. Hence,
we argue that previous strategy improvement algorithms fail because they ignore
the structural properties of the game that they are solving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.2977</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.2977</id><created>2010-03-15</created><updated>2010-06-03</updated><authors><author><keyname>Bansal</keyname><forenames>Nikhil</forenames></author><author><keyname>Khandekar</keyname><forenames>Rohit</forenames></author><author><keyname>Konemann</keyname><forenames>Jochen</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Peis</keyname><forenames>Britta</forenames></author></authors><title>On Generalizations of Network Design Problems with Degree Bounds</title><categories>cs.DS</categories><comments>v2, 24 pages, 4 figures</comments><acm-class>F.2.2</acm-class><doi>10.1007/978-3-642-13036-6_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative rounding and relaxation have arguably become the method of choice
in dealing with unconstrained and constrained network design problems. In this
paper we extend the scope of the iterative relaxation method in two directions:
(1) by handling more complex degree constraints in the minimum spanning tree
problem (namely, laminar crossing spanning tree), and (2) by incorporating
`degree bounds' in other combinatorial optimization problems such as matroid
intersection and lattice polyhedra. We give new or improved approximation
algorithms, hardness results, and integrality gaps for these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3045</identifier>
 <datestamp>2010-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3045</id><created>2010-03-15</created><updated>2010-08-19</updated><authors><author><keyname>Fang</keyname><forenames>Wenjie</forenames></author></authors><title>A Computational Approach to the Graceful Tree Conjecture</title><categories>cs.DM math.CO</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graceful tree conjecture is a well-known open problem in graph theory. Here
we present a computational approach to this conjecture. An algorithm for
finding graceful labelling for trees is proposed. With this algorithm, we show
that every tree with at most 35 vertices allows a graceful labelling, hence we
verify that the graceful tree conjecture is correct for trees with at most 35
vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3047</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3047</id><created>2010-03-15</created><updated>2010-04-21</updated><authors><author><keyname>Nordstr&#xf6;m</keyname><forenames>Jakob</forenames></author></authors><title>On the Relative Strength of Pebbling and Resolution</title><categories>cs.CC cs.DM math.CO</categories><comments>Full-length version of paper to appear in Proceedings of the 25th
  Annual IEEE Conference on Computational Complexity (CCC '10), June 2010</comments><acm-class>F.1.1; F.1.3; F.2.3; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last decade has seen a revival of interest in pebble games in the context
of proof complexity. Pebbling has proven a useful tool for studying
resolution-based proof systems when comparing the strength of different
subsystems, showing bounds on proof space, and establishing size-space
trade-offs. The typical approach has been to encode the pebble game played on a
graph as a CNF formula and then argue that proofs of this formula must inherit
(various aspects of) the pebbling properties of the underlying graph.
Unfortunately, the reductions used here are not tight. To simulate resolution
proofs by pebblings, the full strength of nondeterministic black-white pebbling
is needed, whereas resolution is only known to be able to simulate
deterministic black pebbling. To obtain strong results, one therefore needs to
find specific graph families which either have essentially the same properties
for black and black-white pebbling (not at all true in general) or which admit
simulations of black-white pebblings in resolution. This paper contributes to
both these approaches. First, we design a restricted form of black-white
pebbling that can be simulated in resolution and show that there are graph
families for which such restricted pebblings can be asymptotically better than
black pebblings. This proves that, perhaps somewhat unexpectedly, resolution
can strictly beat black-only pebbling, and in particular that the space lower
bounds on pebbling formulas in [Ben-Sasson and Nordstrom 2008] are tight.
Second, we present a versatile parametrized graph family with essentially the
same properties for black and black-white pebbling, which gives sharp
simultaneous trade-offs for black and black-white pebbling for various
parameter settings. Both of our contributions have been instrumental in
obtaining the time-space trade-off results for resolution-based proof systems
in [Ben-Sasson and Nordstrom 2009].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3056</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3056</id><created>2010-03-15</created><authors><author><keyname>Louie</keyname><forenames>Raymond H. Y.</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Collings</keyname><forenames>Iain B.</forenames></author></authors><title>Spatial multiplexing with MMSE receivers: Single-stream optimality in ad
  hoc networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to IEEE Globecom 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of spatial multiplexing systems with linear
minimum-mean-squared-error receivers is investigated in ad hoc networks. It is
shown that single-stream transmission is preferable over multi-stream
transmission, due to the weaker interference powers from the strongest
interferers remaining after interference-cancelation. This result is obtained
by new exact closed-form expressions we derive for the outage probability and
transmission capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3080</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3080</id><created>2010-03-16</created><authors><author><keyname>Muslim</keyname><forenames>A.</forenames></author><author><keyname>Mutiara</keyname><forenames>A. B.</forenames></author><author><keyname>Karyati</keyname><forenames>C. M.</forenames></author><author><keyname>Musa</keyname><forenames>P.</forenames></author></authors><title>An Algorithm for Index Multimedia Data (Video) using the Movement
  Oriented Method for Real-time Online Services</title><categories>cs.MM cs.IR</categories><comments>5 pages, International Conference on Robotics, Informatics,
  Intelligence control system Technologies (RIIT'09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimedia data is a form of data that can represent all types of data
(images, sound and text). The use of multimedia data for the online application
requires a more comprehensive database in the use of storage media, Sorting /
indexing, search and system / data searching. This is necessary in order to
help providers and users to access multimedia data online. Systems that use of
the index image as a reference requires storage media so that the rules and
require special expertise to obtain the desired file. Changes in multimedia
data into a series of stories / storyboard in the form of a text will help
reduce the consumption of media storage, system index / sorting and search
applications. Oriented Movement is one method that is being developed to change
the form of multimedia data into a storyboard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3082</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3082</id><created>2010-03-16</created><authors><author><keyname>Banowosari</keyname><forenames>L. Y.</forenames></author><author><keyname>Wicaksana</keyname><forenames>I. W. S.</forenames></author><author><keyname>Mutiara</keyname><forenames>A. B.</forenames></author></authors><title>Agreement Maintenance Based on Schema and Ontology Change in P2P
  Environment</title><categories>cs.AI cs.DB</categories><comments>6 pages, the *11th Annual International Seminar on Global Meltdown or
  Recession: India vis-\`a-vis the rest of the world, January 4-5, 2010 at New
  Delhi.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concern about developing a semantic agreement maintenance
method based on semantic distance by calculating the change of local schema or
ontology. This approach is important in dynamic and autonomous environment, in
which the current approach assumed that agreement or mapping in static
environment. The contribution of this research is to develop a framework based
on semantic agreement maintenance approach for P2P environment. This framework
based on two level hybrid P2P model architecture, which consist of two peer
type: (1) super peer that use to register and manage the other peers, and (2)
simple peer, as a simple peer, it exports and shares its contents with others.
This research develop a model to maintain the semantic agreement in P2P
environment, so the current approach which does not have the mechanism to know
the change, since it assumed that ontology and local schema are in the static
condition, and it is different in dynamic condition. The main issues are how to
calculate the change of local schema or common ontology and the calculation
result is used to determine which algorithm in maintaining the agreement. The
experiment on the job matching domain in Indonesia have been done to show how
far the performance of the approach. From the experiment, the main result are
(i) the more change so the F-measure value tend to be decreased, (ii) there is
no significant different in F-measure value for various modification type (add,
delete, rename), and (iii) the correct choice of algorithm would improve the
F-measure value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3085</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3085</id><created>2010-03-16</created><authors><author><keyname>Babenko</keyname><forenames>Maxim</forenames></author><author><keyname>Kolesnichenko</keyname><forenames>Ignat</forenames></author><author><keyname>Razenshteyn</keyname><forenames>Ilya</forenames></author></authors><title>A Linear Time Algorithm for Finding Three Edge-Disjoint Paths in
  Eulerian Networks</title><categories>math.CO cs.DS</categories><comments>SOFSEM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider an undirected graph $G = (VG, EG)$ and a set of six \emph{terminals}
$T = \set{s_1, s_2, s_3, t_1, t_2, t_3} \subseteq VG$. The goal is to find a
collection $\calP$ of three edge-disjoint paths $P_1$, $P_2$, and $P_3$, where
$P_i$ connects nodes $s_i$ and $t_i$ ($i = 1, 2, 3$). Results obtained by
Robertson and Seymour by graph minor techniques imply a polynomial time
solvability of this problem. The time bound of their algorithm is $O(m^3)$
(hereinafter we assume $n := \abs{VG}$, $m := \abs{EG}$, $n = O(m)$). In this
paper we consider a special, \emph{Eulerian} case of $G$ and $T$. Namely,
construct the \emph{demand graph} $H = (VG, \set{s_1t_1, s_2t_2, s_3t_3})$. The
edges of $H$ correspond to the desired paths in $\calP$. In the Eulerian case
the degrees of all nodes in the (multi-) graph $G + H$ ($ = (VG, EG \cup EH)$)
are even. Schrijver showed that, under the assumption of Eulerianess, cut
conditions provide a criterion for the existence of $\calP$. This, in
particular, implies that checking for existence of $\calP$ can be done in
$O(m)$ time. Our result is a combinatorial $O(m)$-time algorithm that
constructs $\calP$ (if the latter exists).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3090</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3090</id><created>2010-03-16</created><authors><author><keyname>Babu</keyname><forenames>A. V.</forenames><affiliation>National Institute of Technology Calicut, India</affiliation></author><author><keyname>Singh</keyname><forenames>Mukesh Kumar</forenames><affiliation>National Institute of Technology Calicut, India</affiliation></author></authors><title>Node Isolation Probability of Wireless Adhoc Networks in Nagakami Fading
  Channel</title><categories>cs.NI</categories><comments>16 pages, IJCNC Journal</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 21-36</journal-ref><doi>10.5121/ijcnc.2010.2202</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper investigates the issue of connectivity of a wireless adhoc network
in the presence of channel impairments. We derive analytical expressions for
the node isolation probability in an adhoc network in the presence of
Nakagami-m fading with superimposed lognormal shadowing. The node isolation
probability is the probability that a randomly chosen node is not able to
communicate with none of the other nodes in the network. An extensive
investigation into the impact of path loss exponent, lognormal shadowing,
Nakagami fading severity index, node density, and diversity order on the node
isolation probability is conducted. The presented results are beneficial for
the practical design of ad hoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3091</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3091</id><created>2010-03-16</created><authors><author><keyname>Ribeiro</keyname><forenames>Cristina</forenames><affiliation>University of Guelph, Canada and</affiliation></author><author><keyname>Ferworn</keyname><forenames>Alexander</forenames><affiliation>Ryerson University, Toronto, Canada</affiliation></author><author><keyname>Tran</keyname><forenames>Jimmy</forenames><affiliation>Ryerson University, Toronto, Canada</affiliation></author></authors><title>Wireless Mesh Network Performance for Urban Search and Rescue Missions</title><categories>cs.NI</categories><comments>19 Pages, IJCNC Journal</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 38-57</journal-ref><doi>10.5121/ijcnc.2010.2203</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we demonstrate that the Canine Pose Estimation (CPE) system can
provide a reliable estimate for some poses and when coupled with effective
wireless transmission over a mesh network. Pose estimates are time sensitive,
thus it is important that pose data arrives at its destination quickly.
Propagation delay and packet delivery ratio measuring algorithms were developed
and used to appraise Wireless Mesh Network (WMN) performance as a means of
carriage for this time-critical data. The experiments were conducted in the
rooms of a building where the radio characteristics closely resembled those of
a partially collapsed building-a typical US&amp;R environment. This paper presents
the results of the experiments, which demonstrate that it is possible to
receive the canine pose estimation data in realtime although accuracy of the
results depend on the network size and the deployment environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3092</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3092</id><created>2010-03-16</created><authors><author><keyname>Amar</keyname><forenames>Ebtisam</forenames><affiliation>University of Pierre and Marie Curie, France</affiliation></author><author><keyname>Boumerdassi</keyname><forenames>Selma</forenames><affiliation>CNAM - CEDRIC, France</affiliation></author><author><keyname>Renault</keyname><forenames>&#xc9;ric</forenames><affiliation>Institut T&#xe9;l&#xe9;com - T&#xe9;l&#xe9;com SudParis, France and</affiliation><affiliation>Samovar UMR INT-CNRS, France</affiliation></author></authors><title>Hierarchical Location Service with Prediction in Mobile Ad-Hoc Networks</title><categories>cs.NI</categories><comments>14 Pages, IJCNC Journal</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 59-72</journal-ref><doi>10.5121/ijcnc.2010.2204</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Position-based routing protocols take advantage of location information to
perform a stateless and efficient routing. To enable position-based routing, a
node must be able to discover the location of the messages' destination node.
This task is typically accomplished by a location service. Recently, several
location service protocols have been developed for ad hoc networks. In this
paper we propose a novel location service called PHLS: Predictive Hierarchical
Location Service. In PHLS, the entire network is partitioned into a hierarchy
of smaller and smaller regions. For each node, one node in each-level region of
the hierarchy is chosen as its local location server. When the network
initializes or when a node attaches the network, nodes contact their local
location server with their current location information (ie. position and
velocity). Then, they only need to update their location server when they move
away from their current region. Finally, nodes query their location servers and
get the exact or predicted location of destination nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3094</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3094</id><created>2010-03-16</created><authors><author><keyname>Malayeri</keyname><forenames>A. Daneshmand</forenames></author><author><keyname>Abdollahi</keyname><forenames>J.</forenames></author><author><keyname>Rezaei</keyname><forenames>R.</forenames></author></authors><title>Graphically E-Learning introduction and its benefits in Virtual Learning</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E-learning with using multimedia and graphical interfaces is now fashionable
in some virtual learning environments. Especially, in open colleges,
universities and E-learning databases, using these interfaces can improve
quality of educating by increasing attraction of educational subjects. In this
paper, we introduce this technology and its aspects by defining some Graphical
User Interfaces (GUI). Improving some indexes in E-learning environments can be
measured by using GUI. Adding some plug-ins in E-learning softwares and
environments like relative sound, electronic noting paper and virtual
classrooms can be created by E-learning GUI (ELGUI) as explain in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3097</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3097</id><created>2010-03-16</created><authors><author><keyname>Malayeri</keyname><forenames>Amin Daneshmand</forenames></author><author><keyname>Abdollahi</keyname><forenames>Jalal</forenames></author></authors><title>New designing of E-Learning systems with using network learning</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most applied learning in virtual spaces is using E-Learning
systems. Some E-Learning methodologies has been introduced, but the main
subject is the most positive feedback from E-Learning systems. In this paper,
we introduce a new methodology of E-Learning systems entitle &quot;Network Learning&quot;
with review of another aspects of E-Learning systems. Also, we present benefits
and advantages of using these systems in educating and fast learning programs.
Network Learning can be programmable for every education system and it is
flexible with too positive results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3103</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3103</id><created>2010-03-16</created><authors><author><keyname>Durand</keyname><forenames>Bruno</forenames></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>Effective closed subshifts in 1D can be implemented in 2D</title><categories>cs.LO cs.DM math.CO math.DS</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we use fixed point tilings to answer a question posed by
Michael Hochman and show that every one-dimensional effectively closed subshift
can be implemented by a local rule in two dimensions. The proof uses the
fixed-point construction of an aperiodic tile set and its extensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3131</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3131</id><created>2010-03-16</created><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author></authors><title>Strategic Cooperation in Cost Sharing Games</title><categories>cs.GT cs.DS cs.MA</categories><comments>17 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider strategic cost sharing games with so-called
arbitrary sharing based on various combinatorial optimization problems, such as
vertex and set cover, facility location, and network design problems. We
concentrate on the existence and computational complexity of strong equilibria,
in which no coalition can improve the cost of each of its members. Our main
result reveals a connection between strong equilibrium in strategic games and
the core in traditional coalitional cost sharing games studied in economics.
For set cover and facility location games this results in a tight
characterization of the existence of strong equilibrium using the integrality
gap of suitable linear programming formulations. Furthermore, it allows to
derive all existing results for strong equilibria in network design cost
sharing games with arbitrary sharing via a unified approach. In addition, we
are able to show that in general the strong price of anarchy is always 1. This
should be contrasted with the price of anarchy of \Theta(n) for Nash
equilibria. Finally, we indicate that the LP-approach can also be used to
compute near-optimal and near-stable approximate strong equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3139</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3139</id><created>2010-03-16</created><updated>2010-04-13</updated><authors><author><keyname>Cali</keyname><forenames>Andrea</forenames></author><author><keyname>Martinenghi</keyname><forenames>Davide</forenames></author></authors><title>Querying Incomplete Data over Extended ER Schemata</title><categories>cs.DB cs.LO</categories><comments>40 pages, 1 figure.</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since Chen's Entity-Relationship (ER) model, conceptual modeling has been
playing a fundamental role in relational data design. In this paper we consider
an extended ER (EER) model enriched with cardinality constraints, disjointness
assertions, and is-a relations among both entities and relationships. In this
setting, we consider the case of incomplete data, which is likely to occur, for
instance, when data from different sources are integrated. In such a context,
we address the problem of providing correct answers to conjunctive queries by
reasoning on the schema. Based on previous results about decidability of the
problem, we provide a query answering algorithm that performs rewriting of the
initial query into a recursive Datalog query encoding the information about the
schema. We finally show extensions to more general settings. This paper will
appear in the special issue of Theory and Practice of Logic Programming (TPLP)
titled Logic Programming in Databases: From Datalog to Semantic-Web Rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3181</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3181</id><created>2010-03-16</created><authors><author><keyname>Hou</keyname><forenames>Xiaorong</forenames></author><author><keyname>Shao</keyname><forenames>Junwei</forenames></author></authors><title>Stability Analysis of Linear Uncertain Systems via Checking Positivity
  of Forms on Simplices</title><categories>cs.SC math.DS</categories><comments>8 pages.</comments><msc-class>34D10, 34D20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we mainly study the robust stability of linear continuous
systems with parameter uncertainties, a more general kind of uncertainties for
system matrices is considered, i.e., entries of system matrices are rational
functions of uncertain parameters which are varying in intervals. we present a
method which can check the robust Hurwitz stability of such uncertain systems
in finite steps. Examples show the efficiency of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3195</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3195</id><created>2010-03-16</created><updated>2010-10-29</updated><authors><author><keyname>Cubitt</keyname><forenames>Toby S.</forenames></author><author><keyname>Leung</keyname><forenames>Debbie</forenames></author><author><keyname>Matthews</keyname><forenames>William</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Zero-error channel capacity and simulation assisted by non-local
  correlations</title><categories>quant-ph cs.IT math.IT</categories><comments>18 pages, 1 figure. Small changes to text in v2. Removed an
  unnecessarily strong requirement in the premise of Theorem 11</comments><journal-ref>IEEE Trans. Info. Theory, Volume 57, Issue 8, pages 5509 - 5523
  (Aug 2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shannon's theory of zero-error communication is re-examined in the broader
setting of using one classical channel to simulate another exactly, and in the
presence of various resources that are all classes of non-signalling
correlations: Shared randomness, shared entanglement and arbitrary
non-signalling correlations. Specifically, when the channel being simulated is
noiseless, this reduces to the zero-error capacity of the channel, assisted by
the various classes of non-signalling correlations. When the resource channel
is noiseless, it results in the &quot;reverse&quot; problem of simulating a noisy channel
exactly by a noiseless one, assisted by correlations. In both cases, 'one-shot'
separations between the power of the different assisting correlations are
exhibited. The most striking result of this kind is that entanglement can
assist in zero-error communication, in stark contrast to the standard setting
of communicaton with asymptotically vanishing error in which entanglement does
not help at all. In the asymptotic case, shared randomness is shown to be just
as powerful as arbitrary non-signalling correlations for noisy channel
simulation, which is not true for the asymptotic zero-error capacities. For
assistance by arbitrary non-signalling correlations, linear programming
formulas for capacity and simulation are derived, the former being equal (for
channels with non-zero unassisted capacity) to the feedback-assisted zero-error
capacity originally derived by Shannon to upper bound the unassisted zero-error
capacity. Finally, a kind of reversibility between non-signalling-assisted
capacity and simulation is observed, mirroring the famous &quot;reverse Shannon
theorem&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3242</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3242</id><created>2010-03-16</created><updated>2010-03-23</updated><authors><author><keyname>Castelluccia</keyname><forenames>Claude</forenames></author><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Perito</keyname><forenames>Daniele</forenames></author></authors><title>Private Information Disclosure from Web Searches. (The case of Google
  Web History)</title><categories>cs.CR</categories><comments>Our report was sent to Google on February 23rd, 2010. Google is
  investigating the problem and has decided to temporarily suspend search
  suggestions from Search History. Furthermore, Google Web History page is now
  offered over HTTPS only. Updated information about this project is available
  at:
  http://planete.inrialpes.fr/projects/private-information-disclosure-from-web-searches</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the amount of personal information stored at remote service providers
increases, so does the danger of data theft. When connections to remote
services are made in the clear and authenticated sessions are kept using HTTP
cookies, data theft becomes extremely easy to achieve. In this paper, we study
the architecture of the world's largest service provider, i.e., Google. First,
with the exception of a few services that can only be accessed over HTTPS
(e.g., Gmail), we find that many Google services are still vulnerable to simple
session hijacking. Next, we present the Historiographer, a novel attack that
reconstructs the web search history of Google users, i.e., Google's Web
History, even though such a service is supposedly protected from session
hijacking by a stricter access control policy. The Historiographer uses a
reconstruction technique inferring search history from the personalized
suggestions fed by the Google search engine. We validate our technique through
experiments conducted over real network traffic and discuss possible
countermeasures. Our attacks are general and not only specific to Google, and
highlight privacy concerns of mixed architectures using both secure and
insecure connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3266</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3266</id><created>2010-03-16</created><authors><author><keyname>Sofina</keyname><forenames>Olga</forenames></author><author><keyname>Bunyak</keyname><forenames>Yuriy</forenames></author><author><keyname>Kvetnyy</keyname><forenames>Roman</forenames></author></authors><title>Pattern recognition using inverse resonance filtration</title><categories>cs.CV</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approach to textures pattern recognition based on inverse resonance
filtration (IRF) is considered. A set of principal resonance harmonics of
textured image signal fluctuations eigen harmonic decomposition (EHD) is used
for the IRF design. It was shown that EHD is invariant to textured image linear
shift. The recognition of texture is made by transfer of its signal into
unstructured signal which simple statistical parameters can be used for texture
pattern recognition. Anomalous variations of this signal point on foreign
objects. Two methods of 2D EHD parameters estimation are considered with the
account of texture signal breaks presence. The first method is based on the
linear symmetry model that is not sensitive to signal phase jumps. The
condition of characteristic polynomial symmetry provides the model stationarity
and periodicity. Second method is based on the eigenvalues problem of matrices
pencil projection into principal vectors space of singular values decomposition
(SVD) of 2D correlation matrix. Two methods of classification of retrieval from
textured image foreign objects are offered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3275</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3275</id><created>2010-03-16</created><updated>2010-03-18</updated><authors><author><keyname>Chiniforooshan</keyname><forenames>Ehsan</forenames></author><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Kari</keyname><forenames>Lila</forenames></author><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames></author></authors><title>Scalable, Time-Responsive, Digital, Energy-Efficient Molecular Circuits
  using DNA Strand Displacement</title><categories>cs.OH</categories><comments>version 2: the paper itself is unchanged from version 1, but the
  arXiv software stripped some asterisk characters out of the abstract whose
  purpose was to highlight words. These characters have been replaced with
  underscores in version 2. The arXiv software also removed the second
  paragraph of the abstract, which has been (attempted to be) re-inserted.
  Also, although the secondary subject is &quot;Soft Condensed Matter&quot;, this
  classification was chosen by the arXiv moderators after submission, not
  chosen by the authors. The authors consider this submission to be a
  theoretical computer science paper.</comments><acm-class>F.1.1</acm-class><doi>10.1007/978-3-642-18305-8_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel theoretical biomolecular design to implement any Boolean
circuit using the mechanism of DNA strand displacement. The design is scalable:
all species of DNA strands can in principle be mixed and prepared in a single
test tube, rather than requiring separate purification of each species, which
is a barrier to large-scale synthesis. The design is time-responsive: the
concentration of output species changes in response to the concentration of
input species, so that time-varying inputs may be continuously processed. The
design is digital: Boolean values of wires in the circuit are represented as
high or low concentrations of certain species, and we show how to construct a
single-input, single-output signal restoration gate that amplifies the
difference between high and low, which can be distributed to each wire in the
circuit to overcome signal degradation. This means we can achieve a digital
abstraction of the analog values of concentrations. Finally, the design is
energy-efficient: if input species are specified ideally (meaning absolutely 0
concentration of unwanted species), then output species converge to their ideal
concentrations at steady-state, and the system at steady-state is in (dynamic)
equilibrium, meaning that no energy is consumed by irreversible reactions until
the input again changes.
  Drawbacks of our design include the following. If input is provided
non-ideally (small positive concentration of unwanted species), then energy
must be continually expended to maintain correct output concentrations even at
steady-state. In addition, our fuel species - those species that are
permanently consumed in irreversible reactions - are not &quot;generic&quot;; each gate
in the circuit is powered by its own specific type of fuel species. Hence
different circuits must be powered by different types of fuel. Finally, we
require input to be given according to the dual-rail convention, so that an
input of 0 is specified not only by the absence of a certain species, but by
the presence of another. That is, we do not construct a &quot;true NOT gate&quot; that
sets its output to high concentration if and only if its input's concentration
is low. It remains an open problem to design scalable, time-responsive,
digital, energy-efficient molecular circuits that additionally solve one of
these problems, or to prove that some subset of their resolutions are mutually
incompatible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3279</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3279</id><created>2010-03-16</created><authors><author><keyname>Mucherino</keyname><forenames>Antonio</forenames></author><author><keyname>Cafieri</keyname><forenames>Sonia</forenames></author></authors><title>A New Heuristic for Feature Selection by Consistent Biclustering</title><categories>cs.LG cs.DM math.CO</categories><acm-class>H.2.8; G.1.6; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of data, biclustering aims at finding simultaneous partitions in
biclusters of its samples and of the features which are used for representing
the samples. Consistent biclusterings allow to obtain correct classifications
of the samples from the known classification of the features, and vice versa,
and they are very useful for performing supervised classifications. The problem
of finding consistent biclusterings can be seen as a feature selection problem,
where the features that are not relevant for classification purposes are
removed from the set of data, while the total number of features is maximized
in order to preserve information. This feature selection problem can be
formulated as a linear fractional 0-1 optimization problem. We propose a
reformulation of this problem as a bilevel optimization problem, and we present
a heuristic algorithm for an efficient solution of the reformulated problem.
Computational experiments show that the presented algorithm is able to find
better solutions with respect to the ones obtained by employing previously
presented heuristic algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3299</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3299</id><created>2010-03-17</created><updated>2010-03-19</updated><authors><author><keyname>Bah</keyname><forenames>Bubacarr</forenames></author><author><keyname>Tanner</keyname><forenames>Jared</forenames></author></authors><title>Improved Bounds on Restricted Isometry Constants for Gaussian Matrices</title><categories>cs.IT math.CO math.IT math.NA</categories><comments>16 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Restricted Isometry Constants (RIC) of a matrix $A$ measures how close to
an isometry is the action of $A$ on vectors with few nonzero entries, measured
in the $\ell^2$ norm. Specifically, the upper and lower RIC of a matrix $A$ of
size $n\times N$ is the maximum and the minimum deviation from unity (one) of
the largest and smallest, respectively, square of singular values of all
${N\choose k}$ matrices formed by taking $k$ columns from $A$. Calculation of
the RIC is intractable for most matrices due to its combinatorial nature;
however, many random matrices typically have bounded RIC in some range of
problem sizes $(k,n,N)$. We provide the best known bound on the RIC for
Gaussian matrices, which is also the smallest known bound on the RIC for any
large rectangular matrix. Improvements over prior bounds are achieved by
exploiting similarity of singular values for matrices which share a substantial
number of columns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3305</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3305</id><created>2010-03-17</created><authors><author><keyname>Khemakhem</keyname><forenames>Maher</forenames></author><author><keyname>Belghith</keyname><forenames>Abdelfettah</forenames></author><author><keyname>University</keyname><forenames>Sousse</forenames></author><author><keyname>Tunisia</keyname></author><author><keyname>University</keyname><forenames>Manouba</forenames></author><author><keyname>Tunisia)</keyname></author></authors><title>Towards trusted volunteer grid environments</title><categories>cs.DC</categories><comments>9 Pages, IJCNC Journal 2010</comments><doi>10.5121/ijcnc.2010.2207</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Intensive experiences show and confirm that grid environments can be
considered as the most promising way to solve several kinds of problems
relating either to cooperative work especially where involved collaborators are
dispersed geographically or to some very greedy applications which require
enough power of computing or/and storage. Such environments can be classified
into two categories; first, dedicated grids where the federated computers are
solely devoted to a specific work through its end. Second, Volunteer grids
where federated computers are not completely devoted to a specific work but
instead they can be randomly and intermittently used, at the same time, for any
other purpose or they can be connected or disconnected at will by their owners
without any prior notification. Each category of grids includes surely several
advantages and disadvantages; nevertheless, we think that volunteer grids are
very promising and more convenient especially to build a general multipurpose
distributed scalable environment. Unfortunately, the big challenge of such
environments is, however, security and trust. Indeed, owing to the fact that
every federated computer in such an environment can randomly be used at the
same time by several users or can be disconnected suddenly, several security
problems will automatically arise. In this paper, we propose a novel solution
based on identity federation, agent technology and the dynamic enforcement of
access control policies that lead to the design and implementation of trusted
volunteer grid environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3307</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3307</id><created>2010-03-17</created><authors><author><keyname>Mehta</keyname><forenames>S.</forenames><affiliation>Inha University, Korea</affiliation></author><author><keyname>Kwak</keyname><forenames>K. S.</forenames><affiliation>Inha University, Korea</affiliation></author></authors><title>H-MAC: A Hybrid MAC Protocol for Wireless Sensor Networks</title><categories>cs.NI</categories><comments>10 pages, IJCNC Journal 2010</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 108-117</journal-ref><doi>10.5121/ijcnc.2010.2208</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we propose a hybrid medium access control protocol (H-MAC) for
wireless sensor networks. It is based on the IEEE 802.11's power saving
mechanism (PSM) and slotted aloha, and utilizes multiple slots dynamically to
improve performance. Existing MAC protocols for sensor networks reduce energy
consumptions by introducing variation in an active/sleep mechanism. But they
may not provide energy efficiency in varying traffic conditions as well as they
did not address Quality of Service (QoS) issues. H-MAC, the propose MAC
protocol maintains energy efficiency as well as QoS issues like latency,
throughput, and channel utilization. Our numerical results show that H-MAC has
significant improvements in QoS parameters than the existing MAC protocols for
sensor networks while consuming comparable amount of energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3310</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3310</id><created>2010-03-17</created><authors><author><keyname>Bhanja</keyname><forenames>Urmila</forenames><affiliation>Indian Institute of Technology, Kharagpur, India</affiliation></author><author><keyname>Mahapatra</keyname><forenames>Sudipta</forenames><affiliation>Indian Institute of Technology, Kharagpur, India</affiliation></author><author><keyname>Roy</keyname><forenames>Rajarshi</forenames><affiliation>Indian Institute of Technology, Kharagpur, India</affiliation></author></authors><title>A Novel Solution to the Dynamic Routing and Wavelength Assignment
  Problem in Transparent Optical Networks</title><categories>cs.NI</categories><comments>12 Pages, IJCNC Journal 2010</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 119-130</journal-ref><doi>10.5121/ijcnc.2010.2209</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present an evolutionary programming algorithm for solving the dynamic
routing and wavelength assignment (DRWA) problem in optical wavelength-division
multiplexing (WDM) networks under wavelength continuity constraint. We assume
an ideal physical channel and therefore neglect the blocking of connection
requests due to the physical impairments. The problem formulation includes
suitable constraints that enable the algorithm to balance the load among the
individuals and thus results in a lower blocking probability and lower mean
execution time than the existing bio-inspired algorithms available in the
literature for the DRWA problems. Three types of wavelength assignment
techniques, such as First fit, Random, and Round Robin wavelength assignment
techniques have been investigated here. The ability to guarantee both low
blocking probability without any wavelength converters and small delay makes
the improved algorithm very attractive for current optical switching networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3311</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3311</id><created>2010-03-17</created><authors><author><keyname>Al-Mogren</keyname><forenames>Ahmad Saad</forenames><affiliation>King Saud University, Saudi Arabia</affiliation></author></authors><title>A Powerful Optimization Approach for the Multi Channel Dissemination
  Networks</title><categories>cs.NI</categories><comments>9 Pages, IJCNC Journal 2010</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 132-140</journal-ref><doi>10.5121/ijcnc.2010.2210</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In the wireless environment, dissemination techniques may improve data access
for the users. In this paper, we show a description of dissemination
architecture that fits the overall telecommunication network. This architecture
is designed to provide efficient data access and power saving for the mobile
units. A concurrency control approach, MCD, is suggested for data consistency
and conflict checking. A performance study shows that the power consumption,
space overhead, and response time associated with MCD is far less than other
previous techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3312</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3312</id><created>2010-03-17</created><authors><author><keyname>Ali</keyname><forenames>G. G. Md. Nawaz</forenames><affiliation>City University of Hong Kong, China and</affiliation></author><author><keyname>Chakraborty</keyname><forenames>Rajib</forenames><affiliation>Khulna University of Engineering &amp; Technology, Bangladesh</affiliation></author><author><keyname>Alam</keyname><forenames>Md. Shihabul</forenames><affiliation>Khulna University of Engineering &amp; Technology, Bangladesh</affiliation></author><author><keyname>Chan</keyname><forenames>Edward</forenames><affiliation>City University of Hong Kong, China and</affiliation></author></authors><title>An Efficient Approach for Generalized Load Balancing in Multipath Packet
  Switched Networks</title><categories>cs.NI</categories><comments>12 Pages, IJCNC Journal 2010</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 142-153</journal-ref><doi>10.5121/ijcnc.2010.2211</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper is a quantitative analysis on packet switched network with a view
to generalize load balancing and determination of appropriate routing algorithm
in multipath environment. Several routing algorithms have been introduced for
routing of packets from source to destination. Some of them route packets
accurately with increased workload and some of them drastically cut down the
workload. A few of them can find out a minimum workload deviation for both UDP
and TCP packets. We simulated these approaches in a well defined simulator,
analyzed and evaluated their performance. After expanding our analysis with
varying weights and number of paths we found that the recently proposed routing
algorithm Mixed Weighted Fair Routing (MWFR) outperforms the existing routing
algorithms by reducing the routing and network overhead and saving the scarce
bandwidth as well as CPU consumption for packet switching networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3317</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3317</id><created>2010-03-17</created><authors><author><keyname>Ling</keyname><forenames>Zhou</forenames><affiliation>Central South University, P.R.China and</affiliation></author><author><keyname>Wei-xiong</keyname><forenames>Ding</forenames><affiliation>Foshan University, P.R. China</affiliation></author><author><keyname>Yu-xi</keyname><forenames>Zhu</forenames><affiliation>Foshan University, P.R. China</affiliation></author></authors><title>Delay-Constrained Multicast Routing Algorithm Based on Average Distance
  Heuristic</title><categories>cs.NI</categories><comments>8 Pages, IJCNC Journal 2010</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 155-162</journal-ref><doi>10.5121/ijcnc.2010.2212</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Multicast is the ability of a communication network to accept a single
message from an application and to deliver copies of the message to multiple
recipients at different location. With the development of Internet, Multicast
is widely applied in all kinds of multimedia real-time application: distributed
multimedia systems, collaborative computing, video-conferencing, distance
education, etc. In order to construct a delay-constrained multicast routing
tree, average distance heuristic (ADH) algorithm is analyzed firstly. Then a
delay-constrained algorithm called DCADH (delay-constrained average distance
heuristic) is presented. By using ADH a least cost multicast routing tree can
be constructed; if the path delay can't meet the delay upper bound, a shortest
delay path which is computed by Dijkstra algorithm will be merged into the
existing multicast routing tree to meet the delay upper bound. Simulation
experiments show that DCADH has a good performance in achieving a low-cost
multicast routing tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3322</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3322</id><created>2010-03-17</created><authors><author><keyname>Zafoune</keyname><forenames>Youcef</forenames><affiliation>USTHB University, Algeria and</affiliation></author><author><keyname>Mokhtari</keyname><forenames>Aicha</forenames><affiliation>USTHB University, Algeria and</affiliation></author><author><keyname>kanawati</keyname><forenames>Rushed</forenames><affiliation>Institute Galilee, Paris13 University, Paris, French</affiliation></author></authors><title>Mobile Codes Localization in Ad hoc Networks: a Comparative Study of
  Centralized and Distributed Approaches</title><categories>cs.NI</categories><comments>14 Pages, IJCNC Journal 2010</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 164-177</journal-ref><doi>10.5121/ijcnc.2010.2213</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents a new approach in the management of mobile ad hoc
networks. Our alternative, based on mobile agent technology, allows the design
of mobile centralized server in ad hoc network, where it is not obvious to
think about a centralized management, due to the absence of any administration
or fixed infrastructure in these networks. The aim of this centralized approach
is to provide permanent availability of services in ad hoc networks which are
characterized by a distributed management. In order to evaluate the performance
of the proposed approach, we apply it to solve the problem of mobile code
localization in ad hoc networks. A comparative study, based upon a simulation,
of centralized and distributed localization protocols in terms of messages
number exchanged and response time shows that the centralized approach in a
distributed form is more interesting than a totally centralized approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3325</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3325</id><created>2010-03-17</created><authors><author><keyname>Abdelkader</keyname><forenames>K.</forenames></author><author><keyname>Broeckhove</keyname><forenames>J.</forenames></author><author><keyname>Vanmechelen</keyname><forenames>K.</forenames></author><author><keyname>Antwerp</keyname><forenames>University of</forenames></author><author><keyname>Belgium)</keyname></author></authors><title>Resource Pricing In A Dynamic Multi-Commodity Market For Computational
  Resources</title><categories>cs.GT cs.DC cs.NI</categories><comments>14 Pages, IJCNC Journal</comments><journal-ref>International Journal of Computer Networks &amp; Communications 2.2
  (2010) 74-87</journal-ref><doi>10.5121/ijcnc.2010.2205</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The adoption of market-based principles in resource management systems for
computational infrastructures such as grids and clusters allows for matching
demand and supply for resources in a utility maximizing manner. As such, they
offer a promise of producing more efficient resource allocations, compared to
traditional system-centric approaches that do not allow consumers and providers
to express their valuations for computational resources. In this paper, we
investigate the pricing of resources in grids through the use of a
computational commodity market of CPU resources, where resource prices are
determined through the computation of a supply-and-demand equilibrium. In
particular, we introduce several categories of CPUs characterized by their
execution speed. These differ in cost and performance but may be used
interchangeably in executing jobs and thus represent so-called substitutable
resources. We investigate the performance of the algorithms for computing the
supply-and-demand equilibrium in this multi-commodity setting under dynamically
varying consumer and provider populations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3326</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3326</id><created>2010-03-17</created><authors><author><keyname>Sharma</keyname><forenames>Abhishek</forenames><affiliation>Victoria University, Australia</affiliation></author><author><keyname>Shi</keyname><forenames>Hao</forenames><affiliation>Victoria University, Australia</affiliation></author></authors><title>Innovative Rated-Resource Peer-to-Peer Network</title><categories>cs.NI</categories><comments>8 Pages, IJCNC Journal 2010</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.2 (2010) 89-96</journal-ref><doi>10.5121/ijcnc.2010.2206</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Peer-to-Peer (P2P) networks provide a significant solution for file sharing
among peers connected to Internet. It is fast and completely decentralised
system with robustness. But due to absence of a server documents on a P2P
network are not rated which makes it difficult for a peer to obtain precise
information in result of a query. In past, some researchers tried to attach
ratings to the peers itself but it was complex and less effective. In this
paper, a novel P2P architecture is proposed which attaches ratings to the
uploaded document directly. These ratings then become as &lt;Rating&gt; element in
its XML advertisement which has several child elements for information
classification. The attached &lt;Rating&gt; element is extracted from the
advertisement in real time and the document is then sorted accordingly.
Therefore, the information can be easily sorted based on a request by a peer
according to the relevance of matter. The information regarding relevance is
obtained by the peer issuing the query. This research leads to a smart P2P
model, the Rated-Resource P2P network (R2P2P).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3330</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3330</id><created>2010-03-17</created><authors><author><keyname>Mangler</keyname><forenames>Juergen</forenames></author><author><keyname>Stuermer</keyname><forenames>Gerhard</forenames></author><author><keyname>Schikuta</keyname><forenames>Erich</forenames></author></authors><title>Cloud Process Execution Engine - Evaluation of the Core Concepts</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this technical report we describe describe the Domain Specific Language
(DSL) of the Workflow Execution Execution (WEE). Instead of interpreting an XML
based workflow description language like BPEL, the WEE uses a minimized but
expressive set of statements that runs directly on to of a virtual machine that
supports the Ruby language.Frameworks/Virtual Machines supporting supporting
this language include Java, .NET and there exists also a standalone Virtual
Machine. Using a DSL gives us the advantage of maintaining a very compact code
base of under 400 lines of code, as the host programming language implements
all the concepts like parallelism, threads, checking for syntactic correctness.
The implementation just hooks into existing statements to keep track of the
workflow and deliver information about current existing context variables and
state to the environment that embeds WEE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3338</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3338</id><created>2010-03-17</created><authors><author><keyname>Bottoni</keyname><forenames>Paolo</forenames></author><author><keyname>Guerra</keyname><forenames>Esther</forenames></author><author><keyname>de Lara</keyname><forenames>Juan</forenames></author></authors><title>An Algebraic Formalization of the GoF Design Patterns</title><categories>cs.SE</categories><comments>17 pages and 41 figures. Supplementary material for the paper to
  appear in the Information and Software Technology Journal.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document reports on the use of an algebraic, visual, formal approach to
the specification of patterns for the formalization of the GoF design patterns.
The approach is based on graphs, morphisms and operations from category theory
and exploits triple graphs to annotate model elements with pattern roles. Being
based on category theory, the approach can be applied to formalize patterns in
different domains. Novel in our proposal is the possibility of describing
(nested) variable submodels, inter-pattern synchronization across several
diagrams (e.g. class and sequence diagrams for UML design patterns), pattern
composition, and conflict analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3362</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3362</id><created>2010-03-17</created><authors><author><keyname>Wang</keyname><forenames>Ge</forenames></author><author><keyname>Yang</keyname><forenames>Jiansheng</forenames></author></authors><title>Axiomatic Quantification of Co-authors' Relative Contributions</title><categories>stat.AP cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past decades, the competition for academic resources has gradually
intensified, and worsened with the current financial crisis. To optimize the
resource allocation, individualized assessment of research results is being
actively studied but the current indices, such as the number of papers, the
number of citations, the h-factor and its variants have limitations, especially
their inability of determining co-authors' credit shares fairly. Here we
establish an axiomatic system and quantify co-authors' relative contributions.
Our methodology avoids subjective assignment of co-authors' credits using the
inflated, fractional or harmonic methods, and provides a quantitative tool for
scientific management such as funding and tenure decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3370</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3370</id><created>2010-03-17</created><authors><author><keyname>Havinga</keyname><forenames>Yeb</forenames></author><author><keyname>Dijkstra</keyname><forenames>Willem</forenames></author><author><keyname>de Keijzer</keyname><forenames>Ander</forenames></author></authors><title>Adding HL7 version 3 data types to PostgreSQL</title><categories>cs.DB</categories><comments>12 pages, 9 figures, 6 tables</comments><msc-class>68N99</msc-class><acm-class>C.4; D.3.3; H.2.4; H.2.8; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The HL7 standard is widely used to exchange medical information
electronically. As a part of the standard, HL7 defines scalar communication
data types like physical quantity, point in time and concept descriptor but
also complex types such as interval types, collection types and probabilistic
types. Typical HL7 applications will store their communications in a database,
resulting in a translation from HL7 concepts and types into database types.
Since the data types were not designed to be implemented in a relational
database server, this transition is cumbersome and fraught with programmer
error. The purpose of this paper is two fold. First we analyze the HL7 version
3 data type definitions and define a number of conditions that must be met, for
the data type to be suitable for implementation in a relational database. As a
result of this analysis we describe a number of possible improvements in the
HL7 specification. Second we describe an implementation in the PostgreSQL
database server and show that the database server can effectively execute
scientific calculations with units of measure, supports a large number of
operations on time points and intervals, and can perform operations that are
akin to a medical terminology server. Experiments on synthetic data show that
the user defined types perform better than an implementation that uses only
standard data types from the database server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3384</identifier>
 <datestamp>2011-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3384</id><created>2010-03-17</created><updated>2011-09-22</updated><authors><author><keyname>Como</keyname><forenames>Giacomo</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author></authors><title>Scaling limits for continuous opinion dynamics systems</title><categories>math.PR cs.SI math.AP math.DS</categories><comments>Published at http://dx.doi.org/10.1214/10-AAP739 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP739</report-no><journal-ref>Annals of Applied Probability 2011, Vol. 21, No. 4, 1537-1567</journal-ref><doi>10.1214/10-AAP739</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scaling limits are analyzed for stochastic continuous opinion dynamics
systems, also known as gossip models. In such models, agents update their
vector-valued opinion to a convex combination (possibly agent- and
opinion-dependent) of their current value and that of another observed agent.
It is shown that, in the limit of large agent population size, the empirical
opinion density concentrates, at an exponential probability rate, around the
solution of a probability-measure-valued ordinary differential equation
describing the system's mean-field dynamics. Properties of the associated
initial value problem are studied. The asymptotic behavior of the solution is
analyzed for bounded-confidence opinion dynamics, and in the presence of an
heterogeneous influential environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3386</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3386</id><created>2010-03-17</created><authors><author><keyname>Martinez-Moro</keyname><forenames>Edgar</forenames></author><author><keyname>Ozadam</keyname><forenames>Hakan</forenames></author><author><keyname>Ozbudak</keyname><forenames>Ferruh</forenames></author><author><keyname>Szabo</keyname><forenames>Steve</forenames></author></authors><title>Monomial-like codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a generalization of cyclic codes of length p^s over F_{p^a}, we study
n-dimensional cyclic codes of length p^{s_1} X ... X p^{s_n} over F_{p^a}
generated by a single &quot;monomial&quot;. Namely, we study multi-variable cyclic codes
of the form &lt;(x_1 - 1)^{i_1} ... (x_n - 1)^{i_n}&gt; in F_{p^a}[x_1...x_n] / &lt;
x_1^{p^{s_1}}-1, ..., x_n^{p^{s_n}}-1 &gt;. We call such codes monomial-like
codes. We show that these codes arise from the product of certain single
variable codes and we determine their minimum Hamming distance. We determine
the dual of monomial-like codes yielding a parity check matrix. We also present
an alternative way of constructing a parity check matrix using the Hasse
derivative. We study the weight hierarchy of certain monomial like codes. We
simplify an expression that gives us the weight hierarchy of these codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3396</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3396</id><created>2010-03-17</created><authors><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Stability and Capacity Regions or Discrete Time Queueing Networks</title><categories>cs.NI</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider stability and network capacity in discrete time queueing systems.
Relationships between four common notions of stability are described.
Specifically, we consider rate stability, mean rate stability, steady state
stability, and strong stability. We then consider networks of queues with
random events and control actions that can be implemented over time to affect
arrivals and service at the queues. The control actions also generate a vector
of additional network attributes. We characterize the network capacity region,
being the closure of the set of all rate vectors that can be supported subject
to network stability and to additional time average attribute constraints. We
show that (under mild technical assumptions) the capacity region is the same
under all four stability definitions. Our capacity achievability proof uses the
drift-plus-penalty method of Lyapunov optimization, and provides full details
for the case when network states obey a decaying memory property, which holds
for finite state ergodic systems and more general systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3406</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3406</id><created>2010-03-17</created><authors><author><keyname>Khovanova</keyname><forenames>Tanya</forenames></author><author><keyname>Knop</keyname><forenames>Konstantin</forenames></author><author><keyname>Radul</keyname><forenames>Alexey</forenames></author></authors><title>Baron Munchhausen's Sequence</title><categories>math.CO cs.DM cs.DS math.HO</categories><comments>26 pages</comments><msc-class>11B99, 00A08, 00A08</msc-class><journal-ref>Journal of Integer Sequences, v.13 (2010), Article 10.8.7</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a coin-weighing puzzle that appeared in the all-Russian math
Olympiad in 2000. We liked the puzzle because the methods of analysis differ
from classical coin-weighing puzzles. We generalize the puzzle by varying the
number of participating coins, and deduce a complete solution, perhaps
surprisingly, the objective can be achieved in no more than two weighings
regardless of the number of coins involved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3418</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3418</id><created>2010-03-17</created><authors><author><keyname>Fearnley</keyname><forenames>John</forenames></author></authors><title>Exponential Lower Bounds For Policy Iteration</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study policy iteration for infinite-horizon Markov decision processes. It
has recently been shown policy iteration style algorithms have exponential
lower bounds in a two player game setting. We extend these lower bounds to
Markov decision processes with the total reward and average-reward optimality
criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3457</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3457</id><created>2010-03-17</created><authors><author><keyname>Al_Qaheri</keyname><forenames>Hameed</forenames></author><author><keyname>Dey</keyname><forenames>Sandipan</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Hiding Inside HTML and Other Source Codes</title><categories>cs.CR</categories><comments>10 Pages, 7 Figures, 2 Algorithms</comments><journal-ref>International Journal on Image Processing and Communications,
  Poland, Vol. 14, No. 2-3, pp. 59 - 68, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many steganographic techniques were proposed for hiding secret message inside
images, the simplest of them being the LSB data hiding. In this paper, we
suggest a novel data hiding technique in an HTML Web page and also propose some
simple techniques to extend the embedding technique to source codes written in
any programming language (both case insensitive like HTML, Pascal and case
sensitive languages like C, C++, Java). We basically try to exploit the
case-redundancy in case-insensitive language, while we try hiding data with
minimal changes in the source code (almost not raising suspicion). HTML Tags
are case insensitive and hence an alphabet in lowercase and one in uppercase
present inside an HTML tag are interpreted in the same manner by the browser,
i.e., change in case in a web page is imperceptible to the browser. We first
exploit this redundancy and use it to embed secret data inside an web page,
with no changes visible to the user of the web page, so that he can not even
suspect about the data hiding. The embedded data can be recovered by viewing
the source of the HTML page. This technique can easily be extended to embed
secret message inside any piece of source-code where the standard interpreter
of that language is case-insensitive. For case-sensitive programming languages
we do minimal changes in the source code (e.g., add an extra character in the
token identified by the lexical analyzer) without violating the lexical and
syntactic notation for that language) and try to make the change almost
imperceptible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3477</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3477</id><created>2010-03-17</created><authors><author><keyname>Bu&#x161;i&#x107;</keyname><forenames>Ana</forenames></author><author><keyname>Gupta</keyname><forenames>Varun</forenames></author><author><keyname>Mairesse</keyname><forenames>Jean</forenames></author></authors><title>Stability of the bipartite matching model</title><categories>cs.DM math.PR</categories><msc-class>60J10, 60K25, 68M20, 05C21</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the bipartite matching model of customers and servers introduced
by Caldentey, Kaplan, and Weiss (Adv. Appl. Probab., 2009). Customers and
servers play symmetrical roles. There is a finite set C resp. S, of customer,
resp. server, classes. Time is discrete and at each time step, one customer and
one server arrive in the system according to a joint probability measure on
CxS, independently of the past. Also, at each time step, pairs of matched
customer and server, if they exist, depart from the system. Authorized
matchings are given by a fixed bipartite graph. A matching policy is chosen,
which decides how to match when there are several possibilities.
Customers/servers that cannot be matched are stored in a buffer. The evolution
of the model can be described by a discrete time Markov chain. We study its
stability under various admissible matching policies including: ML (Match the
Longest), MS (Match the Shortest), FIFO (match the oldest), priorities. There
exist natural necessary conditions for stability (independent of the matching
policy) defining the maximal possible stability region. For some bipartite
graphs, we prove that the stability region is indeed maximal for any admissible
matching policy. For the ML policy, we prove that the stability region is
maximal for any bipartite graph. For the MS and priority policies, we exhibit a
bipartite graph with a non-maximal stability region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3478</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3478</id><created>2010-03-17</created><authors><author><keyname>Levandovskyy</keyname><forenames>Viktor</forenames></author><author><keyname>Mart&#xed;n-Morales</keyname><forenames>Jorge</forenames></author></authors><title>Algorithms for Checking Rational Roots of $b$-functions and their
  Applications</title><categories>math.AG cs.SC math.RA</categories><comments>26 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bernstein-Sato polynomial of a hypersurface is an important object with
numerous applications. It is known, that it is complicated to obtain it
computationally, as a number of open questions and challenges indicate. In this
paper we propose a family of algorithms called \texttt{checkRoot} for optimized
check of whether a given rational number is a root of Bernstein-Sato polynomial
and the computations of its multiplicity. This algorithms are used in the new
approach to compute the whole global or local Bernstein-Sato polynomial and
$b$-function of a holonomic ideal with respect to weights. They are applied in
numerous situations, where there is a possibility to compute an upper bound for
the polynomial. Namely, it can be achieved by means of embedded resolution, for
topologically equivalent singularities or using the formula of A'Campo and
spectral numbers. We also present approaches to the logarithmic comparison
problem and the intersection homology D-module. Several applications are
presented as well as solutions to some challenges which were intractable with
the classical methods. One of the main applications consists of computing of a
stratification of affine space with the local $b$-function being constant on
each stratum. Notably, the algorithm we propose does not employ primary
decomposition. Also we apply our results for the computation of Bernstein-Sato
polynomials for varieties. The methods from this paper have been implemented in
{\sc Singular:Plural} as libraries {\tt dmod.lib} and {\tt bfun.lib}. All the
examples from the paper have been computed with this implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3490</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3490</id><created>2010-03-17</created><authors><author><keyname>Panina</keyname><forenames>Gaiane</forenames></author><author><keyname>Streinu</keyname><forenames>Ileana</forenames></author></authors><title>Flattening single-vertex origami: the non-expansive case</title><categories>cs.CG math.DG math.MG</categories><comments>Accepted, to appear in Computational Geometry: Theory and
  applications.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single-vertex origami is a piece of paper with straight-line rays called
creases emanating from a fold vertex placed in its interior or on its boundary.
The Single-Vertex Origami Flattening problem asks whether it is always possible
to reconfigure the creased paper from any configuration compatible with the
metric, to a flat, non-overlapping position, in such a way that the paper is
not torn, stretched and, for rigid origami, not bent anywhere except along the
given creases.
  Streinu and Whiteley showed how to reduce the problem to the carpenter's rule
problem for spherical polygons. Using spherical expansive motions, they solved
the cases of open &lt; \pi and closed &lt;= 2\pi spherical polygons. Here, we solve
the case of open polygons with total length between [\pi, 2\pi), which requires
non-expansive motions. Our motion planning algorithm works in a finite number
of discrete steps, for which we give precise bounds depending on both the
number of links and the angle deficit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3492</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3492</id><created>2010-03-17</created><authors><author><keyname>Zhang</keyname><forenames>WeiGuo</forenames></author><author><keyname>Xiao</keyname><forenames>GuoZhen</forenames></author></authors><title>Generalized Maiorana-McFarland Constructions for Almost Optimal
  Resilient Functions</title><categories>cs.CR cs.IT math.CO math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper \cite{Zhang-Xiao}, Zhang and Xiao describe a technique on
constructing almost optimal resilient functions on even number of variables. In
this paper, we will present an extensive study of the constructions of almost
optimal resilient functions by using the generalized Maiorana-McFarland (GMM)
construction technique. It is shown that for any given $m$, it is possible to
construct infinitely many $n$-variable ($n$ even), $m$-resilient Boolean
functions with nonlinearity equal to $2^{n-1}-2^{n/2-1}-2^{k-1}$ where $k&lt;n/2$.
A generalized version of GMM construction is further described to obtain almost
optimal resilient functions with higher nonlinearity. We then modify the GMM
construction slightly to make the constructed functions satisfying strict
avalanche criterion (SAC). Furthermore we can obtain infinitely many new
resilient functions with nonlinearity $&gt;2^{n-2}-2^{(n-1)/2}$ ($n$ odd) by using
Patterson-Wiedemann functions or Kavut-Y$\ddot{u}$cel functions. Finally, we
provide a GMM construction technique for multiple-output almost optimal
$m$-resilient functions $F: \mathbb{F}_2^n\mapsto \mathbb{F}_2^r$ ($n$ even)
with nonlinearity $&gt;2^{n-1}-2^{n/2}$. Using the methods proposed in this paper,
a large class of previously unknown cryptographic resilient functions are
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3499</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3499</id><created>2010-03-17</created><authors><author><keyname>Rieffel</keyname><forenames>Eleanor G.</forenames></author><author><keyname>Kimber</keyname><forenames>Don</forenames></author><author><keyname>Vaughan</keyname><forenames>Jim</forenames></author></authors><title>Geometric reconstruction from point-normal data</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Creating virtual models of real spaces and objects is cumbersome and time
consuming. This paper focuses on the problem of geometric reconstruction from
sparse data obtained from certain image-based modeling approaches. A number of
elegant and simple-to-state problems arise concerning when the geometry can be
reconstructed. We describe results and counterexamples, and list open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3501</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3501</id><created>2010-03-17</created><updated>2010-03-21</updated><authors><author><keyname>Rebelatto</keyname><forenames>Jo&#xe3;o Luiz</forenames></author><author><keyname>Uch&#xf4;a-Filho</keyname><forenames>Bartolomeu F.</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Generalized Distributed Network Coding Based on Nonbinary Linear Block
  Codes for Multi-User Cooperative Communications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose and analyze a generalized construction of
distributed network codes for a network consisting of M users sending different
information to a common base station through independent block fading channels.
The aim is to increase the diversity order of the system without reducing its
code rate. The proposed scheme, called generalized dynamic network codes
(GDNC), is a generalization of the dynamic network codes (DNC) recently
proposed by Xiao and Skoglund. The design of the network codes that maximizes
the diversity order is recognized as equivalent to the design of linear block
codes over a nonbinary finite field under the Hamming metric. The proposed
scheme offers a much better tradeoff between rate and diversity order. An
outage probability analysis showing the improved performance is carried out,
and computer simulations results are shown to agree with the analytical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3507</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3507</id><created>2010-03-18</created><updated>2010-03-22</updated><authors><author><keyname>Ke</keyname><forenames>Lei</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>On the Degrees of Freedom Regions of Two-User MIMO Z and Full
  Interference Channels with Reconfigurable Antennas</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Globecom conference 2010. 5 pages. No figures.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the degrees of freedom (DoF) regions of two-user multiple-input
multiple-output (MIMO) Z and full interference channels in this paper. We
assume that the receivers always have perfect channel state information. We
derive the DoF region of Z interference channel with channel state information
at transmitter (CSIT). For full interference channel without CSIT, the DoF
region has been obtained in previous work except for a special case M1&lt;
N1&lt;min(M2,N2), where M_i and N_i are the number of transmit and receive
antennas of user i, respectively. We show that for this case the DoF regions of
the Z and full interference channels are the same. We establish the
achievability based on the assumption of transmitter antenna mode switching. A
systematic way of constructing the DoF-achieving nulling and beamforming
matrices is presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3508</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3508</id><created>2010-03-18</created><updated>2011-05-03</updated><authors><author><keyname>Dickenstein</keyname><forenames>Alicia</forenames></author><author><keyname>Tobis</keyname><forenames>Enrique A.</forenames></author></authors><title>Independent Sets from an Algebraic Perspective</title><categories>math.AC cs.CC math.CO</categories><comments>Final version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the basic problem of counting independent sets in a
graph and, in particular, the problem of counting antichains in a finite poset,
from an algebraic perspective. We show that neither independence polynomials of
bipartite Cohen-Macaulay graphs nor Hilbert series of initial ideals of radical
zero-dimensional complete intersections ideals, can be evaluated in polynomial
time, unless #P=P. Moreover, we present a family of radical zero-dimensional
complete intersection ideals J_P associated to a finite poset P, for which we
describe a universal Gr\&quot;obner basis. This implies that the bottleneck in
computing the dimension of the quotient by J_P (that is, the number of zeros of
J_P) using Gr\&quot;obner methods lies in the description of the standard monomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3530</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3530</id><created>2010-03-18</created><authors><author><keyname>Kannan</keyname><forenames>Rajkumar</forenames></author></authors><title>Topic Map: An Ontology Framework for Information Retrieval</title><categories>cs.DL cs.IR</categories><comments>National Conference on Advances in Knowledge Management(NCAKM'10),
  pp195-198, March 2010, India</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The basic classification techniques for organizing information are thesauri,
taxonomy and faceted classification. Topic map is relatively a new entrant to
this information space. Topic map standard describes how complex relationships
between abstract concepts and real world resources can be represented using XML
syntax. This paper explores how topic map incorporates the traditional
techniques and what are its advantages and disadvantages in several dimensions
such as content management, indexing, knowledge representation, constraint
specification and query languages in the context of information retrieval. The
constructs of topic maps are illustrated with a use-case implemented in XTM
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3533</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3533</id><created>2010-03-18</created><authors><author><keyname>Kannan</keyname><forenames>Rajkumar</forenames></author><author><keyname>Andres</keyname><forenames>Frederic</forenames></author></authors><title>Towards Automated Lecture Capture, Navigation and Delivery System for
  Web-Lecture on Demand</title><categories>cs.MM cs.IR</categories><comments>3rd International Conference on Data Management, March 2010, India</comments><journal-ref>Book Chapter in Innovations and Advances in Computer Science and
  Engineering, MacMillan Publishers, 386-394, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Institutions all over the world are continuously exploring ways to use ICT in
improving teaching and learning effectiveness. The use of course web pages,
discussion groups, bulletin boards, and e-mails have shown considerable impact
on teaching and learning in significant ways, across all disciplines. ELearning
has emerged as an alternative to traditional classroom-based education and
training and web lectures can be a powerful addition to traditional lectures.
They can even serve as a main content source for learning, provided users can
quickly navigate and locate relevant pages in a web lecture. A web lecture
consists of video and audio of the presenter and slides complemented with
screen capturing. In this paper, an automated approach for recording live
lectures and for browsing available web lectures for on-demand applications by
end users is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3536</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3536</id><created>2010-03-18</created><updated>2010-08-21</updated><authors><author><keyname>Jiang</keyname><forenames>Bin</forenames></author><author><keyname>Liu</keyname><forenames>Xintao</forenames></author></authors><title>Computing the Fewest-turn Map Directions based on the Connectivity of
  Natural Roads</title><categories>cs.CG cs.DB cs.DS</categories><comments>12 pages, 5 figures, and 4 tables, language editing, some significant
  revisions, missing references added</comments><journal-ref>International Journal of Geographical Information Science, 25(7),
  2011, 1069-1082</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduced a novel approach to computing the fewest-turn
map directions or routes based on the concept of natural roads. Natural roads
are joined road segments that perceptually constitute good continuity. This
approach relies on the connectivity of natural roads rather than that of road
segments for computing routes or map directions. Because of this, the derived
routes posses the fewest turns. However, what we intend to achieve are the
routes that not only possess the fewest turns, but are also as short as
possible. This kind of map direction is more effective and favorable by people,
because they bear less cognitive burden. Furthermore, the computation of the
routes is more efficient, since it is based on the graph encoding the
connectivity of roads, which is significantly smaller than the graph of road
segments. We made experiments applied to eight urban street networks from North
America and Europe in order to illustrate the above stated advantages. The
experimental results indicate that the fewest-turn routes posses fewer turns
and shorter distances than the simplest paths and the routes provided by Google
Maps. For example, the fewest-turn-and-shortest routes are on average 15%
shorter than the routes suggested by Google Maps, while the number of turns is
just half as much. This approach is a key technology behind FromToMap.org - a
web mapping service using openstreetmap data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3543</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3543</id><created>2010-03-18</created><updated>2010-03-26</updated><authors><author><keyname>Jafarizadeh</keyname><forenames>Saber</forenames></author></authors><title>Fastest Distributed Consensus Problem on Fusion of Two Star Networks</title><categories>cs.IT cs.DC math.IT</categories><comments>26 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding optimal weights for the problem of Fastest Distributed Consensus on
networks with different topologies has been an active area of research for a
number of years. Here in this work we present an analytical solution for the
problem of Fastest Distributed Consensus for a network formed from fusion of
two different symmetric star networks or in other words a network consists of
two different symmetric star networks which share the same central node. The
solution procedure consists of stratification of associated connectivity graph
of network and Semidefinite Programming (SDP), particularly solving the
slackness conditions, where the optimal weights are obtained by inductive
comparing of the characteristic polynomials initiated by slackness conditions.
Some numerical simulations are carried out to investigate the trade-off between
the parameters of two fused star networks, namely the length and number of
branches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3553</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3553</id><created>2010-03-18</created><authors><author><keyname>Prajapati</keyname><forenames>N. B.</forenames><affiliation>B. V. M. Engineering. College, India</affiliation></author><author><keyname>Agravat</keyname><forenames>R. R.</forenames><affiliation>B. V. M. Engineering. College, India</affiliation></author><author><keyname>Hasan</keyname><forenames>M. I.</forenames><affiliation>B. V. M. Engineering. College, India</affiliation></author></authors><title>Simulated Annealing for Location Area Planning in Cellular networks</title><categories>cs.NI</categories><comments>7 Pages, JGraph-Hoc Journal</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 1-7</journal-ref><doi>10.5121/jgraphhoc.2010.2101</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  LA planning in cellular network is useful for minimizing location management
cost in GSM network. In fact, size of LA can be optimized to create a balance
between the LA update rate and expected paging rate within LA. To get optimal
result for LA planning in cellular network simulated annealing algorithm is
used. Simulated annealing give optimal results in acceptable run-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3555</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3555</id><created>2010-03-18</created><authors><author><keyname>Gupta</keyname><forenames>Anand</forenames><affiliation>Netaji Subhas Institute of Technology, Delhi University, India</affiliation></author><author><keyname>Bedi</keyname><forenames>Harsh</forenames><affiliation>Netaji Subhas Institute of Technology, Delhi University, India</affiliation></author><author><keyname>Bosco</keyname><forenames>MS Don</forenames><affiliation>Netaji Subhas Institute of Technology, Delhi University, India</affiliation></author><author><keyname>Shashidhar</keyname><forenames>Vinay</forenames><affiliation>Netaji Subhas Institute of Technology, Delhi University, India</affiliation></author></authors><title>Simulation to track 3D location in GSM through NS2 and real life</title><categories>cs.NI</categories><comments>12 Pages, JGraph-Hoc Journal</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 18-29</journal-ref><doi>10.5121/jgraphhoc.2010.2103</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In recent times the cost of mobile communication has dropped significantly
leading to a dramatic increase in mobile phone usage. The widespread usage has
led mobiles to emerge as a strong alternative for other applications one of
which is tracking. This has enabled law-enforcing agencies to detect
overspeeding vehicles and organizations to keep track its employees. The 3
major ways of tracking being employed presently are (a) via GPS [1] (b) signal
attenuation property of a packet [3] and (c) using GSM Network [2]. The initial
cost of GPS is very high resulting in low usage whereas (b) needs a very high
precision measuring device. The paper presents a GSM-based tracking technique
which eliminates the above mentioned overheads, implements it in NS2 and shows
the limitations of the real life simulation. An accuracy of 97% was achieved
during NS2 simulation which is comparable to the above mentioned alternate
methods of tracking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3556</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3556</id><created>2010-03-18</created><authors><author><keyname>Das</keyname><forenames>Bikramaditya</forenames><affiliation>National Institute of Technology, Rourkela, India</affiliation></author><author><keyname>Das</keyname><forenames>Susmita</forenames><affiliation>National Institute of Technology, Rourkela, India</affiliation></author></authors><title>Performance Analysis of Ultra Wideband Receivers for High Data Rate
  Wireless Personal Area Network System</title><categories>cs.NI</categories><comments>13 Pages, JGraph-Hoc Journal</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 31-43</journal-ref><doi>10.5121/jgraphhoc.2010.2104</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  For high data rate ultra wideband communication system, performance
comparison of Rake, MMSE and Rake-MMSE receivers is attempted in this paper.
Further a detail study on Rake-MMSE time domain equalizers is carried out
taking into account all the important parameters such as the effect of the
number of Rake fingers and equalizer taps on the error rate performance. This
receiver combats inter-symbol interference by taking advantages of both the
Rake and equalizer structure. The bit error rate performances are investigated
using MATLAB simulation on IEEE 802.15.3a defined UWB channel models.
Simulation results show that the bit error rate probability of Rake-MMSE
receiver is much better than Rake receiver and MMSE equalizer. Study on
non-line of sight indoor channel models illustrates that bit error rate
performance of Rake-MMSE (both LE and DFE) improves for CM3 model with smaller
spread compared to CM4 channel model. It is indicated that for a MMSE equalizer
operating at low to medium SNR values, the number of Rake fingers is the
dominant factor to improve system performance, while at high SNR values the
number of equalizer taps plays a more significant role in reducing the error
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3558</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3558</id><created>2010-03-18</created><authors><author><keyname>Kumar</keyname><forenames>Neeraj</forenames><affiliation>SMVD University, Katra</affiliation></author><author><keyname>Kumar</keyname><forenames>Manoj</forenames><affiliation>SMVD University, Katra</affiliation></author><author><keyname>Patel</keyname><forenames>R. B.</forenames><affiliation>MITS University, Rajassthan, India</affiliation></author></authors><title>Coverage and Connectivity Aware Neural Network Based Energy Efficient
  Routing in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>16 Pages, JGraph-Hoc Journal</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 45-60</journal-ref><doi>10.5121/jgraphhoc.2010.2105</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  There are many challenges when designing and deploying wireless sensor
networks (WSNs). One of the key challenges is how to make full use of the
limited energy to prolong the lifetime of the network, because energy is a
valuable resource in WSNs. The status of energy consumption should be
continuously monitored after network deployment. In this paper, we propose
coverage and connectivity aware neural network based energy efficient routing
in WSN with the objective of maximizing the network lifetime. In the proposed
scheme, the problem is formulated as linear programming (LP) with coverage and
connectivity aware constraints. Cluster head selection is proposed using
adaptive learning in neural networks followed by coverage and connectivity
aware routing with data transmission. The proposed scheme is compared with
existing schemes with respect to the parameters such as number of alive nodes,
packet delivery fraction, and node residual energy. The simulation results show
that the proposed scheme can be used in wide area of applications in WSNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3564</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3564</id><created>2010-03-18</created><authors><author><keyname>Sumathy</keyname><forenames>S.</forenames><affiliation>VIT University, India</affiliation></author><author><keyname>Kumar</keyname><forenames>B. Upendra</forenames><affiliation>VIT University, India</affiliation></author></authors><title>Secure Key Exchange and Encryption Mechanism for Group Communication in
  Wireless Ad Hoc Networks</title><categories>cs.NI</categories><comments>8 Pages, JGraph-Hoc Journal</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 9-16</journal-ref><doi>10.5121/jgraphhoc.2010.2102</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Secured communication in ad hoc wireless networks is primarily important,
because the communication signals are openly available as they propagate
through air and are more susceptible to attacks ranging from passive
eavesdropping to active interfering. The lack of any central coordination and
shared wireless medium makes them more vulnerable to attacks than wired
networks. Nodes act both as hosts and routers and are interconnected by Multi-
hop communication path for forwarding and receiving packets to/from other
nodes. The objective of this paper is to propose a key exchange and encryption
mechanism that aims to use the MAC address as an additional parameter as the
message specific key[to encrypt]and forward data among the nodes. The nodes are
organized in spanning tree fashion, as they avoid forming cycles and exchange
of key occurs only with authenticated neighbors in ad hoc networks, where nodes
join or leave the network dynamically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3565</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3565</id><created>2010-03-18</created><authors><author><keyname>Al-Omari</keyname><forenames>Saleh Ali K.</forenames><affiliation>Universiti Sains Malaysia, Malaysia</affiliation></author><author><keyname>Sumari</keyname><forenames>Putra</forenames><affiliation>Universiti Sains Malaysia, Malaysia</affiliation></author></authors><title>An Overview of Mobile Ad Hoc Networks for the Existing Protocols and
  Applications</title><categories>cs.NI</categories><comments>24 Pages, JGraph-Hoc Journal</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 87-110</journal-ref><doi>10.5121/jgraphhoc.2010.2107</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Mobile Ad Hoc Network (MANET) is a collection of two or more devices or nodes
or terminals with wireless communications and networking capability that
communicate with each other without the aid of any centralized administrator
also the wireless nodes that can dynamically form a network to exchange
information without using any existing fixed network infrastructure. And it's
an autonomous system in which mobile hosts connected by wireless links are free
to be dynamically and some time act as routers at the same time, and we discuss
in this paper the distinct characteristics of traditional wired networks,
including network configuration may change at any time, there is no direction
or limit the movement and so on, and thus needed a new optional path Agreement
(Routing Protocol) to identify nodes for these actions communicate with each
other path, An ideal choice way the agreement should not only be able to find
the right path, and the Ad Hoc Network must be able to adapt to changing
network of this type at any time. and we talk in details in this paper all the
information of Mobile Ad Hoc Network which include the History of ad hoc,
wireless ad hoc, wireless mobile approaches and types of mobile ad Hoc
networks, and then we present more than 13 types of the routing Ad Hoc Networks
protocols have been proposed. In this paper, the more representative of routing
protocols, analysis of individual characteristics and advantages and
disadvantages to collate and compare, and present the all applications or the
Possible Service of Ad Hoc Networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3566</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3566</id><created>2010-03-18</created><authors><author><keyname>Moussa</keyname><forenames>M. Ibrahim</forenames><affiliation>Benha University, Benha, Egypt</affiliation></author></authors><title>An Algorithm for Odd Graceful Labeling of the Union of Paths and Cycles</title><categories>cs.NI</categories><comments>9 Pages, JGraph-Hoc Journal</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 112-119</journal-ref><doi>10.5121/jgraphhoc.2010.2108</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In 1991, Gnanajothi [4] proved that the path graph P_n with n vertex and n-1
edge is odd graceful, and the cycle graph C_m with m vertex and m edges is odd
graceful if and only if m even, she proved the cycle graph is not graceful if m
odd. In this paper, firstly, we studied the graph C_m $\cup$ P_m when m = 4,
6,8,10 and then we proved that the graph C_ $\cup$ P_n is odd graceful if m is
even. Finally, we described an algorithm to label the vertices and the edges of
the vertex set V(C_m $\cup$ P_n) and the edge set E(C_m $\cup$ P_n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3568</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3568</id><created>2010-03-18</created><authors><author><keyname>Goel</keyname><forenames>Aditya</forenames><affiliation>The Technological Institute of Textile &amp; Sciences, Haryana, India</affiliation></author></authors><title>Key distribution in PKC through Quantas</title><categories>cs.NI</categories><comments>11 Pages, JGraph-Hoc Journal 2010</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 121-131</journal-ref><doi>10.5121/jgraphhoc.2010.2109</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cryptography literally means &quot;The art &amp; science of secret writing &amp; sending a
message between two parties in such a way that its contents cannot be
understood by someone other than the intended recipient&quot;. and Quantum word is
related with &quot;Light&quot;. Thus, Quantum Cryptography is a way of descripting any
information in the form of quantum particles. There are no classical
cryptographic systems which are perfectly secure. In contrast to Classical
cryptography which depends upon Mathematics, Quantum Cryptography utilizes the
concepts of Quantum Physics which provides us the security against the
cleverest marauders of the present age. In the view of increasing need of
Network and Information Security, we do require methods to overcome the
Molecular Computing technologies (A future technology) and other techniques of
the various codebrakers. Both the parts i.e. Quantum Key distribution and
Information transference from Sender to Receiver are much efficient and secure.
It is based upon BB84 protocol. It can be of great use for Govt. agencies such
as Banks, Insurance, Brokerages firms, financial institutions, e-commerce and
most important is the Defense &amp; security of any country. It is a Cryptographic
communication system in which the original users can detect unauthorized
eavesdropper and in addition it gives a guarantee of no eavesdropping. It
proves to be the ultra secure mode of communication b/w two intended parties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3569</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3569</id><created>2010-03-18</created><authors><author><keyname>Jang</keyname><forenames>Hung-Chin</forenames><affiliation>National Chengchi University, Taiwan</affiliation></author></authors><title>Applications of Geometric Algorithms to Reduce Interference in Wireless
  Mesh Network</title><categories>cs.NI</categories><comments>24 Pages, JGraph-Hoc Journal 2010</comments><journal-ref>International journal on applications of graph theory in wireless
  ad hoc networks and sensor networks 2.1 (2010) 62-85</journal-ref><doi>10.5121/jgraphhoc.2010.2106</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In wireless mesh networks such as WLAN (IEEE 802.11s) or WMAN (IEEE 802.11),
each node should help to relay packets of neighboring nodes toward gateway
using multi-hop routing mechanisms. Wireless mesh networks usually intensively
deploy mesh nodes to deal with the problem of dead spot communication. However,
the higher density of nodes deployed, the higher radio interference occurred.
This causes significant degradation of system performance. In this paper, we
first convert network problems into geometry problems in graph theory, and then
solve the interference problem by geometric algorithms. We first define line
intersection in a graph to reflect radio interference problem in a wireless
mesh network. We then use plan sweep algorithm to find intersection lines, if
any; employ Voronoi diagram algorithm to delimit the regions among nodes; use
Delaunay Triangulation algorithm to reconstruct the graph in order to minimize
the interference among nodes. Finally, we use standard deviation to prune off
those longer links (higher interference links) to have a further enhancement.
The proposed hybrid solution is proved to be able to significantly reduce
interference in a wireless mesh network in O(n log n) time complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3613</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3613</id><created>2010-03-18</created><updated>2010-09-21</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author></authors><title>Indicators of the Interdisciplinarity of Journals: Diversity,
  Centrality, and Citations</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A citation-based indicator for interdisciplinarity has been missing hitherto
among the set of available journal indicators. In this study, we investigate
network indicators (betweenness centrality), journal indicators (Shannon
entropy, the Gini coefficient), and more recently proposed Rao-Stirling
measures for &quot;interdisciplinarity.&quot; The latter index combines the statistics of
both citation distributions of journals (vector-based) and distances in
citation networks among journals (matrix-based). The effects of various
normalizations are specified and measured using the matrix of 8,207 journals
contained in the Journal Citation Reports of the (Social) Science Citation
Index 2008. Betweenness centrality in symmetrical (1-mode) cosine-normalized
networks provides an indicator outperforming betweenness in the asymmetrical
(2-mode) citation network. Among the vector-based indicators, Shannon entropy
performs better than the Gini coefficient, but is sensitive to size. Science
and Nature, for example, are indicated at the top of the list. The new
diversity measure provides reasonable results when (1 - cosine) is assumed as a
measure for the distance, but results using Euclidean distances were difficult
to interpret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3619</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3619</id><created>2010-03-18</created><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author></authors><title>Using Information Theory to Study the Efficiency and Capacity of
  Computers and Similar Devices</title><categories>cs.IT cs.CC math.IT</categories><msc-class>94A24, 68M01</msc-class><acm-class>B.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problems of estimating the computer efficiency and the
computer capacity. We define the computer efficiency and capacity and suggest a
method for their estimation, based on the analysis of processor instructions
and kinds of accessible memory. It is shown how the suggested method can be
applied to estimate the computer capacity. In particular, this consideration
gives a new look at the organization of the memory of a computer. Obtained
results can be of some interest for practical applications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3629</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3629</id><created>2010-03-18</created><authors><author><keyname>Franceschet</keyname><forenames>Massimo</forenames></author></authors><title>A logic for networks</title><categories>cs.LO cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networks are pervasive in the real world. Nature, society, economy, and
technology are supported by ostensibly different networks that in fact share an
amazing number of interesting structural properties. Network thinking exploded
in the last decade, boosted by the availability of large databases on the
topology of various real networks, mainly the Web and biological networks, and
converged to the new discipline of network analysis - the holistic analysis of
complex systems through the study of the network that wires their components.
Physicists mainly drove the investigation, studying the structure and function
of networks using methods and tools of statistical mechanics. Here, we give an
alternative perspective on network analysis, proposing a logic for specifying
general properties of networks and a modular algorithm for checking these
properties. The logic borrows from two intertwined computing fields: XML
databases and model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3649</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3649</id><created>2010-03-18</created><authors><author><keyname>Bradley</keyname><forenames>Aaron R.</forenames></author></authors><title>k-Step Relative Inductive Generalization</title><categories>cs.DM cs.LO</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new form of SAT-based symbolic model checking. One common idea
in SAT-based symbolic model checking is to generate new clauses from states
that can lead to property violations. Our previous work suggests applying
induction to generalize from such states. While effective on some benchmarks,
the main problem with inductive generalization is that not all such states can
be inductively generalized at a given time in the analysis, resulting in long
searches for generalizable states on some benchmarks. This paper introduces the
idea of inductively generalizing states relative to $k$-step
over-approximations: a given state is inductively generalized relative to the
latest $k$-step over-approximation relative to which the negation of the state
is itself inductive. This idea motivates an algorithm that inductively
generalizes a given state at the highest level $k$ so far examined, possibly by
generating more than one mutually $k$-step relative inductive clause. We
present experimental evidence that the algorithm is effective in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3654</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3654</id><created>2010-03-18</created><authors><author><keyname>Gopalan</keyname><forenames>Chitrakala</forenames></author><author><keyname>Manjula</keyname><forenames>D.</forenames></author></authors><title>Sliding window approach based Text Binarisation from Complex Textual
  images</title><categories>cs.CV</categories><comments>5 Pages IEEE format, International Journal on Computer Science and
  Engineering, IJCSE 2010, ISSN 0975-3397, Impact Factor 0.583</comments><journal-ref>International Journal on Computer Science and Engineering, IJCSE,
  Vol. 2, No. 2 March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text binarisation process classifies individual pixels as text or background
in the textual images. Binarization is necessary to bridge the gap between
localization and recognition by OCR. This paper presents Sliding window method
to binarise text from textual images with textured background. Suitable
preprocessing techniques are applied first to increase the contrast of the
image and blur the background noises due to textured background. Then Edges are
detected by iterative thresholding. Subsequently formed edge boxes are analyzed
to remove unwanted edges due to complex background and binarised by sliding
window approach based character size uniformity check algorithm. The proposed
method has been applied on localized region from heterogeneous textual images
and compared with Otsu, Niblack methods and shown encouraging performance of
the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3661</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3661</id><created>2010-03-18</created><authors><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Balakireva</keyname><forenames>Lyudmila L.</forenames></author><author><keyname>Shankar</keyname><forenames>Harihar</forenames></author><author><keyname>Ainsworth</keyname><forenames>Scott</forenames></author></authors><title>An HTTP-Based Versioning Mechanism for Linked Data</title><categories>cs.DL cs.IR</categories><comments>Proceedings of Linked Data on the Web (LDOW2010), April 27, 2010,
  Raleigh, USA</comments><acm-class>H.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dereferencing a URI returns a representation of the current state of the
resource identified by that URI. But, on the Web representations of prior
states of a resource are also available, for example, as resource versions in
Content Management Systems or archival resources in Web Archives such as the
Internet Archive. This paper introduces a resource versioning mechanism that is
fully based on HTTP and uses datetime as a global version indicator. The
approach allows &quot;follow your nose&quot; style navigation both from the current
time-generic resource to associated time-specific version resources as well as
among version resources. The proposed versioning mechanism is congruent with
the Architecture of the World Wide Web, and is based on the Memento framework
that extends HTTP with transparent content negotiation in the datetime
dimension. The paper shows how the versioning approach applies to Linked Data,
and by means of a demonstrator built for DBpedia, it also illustrates how it
can be used to conduct a time-series analysis across versions of Linked Data
descriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3672</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3672</id><created>2010-03-18</created><authors><author><keyname>Dey</keyname><forenames>Sandipan</forenames></author><author><keyname>Abraham</keyname><forenames>Ajith</forenames></author><author><keyname>Bandyopadhyay</keyname><forenames>Bijoy</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Data Hiding Techniques Using Prime and Natural Numbers</title><categories>cs.CR</categories><comments>45 Pages, 14 Figures, 5 Tables</comments><journal-ref>Journal of Digital Information Management, ISSN 0972-7272, Volume
  6, No 3, pp. 463-485, 2008.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a few novel data hiding techniques are proposed. These
techniques are improvements over the classical LSB data hiding technique and
the Fibonacci LSB data-hiding technique proposed by Battisti et al. \cite{r1}.
The classical LSB technique is the simplest, but using this technique it is
possible to embed only in first few bit-planes, since image quality becomes
drastically distorted when embedding in higher bit-planes. Battisti et al.
\cite{r1} proposed an improvement over this by using Fibonacci decomposition
technique and generating a different set of virtual bit-planes all together,
thereby increasing the number of bit-planes. In this paper, first we
mathematically model and generalize this particular approach of virtual
bit-plane generation. Then we propose two novel embedding techniques, both of
which are special-cases of our generalized model. The first embedding scheme is
based on decomposition of a number (pixel-value) in sum of prime numbers, while
the second one is based on decomposition in sum of natural numbers. Each of
these particular representations generates a different set of (virtual)
bit-planes altogether, suitable for embedding purposes. They not only allow one
to embed secret message in higher bit-planes but also do it without much
distortion, with a much better stego-image quality, in a reliable and secured
manner, guaranteeing efficient retrieval of secret message. A comparative
performance study between the classical Least Significant Bit (LSB) method, the
data hiding technique using Fibonacci -p-Sequence decomposition and our
proposed schemes has been done. Theoretical analysis indicates that image
quality of the stego-image hidden by the technique using Fibonacci
decomposition improves against simple LSB substitution method, while the same
using the prime decomposition method improves drastically against that using
Fibonacci decomposition technique, and finally the natural number decomposition
method is a further improvement against that using prime decomposition
technique. Also, optimality for the last technique is proved. For both of our
data-hiding techniques, the experimental results show that, the stego-image is
visually indistinguishable from the original cover image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3676</identifier>
 <datestamp>2013-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3676</id><created>2010-03-18</created><updated>2012-02-22</updated><authors><author><keyname>Moreira</keyname><forenames>Mayron C&#xe9;sar O.</forenames></author><author><keyname>Ritt</keyname><forenames>Marcus</forenames></author><author><keyname>Costa</keyname><forenames>Alysson M.</forenames></author><author><keyname>Chaves</keyname><forenames>Antonio A.</forenames></author></authors><title>Simple heuristics for the assembly line worker assignment and balancing
  problem</title><categories>cs.DS cs.NE</categories><comments>18 pages, 1 figure</comments><doi>10.1007/s10732-012-9195-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose simple heuristics for the assembly line worker assignment and
balancing problem. This problem typically occurs in assembly lines in sheltered
work centers for the disabled. Different from the classical simple assembly
line balancing problem, the task execution times vary according to the assigned
worker. We develop a constructive heuristic framework based on task and worker
priority rules defining the order in which the tasks and workers should be
assigned to the workstations. We present a number of such rules and compare
their performance across three possible uses: as a stand-alone method, as an
initial solution generator for meta-heuristics, and as a decoder for a hybrid
genetic algorithm. Our results show that the heuristics are fast, they obtain
good results as a stand-alone method and are efficient when used as a initial
solution generator or as a solution decoder within more elaborate approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3684</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3684</id><created>2010-03-18</created><authors><author><keyname>Yoo</keyname><forenames>Andy</forenames></author><author><keyname>Henderson</keyname><forenames>Keith</forenames></author></authors><title>Parallel Generation of Massive Scale-Free Graphs</title><categories>cs.DC</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  One of the biggest huddles faced by researchers studying algorithms for
massive graphs is the lack of large input graphs that are essential for the
development and test of the graph algorithms. This paper proposes two efficient
and highly scalable parallel graph generation algorithms that can produce
massive realistic graphs to address this issue. The algorithms, designed to
achieve high degree of parallelism by minimizing inter-processor
communications, are two of the fastest graph generators which are capable of
generating scale-free graphs with billions of vertices and edges. The synthetic
graphs generated by the proposed methods possess the most common properties of
real complex networks such as power-law degree distribution, small-worldness,
and communities-within-communities. Scalability was tested on a large cluster
at Lawrence Livermore National Laboratory. In the experiment, we were able to
generate a graph with 1 billion vertices and 5 billion edges in less than 13
seconds. To the best of our knowledge, this is the largest synthetic scale-free
graph reported in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3689</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3689</id><created>2010-03-18</created><updated>2013-02-12</updated><authors><author><keyname>Manguoglu</keyname><forenames>Murat</forenames></author></authors><title>A Highly Efficient Parallel Algorithm for Computing the Fiedler Vector</title><categories>cs.NA cs.MS</categories><comments>This paper has been withdrawn by the author because it is under
  revision</comments><acm-class>G.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3704</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3704</id><created>2010-03-18</created><updated>2010-03-29</updated><authors><author><keyname>Jain</keyname><forenames>Peiyush</forenames></author></authors><title>On a variant of Monotone NAE-3SAT and the Triangle-Free Cut problem</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we define a restricted version of Monotone NAE-3SAT and show
that it remains NP-Complete even under that restriction. We expect this result
would be useful in proving NP-Completeness results for problems on
$k$-colourable graphs ($k \ge 5$). We also prove the NP-Completeness of the
Triangle-Free Cut problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3707</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3707</id><created>2010-03-18</created><updated>2010-05-25</updated><authors><author><keyname>Suh</keyname><forenames>Changho</forenames></author><author><keyname>Ho</keyname><forenames>Minnie</forenames></author><author><keyname>Tse</keyname><forenames>David</forenames></author></authors><title>Downlink Interference Alignment</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an interference alignment (IA) technique for a downlink cellular
system. In the uplink, IA schemes need channel-state-information exchange
across base-stations of different cells, but our downlink IA technique requires
feedback only within a cell. As a result, the proposed scheme can be
implemented with a few changes to an existing cellular system where the
feedback mechanism (within a cell) is already being considered for supporting
multi-user MIMO. Not only is our proposed scheme implementable with little
effort, it can in fact provide substantial gain especially when interference
from a dominant interferer is significantly stronger than the remaining
interference: it is shown that in the two-isolated cell layout, our scheme
provides four-fold gain in throughput performance over a standard multi-user
MIMO technique. We show through simulations that our technique provides
respectable gain under a more realistic scenario: it gives approximately 20%
gain for a 19 hexagonal wrap-around-cell layout. Furthermore, we show that our
scheme has the potential to provide substantial gain for macro-pico cellular
networks where pico-users can be significantly interfered with by the nearby
macro-BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3708</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3708</id><created>2010-03-18</created><authors><author><keyname>Kryssanov</keyname><forenames>Victor V.</forenames></author><author><keyname>Kumokawa</keyname><forenames>Shizuka</forenames></author><author><keyname>Goncharenko</keyname><forenames>Igor</forenames></author><author><keyname>Ogawa</keyname><forenames>Hitoshi</forenames></author></authors><title>Perceiving the Social: A Multi-Agent System to Support Human Navigation
  in Foreign Communities</title><categories>cs.CY cs.HC</categories><comments>16 pages, 3 figures, 5 tables.</comments><acm-class>H.5.1; K.4.2; H.4.2; H.5.2</acm-class><journal-ref>Kryssanov, Victor V.; Kumokawa, Shizuka; Goncharenko, Igor; Ogawa,
  Hitoshi, 2010, Perceiving the Social: A Multi-Agent System to Support Human
  Navigation in Foreign Communities. International Journal of Software Science
  and Computational Intelligence, Vol. 2(1), 24-37</journal-ref><doi>10.4018/jssci.2010101902</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a system developed to help people explore local
communities by providing navigation services in social spaces created by the
community members via communication and knowledge sharing. The proposed system
utilizes data of a community's social network to reconstruct the social space,
which is otherwise not physically perceptible but imaginary, experiential, yet
learnable. The social space is modeled with an agent network, where each agent
stands for a member of the community and has knowledge about expertise and
personal characteristics of some other members. An agent can gather
information, using its social &quot;connections&quot;, to find community members most
suitable to communicate to in a specific situation defined by the system's
user. The system then deploys its multimodal interface, which &quot;maps&quot; the social
space onto a representation of the relevant physical space, to locate the
potential interlocutors and advise the user on an efficient communication
strategy for the given community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3713</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3713</id><created>2010-03-19</created><updated>2010-06-01</updated><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>The Yao Graph Y_6 is a Spanner</title><categories>cs.CG</categories><comments>12 pages, 11 figures, 2 references, unpublished. A subcase of Case(2)
  of Theorem 1 was overlooked, and I withdraw the paper until that gap is
  filled.</comments><acm-class>F.2.2; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that Y_6 is a spanner. Y_6 is the Yao graph on a set of planar
points, which has an edge from each point x to a closest point y within each of
the six angular cones of 60 deg surrounding x.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3754</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3754</id><created>2010-03-19</created><updated>2012-01-13</updated><authors><author><keyname>G&#xfc;zeltepe</keyname><forenames>Murat</forenames></author><author><keyname>&#xd6;zen</keyname><forenames>Mehmet</forenames></author></authors><title>Quantum codes from codes over Gaussian integers with respect to the
  Mannheim metric</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><msc-class>94B05, 94B60, 81P70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, some nonbinary quantum codes using classical codes over
Gaussian integers are obtained. Also, some of our quantum codes are better than
or comparable with those known before, (for instance [[8; 2; 5]]4+i).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3765</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3765</id><created>2010-03-19</created><authors><author><keyname>Bingbing</keyname><forenames>Zheng</forenames></author><author><keyname>Lingge</keyname><forenames>Jiang</forenames></author><author><keyname>Chen</keyname><forenames>He</forenames></author><author><keyname>Qingchuan</keyname><forenames>Wang</forenames></author></authors><title>Design of Nested LDGM-LDPC Codes for Compress-and-Forward in Relay
  Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A three terminal relay system with binary erasure channel (BEC) was
considered, in which a source forwarded information to a destination with a
relay's &quot;assistance&quot;. The nested LDGM (Low-density generator-matrix) -LDPC
(low-density parity-check) was designed to realize Compress-and-forward (CF) at
the relay. LDGM coding compressed the received signals losslessly and LDPC
realized the binning for Slepian-Wolf coding. Firstly a practical coding scheme
was proposed to achieve the cut-set bound on the capacity of the system,
employing LDPC and Nested LDGM-LDPC codes at the source and relay respectively.
Then, the degree distribution of LDGM and LDPC codes was optimized with a given
rate bound, which ensured that the iterative belief propagation (BP) decoding
algorithm at the destination was convergent. Finally, simulations results show
that the performance achieved based on nested codes is very close to
Slepian-Wolf theoretical limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3766</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3766</id><created>2010-03-19</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Chris</forenames></author></authors><title>Modelling and simulating retail management practices: a first approach</title><categories>cs.AI cs.CE cs.MA</categories><comments>33 pages, INFORMS Simulation Society Workshop,</comments><journal-ref>International Journal of Simulation and Process Modelling 5 (3),
  215-232 , 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-agent systems offer a new and exciting way of understanding the world
of work. We apply agent-based modeling and simulation to investigate a set of
problems in a retail context. Specifically, we are working to understand the
relationship between people management practices on the shop-floor and retail
performance. Despite the fact we are working within a relatively novel and
complex domain, it is clear that using an agent-based approach offers great
potential for improving organizational capabilities in the future. Our
multi-disciplinary research team has worked closely with one of the UK's top
ten retailers to collect data and build an understanding of shop-floor
operations and the key actors in a department (customers, staff, and managers).
Based on this case study we have built and tested our first version of a retail
branch agent-based simulation model where we have focused on how we can
simulate the effects of people management practices on customer satisfaction
and sales. In our experiments we have looked at employee development and
cashier empowerment as two examples of shop floor management practices. In this
paper we describe the underlying conceptual ideas and the features of our
simulation model. We present a selection of experiments we have conducted in
order to validate our simulation model and to show its potential for answering
&quot;what-if&quot; questions in a retail context. We also introduce a novel performance
measure which we have created to quantify customers' satisfaction with service,
based on their individual shopping experiences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3767</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3767</id><created>2010-03-19</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Chris</forenames></author></authors><title>Multi-Agent Simulation and Management Practices</title><categories>cs.AI cs.CE cs.MA</categories><comments>19 pages, 3 figures, Encyclopedia of Decision Making and Decision
  Support Technologies</comments><journal-ref>Encyclopedia of Decision Making and Decision Support Technologies,
  645-652, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent agents offer a new and exciting way of understanding the world of
work. Agent-Based Simulation (ABS), one way of using intelligent agents,
carries great potential for progressing our understanding of management
practices and how they link to retail performance. We have developed simulation
models based on research by a multi-disciplinary team of economists, work
psychologists and computer scientists. We will discuss our experiences of
implementing these concepts working with a well-known retail department store.
There is no doubt that management practices are linked to the performance of an
organisation (Reynolds et al., 2005; Wall &amp; Wood, 2005). Best practices have
been developed, but when it comes down to the actual application of these
guidelines considerable ambiguity remains regarding their effectiveness within
particular contexts (Siebers et al., forthcoming a). Most Operational Research
(OR) methods can only be used as analysis tools once management practices have
been implemented. Often they are not very useful for giving answers to
speculative 'what-if' questions, particularly when one is interested in the
development of the system over time rather than just the state of the system at
a certain point in time. Simulation can be used to analyse the operation of
dynamic and stochastic systems. ABS is particularly useful when complex
interactions between system entities exist, such as autonomous decision making
or negotiation. In an ABS model the researcher explicitly describes the
decision process of simulated actors at the micro level. Structures emerge at
the macro level as a result of the actions of the agents and their interactions
with other agents and the environment. 3 We will show how ABS experiments can
deal with testing and optimising management practices such as training,
empowerment or teamwork. Hence, questions such as &quot;will staff setting their own
break times improve performance?&quot; can be investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3775</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3775</id><created>2010-03-19</created><authors><author><keyname>Adewunmi</keyname><forenames>Adrian</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Optimisation of a Crossdocking Distribution Centre Simulation Model</title><categories>cs.AI cs.CE</categories><comments>6 pages, 7 tables, 2008 International Simulation Multi-Conference
  (SCS), San Diego, USA</comments><journal-ref>Proceedings of 2008 International Simulation Multi-Conference
  (SCS), San Diego, USA, 434-439</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports on continuing research into the modelling of an order
picking process within a Crossdocking distribution centre using Simulation
Optimisation. The aim of this project is to optimise a discrete event
simulation model and to understand factors that affect finding its optimal
performance. Our initial investigation revealed that the precision of the
selected simulation output performance measure and the number of replications
required for the evaluation of the optimisation objective function through
simulation influences the ability of the optimisation technique. We
experimented with Common Random Numbers, in order to improve the precision of
our simulation output performance measure, and intended to use the number of
replications utilised for this purpose as the initial number of replications
for the optimisation of our Crossdocking distribution centre simulation model.
Our results demonstrate that we can improve the precision of our selected
simulation output performance measure value using Common Random Numbers at
various levels of replications. Furthermore, after optimising our Crossdocking
distribution centre simulation model, we are able to achieve optimal
performance using fewer simulations runs for the simulation model which uses
Common Random Numbers as compared to the simulation model which does not use
Common Random Numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3784</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3784</id><created>2010-03-19</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Chris</forenames></author></authors><title>Simulating Customer Experience and Word Of Mouth in Retail - A Case
  Study</title><categories>cs.MA cs.CE</categories><comments>32 pages, Simulation: Transactions of the Society for Modeling and
  Simulation International</comments><journal-ref>Simulation: Transactions of the Society for Modeling and
  Simulation International, 86 (1), 5-30, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agents offer a new and exciting way of understanding the world of work. In
this paper we describe the development of agent-based simulation models,
designed to help to understand the relationship between people management
practices and retail performance. We report on the current development of our
simulation models which includes new features concerning the evolution of
customers over time. To test the features we have conducted a series of
experiments dealing with customer pool sizes, standard and noise reduction
modes, and the spread of customers' word of mouth. To validate and evaluate our
model, we introduce new performance measure specific to retail operations. We
show that by varying different parameters in our model we can simulate a range
of customer experiences leading to significant differences in performance
measures. Ultimately, we are interested in better understanding the impact of
changes in staff behavior due to changes in store management practices. Our
multi-disciplinary research team draws upon expertise from work psychologists
and computer scientists. Despite the fact we are working within a relatively
novel and complex domain, it is clear that intelligent agents offer potential
for fostering sustainable organizational capabilities in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3785</identifier>
 <datestamp>2011-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3785</id><created>2010-03-19</created><authors><author><keyname>Levandovskyy</keyname><forenames>Viktor</forenames></author><author><keyname>Schindelar</keyname><forenames>Kristina</forenames></author></authors><title>Computing diagonal form and Jacobson normal form of a matrix using
  Gr\&quot;obner bases</title><categories>math.RA cs.SC math.OC</categories><msc-class>13P10, 93B25, 16Z05</msc-class><journal-ref>Journal of Symbolic Computation 46 (2011) 595-608</journal-ref><doi>10.1016/j.jsc.2010.10.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present two algorithms for the computation of a diagonal
form of a matrix over non-commutative Euclidean domain over a field with the
help of Gr\&quot;obner bases. This can be viewed as the pre-processing for the
computation of Jacobson normal form and also used for the computation of Smith
normal form in the commutative case. We propose a general framework for
handling, among other, operator algebras with rational coefficients. We employ
special &quot;polynomial&quot; strategy in Ore localizations of non-commutative
$G$-algebras and show its merits. In particular, for a given matrix $M$ we
provide an algorithm to compute $U,V$ and $D$ with fraction-free entries such
that $UMV=D$ holds. The polynomial approach allows one to obtain more precise
information, than the rational one e. g. about singularities of the system.
  Our implementation of polynomial strategy shows very impressive performance,
compared with methods, which directly use fractions. In particular, we
experience quite moderate swell of coefficients and obtain uncomplicated
transformation matrices. This shows that this method is well suitable for
solving nontrivial practical problems. We present an implementation of
algorithms in SINGULAR:PLURAL and compare it with other available systems. We
leave questions on the algorithmic complexity of this algorithm open, but we
stress the practical applicability of the proposed method to a bigger class of
non-commutative algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3792</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3792</id><created>2010-03-19</created><authors><author><keyname>Kienle</keyname><forenames>Frank</forenames></author><author><keyname>Wehn</keyname><forenames>Norbert</forenames></author><author><keyname>Meyr</keyname><forenames>Heinrich</forenames></author></authors><title>On Complexity, Energy- and Implementation-Efficiency of Channel Decoders</title><categories>cs.IT cs.AR math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future wireless communication systems require efficient and flexible baseband
receivers. Meaningful efficiency metrics are key for design space exploration
to quantify the algorithmic and the implementation complexity of a receiver.
Most of the current established efficiency metrics are based on counting
operations, thus neglecting important issues like data and storage complexity.
In this paper we introduce suitable energy and area efficiency metrics which
resolve the afore-mentioned disadvantages. These are decoded information bit
per energy and throughput per area unit. Efficiency metrics are assessed by
various implementations of turbo decoders, LDPC decoders and convolutional
decoders. New exploration methodologies are presented, which permit an
appropriate benchmarking of implementation efficiency, communications
performance, and flexibility trade-offs. These exploration methodologies are
based on efficiency trajectories rather than a single snapshot metric as done
in state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3821</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3821</id><created>2010-03-19</created><authors><author><keyname>Guralnik</keyname><forenames>Dan</forenames></author></authors><title>A Formal Approach to Modeling the Memory of a Living Organism</title><categories>cs.AI cs.DS cs.LG q-bio.NC</categories><comments>33 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a living organism as an observer of the evolution of its
environment recording sensory information about the state space X of the
environment in real time. Sensory information is sampled and then processed on
two levels. On the biological level, the organism serves as an evaluation
mechanism of the subjective relevance of the incoming data to the observer: the
observer assigns excitation values to events in X it could recognize using its
sensory equipment. On the algorithmic level, sensory input is used for updating
a database, the memory of the observer whose purpose is to serve as a
geometric/combinatorial model of X, whose nodes are weighted by the excitation
values produced by the evaluation mechanism. These values serve as a guidance
system for deciding how the database should transform as observation data
mounts. We define a searching problem for the proposed model and discuss the
model's flexibility and its computational efficiency, as well as the
possibility of implementing it as a dynamic network of neuron-like units. We
show how various easily observable properties of the human memory and thought
process can be explained within the framework of this model. These include:
reasoning (with efficiency bounds), errors, temporary and permanent loss of
information. We are also able to define general learning problems in terms of
the new model, such as the language acquisition problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3830</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3830</id><created>2010-03-19</created><authors><author><keyname>Cordeiro</keyname><forenames>Lucas</forenames></author><author><keyname>Fischer</keyname><forenames>Bernd</forenames></author></authors><title>Bounded Model Checking of Multi-threaded Software using SMT solvers</title><categories>cs.LO cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transition from single-core to multi-core processors has made
multi-threaded software an important subject in computer aided verification.
Here, we describe and evaluate an extension of the ESBMC model checker to
support the verification of multi-threaded software with shared variables and
locks using bounded model checking (BMC) based on Satisfiability Modulo
Theories (SMT). We describe three approaches to model check multi-threaded
software and our modelling of the synchronization primitives of the Pthread
library. In the lazy approach, we generate all possible interleavings and call
the BMC procedure on each of them individually, until we either find a bug, or
have systematically explored all interleavings. In the schedule recording
approach, we encode all possible interleavings into one single formula and then
exploit the high speed of the SMT solvers. In the underapproximation-widening
approach, we reduce the state space by abstracting the number of state
variables and interleavings from the proofs of unsatisfiability generated by
the SMT solvers. In all three approaches, we use partial-order reduction (POR)
techniques to reduce the number of interleavings explored. Experiments show
that our approaches can analyze larger problems and substantially reduce the
verification time compared to state-of-the-art techniques that combine classic
POR methods with symbolic algorithms and others that implement the
Counter-Example Guided Abstraction Refinement technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3866</identifier>
 <datestamp>2010-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3866</id><created>2010-03-19</created><updated>2010-05-13</updated><authors><author><keyname>Khajeh-Hosseini</keyname><forenames>Ali</forenames></author><author><keyname>Greenwood</keyname><forenames>David</forenames></author><author><keyname>Smith</keyname><forenames>James W.</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author></authors><title>The Cloud Adoption Toolkit: Addressing the Challenges of Cloud Adoption
  in Enterprise</title><categories>cs.DC</categories><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing promises a radical shift in the provisioning of computing
resource within the enterprise. This paper: i) describes the challenges that
decision makers face when attempting to determine the feasibility of the
adoption of cloud computing in their organisations; ii) illustrates a lack of
existing work to address the feasibility challenges of cloud adoption in the
enterprise; iii) introduces the Cloud Adoption Toolkit that provides a
framework to support decision makers in identifying their concerns, and
matching these concerns to appropriate tools/techniques that can be used to
address them. The paper adopts a position paper methodology such that case
study evidence is provided, where available, to support claims. We conclude
that the Cloud Adoption Toolkit, whilst still under development, shows signs
that it is a useful tool for decision makers as it helps address the
feasibility challenges of cloud adoption in the enterprise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3879</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3879</id><created>2010-03-19</created><updated>2011-08-17</updated><authors><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Richerby</keyname><forenames>David</forenames></author></authors><title>An Effective Dichotomy for the Counting Constraint Satisfaction Problem</title><categories>cs.CC</categories><comments>31 pages. Corrected some errors from previous versions</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bulatov (2008) gave a dichotomy for the counting constraint satisfaction
problem #CSP. A problem from #CSP is characterised by a constraint language,
which is a fixed, finite set of relations over a finite domain D. An instance
of the problem uses these relations to constrain the variables in a larger set.
Bulatov showed that the problem of counting the satisfying assignments of
instances of any problem from #CSP is either in polynomial time (FP) or is
#P-complete. His proof draws heavily on techniques from universal algebra and
cannot be understood without a secure grasp of that field. We give an
elementary proof of Bulatov's dichotomy, based on succinct representations,
which we call frames, of a class of highly structured relations, which we call
strongly rectangular. We show that these are precisely the relations which are
invariant under a Mal'tsev polymorphism. En route, we give a simplification of
a decision algorithm for strongly rectangular constraint languages, due to
Bulatov and Dalmau (2006). We establish a new criterion for the #CSP dichotomy,
which we call strong balance, and we prove that this property is decidable. In
fact, we establish membership in NP. Thus, we show that the dichotomy is
effective, resolving the most important open question concerning the #CSP
dichotomy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3880</identifier>
 <datestamp>2010-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3880</id><created>2010-03-19</created><updated>2010-05-14</updated><authors><author><keyname>Greenwood</keyname><forenames>David</forenames></author><author><keyname>Khajeh-Hosseini</keyname><forenames>Ali</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author></authors><title>Lessons from the Failure and Subsequent Success of a Complex Healthcare
  Sector IT Project</title><categories>cs.SE</categories><acm-class>K.4.3; K.6.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper argues that IT failures diagnosed as errors at the technical or
project management level are often mistakenly pointing to symptoms of failure
rather than a project's underlying socio-complexity (complexity resulting from
the interactions of people and groups) which is usually the actual source of
failure. We propose a novel method, Stakeholder Impact Analysis, that can be
used to identify risks associated with socio-complexity as it is grounded in
insights from the social sciences, psychology and management science. This
paper demonstrates the effectiveness of Stakeholder Impact Analysis by using
the 1992 London Ambulance Service Computer Aided Dispatch project as a case
study, and shows that had our method been used to identify the risks and had
they been mitigated, it would have reduced the risk of project failure. This
paper's original contribution comprises expanding upon existing accounts of
failure by examining failures at a level of granularity not seen elsewhere that
enables the underlying socio-complexity sources of risk to be identified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3893</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3893</id><created>2010-03-19</created><authors><author><keyname>Zhang</keyname><forenames>Chenyi</forenames></author></authors><title>Unwinding Conditional Noninterference</title><categories>cs.CR</categories><comments>16 pages including proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noninterference provides a control over information flow in a system for
ensuring confidentiality and integrity properties. In the literature this
notion has been well studied as transitive noninterference and intransitive
noninterference. In this paper we define a framework on the notion of
conditional noninterference, which allows to specify information flow policies
based on the semantics of action channels. Our new policies subsume the
policies of both transitive and intransitive noninterference, and support
dynamic requirements such as upgrading and downgrading. We also present
unwinding relations that are both sound and complete for the new policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3898</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3898</id><created>2010-03-19</created><updated>2014-02-17</updated><authors><author><keyname>Keeler</keyname><forenames>H. Paul</forenames></author></authors><title>A stochastic analysis of greedy routing in a spatially dependent sensor
  network</title><categories>math.PR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a sensor network, a tractable spatially-dependent node deployment model
is presented with the property that the density is inversely proportional to
the sink distance. A stochastic model is formulated to examine message
advancements under greedy routing in such a sensor network. The aim of this
work is to demonstrate that an inhomogeneous Poisson process can be used to
model a sensor network with spatially-dependent node density. Elliptic
integrals and asymptotic approximations are used to describe the random
behaviour of hops. Types of dependence that affect hop advancements are
examined. We observe that the dependence between successive jumps in a multihop
path is captured by including only the previous forwarding node location. We
include a simple uncoordinated sleep scheme, and observe that the complexity of
the model is reduced when enough nodes are asleep. All expressions involving
multidimensional integrals are derived and evaluated with quasi-Monte Carlo
integration methods based on Halton sequences and recently-developed lattice
rules. An importance sampling function is derived to speed up the quasi-Monte
Carlo methods. The ensuing results agree extremely well with simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3904</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3904</id><created>2010-03-19</created><updated>2011-01-18</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>The graph bottleneck identity</title><categories>math.CO cs.DM cs.NI math.MG</categories><comments>12 pages, 18 references. Advances in Applied Mathematics</comments><msc-class>05C12 05C50 05C05 15A48 15A51</msc-class><journal-ref>Advances in Applied Mathematics. 47 (2011), No.3, P.403-413</journal-ref><doi>10.1016/j.aam.2010.11.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A matrix $S=(s_{ij})\in{\mathbb R}^{n\times n}$ is said to determine a
\emph{transitional measure} for a digraph $G$ on $n$ vertices if for all
$i,j,k\in\{1,\...,n\},$ the \emph{transition inequality} $s_{ij} s_{jk}\le
s_{ik} s_{jj}$ holds and reduces to the equality (called the \emph{graph
bottleneck identity}) if and only if every path in $G$ from $i$ to $k$ contains
$j$. We show that every positive transitional measure produces a distance by
means of a logarithmic transformation. Moreover, the resulting distance
$d(\cdot,\cdot)$ is \emph{graph-geodetic}, that is, $d(i,j)+d(j,k)=d(i,k)$
holds if and only if every path in $G$ connecting $i$ and $k$ contains $j$.
Five types of matrices that determine transitional measures for a digraph are
considered, namely, the matrices of path weights, connection reliabilities,
route weights, and the weights of in-forests and out-forests. The results
obtained have undirected counterparts. In [P. Chebotarev, A class of
graph-geodetic distances generalizing the shortest-path and the resistance
distances, Discrete Appl. Math., URL
http://dx.doi.org/10.1016/j.dam.2010.11.017] the present approach is used to
fill the gap between the shortest path distance and the resistance distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3908</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3908</id><created>2010-03-20</created><authors><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Shi</keyname><forenames>Long</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>Full Diversity Space-Time Block Codes with Low-Complexity Partial
  Interference Cancellation Group Decoding</title><categories>cs.IT math.IT</categories><comments>10 pages, 3 figures.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partial interference cancellation (PIC) group decoding proposed by Guo and
Xia is an attractive low-complexity alternative to the optimal processing for
multiple-input multiple-output (MIMO) wireless communications. It can well deal
with the tradeoff among rate, diversity and complexity of space-time block
codes (STBC). In this paper, a systematic design of full-diversity STBC with
low-complexity PIC group decoding is proposed. The proposed code design is
featured as a group-orthogonal STBC by replacing every element of an Alamouti
code matrix with an elementary matrix composed of multiple diagonal layers of
coded symbols. With the PIC group decoding and a particular grouping scheme,
the proposed STBC can achieve full diversity, a rate of $(2M)/(M+2)$ and a
low-complexity decoding for $M$ transmit antennas. Simulation results show that
the proposed codes can achieve the full diversity with PIC group decoding while
requiring half decoding complexity of the existing codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3909</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3909</id><created>2010-03-20</created><authors><author><keyname>Ahammed</keyname><forenames>G. F. Ali</forenames></author><author><keyname>Banu</keyname><forenames>Reshma</forenames></author></authors><title>Anakyzing the performance of Active Queue Management Algorithms</title><categories>cs.NI</categories><comments>19 Pages, IJCNC Journal 2010</comments><doi>10.5121/ijcnc.2010.2201</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Congestion is an important issue which researchers focus on in the
Transmission Control Protocol (TCP) network environment. To keep the stability
of the whole network, congestion control algorithms have been extensively
studied. Queue management method employed by the routers is one of the
important issues in the congestion control study. Active queue management (AQM)
has been proposed as a router-based mechanism for early detection of congestion
inside the network. In this paper we analyzed several active queue management
algorithms with respect to their abilities of maintaining high resource
utilization, identifying and restricting disproportionate bandwidth usage, and
their deployment complexity. We compare the performance of FRED, BLUE, SFB, and
CHOKe based on simulation results, using RED and Drop Tail as the evaluation
baseline. The characteristics of different algorithms are also discussed and
compared. Simulation is done by using Network Simulator(NS2) and the graphs are
drawn using X- graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3920</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3920</id><created>2010-03-20</created><authors><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Ranjan</keyname><forenames>Rajiv</forenames></author><author><keyname>Calheiros</keyname><forenames>Rodrigo N.</forenames></author></authors><title>InterCloud: Utility-Oriented Federation of Cloud Computing Environments
  for Scaling of Application Services</title><categories>cs.DC</categories><comments>20 pages, 4 figures, 3 tables, conference paper</comments><acm-class>C.2.4</acm-class><journal-ref>Proceedings of the 10th International Conference on Algorithms and
  Architectures for Parallel Processing (ICA3PP 2010, Busan, South Korea, May
  21-23, 2010), LNCS, Springer, Germany, 2010.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing providers have setup several data centers at different
geographical locations over the Internet in order to optimally serve needs of
their customers around the world. However, existing systems do not support
mechanisms and policies for dynamically coordinating load distribution among
different Cloud-based data centers in order to determine optimal location for
hosting application services to achieve reasonable QoS levels. Further, the
Cloud computing providers are unable to predict geographic distribution of
users consuming their services, hence the load coordination must happen
automatically, and distribution of services must change in response to changes
in the load. To counter this problem, we advocate creation of federated Cloud
computing environment (InterCloud) that facilitates just-in-time,
opportunistic, and scalable provisioning of application services, consistently
achieving QoS targets under variable workload, resource and network conditions.
The overall goal is to create a computing environment that supports dynamic
expansion or contraction of capabilities (VMs, services, storage, and database)
for handling sudden variations in service demands.
  This paper presents vision, challenges, and architectural elements of
InterCloud for utility-oriented federation of Cloud computing environments. The
proposed InterCloud environment supports scaling of applications across
multiple vendor clouds. We have validated our approach by conducting a set of
rigorous performance evaluation study using the CloudSim toolkit. The results
demonstrate that federated Cloud computing model has immense potential as it
offers significant performance gains as regards to response time and cost
saving under dynamic workload scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3932</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3932</id><created>2010-03-20</created><authors><author><keyname>Gingl</keyname><forenames>Zoltan</forenames></author><author><keyname>Khatri</keyname><forenames>Sunil</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo</forenames></author></authors><title>Towards brain-inspired computing</title><categories>physics.gen-ph cs.OH</categories><comments>10 pages</comments><journal-ref>Fluctuation and Noise Letters 9 (2010) pp. 403-412</journal-ref><doi>10.1142/S0219477510000332</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present introductory considerations and analysis toward computing
applications based on the recently introduced deterministic logic scheme with
random spike (pulse) trains [Phys. Lett. A 373 (2009) 2338-2342]. Also, in
considering the questions, &quot;Why random?&quot; and &quot;Why pulses?&quot;, we show that the
random pulse based scheme provides the advantages of realizing multivalued
deterministic logic. Pulse trains are realized by an element called
orthogonator. We discuss two different types of orthogonators, parallel
(intersection-based) and serial (demultiplexer-based) orthogonators. The last
one can be slower but it makes sequential logic design straightforward. We
propose generating a multidimensional logic hyperspace [Physics Letters A 373
(2009) 1928-1934] by using the zero-crossing events of uncorrelated Gaussian
electrical noises available in the chips. The spike trains in the hyperspace
are non-overlapping, and are referred to as neuro-bits. To demonstrate this
idea, we generate 3-dimensional hyperspace bases using 2 Gaussian noises as
sources for neuro-bits, respectively. In such a scenario, the detection of
different hyperspace basis elements may have vastly differing delays. We show
that it is possible to provide an identical speed for all the hyperspace bases
elements using correlated noise sources, and demonstrate this for the 2
neuro-bits situations. The key impact of this paper is to demonstrate that a
logic design approach using such neuro-bits can yield a fast, low power
processing and environmental variation tolerant means of designing computer
circuitry. It also enables the realization of multi-valued logic, significantly
increasing the complexity of computer circuits by allowing several neuro-bits
to be transmitted on a single wire.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3956</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3956</id><created>2010-03-20</created><authors><author><keyname>Keller</keyname><forenames>Nathan</forenames></author></authors><title>A tight quantitative version of Arrow's impossibility theorem</title><categories>math.CO cs.GT math.PR</categories><comments>24 pages</comments><msc-class>05D40; 60C05; 91B14; 39A12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The well-known Impossibility Theorem of Arrow asserts that any Generalized
Social Welfare Function (GSWF) with at least three alternatives, which
satisfies Independence of Irrelevant Alternatives (IIA) and Unanimity and is
not a dictatorship, is necessarily non-transitive. In 2002, Kalai asked whether
one can obtain the following quantitative version of the theorem: For any
$\epsilon&gt;0$, there exists $\delta=\delta(\epsilon)$ such that if a GSWF on
three alternatives satisfies the IIA condition and its probability of
non-transitive outcome is at most $\delta$, then the GSWF is at most
$\epsilon$-far from being a dictatorship or from breaching the Unanimity
condition. In 2009, Mossel proved such quantitative version, with
$\delta(\epsilon)=\exp(-C/\epsilon^{21})$, and generalized it to GSWFs with $k$
alternatives, for all $k \geq 3$. In this paper we show that the quantitative
version holds with $\delta(\epsilon)=C \cdot \epsilon^3$, and that this result
is tight up to logarithmic factors. Furthermore, our result (like Mossel's)
generalizes to GSWFs with $k$ alternatives. Our proof is based on the works of
Kalai and Mossel, but uses also an additional ingredient: a combination of the
Bonami-Beckner hypercontractive inequality with a reverse hypercontractive
inequality due to Borell, applied to find simultaneously upper bounds and lower
bounds on the &quot;noise correlation&quot; between Boolean functions on the discrete
cube.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3966</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3966</id><created>2010-03-20</created><authors><author><keyname>Dey</keyname><forenames>Sandipan</forenames></author><author><keyname>Abraham</keyname><forenames>Ajith</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>An LSB Data Hiding Technique Using Natural Numbers</title><categories>cs.CR</categories><comments>6 Pages, 5 Figures, IEEE Third International Conference on
  Intelligent Information Hiding and Multimedia Signal Processing, IIHMSP 2007,
  Nov 26-28, 2007, Kaohsiung City, Taiwan, IEEE Computer Society press, USA,
  ISBN 0-7695-2994-1, pp. 473-476, 2007.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel data hiding technique is proposed, as an improvement
over the Fibonacci LSB data-hiding technique proposed by Battisti et al,based
on decomposition of a number (pixel-value) in sum of natural numbers. This
particular representation again generates a different set of (virtual)
bit-planes altogether, suitable for embedding purposes. We get more bit-planes
than that we get using Prime technique.These bit-planes not only allow one to
embed secret message in higher bit-planes but also do it without much
distortion, with a much better stego-image quality, and in a reliable and
secured manner, guaranteeing efficient retrieval of secret message. A
comparative performance study between the classical Least Significant Bit(LSB)
method, the Fibonacci LSB data-hiding technique and the proposed schemes
indicate that image quality of the stego-image hidden by the technique using
the natural decomposition method improves drastically against that using Prime
and Fibonacci decomposition technique. Experimental results also illustrate
that, the stego-image is visually indistinguishable from the original
cover-image. Also we show the optimality of our technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3967</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3967</id><created>2010-03-21</created><updated>2012-10-16</updated><authors><author><keyname>Golovin</keyname><forenames>Daniel</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Adaptive Submodularity: Theory and Applications in Active Learning and
  Stochastic Optimization</title><categories>cs.LG cs.AI cs.DS</categories><comments>53 pages, 6 figures. Version 3 was a major revision, with an improved
  policy-centric exposition and much new material. Version 4 is a minor
  revision, mostly to elaborate on the proof of the min-cost cover results; see
  Theorem 37 and Lemma 38</comments><acm-class>I.2.6; F.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving stochastic optimization problems under partial observability, where
one needs to adaptively make decisions with uncertain outcomes, is a
fundamental but notoriously difficult challenge. In this paper, we introduce
the concept of adaptive submodularity, generalizing submodular set functions to
adaptive policies. We prove that if a problem satisfies this property, a simple
adaptive greedy algorithm is guaranteed to be competitive with the optimal
policy. In addition to providing performance guarantees for both stochastic
maximization and coverage, adaptive submodularity can be exploited to
drastically speed up the greedy algorithm by using lazy evaluations. We
illustrate the usefulness of the concept by giving several examples of adaptive
submodular objectives arising in diverse applications including sensor
placement, viral marketing and active learning. Proving adaptive submodularity
for these problems allows us to recover existing results in these applications
as special cases, improve approximation guarantees and handle natural
generalizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3984</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3984</id><created>2010-03-21</created><authors><author><keyname>Turek</keyname><forenames>Javier</forenames></author><author><keyname>Yavneh</keyname><forenames>Irad</forenames></author><author><keyname>Protter</keyname><forenames>Matan</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author></authors><title>On MMSE and MAP Denoising Under Sparse Representation Modeling Over a
  Unitary Dictionary</title><categories>cs.CV stat.AP</categories><comments>29 pages, 10 figures</comments><msc-class>68U10</msc-class><doi>10.1109/TSP.2011.2151190</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among the many ways to model signals, a recent approach that draws
considerable attention is sparse representation modeling. In this model, the
signal is assumed to be generated as a random linear combination of a few atoms
from a pre-specified dictionary. In this work we analyze two Bayesian denoising
algorithms -- the Maximum-Aposteriori Probability (MAP) and the
Minimum-Mean-Squared-Error (MMSE) estimators, under the assumption that the
dictionary is unitary. It is well known that both these estimators lead to a
scalar shrinkage on the transformed coefficients, albeit with a different
response curve. In this work we start by deriving closed-form expressions for
these shrinkage curves and then analyze their performance. Upper bounds on the
MAP and the MMSE estimation errors are derived. We tie these to the error
obtained by a so-called oracle estimator, where the support is given,
establishing a worst-case gain-factor between the MAP/MMSE estimation errors
and the oracle's performance. These denoising algorithms are demonstrated on
synthetic signals and on true data (images).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3985</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3985</id><created>2010-03-21</created><authors><author><keyname>Giryes</keyname><forenames>Raja</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C</forenames></author></authors><title>The Projected GSURE for Automatic Parameter Tuning in Iterative
  Shrinkage Methods</title><categories>cs.CV stat.AP</categories><comments>20 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear inverse problems are very common in signal and image processing. Many
algorithms that aim at solving such problems include unknown parameters that
need tuning. In this work we focus on optimally selecting such parameters in
iterative shrinkage methods for image deblurring and image zooming. Our work
uses the projected Generalized Stein Unbiased Risk Estimator (GSURE) for
determining the threshold value lambda and the iterations number K in these
algorithms. The proposed parameter selection is shown to handle any degradation
operator, including ill-posed and even rectangular ones. This is achieved by
using GSURE on the projected expected error. We further propose an efficient
greedy parameter setting scheme, that tunes the parameter while iterating
without impairing the resulting deblurring performance. Finally, we provide
extensive comparisons to conventional methods for parameter selection, showing
the superiority of the use of the projected GSURE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.3996</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.3996</id><created>2010-03-21</created><authors><author><keyname>Neufeld</keyname><forenames>Michael</forenames></author></authors><title>DIP: Disruption-Tolerance for IP</title><categories>cs.NI</categories><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Disruption Tolerant Networks (DTN) have been a popular subject of recent
research and development. These networks are characterized by frequent, lengthy
outages and a lack of contemporaneous end-to-end paths. In this work we discuss
techniques for extending IP to operate more effectively in DTN scenarios. Our
scheme, Disruption Tolerant IP (DIP) uses existing IP packet headers, uses the
existing socket API for applications, is compatible with IPsec, and uses
familiar Policy-Based Routing techniques for network management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4012</identifier>
 <datestamp>2010-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4012</id><created>2010-03-21</created><authors><author><keyname>Fretter</keyname><forenames>Christoph</forenames></author><author><keyname>Krumov</keyname><forenames>Lachezar</forenames></author><author><keyname>Weihe</keyname><forenames>Karsten</forenames></author><author><keyname>M&#xfc;ller-Hannemann</keyname><forenames>Matthias</forenames></author><author><keyname>H&#xfc;tt</keyname><forenames>Marc-Thorsten</forenames></author></authors><title>Phase Synchronization in Railway Timetables</title><categories>cs.DS math.OC physics.soc-ph</categories><journal-ref>European Physical Journal B, Volume 77, Number 2, 281-289 (2010)</journal-ref><doi>10.1140/epjb/e2010-00234-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timetable construction belongs to the most important optimization problems in
public transport. Finding optimal or near-optimal timetables under the
subsidiary conditions of minimizing travel times and other criteria is a
targeted contribution to the functioning of public transport. In addition to
efficiency (given, e.g., by minimal average travel times), a significant
feature of a timetable is its robustness against delay propagation. Here we
study the balance of efficiency and robustness in long-distance railway
timetables (in particular the current long-distance railway timetable in
Germany) from the perspective of synchronization, exploiting the fact that a
major part of the trains run nearly periodically. We find that synchronization
is highest at intermediate-sized stations. We argue that this synchronization
perspective opens a new avenue towards an understanding of railway timetables
by representing them as spatio-temporal phase patterns. Robustness and
efficiency can then be viewed as properties of this phase pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4016</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4016</id><created>2010-03-21</created><authors><author><keyname>Iv&#xe1;nyi</keyname><forenames>Antal</forenames></author></authors><title>Reconstruction of complete interval tournaments</title><categories>cs.DM</categories><msc-class>05C20, 68C25</msc-class><acm-class>F.2</acm-class><journal-ref>Acta Univ. Sapientiae, Informatica, 1, 1 (2009) 71-88</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $a, b$ and $n$ be nonnegative integers $(b \geq a, \ b &gt; 0, \ n \geq 1)$,
$\mathcal{G}_n(a,b)$ be a multigraph on $n$ vertices in which any pair of
vertices is connected with at least $a$ and at most $b$ edges and \textbf{v =}
$(v_1, v_2, ..., v_n)$ be a vector containing $n$ nonnegative integers. We give
a necessary and sufficient condition for the existence of such orientation of
the edges of $\mathcal{G}_n(a,b)$, that the resulted out-degree vector equals
to \textbf{v}. We describe a reconstruction algorithm. In worst case checking
of \textbf{v} requires $\Theta(n)$ time and the reconstruction algorithm works
in $O(bn^3)$ time. Theorems of H. G. Landau (1953) and J. W. Moon (1963) on the
score sequences of tournaments are special cases $b = a = 1$ resp. $b = a \geq
1$ of our result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4021</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4021</id><created>2010-03-21</created><authors><author><keyname>Pimenov</keyname><forenames>Vitaly</forenames></author></authors><title>System-theoretic approach to image interest point detection</title><categories>cs.CV</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interest point detection is a common task in various computer vision
applications. Although a big variety of detector are developed so far
computational efficiency of interest point based image analysis remains to be
the problem. Current paper proposes a system-theoretic approach to interest
point detection. Starting from the analysis of interdependency between detector
and descriptor it is shown that given a descriptor it is possible to introduce
to notion of detector redundancy. Furthermore for each detector it is possible
to construct its irredundant and equivalent modification. Modified detector
possesses lower computational complexity and is preferable. It is also shown
that several known approaches to reduce computational complexity of image
registration can be generalized in terms of proposed theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4029</identifier>
 <datestamp>2010-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4029</id><created>2010-03-21</created><updated>2010-12-11</updated><authors><author><keyname>Reshef</keyname><forenames>Yakir</forenames></author><author><keyname>Vadhan</keyname><forenames>Salil</forenames></author></authors><title>On Extractors and Exposure-Resilient Functions for Sublogarithmic
  Entropy</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study deterministic extractors for oblivious bit-fixing sources (a.k.a.
resilient functions) and exposure-resilient functions with small min-entropy:
of the function's n input bits, k &lt;&lt; n bits are uniformly random and unknown to
the adversary. We simplify and improve an explicit construction of extractors
for bit-fixing sources with sublogarithmic k due to Kamp and Zuckerman (SICOMP
2006), achieving error exponentially small in k rather than polynomially small
in k. Our main result is that when k is sublogarithmic in n, the short output
length of this construction (O(log k) output bits) is optimal for extractors
computable by a large class of space-bounded streaming algorithms.
  Next, we show that a random function is an extractor for oblivious bit-fixing
sources with high probability if and only if k is superlogarithmic in n,
suggesting that our main result may apply more generally. In contrast, we show
that a random function is a static (resp. adaptive) exposure-resilient function
with high probability even if k is as small as a constant (resp. log log n). No
explicit exposure-resilient functions achieving these parameters are known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4036</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4036</id><created>2010-03-21</created><authors><author><keyname>Dey</keyname><forenames>Sandipan</forenames></author><author><keyname>Abraham</keyname><forenames>Ajith</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>A Very Simple Approach for 3-D to 2-D Mapping</title><categories>cs.GR</categories><comments>7 Pages, 5 Figures,</comments><journal-ref>International Journal on Image Processing and Communications ,
  Poland, Editor-in-Chief: R. S. Choras; Volume 11, No. 2, pp. 75 - 82, 2007.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many times we need to plot 3-D functions e.g., in many scientificc
experiments. To plot this 3-D functions on 2-D screen it requires some kind of
mapping. Though OpenGL, DirectX etc 3-D rendering libraries have made this job
very simple, still these libraries come with many complex pre- operations that
are simply not intended, also to integrate these libraries with any kind of
system is often a tough trial. This article presents a very simple method of
mapping from 3D to 2D, that is free from any complex pre-operation, also it
will work with any graphics system where we have some primitive 2-D graphics
function. Also we discuss the inverse transform and how to do basic computer
graphics transformations using our coordinate mapping system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4042</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4042</id><created>2010-03-21</created><updated>2015-03-26</updated><authors><author><keyname>Choi</keyname><forenames>Sou-Cheng T.</forenames></author><author><keyname>Paige</keyname><forenames>Christopher C.</forenames></author><author><keyname>Saunders</keyname><forenames>Michael A.</forenames></author></authors><title>MINRES-QLP: a Krylov subspace method for indefinite or singular
  symmetric systems</title><categories>math.NA cs.CE cs.NA stat.CO</categories><comments>26 pages, 6 figures</comments><msc-class>15A06, 65F10, 65F20, 65F22, 65F25, 65F35, 65F50, 93E24</msc-class><journal-ref>SIAM Journal on Scientific Computing, Volume 33, Issue 4,
  1810-1836, 2011</journal-ref><doi>10.1137/100787921</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  CG, SYMMLQ, and MINRES are Krylov subspace methods for solving symmetric
systems of linear equations. When these methods are applied to an incompatible
system (that is, a singular symmetric least-squares problem), CG could break
down and SYMMLQ's solution could explode, while MINRES would give a
least-squares solution but not necessarily the minimum-length (pseudoinverse)
solution. This understanding motivates us to design a MINRES-like algorithm to
compute minimum-length solutions to singular symmetric systems.
  MINRES uses QR factors of the tridiagonal matrix from the Lanczos process
(where R is upper-tridiagonal). MINRES-QLP uses a QLP decomposition (where
rotations on the right reduce R to lower-tridiagonal form). On ill-conditioned
systems (singular or not), MINRES-QLP can give more accurate solutions than
MINRES. We derive preconditioned MINRES-QLP, new stopping rules, and better
estimates of the solution and residual norms, the matrix norm, and the
condition number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4049</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4049</id><created>2010-03-21</created><authors><author><keyname>Dakshayini</keyname><forenames>M</forenames></author><author><keyname>Nair</keyname><forenames>T R GopalaKrishnan</forenames></author></authors><title>An Optimal Prefix Replication Strategy for VoD Services</title><categories>cs.MM</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose scalable proxy servers cluster architecture of
interconnected proxy servers for high quality and high availability services.
We also propose an optimal regional popularity based video prefix replication
strategy and a scene change based replica caching algorithm that utilizes the
zipf-like video popularity distribution to maximize the availability of videos
closer to the client and request-servicing rate thereby reducing the client
rejection ratio and the response time for the client. The simulation results of
our proposed architecture and algorithm show the greater achievement in
maximizing the availability of videos, client request-servicing rate and in
reduction of initial start-up latency and client rejection ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4053</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4053</id><created>2010-03-21</created><authors><author><keyname>Maini</keyname><forenames>Raman</forenames></author><author><keyname>Aggarwal</keyname><forenames>Himanshu</forenames></author></authors><title>A Comprehensive Review of Image Enhancement Techniques</title><categories>cs.CV</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principle objective of Image enhancement is to process an image so that
result is more suitable than original image for specific application. Digital
image enhancement techniques provide a multitude of choices for improving the
visual quality of images. Appropriate choice of such techniques is greatly
influenced by the imaging modality, task at hand and viewing conditions. This
paper will provide an overview of underlying concepts, along with algorithms
commonly used for image enhancement. The paper focuses on spatial domain
techniques for image enhancement, with particular reference to point processing
methods and histogram processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4057</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4057</id><created>2010-03-22</created><authors><author><keyname>Kim</keyname><forenames>Hyun Kwang</forenames></author><author><keyname>Lee</keyname><forenames>Joon Yop</forenames></author><author><keyname>Oh</keyname><forenames>Dong Yeol</forenames></author></authors><title>Construction of optimal codes in deletion and insertion metric</title><categories>cs.IT math.IT</categories><comments>20 pages, The material of this paper was presented in part at the
  10th International Workshop on Algebraic and Combinatorial Coding Theory,
  Zvenigorod, Russia, September 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve Levenshtein's upper bound for the cardinality of a code of length
four that is capable of correcting single deletions over an alphabet of even
size. We also illustrate that the new upper bound is sharp. Furthermore we
construct an optimal perfect code that is capable of correcting single
deletions for the same parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4062</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4062</id><created>2010-03-22</created><authors><author><keyname>Nair</keyname><forenames>T R Gopalakrishnan</forenames></author><author><keyname>Jayarekha</keyname><forenames>P</forenames></author></authors><title>A Rank Based Replacement Policy for Multimedia Server Cache Using
  Zipf-Like Law</title><categories>cs.PF</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cache replacement algorithm plays an important role in the overall
performance of Proxy-Server system. In this paper we have proposed VoD cache
memory replacement algorithm for a multimedia server system. We propose a Rank
based cache replacement policy to manage the cache space in individual proxy
server cache. Proposed replacement strategy incorporates in a simple way the
most important characteristics of the video and its accesses such as its size,
access frequency, recentness of the last access and the cost incurred while
transferring the requested video from the server to the proxy. We compare our
algorithm with some popular cache replacement algorithm using simulation. The
video objects are ranked based on the access trend by considering the factors
such as size, frequency and cost. Many studies have demonstrated that
Zipf's-like law can govern many features of the VoD and is used to describe the
popularity of the video. In this paper, we have designed a model, which ranks
the video on the basis of its popularity using the Zipf-like law. The video
with higher ranking is named &quot;hot&quot;, while the video with lower ranking is named
&quot;cold&quot;. The result show that the proposed rank based algorithm improves cache
hit ratio, cache byte ratio and average request latencies compared to other
algorithms. Our experimental results indicate that Rank based cache replacement
algorithm outperforms LRU, LFU and Greedy Dual.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4063</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4063</id><created>2010-03-22</created><authors><author><keyname>Suresh</keyname><forenames>P</forenames></author><author><keyname>Kesavan</keyname><forenames>R</forenames></author></authors><title>Analysis of Supply Chain Network Using RFID Technique with Hybrid
  Algorithm</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio Frequency IDentification (RFID) is a dedicated short range
communication technology. The term RFID is used to describe various
technologies that use radio waves to automatically identify people or objects.
RFID is a method of remotely storing and retrieving data using RFID tag. Radio
Frequency Identification (RFID) technology has been attracting considerable
attention with the expectation of improved supply chain visibility for consumer
goods, apparel, and pharmaceutical manufacturers, as well as retailers and
government procurement agencies. RFID technology is used today in many
applications, including security and access control, transportation and supply
chain tracking. Supply Chain Management (SCM) is now at the centre stage of
Manufacturing and service organizations. According to the strategies in
markets, supply chains and logistics are naturally being modelled as
distributed systems. The economic importance has motivated both private
companies and academic researchers to pursue the use of operations research and
management service tools to improve the efficiency of Transportation. Referring
to such scenario, in this work RFID Technique adopted with hybrid algorithm to
optimize supply chain distribution network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4064</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4064</id><created>2010-03-22</created><authors><author><keyname>Madheswari</keyname><forenames>A. Neela</forenames></author><author><keyname>Banu</keyname><forenames>R. S. D. Wahida</forenames></author></authors><title>Measuring Bandwidth for Super Computer Workloads</title><categories>cs.PF</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel computing plays a major role in almost all the fields from research
to major concern problem solving purposes. Many researches are till now
focusing towards the area of parallel processing. Nowadays it extends its usage
towards the end user application such as GPU as well as multi-core processor
development. The bandwidth measurement is essential for resource management and
for studying the various performance factors of the existing super computer
systems which will be helpful for better system utilization since super
computers are very few and their resources should be properly utilized. In this
paper the real workload trace of one of the super computers LANL is taken and
shown how the bandwidth is estimated with the given parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4065</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4065</id><created>2010-03-22</created><authors><author><keyname>Chen</keyname><forenames>Chien-Ying</forenames></author><author><keyname>Yeh</keyname><forenames>Jen-Yuan</forenames></author><author><keyname>Ke</keyname><forenames>Hao-Ren</forenames></author></authors><title>Plagiarism Detection using ROUGE and WordNet</title><categories>cs.OH cs.CL</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the arrival of digital era and Internet, the lack of information control
provides an incentive for people to freely use any content available to them.
Plagiarism occurs when users fail to credit the original owner for the content
referred to, and such behavior leads to violation of intellectual property. Two
main approaches to plagiarism detection are fingerprinting and term occurrence;
however, one common weakness shared by both approaches, especially
fingerprinting, is the incapability to detect modified text plagiarism. This
study proposes adoption of ROUGE and WordNet to plagiarism detection. The
former includes ngram co-occurrence statistics, skip-bigram, and longest common
subsequence (LCS), while the latter acts as a thesaurus and provides semantic
information. N-gram co-occurrence statistics can detect verbatim copy and
certain sentence modification, skip-bigram and LCS are immune from text
modification such as simple addition or deletion of words, and WordNet may
handle the problem of word substitution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4066</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4066</id><created>2010-03-22</created><authors><author><keyname>Vidhya</keyname><forenames>S.</forenames></author><author><keyname>Karthikeyan</keyname><forenames>S.</forenames></author></authors><title>A Security Based Data Mining Approach in Data Grid</title><categories>cs.DC cs.DB</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grid computing is the next logical step to distributed computing. Main
objective of grid computing is an innovative approach to share resources such
as CPU usage; memory sharing and software sharing. Data Grids provide
transparent access to semantically related data resources in a heterogeneous
system. The system incorporates both data mining and grid computing techniques
where Grid application reduces the time for sending results to several clients
at the same time and Data mining application on computational grids gives fast
and sophisticated results to users. In this work, grid based data mining
technique is used to do automatic allocation based on probabilistic mining
frequent sequence algorithm. It finds frequent sequences for many users at a
time with accurate result. It also includes the trust management architecture
for trust enhanced security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4067</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4067</id><created>2010-03-22</created><authors><author><keyname>JansiRani</keyname><forenames>P. G.</forenames></author><author><keyname>Bhaskaran</keyname><forenames>R.</forenames></author></authors><title>Computation of Reducts Using Topology and Measure of Significance of
  Attributes</title><categories>cs.IR</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data generated in the fields of science, technology, business and in many
other fields of research are increasing in an exponential rate. The way to
extract knowledge from a huge set of data is a challenging task. This paper
aims to propose a hybrid and viable method to deal with an information system
in data mining, using topological techniques and the significance of the
attributes measured using rough set theory, to compute the reduct, This will
reduce the randomness in the process of elimination of redundant attributes,
which, in turn, will reduce the complexity of the computation of reducts of an
information system where a large amount of data have to be processed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4068</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4068</id><created>2010-03-22</created><authors><author><keyname>Gautam</keyname><forenames>Pratima</forenames></author><author><keyname>Pardasani</keyname><forenames>K. R.</forenames></author></authors><title>A Novel Approach For Discovery Multi Level Fuzzy Association Rule Mining</title><categories>cs.DB</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding multilevel association rules in transaction databases is most
commonly seen in is widely used in data mining. In this paper, we present a
model of mining multilevel association rules which satisfies the different
minimum support at each level, we have employed fuzzy set concepts, multi-level
taxonomy and different minimum supports to find fuzzy multilevel association
rules in a given transaction data set. Apriori property is used in model to
prune the item sets. The proposed model adopts a topdown progressively
deepening approach to derive large itemsets. This approach incorporates fuzzy
boundaries instead of sharp boundary intervals. An example is also given to
demonstrate and support that the proposed mining algorithm can derive the
multiple-level association rules under different supports in a simple and
effective manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4070</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4070</id><created>2010-03-22</created><authors><author><keyname>Kapadia</keyname><forenames>Viral V.</forenames></author><author><keyname>Patel</keyname><forenames>Sudarshan N.</forenames></author><author><keyname>Jhaveri</keyname><forenames>Rutvij H.</forenames></author></authors><title>Comparative Study of Hidden Node Problem and Solution Using Different
  Techniques and Protocols</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden nodes in a wireless network refer to nodes that are out of range of
other nodes or a collection of nodes. We will discuss a few problems introduced
by the RTS/CTS mechanism of collision avoidance and focus on the virtual
jamming problem, which allows a malicious node to effectively jam a large
fragment of a wireless network at minimum expense of power. We have also
discussed WiCCP (Wireless Central Coordinated Protocol) which is a protocol
booster that also provides good solution to hidden nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4071</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4071</id><created>2010-03-22</created><authors><author><keyname>Sheikh</keyname><forenames>Rashid</forenames></author><author><keyname>Kumar</keyname><forenames>Beerendra</forenames></author><author><keyname>Mishra</keyname><forenames>Durgesh Kumar</forenames></author></authors><title>A Distributed k-Secure Sum Protocol for Secure Multi-Party Computations</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure sum computation of private data inputs is an interesting example of
Secure Multiparty Computation (SMC) which has attracted many researchers to
devise secure protocols with lower probability of data leakage. In this paper,
we provide a novel protocol to compute the sum of individual data inputs with
zero probability of data leakage when two neighbor parties collude to know the
data of a middle party. We break the data block of each party into number of
segments and redistribute the segments among parties before the computation.
These entire steps create a scenario in which it becomes impossible for semi
honest parties to know the private data of some other party.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4073</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4073</id><created>2010-03-22</created><authors><author><keyname>Mirashe</keyname><forenames>Shivaji P.</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author></authors><title>Quality of Service with Bandwidth</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with providing Quality of Service (QoS) over IP based
networks. We are going to give a brief survey about this topic, and present our
work at this area. There are many solutions of the problem, but the
standardization of the methods is not finished yet. At the moment there are two
kinds of approaches of the reservation problem. The distributed method handles
the network nodes independently, and get the nodes making their own admittance
decisions along the reservation path (i.e. Border Gateway Reservation Protocol
BGRP. The centralized way -we discuss in details-, which collects the network
nodes into domains, and handles them using a network manager. Generally there
are two significant parts of the network management: intra domain, and
inter-domain. This article focuses on making reservations over several domains,
which is the part of the inter-domain functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4074</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4074</id><created>2010-03-22</created><authors><author><keyname>Mirashe</keyname><forenames>Shivaji P.</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author></authors><title>Cloud Computing</title><categories>cs.DC cs.NI</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing as you know it is about to change, your applications and documents
are going to move from the desktop into the cloud. I'm talking about cloud
computing, where applications and files are hosted on a &quot;cloud&quot; consisting of
thousands of computers and servers, all linked together and accessible via the
Internet. With cloud computing, everything you do is now web based instead of
being desktop based. You can access all your programs and documents from any
computer that's connected to the Internet. How will cloud computing change the
way you work? For one thing, you're no longer tied to a single computer. You
can take your work anywhere because it's always accessible via the web. In
addition, cloud computing facilitates group collaboration, as all group members
can access the same programs and documents from wherever they happen to be
located. Cloud computing might sound far-fetched, but chances are you're
already using some cloud applications. If you're using a web-based email
program, such as Gmail or Hotmail, you're computing in the cloud. If you're
using a web-based application such as Google Calendar or Apple Mobile Me,
you're computing in the cloud. If you're using a file- or photo-sharing site,
such as Flickr or Picasa Web Albums, you're computing in the cloud. It's the
technology of the future, available to use today.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4075</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4075</id><created>2010-03-22</created><authors><author><keyname>Havangi</keyname><forenames>R.</forenames></author><author><keyname>Teshnehlab</keyname><forenames>M.</forenames></author><author><keyname>Nekoui</keyname><forenames>M. A.</forenames></author></authors><title>A Neuro-Fuzzy Multi Swarm FastSLAM Framework</title><categories>cs.RO</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  FastSLAM is a framework for simultaneous localization using a
Rao-Blackwellized particle filter. In FastSLAM, particle filter is used for the
mobile robot pose (position and orientation) estimation, and an Extended Kalman
Filter (EKF) is used for the feature location's estimation. However, FastSLAM
degenerates over time. This degeneracy is due to the fact that a particle set
estimating the pose of the robot loses its diversity. One of the main reasons
for loosing particle diversity in FastSLAM is sample impoverishment. It occurs
when likelihood lies in the tail of the proposal distribution. In this case,
most of particle weights are insignificant. Another problem of FastSLAM relates
to the design of an extended Kalman filter for landmark position's estimation.
The performance of the EKF and the quality of the estimation depends heavily on
correct a priori knowledge of the process and measurement noise covariance
matrices (Q and R) that are in most applications unknown. On the other hand, an
incorrect a priori knowledge of Q and R may seriously degrade the performance
of the Kalman filter. This paper presents a Neuro-Fuzzy Multi Swarm FastSLAM
Framework. In our proposed method, a Neuro-Fuzzy extended kalman filter for
landmark feature estimation, and a particle filter based on particle swarm
optimization are presented to overcome the impoverishment of FastSLAM.
Experimental results demonstrate the effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4076</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4076</id><created>2010-03-22</created><authors><author><keyname>Danessh</keyname><forenames>M. S.</forenames></author><author><keyname>Balasubramanian</keyname><forenames>C.</forenames></author><author><keyname>Duraiswamy</keyname><forenames>K.</forenames></author></authors><title>Similarity Data Item Set Approach: An Encoded Temporal Data Base
  Technique</title><categories>cs.DB</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data mining has been widely recognized as a powerful tool to explore added
value from large-scale databases. Finding frequent item sets in databases is a
crucial in data mining process of extracting association rules. Many algorithms
were developed to find the frequent item sets. This paper presents a summary
and a comparative study of the available FP-growth algorithm variations
produced for mining frequent item sets showing their capabilities and
efficiency in terms of time and memory consumption on association rule mining
by taking application of specific information into account. It proposes pattern
growth mining paradigm based FP-tree growth algorithm, which employs a tree
structure to compress the database. The performance study shows that the anti-
FP-growth method is efficient and scalable for mining both long and short
frequent patterns and is about an order of magnitude faster than the Apriority
algorithm and also faster than some recently reported new frequent-pattern
mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4077</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4077</id><created>2010-03-22</created><updated>2010-03-29</updated><authors><author><keyname>Javed</keyname><forenames>Muhammad</forenames></author><author><keyname>Ahmad</keyname><forenames>Bashir</forenames></author><author><keyname>Hussain</keyname><forenames>Shahid</forenames></author><author><keyname>Ahmad</keyname><forenames>Shakeel</forenames></author></authors><title>Mapping The Best Practices of XP and Project Management: Well defined
  approach for Project Manager</title><categories>cs.SE</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software engineering is one of the most recent additions in various
disciplines of system engineering. It has emerged as a key obedience of system
engineering in a quick succession of time. Various Software Engineering
approaches are followed in order to produce comprehensive software solutions of
affordable cost with reasonable delivery timeframe with less uncertainty. All
these objectives are only satisfied when project's status is properly monitored
and controlled; eXtreme Programming (XP) uses the best practices of AGILE
methodology and helps in development of small size software very sharply. In
this paper, authors proposed that via XP, high quality software with less
uncertainty and under estimated cost can be developed due to proper monitoring
and controlling of project. Moreover, authors give guidelines that how
activities of project management can be embedded into development life cycle of
XP to enhance the quality of software products and reduce the uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4078</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4078</id><created>2010-03-22</created><authors><author><keyname>Kulkarni</keyname><forenames>Shrirang Ambaji</forenames></author><author><keyname>Rao</keyname><forenames>G Raghavendra</forenames></author></authors><title>A Group Vehicular Mobility Model for Routing Protocol Analysis in Mobile
  Ad Hoc Network</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance of routing protocols in mobile ad-hoc networks is greatly
affected by the dynamic nature of nodes, route failures, wireless channels with
variable bandwidth and scalability issues. A mobility model imitates the real
world movement of mobile nodes and is central component to simulation based
studies. In this paper we consider mobility nodes which mimic the vehicular
motion of nodes like Manhattan mobility model and City Section mobility model.
We also propose a new Group Vehicular mobility model that takes the best
features of group mobility models like Reference Point Group mobility model and
applies it to vehicular models. We analyze the performance of our model known
as Group Vehicular mobility model (GVMM) and other vehicular mobility models
with various metrics. This analysis provides us with an insight about the
impact of mobility models on the performance of routing protocols for ad-hoc
networks. The routing protocols are simulated and measured for performance and
finally we arrive at the correlation about the impact of mobility models on
routing protocols, which are central to the design of mobile adhoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4079</identifier>
 <datestamp>2010-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4079</id><created>2010-03-22</created><authors><author><keyname>H</keyname><forenames>Swathi.</forenames></author></authors><title>Gene Expression Data Knowledge Discovery using Global and Local
  Clustering</title><categories>cs.CE cs.LG q-bio.GN</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To understand complex biological systems, the research community has produced
huge corpus of gene expression data. A large number of clustering approaches
have been proposed for the analysis of gene expression data. However,
extracting important biological knowledge is still harder. To address this
task, clustering techniques are used. In this paper, hybrid Hierarchical
k-Means algorithm is used for clustering and biclustering gene expression data
is used. To discover both local and global clustering structure biclustering
and clustering algorithms are utilized. A validation technique, Figure of Merit
is used to determine the quality of clustering results. Appropriate knowledge
is mined from the clusters by embedding a BLAST similarity search program into
the clustering and biclustering process. To discover both local and global
clustering structure biclustering and clustering algorithms are utilized. To
determine the quality of clustering results, a validation technique, Figure of
Merit is used. Appropriate knowledge is mined from the clusters by embedding a
BLAST similarity search program into the clustering and biclustering process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4080</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4080</id><created>2010-03-22</created><authors><author><keyname>Haron</keyname><forenames>Nazleeni S.</forenames></author><author><keyname>Saleem</keyname><forenames>Nur S.</forenames></author><author><keyname>Hasan</keyname><forenames>Mohd H.</forenames></author><author><keyname>Ariffin</keyname><forenames>Mazeyanti M.</forenames></author><author><keyname>Aziz</keyname><forenames>Izzatdin A.</forenames></author></authors><title>A RFID-based Campus Context-Aware Notification System</title><categories>cs.NI</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and development of a context-aware
notification system for university students using RFID technology. This system
is leveraging on the student's matrix card as the RFID tag (sensor), RFID
reader and server as the processors and screen monitor at the various locations
in the campus as the actuator of the output. This system aims to deliver urgent
notifications to the intended students immediately at their respective
locations. In addition, the system is also able to display personalized
information based on the students' preferences and current location when
accessing the system. The background of the study, the design approaches for
this system and the preliminary evaluation of the prototype are presented in
this paper. The evaluation results have indicated that the the proposed system
is useful and easy to use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4081</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4081</id><created>2010-03-22</created><authors><author><keyname>Rashid</keyname><forenames>Razif</forenames></author><author><keyname>Elamvazuthi</keyname><forenames>I.</forenames></author><author><keyname>Begam</keyname><forenames>Mumtaj</forenames></author><author><keyname>Arrofiq</keyname><forenames>M.</forenames></author></authors><title>Fuzzy-based Navigation and Control of a Non-Holonomic Mobile Robot</title><categories>cs.NE cs.RO</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the use of non-analytical methods of computing such as fuzzy
logic, evolutionary computation, and neural networks has demonstrated the
utility and potential of these paradigms for intelligent control of mobile
robot navigation. In this paper, a theoretical model of a fuzzy based
controller for an autonomous mobile robot is developed. The paper begins with
the mathematical model of the robot that involves the kinematic model. Then,
the fuzzy logic controller is developed and discussed in detail. The proposed
method is successfully tested in simulations, and it compares the effectiveness
of three different set of membership of functions. It is shown that fuzzy logic
controller with input membership of three provides better performance compared
with five and seven membership functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4083</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4083</id><created>2010-03-22</created><authors><author><keyname>Muda</keyname><forenames>Lindasalwa</forenames></author><author><keyname>Begam</keyname><forenames>Mumtaj</forenames></author><author><keyname>Elamvazuthi</keyname><forenames>I.</forenames></author></authors><title>Voice Recognition Algorithms using Mel Frequency Cepstral Coefficient
  (MFCC) and Dynamic Time Warping (DTW) Techniques</title><categories>cs.MM</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital processing of speech signal and voice recognition algorithm is very
important for fast and accurate automatic voice recognition technology. The
voice is a signal of infinite information. A direct analysis and synthesizing
the complex voice signal is due to too much information contained in the
signal. Therefore the digital signal processes such as Feature Extraction and
Feature Matching are introduced to represent the voice signal. Several methods
such as Liner Predictive Predictive Coding (LPC), Hidden Markov Model (HMM),
Artificial Neural Network (ANN) and etc are evaluated with a view to identify a
straight forward and effective method for voice signal. The extraction and
matching process is implemented right after the Pre Processing or filtering
signal is performed. The non-parametric method for modelling the human auditory
perception system, Mel Frequency Cepstral Coefficients (MFCCs) are utilize as
extraction techniques. The non linear sequence alignment known as Dynamic Time
Warping (DTW) introduced by Sakoe Chiba has been used as features matching
techniques. Since it's obvious that the voice signal tends to have different
temporal rate, the alignment is important to produce the better
performance.This paper present the viability of MFCC to extract features and
DTW to compare the test patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4084</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4084</id><created>2010-03-22</created><authors><author><keyname>Alanazi</keyname><forenames>Hamdan. O.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author><author><keyname>Jalab</keyname><forenames>Hamid A.</forenames></author><author><keyname>AL-Ani</keyname><forenames>Zaidoon Kh.</forenames></author></authors><title>New Classification Methods for Hiding Information into Two Parts:
  Multimedia Files and Non Multimedia Files</title><categories>cs.MM cs.CR</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of various multimedia technologies, more and more
multimedia data are generated and transmitted in the medical, commercial, and
military fields, which may include some sensitive information which should not
be accessed by or can only be partially exposed to the general users.
Therefore, security and privacy has become an important, Another problem with
digital document and video is that undetectable modifications can be made with
very simple and widely available equipment, which put the digital material for
evidential purposes under question .With the large flood of information and the
development of the digital format Information hiding considers one of the
techniques which used to protect the important information. The main goals for
this paper, provides a general overview of the New Classification Methods for
Hiding Information into Two Parts: Multimedia Files and Non Multimedia Files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4085</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4085</id><created>2010-03-22</created><authors><author><keyname>Alanazi</keyname><forenames>Hamdan. O.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author><author><keyname>Jalab</keyname><forenames>Hamid A.</forenames></author><author><keyname>Shabbir</keyname><forenames>M.</forenames></author><author><keyname>Al-Nabhani</keyname><forenames>Y.</forenames></author></authors><title>New Comparative Study Between DES, 3DES and AES within Nine Factors</title><categories>cs.CR</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the rapid development of various multimedia technologies, more and more
multimedia data are generated and transmitted in the medical, also the internet
allows for wide distribution of digital media data. It becomes much easier to
edit, modify and duplicate digital information. Besides that, digital documents
are also easy to copy and distribute, therefore it will be faced by many
threats. It is a big security and privacy issue, it become necessary to find
appropriate protection because of the significance, accuracy and sensitivity of
the information, which may include some sensitive information which should not
be accessed by or can only be partially exposed to the general users.
Therefore, security and privacy has become an important. Another problem with
digital document and video is that undetectable modifications can be made with
very simple and widely available equipment, which put the digital material for
evidential purposes under question. Cryptography considers one of the
techniques which used to protect the important information. In this paper a
three algorithm of multimedia encryption schemes have been proposed in the
literature and description. The New Comparative Study between DES, 3DES and AES
within Nine Factors achieving an efficiency, flexibility and security, which is
a challenge of researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4086</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4086</id><created>2010-03-22</created><authors><author><keyname>AL-Ani</keyname><forenames>Zaidoon Kh.</forenames></author><author><keyname>Zaidan</keyname><forenames>A. A.</forenames></author><author><keyname>Zaidan</keyname><forenames>B. B.</forenames></author><author><keyname>Alanazi</keyname><forenames>Hamdan. O.</forenames></author></authors><title>Overview: Main Fundamentals for Steganography</title><categories>cs.CR cs.MM</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid development of multimedia and internet allows for wide distribution
of digital media data. It becomes much easier to edit, modify and duplicate
digital information .Besides that, digital documents are also easy to copy and
distribute, therefore it will be faced by many threats. It is a big security
and privacy issue, it become necessary to find appropriate protection because
of the significance, accuracy and sensitivity of the information. Steganography
considers one of the techniques which used to protect the important
information. The main goals for this paper, to recognize the researchers for
the main fundamentals of steganography. In this paper provides a general
overview of the following subject areas: Steganography types, General
Steganography system, Characterization of Steganography Systems and
Classification of Steganography Techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4087</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4087</id><created>2010-03-22</created><authors><author><keyname>Pradhan</keyname><forenames>Ratika</forenames></author><author><keyname>Pradhan</keyname><forenames>Mohan P.</forenames></author><author><keyname>Bhusan</keyname><forenames>Ashish</forenames></author><author><keyname>Pradhan</keyname><forenames>Ronak K.</forenames></author><author><keyname>Ghose</keyname><forenames>M. K.</forenames></author></authors><title>Land-cover Classification and Mapping for Eastern Himalayan State Sikkim</title><categories>cs.CV</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Area of classifying satellite imagery has become a challenging task in
current era where there is tremendous growth in settlement i.e. construction of
buildings, roads, bridges, dam etc. This paper suggests an improvised k-means
and Artificial Neural Network (ANN) classifier for land-cover mapping of
Eastern Himalayan state Sikkim. The improvised k-means algorithm shows
satisfactory results compared to existing methods that includes k-Nearest
Neighbor and maximum likelihood classifier. The strength of the Artificial
Neural Network (ANN) classifier lies in the fact that they are fast and have
good recognition rate and it's capability of self-learning compared to other
classification algorithms has made it widely accepted. Classifier based on ANN
shows satisfactory and accurate result in comparison with the classical method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4088</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4088</id><created>2010-03-22</created><authors><author><keyname>Gupta</keyname><forenames>Richa</forenames></author><author><keyname>Tokekar</keyname><forenames>Sanjiv</forenames></author></authors><title>Proficient Pair of Replacement Algorithms on L1 and L2 Cache for Merge
  Sort</title><categories>cs.OS</categories><journal-ref>Journal of Computing, Volume 2, Issue 3, March 2010,
  https://sites.google.com/site/journalofcomputing/</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memory hierarchy is used to compete the processors speed. Cache memory is the
fast memory which is used to conduit the speed difference of memory and
processor. The access patterns of Level 1 cache (L1) and Level 2 cache (L2) are
different, when CPU not gets the desired data in L1 then it accesses L2. Thus
the replacement algorithm which works efficiently on L1 may not be as efficient
on L2. Similarly various applications such as Matrix Multiplication, Web, Fast
Fourier Transform (FFT) etc will have varying access pattern. Thus same
replacement algorithm for all types of application may not be efficient. This
paper works for getting an efficient pair of replacement algorithm on L1 and L2
for the algorithm Merge Sort. With the memory reference string of Merge Sort,
we have analyzed the behavior of various existing replacement algorithms on L1.
The existing replacement algorithms which are taken into consideration are:
Least Recently Used (LRU), Least Frequently Used (LFU) and First In First Out
(FIFO). After Analyzing the memory reference pattern of Merge Sort, we have
proposed a Partition Based Replacement algorithm (PBR_L1)) on L1 Cache.
Furthermore we have analyzed various pairs of algorithms on L1 and L2
respectively, resulting in finding a suitable pair of replacement algorithms.
Simulation on L1 shows, among the considered existing replacement algorithms
FIFO is performing better than others. While the proposed replacement algorithm
PBR_L1 is working about 1.7% to 44 % better than FIFO for various cache sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4090</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4090</id><created>2010-03-22</created><authors><author><keyname>Machado</keyname><forenames>Rodrigo</forenames><affiliation>Universidade Federal do Rio Grande do Sul</affiliation></author><author><keyname>Heckel</keyname><forenames>Reiko</forenames><affiliation>University of Leicester</affiliation></author><author><keyname>Ribeiro</keyname><forenames>Leila</forenames><affiliation>Universidade Federal do Rio Grande do Sul</affiliation></author></authors><title>Modeling and Reasoning over Distributed Systems using Aspect-Oriented
  Graph Grammars</title><categories>cs.LO cs.PL cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 39-50</journal-ref><doi>10.4204/EPTCS.21.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aspect-orientation is a relatively new paradigm that introduces abstractions
to modularize the implementation of system-wide policies. It is based on a
composition operation, called aspect weaving, that implicitly modifies a base
system by performing related changes within the system modules. Aspect-oriented
graph grammars (AOGG) extend the classic graph grammar formalism by defining
aspects as sets of rule-based modifications over a base graph grammar. Despite
the advantages of aspect-oriented concepts regarding modularity, the implicit
nature of the aspect weaving operation may also introduce issues when reasoning
about the system behavior. Since in AOGGs aspect weaving is characterized by
means of rule-based rewriting, we can overcome these problems by using known
analysis techniques from the graph transformation literature to study aspect
composition. In this paper, we present a case study of a distributed
client-server system with global policies, modeled as an aspect-oriented graph
grammar, and discuss how to use the AGG tool to identify potential conflicts in
aspect weaving.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4105</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4105</id><created>2010-03-22</created><authors><author><keyname>Kopczy&#x144;ski</keyname><forenames>Eryk</forenames></author></authors><title>Complexity of Problems for Commutative Grammars</title><categories>cs.FL</categories><comments>Full version of submission to LICS 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Parikh images of languages accepted by non-deterministic finite
automata and context-free grammars; in other words, we treat the languages in a
commutative way --- we do not care about the order of letters in the accepted
word, but rather how many times each one of them appears. In most cases we
assume that the alphabet is of fixed size. We show tight complexity bounds for
problems like membership, equivalence, and disjointness. In particular, we show
polynomial algorithms for membership and disjointness for Parikh images of
non-deterministic finite automata over fixed alphabet, and we show that
equivalence is Pi2P complete for context-free grammars over fixed terminal
alphabet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4140</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4140</id><created>2010-03-22</created><authors><author><keyname>Gu</keyname><forenames>Feng</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Integrating Real-Time Analysis With The Dendritic Cell Algorithm Through
  Segmentation</title><categories>cs.NE cs.AI cs.CR</categories><comments>8 pages, 7 tables, 3 figures, Genetic and Evolutionary Computation
  Conference (GECCO 2009), Montreal, Canada</comments><journal-ref>Proceedings of Genetic and Evolutionary Computation Conference
  (GECCO 2009), Montreal, Canada, 1203-1210</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an immune inspired algorithm, the Dendritic Cell Algorithm (DCA) has been
applied to a range of problems, particularly in the area of intrusion
detection. Ideally, the intrusion detection should be performed in real-time,
to continuously detect misuses as soon as they occur. Consequently, the
analysis process performed by an intrusion detection system must operate in
real-time or near-to real-time. The analysis process of the DCA is currently
performed offline, therefore to improve the algorithm's performance we suggest
the development of a real-time analysis component. The initial step of the
development is to apply segmentation to the DCA. This involves segmenting the
current output of the DCA into slices and performing the analysis in various
ways. Two segmentation approaches are introduced and tested in this paper,
namely antigen based segmentation (ABS) and time based segmentation (TBS). The
results of the corresponding experiments suggest that applying segmentation
produces different and significantly better results in some cases, when
compared to the standard DCA without segmentation. Therefore, we conclude that
the segmentation is applicable to the DCA for the purpose of real-time
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4141</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4141</id><created>2010-03-22</created><authors><author><keyname>Majid</keyname><forenames>Mazlina Abdul</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author></authors><title>Investigating Output Accuracy for a Discrete Event Simulation Model and
  an Agent Based Simulation Model</title><categories>cs.AI cs.CE cs.MA</categories><comments>5 pages, 4 figures, INFORMS Simulation Society Research Workshop</comments><journal-ref>Proceedings of the INFORMS Simulation Society Research Workshop,
  June 25-27, 2009, Warwick, UK, 101-105</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate output accuracy for a Discrete Event Simulation
(DES) model and Agent Based Simulation (ABS) model. The purpose of this
investigation is to find out which of these simulation techniques is the best
one for modelling human reactive behaviour in the retail sector. In order to
study the output accuracy in both models, we have carried out a validation
experiment in which we compared the results from our simulation models to the
performance of a real system. Our experiment was carried out using a large UK
department store as a case study. We had to determine an efficient
implementation of management policy in the store's fitting room using DES and
ABS. Overall, we have found that both simulation models were a good
representation of the real system when modelling human reactive behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4142</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4142</id><created>2010-03-22</created><authors><author><keyname>Kim</keyname><forenames>Jungwon</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Malicious Code Execution Detection and Response Immune System inspired
  by the Danger Theory</title><categories>cs.AI cs.CR cs.NE</categories><comments>4 pages, 1 table, Adaptive and Resilient Computing Security Workshop
  (ARCS-05), Santa Fe, USA</comments><journal-ref>Proceedings of Adaptive and Resilient Computing Security Workshop
  (ARCS-05), Santa Fe, USA, 2005,</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of system calls is one method employed by anomaly detection
systems to recognise malicious code execution. Similarities can be drawn
between this process and the behaviour of certain cells belonging to the human
immune system, and can be applied to construct an artificial immune system. A
recently developed hypothesis in immunology, the Danger Theory, states that our
immune system responds to the presence of intruders through sensing molecules
belonging to those invaders, plus signals generated by the host indicating
danger and damage. We propose the incorporation of this concept into a
responsive intrusion detection system, where behavioural information of the
system and running processes is combined with information regarding individual
system calls.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4145</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4145</id><created>2010-03-22</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan</forenames></author></authors><title>Mimicking the Behaviour of Idiotypic AIS Robot Controllers Using
  Probabilistic Systems</title><categories>cs.AI cs.NE cs.RO</categories><comments>7 pages, 2 figures, 6 tables, 13th World Multi-Conference on
  Systemics, Cybernetics and Informatics: WMSCI 2009, Orlando, Florida, USA</comments><journal-ref>Proceedings of the 13th World Multi-Conference on Systemics,
  Cybernetics and Informatics: WMSCI 2009, Orlando, Florida, USA, 272-278</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work has shown that robot navigation systems that employ an
architecture based upon the idiotypic network theory of the immune system have
an advantage over control techniques that rely on reinforcement learning only.
This is thought to be a result of intelligent behaviour selection on the part
of the idiotypic robot. In this paper an attempt is made to imitate idiotypic
dynamics by creating controllers that use reinforcement with a number of
different probabilistic schemes to select robot behaviour. The aims are to show
that the idiotypic system is not merely performing some kind of periodic random
behaviour selection, and to try to gain further insight into the processes that
govern the idiotypic mechanism. Trials are carried out using simulated Pioneer
robots that undertake navigation exercises. Results show that a scheme that
boosts the probability of selecting highly-ranked alternative behaviours to 50%
during stall conditions comes closest to achieving the properties of the
idiotypic system, but remains unable to match it in terms of all round
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4146</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4146</id><created>2010-03-22</created><authors><author><keyname>Bommarito</keyname><forenames>Michael J.</forenames><suffix>II</suffix></author><author><keyname>Katz</keyname><forenames>Daniel Martin</forenames></author></authors><title>A Mathematical Approach to the Study of the United States Code</title><categories>cs.IR cs.CY cs.DL physics.soc-ph</categories><comments>5 pages, 6 figures, 2 tables.</comments><doi>10.1016/j.physa.2010.05.057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The United States Code (Code) is a document containing over 22 million words
that represents a large and important source of Federal statutory law. Scholars
and policy advocates often discuss the direction and magnitude of changes in
various aspects of the Code. However, few have mathematically formalized the
notions behind these discussions or directly measured the resulting
representations. This paper addresses the current state of the literature in
two ways. First, we formalize a representation of the United States Code as the
union of a hierarchical network and a citation network over vertices containing
the language of the Code. This representation reflects the fact that the Code
is a hierarchically organized document containing language and explicit
citations between provisions. Second, we use this formalization to measure
aspects of the Code as codified in October 2008, November 2009, and March 2010.
These measurements allow for a characterization of the actual changes in the
Code over time. Our findings indicate that in the recent past, the Code has
grown in its amount of structure, interdependence, and language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4149</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4149</id><created>2010-03-22</created><authors><author><keyname>Martineau</keyname><forenames>Claude</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Tolone</keyname><forenames>Elsa</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Voyatzi</keyname><forenames>Stavroula</forenames><affiliation>IGM-LabInfo</affiliation></author></authors><title>Les Entit\'es Nomm\'ees : usage et degr\'es de pr\'ecision et de
  d\'esambigu\&quot;isation</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>26\`eme Colloque international sur le Lexique et la Grammaire
  (LGC'07), Bonifacio : France (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recognition and classification of Named Entities (NER) are regarded as an
important component for many Natural Language Processing (NLP) applications.
The classification is usually made by taking into account the immediate context
in which the NE appears. In some cases, this immediate context does not allow
getting the right classification. We show in this paper that the use of an
extended syntactic context and large-scale resources could be very useful in
the NER task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4187</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4187</id><created>2010-03-22</created><authors><author><keyname>Armbruster</keyname><forenames>Chris</forenames><affiliation>MPDL</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Saclay - Ile de France, IDSL</affiliation></author></authors><title>Comparing Repository Types - Challenges and barriers for subject-based
  repositories, research repositories, national repository systems and
  institutional repositories in serving scholarly communication</title><categories>cs.DL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After two decades of repository development, some conclusions may be drawn as
to which type of repository and what kind of service best supports digital
scholarly communication, and thus the production of new knowledge. Four types
of publication repository may be distinguished, namely the subject-based
repository, research repository, national repository system and institutional
repository. Two important shifts in the role of repositories may be noted. With
regard to content, a well-defined and high quality corpus is essential. This
implies that repository services are likely to be most successful when
constructed with the user and reader uppermost in mind. With regard to service,
high value to specific scholarly communities is essential. This implies that
repositories are likely to be most useful to scholars when they offer dedicated
services supporting the production of new knowledge. Along these lines,
challenges and barriers to repository development may be identified in three
key dimensions: a) identification and deposit of content; b) access and use of
services; and c) preservation of content and sustainability of service. An
indicative comparison of challenges and barriers in some major world regions
such as Europe, North America and East Asia plus Australia is offered in
conclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4196</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4196</id><created>2010-03-22</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Sherman</keyname><forenames>Galina</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Development of a Cargo Screening Process Simulator: A First Approach</title><categories>cs.AI cs.CE cs.MA</categories><comments>10 pages, 7 figures, 6th International Mediterranean Modeling
  Multiconference (EMSS 2009), Tenerife, Spain</comments><journal-ref>Proceedings of the 6th International Mediterranean Modeling
  Multiconference (EMSS 2009), Tenerife, Spain, 200-209</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficiency of current cargo screening processes at sea and air ports is
largely unknown as few benchmarks exists against which they could be measured.
Some manufacturers provide benchmarks for individual sensors but we found no
benchmarks that take a holistic view of the overall screening procedures and no
benchmarks that take operator variability into account. Just adding up
resources and manpower used is not an effective way for assessing systems where
human decision-making and operator compliance to rules play a vital role. Our
aim is to develop a decision support tool (cargo-screening system simulator)
that will map the right technology and manpower to the right commodity-threat
combination in order to maximise detection rates. In this paper we present our
ideas for developing such a system and highlight the research challenges we
have identified. Then we introduce our first case study and report on the
progress we have made so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4216</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4216</id><created>2010-03-18</created><updated>2011-05-05</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Hu</keyname><forenames>Xueying</forenames></author><author><keyname>Young</keyname><forenames>Virginia R.</forenames></author></authors><title>Minimizing the Probability of Lifetime Ruin under Stochastic Volatility</title><categories>q-fin.PM cs.SY math.OC math.PR</categories><comments>Keywords: Optimal investment, minimizing the probability of lifetime
  ruin, stochastic volatility</comments><doi>10.1016/j.insmatheco.2011.04.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We assume that an individual invests in a financial market with one riskless
and one risky asset, with the latter's price following a diffusion with
stochastic volatility. In the current financial market especially, it is
important to include stochastic volatility in the risky asset's price process.
Given the rate of consumption, we find the optimal investment strategy for the
individual who wishes to minimize the probability of going bankrupt. To solve
this minimization problem, we use techniques from stochastic optimal control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4261</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4261</id><created>2010-03-22</created><authors><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>L_1 embeddings of the Heisenberg group and fast estimation of graph
  isoperimetry</title><categories>math.MG cs.DS math.FA</categories><comments>To appear in Proceedings of the International Congress of
  Mathematicians, Hyderabad India, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey connections between the theory of bi-Lipschitz embeddings and the
Sparsest Cut Problem in combinatorial optimization. The story of the Sparsest
Cut Problem is a striking example of the deep interplay between analysis,
geometry, and probability on the one hand, and computational issues in discrete
mathematics on the other. We explain how the key ideas evolved over the past 20
years, emphasizing the interactions with Banach space theory, geometric measure
theory, and geometric group theory. As an important illustrative example, we
shall examine recently established connections to the the structure of the
Heisenberg group, and the incompatibility of its Carnot-Carath\'eodory geometry
with the geometry of the Lebesgue space $L_1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4270</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4270</id><created>2010-03-22</created><authors><author><keyname>Ning</keyname><forenames>Haishi</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author><author><keyname>Leung</keyname><forenames>Kin K.</forenames></author></authors><title>Wireless Network Coding with Imperfect Overhearing</title><categories>cs.IT math.IT</categories><comments>21 pages, 6 figures, IEEE Trans. Commun.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Not only is network coding essential to achieve the capacity of a
single-session multicast network, it can also help to improve the throughput of
wireless networks with multiple unicast sessions when overheard information is
available. Most previous research aimed at realizing such improvement by using
perfectly overheard information, while in practice, especially for wireless
networks, overheard information is often imperfect. To date, it is unclear
whether network coding should still be used in such situations with imperfect
overhearing. In this paper, a simple but ubiquitous wireless network model with
two unicast sessions is used to investigate this problem. From the diversity
and multiplexing tradeoff perspective, it is proved that even when overheard
information is imperfect, network coding can still help to improve the overall
system performance. This result implies that network coding should be used
actively regardless of the reception quality of overheard information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4274</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4274</id><created>2010-03-22</created><authors><author><keyname>Duersch</keyname><forenames>Peter</forenames></author><author><keyname>Oechssler</keyname><forenames>Joerg</forenames></author><author><keyname>Schipper</keyname><forenames>Burkhard C.</forenames></author></authors><title>Unbeatable Imitation</title><categories>cs.GT cs.LG</categories><doi>10.1016/j.geb.2012.05.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for many classes of symmetric two-player games, the simple
decision rule &quot;imitate-the-best&quot; can hardly be beaten by any other decision
rule. We provide necessary and sufficient conditions for imitation to be
unbeatable and show that it can only be beaten by much in games that are of the
rock-scissors-paper variety. Thus, in many interesting examples, like 2x2
games, Cournot duopoly, price competition, rent seeking, public goods games,
common pool resource games, minimum effort coordination games, arms race,
search, bargaining, etc., imitation cannot be beaten by much even by a very
clever opponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4277</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4277</id><created>2010-03-22</created><authors><author><keyname>Duersch</keyname><forenames>Peter</forenames></author><author><keyname>Oechssler</keyname><forenames>Joerg</forenames></author><author><keyname>Schipper</keyname><forenames>Burkhard C.</forenames></author></authors><title>Pure Saddle Points and Symmetric Relative Payoff Games</title><categories>cs.GT</categories><doi>10.1007/s00182-011-0302-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the rock-paper-scissors game has no pure saddle point.
We show that this holds more generally: A symmetric two-player zero-sum game
has a pure saddle point if and only if it is not a generalized
rock-paper-scissors game. Moreover, we show that every finite symmetric
quasiconcave two-player zero-sum game has a pure saddle point. Further
sufficient conditions for existence are provided. We apply our theory to a rich
collection of examples by noting that the class of symmetric two-player
zero-sum games coincides with the class of relative payoff games associated
with symmetric two-player games. This allows us to derive results on the
existence of a finite population evolutionary stable strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4287</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4287</id><created>2010-03-22</created><authors><author><keyname>Kabra</keyname><forenames>Mayank</forenames></author><author><keyname>Conery</keyname><forenames>Annie L.</forenames></author><author><keyname>O'Rourke</keyname><forenames>Eyleen J.</forenames></author><author><keyname>Xie</keyname><forenames>Xin</forenames></author><author><keyname>Ljosa</keyname><forenames>Vebjorn</forenames></author><author><keyname>Jones</keyname><forenames>Thouis R.</forenames></author><author><keyname>Ausubel</keyname><forenames>Frederick M.</forenames></author><author><keyname>Ruvkun</keyname><forenames>Gary</forenames></author><author><keyname>Carpenter</keyname><forenames>Anne E.</forenames></author><author><keyname>Freund</keyname><forenames>Yoav</forenames></author></authors><title>Towards automated high-throughput screening of C. elegans on agar</title><categories>cs.CV q-bio.GN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-throughput screening (HTS) using model organisms is a promising method
to identify a small number of genes or drugs potentially relevant to human
biology or disease. In HTS experiments, robots and computers do a significant
portion of the experimental work. However, one remaining major bottleneck is
the manual analysis of experimental results, which is commonly in the form of
microscopy images. This manual inspection is labor intensive, slow and
subjective. Here we report our progress towards applying computer vision and
machine learning methods to analyze HTS experiments that use Caenorhabditis
elegans (C. elegans) worms grown on agar. Our main contribution is a robust
segmentation algorithm for separating the worms from the background using
brightfield images. We also show that by combining the output of this
segmentation algorithm with an algorithm to detect the fluorescent dye, Nile
Red, we can reliably distinguish different fluorescence-based phenotypes even
though the visual differences are subtle. The accuracy of our method is similar
to that of expert human analysts. This new capability is a significant step
towards fully automated HTS experiments using C. elegans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4301</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4301</id><created>2010-03-22</created><authors><author><keyname>Kushnerov</keyname><forenames>Alexander</forenames></author></authors><title>High-Efficiency Self-Adjusting Switched Capacitor DC-DC Converter with
  Binary Resolution</title><categories>math.NT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Switched-Capacitor Converters (SCC) suffer from a fundamental power loss
deficiency which make their use in some applications prohibitive. The power
loss is due to the inherent energy dissipation when SCC operate between or
outside their output target voltages. This drawback was alleviated in this work
by developing two new classes of SCC providing binary and arbitrary resolution
of closely spaced target voltages. Special attention is paid to SCC topologies
of binary resolution. Namely, SCC systems that can be configured to have a
no-load output to input voltage ratio that is equal to any binary fraction for
a given number of bits. To this end, we define a new number system and develop
rules to translate these numbers into SCC hardware that follows the algebraic
behavior. According to this approach, the flying capacitors are automatically
kept charged to binary weighted voltages and consequently the resolution of the
target voltages follows a binary number representation and can be made higher
by increasing the number of capacitors (bits). The ability to increase the
number of target voltages reduces the spacing between them and, consequently,
increases the efficiency when the input varies over a large voltage range. The
thesis presents the underlining theory of the binary SCC and its extension to
the general radix case. Although the major application is in step-down SCC, a
simple method to utilize these SCC for step-up conversion is also described, as
well as a method to reduce the output voltage ripple. In addition, the generic
and unified model is strictly applied to derive the SCC equivalent resistor,
which is a measure of the power loss. The theoretical predictions are verified
by simulation and experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4302</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4302</id><created>2010-03-22</created><updated>2012-04-26</updated><authors><author><keyname>Dong</keyname><forenames>Min</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>Mahdi</forenames></author><author><keyname>Liang</keyname><forenames>Ben</forenames></author></authors><title>Optimal Unitary Linear Processing for Amplify-and-Forward Cooperative
  OFDM systems</title><categories>cs.IT math.IT math.OC</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the amplified-and-forward relaying in an OFDM
system with unitary linear processing at the relay. We proposed a general
analytical framework to find the unitary linear processing matrix that
maximizes the system achievable rate. We show that the optimal processing
matrix is a permutation matrix, which implies that a subcarrier pairing
strategy is optimal. We further derived the optimal subcarrier pairing schemes
for scenarios with and without the direct source-destination path for
diversity. Simulation results are presented to demonstrate the achievable gain
of optimal subcarrier pairing compared with non-optimal linear processing and
non-pairing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4307</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4307</id><created>2010-03-22</created><authors><author><keyname>Kannan</keyname><forenames>Rajgopal</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author></authors><title>Bottleneck Routing Games with Low Price of Anarchy</title><categories>cs.GT</categories><comments>12 pages</comments><doi>10.1007/978-3-642-16170-4_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study {\em bottleneck routing games} where the social cost is determined
by the worst congestion on any edge in the network. In the literature,
bottleneck games assume player utility costs determined by the worst congested
edge in their paths. However, the Nash equilibria of such games are inefficient
since the price of anarchy can be very high and proportional to the size of the
network. In order to obtain smaller price of anarchy we introduce {\em
exponential bottleneck games} where the utility costs of the players are
exponential functions of their congestions. We find that exponential bottleneck
games are very efficient and give a poly-log bound on the price of anarchy:
$O(\log L \cdot \log |E|)$, where $L$ is the largest path length in the
players' strategy sets and $E$ is the set of edges in the graph. By adjusting
the exponential utility costs with a logarithm we obtain games whose player
costs are almost identical to those in regular bottleneck games, and at the
same time have the good price of anarchy of exponential games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4314</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4314</id><created>2010-03-22</created><authors><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author></authors><title>A New Approach to Population Sizing for Memetic Algorithms: A Case Study
  for the Multidimensional Assignment Problem</title><categories>cs.DS</categories><comments>25 pages</comments><journal-ref>Evolutionary Computation 19(3), pages 345-371, 2011</journal-ref><doi>10.1162/EVCO_a_00026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memetic Algorithms are known to be a powerful technique in solving hard
optimization problems. To design a memetic algorithm one needs to make a host
of decisions; selecting a population size is one of the most important among
them. Most algorithms in the literature fix the population size to a certain
constant value. This reduces the algorithm's quality since the optimal
population size varies for different instances, local search procedures and
running times. In this paper we propose an adjustable population size. It is
calculated as a function of the running time of the whole algorithm and the
average running time of the local search for the given instance. Note that in
many applications the running time of a heuristic should be limited and
therefore we use this limit as a parameter of the algorithm. The average
running time of the local search procedure is obtained during the algorithm's
run. Some coefficients which are independent with respect to the instance or
the local search are to be tuned before the algorithm run; we provide a
procedure to find these coefficients. The proposed approach was used to develop
a memetic algorithm for the Multidimensional Assignment Problem (MAP or s-AP in
the case of s dimensions) which is an extension of the well-known assignment
problem. MAP is NP-hard and has a host of applications. We show that using
adjustable population size makes the algorithm flexible to perform well for
instances of very different sizes and types and for different running times and
local searches. This allows us to select the most efficient local search for
every instance type. The results of computational experiments for several
instance families and sizes prove that the proposed algorithm performs
efficiently for a wide range of the running times and clearly outperforms the
state-of-the art 3-AP memetic algorithm being given the same time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4326</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4326</id><created>2010-03-22</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London</affiliation></author><author><keyname>Namet</keyname><forenames>Olivier</forenames><affiliation>King's College London</affiliation></author></authors><title>Graph Creation, Visualisation and Transformation</title><categories>cs.LO cs.PL cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 1-11</journal-ref><doi>10.4204/EPTCS.21.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a tool to create, edit, visualise and compute with interaction
nets - a form of graph rewriting systems. The editor, called GraphPaper, allows
users to create and edit graphs and their transformation rules using an
intuitive user interface. The editor uses the functionalities of the TULIP
system, which gives us access to a wealth of visualisation algorithms.
Interaction nets are not only a formalism for the specification of graphs, but
also a rewrite-based computation model. We discuss graph rewriting strategies
and a language to express them in order to perform strategic interaction net
rewriting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4328</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4328</id><created>2010-03-22</created><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>New inner and outer bounds for the discrete memoryless cognitive
  interference channel and some capacity results</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The cognitive interference channel is an interference channel in which one
transmitter is non-causally provided with the message of the other transmitter.
This channel model has been extensively studied in the past years and capacity
results for certain classes of channels have been proved. In this paper we
present new inner and outer bounds for the capacity region of the cognitive
interference channel as well as new capacity results. Previously proposed outer
bounds are expressed in terms of auxiliary random variables for which no
cardinality constraint is known. Consequently it is not possible to evaluate
such outer bounds explicitly for a given channel model. The outer bound we
derive is based on an idea originally devised by Sato for the broadcast channel
and does not contain auxiliary random variables, allowing it to be more easily
evaluated. The inner bound we derive is the largest known to date and is
explicitly shown to include all previously proposed achievable rate regions.
This comparison highlights which features of the transmission scheme - which
includes rate-splitting, superposition coding, a broadcast channel-like binning
scheme, and Gel'fand Pinsker coding - are most effective in approaching
capacity. We next present new capacity results for a class of discrete
memoryless channels that we term the &quot;better cognitive decoding regime&quot; which
includes all previously known regimes in which capacity results have been
derived as special cases. Finally, we determine the capacity region of the
semi-deterministic cognitive interference channel, in which the signal at the
cognitive receiver is a deterministic function of the channel inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4353</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4353</id><created>2010-03-23</created><updated>2010-03-24</updated><authors><author><keyname>Maneth</keyname><forenames>Sebastian</forenames></author><author><keyname>Nguyen</keyname><forenames>Kim</forenames></author></authors><title>XPath Whole Query Optimization</title><categories>cs.DB</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work reports about SXSI, a fast XPath engine which executes tree
automata over compressed XML indexes. Here, reasons are investigated why SXSI
is so fast. It is shown that tree automata can be used as a general framework
for fine grained XML query optimization. We define the &quot;relevant nodes&quot; of a
query as those nodes that a minimal automaton must touch in order to answer the
query. This notion allows to skip many subtrees during execution, and, with the
help of particular tree indexes, even allows to skip internal nodes of the
tree. We efficiently approximate runs over relevant nodes by means of
on-the-fly removal of alternation and non-determinism of (alternating) tree
automata. We also introduce many implementation techniques which allows us to
efficiently evaluate tree automata, even in the absence of special indexes.
Through extensive experiments, we demonstrate the impact of the different
optimization techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4355</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4355</id><created>2010-03-23</created><authors><author><keyname>Sun</keyname><forenames>Xiaojun</forenames></author><author><keyname>Zhao</keyname><forenames>Chunming</forenames></author><author><keyname>Jiang</keyname><forenames>Ming</forenames></author></authors><title>Closed-Form Expressions for Secrecy Capacity over Correlated Rayleigh
  Fading Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the secure communications over correlated wiretap Rayleigh
fading channels assuming the full channel state information (CSI) available.
Based on the information theoretic formulation, we derive closed-form
expressions for the average secrecy capacity and the outage probability.
Simulation results confirm our analytical expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4366</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4366</id><created>2010-03-23</created><authors><author><keyname>Nissen</keyname><forenames>Marco</forenames></author></authors><title>Graph Iterators: Decoupling Graph Structures from Algorithms</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I will present a way to implement graph algorithms which is different from
traditional methods. This work was motivated by the belief that some ideas from
software engineering should be applied to graph algorithms. Re-usability of
software is an important and difficult problem in general, and this is
particularly true for graph algorithms. The scientific literature demonstrates
plenty of applications of graph algorithms as subroutines for other algorithms.
Moreover, many practical problems from various domains may be modeled as graph
problems and hence solved by means of graph algorithms. Chapter 2 introduces
some data structures that will be used in 5 basic graph algorithms in chapter
3. Chapter 4 discusses an implementation of a maximum cardinality matching
algorithm for general graphs. Chapter 5 explains some techniques in C++, which
are useful to implement the data structures and algorithms in an efficient way.
Finally chapter 6 contains some concluding remarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4369</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4369</id><created>2010-03-23</created><authors><author><keyname>Balbiani</keyname><forenames>Ph.</forenames></author><author><keyname>Echahed</keyname><forenames>R.</forenames></author><author><keyname>Herzig</keyname><forenames>A.</forenames></author></authors><title>A Modal Logic for Termgraph Rewriting</title><categories>cs.LO cs.PL cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a modal logic tailored to describe graph transformations and
discuss some of its properties. We focus on a particular class of graphs called
termgraphs. They are first-order terms augmented with sharing and cycles.
Termgraphs allow one to describe classical data-structures (possibly with
pointers) such as doubly-linked lists, circular lists etc. We show how the
proposed logic can faithfully describe (i) termgraphs as well as (ii) the
application of a termgraph rewrite rule (i.e. matching and replacement) and
(iii) the computation of normal forms with respect to a given rewrite system.
We also show how the proposed logic, which is more expressive than
propositional dynamic logic, can be used to specify shapes of classical
data-structures (e.g. binary trees, circular lists etc.).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4391</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4391</id><created>2010-03-23</created><authors><author><keyname>Deza</keyname><forenames>Michel</forenames></author><author><keyname>Shklyar</keyname><forenames>Roman</forenames></author></authors><title>Enumeration of Hamiltonian Cycles in 6-cube</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the number 2H6 of directed Hamiltonian cycles in 6-cube is problem 43
in Section 7.2.1.1 of Knuth's ' The Art of Computer Programming'; various
proposed estimates are surveyed below. We computed exact value:
H6=14,754,666,508,334,433,250,560=6*2^4*217,199*1,085,989*5,429,923. Also the
number Aut6 of those cycles up to automorphisms of 6-cube was computed as
147,365,405,634,413,085
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4394</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4394</id><created>2010-03-23</created><authors><author><keyname>Coecke</keyname><forenames>Bob</forenames></author><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author><author><keyname>Clark</keyname><forenames>Stephen</forenames></author></authors><title>Mathematical Foundations for a Compositional Distributional Model of
  Meaning</title><categories>cs.CL cs.LO math.CT</categories><comments>to appear</comments><journal-ref>Lambek Festschirft, special issue of Linguistic Analysis, 2010.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a mathematical framework for a unification of the distributional
theory of meaning in terms of vector space models, and a compositional theory
for grammatical types, for which we rely on the algebra of Pregroups,
introduced by Lambek. This mathematical framework enables us to compute the
meaning of a well-typed sentence from the meanings of its constituents.
Concretely, the type reductions of Pregroups are `lifted' to morphisms in a
category, a procedure that transforms meanings of constituents into a meaning
of the (well-typed) whole. Importantly, meanings of whole sentences live in a
single space, independent of the grammatical structure of the sentence. Hence
the inner-product can be used to compare meanings of arbitrary sentences, as it
is for comparing the meanings of words in the distributional model. The
mathematical structure we employ admits a purely diagrammatic calculus which
exposes how the information flows between the words in a sentence in order to
make up the meaning of the whole sentence. A variation of our `categorical
model' which involves constraining the scalars of the vector spaces to the
semiring of Booleans results in a Montague-style Boolean-valued semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4406</identifier>
 <datestamp>2014-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4406</id><created>2010-03-23</created><updated>2014-10-28</updated><authors><author><keyname>Anguelov</keyname><forenames>R.</forenames></author><author><keyname>Butler</keyname><forenames>P. W.</forenames></author><author><keyname>Rohwer</keyname><forenames>C. H.</forenames></author><author><keyname>Wild</keyname><forenames>M.</forenames></author></authors><title>The output distribution of important LULU-operators</title><categories>math.PR cs.OH</categories><comments>20 pages, up to trivial differences this is the final version to be
  published in Quaestiones Mathematicae 2015</comments><msc-class>62E15</msc-class><doi>10.2989/16073606.2014.981684</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two procedures to compute the output distribution phi_S of certain stack
filters S (so called erosion-dilation cascades) are given. One rests on the
disjunctive normal form of S and also yields the rank selection probabilities.
The other is based on inclusion-exclusion and e.g. yields phi_S for some
important LULU-operators S. Properties of phi_S can be used to characterize
smoothing properties of S. One of the methods discussed also allows for the
calculation of the reliability polynomial of any positive Boolean function
(e.g. one derived from a connected graph).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4418</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4418</id><created>2010-03-23</created><authors><author><keyname>Endrullis</keyname><forenames>Stefan</forenames></author><author><keyname>Thor</keyname><forenames>Andreas</forenames></author><author><keyname>Rahm</keyname><forenames>Erhard</forenames></author></authors><title>Evaluation of Query Generators for Entity Search Engines</title><categories>cs.DB cs.IR</categories><acm-class>H.3.3; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic web applications such as mashups need efficient access to web data
that is only accessible via entity search engines (e.g. product or publication
search engines). However, most current mashup systems and applications only
support simple keyword searches for retrieving data from search engines. We
propose the use of more powerful search strategies building on so-called query
generators. For a given set of entities query generators are able to
automatically determine a set of search queries to retrieve these entities from
an entity search engine. We demonstrate the usefulness of query generators for
on-demand web data integration and evaluate the effectiveness and efficiency of
query generators for a challenging real-world integration scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4539</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4539</id><created>2010-03-23</created><authors><author><keyname>Gluesing-Luerssen</keyname><forenames>Heide</forenames></author><author><keyname>Weaver</keyname><forenames>Elizabeth</forenames></author></authors><title>Linear tail-biting trellises: Characteristic generators and the
  BCJR-construction</title><categories>cs.IT math.IT</categories><comments>28 pages</comments><msc-class>94B05, 94B12, 68R10, 93B20</msc-class><journal-ref>updated version in IEEE Trans. Inf. Theory, 2011, vol. 57, 738-751</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the constructions of tail-biting trellises for linear block
codes introduced by Koetter/Vardy (2003) and Nori/Shankar (2006). For a given
code we will define the sets of characteristic generators more generally than
by Koetter/Vardy and we will investigate how the choice of characteristic
generators affects the set of resulting product trellises, called KV-trellises.
Furthermore, we will show that each KV-trellis is a BCJR-trellis, defined in a
slightly stronger sense than by Nori/Shankar, and that the latter are always
non-mergeable. Finally, we will address a duality conjecture of Koetter/Vardy
by making use of a dualization technique of BCJR-trellises and prove the
conjecture for minimal trellises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4546</identifier>
 <datestamp>2011-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4546</id><created>2010-03-23</created><updated>2011-03-26</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Fusy</keyname><forenames>&#xc9;ric</forenames></author><author><keyname>Kang</keyname><forenames>Mihyun</forenames></author><author><keyname>Vigerske</keyname><forenames>Stefan</forenames></author></authors><title>Boltzmann Samplers, P\'olya Theory, and Cycle Pointing</title><categories>cs.DM math.CO</categories><comments>41 pages. This is an extended and revised journal version of a
  conference paper with the title &quot;An unbiased pointing operator for unlabeled
  structures, with applications to counting and sampling&quot;, Proceedings of
  ACM-SIAM Symposium on Discrete Algorithms (SODA'07), 2007, New Orleans. The
  second Arxiv version incorporates many improvements suggested by anonymous
  referees of the journal version</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We introduce a general method to count unlabeled combinatorial structures and
to efficiently generate them at random. The approach is based on pointing
unlabeled structures in an &quot;unbiased&quot; way that a structure of size n gives rise
to n pointed structures. We extend Polya theory to the corresponding pointing
operator, and present a random sampling framework based on both the principles
of Boltzmann sampling and on P\'olya operators. All previously known unlabeled
construction principles for Boltzmann samplers are special cases of our new
results. Our method is illustrated on several examples: in each case, we
provide enumerative results and efficient random samplers. The approach applies
to unlabeled families of plane and nonplane unrooted trees, and tree-like
structures in general, but also to families of graphs (such as cacti graphs and
outerplanar graphs) and families of planar maps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4552</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4552</id><created>2010-03-23</created><authors><author><keyname>Jacobs</keyname><forenames>Bart</forenames></author></authors><title>Involutive Categories and Monoids, with a GNS-correspondence</title><categories>cs.LO math.CT</categories><msc-class>18C10</msc-class><acm-class>F.4.1</acm-class><doi>10.1007/s10701-011-9595-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops the basics of the theory of involutive categories and
shows that such categories provide the natural setting in which to describe
involutive monoids. It is shown how categories of Eilenberg-Moore algebras of
involutive monads are involutive, with conjugation for modules and vector
spaces as special case. The core of the so-called Gelfand-Naimark-Segal (GNS)
construction is identified as a bijective correspondence between states on
involutive monoids and inner products. This correspondence exists in arbritrary
involutive categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4562</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4562</id><created>2010-03-23</created><authors><author><keyname>Hassan</keyname><forenames>Abubakar</forenames><affiliation>University of Sussex</affiliation></author><author><keyname>Jiresch</keyname><forenames>Eugen</forenames><affiliation>Vienna University of Technology</affiliation></author><author><keyname>Sato</keyname><forenames>Shinya</forenames><affiliation>Himeji Dokkyo University</affiliation></author></authors><title>An Implementation of Nested Pattern Matching in Interaction Nets</title><categories>cs.LO cs.PL cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 13-25</journal-ref><doi>10.4204/EPTCS.21.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reduction rules in interaction nets are constrained to pattern match exactly
one argument at a time. Consequently, a programmer has to introduce auxiliary
rules to perform more sophisticated matches. In this paper, we describe the
design and implementation of a system for interaction nets which allows nested
pattern matching on interaction rules. We achieve a system that provides
convenient ways to express interaction net programs without defining auxiliary
rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4563</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4563</id><created>2010-03-23</created><authors><author><keyname>Plump</keyname><forenames>Detlef</forenames><affiliation>The University of York</affiliation></author><author><keyname>Steinert</keyname><forenames>Sandra</forenames><affiliation>The University of York</affiliation></author></authors><title>The Semantics of Graph Programs</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 27-38</journal-ref><doi>10.4204/EPTCS.21.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GP (for Graph Programs) is a rule-based, nondeterministic programming
language for solving graph problems at a high level of abstraction, freeing
programmers from handling low-level data structures. The core of GP consists of
four constructs: single-step application of a set of conditional
graph-transformation rules, sequential composition, branching and iteration. We
present a formal semantics for GP in the style of structural operational
semantics. A special feature of our semantics is the use of finitely failing
programs to define GP's powerful branching and iteration commands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4610</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4610</id><created>2010-03-24</created><authors><author><keyname>Di Fabio</keyname><forenames>Barbara</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author></authors><title>Stability of Reeb graphs under function perturbations: the case of
  closed curves</title><categories>cs.CG</categories><comments>23 pages, 12 figures</comments><report-no>2759</report-no><msc-class>Primary 68U05; Secondary 68T10; 05C10; 57R99</msc-class><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reeb graphs provide a method for studying the shape of a manifold by encoding
the evolution and arrangement of level sets of a simple Morse function defined
on the manifold. Since their introduction in computer graphics they have been
gaining popularity as an effective tool for shape analysis and matching. In
this context one question deserving attention is whether Reeb graphs are robust
against function perturbations. Focusing on 1-dimensional manifolds, we define
an editing distance between Reeb graphs of curves, in terms of the cost
necessary to transform one graph into another. Our main result is that changes
in Morse functions induce smaller changes in the editing distance between Reeb
graphs of curves, implying stability of Reeb graphs under function
perturbations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4627</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4627</id><created>2010-03-24</created><authors><author><keyname>Spasov</keyname><forenames>Dejan</forenames></author></authors><title>Unique and Minimum Distance Decoding of Linear Codes with Reduced
  Complexity</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for (systematic) linear codes the time complexity of unique
decoding is O(n^{2}q^{nRH(delta/2/R)}) and the time complexity of minimum
distance decoding is O(n^{2}q^{nRH(delta/R)}). The proposed algorithm inspects
all error patterns in the information set of the received message of weight
less than d/2 or d, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4628</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4628</id><created>2010-03-24</created><updated>2010-03-30</updated><authors><author><keyname>Gonnet</keyname><forenames>Pedro</forenames></author></authors><title>Efficient Construction, Update and Downdate Of The Coefficients Of
  Interpolants Based On Polynomials Satisfying A Three-Term Recurrence Relation</title><categories>cs.NA cs.MS math.NA</categories><comments>18 pages, submitted to the Journal of Scientific Computing.</comments><msc-class>65D05</msc-class><acm-class>G.1.1; G.1.3; G.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider methods to compute the coefficients of
interpolants relative to a basis of polynomials satisfying a three-term
recurrence relation. Two new algorithms are presented: the first constructs the
coefficients of the interpolation incrementally and can be used to update the
coefficients whenever a nodes is added to or removed from the interpolation.
The second algorithm, which constructs the interpolation coefficients by
decomposing the Vandermonde-like matrix iteratively, can not be used to update
or downdate an interpolation, yet is more numerically stable than the first
algorithm and is more efficient when the coefficients of multiple
interpolations are to be computed over the same set of nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4629</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4629</id><created>2010-03-24</created><updated>2010-11-07</updated><authors><author><keyname>Gonnet</keyname><forenames>Pedro</forenames></author></authors><title>A Review of Error Estimation in Adaptive Quadrature</title><categories>cs.NA cs.MS math.NA</categories><comments>Submitted to ACM Computing Surveys</comments><msc-class>65D30</msc-class><acm-class>F.2.1; G.1.0; G.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most critical component of any adaptive numerical quadrature routine is
the estimation of the integration error. Since the publication of the first
algorithms in the 1960s, many error estimation schemes have been presented,
evaluated and discussed. This paper presents a review of existing error
estimation techniques and discusses their differences and their common
features. Some common shortcomings of these algorithms are discussed and a new
general error estimation technique is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4637</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4637</id><created>2010-03-24</created><authors><author><keyname>Chen</keyname><forenames>Zhineng</forenames></author><author><keyname>Cao</keyname><forenames>Juan</forenames></author><author><keyname>Song</keyname><forenames>Yicheng</forenames></author><author><keyname>Guo</keyname><forenames>Junbo</forenames></author><author><keyname>Zhang</keyname><forenames>Yongdong</forenames></author><author><keyname>Li</keyname><forenames>Jintao</forenames></author></authors><title>Context-Oriented Web Video Tag Recommendation</title><categories>cs.MM</categories><comments>2 pages, 2 figures, 1 table</comments><journal-ref>Proceedings of the 19th international conference on World wide web
  (WWW2010), April 26-30, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tag recommendation is a common way to enrich the textual annotation of
multimedia contents. However, state-of-the-art recommendation methods are built
upon the pair-wised tag relevance, which hardly capture the context of the web
video, i.e., when who are doing what at where. In this paper we propose the
context-oriented tag recommendation (CtextR) approach, which expands tags for
web videos under the context-consistent constraint. Given a web video, CtextR
first collects the multi-form WWW resources describing the same event with the
video, which produce an informative and consistent context; and then, the tag
recommendation is conducted based on the obtained context. Experiments on an
80,031 web video collection show CtextR recommends various relevant tags to web
videos. Moreover, the enriched tags improve the performance of web video
categorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4657</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4657</id><created>2010-03-24</created><authors><author><keyname>Ivanova</keyname><forenames>Anna</forenames></author></authors><title>Identification of Convection Heat Transfer Coefficient of Secondary
  Cooling Zone of CCM based on Least Squares Method and Stochastic
  Approximation Method</title><categories>math.OC cs.CE</categories><comments>14 pages, 7 figures</comments><msc-class>93B30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detailed mathematical model of heat and mass transfer of steel ingot of
curvilinear continuous casting machine is proposed. The process of heat and
mass transfer is described by nonlinear partial differential equations of
parabolic type. Position of phase boundary is determined by Stefan conditions.
The temperature of cooling water in mould channel is described by a special
balance equation. Boundary conditions of secondary cooling zone include radiant
and convective components of heat exchange and account for the complex
mechanism of heat-conducting due to airmist cooling using compressed air and
water. Convective heat-transfer coefficient of secondary cooling zone is
unknown and considered as distributed parameter. To solve this problem the
algorithm of initial adjustment of parameter and the algorithm of operative
adjustment are developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4679</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4679</id><created>2010-03-24</created><authors><author><keyname>Pospelov</keyname><forenames>Alexey</forenames></author></authors><title>Bounds for Bilinear Complexity of Noncommutative Group Algebras</title><categories>cs.CC math.RT</categories><comments>20 pages</comments><acm-class>F.2.1; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of multiplication in noncommutative group algebras
which is closely related to the complexity of matrix multiplication. We
characterize such semisimple group algebras of the minimal bilinear complexity
and show nontrivial lower bounds for the rest of the group algebras. These
lower bounds are built on the top of Bl\&quot;aser's results for semisimple algebras
and algebras with large radical and the lower bound for arbitrary associative
algebras due to Alder and Strassen. We also show subquadratic upper bounds for
all group algebras turning into &quot;almost linear&quot; provided the exponent of matrix
multiplication equals 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4712</identifier>
 <datestamp>2010-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4712</id><created>2010-03-24</created><authors><author><keyname>Muchnik</keyname><forenames>Andrej A.</forenames></author><author><keyname>Mezhirov</keyname><forenames>Ilya</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author><author><keyname>Vereshchagin</keyname><forenames>Nikolay</forenames></author></authors><title>Game interpretation of Kolmogorov complexity</title><categories>math.LO cs.GT cs.IT math.IT</categories><comments>11 pages. Presented in 2009 at the conference on randomness in
  Madison.</comments><msc-class>68Q30</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kolmogorov complexity function K can be relativized using any oracle A,
and most properties of K remain true for relativized versions. In section 1 we
provide an explanation for this observation by giving a game-theoretic
interpretation and showing that all &quot;natural&quot; properties are either true for
all sufficiently powerful oracles or false for all sufficiently powerful
oracles. This result is a simple consequence of Martin's determinacy theorem,
but its proof is instructive: it shows how one can prove statements about
Kolmogorov complexity by constructing a special game and a winning strategy in
this game. This technique is illustrated by several examples (total conditional
complexity, bijection complexity, randomness extraction, contrasting plain and
prefix complexities).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4719</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4719</id><created>2010-03-24</created><updated>2011-08-23</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Introduction to clarithmetic I</title><categories>cs.LO cs.CC math.LO math.NT</categories><msc-class>03F50, 03D75, 03D15, 68Q10, 68T27, 68T30</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><journal-ref>Information and Computation 209 (2011), pp. 1312-1354</journal-ref><doi>10.1016/j.ic.2011.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Clarithmetic&quot; is a generic name for formal number theories similar to Peano
arithmetic, but based on computability logic (see
http://www.cis.upenn.edu/~giorgi/cl.html) instead of the more traditional
classical or intuitionistic logics. Formulas of clarithmetical theories
represent interactive computational problems, and their &quot;truth&quot; is understood
as existence of an algorithmic solution. Imposing various complexity
constraints on such solutions yields various versions of clarithmetic. The
present paper introduces a system of clarithmetic for polynomial time
computability, which is shown to be sound and complete. Sound in the sense that
every theorem T of the system represents an interactive number-theoretic
computational problem with a polynomial time solution and, furthermore, such a
solution can be efficiently extracted from a proof of T. And complete in the
sense that every interactive number-theoretic problem with a polynomial time
solution is represented by some theorem T of the system. The paper is written
in a semitutorial style and targets readers with no prior familiarity with
computability logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4764</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4764</id><created>2010-03-24</created><authors><author><keyname>Shi</keyname><forenames>Changxin</forenames></author><author><keyname>Berry</keyname><forenames>Randall A.</forenames></author><author><keyname>Honig</keyname><forenames>Michael L.</forenames></author></authors><title>Adaptive Beamforming in Interference Networks via Bi-Directional
  Training</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures. An earlier version appeared in 44th Annual
  Conference on Information Sciences and Systems (CISS), Princeton, NJ, March
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study distributed algorithms for adjusting beamforming vectors and
receiver filters in multiple-input multiple-output (MIMO) interference
networks, with the assumption that each user uses a single beam and a linear
filter at the receiver. In such a setting there have been several distributed
algorithms studied for maximizing the sum-rate or sum-utility assuming perfect
channel state information (CSI) at the transmitters and receivers. The focus of
this paper is to study adaptive algorithms for time-varying channels, without
assuming any CSI at the transmitters or receivers. Specifically, we consider an
adaptive version of the recent Max-SINR algorithm for a time-division duplex
system. This algorithm uses a period of bi-directional training followed by a
block of data transmission. Training in the forward direction is sent using the
current beam-formers and used to adapt the receive filters. Training in the
reverse direction is sent using the current receive filters as beams and used
to adapt the transmit beamformers. The adaptation of both receive filters and
beamformers is done using a least-squares objective for the current block. In
order to improve the performance when the training data is limited, we also
consider using exponentially weighted data from previous blocks. Numerical
results are presented that compare the performance of the algorithms in
different settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4778</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4778</id><created>2010-03-24</created><authors><author><keyname>Wang</keyname><forenames>Meng</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>A Unique &quot;Nonnegative&quot; Solution to an Underdetermined System: from
  Vectors to Matrices</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2010.2089624</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the uniqueness of a nonnegative vector solution and
the uniqueness of a positive semidefinite matrix solution to underdetermined
linear systems. A vector solution is the unique solution to an underdetermined
linear system only if the measurement matrix has a row-span intersecting the
positive orthant. Focusing on two types of binary measurement matrices,
Bernoulli 0-1 matrices and adjacency matrices of general expander graphs, we
show that, in both cases, the support size of a unique nonnegative solution can
grow linearly, namely O(n), with the problem dimension n. We also provide
closed-form characterizations of the ratio of this support size to the signal
dimension. For the matrix case, we show that under a necessary and sufficient
condition for the linear compressed observations operator, there will be a
unique positive semidefinite matrix solution to the compressed linear
observations. We further show that a randomly generated Gaussian linear
compressed observations operator will satisfy this condition with
overwhelmingly high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4781</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4781</id><created>2010-03-24</created><authors><author><keyname>Miao</keyname><forenames>Xu</forenames></author><author><keyname>Rao</keyname><forenames>Rajesh P. N.</forenames></author></authors><title>Large Margin Boltzmann Machines and Large Margin Sigmoid Belief Networks</title><categories>cs.LG cs.AI cs.CV</categories><report-no>UW-CSE-09-04-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current statistical models for structured prediction make simplifying
assumptions about the underlying output graph structure, such as assuming a
low-order Markov chain, because exact inference becomes intractable as the
tree-width of the underlying graph increases. Approximate inference algorithms,
on the other hand, force one to trade off representational power with
computational efficiency. In this paper, we propose two new types of
probabilistic graphical models, large margin Boltzmann machines (LMBMs) and
large margin sigmoid belief networks (LMSBNs), for structured prediction.
LMSBNs in particular allow a very fast inference algorithm for arbitrary graph
structures that runs in polynomial time with a high probability. This
probability is data-distribution dependent and is maximized in learning. The
new approach overcomes the representation-efficiency trade-off in previous
models and allows fast structured prediction with complicated graph structures.
We present results from applying a fully connected model to multi-label scene
classification and demonstrate that the proposed approach can yield significant
performance gains over current state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4799</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4799</id><created>2010-03-25</created><authors><author><keyname>Kirchner</keyname><forenames>Claude</forenames></author><author><keyname>Moreau</keyname><forenames>Pierre-Etienne</forenames></author><author><keyname>Tavares</keyname><forenames>Cl&#xe1;udia</forenames></author></authors><title>A Type System for Tom</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 51-63</journal-ref><doi>10.4204/EPTCS.21.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extending a given language with new dedicated features is a general and quite
used approach to make the programming language more adapted to problems. Being
closer to the application, this leads to less programming flaws and easier
maintenance. But of course one would still like to perform program analysis on
these kinds of extended languages, in particular type checking and inference.
In this case one has to make the typing of the extended features compatible
with the ones in the starting language.
  The Tom programming language is a typical example of such a situation as it
consists of an extension of Java that adds pattern matching, more particularly
associative pattern matching, and reduction strategies.
  This paper presents a type system with subtyping for Tom, that is compatible
with Java's type system, and that performs both type checking and type
inference. We propose an algorithm that checks if all patterns of a Tom program
are well-typed. In addition, we propose an algorithm based on equality and
subtyping constraints that infers types of variables occurring in a pattern.
Both algorithms are exemplified and the proposed type system is showed to be
sound and complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4800</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4800</id><created>2010-03-25</created><authors><author><keyname>Freitas</keyname><forenames>Gabriel Falconieri</forenames></author><author><keyname>Corn&#xe9;lio</keyname><forenames>M&#xe1;rcio</forenames></author><author><keyname>Massoni</keyname><forenames>Tiago</forenames></author><author><keyname>Gheyi</keyname><forenames>Rohit</forenames></author></authors><title>Object-oriented Programming Laws for Annotated Java Programs</title><categories>cs.LO cs.PL cs.SE</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 65-76</journal-ref><doi>10.4204/EPTCS.21.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented programming laws have been proposed in the context of
languages that are not combined with a behavioral interface specification
language (BISL). The strong dependence between source-code and interface
specifications may cause a number of difficulties when transforming programs.
In this paper we introduce a set of programming laws for object-oriented
languages like Java combined with the Java Modeling Language (JML). The set of
laws deals with object-oriented features taking into account their
specifications. Some laws deal only with features of the specification
language. These laws constitute a set of small transformations for the
development of more elaborate ones like refactorings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4802</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4802</id><created>2010-03-25</created><authors><author><keyname>Marcos</keyname><forenames>Jo&#xe3;o</forenames></author></authors><title>Automatic Generation of Proof Tactics for Finite-Valued Logics</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 91-98</journal-ref><doi>10.4204/EPTCS.21.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of flexible tactic-based logical frameworks are nowadays available
that can implement a wide range of mathematical theories using a common
higher-order metalanguage. Used as proof assistants, one of the advantages of
such powerful systems resides in their responsiveness to extensibility of their
reasoning capabilities, being designed over rule-based programming languages
that allow the user to build her own `programs to construct proofs' - the
so-called proof tactics.
  The present contribution discusses the implementation of an algorithm that
generates sound and complete tableau systems for a very inclusive class of
sufficiently expressive finite-valued propositional logics, and then
illustrates some of the challenges and difficulties related to the algorithmic
formation of automated theorem proving tactics for such logics. The procedure
on whose implementation we will report is based on a generalized notion of
analyticity of proof systems that is intended to guarantee termination of the
corresponding automated tactics on what concerns theoremhood in our targeted
logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4803</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4803</id><created>2010-03-25</created><authors><author><keyname>Boyer</keyname><forenames>Beno&#xee;t</forenames></author><author><keyname>Genet</keyname><forenames>Thomas</forenames></author></authors><title>Verifying Temporal Regular Properties of Abstractions of Term Rewriting
  Systems</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010, pp. 99-108</journal-ref><doi>10.4204/EPTCS.21.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tree automaton completion is an algorithm used for proving safety
properties of systems that can be modeled by a term rewriting system. This
representation and verification technique works well for proving properties of
infinite systems like cryptographic protocols or more recently on Java Bytecode
programs. This algorithm computes a tree automaton which represents a (regular)
over approximation of the set of reachable terms by rewriting initial terms.
This approach is limited by the lack of information about rewriting relation
between terms. Actually, terms in relation by rewriting are in the same
equivalence class: there are recognized by the same state in the tree
automaton.
  Our objective is to produce an automaton embedding an abstraction of the
rewriting relation sufficient to prove temporal properties of the term
rewriting system.
  We propose to extend the algorithm to produce an automaton having more
equivalence classes to distinguish a term or a subterm from its successors
w.r.t. rewriting. While ground transitions are used to recognize equivalence
classes of terms, epsilon-transitions represent the rewriting relation between
terms. From the completed automaton, it is possible to automatically build a
Kripke structure abstracting the rewriting sequence. States of the Kripke
structure are states of the tree automaton and the transition relation is given
by the set of epsilon-transitions. States of the Kripke structure are labelled
by the set of terms recognized using ground transitions. On this Kripke
structure, we define the Regular Linear Temporal Logic (R-LTL) for expressing
properties. Such properties can then be checked using standard model checking
algorithms. The only difference between LTL and R-LTL is that predicates are
replaced by regular sets of acceptable terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4810</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4810</id><created>2010-03-25</created><authors><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Li</keyname><forenames>Yiyang</forenames></author></authors><title>The asymptotic value of Randic index for trees</title><categories>math.CO cs.DM</categories><comments>12 pages</comments><msc-class>05C05; 05C12; 05C30; 05D40; 05A15; 05A16; 92E10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal{T}_n$ denote the set of all unrooted and unlabeled trees with
$n$ vertices, and $(i,j)$ a double-star. By assuming that every tree of
$\mathcal{T}_n$ is equally likely, we show that the limiting distribution of
the number of occurrences of the double-star $(i,j)$ in $\mathcal{T}_n$ is
normal. Based on this result, we obtain the asymptotic value of Randi\'c index
for trees. Fajtlowicz conjectured that for any connected graph the Randi\'c
index is at least the average distance. Using this asymptotic value, we show
that this conjecture is true not only for almost all connected graphs but also
for almost all trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4812</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4812</id><created>2010-03-25</created><authors><author><keyname>Everdij</keyname><forenames>Mariken H. C.</forenames></author><author><keyname>Blom</keyname><forenames>Henk A. P.</forenames></author></authors><title>Bisimulation Relations Between Automata, Stochastic Differential
  Equations and Petri Nets</title><categories>cs.LO</categories><comments>15 pages, 4 figures, Workshop on Formal Methods for Aerospace (FMA),
  EPTCS 20m 2010</comments><journal-ref>EPTCS 20, 2010, pp. 1-15</journal-ref><doi>10.4204/EPTCS.20.1</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Two formal stochastic models are said to be bisimilar if their solutions as a
stochastic process are probabilistically equivalent. Bisimilarity between two
stochastic model formalisms means that the strengths of one stochastic model
formalism can be used by the other stochastic model formalism. The aim of this
paper is to explain bisimilarity relations between stochastic hybrid automata,
stochastic differential equations on hybrid space and stochastic hybrid Petri
nets. These bisimilarity relations make it possible to combine the formal
verification power of automata with the analysis power of stochastic
differential equations and the compositional specification power of Petri nets.
The relations and their combined strengths are illustrated for an air traffic
example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4827</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4827</id><created>2010-03-25</created><authors><author><keyname>Martinez</keyname><forenames>Jos&#xe9;</forenames><affiliation>LINA</affiliation></author><author><keyname>Malta</keyname><forenames>Carmelo</forenames></author></authors><title>Tuple-based abstract data types: full parallelism</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>International Symposium on Computer and Information Sciences
  (ISCIS'92), Antalya : Turkey (1992)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commutativity has the same inherent limitations as compatibility. Then, it is
worth conceiving simple concurrency control techniques. We propose a restricted
form of commutativity which increases parallelism without incurring a higher
overhead than compatibility. Advantages of our proposition are: (1)
commutativity of operations is determined at compile-time, (2) run-time
checking is as efficient as for compatibility, (3) neither commutativity
relations, (4) nor inverse operations, need to be specified, and (5) log space
utilization is reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4828</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4828</id><created>2010-03-25</created><authors><author><keyname>Malta</keyname><forenames>Carmelo</forenames><affiliation>LINA</affiliation></author><author><keyname>Martinez</keyname><forenames>Jos&#xe9;</forenames><affiliation>LINA</affiliation></author></authors><title>A framework for designing concurrent and recoverable abstract data types
  based on commutativity</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>International Symposium on Computer and Information Sciences
  (ISCIS'91), Side : Turkey (1991)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we try to focus the reader's interest on the problems that
transactional systems have to resolve for taking advantage of commutativity in
a serializable and recoverable way. Our framework is, (as others), based on the
use of conditional commutativity on abstract date types. We present new
features that have not been found in the literature hitherto, that both
increase concurrency and simplify recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4830</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4830</id><created>2010-03-25</created><authors><author><keyname>Malta</keyname><forenames>Carmelo</forenames><affiliation>LINA</affiliation></author><author><keyname>Martinez</keyname><forenames>Jos&#xe9;</forenames><affiliation>LINA</affiliation></author></authors><title>Limits of Commutativity on Abstract Data Types</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>5th International Conference on Information Systems and Management
  of Data (CISMOD'92), Bangalore : India (1992)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present some formal properties of (symmetrical) commutativity, the major
criterion used in transactional systems, which allow us to fully understand its
advantages and disadvantages. The main result is that commutativity is subject
to the same limitation as compatibility for arbitrary objects. However,
commutativity has also a number of attracting properties, one of which is
related to recovery and, to our knowledge, has not been exploited in the
literature. Advantages and disadvantages are illustrated on abstract data types
of interest. We also show how limits of commutativity have been circumvented,
which gives guidelines for doing so (or not!).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4831</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4831</id><created>2010-03-25</created><authors><author><keyname>Aoustin</keyname><forenames>Yannick</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Formal'skii</keyname><forenames>Alexander</forenames></author></authors><title>Ball on a beam: stabilization under saturated input control with large
  basin of attraction</title><categories>cs.RO cs.SY physics.med-ph</categories><proxy>ccsd</proxy><journal-ref>Multibody System Dynamics 21 (2008) 71-89</journal-ref><doi>10.1007/s11044-008-9128-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is devoted to the stabilization of two underactuated planar
systems, the well-known straight beam-and-ball system and an original circular
beam-and-ball system. The feedback control for each system is designed, using
the Jordan form of its model, linearized near the unstable equilibrium. The
limits on the voltage, fed to the motor, are taken into account explicitly. The
straight beam-and-ball system has one unstable mode in the motion near the
equilibrium point. The proposed control law ensures that the basin of
attraction coincides with the controllability domain. The circular
beam-and-ball system has two unstable modes near the equilibrium point.
Therefore, this device, never considered in the past, is much more difficult to
control than the straight beam-and-ball system. The main contribution is to
propose a simple new control law, which ensures by adjusting its gain
parameters that the basin of attraction arbitrarily can approach the
controllability domain for the linear case. For both nonlinear systems,
simulation results are presented to illustrate the efficiency of the designed
nonlinear control laws and to determine the basin of attraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4836</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4836</id><created>2010-03-25</created><authors><author><keyname>Malta</keyname><forenames>Carmelo</forenames><affiliation>LINA</affiliation></author><author><keyname>Martinez</keyname><forenames>Jos&#xe9;</forenames><affiliation>LINA</affiliation></author></authors><title>Automating Fine Concurrency Control in Object-Oriented Databases</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>IEEE 9th International Conference on Data Engineering (ICDE'93),
  Vienn : Austria (1993)</journal-ref><doi>10.1109/ICDE.1993.344057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several propositions were done to provide adapted concurrency control to
object-oriented databases. However, most of these proposals miss the fact that
considering solely read and write access modes on instances may lead to less
parallelism than in relational databases! This paper cope with that issue, and
advantages are numerous: (1) commutativity of methods is determined a priori
and automatically by the compiler, without measurable overhead, (2) run-time
checking of commutativity is as efficient as for compatibility, (3) inverse
operations need not be specified for recovery, (4) this scheme does not
preclude more sophisticated approaches, and, last but not least, (5) relational
and object-oriented concurrency control schemes with read and write access
modes are subsumed under this proposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4847</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4847</id><created>2010-03-25</created><updated>2010-08-06</updated><authors><author><keyname>Bedini</keyname><forenames>Andrea</forenames><affiliation>INFN, Sezione di Milano</affiliation></author><author><keyname>Jacobsen</keyname><forenames>Jesper Lykke</forenames><affiliation>LPTENS</affiliation></author></authors><title>A tree-decomposed transfer matrix for computing exact Potts model
  partition functions for arbitrary graphs, with applications to planar graph
  colourings</title><categories>math-ph cond-mat.stat-mech cs.DS math.CO math.MP</categories><comments>5 pages, 3 figures. Version 2 has been substantially expanded.
  Version 3 shows that the worst-case running time is sub-exponential in the
  number of vertices</comments><proxy>ccsd</proxy><doi>10.1088/1751-8113/43/38/385001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining tree decomposition and transfer matrix techniques provides a very
general algorithm for computing exact partition functions of statistical models
defined on arbitrary graphs. The algorithm is particularly efficient in the
case of planar graphs. We illustrate it by computing the Potts model partition
functions and chromatic polynomials (the number of proper vertex colourings
using Q colours) for large samples of random planar graphs with up to N=100
vertices. In the latter case, our algorithm yields a sub-exponential average
running time of ~ exp(1.516 sqrt(N)), a substantial improvement over the
exponential running time ~ exp(0.245 N) provided by the hitherto best known
algorithm. We study the statistics of chromatic roots of random planar graphs
in some detail, comparing the findings with results for finite pieces of a
regular lattice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4852</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4852</id><created>2010-03-25</created><authors><author><keyname>Rifa</keyname><forenames>J.</forenames></author><author><keyname>Ronquillo</keyname><forenames>L.</forenames></author></authors><title>Product Perfect Z2Z4-linear codes in Steganography</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, submitted to the 2010 International Symposium on
  Information Theory and Its Applications (ISITA2010)</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Product perfect codes have been proven to enhance the performance of the F5
steganographic method, whereas perfect Z2Z4-linear codes have been recently
introduced as an efficient way to embed data, conforming to the
+/-1-steganography. In this paper, we present two steganographic methods. On
the one hand, a generalization of product perfect codes is made. On the other
hand, this generalization is applied to perfect Z2Z4-linear codes. Finally, the
performance of the proposed methods is evaluated and compared with those of the
aforementioned schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4865</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4865</id><created>2010-03-25</created><updated>2013-04-29</updated><authors><author><keyname>Pikhurko</keyname><forenames>Oleg</forenames></author><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>Logical complexity of graphs: a survey</title><categories>math.CO cs.CC cs.LO math.LO</categories><comments>57 pages; 2 figures. This version contains an appendix with an
  improvement of Theorem 4.7</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the definability of finite graphs in first-order logic with two
relation symbols for adjacency and equality of vertices. The logical depth
$D(G)$ of a graph $G$ is equal to the minimum quantifier depth of a sentence
defining $G$ up to isomorphism. The logical width $W(G)$ is the minimum number
of variables occurring in such a sentence. The logical length $L(G)$ is the
length of a shortest defining sentence. We survey known estimates for these
graph parameters and discuss their relations to other topics (such as the
efficiency of the Weisfeiler-Lehman algorithm in isomorphism testing, the
evolution of a random graph, quantitative characteristics of the zero-one law,
or the contribution of Frank Ramsey to the research on Hilbert's
Entscheidungsproblem). Also, we trace the behavior of the descriptive
complexity of a graph as the logic becomes more restrictive (for example, only
definitions with a bounded number of variables or quantifier alternations are
allowed) or more expressible (after powering with counting quantifiers).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4866</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4866</id><created>2010-03-25</created><authors><author><keyname>Crochemore</keyname><forenames>Maxime</forenames></author><author><keyname>Kubica</keyname><forenames>Marcin</forenames></author><author><keyname>Radoszewski</keyname><forenames>Jakub</forenames></author><author><keyname>Rytter</keyname><forenames>Wojciech</forenames></author><author><keyname>Walen</keyname><forenames>Tomasz</forenames></author></authors><title>On the maximal sum of exponents of runs in a string</title><categories>cs.DM cs.FL</categories><comments>7 pages, 1 figure</comments><doi>10.1007/978-3-642-19222-7_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A run is an inclusion maximal occurrence in a string (as a subinterval) of a
repetition $v$ with a period $p$ such that $2p \le |v|$. The exponent of a run
is defined as $|v|/p$ and is $\ge 2$. We show new bounds on the maximal sum of
exponents of runs in a string of length $n$. Our upper bound of $4.1n$ is
better than the best previously known proven bound of $5.6n$ by Crochemore &amp;
Ilie (2008). The lower bound of $2.035n$, obtained using a family of binary
words, contradicts the conjecture of Kolpakov &amp; Kucherov (1999) that the
maximal sum of exponents of runs in a string of length $n$ is smaller than $2n$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4879</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4879</id><created>2010-03-25</created><authors><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Large Constant Dimension Codes and Lexicodes</title><categories>cs.IT math.IT</categories><comments>submitted for ALCOMA10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant dimension codes, with a prescribed minimum distance, have found
recently an application in network coding. All the codewords in such a code are
subspaces of $\F_q^n$ with a given dimension. A computer search for large
constant dimension codes is usually inefficient since the search space domain
is extremely large. Even so, we found that some constant dimension lexicodes
are larger than other known codes. We show how to make the computer search more
efficient. In this context we present a formula for the computation of the
distance between two subspaces, not necessarily of the same dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4894</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4894</id><created>2010-03-25</created><authors><author><keyname>Aurnague</keyname><forenames>Michel</forenames><affiliation>CLLE</affiliation></author><author><keyname>Vieu</keyname><forenames>Laure</forenames><affiliation>IRIT</affiliation></author><author><keyname>Borillo</keyname><forenames>Andr&#xe9;e</forenames><affiliation>CLLE</affiliation></author></authors><title>La repr\'esentation formelle des concepts spatiaux dans la langue</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>Langage et cognition spatiale, Michel Denis (Ed.) (1997) 69-102</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter, we assume that systematically studying spatial markers
semantics in language provides a means to reveal fundamental properties and
concepts characterizing conceptual representations of space. We propose a
formal system accounting for the properties highlighted by the linguistic
analysis, and we use these tools for representing the semantic content of
several spatial relations of French. The first part presents a semantic
analysis of the expression of space in French aiming at describing the
constraints that formal representations have to take into account. In the
second part, after presenting the structure of our formal system, we set out
its components. A commonsense geometry is sketched out and several functional
and pragmatic spatial concepts are formalized. We take a special attention in
showing that these concepts are well suited to representing the semantic
content of several prepositions of French ('sur' (on), 'dans' (in), 'devant'
(in front of), 'au-dessus' (above)), and in illustrating the inferential
adequacy of these representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4898</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4898</id><created>2010-03-25</created><authors><author><keyname>Aurnague</keyname><forenames>Michel</forenames><affiliation>CLLE</affiliation></author><author><keyname>Hickmann</keyname><forenames>Maya</forenames><affiliation>SFLTAMP</affiliation></author><author><keyname>Vieu</keyname><forenames>Laure</forenames><affiliation>IRIT</affiliation></author></authors><title>Les entit\'es spatiales dans la langue : \'etude descriptive, formelle
  et exp\'erimentale de la cat\'egorisation</title><categories>cs.CL</categories><proxy>ccsd</proxy><journal-ref>Agir dans l'espace, Catherine Thinus-Blanc \&amp; Jean Bullier (Ed.)
  (2005) 217-232</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While previous linguistic and psycholinguistic research on space has mainly
analyzed spatial relations, the studies reported in this paper focus on how
language distinguishes among spatial entities. Descriptive and experimental
studies first propose a classification of entities, which accounts for both
static and dynamic space, has some cross-linguistic validity, and underlies
adults' cognitive processing. Formal and computational analyses then introduce
theoretical elements aiming at modelling these categories, while fulfilling
various properties of formal ontologies (generality, parsimony, coherence...).
This formal framework accounts, in particular, for functional dependences among
entities underlying some part-whole descriptions. Finally, developmental
research shows that language-specific properties have a clear impact on how
children talk about space. The results suggest some cross-linguistic
variability in children's spatial representations from an early age onwards,
bringing into question models in which general cognitive capacities are the
only determinants of spatial cognition during the course of development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4905</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4905</id><created>2010-03-25</created><authors><author><keyname>Dideban</keyname><forenames>Abbas</forenames><affiliation>GIPSA-lab</affiliation></author><author><keyname>Alla</keyname><forenames>Hassane</forenames><affiliation>GIPSA-lab</affiliation></author></authors><title>Feedback control logic synthesis for non safe Petri nets</title><categories>cs.LO</categories><proxy>ccsd</proxy><journal-ref>Conf\'erence INCOM 2009, Moscou : Russian Federation (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of forbidden states of non safe Petri Net
(PN) modelling discrete events systems. To prevent the forbidden states, it is
possible to use conditions or predicates associated with transitions.
Generally, there are many forbidden states, thus many complex conditions are
associated with the transitions. A new idea for computing predicates in non
safe Petri nets will be presented. Using this method, we can construct a
maximally permissive controller if it exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4908</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4908</id><created>2010-03-25</created><authors><author><keyname>Bezat</keyname><forenames>Marie-C&#xe9;line</forenames><affiliation>PSA</affiliation></author><author><keyname>Roussarie</keyname><forenames>Vincent</forenames><affiliation>PSA</affiliation></author><author><keyname>Richard</keyname><forenames>Kronland-Martinet</forenames><affiliation>LMA</affiliation></author><author><keyname>Ystad</keyname><forenames>Solvi</forenames><affiliation>LMA</affiliation></author><author><keyname>Mcadams</keyname><forenames>Stephen</forenames></author></authors><title>Perceptual analyses of action-related impact sounds</title><categories>cs.SD</categories><proxy>ccsd</proxy><journal-ref>Euronoise 2006, Tampere : France (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among environmental sounds, we have chosen to study a class of action-related
impact sounds: automobile door closure sounds. We propose to describe these
sounds using a model composed of perceptual properties. The development of the
perceptual model was derived from the evaluation of many door closure sounds
measured under controlled laboratory listening conditions. However, listening
to such sounds normally occurs within a natural context, which probably
modifies their perception. We therefore need to study differences between the
real situation and the laboratory situation by following standard practices in
order to specify the precise listening conditions and observe the influence of
previous learning, expectations, action-perception interactions, and attention
given to sounds. Our process consists in doing in situ experiments that are
compared with specific laboratory experiments in order to isolate certain
influential, context dependent components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4919</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4919</id><created>2010-03-25</created><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author></authors><title>Doubly Perfect Nonlinear Boolean Permutations</title><categories>cs.DM cs.CR</categories><proxy>ccsd</proxy><journal-ref>Journal of Discrete Mathematical Sciences and Cryptography 13, 6
  (2010) 571-582</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to implementation constraints the XOR operation is widely used in order
to combine plaintext and key bit-strings in secret-key block ciphers. This
choice directly induces the classical version of the differential attack by the
use of XOR-kind differences. While very natural, there are many alternatives to
the XOR. Each of them inducing a new form for its corresponding differential
attack (using the appropriate notion of difference) and therefore block-ciphers
need to use S-boxes that are resistant against these nonstandard differential
cryptanalysis. In this contribution we study the functions that offer the best
resistance against a differential attack based on a finite field
multiplication. We also show that in some particular cases, there are robust
permutations which offers the best resistant against both multiplication and
exponentiation base differential attacks. We call them doubly perfect nonlinear
permutations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4924</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4924</id><created>2010-03-25</created><authors><author><keyname>Chellali</keyname><forenames>Amine</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Dumas</keyname><forenames>C&#xe9;dric</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Milleville-Pennel</keyname><forenames>Isabelle</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Nouri</keyname><forenames>Eric</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Common Frame of reference in collaborative virtual environments and
  their impact on presence</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>The 10th Annual International Workshop on Presence, Barcelone :
  Spain (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtual collaborative environment are 3D shared spaces in which people can
work together. To collaborate through these systems, users must have a shared
comprehension of the environment. The objective of this experimental study was
to determine if visual stable landmarks improve the construction of a common
representation of the virtual environment and thus facilitate collaboration.
This seems to increase the awareness of the partner's presence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4942</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4942</id><created>2010-03-25</created><updated>2010-07-03</updated><authors><author><keyname>Miller</keyname><forenames>Gary L.</forenames></author><author><keyname>Peng</keyname><forenames>Richard</forenames></author><author><keyname>Schwartz</keyname><forenames>Russell</forenames></author><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author></authors><title>Approximate Dynamic Programming using Halfspace Queries and Multiscale
  Monge decomposition</title><categories>cs.DS cs.CG</categories><comments>1) 12 pages 2) Updated 2nd Version: Removed section 3.3 of 1st
  version, updated references (for more details see
  www.cs.cmu.edu/~ctsourak/approxdp_note.txt)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P=(P_1, P_2, \ldots, P_n)$, $P_i \in \field{R}$ for all $i$, be a signal
and let $C$ be a constant. In this work our goal is to find a function
$F:[n]\rightarrow \field{R}$ which optimizes the following objective function:
  $$ \min_{F} \sum_{i=1}^n (P_i-F_i)^2 + C\times |\{i:F_i \neq F_{i+1} \} | $$
  The above optimization problem reduces to solving the following recurrence,
which can be done efficiently using dynamic programming in $O(n^2)$ time:
  $$ OPT_i = \min_{0 \leq j \leq i-1} [ OPT_j + \sum_{k=j+1}^i (P_k -
(\sum_{m=j+1}^i P_m)/(i-j) )^2 ]+ C $$
  The above recurrence arises naturally in applications where we wish to
approximate the original signal $P$ with another signal $F$ which consists
ideally of few piecewise constant segments. Such applications include database
(e.g., histogram construction), speech recognition, biology (e.g., denoising
aCGH data) applications and many more.
  In this work we present two new techniques for optimizing dynamic programming
that can handle cost functions not treated by other standard methods. The basis
of our first algorithm is the definition of a constant-shifted variant of the
objective function that can be efficiently approximated using state of the art
methods for range searching. Our technique approximates the optimal value of
our objective function within additive $\epsilon$ error and runs in
$\tilde{O}(n^{1.5} \log{(\frac{U}{\epsilon}))}$ time, where $U = \max_i f_i$.
The second algorithm we provide solves a similar recurrence within a factor of
$\epsilon$ and runs in $O(n \log^2n / \epsilon)$. The new technique introduced
by our algorithm is the decomposition of the initial problem into a small
(logarithmic) number of Monge optimization subproblems which we can speed up
using existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4944</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4944</id><created>2010-03-25</created><authors><author><keyname>Adams</keyname><forenames>Ryan Prescott</forenames></author><author><keyname>Dahl</keyname><forenames>George E.</forenames></author><author><keyname>Murray</keyname><forenames>Iain</forenames></author></authors><title>Incorporating Side Information in Probabilistic Matrix Factorization
  with Gaussian Processes</title><categories>stat.ML cs.LG</categories><comments>18 pages, 4 figures, Submitted to UAI 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic matrix factorization (PMF) is a powerful method for modeling
data associated with pairwise relationships, finding use in collaborative
filtering, computational biology, and document analysis, among other areas. In
many domains, there is additional information that can assist in prediction.
For example, when modeling movie ratings, we might know when the rating
occurred, where the user lives, or what actors appear in the movie. It is
difficult, however, to incorporate this side information into the PMF model. We
propose a framework for incorporating side information by coupling together
multiple PMF problems via Gaussian process priors. We replace scalar latent
features with functions that vary over the space of side information. The GP
priors on these functions require them to vary smoothly and share information.
We successfully use this new method to predict the scores of professional
basketball games, where side information about the venue and date of the game
are relevant for the outcome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4963</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4963</id><created>2010-03-25</created><authors><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Chaitman</keyname><forenames>Lilach</forenames></author></authors><title>Bounded Degree Planar Geometric Spanners</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set $P$ of $n$ points in the plane, we show how to compute in $O(n
\log n)$ time a subgraph of their Delaunay triangulation that has maximum
degree 7 and is a strong planar $t$-spanner of $P$ with $t =(1+ \sqrt{2})^2
*\delta$, where $\delta$ is the spanning ratio of the Delaunay triangulation.
Furthermore, given a Delaunay triangulation, we show a distributed algorithm
that computes the same bounded degree planar spanner in O(n) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4972</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4972</id><created>2010-03-25</created><updated>2011-05-13</updated><authors><author><keyname>Krishnamurthy</keyname><forenames>Vikram</forenames></author></authors><title>Quickest Time Herding and Detection for Optimal Social Learning</title><categories>cs.IT math.IT math.OC physics.soc-ph</categories><comments>This paper is an old/outdated version of the paper &quot;Bayesian
  Sequential Detection with Phase-Distributed Change Time and Nonlinear Penalty
  -- A Lattice programming approach&quot; arXiv:1011.5298</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers social learning amongst rational agents (for example,
sensors in a network). We consider three models of social learning in
increasing order of sophistication. In the first model, based on its private
observation of a noisy underlying state process, each agent selfishly optimizes
its local utility and broadcasts its action. This protocol leads to a herding
behavior where the agents eventually choose the same action irrespective of
their observations. We then formulate a second more general model where each
agent is benevolent and chooses its sensor-mode to optimize a social welfare
function to facilitate social learning. Using lattice programming and
stochastic orders, it is shown that the optimal decision each agent makes is
characterized by a switching curve on the space of Bayesian distributions. We
then present a third more general model where social learning takes place to
achieve quickest time change detection. Both geometric and phase-type change
time distributions are considered. It is proved that the optimal decision is
again characterized by a switching curve We present a stochastic approximation
(adaptive filtering) algorithms to estimate this switching curve. Finally, we
present extensions of the social learning model in a changing world (Markovian
target) where agents learn in multiple iterations. By using Blackwell
stochastic dominance, we give conditions under which myopic decisions are
optimal. We also analyze the effect of target dynamics on the social welfare
cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.4994</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.4994</id><created>2010-03-25</created><updated>2012-03-19</updated><authors><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Weak Decoupling Duality and Quantum Identification</title><categories>quant-ph cs.IT math.IT</categories><comments>14 pages; v2 has some remarks added and inaccuracies corrected; v3
  has new title, improved presentation and additional references; v4 is the
  final, accepted version (to appear in IEEE IT), title changed once more and
  numerous improvements made - the main one being that we can now show that
  nontrivial amortization is necessary in erasure channels</comments><journal-ref>IEEE Transactions on Information Theory 58(7):4914-4929, 2012</journal-ref><doi>10.1109/TIT.2012.2191695</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If a quantum system is subject to noise, it is possible to perform quantum
error correction reversing the action of the noise if and only if no
information about the system's quantum state leaks to the environment. In this
article, we develop an analogous duality in the case that the environment
approximately forgets the identity of the quantum state, a weaker condition
satisfied by epsilon-randomizing maps and approximate unitary designs.
Specifically, we show that the environment approximately forgets quantum states
if and only if the original channel approximately preserves pairwise fidelities
of pure inputs, an observation we call weak decoupling duality. Using this
tool, we then go on to study the task of using the output of a channel to
simulate restricted classes of measurements on a space of input states. The
case of simulating measurements that test whether the input state is an
arbitrary pure state is known as equality testing or quantum identification. An
immediate consequence of weak decoupling duality is that the ability to perform
quantum identification cannot be cloned. We furthermore establish that the
optimal amortized rate at which quantum states can be identified through a
noisy quantum channel is equal to the entanglement-assisted classical capacity
of the channel, despite the fact that the task is quantum, not classical, and
entanglement-assistance is not allowed. In particular, this rate is strictly
positive for every non-constant quantum channel, including classical channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5042</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5042</id><created>2010-03-26</created><authors><author><keyname>Chowdary</keyname><forenames>C Ravindranath</forenames></author></authors><title>Local Popularity based Page Link Analysis</title><categories>cs.IR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we introduce the concept of dynamic link pages. A web site/page
contains a number of links to other pages. All the links are not equally
important. Few links are more frequently visited and few rarely visited. In
this scenario, identifying the frequently used links and placing them in the
top left corner of the page will increase the user's satisfaction. This process
will reduce the time spent by a visitor on the page, as most of the times, the
popular links are presented in the visible part of the screen itself. Also, a
site can be indexed based on the popular links in that page. This will increase
the efficiency of the retrieval system. We presented a model to display the
popular links, and also proposed a method to increase the quality of retrieval
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5056</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5056</id><created>2010-03-26</created><authors><author><keyname>Nedjar</keyname><forenames>Sebastien</forenames><affiliation>LIF</affiliation></author><author><keyname>Casali</keyname><forenames>Alain</forenames><affiliation>LIF</affiliation></author><author><keyname>Cicchetti</keyname><forenames>Rosine</forenames><affiliation>LIF</affiliation></author><author><keyname>Lakhal</keyname><forenames>Lotfi</forenames><affiliation>LIF</affiliation></author></authors><title>Cubes convexes</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>Revue des Sciences et Technologies de l'Information (S\'erie
  Ing\'enierie des Syst\`emes d'Information) 11, 6 (2006) 11-31</journal-ref><doi>10.3166/isi.11.6.11-31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In various approaches, data cubes are pre-computed in order to answer
efficiently OLAP queries. The notion of data cube has been declined in various
ways: iceberg cubes, range cubes or differential cubes. In this paper, we
introduce the concept of convex cube which captures all the tuples of a
datacube satisfying a constraint combination. It can be represented in a very
compact way in order to optimize both computation time and required storage
space. The convex cube is not an additional structure appended to the list of
cube variants but we propose it as a unifying structure that we use to
characterize, in a simple, sound and homogeneous way, the other quoted types of
cubes. Finally, we introduce the concept of emerging cube which captures the
significant trend inversions. characterizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5068</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5068</id><created>2010-03-26</created><authors><author><keyname>Bonald</keyname><forenames>T.</forenames><affiliation>Telecom ParisTech, Paris, France</affiliation></author><author><keyname>Feuillet</keyname><forenames>M.</forenames><affiliation>INRIA, Rocquencourt, France</affiliation></author></authors><title>On the stability of flow-aware CSMA</title><categories>cs.PF cs.NI math.PR</categories><doi>10.1016/j.peva.2010.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless network where each flow (instead of each link) runs
its own CSMA (Carrier Sense Multiple Access) algorithm. Specifically, each flow
attempts to access the radio channel after some random time and transmits a
packet if the channel is sensed idle. We prove that, unlike the standard CSMA
algorithm, this simple distributed access scheme is optimal in the sense that
the network is stable for all traffic intensities in the capacity region of the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5080</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5080</id><created>2010-03-26</created><authors><author><keyname>Xiao</keyname><forenames>Xiaokui</forenames></author><author><keyname>Tao</keyname><forenames>Yufei</forenames></author><author><keyname>Koudas</keyname><forenames>Nick</forenames></author></authors><title>Transparent Anonymization: Thwarting Adversaries Who Know the Algorithm</title><categories>cs.DB</categories><comments>To appear in the ACM Transaction on Database Systems (TODS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous generalization techniques have been proposed for privacy preserving
data publishing. Most existing techniques, however, implicitly assume that the
adversary knows little about the anonymization algorithm adopted by the data
publisher. Consequently, they cannot guard against privacy attacks that exploit
various characteristics of the anonymization mechanism. This paper provides a
practical solution to the above problem. First, we propose an analytical model
for evaluating disclosure risks, when an adversary knows everything in the
anonymization process, except the sensitive values. Based on this model, we
develop a privacy principle, transparent l-diversity, which ensures privacy
protection against such powerful adversaries. We identify three algorithms that
achieve transparent l-diversity, and verify their effectiveness and efficiency
through extensive experiments with real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5097</identifier>
 <datestamp>2012-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5097</id><created>2010-03-26</created><updated>2012-03-02</updated><authors><author><keyname>Coon</keyname><forenames>J. P.</forenames></author><author><keyname>Cepeda</keyname><forenames>R.</forenames></author></authors><title>Power Loading in Parallel Diversity Channels Based on Statistical
  Channel Information</title><categories>cs.IT math.IT</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that there exists an arbitrary number of power
allocation schemes that achieve capacity in systems operating in parallel
channels comprised of single-input multiple-output (SIMO) Nakagami-m fading
subchannels when the number of degrees of freedom L (e.g., the number of
receive antennas) tends to infinity. Statistical waterfilling -- i.e.,
waterfilling using channel statistics rather than instantaneous channel
knowledge -- is one such scheme. We further prove that the convergence of
statistical waterfilling to the optimal power loading scheme is at least O(1/(L
log(L))), whereas convergence of other schemes is at worst O(1/log(L)). To
validate and demonstrate the practical use of our findings, we evaluate the
mutual information of example SIMO parallel channels using simulations as well
as new measured ultrawideband channel data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5104</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5104</id><created>2010-03-26</created><authors><author><keyname>Erdene-Ochir</keyname><forenames>Ochirkhand</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Minier</keyname><forenames>Marine</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Valois</keyname><forenames>Fabrice</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Kountouris</keyname><forenames>Apostolos</forenames><affiliation>FT R&amp;D</affiliation></author></authors><title>Resilient networking in wireless sensor networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><report-no>RR-7230</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report deals with security in wireless sensor networks (WSNs),
especially in network layer. Multiple secure routing protocols have been
proposed in the literature. However, they often use the cryptography to secure
routing functionalities. The cryptography alone is not enough to defend against
multiple attacks due to the node compromise. Therefore, we need more
algorithmic solutions. In this report, we focus on the behavior of routing
protocols to determine which properties make them more resilient to attacks.
Our aim is to find some answers to the following questions. Are there any
existing protocols, not designed initially for security, but which already
contain some inherently resilient properties against attacks under which some
portion of the network nodes is compromised? If yes, which specific behaviors
are making these protocols more resilient? We propose in this report an
overview of security strategies for WSNs in general, including existing attacks
and defensive measures. In this report we focus at the network layer in
particular, and an analysis of the behavior of four particular routing
protocols is provided to determine their inherent resiliency to insider
attacks. The protocols considered are: Dynamic Source Routing (DSR),
Gradient-Based Routing (GBR), Greedy Forwarding (GF) and Random Walk Routing
(RWR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5105</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5105</id><created>2010-03-26</created><authors><author><keyname>Anya</keyname><forenames>Apavatjrut</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Goursaud</keyname><forenames>Claire</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Jaffr&#xe8;s-Runser</keyname><forenames>Katia</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes, WNET</affiliation></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames><affiliation>WNET</affiliation></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Towards increasing diversity for the relaying of LT Fountain Codes in
  Wireless Sensor Networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diversity is a powerful means to increase the transmission performance of
wireless communications. For the case of fountain codes relaying, it has been
shown previously that introducing diversity is also beneficial since it
counteracts transmission losses on the channel. Instead of simply hop-by-hop
forwarding information, each sensor node diversifies the information flow using
XOR combinations of stored packets. This approach has been shown to be
efficient for random linear fountain codes. However, random linear codes
exhibit high decoding complexity. In this paper, we propose diversity increased
relaying strategies for the more realistic Luby Transform code in order to
maintain high transmission performance with low decoding computational
complexity in a linear network. Results are provided herein for a linear
network assuming uniform imperfect channel states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5173</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5173</id><created>2010-03-26</created><authors><author><keyname>Robert</keyname><forenames>Charles A. B.</forenames><affiliation>LORIA</affiliation></author></authors><title>LEXSYS: Architecture and Implication for Intelligent Agent systems</title><categories>cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LEXSYS, (Legume Expert System) was a project conceived at IITA (International
Institute of Tropical Agriculture) Ibadan Nigeria. It was initiated by the
COMBS (Collaborative Group on Maize-Based Systems Research in the 1990. It was
meant for a general framework for characterizing on-farm testing for technology
design for sustainable cereal-based cropping system. LEXSYS is not a true
expert system as the name would imply, but simply a user-friendly information
system. This work is an attempt to give a formal representation of the existing
system and then present areas where intelligent agent can be applied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5192</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5192</id><created>2010-03-26</created><authors><author><keyname>Lange</keyname><forenames>Christoph</forenames></author></authors><title>wiki.openmath.org - how it works, how you can participate</title><categories>cs.DL cs.MS math.HO</categories><comments>OpenMath workshop 2009 (http://staff.bath.ac.uk/masjhd/OM2009.html)</comments><msc-class>68T35, 68T30</msc-class><acm-class>F.4.m; H.3.5; H.5.3; H.5.4; J.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  At http://wiki.openmath.org, the OpenMath 2 and 3 Content Dictionaries are
accessible via a semantic wiki interface, powered by the SWiM system. We
shortly introduce the inner workings of the system, then describe how to use
it, and conclude with first experiences gained from OpenMath society members
working with the system and an outlook to further development plans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5196</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5196</id><created>2010-03-26</created><authors><author><keyname>Lange</keyname><forenames>Christoph</forenames></author></authors><title>SWiM -- A Semantic Wiki for Mathematical Knowledge Management</title><categories>cs.DL cs.MS math.HO</categories><msc-class>68T35; 68T30</msc-class><acm-class>F.4.m; H.3.5; H.5.3; H.5.4; J.2</acm-class><journal-ref>S. Bechhofer, M. Hauswirth, J. Hoffmann, M. Koubarakis. The
  Semantic Web: Research and Applications. ESWC 2008. LNCS 5021, Springer 2008</journal-ref><doi>10.1007/978-3-540-68234-9_68</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  SWiM is a semantic wiki for collaboratively building, editing and browsing
mathematical knowledge represented in the domain-specific structural semantic
markup language OMDoc. It motivates users to contribute to collections of
mathematical knowledge by instantly sharing the benefits of knowledge-powered
services with them. SWiM is currently being used for authoring content
dictionaries, i. e. collections of uniquely identified mathematical symbols,
and prepared for managing a large-scale proof formalisation effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5197</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5197</id><created>2010-03-26</created><updated>2010-07-11</updated><authors><author><keyname>Garcia</keyname><forenames>Ronald</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Lumsdaine</keyname><forenames>Andrew</forenames><affiliation>Indiana University</affiliation></author><author><keyname>Sabry</keyname><forenames>Amr</forenames><affiliation>Indiana University</affiliation></author></authors><title>Lazy Evaluation and Delimited Control</title><categories>cs.PL</categories><proxy>LMCS</proxy><acm-class>D.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (July 11,
  2010) lmcs:1013</journal-ref><doi>10.2168/LMCS-6(3:1)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The call-by-need lambda calculus provides an equational framework for
reasoning syntactically about lazy evaluation. This paper examines its
operational characteristics. By a series of reasoning steps, we systematically
unpack the standard-order reduction relation of the calculus and discover a
novel abstract machine definition which, like the calculus, goes &quot;under
lambdas.&quot; We prove that machine evaluation is equivalent to standard-order
evaluation. Unlike traditional abstract machines, delimited control plays a
significant role in the machine's behavior. In particular, the machine replaces
the manipulation of a heap using store-based effects with disciplined
management of the evaluation stack using control-based effects. In short, state
is replaced with control. To further articulate this observation, we present a
simulation of call-by-need in a call-by-value language using delimited control
operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5212</identifier>
 <datestamp>2010-03-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5212</id><created>2010-03-26</created><authors><author><keyname>Topakkaya</keyname><forenames>Hakan</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>Diversity-Multiplexing Tradeoff of Cooperative Communication with Linear
  Network Coded Relays</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Globecom conference 2010. 5 pages, 6 figures.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding and cooperative communication have received considerable
attention from the research community recently in order to mitigate the adverse
effects of fading in wireless transmissions and at the same time to achieve
high throughput and better spectral efficiency. In this work, we analyze a
network coding scheme for a cooperative communication setup with multiple
sources and destinations. The proposed protocol achieves the full diversity
order at the expense of a slightly reduced multiplexing rate compared to
existing schemes in the literature. We show that our scheme outperforms
conventional cooperation in terms of the diversity-multiplexing tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5238</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5238</id><created>2010-03-26</created><updated>2010-10-26</updated><authors><author><keyname>Klus</keyname><forenames>Stefan</forenames></author><author><keyname>Sahai</keyname><forenames>Tuhin</forenames></author><author><keyname>Liu</keyname><forenames>Cong</forenames></author><author><keyname>Dellnitz</keyname><forenames>Michael</forenames></author></authors><title>An efficient algorithm for the parallel solution of high-dimensional
  differential equations</title><categories>cs.DC math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of high-dimensional differential equations is challenging and
difficult due to the analytical and computational intractability. Here, we
improve the speed of waveform relaxation (WR), a method to simulate
high-dimensional differential-algebraic equations. This new method termed
adaptive waveform relaxation (AWR) is tested on a communication network
example. Further we propose different heuristics for computing graph partitions
tailored to adaptive waveform relaxation. We find that AWR coupled with
appropriate graph partitioning methods provides a speedup by a factor between 3
and 16.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5239</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5239</id><created>2010-03-26</created><updated>2010-08-20</updated><authors><author><keyname>Rajawat</keyname><forenames>Ketan</forenames></author><author><keyname>Gatsis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Cross-Layer Designs in Coded Wireless Fading Networks with Multicast</title><categories>cs.NI math.OC</categories><comments>Accepted in IEEE/ACM Transactions on Networking; revision pending</comments><doi>10.1109/TNET.2011.2109010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cross-layer design along with an optimal resource allocation framework is
formulated for wireless fading networks, where the nodes are allowed to perform
network coding. The aim is to jointly optimize end-to-end transport layer
rates, network code design variables, broadcast link flows, link capacities,
average power consumption, and short-term power allocation policies. As in the
routing paradigm where nodes simply forward packets, the cross-layer
optimization problem with network coding is non-convex in general. It is proved
however, that with network coding, dual decomposition for multicast is optimal
so long as the fading at each wireless link is a continuous random variable.
This lends itself to provably convergent subgradient algorithms, which not only
admit a layered-architecture interpretation but also optimally integrate
network coding in the protocol stack. The dual algorithm is also paired with a
scheme that yields near-optimal network design variables, namely multicast
end-to-end rates, network code design quantities, flows over the broadcast
links, link capacities, and average power consumption. Finally, an asynchronous
subgradient method is developed, whereby the dual updates at the physical layer
can be affordably performed with a certain delay with respect to the resource
allocation tasks in upper layers. This attractive feature is motivated by the
complexity of the physical layer subproblem, and is an adaptation of the
subgradient method suitable for network control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5249</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5249</id><created>2010-03-26</created><authors><author><keyname>Sznitman</keyname><forenames>Raphael</forenames></author><author><keyname>Jedynak</keyname><forenames>Bruno</forenames></author></authors><title>Active Testing for Face Detection and Localization</title><categories>cs.CV</categories><comments>16 pages, 5 figures, accepted in IEEE Transactions on Pattern
  Analysis and Machine Intelligence (TPAMI), 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a novel search technique, which uses a hierarchical model and a
mutual information gain heuristic to efficiently prune the search space when
localizing faces in images. We show exponential gains in computation over
traditional sliding window approaches, while keeping similar performance
levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5257</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5257</id><created>2010-03-26</created><updated>2010-06-05</updated><authors><author><keyname>Nagarajan</keyname><forenames>H.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author></authors><title>Enforcing the non-negativity constraint and maximum principles for
  diffusion with decay on general computational grids</title><categories>cs.NA</categories><doi>10.1002/fld.2389</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider anisotropic diffusion with decay, and the
diffusivity coefficient to be a second-order symmetric and positive definite
tensor. It is well-known that this particular equation is a second-order
elliptic equation, and satisfies a maximum principle under certain regularity
assumptions. However, the finite element implementation of the classical
Galerkin formulation for both anisotropic and isotropic diffusion with decay
does not respect the maximum principle.
  We first show that the numerical accuracy of the classical Galerkin
formulation deteriorates dramatically with increase in the decay coefficient
for isotropic medium and violates the discrete maximum principle. However, in
the case of isotropic medium, the extent of violation decreases with mesh
refinement. We then show that, in the case of anisotropic medium, the classical
Galerkin formulation for anisotropic diffusion with decay violates the discrete
maximum principle even at lower values of decay coefficient and does not vanish
with mesh refinement. We then present a methodology for enforcing maximum
principles under the classical Galerkin formulation for anisotropic diffusion
with decay on general computational grids using optimization techniques.
Representative numerical results (which take into account anisotropy and
heterogeneity) are presented to illustrate the performance of the proposed
formulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5268</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5268</id><created>2010-03-27</created><authors><author><keyname>Upadhyay</keyname><forenames>Ashish Kumar</forenames></author></authors><title>Contractible Hamiltonian Cycles in Triangulated Surfaces</title><categories>math.GT cs.CG math.CO</categories><comments>6 pages, 1 figure</comments><msc-class>57Q15, 57M20, 57N05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A triangulation of a surface is called $q$-equivelar if each of its vertices
is incident with exactly $q$ triangles. In 1972 Altshuler had shown that an
equivelar triangulation of torus has a Hamiltonian Circuit. Here we present a
necessary and sufficient condition for existence of a contractible Hamiltonian
Cycle in equivelar triangulation of a surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5303</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5303</id><created>2010-03-27</created><updated>2010-07-25</updated><authors><author><keyname>Aviram</keyname><forenames>Amittai</forenames></author><author><keyname>Hu</keyname><forenames>Sen</forenames></author><author><keyname>Ford</keyname><forenames>Bryan</forenames></author><author><keyname>Gummadi</keyname><forenames>Ramakrishna</forenames></author></authors><title>Determinating Timing Channels in Compute Clouds</title><categories>cs.OS cs.CR</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Timing side-channels represent an insidious security challenge for cloud
computing, because: (a) massive parallelism in the cloud makes timing channels
pervasive and hard to control; (b) timing channels enable one customer to steal
information from another without leaving a trail or raising alarms; (c) only
the cloud provider can feasibly detect and report such attacks, but the
provider's incentives are not to; and (d) resource partitioning schemes for
timing channel control undermine statistical sharing efficiency, and, with it,
the cloud computing business model. We propose a new approach to timing channel
control, using provider-enforced deterministic execution instead of resource
partitioning to eliminate timing channels within a shared cloud domain.
Provider-enforced determinism prevents execution timing from affecting the
results of a compute task, however large or parallel, ensuring that a task's
outputs leak no timing information apart from explicit timing inputs and total
compute duration. Experiments with a prototype OS for deterministic cloud
computing suggest that such an approach may be practical and efficient. The OS
supports deterministic versions of familiar APIs such as processes, threads,
shared memory, and file systems, and runs coarse-grained parallel tasks as
efficiently and scalably as current timing channel-ridden systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5304</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5304</id><created>2010-03-27</created><updated>2010-09-12</updated><authors><author><keyname>Usatyuk</keyname><forenames>V. S.</forenames></author></authors><title>Review of Lattice-based Public key Cryptography(Russian)</title><categories>cs.CR</categories><comments>13 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presets a review of the achievements rapidly developing field of
cryptography - public-key cryptography based on the lattice theory. Paper
contains the necessary basic concepts and the major problems of the lattice
theory, as well as together with the description on the benefits of this
cryptography class - the properties of the reliability to quantum computers and
full homomorphism, the shortcomings of specific implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5305</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5305</id><created>2010-03-27</created><updated>2010-04-16</updated><authors><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>Rational Value of Information Estimation for Measurement Selection</title><categories>cs.AI</categories><comments>7 pages, 2 figures, presented at URPDM2010; plots fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing value of information (VOI) is a crucial task in various aspects of
decision-making under uncertainty, such as in meta-reasoning for search; in
selecting measurements to make, prior to choosing a course of action; and in
managing the exploration vs. exploitation tradeoff. Since such applications
typically require numerous VOI computations during a single run, it is
essential that VOI be computed efficiently. We examine the issue of anytime
estimation of VOI, as frequently it suffices to get a crude estimate of the
VOI, thus saving considerable computational resources. As a case study, we
examine VOI estimation in the measurement selection problem. Empirical
evaluation of the proposed scheme in this domain shows that computational
resources can indeed be significantly reduced, at little cost in expected
rewards achieved in the overall decision problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5309</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5309</id><created>2010-03-27</created><authors><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael G.</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author></authors><title>Gossip Algorithms for Distributed Signal Processing</title><categories>cs.DC cs.IT cs.NI math.IT</categories><comments>Submitted to Proceedings of the IEEE, 29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gossip algorithms are attractive for in-network processing in sensor networks
because they do not require any specialized routing, there is no bottleneck or
single point of failure, and they are robust to unreliable wireless network
conditions. Recently, there has been a surge of activity in the computer
science, control, signal processing, and information theory communities,
developing faster and more robust gossip algorithms and deriving theoretical
performance guarantees. This article presents an overview of recent work in the
area. We describe convergence rate results, which are related to the number of
transmitted messages and thus the amount of energy consumed in the network for
gossiping. We discuss issues related to gossiping over wireless links,
including the effects of quantization and noise, and we illustrate the use of
gossip algorithms for canonical signal processing tasks including distributed
estimation, source localization, and compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5320</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5320</id><created>2010-03-27</created><authors><author><keyname>Bronstein</keyname><forenames>Alexander M.</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author><author><keyname>Kimmel</keyname><forenames>Ron</forenames></author></authors><title>The Video Genome</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast evolution of Internet technologies has led to an explosive growth of
video data available in the public domain and created unprecedented challenges
in the analysis, organization, management, and control of such content. The
problems encountered in video analysis such as identifying a video in a large
database (e.g. detecting pirated content in YouTube), putting together video
fragments, finding similarities and common ancestry between different versions
of a video, have analogous counterpart problems in genetic research and
analysis of DNA and protein sequences. In this paper, we exploit the analogy
between genetic sequences and videos and propose an approach to video analysis
motivated by genomic research. Representing video information as video DNA
sequences and applying bioinformatic algorithms allows to search, match, and
compare videos in large-scale databases. We show an application for
content-based metadata mapping between versions of annotated video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5324</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5324</id><created>2010-03-27</created><updated>2010-08-24</updated><authors><author><keyname>Kesidis</keyname><forenames>G.</forenames></author><author><keyname>Jin</keyname><forenames>Y.</forenames></author><author><keyname>Azad</keyname><forenames>A. P.</forenames></author><author><keyname>Altman</keyname><forenames>E.</forenames></author></authors><title>Stable Nash equilibria of medium access games under symmetric, socially
  altruistic behavior</title><categories>cs.GT cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the effects of altruistic behavior on random medium access
control (slotted ALOHA) for local area communication networks. For an
idealized, synchronously iterative, two-player game with asymmetric player
demands, we find a Hamiltonian governing the Jacobi dynamics under purely
altruistic behavior. Though the positions of the interior Nash equilibrium
points do not change in the presence of altruistic behavior, the nature of
their local asymptotic stability does. There is a region of partially
altruistic behavior for which neither interior Nash equilibrium point is
locally asymptotically stable. Also, for a power control game with a single
Nash equilibrium, we show how its stability changes as a function of the
altruism parameter. Variations of these altruistic game frameworks are
discussed considering power (instead of throughput) based costs and linear
utility functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5325</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5325</id><created>2010-03-27</created><authors><author><keyname>Meiss</keyname><forenames>Mark</forenames></author><author><keyname>Duncan</keyname><forenames>John</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Bruno</forenames></author><author><keyname>Ramasco</keyname><forenames>Jos&#xe9; J.</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>What's in a Session: Tracking Individual Behavior on the Web</title><categories>cs.HC cs.MA physics.soc-ph</categories><comments>10 pages, 13 figures, 1 table</comments><journal-ref>Proceedings of the 20th ACM conference on Hypertext and
  hypermedia, 173-182 (2009)</journal-ref><doi>10.1145/1557914.1557946</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the properties of all HTTP requests generated by a thousand
undergraduates over a span of two months. Preserving user identity in the data
set allows us to discover novel properties of Web traffic that directly affect
models of hypertext navigation. We find that the popularity of Web sites -- the
number of users who contribute to their traffic -- lacks any intrinsic mean and
may be unbounded. Further, many aspects of the browsing behavior of individual
users can be approximated by log-normal distributions even though their
aggregate behavior is scale-free. Finally, we show that users' click streams
cannot be cleanly segmented into sessions using timeouts, affecting any attempt
to model hypertext navigation using statistics of individual sessions. We
propose a strictly logical definition of sessions based on browsing activity as
revealed by referrer URLs; a user may have several active sessions in their
click stream at any one time. We demonstrate that applying a timeout to these
logical sessions affects their statistics to a lesser extent than a purely
timeout-based mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5326</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5326</id><created>2010-03-27</created><updated>2011-02-28</updated><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Fiat</keyname><forenames>Amos</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Olonetsky</keyname><forenames>Svetlana</forenames></author></authors><title>Truth and Envy in Capacitated Allocation Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study auctions with additive valuations where agents have a limit on the
number of goods they may receive. We refer to such valuations as {\em
capacitated} and seek mechanisms that maximize social welfare and are
simultaneously incentive compatible, envy-free, individually rational, and have
no positive transfers. If capacities are infinite, then sequentially repeating
the 2nd price Vickrey auction meets these requirements. In 1983, Leonard showed
that for unit capacities, VCG with Clarke Pivot payments is also envy free. For
capacities that are all unit or all infinite, the mechanism produces a
Walrasian pricing (subject to capacity constraints). Here, we consider general
capacities. For homogeneous capacities (all capacities equal) we show that VCG
with Clarke Pivot payments is envy free (VCG with Clarke Pivot payments is
always incentive compatible, individually rational, and has no positive
transfers). Contrariwise, there is no incentive compatible Walrasian pricing.
For heterogeneous capacities, we show that there is no mechanism with all 4
properties, but at least in some cases, one can achieve both incentive
compatibility and envy freeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5327</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5327</id><created>2010-03-27</created><authors><author><keyname>Meiss</keyname><forenames>Mark</forenames></author><author><keyname>Gon&#xe7;alves</keyname><forenames>Bruno</forenames></author><author><keyname>Ramasco</keyname><forenames>Jos&#xe9; J.</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Agents, Bookmarks and Clicks: A topical model of Web traffic</title><categories>cs.NI cs.IR cs.MA physics.soc-ph</categories><comments>10 pages, 16 figures, 1 table - Long version of paper to appear in
  Proceedings of the 21th ACM conference on Hypertext and Hypermedia</comments><journal-ref>Proceedings of the 21th ACM conference on Hypertext and
  hypermedia, 229 (2010)</journal-ref><doi>10.1145/1810617.1810658</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of aggregate and individual Web traffic has shown that PageRank is a
poor model of how people navigate the Web. Using the empirical traffic patterns
generated by a thousand users, we characterize several properties of Web
traffic that cannot be reproduced by Markovian models. We examine both
aggregate statistics capturing collective behavior, such as page and link
traffic, and individual statistics, such as entropy and session size. No model
currently explains all of these empirical observations simultaneously. We show
that all of these traffic patterns can be explained by an agent-based model
that takes into account several realistic browsing behaviors. First, agents
maintain individual lists of bookmarks (a non-Markovian memory mechanism) that
are used as teleportation targets. Second, agents can retreat along visited
links, a branching mechanism that also allows us to reproduce behaviors such as
the use of a back button and tabbed browsing. Finally, agents are sustained by
visiting novel pages of topical interest, with adjacent pages being more
topically related to each other than distant ones. This modulates the
probability that an agent continues to browse or starts a new session, allowing
us to recreate heterogeneous session lengths. The resulting model is capable of
reproducing the collective and individual behaviors we observe in the empirical
data, reconciling the narrowly focused browsing patterns of individual users
with the extreme heterogeneity of aggregate traffic measurements. This result
allows us to identify a few salient features that are necessary and sufficient
to interpret the browsing patterns observed in our data. In addition to the
descriptive and explanatory power of such a model, our results may lead the way
to more sophisticated, realistic, and effective ranking and crawling
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5328</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5328</id><created>2010-03-27</created><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Fiat</keyname><forenames>Amos</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Olonetsky</keyname><forenames>Svetlana</forenames></author></authors><title>On the Interplay between Incentive Compatibility and Envy Freeness</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study mechanisms for an allocation of goods among agents, where agents
have no incentive to lie about their true values (incentive compatible) and for
which no agent will seek to exchange outcomes with another (envy-free).
Mechanisms satisfying each requirement separately have been studied
extensively, but there are few results on mechanisms achieving both. We are
interested in those allocations for which there exist payments such that the
resulting mechanism is simultaneously incentive compatible and envy-free.
Cyclic monotonicity is a characterization of incentive compatible allocations,
local efficiency is a characterization for envy-free allocations. We combine
the above to give a characterization for allocations which are both incentive
compatible and envy free. We show that even for allocations that allow payments
leading to incentive compatible mechanisms, and other payments leading to envy
free mechanisms, there may not exist any payments for which the mechanism is
simultaneously incentive compatible and envy-free. The characterization that we
give lets us compute the set of Pareto-optimal mechanisms that trade off envy
freeness for incentive compatibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5330</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5330</id><created>2010-03-27</created><updated>2010-06-23</updated><authors><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author></authors><title>Lin-Kernighan Heuristic Adaptations for the Generalized Traveling
  Salesman Problem</title><categories>cs.DS</categories><comments>25 pages</comments><journal-ref>European Journal of Operational Research 208(3), pages 221-232,
  2011</journal-ref><doi>10.1016/j.ejor.2010.08.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Lin-Kernighan heuristic is known to be one of the most successful
heuristics for the Traveling Salesman Problem (TSP). It has also proven its
efficiency in application to some other problems. In this paper we discuss
possible adaptations of TSP heuristics for the Generalized Traveling Salesman
Problem (GTSP) and focus on the case of the Lin-Kernighan algorithm. At first,
we provide an easy-to-understand description of the original Lin-Kernighan
heuristic. Then we propose several adaptations, both trivial and complicated.
Finally, we conduct a fair competition between all the variations of the
Lin-Kernighan adaptation and some other GTSP heuristics. It appears that our
adaptation of the Lin-Kernighan algorithm for the GTSP reproduces the success
of the original heuristic. Different variations of our adaptation outperform
all other heuristics in a wide range of trade-offs between solution quality and
running time, making Lin-Kernighan the state-of-the-art GTSP local search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5342</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5342</id><created>2010-03-28</created><authors><author><keyname>Mostafa</keyname><forenames>Samih Mohemmed</forenames></author></authors><title>Improving Waiting Time of Tasks Scheduled Under Preemptive Round Robin
  Using Changeable Time Quantum</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimizing waiting time for tasks waiting in the queue for execution is one
of the important scheduling cri-teria which took a wide area in scheduling
preemptive tasks. In this paper we present Changeable Time Quan-tum (CTQ)
approach combined with the round-robin algorithm, we try to adjust the time
quantum according to the burst times of the tasks in the ready queue. There are
two important benefits of using (CTQ) approach: minimizing the average waiting
time of the tasks, consequently minimizing the average turnaround time, and
keeping the number of context switches as low as possible, consequently
minimizing the scheduling overhead. In this paper, we consider the scheduling
problem for preemptive tasks, where the time costs of these tasks are known a
priori. Our experimental results demonstrate that CTQ can provide much lower
scheduling overhead and better scheduling criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5345</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5345</id><created>2010-03-28</created><authors><author><keyname>Pad</keyname><forenames>P.</forenames></author><author><keyname>Shafinia</keyname><forenames>M. H.</forenames></author><author><keyname>Mansouri</keyname><forenames>S. M.</forenames></author><author><keyname>Kabir</keyname><forenames>P.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author></authors><title>Bounds for the Sum Capacity of Binary CDMA Systems in Presence of
  Near-Far Effect</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are going to estimate the sum capacity of a binary CDMA
system in presence of the near-far effect. We model the near-far effect as a
random variable that is multiplied by the users binary data before entering the
noisy channel. We will find a lower bound and a conjectured upper bound for the
sum capacity in this situation. All the derivations are in the asymptotic case.
Simulations show that especially the lower bound is very tight for typical
values Eb/N0 and near-far effect. Also, we exploit our idea in conjunction with
the Tanaka's formula [6] which also estimates the sum capacity of binary CDMA
systems with perfect power control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5350</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5350</id><created>2010-03-28</created><authors><author><keyname>Dougherty</keyname><forenames>Daniel J.</forenames></author></authors><title>An Improved Algorithm for Generating Database Transactions from
  Relational Algebra Specifications</title><categories>cs.DB cs.LO cs.PL</categories><journal-ref>EPTCS 21, 2010, pp. 77-89</journal-ref><doi>10.4204/EPTCS.21.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alloy is a lightweight modeling formalism based on relational algebra. In
prior work with Fisler, Giannakopoulos, Krishnamurthi, and Yoo, we have
presented a tool, Alchemy, that compiles Alloy specifications into
implementations that execute against persistent databases. The foundation of
Alchemy is an algorithm for rewriting relational algebra formulas into code for
database transactions. In this paper we report on recent progress in improving
the robustness and efficiency of this transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5363</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5363</id><created>2010-03-28</created><authors><author><keyname>Bujorianu</keyname><forenames>Manuela</forenames><affiliation>University of Manchester, UK</affiliation></author><author><keyname>Fisher</keyname><forenames>Michael</forenames><affiliation>University of Liverpool, UK</affiliation></author></authors><title>Proceedings FM-09 Workshop on Formal Methods for Aerospace</title><categories>cs.LO cs.SE</categories><proxy>EPTCS</proxy><acm-class>D.2.2; D.2.4; J.2; B.1.2</acm-class><journal-ref>EPTCS 20, 2010</journal-ref><doi>10.4204/EPTCS.20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main workshop objective was to promote a holistic view and
interdisciplinary methods for design, verification and co-ordination of
aerospace systems, by combining formal methods with techniques from control
engineering and artificial intelligence. The very demanding safety, robustness
and performance requirements of these systems require unprecedented integration
of heterogeneous techniques and models. The aim of FMA was to bring together
active researchers from all the above areas to discuss and present their work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5372</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5372</id><created>2010-03-28</created><authors><author><keyname>Afantenos</keyname><forenames>Stergos</forenames></author><author><keyname>Denis</keyname><forenames>Pascal</forenames></author><author><keyname>Muller</keyname><forenames>Philippe</forenames></author><author><keyname>Danlos</keyname><forenames>Laurence</forenames></author></authors><title>Learning Recursive Segments for Discourse Parsing</title><categories>cs.CL</categories><comments>published at LREC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatically detecting discourse segments is an important preliminary step
towards full discourse parsing. Previous research on discourse segmentation
have relied on the assumption that elementary discourse units (EDUs) in a
document always form a linear sequence (i.e., they can never be nested).
Unfortunately, this assumption turns out to be too strong, for some theories of
discourse like SDRT allows for nested discourse units. In this paper, we
present a simple approach to discourse segmentation that is able to produce
nested EDUs. Our approach builds on standard multi-class classification
techniques combined with a simple repairing heuristic that enforces global
coherence. Our system was developed and evaluated on the first round of
annotations provided by the French Annodis project (an ongoing effort to create
a discourse bank for French). Cross-validated on only 47 documents (1,445
EDUs), our system achieves encouraging performance results with an F-score of
73% for finding EDUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5383</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5383</id><created>2010-03-28</created><authors><author><keyname>Malladi</keyname><forenames>Sreekanth</forenames></author><author><keyname>Bruhadeshwar</keyname><forenames>Bezawada</forenames></author><author><keyname>Kothapalli</keyname><forenames>Kishore</forenames></author></authors><title>Automatic analysis of distance bounding protocols</title><categories>cs.CR cs.NI</categories><comments>22 pages, Appeared in Foundations of Computer Security, (Affiliated
  workshop of LICS 2009, Los Angeles, CA).</comments><report-no>FCS09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance bounding protocols are used by nodes in wireless networks to
calculate upper bounds on their distances to other nodes. However, dishonest
nodes in the network can turn the calculations both illegitimate and inaccurate
when they participate in protocol executions. It is important to analyze
protocols for the possibility of such violations. Past efforts to analyze
distance bounding protocols have only been manual. However, automated
approaches are important since they are quite likely to find flaws that manual
approaches cannot, as witnessed in literature for analysis pertaining to key
establishment protocols. In this paper, we use the constraint solver tool to
automatically analyze distance bounding protocols. We first formulate a new
trace property called Secure Distance Bounding (SDB) that protocol executions
must satisfy. We then classify the scenarios in which these protocols can
operate considering the (dis)honesty of nodes and location of the attacker in
the network. Finally, we extend the constraint solver so that it can be used to
test protocols for violations of SDB in these scenarios and illustrate our
technique on some published protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5384</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5384</id><created>2010-03-28</created><updated>2010-05-09</updated><authors><author><keyname>Malladi</keyname><forenames>Sreekanth</forenames></author></authors><title>Protocol indepedence through disjoint encryption under Exclusive-OR</title><categories>cs.CR cs.SC</categories><comments>22 pages, In Proceedings, Foundations of Security and Privacy
  (FCS-PrivMod 2010).</comments><report-no>DSU-BIS-IA-Mallb2010</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-protocol attacks due to protocol interaction has been a notorious
problem for security. Gutman-Thayer proved that they can be prevented by
ensuring that encrypted messages are distinguishable across protocols, under a
free algebra. In this paper, we prove that a similar suggestion prevents these
attacks under commonly used operators such as Exclusive-OR, that induce
equational theories, breaking the free algebra assumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5385</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5385</id><created>2010-03-28</created><authors><author><keyname>Malladi</keyname><forenames>Sreekanth</forenames></author><author><keyname>Lafourcade</keyname><forenames>Pascal</forenames></author></authors><title>How to prevent type-flaw attacks on security protocols under algebraic
  properties</title><categories>cs.CR</categories><comments>16 pages, Appeared in proceedings of Security with Rewriting
  Techniques (SecRet09), Affiliated to CSF Symposium 2009, Port Jefferson, NY.</comments><report-no>ML09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Type-flaw attacks upon security protocols wherein agents are led to
misinterpret message types have been reported frequently in the literature.
Preventing them is crucial for protocol security and verification. Heather et
al. proved that tagging every message field with it's type prevents all
type-flaw attacks under a free message algebra and perfect encryption system.
In this paper, we prove that type-flaw attacks can be prevented with the same
technique even under the ACUN algebraic properties of XOR which is commonly
used in &quot;real-world&quot; protocols such as SSL 3.0. Our proof method is general and
can be easily extended to other monoidal operators that possess properties such
as Inverse and Idempotence as well. We also discuss how tagging could be used
to prevent type-flaw attacks under other properties such as associativity of
pairing, commutative encryption, prefix property and homomorphic encryption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5390</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5390</id><created>2010-03-28</created><authors><author><keyname>Libby</keyname><forenames>Vibeke</forenames></author></authors><title>A Fast Algorithm for Determining the Existence and Value of Integer
  Roots of N</title><categories>math.NT cs.DM cs.DS</categories><comments>12 pages, 8 figures</comments><msc-class>11A07; 11D09; 11Y05</msc-class><acm-class>B.2.4; D.1.0; F.2.1; G.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that all perfect odd integer squares not divisible by 3, can be
usefully written as sqrt(N) = a + 18p, where the constant a is determined by
the basic properties of N. The equation can be solved deterministically by an
efficient four step algorithm that is solely based on integer arithmetic. There
is no required multiplication or division by multiple digit integers, nor does
the algorithm need a seed value. It finds the integer p when N is a perfect
square, and certifies N as a non-square when the algorithm terminates without a
solution. The number of iterations scales approximately as log(sqrt(N)/2) for
square roots. The paper also outlines how one of the methods discussed for
squares can be extended to finding an arbitrary root of N. Finally, we present
a rule that distinguishes products of twin primes from squares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5399</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5399</id><created>2010-03-28</created><updated>2010-10-18</updated><authors><author><keyname>Kontchakov</keyname><forenames>Roman</forenames><affiliation>Birkbeck College London</affiliation></author><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames><affiliation>Department of Computer Science, Manchester University</affiliation></author><author><keyname>Wolter</keyname><forenames>Frank</forenames><affiliation>Department of Computer Science, University of Liverpool</affiliation></author><author><keyname>Zakharyaschev</keyname><forenames>Michael</forenames><affiliation>Birkbeck College London</affiliation></author></authors><title>Spatial logics with connectedness predicates</title><categories>cs.LO</categories><comments>Some results of the paper were presented at LPAR 2008 and ECAI 2000</comments><proxy>LMCS</proxy><acm-class>F.4.1, I.2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (August 18,
  2010) lmcs:1229</journal-ref><doi>10.2168/LMCS-6(3:7)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider quantifier-free spatial logics, designed for qualitative spatial
representation and reasoning in AI, and extend them with the means to represent
topological connectedness of regions and restrict the number of their connected
components. We investigate the computational complexity of these logics and
show that the connectedness constraints can increase complexity from NP to
PSpace, ExpTime and, if component counting is allowed, to NExpTime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5406</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5406</id><created>2010-03-28</created><updated>2010-04-09</updated><authors><author><keyname>Malladi</keyname><forenames>Sreekanth</forenames></author></authors><title>Disabling equational theories in unification for cryptographic protocol
  analysis through tagging</title><categories>cs.CR cs.DM cs.LO cs.SC</categories><comments>8 pages, submitted for publication</comments><report-no>DSU-BIS-MSIA-Mall2010C</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show a new tagging scheme for cryptographic protocol
messages. Under this tagging, equational theories of operators such as
exclusive-or, binary addition etc. are effectively disabled, when terms are
unified. We believe that this result has a significant impact on protocol
analysis and security, since unification is at the heart of symbolic protocol
analysis. Hence, disabling equational theories in unification implies disabling
them altogether in protocol analysis for most operators and theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5413</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5413</id><created>2010-03-28</created><authors><author><keyname>Zhao</keyname><forenames>Yong-Xiang</forenames></author><author><keyname>Chen</keyname><forenames>Chang-Jia</forenames></author></authors><title>Modeling Multi-Point Transport Protocol in P2P Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional end-to-end congestion control mechanisms assume data transferring
happens between each pair user. In contrast, in a P2P network, many peers may
locally keep a copy of a specific data object. If the path between a pair of
peers is congested, the requesting peer who wants to download data will switch
to another peer in its neighbor peer list to fetch the data instead of
decreasing the download rate from the current peer. Thus, it is critical to
study the performance in multi-point-to-multi-point (M2M) transport protocol in
a P2P network. In this paper, we build a mathematical model for identifying the
key parameters for the M2M transport protocol and also the relationships among
these parameters. Finally, we conduct simulation experiments to validate our
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5429</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5429</id><created>2010-03-29</created><authors><author><keyname>Onofrei</keyname><forenames>Andreea Ancuta</forenames></author><author><keyname>Rebahi</keyname><forenames>Yacine</forenames></author><author><keyname>Magedanz</keyname><forenames>Thomas</forenames></author><author><keyname>Institute</keyname><forenames>Fokus Fraunhofer</forenames></author><author><keyname>Germany</keyname></author></authors><title>Preventing Distributed Denial-of-Service Attacks on the IMS Emergency
  Services Support through Adaptive Firewall Pinholing</title><categories>cs.NI cs.CR</categories><comments>17 Pages, IJNGN Journal</comments><journal-ref>International Journal of Next-Generation Networks 2.1 (2010) 1-17</journal-ref><doi>10.5121/ijngn.2010.2101</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Emergency services are vital services that Next Generation Networks (NGNs)
have to provide. As the IP Multimedia Subsystem (IMS) is in the heart of NGNs,
3GPP has carried the burden of specifying a standardized IMS-based emergency
services framework. Unfortunately, like any other IP-based standards, the
IMS-based emergency service framework is prone to Distributed Denial of Service
(DDoS) attacks. We propose in this work, a simple but efficient solution that
can prevent certain types of such attacks by creating firewall pinholes that
regular clients will surely be able to pass in contrast to the attackers
clients. Our solution was implemented, tested in an appropriate testbed, and
its efficiency was proven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5431</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5431</id><created>2010-03-29</created><authors><author><keyname>Somayaji</keyname><forenames>Siva Rama Krishnan</forenames><affiliation>VIT University, India</affiliation></author><author><keyname>Murty</keyname><forenames>Ch. A. S</forenames><affiliation>C-DAC, Hyderabad, India</affiliation></author></authors><title>Securing Internet Protocol (IP) Storage: A Case Study</title><categories>cs.NI</categories><comments>10 Pages, IJNGN Journal</comments><journal-ref>International Journal of Next-Generation Networks 2.1 (2010) 19-28</journal-ref><doi>10.5121/ijngn.2010.2102</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Storage networking technology has enjoyed strong growth in recent years, but
security concerns and threats facing networked data have grown equally fast.
Today, there are many potential threats that are targeted at storage networks,
including data modification, destruction and theft, DoS attacks, malware,
hardware theft and unauthorized access, among others. In order for a Storage
Area Network (SAN) to be secure, each of these threats must be individually
addressed. In this paper, we present a comparative study by implementing
different security methods in IP Storage network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5432</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5432</id><created>2010-03-29</created><authors><author><keyname>Pal</keyname><forenames>Sanjay Kumar</forenames><affiliation>NSHM College of Management &amp; Technology, India</affiliation></author><author><keyname>Sarma</keyname><forenames>Samar Sen</forenames><affiliation>University of Calcutta, India</affiliation></author></authors><title>Computer Network Topology Design in Limelight of Pascal Graph Property</title><categories>cs.NI</categories><comments>6 Pages, IJNGN Journal</comments><journal-ref>International Journal of Next-Generation Networks 2.1 (2010) 30-35</journal-ref><doi>10.5121/ijngn.2010.2103</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Constantly growing demands of high productivity and security of computer
systems and computer networks call the interest of specialists in the
environment of construction of optimum topologies of computer mediums. In
earliest phases of design, the study of the topological influence of the
processes that happen in computer systems and computer networks allows to
obtain useful information which possesses a significant value in the subsequent
design. It has always been tried to represent the different computer network
topologies using appropriate graph models. Graphs have huge contributions
towards the performance improvement factor of a network. Some major
contributors are de-Bruijn, Hypercube, Mesh and Pascal. They had been studied a
lot and different new features were always a part of research outcome. As per
the definition of interconnection network it is equivalent that a suitable
graph can represent the physical and logical layout very efficiently. In this
present study Pascal graph is researched again and a new characteristics has
been discovered. From the perspective of network topologies Pascal graph and
its properties were first studied more than two decades back. Since then, a
numerous graph models have emerged with potentials to be used as network
topologies. This new property is guaranteed to make an everlasting mark towards
the reliability of this graph to be used as a substantial contributor as a
computer network topology. This shows its credentials over so many other
topologies. This study reviews the characteristics of the Pascal graph and the
new property is established using appropriate algorithm and the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5435</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5435</id><created>2010-03-29</created><authors><author><keyname>Swamy</keyname><forenames>Kilari Veera</forenames><affiliation>QISCET, Ongole, India</affiliation></author><author><keyname>Mohan</keyname><forenames>B. Chandra</forenames><affiliation>BEC, Bapatla, India</affiliation></author><author><keyname>Reddy</keyname><forenames>Y. V. Bhaskar</forenames><affiliation>QISCET, Ongole, India and</affiliation></author><author><keyname>Kumar</keyname><forenames>S. Srinivas</forenames><affiliation>JNTU, Kakinada, India</affiliation></author></authors><title>Image Compression and Watermarking scheme using Scalar Quantization</title><categories>cs.CV cs.MM</categories><comments>11 Pages, IJNGN Journal 2010</comments><journal-ref>International Journal of Next-Generation Networks 2.1 (2010) 37-47</journal-ref><doi>10.5121/ijngn.2010.2104</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents a new compression technique and image watermarking
algorithm based on Contourlet Transform (CT). For image compression, an energy
based quantization is used. Scalar quantization is explored for image
watermarking. Double filter bank structure is used in CT. The Laplacian Pyramid
(LP) is used to capture the point discontinuities, and then followed by a
Directional Filter Bank (DFB) to link point discontinuities. The coefficients
of down sampled low pass version of LP decomposed image are re-ordered in a
pre-determined manner and prediction algorithm is used to reduce entropy
(bits/pixel). In addition, the coefficients of CT are quantized based on the
energy in the particular band. The superiority of proposed algorithm to JPEG is
observed in terms of reduced blocking artifacts. The results are also compared
with wavelet transform (WT). Superiority of CT to WT is observed when the image
contains more contours. The watermark image is embedded in the low pass image
of contourlet decomposition. The watermark can be extracted with minimum error.
In terms of PSNR, the visual quality of the watermarked image is exceptional.
The proposed algorithm is robust to many image attacks and suitable for
copyright protection applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5437</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5437</id><created>2010-03-29</created><authors><author><keyname>Prasanth</keyname><forenames>K.</forenames><affiliation>K.S.Rangasamy College of Technology, India</affiliation></author><author><keyname>Duraiswamy</keyname><forenames>Dr. K.</forenames><affiliation>K.S.Rangasamy College of Technology, India</affiliation></author><author><keyname>Jayasudha</keyname><forenames>K.</forenames><affiliation>K.S.R College of Engineering, India</affiliation></author><author><keyname>Chandrasekar</keyname><forenames>Dr. C.</forenames><affiliation>Periyar University, India</affiliation></author></authors><title>Improved Packet Forwarding Approach in Vehicular Ad Hoc Networks Using
  RDGR Algorithm</title><categories>cs.NI</categories><comments>14 Pages, IJNGN Journal</comments><journal-ref>International Journal of Next-Generation Networks 2.1 (2010) 64-77</journal-ref><doi>10.5121/ijngn.2010.2106</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  VANETs (Vehicular Ad hoc Networks) are highly mobile wireless ad hoc networks
and will play an important role in public safety communications and commercial
applications. Routing of data in VANETs is a challenging task due to rapidly
changing topology and high speed mobility of vehicles. Position based routing
protocols are becoming popular due to advancement and availability of GPS
devices. One of the critical issues of VANETs are frequent path disruptions
caused by high speed mobility of vehicle that leads to broken links which
results in low throughput and high overhead . This paper argues the use of
information on vehicles' movement information (e.g., position, direction, speed
of vehicles) to predict a possible link-breakage event prior to its occurrence.
So in this paper we propose a Reliable Directional Greedy routing (RDGR), a
reliable position based routing approach which obtains position, speed and
direction of its neighboring nodes from GPS. This approach incorporates
potential score based strategy, which calculates link stability between
neighbor nodes in distributed fashion for reliable forwarding of data packet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5438</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5438</id><created>2010-03-29</created><authors><author><keyname>Ouyang</keyname><forenames>Ye</forenames></author><author><keyname>Fallah</keyname><forenames>M. Hosein</forenames></author></authors><title>A Performance Analysis for UMTS Packet Switched Network Based on
  Multivariate KPIS</title><categories>cs.NI</categories><comments>15 Pages, IJNGN Journal</comments><journal-ref>International Journal of Next-Generation Networks 2.1 (2010) 79-92</journal-ref><doi>10.5121/ijngn.2010.2107</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Mobile data services are penetrating mobile markets rapidly. The mobile
industry relies heavily on data service to replace the traditional voice
services with the evolution of the wireless technology and market. A reliable
packet service network is critical to the mobile operators to maintain their
core competence in data service market. Furthermore, mobile operators need to
develop effective operational models to manage the varying mix of voice, data
and video traffic on a single network. Application of statistical models could
prove to be an effective approach. This paper first introduces the architecture
of Universal Mobile Telecommunications System (UMTS) packet switched (PS)
network and then applies multivariate statistical analysis to Key Performance
Indicators (KPI) monitored from network entities in UMTS PS network to guide
the long term capacity planning for the network. The approach proposed in this
paper could be helpful to mobile operators in operating and maintaining their
3G packet switched networks for the long run.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5439</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5439</id><created>2010-03-29</created><authors><author><keyname>Baruah</keyname><forenames>Ratul Kr.</forenames><affiliation>Tezpur University, India</affiliation></author></authors><title>Design of A Low Power Low Voltage CMOS Opamp</title><categories>cs.OH</categories><comments>8 Pages, VLSICS Journal</comments><journal-ref>International Journal Of VLSI Design &amp; Communication Systems 1.1
  (2010) 1-8</journal-ref><doi>10.5121/vlsic.2010.1101</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper a CMOS operational amplifier is presented which operates at 2V
power supply and 1microA input bias current at 0.8 micron technology using non
conventional mode of operation of MOS transistors and whose input is depended
on bias current. The unique behaviour of the MOS transistors in subthreshold
region not only allows a designer to work at low input bias current but also at
low voltage. While operating the device at weak inversion results low power
dissipation but dynamic range is degraded. Optimum balance between power
dissipation and dynamic range results when the MOS transistors are operated at
moderate inversion. Power is again minimised by the application of input
dependant bias current using feedback loops in the input transistors of the
differential pair with two current substractors. In comparison with the
reported low power low voltage opamps at 0.8 micron technology, this opamp has
very low standby power consumption with a high driving capability and operates
at low voltage. The opamp is fairly small (0.0084 mm 2) and slew rate is more
than other low power low voltage opamps reported at 0.8 um technology [1,2].
Vittoz at al [3] reported that slew rate can be improved by adaptive biasing
technique and power dissipation can be reduced by operating the device in weak
inversion. Though lower power dissipation is achieved the area required by the
circuit is very large and speed is too small. So, operating the device in
moderate inversion is a good solution. Also operating the device in
subthreshold region not only allows lower power dissipation but also a lower
voltage operation is achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5440</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5440</id><created>2010-03-29</created><authors><author><keyname>Ayyappan</keyname><forenames>K.</forenames><affiliation>Rajiv Gandhi College of Engineering and Technology, India</affiliation></author><author><keyname>Kumar</keyname><forenames>R.</forenames><affiliation>SRM University, India</affiliation></author></authors><title>QoS Based Capacity Enhancement for WCDMA Network with Coding Scheme</title><categories>cs.NI</categories><comments>10 Pages, VLSICS Journal</comments><journal-ref>International Journal Of VLSI Design &amp; Communication Systems 1.1
  (2010) 10-19</journal-ref><doi>10.5121/vlsic.2010.1102</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The wide-band code division multiple access (WCDMA) based 3G and beyond
cellular mobile wireless networks are expected to provide a diverse range of
multimedia services to mobile users with guaranteed quality of service (QoS).
To serve diverse quality of service requirements of these networks it
necessitates new radio resource management strategies for effective utilization
of network resources with coding schemes. Call admission control (CAC) is a
significant component in wireless networks to guarantee quality of service
requirements and also to enhance the network resilience. In this paper capacity
enhancement for WCDMA network with convolutional coding scheme is discussed and
compared with block code and without coding scheme to achieve a better balance
between resource utilization and quality of service provisioning. The model of
this network is valid for the real-time (RT) and non-real-time (NRT) services
having different data rate. Simulation results demonstrate the effectiveness of
the network using convolutional code in terms of capacity enhancement and QoS
of the voice and video services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5442</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5442</id><created>2010-03-29</created><authors><author><keyname>Patel</keyname><forenames>Vasundara</forenames><affiliation>Vishweshwaraiah Technological University, India</affiliation></author><author><keyname>Gurumurthy</keyname><forenames>K. S.</forenames><affiliation>UVCE, Bangalore, India</affiliation></author></authors><title>Arithmetic Operations in Multi-Valued Logic</title><categories>cs.OH</categories><comments>12 Pages, VLSICS Journal 2010</comments><journal-ref>International Journal Of VLSI Design &amp; Communication Systems 1.1
  (2010) 21-32</journal-ref><doi>10.5121/vlsic.2010.1103</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents arithmetic operations like addition, subtraction and
multiplications in Modulo-4 arithmetic, and also addition, multiplication in
Galois field, using multi-valued logic (MVL). Quaternary to binary and binary
to quaternary converters are designed using down literal circuits. Negation in
modular arithmetic is designed with only one gate. Logic design of each
operation is achieved by reducing the terms using Karnaugh diagrams, keeping
minimum number of gates and depth of net in to consideration. Quaternary
multiplier circuit is proposed to achieve required optimization. Simulation
result of each operation is shown separately using Hspice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5447</identifier>
 <datestamp>2010-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5447</id><created>2010-03-29</created><updated>2010-05-14</updated><authors><author><keyname>Gacek</keyname><forenames>Andrew</forenames></author></authors><title>Relating Nominal and Higher-order Abstract Syntax Specifications</title><categories>cs.LO</categories><comments>To appear in PPDP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nominal abstract syntax and higher-order abstract syntax provide a means for
describing binding structure which is higher-level than traditional techniques.
These approaches have spawned two different communities which have developed
along similar lines but with subtle differences that make them difficult to
relate. The nominal abstract syntax community has devices like names,
freshness, name-abstractions with variable capture, and the new-quantifier,
whereas the higher-order abstract syntax community has devices like
lambda-binders, lambda-conversion, raising, and the nabla-quantifier. This
paper aims to unify these communities and provide a concrete correspondence
between their different devices. In particular, we develop a
semantics-preserving translation from alpha-Prolog, a nominal abstract syntax
based logic programming language, to G-, a higher-order abstract syntax based
logic programming language. We also discuss higher-order judgments, a common
and powerful tool for specifications with higher-order abstract syntax, and we
show how these can be incorporated into G-. This establishes G- as a language
with the power of higher-order abstract syntax, the fine-grained variable
control of nominal specifications, and the desirable properties of higher-order
judgments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5455</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5455</id><created>2010-03-29</created><authors><author><keyname>Chepelianskii</keyname><forenames>A. D.</forenames></author></authors><title>Towards physical laws for software architecture</title><categories>cs.SE cs.IR physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Starting from the pioneering works on software architecture precious
guidelines have emerged to indicate how computer programs should be organized.
For example the &quot;separation of concerns&quot; suggests to split a program into
modules that overlap in functionality as little as possible. However these
recommendations are mainly conceptual and are thus hard to express in a
quantitative form. Hence software architecture relies on the individual
experience and skill of the designers rather than on quantitative laws. In this
article I apply the methods developed for the classification of information on
the World-Wide-Web to study the organization of Open Source programs in an
attempt to establish the statistical laws governing software architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5458</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5458</id><created>2010-03-29</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>Seidel complementation on ($P_5$, $House$, $Bull$)-free graphs</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Seidel complementation on ($P_5, \bar{P_5}, Bull)$-free
graphs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5459</identifier>
 <datestamp>2014-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5459</id><created>2010-03-29</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Thuillier</keyname><forenames>Henri</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On a family of cubic graphs containing the flower snarks</title><categories>cs.DM</categories><proxy>ccsd</proxy><journal-ref>Discussiones Mathematicae Graph Theory 30, 2 (2010) 289-314</journal-ref><doi>10.7151/dmgt.1495</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider cubic graphs formed with $k \geq 2$ disjoint claws $C_i \sim
K_{1, 3}$ ($0 \leq i \leq k-1$) such that for every integer $i$ modulo $k$ the
three vertices of degree 1 of $\ C_i$ are joined to the three vertices of
degree 1 of $C_{i-1}$ and joined to the three vertices of degree 1 of
$C_{i+1}$. Denote by $t_i$ the vertex of degree 3 of $C_i$ and by $T$ the set
$\{t_1, t_2,..., t_{k-1}\}$. In such a way we construct three distinct graphs,
namely $FS(1,k)$, $FS(2,k)$ and $FS(3,k)$. The graph $FS(j,k)$ ($j \in \{1, 2,
3\}$) is the graph where the set of vertices $\cup_{i=0}^{i=k-1}V(C_i)
\setminus T$ induce $j$ cycles (note that the graphs $FS(2,2p+1)$, $p\geq2$,
are the flower snarks defined by Isaacs \cite{Isa75}). We determine the number
of perfect matchings of every $FS(j,k)$. A cubic graph $G$ is said to be {\em
2-factor hamiltonian} if every 2-factor of $G$ is a hamiltonian cycle. We
characterize the graphs $FS(j,k)$ that are 2-factor hamiltonian (note that
FS(1,3) is the &quot;Triplex Graph&quot; of Robertson, Seymour and Thomas \cite{RobSey}).
A {\em strong matching} $M$ in a graph $G$ is a matching $M$ such that there is
no edge of $E(G)$ connecting any two edges of $M$. A cubic graph having a
perfect matching union of two strong matchings is said to be a {\em\Jaev}. We
characterize the graphs $FS(j,k)$ that are \Jaesv.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5461</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5461</id><created>2010-03-29</created><authors><author><keyname>Vera</keyname><forenames>Antonio Ignacio</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A Note on Integer Factorization Using Lattices</title><categories>cs.DS cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit Schnorr's lattice-based integer factorization algorithm, now with
an effective point of view. We present effective versions of Theorem 2 of
Schnorr's &quot;Factoring integers and computing discrete logarithms via diophantine
approximation&quot; paper, as well as new elementary properties of the Prime Number
Lattice bases of Schnorr and Adleman.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5474</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5474</id><created>2010-03-29</created><updated>2010-04-16</updated><authors><author><keyname>Zvedeniouk</keyname><forenames>Ilia</forenames></author><author><keyname>Chawla</keyname><forenames>Sanjay</forenames></author></authors><title>Angle Tree: Nearest Neighbor Search in High Dimensions with Low
  Intrinsic Dimensionality</title><categories>cs.DS</categories><comments>To be submitted to IEEE Transactions on Pattern Analysis and Machine
  Intelligence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an extension of tree-based space-partitioning indexing structures
for data with low intrinsic dimensionality embedded in a high dimensional
space. We call this extension an Angle Tree. Our extension can be applied to
both classical kd-trees as well as the more recent rp-trees. The key idea of
our approach is to store the angle (the &quot;dihedral angle&quot;) between the data
region (which is a low dimensional manifold) and the random hyperplane that
splits the region (the &quot;splitter&quot;). We show that the dihedral angle can be used
to obtain a tight lower bound on the distance between the query point and any
point on the opposite side of the splitter. This in turn can be used to
efficiently prune the search space. We introduce a novel randomized strategy to
efficiently calculate the dihedral angle with a high degree of accuracy.
Experiments and analysis on real and synthetic data sets shows that the Angle
Tree is the most efficient known indexing structure for nearest neighbor
queries in terms of preprocessing and space usage while achieving high accuracy
and fast search time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5480</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5480</id><created>2010-03-29</created><updated>2010-07-31</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Tamuz</keyname><forenames>Omer</forenames></author></authors><title>Truthful Fair Division</title><categories>cs.GT</categories><comments>10 pages</comments><journal-ref>Algorithmic Game Theory, volume 6386 of Lecture Notes in Computer
  Science, pages 288-299. Springer Berlin / Heidelberg, 2010 (SAGT 2010)</journal-ref><doi>10.1007/978-3-642-16170-4_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of fair division, or cake cutting, with the goal of
finding truthful mechanisms. In the case of a general measure space (&quot;cake&quot;)
and non-atomic, additive individual preference measures - or utilities - we
show that there exists a truthful &quot;mechanism&quot; which ensures that each of the k
players gets at least 1/k of the cake. This mechanism also minimizes risk for
truthful players. Furthermore, in the case where there exist at least two
different measures we present a different truthful mechanism which ensures that
each of the players gets more than 1/k of the cake.
  We then turn our attention to partitions of indivisible goods with bounded
utilities and a large number of goods. Here we provide similar mechanisms, but
with slightly weaker guarantees. These guarantees converge to those obtained in
the non-atomic case as the number of goods goes to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5509</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5509</id><created>2010-03-29</created><authors><author><keyname>Dey</keyname><forenames>Sandipan</forenames></author><author><keyname>Abraham</keyname><forenames>Ajith</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>An LSB Data Hiding Technique Using Prime Numbers</title><categories>cs.CR</categories><comments>6 Pages, 7 Figures, Third International Symposium on Information
  Assurance and Security, August 29-31, 2007, Manchester, United Kingdom, IEEE
  Computer Society press, USA, ISBN 0-7695-2876-7, pp. 101-106, 2007.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel data hiding technique is proposed, as an improvement
over the Fibonacci LSB data-hiding technique proposed by Battisti et al. First
we mathematically model and generalize our approach. Then we propose our novel
technique, based on decomposition of a number (pixel-value) in sum of prime
numbers. The particular representation generates a different set of (virtual)
bit-planes altogether, suitable for embedding purposes. They not only allow one
to embed secret message in higher bit-planes but also do it without much
distortion, with a much better stego-image quality, and in a reliable and
secured manner, guaranteeing efficient retrieval of secret message. A
comparative performance study between the classical Least Significant Bit
(LSB)method, the Fibonacci LSB data-hiding technique and our proposed schemes
has been done. Analysis indicates that image quality of the stego-image hidden
by the technique using Fibonacci decomposition improves against that using
simple LSB substitution method, while the same using the prime decomposition
method improves drastically against that using Fibonacci decomposition
technique. Experimental results show that, the stego-image is visually
indistinguishable from the original cover-image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5510</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5510</id><created>2010-03-29</created><updated>2011-10-18</updated><authors><author><keyname>Castelluccia</keyname><forenames>Claude</forenames></author><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Francillon</keyname><forenames>Aurelien</forenames></author><author><keyname>Kaafar</keyname><forenames>Mohamed-Ali</forenames></author></authors><title>EphPub: Toward Robust Ephemeral Publishing</title><categories>cs.CR cs.NI</categories><comments>Proceedings of IEEE ICNP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing amount of personal and sensitive information disseminated over
the Internet prompts commensurately growing privacy concerns. Digital data
often lingers indefinitely and users lose its control. This motivates the
desire to restrict content availability to an expiration time set by the data
owner. This paper presents and formalizes the notion of Ephemeral Publishing
(EphPub), to prevent the access to expired content. We propose an efficient and
robust protocol that builds on the Domain Name System (DNS) and its caching
mechanism. With EphPub, sensitive content is published encrypted and the key
material is distributed, in a steganographic manner, to randomly selected and
independent resolvers. The availability of content is then limited by the
evanescence of DNS cache entries. The EphPub protocol is transparent to
existing applications, and does not rely on trusted hardware, centralized
servers, or user proactive actions. We analyze its robustness and show that it
incurs a negligible overhead on the DNS infrastructure. We also perform a
large-scale study of the caching behavior of 900K open DNS resolvers. Finally,
we propose Firefox and Thunderbird extensions that provide ephemeral publishing
capabilities, as well as a command-line tool to create ephemeral files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5511</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5511</id><created>2010-03-29</created><authors><author><keyname>Gaboardi</keyname><forenames>Marco</forenames></author><author><keyname>Piccolo</keyname><forenames>Mauro</forenames></author></authors><title>Categorical Models for a Semantically Linear Lambda-calculus</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 22, 2010, pp. 1-13</journal-ref><doi>10.4204/EPTCS.22.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about a categorical approach to model a very simple
Semantically Linear lambda calculus, named Sll-calculus. This is a core
calculus underlying the programming language SlPCF. In particular, in this
work, we introduce the notion of Sll-Category, which is able to describe a very
large class of sound models of Sll-calculus. Sll-Category extends in the
natural way Benton, Bierman, Hyland and de Paiva's Linear Category, in order to
soundly interpret all the constructs of Sll-calculus. This category is general
enough to catch interesting models in Scott Domains and Coherence Spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5512</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5512</id><created>2010-03-29</created><authors><author><keyname>Torrini</keyname><forenames>Paolo</forenames></author><author><keyname>Heckel</keyname><forenames>Reiko</forenames></author></authors><title>Resource-Bound Quantification for Graph Transformation</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 22, 2010, pp. 14-25</journal-ref><doi>10.4204/EPTCS.22.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph transformation has been used to model concurrent systems in software
engineering, as well as in biochemistry and life sciences. The application of a
transformation rule can be characterised algebraically as construction of a
double-pushout (DPO) diagram in the category of graphs. We show how
intuitionistic linear logic can be extended with resource-bound quantification,
allowing for an implicit handling of the DPO conditions, and how resource logic
can be used to reason about graph transformation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5513</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5513</id><created>2010-03-29</created><authors><author><keyname>de Vries</keyname><forenames>Edsko</forenames></author><author><keyname>Francalanza</keyname><forenames>Adrian</forenames></author><author><keyname>Hennessy</keyname><forenames>Matthew</forenames></author></authors><title>Uniqueness Typing for Resource Management in Message-Passing Concurrency</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 22, 2010, pp. 26-37</journal-ref><doi>10.4204/EPTCS.22.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We view channels as the main form of resources in a message-passing
programming paradigm. These channels need to be carefully managed in settings
where resources are scarce. To study this problem, we extend the pi-calculus
with primitives for channel allocation and deallocation and allow channels to
be reused to communicate values of different types. Inevitably, the added
expressiveness increases the possibilities for runtime errors. We define a
substructural type system which combines uniqueness typing and affine typing to
reject these ill-behaved programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5515</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5515</id><created>2010-03-29</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames></author><author><keyname>Siafakas</keyname><forenames>Nikolaos</forenames></author></authors><title>Labelled Lambda-calculi with Explicit Copy and Erase</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 22, 2010, pp. 49-64</journal-ref><doi>10.4204/EPTCS.22.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two rewriting systems that define labelled explicit substitution
lambda-calculi. Our work is motivated by the close correspondence between
Levy's labelled lambda-calculus and paths in proof-nets, which played an
important role in the understanding of the Geometry of Interaction. The
structure of the labels in Levy's labelled lambda-calculus relates to the
multiplicative information of paths; the novelty of our work is that we design
labelled explicit substitution calculi that also keep track of exponential
information present in call-by-value and call-by-name translations of the
lambda-calculus into linear logic proof-nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5517</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5517</id><created>2010-03-29</created><authors><author><keyname>Duan</keyname><forenames>Lingjie</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Shou</keyname><forenames>Biying</forenames></author></authors><title>Competition with Dynamic Spectrum Leasing</title><categories>cs.NI</categories><comments>A shorter version appears in IEEE DySPAN 2010. This version has been
  submitted to IEEE/ACM Transactions on Networking.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a comprehensive analytical study of two competitive
cognitive operators' spectrum leasing and pricing strategies, taking into
account operators' heterogeneity in leasing costs and users' heterogeneity in
transmission power and channel conditions. We model the interactions between
operators and users as a three-stage dynamic game, where operators make
simultaneous spectrum leasing and pricing decisions in Stages I and II, and
users make purchase decisions in Stage III. Using backward induction, we are
able to completely characterize the game's equilibria. We show that both
operators make the equilibrium leasing and pricing decisions based on simple
threshold policies. Moreover, two operators always choose the same equilibrium
price despite their difference in leasing costs. Each user receives the same
signal-to-noise-ratio (SNR) at the equilibrium, and the obtained payoff is
linear in its transmission power and channel gain. We also compare the duopoly
equilibrium with the coordinated case where two operators cooperate to maximize
their total profit. We show that the maximum loss of total profit due to
operators' competition is no larger than 25%. The users, however, always
benefit from operators' competition in terms of their payoffs. We show that
most of these insights are robust in the general SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5518</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5518</id><created>2010-03-29</created><authors><author><keyname>Bucciarelli</keyname><forenames>A.</forenames></author><author><keyname>Carraro</keyname><forenames>A.</forenames></author><author><keyname>Ehrhard</keyname><forenames>T.</forenames></author><author><keyname>Salibra</keyname><forenames>A.</forenames></author></authors><title>On Linear Information Systems</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 22, 2010, pp. 38-48</journal-ref><doi>10.4204/EPTCS.22.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scott's information systems provide a categorically equivalent, intensional
description of Scott domains and continuous functions. Following a well
established pattern in denotational semantics, we define a linear version of
information systems, providing a model of intuitionistic linear logic (a
new-Seely category), with a &quot;set-theoretic&quot; interpretation of exponentials that
recovers Scott continuous functions via the co-Kleisli construction. From a
domain theoretic point of view, linear information systems are equivalent to
prime algebraic Scott domains, which in turn generalize prime algebraic
lattices, already known to provide a model of classical linear logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5525</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5525</id><created>2010-03-29</created><authors><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Searching publications on operating systems</title><categories>cs.OS</categories><comments>8 pages</comments><acm-class>D.4.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note concerns a search for publications in which one can find statements
that explain the concept of an operating system, reasons for introducing
operating systems, a formalization of the concept of an operating system or
theory about operating systems based on such a formalization. It reports on the
way in which the search has been carried out and the outcome of the search. The
outcome includes not only what the search was meant for, but also some added
bonuses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5619</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5619</id><created>2010-03-29</created><authors><author><keyname>Almuhaideb</keyname><forenames>Abdullah M.</forenames></author><author><keyname>Alhabeeb</keyname><forenames>Mohammed A.</forenames></author><author><keyname>Le</keyname><forenames>Phu D.</forenames></author><author><keyname>Srinivasan</keyname><forenames>Bala</forenames></author></authors><title>Flexible Authentication Technique for Ubiquitous Wireless Communication
  using Passport and Visa Tokens</title><categories>cs.NI</categories><journal-ref>Journal of Telecommunications, Volume 1, Issue 2, pp1-10, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of mobile devices (CPU, memory, and storage) and the
introduction of mobile networks (Ad-Hoc, Wi-Fi, WiMAX, and 3.5G) have opened
new opportunities for next generation of mobile services. It becomes more
convenience and desirable for mobile internet users to be connected everywhere.
However, ubiquitous mobile access connectivity faces interoperation issues
between wireless network providers and wireless network technologies. Although
mobile users would like to get as many services as possible while they travel,
there is a lack of technology to identify visited users in current foreign
network authentication systems. This challenge lies in the fact that a foreign
network provider does not initially have the authentication credentials of a
mobile user. Existing approaches use roaming agreement to exchange
authentication information between home network and foreign network. This paper
proposes a roaming agreement-less approach designed based on our ubiquitous
mobile access model. Our approach consist of two tokens, Passport
(identification token) and Visa (authorisation token) to provide the mobile
user with a flexible authentication method to access foreign network services.
The security analysis indicates that our proposal is more suitable for
ubiquitous mobile communication especially in roaming agreement-less
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5623</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5623</id><created>2010-03-29</created><authors><author><keyname>Kumar</keyname><forenames>Pawan</forenames></author><author><keyname>Biswas</keyname><forenames>Astik</forenames></author><author><keyname>Mishra</keyname><forenames>A . N.</forenames></author><author><keyname>Chandra</keyname><forenames>Mahesh</forenames></author></authors><title>Spoken Language Identification Using Hybrid Feature Extraction Methods</title><categories>cs.SD cs.LG</categories><journal-ref>Journal of Telecommunications, Volume 1, Issue 2, pp11-15, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces and motivates the use of hybrid robust feature
extraction technique for spoken language identification (LID) system. The
speech recognizers use a parametric form of a signal to get the most important
distinguishable features of speech signal for recognition task. In this paper
Mel-frequency cepstral coefficients (MFCC), Perceptual linear prediction
coefficients (PLP) along with two hybrid features are used for language
Identification. Two hybrid features, Bark Frequency Cepstral Coefficients
(BFCC) and Revised Perceptual Linear Prediction Coefficients (RPLP) were
obtained from combination of MFCC and PLP. Two different classifiers, Vector
Quantization (VQ) with Dynamic Time Warping (DTW) and Gaussian Mixture Model
(GMM) were used for classification. The experiment shows better identification
rate using hybrid feature extraction techniques compared to conventional
feature extraction methods.BFCC has shown better performance than MFCC with
both classifiers. RPLP along with GMM has shown best identification performance
among all feature extraction techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5627</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5627</id><created>2010-03-29</created><authors><author><keyname>Abdalla</keyname><forenames>Mahmoud I.</forenames></author><author><keyname>Ali</keyname><forenames>Hanaa S.</forenames></author></authors><title>Wavelet-Based Mel-Frequency Cepstral Coefficients for Speaker
  Identification using Hidden Markov Models</title><categories>cs.SD cs.LG</categories><journal-ref>Journal of Telecommunications, Volume 1, Issue 2, pp16-21, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To improve the performance of speaker identification systems, an effective
and robust method is proposed to extract speech features, capable of operating
in noisy environment. Based on the time-frequency multi-resolution property of
wavelet transform, the input speech signal is decomposed into various frequency
channels. For capturing the characteristic of the signal, the Mel-Frequency
Cepstral Coefficients (MFCCs) of the wavelet channels are calculated. Hidden
Markov Models (HMMs) were used for the recognition stage as they give better
recognition for the speaker's features than Dynamic Time Warping (DTW).
Comparison of the proposed approach with the MFCCs conventional feature
extraction method shows that the proposed method not only effectively reduces
the influence of noise, but also improves recognition. A recognition rate of
99.3% was obtained using the proposed feature extraction technique compared to
98.7% using the MFCCs. When the test patterns were corrupted by additive white
Gaussian noise with 20 dB S/N ratio, the recognition rate was 97.3% using the
proposed method compared to 93.3% using the MFCCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5629</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5629</id><created>2010-03-29</created><authors><author><keyname>Masud</keyname><forenames>M. A.</forenames></author><author><keyname>Samsuzzaman</keyname><forenames>M.</forenames></author><author><keyname>Rahman</keyname><forenames>M. A.</forenames></author></authors><title>Bit Error Rate Performance Analysis on Modulation Techniques of Wideband
  Code Division Multiple Access</title><categories>cs.OH</categories><journal-ref>Journal of Telecommunications,Volume 1, Issue 2, pp22-29, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the beginning of 21st century there has been a dramatic shift in the
market dynamics of telecommunication services. The transmission from base
station to mobile or downlink transmission using M-ary Quadrature Amplitude
modulation (QAM) and Quadrature phase shift keying (QPSK) modulation schemes
are considered in Wideband-Code Division Multiple Access (W-CDMA) system. We
have done the performance analysis of these modulation techniques when the
system is subjected to Additive White Gaussian Noise (AWGN) and multipath
Rayleigh fading are considered in the channel. The research has been performed
by using MATLAB 7.6 for simulation and evaluation of Bit Error Rate (BER) and
Signal-To-Noise Ratio (SNR) for W-CDMA system models. It is shows that the
analysis of Quadrature phases shift key and 16-ary Quadrature Amplitude
modulations which are being used in wideband code division multiple access
system, Therefore, the system could go for more suitable modulation technique
to suit the channel quality, thus we can deliver the optimum and efficient data
rate to mobile terminal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5631</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5631</id><created>2010-03-29</created><authors><author><keyname>Majumder</keyname><forenames>Moumita</forenames></author><author><keyname>Dhar</keyname><forenames>Sumit</forenames></author></authors><title>A Mobile Message Scheduling and Delivery System using m-Learning
  framework</title><categories>cs.OH</categories><journal-ref>Journal of Telecommunications,Volume 1, Issue 2, pp30-34, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless data communications in form of Short Message Service (SMS) and
Wireless Access Protocols (WAP) browsers have gained global popularity, yet,
not much has been done to extend the usage of these devices in electronic
learning (e-learning) and information sharing. This project explores the
extension of e learning into wireless/ handheld (W/H) computing devices with
the help of a mobile learning (m-learning) framework. This framework provides
the requirements to develop m-learning application that can be used to share
academic and administrative information among people within the university
campus. A prototype application has been developed to demonstrate the important
functionality of the proposed system in simulated environment. This system is
supposed to work both in bulk SMS and interactive SMS delivery mode. Here we
have combined both Short Message Service (SMS) and Wireless Access Protocols
(WAP) browsers. SMS is used for Short and in time information delivery and WAP
is used for detailed information delivery like course content, training
material, interactive evolution tests etc. The push model is used for sending
personalized multicasting messages to a group of mobile users with a common
profile thereby improving the effectiveness and usefulness of the cntent
delivered. Again pull mechanism can be applied for sending information as SMS
when requested by end user in interactive SMS delivery mode. The main strength
of the system is that, the actual SMS delivery application can be hosted on a
mobile device, which can operate even when the device is on move.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5633</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5633</id><created>2010-03-29</created><authors><author><keyname>Hasan-Al-Mahmud</keyname><forenames>Tarek</forenames></author><author><keyname>Rahman</keyname><forenames>M. Mahbubur</forenames></author><author><keyname>Debnath</keyname><forenames>Sumon Kumar</forenames></author></authors><title>Performance Analysis of Best suited Adaptive Equalization Algorithm for
  Optical Communication</title><categories>cs.OH</categories><journal-ref>Journal of Telecommunications,Volume 1, Issue 2, pp35-41, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fiber optics is one of the highest bandwidth communication channel types in
the current communication industry. The paper is to analyze a typical optical
channel and perform channel equalization using an adaptive modified DFE with
Activity Detection Guidance and Tap Decoupling algorithm. Evaluation can be
made on the employment of the DFE algorithm and with enhancements, like
Fractionally-Spaced equalization and Activity Detection Guidance, to improve
its stability, steady-state error performance and convergence rate. The
successful implementation of the Adaptive FS-DFE with ADG and TD technique
offers an excellent alternative to linear equalization, which is known to be of
little benefit for optical channels because of exorbitant noise enhancement.
The FSE technique, when combined with the DFE, would offer improved
effectiveness to amplitude distortion. As the impulse response of a typical
optical link would have regions that are essentially zero, the employment of
the activity detection scheme with Tap Decoupling would further enhance the
steady-state error performance and convergence rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5635</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5635</id><created>2010-03-29</created><authors><author><keyname>Al-Zahrani</keyname><forenames>Fahad</forenames></author></authors><title>Web-Based Learning and Training for Virtual Metrology Lab</title><categories>cs.OH</categories><journal-ref>Journal of Telecommunications,Volume 1, Issue 2, pp42-54, March
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of World Web Wide for distance education has received increasing
attention over the past decades. The real challenge of adapting this technology
for engineering education and training is to facilitate the laboratory
experiments via Internet. In the sciences, measurement plays an important role.
The accuracy of the measurement, as well as the units, help scientists to
better understand phenomena occurring in nature. This paper introduces
Metrology educators to the use and adoption of Java-applets in order to create
virtual, online Metrology laboratories for students. These techniques have been
used to successfully form a laboratory course which augments the more
conventional lectures in concepts of Metrology course at Faculty of
Engineering, Albaha University, KSA. Improvements of the package are still
undergoing to incorporate Web-based technologies (Internet home page, HTML,
Java programming etc...). This Web-based education and training has been
successfully class-tested within an undergraduate preliminary year engineering
course and students reported a positive experience with its use. The use of
these labs should be self-explanatory and their reliable operation has been
thoroughly tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5648</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5648</id><created>2010-03-29</created><updated>2010-03-29</updated><authors><author><keyname>Alhussien</keyname><forenames>Hakim</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>The Error-Pattern-Correcting Turbo Equalizer</title><categories>cs.IT math.IT</categories><comments>This work has been submitted to the special issue of the IEEE
  Transactions on Information Theory titled: &quot;Facets of Coding Theory: from
  Algorithms to Networks&quot;. This work was supported in part by the NSF
  Theoretical Foundation Grant 0728676.</comments><journal-ref>Alhussien, H.; Moon, J.; , &quot;The Error-Pattern-Correcting Turbo
  Equalizer: Spectrum Thinning at High SNRs,&quot; Information Theory, IEEE
  Transactions on , vol.57, no.2, pp.953-971, Feb. 2011</journal-ref><doi>10.1109/TIT.2010.2096031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The error-pattern correcting code (EPCC) is incorporated in the design of a
turbo equalizer (TE) with aim to correct dominant error events of the
inter-symbol interference (ISI) channel at the output of its matching Viterbi
detector. By targeting the low Hamming-weight interleaved errors of the outer
convolutional code, which are responsible for low Euclidean-weight errors in
the Viterbi trellis, the turbo equalizer with an error-pattern correcting code
(TE-EPCC) exhibits a much lower bit-error rate (BER) floor compared to the
conventional non-precoded TE, especially for high rate applications. A
maximum-likelihood upper bound is developed on the BER floor of the TE-EPCC for
a generalized two-tap ISI channel, in order to study TE-EPCC's signal-to-noise
ratio (SNR) gain for various channel conditions and design parameters. In
addition, the SNR gain of the TE-EPCC relative to an existing precoded TE is
compared to demonstrate the present TE's superiority for short interleaver
lengths and high coding rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5693</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5693</id><created>2010-03-29</created><authors><author><keyname>Alhussien</keyname><forenames>Hakim</forenames></author><author><keyname>Moon</keyname><forenames>Jaekyun</forenames></author></authors><title>An Iteratively Decodable Tensor Product Code with Application to Data
  Storage</title><categories>cs.IT math.IT</categories><comments>Hakim Alhussien, Jaekyun Moon, &quot;An Iteratively Decodable Tensor
  Product Code with Application to Data Storage&quot;</comments><journal-ref>IEEE Journal on Selected Areas in Communications, vol.28, no.2,
  pp.228-240, February 2010.</journal-ref><doi>10.1109/JSAC.2010.100212</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The error pattern correcting code (EPCC) can be constructed to provide a
syndrome decoding table targeting the dominant error events of an inter-symbol
interference channel at the output of the Viterbi detector. For the size of the
syndrome table to be manageable and the list of possible error events to be
reasonable in size, the codeword length of EPCC needs to be short enough.
However, the rate of such a short length code will be too low for hard drive
applications. To accommodate the required large redundancy, it is possible to
record only a highly compressed function of the parity bits of EPCC's tensor
product with a symbol correcting code. In this paper, we show that the proposed
tensor error-pattern correcting code (T-EPCC) is linear time encodable and also
devise a low-complexity soft iterative decoding algorithm for EPCC's tensor
product with q-ary LDPC (T-EPCC-qLDPC). Simulation results show that
T-EPCC-qLDPC achieves almost similar performance to single-level qLDPC with a
1/2 KB sector at 50% reduction in decoding complexity. Moreover, 1 KB
T-EPCC-qLDPC surpasses the performance of 1/2 KB single-level qLDPC at the same
decoder complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5699</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5699</id><created>2010-03-29</created><authors><author><keyname>Asur</keyname><forenames>Sitaram</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Predicting the Future with Social Media</title><categories>cs.CY physics.soc-ph</categories><doi>10.1016/j.apenergy.2013.03.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, social media has become ubiquitous and important for social
networking and content sharing. And yet, the content that is generated from
these websites remains largely untapped. In this paper, we demonstrate how
social media content can be used to predict real-world outcomes. In particular,
we use the chatter from Twitter.com to forecast box-office revenues for movies.
We show that a simple model built from the rate at which tweets are created
about particular topics can outperform market-based predictors. We further
demonstrate how sentiments extracted from Twitter can be further utilized to
improve the forecasting power of social media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5716</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5716</id><created>2010-03-29</created><authors><author><keyname>Florido</keyname><forenames>M&#xe1;rio</forenames></author><author><keyname>Mackie</keyname><forenames>Ian</forenames></author></authors><title>Proceedings First International Workshop on Linearity</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 22, 2010</journal-ref><doi>10.4204/EPTCS.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of LINEARITY 2009: the first
International Workshop on Linearity, which took place 12th September 2009 in
Coimbra, Portugal. The workshop was a satellite event of CSL 2009, the 18th
EACSL Annual Conference on Computer Science Logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5746</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5746</id><created>2010-03-30</created><authors><author><keyname>Rao</keyname><forenames>Ashwin</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>BitTorrent Experiments on Testbeds: A Study of the Impact of Network
  Latencies</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>JDIR, Sophia Antipolis : France (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the impact of network latency on the time required to
download a file distributed using BitTorrent. This study is essential to
understand if testbeds can be used for experimental evaluation of BitTorrent.
We observe that the network latency has a marginal impact on the time required
to download a file; hence, BitTorrent experiments can performed on testbeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5749</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5749</id><created>2010-03-30</created><authors><author><keyname>Eshkol</keyname><forenames>Iris</forenames><affiliation>CORAL</affiliation></author><author><keyname>Tellier</keyname><forenames>Isabelle</forenames><affiliation>LIFO</affiliation></author><author><keyname>Samer</keyname><forenames>Taalab</forenames><affiliation>LIFO</affiliation></author><author><keyname>Billot</keyname><forenames>Sylvie</forenames><affiliation>LIFO</affiliation></author></authors><title>Etiqueter un corpus oral par apprentissage automatique \`a l'aide de
  connaissances linguistiques</title><categories>cs.LG cs.CL</categories><proxy>ccsd</proxy><journal-ref>10\`emes Journ\'ees Internationales d'Analyse statistique des
  Donn\'ees Textuelles JADT'2010, Rome : Italie (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Thanks to the Eslo1 (&quot;Enqu\^ete sociolinguistique d'Orl\'eans&quot;, i.e.
&quot;Sociolinguistic Inquiery of Orl\'eans&quot;) campain, a large oral corpus has been
gathered and transcribed in a textual format. The purpose of the work presented
here is to associate a morpho-syntactic label to each unit of this corpus. To
this aim, we have first studied the specificities of the necessary labels, and
their various possible levels of description. This study has led to a new
original hierarchical structuration of labels. Then, considering that our new
set of labels was different from the one used in every available software, and
that these softwares usually do not fit for oral data, we have built a new
labeling tool by a Machine Learning approach, from data labeled by Cordial and
corrected by hand. We have applied linear CRF (Conditional Random Fields)
trying to take the best possible advantage of the linguistic knowledge that was
used to define the set of labels. We obtain an accuracy between 85 and 90%,
depending of the parameters used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5758</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5758</id><created>2010-03-30</created><authors><author><keyname>Mackie</keyname><forenames>Ian</forenames></author><author><keyname>Moreira</keyname><forenames>Anamaria Martins</forenames></author></authors><title>Proceedings Tenth International Workshop on Rule-Based Programming</title><categories>cs.PL cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 21, 2010</journal-ref><doi>10.4204/EPTCS.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of RULE 2009: the tenth International
Workshop on Rule-Based Programming. It took place in June 28th 2009, Brasilia,
Brazil, as a satellite event of RDP 2009. The first Rule workshop was held in
Montreal in 2000, and subsequent editions took place in Firenze, Pittsburgh,
Valencia, Aachen, Nara, Seattle, Paris, and Hagenberg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5771</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5771</id><created>2010-03-30</created><updated>2011-05-12</updated><authors><author><keyname>Hsu</keyname><forenames>Fu-Te</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Analysis of a CSMA-Based Wireless Network: Feasible Throughput Region
  and Power Consumption</title><categories>cs.GT cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analytically study a carrier sense multiple access (CSMA)-based network.
In the network, the nodes have their own average throughput demands for
transmission to a common base station. The CSMA is based on the request-to-send
(RTS)/clear-to-send (CTS) handshake mechanism. Each node individually chooses
its probability of transmitting an RTS packet, which specifies the length of
its requested data transmission period. The RTS packets transmitted by
different nodes in the same time slot interfere with one another, and compete
to be received by the base station. If a node's RTS has the received signal to
interference plus noise ratio (SINR) higher than the capture ratio, it will be
successfully received. The node will then be granted the data transmission
period. The transmission probabilities of RTS packets of all nodes will
determine the average throughput and power consumption of each node. The set of
all possible throughput demands of nodes that can be supported by the network
is called the feasible throughput region. We characterize the feasible
throughput region and provide an upper bound on the total power consumption for
any throughput demands in the feasible throughput region. The upper bound
corresponds to one of three points in the feasible throughput region depending
on the fraction of time occupied by the RTS packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5775</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5775</id><created>2010-03-30</created><authors><author><keyname>Ouyang</keyname><forenames>Ye</forenames><affiliation>Stevens Institute of Technology, USA</affiliation></author><author><keyname>Fallah</keyname><forenames>M. Hosein</forenames><affiliation>Stevens Institute of Technology, USA</affiliation></author></authors><title>The impact of cell site re-homing on the performance of umts core
  networks</title><categories>cs.NI</categories><comments>14 Pages, IJNGN Journal</comments><journal-ref>International Journal of Next-Generation Networks 2.1 (2010) 49-62</journal-ref><doi>10.5121/ijngn.2010.2105</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Mobile operators currently prefer optimizing their radio networks via
re-homing or cutting over the cell sites in 2G or 3G networks. The core
network, as the parental part of radio network, is inevitably impacted by the
re-homing in radio domain. This paper introduces the cell site re-homing in
radio network and analyzes its impact on the performance of GSM/UMTS core
network. The possible re-homing models are created and analyzed for core
networks. The paper concludes that appropriate re-homing in radio domain, using
correct algorithms, not only optimizes the radio network but also helps improve
the QoS of the core network and saves the carriers' OPEX and CAPEX on their
core networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5777</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5777</id><created>2010-03-30</created><authors><author><keyname>Polikarpova</keyname><forenames>Nadia</forenames></author><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>Specifying Reusable Components</title><categories>cs.SE</categories><journal-ref>Proceedings of the 3rd International Conference on Verified
  Software: Theories, Tools, and Experiments (VSTTE'10). Lecture Notes in
  Computer Science, 6217:127--141, Springer-Verlag, August 2010</journal-ref><doi>10.1007/978-3-642-15057-9_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reusable software components need expressive specifications. This paper
outlines a rigorous foundation to model-based contracts, a method to equip
classes with strong contracts that support accurate design, implementation, and
formal verification of reusable components. Model-based contracts
conservatively extend the classic Design by Contract with a notion of model,
which underpins the precise definitions of such concepts as abstract
equivalence and specification completeness. Experiments applying model-based
contracts to libraries of data structures suggest that the method enables
accurate specification of practical software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5782</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5782</id><created>2010-03-30</created><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan</forenames></author><author><keyname>Steffen</keyname><forenames>Eckhard</forenames></author></authors><title>Bricks and conjectures of Berge, Fulkerson and Seymour</title><categories>cs.DM</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An $r$-graph is an $r$-regular graph where every odd set of vertices is
connected by at least $r$ edges to the rest of the graph. Seymour conjectured
that any $r$-graph is $r+1$-edge-colorable, and also that any $r$-graph
contains $2r$ perfect matchings such that each edge belongs to two of them. We
show that the minimum counter-example to either of these conjectures is a
brick. Furthermore we disprove a variant of a conjecture of Fan, Raspaud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5783</identifier>
 <datestamp>2011-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5783</id><created>2010-03-30</created><updated>2010-12-16</updated><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan</forenames></author><author><keyname>Steffen</keyname><forenames>Eckhard</forenames></author></authors><title>Measures of edge-uncolorability</title><categories>cs.DM</categories><comments>9 pages</comments><journal-ref>Discrete Mathematics 312/2 (2012) pp. 476--478</journal-ref><doi>10.1016/j.disc.2011.09.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The resistance $r(G)$ of a graph $G$ is the minimum number of edges that have
to be removed from $G$ to obtain a graph which is $\Delta(G)$-edge-colorable.
The paper relates the resistance to other parameters that measure how far is a
graph from being $\Delta$-edge-colorable. The first part considers regular
graphs and the relation of the resistance to structural properties in terms of
2-factors. The second part studies general (multi-) graphs $G$. Let $r_v(G)$ be
the minimum number of vertices that have to be removed from $G$ to obtain a
class 1 graph. We show that $\frac{r(G)}{r_v(G)} \leq \lfloor
\frac{\Delta(G)}{2} \rfloor$, and that this bound is best possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5787</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5787</id><created>2010-03-30</created><authors><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Sarangi</keyname><forenames>Niharjyoti</forenames></author><author><keyname>Bishi</keyname><forenames>Sukant kumar</forenames></author></authors><title>A secured Cryptographic Hashing Algorithm</title><categories>cs.CR</categories><comments>4 pages,2 figures, 1 tabular data set</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptographic hash functions for calculating the message digest of a message
has been in practical use as an effective measure to maintain message integrity
since a few decades. This message digest is unique, irreversible and avoids all
types of collisions for any given input string. The message digest calculated
from this algorithm is propagated in the communication medium along with the
original message from the sender side and on the receiver side integrity of the
message can be verified by recalculating the message digest of the received
message and comparing the two digest values. In this paper we have designed and
developed a new algorithm for calculating the message digest of any message and
implemented t using a high level programming language. An experimental analysis
and comparison with the existing MD5 hashing algorithm, which is predominantly
being used as a cryptographic hashing tool, shows this algorithm to provide
more randomness and greater strength from intrusion attacks. In this algorithm
the plaintext message string is converted into binary string and fragmented
into blocks of 128 bits after being padded with user defined padding bits. Then
using a pseudo random number generator a key is generated for each block and
operated with the respective block by a bitwise operator. This process is
terated for the whole message and finally a fixed length message digest is
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5794</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5794</id><created>2010-03-30</created><updated>2010-04-12</updated><authors><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author><author><keyname>Yuan</keyname><forenames>Lin</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author></authors><title>Scalable Group Management in Large-Scale Virtualized Clusters</title><categories>cs.DC</categories><comments>9 pages</comments><journal-ref>The Journal of High Technology Letters, January, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To save cost, recently more and more users choose to provision virtual
machine resources in cluster systems, especially in data centres. Maintaining a
consistent member view is the foundation of reliable cluster managements, and
it also raises several challenge issues for large scale cluster systems
deployed with virtual machines (which we call virtualized clusters). In this
paper, we introduce our experiences in design and implementation of scalable
member view management on large-scale virtual clusters. Our research
contributions are three-fold: 1) we propose a scalable and reliable management
infrastructure that combines a peer-to-peer structure and a hierarchy structure
to maintain a consistent member view in virtual clusters; 2) we present a
light-weighted group membership algorithm that can reach the consistent member
view within a single round of message exchange; and 3) we design and implement
a scalable membership service that can provision virtual machines and maintain
a consistent member view in virtual clusters. Our work is verified on Dawning
5000A, which ranked No.10 of Top 500 super computers in November, 2008.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5803</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5803</id><created>2010-03-30</created><authors><author><keyname>Zhou</keyname><forenames>Shi</forenames></author></authors><title>Why the Internet is so 'small'?</title><categories>cs.NI</categories><journal-ref>EuropeComm 2009, LNICST 16, pp. 4-12, 2009</journal-ref><doi>10.1007/978-3-642-11284-3_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last three decades the Internet has experienced fascinating
evolution, both exponential growth in traffic and rapid expansion in topology.
The size of the Internet becomes enormous, yet the network is very `small' in
the sense that it is extremely efficient to route data packets across the
global Internet. This paper provides a brief review on three fundamental
properties of the Internet topology at the autonomous systems (AS) level.
Firstly the Internet has a power-law degree distribution, which means the
majority of nodes on the Internet AS graph have small numbers of links, whereas
a few nodes have very large numbers of links. Secondly the Internet exhibits a
property called disassortative mixing, which means poorly-connected nodes tend
to link with well-connected nodes, and vice versa. Thirdly the best-connected
nodes, or the rich nodes, are tightly interconnected with each other forming a
rich-club. We explain that it is these structural properties that make the
global Internet so 'small'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5821</identifier>
 <datestamp>2014-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5821</id><created>2010-03-30</created><authors><author><keyname>Marazzato</keyname><forenames>Roberto</forenames></author><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>Tuning CLD Maps</title><categories>cs.CV</categories><comments>Keywords: coherence length, image analysis, 2D textures; texture
  functions; defect localisation; directional defect pattern; optimization;
  histogram</comments><journal-ref>International Journal of Software Engineering and Computing, 2011,
  Volume 3, Issue 1, Pages 17-23</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Coherence Length Diagram and the related maps have been shown to
represent a useful tool for image analysis. Setting threshold parameters is one
of the most important issues when dealing with such applications, as they
affect both the computability, which is outlined by the support map, and the
appearance of the coherence length diagram itself and of defect maps. A coupled
optimization analysis, returning a range for the basic (saturation) threshold,
and a histogram based method, yielding suitable values for a desired map
appearance, are proposed for an effective control of the analysis process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5831</identifier>
 <datestamp>2013-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5831</id><created>2010-03-27</created><updated>2013-08-07</updated><authors><author><keyname>Szudzik</keyname><forenames>Matthew P.</forenames><affiliation>Carnegie Mellon</affiliation></author></authors><title>The Computable Universe Hypothesis</title><categories>math.LO cs.CC cs.LO math-ph math.MP</categories><comments>33 pages, 0 figures; minor changes</comments><msc-class>03A10 (Primary) 03D80, 03D78 (Secondary)</msc-class><journal-ref>A Computable Universe, World Scientific, 2013, pp. 479-523</journal-ref><doi>10.1142/9789814374309_0025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When can a model of a physical system be regarded as computable? We provide
the definition of a computable physical model to answer this question. The
connection between our definition and Kreisel's notion of a mechanistic theory
is discussed, and several examples of computable physical models are given,
including models which feature discrete motion, a model which features
non-discrete continuous motion, and probabilistic models such as radioactive
decay. We show how computable physical models on effective topological spaces
can be formulated using the theory of type-two effectivity (TTE). Various
common operations on computable physical models are described, such as the
operation of coarse-graining and the formation of statistical ensembles. The
definition of a computable physical model also allows for a precise
formalization of the computable universe hypothesis--the claim that all the
laws of physics are computable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5861</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5861</id><created>2010-03-30</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Mehrotra</keyname><forenames>Hunny</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author></authors><title>Robust multi-camera view face recognition</title><categories>cs.CV</categories><comments>10 pages, 3 figures, IJCA</comments><acm-class>D.2.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents multi-appearance fusion of Principal Component Analysis
(PCA) and generalization of Linear Discriminant Analysis (LDA) for multi-camera
view offline face recognition (verification) system. The generalization of LDA
has been extended to establish correlations between the face classes in the
transformed representation and this is called canonical covariate. The proposed
system uses Gabor filter banks for characterization of facial features by
spatial frequency, spatial locality and orientation to make compensate to the
variations of face instances occurred due to illumination, pose and facial
expression changes. Convolution of Gabor filter bank to face images produces
Gabor face representations with high dimensional feature vectors. PCA and
canonical covariate are then applied on the Gabor face representations to
reduce the high dimensional feature spaces into low dimensional Gabor
eigenfaces and Gabor canonical faces. Reduced eigenface vector and canonical
face vector are fused together using weighted mean fusion rule. Finally,
support vector machines (SVM) have trained with augmented fused set of features
and perform the recognition task. The system has been evaluated with UMIST face
database consisting of multiview faces. The experimental results demonstrate
the efficiency and robustness of the proposed system for multi-view face images
with high recognition rates. Complexity analysis of the proposed system is also
presented at the end of the experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5865</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5865</id><created>2010-03-30</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author></authors><title>Offline Signature Identification by Fusion of Multiple Classifiers using
  Statistical Learning Theory</title><categories>cs.CV cs.LG</categories><comments>11 pages, 3 figures, IJSIA 2010</comments><acm-class>D.2.2; I.2.10</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper uses Support Vector Machines (SVM) to fuse multiple classifiers
for an offline signature system. From the signature images, global and local
features are extracted and the signatures are verified with the help of
Gaussian empirical rule, Euclidean and Mahalanobis distance based classifiers.
SVM is used to fuse matching scores of these matchers. Finally, recognition of
query signatures is done by comparing it with all signatures of the database.
The proposed system is tested on a signature database contains 5400 offline
signatures of 600 individuals and the results are found to be promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5874</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5874</id><created>2010-03-30</created><authors><author><keyname>Agarwal</keyname><forenames>Pankaj K.</forenames></author><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Yu</keyname><forenames>Hai</forenames></author></authors><title>Stability of epsilon-Kernels</title><categories>cs.CG</categories><comments>15 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set P of n points in |R^d, an eps-kernel K subset P approximates the
directional width of P in every direction within a relative (1-eps) factor. In
this paper we study the stability of eps-kernels under dynamic insertion and
deletion of points to P and by changing the approximation factor eps. In the
first case, we say an algorithm for dynamically maintaining a eps-kernel is
stable if at most O(1) points change in K as one point is inserted or deleted
from P. We describe an algorithm to maintain an eps-kernel of size
O(1/eps^{(d-1)/2}) in O(1/eps^{(d-1)/2} + log n) time per update. Not only does
our algorithm maintain a stable eps-kernel, its update time is faster than any
known algorithm that maintains an eps-kernel of size O(1/eps^{(d-1)/2}). Next,
we show that if there is an eps-kernel of P of size k, which may be
dramatically less than O(1/eps^{(d-1)/2}), then there is an (eps/2)-kernel of P
of size O(min {1/eps^{(d-1)/2}, k^{floor(d/2)} log^{d-2} (1/eps)}). Moreover,
there exists a point set P in |R^d and a parameter eps &gt; 0 such that if every
eps-kernel of P has size at least k, then any (eps/2)-kernel of P has size
Omega(k^{floor(d/2)}).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5884</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5884</id><created>2010-03-30</created><authors><author><keyname>Moed</keyname><forenames>Henk F.</forenames></author></authors><title>CWTS crown indicator measures citation impact of a research group's
  publication oeuvre</title><categories>cs.DL physics.soc-ph</categories><comments>Letter to the editor; reply to paper arXiv:1002.2769</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article &quot;Caveats for the journal and field normalizations in the CWTS
(`Leiden') evaluations of research performance&quot;, published by Tobias Opthof and
Loet Leydesdorff (arXiv:1002.2769) deals with a subject as important as the
application of so called field normalized indicators of citation impact in the
assessment of research performance of individual researchers and research
groups. Field normalization aims to account for differences in citation
practices across scientific-scholarly subject fields. As the primary author of
the papers presenting the &quot;Leiden&quot; indicators and of many reports and articles
reporting on the outcomes of assessments actually using these measures, I
comment on the 3 main issues addressed in the paper by Opthof and Leydesdorff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5886</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5886</id><created>2010-03-30</created><authors><author><keyname>Rakshit</keyname><forenames>Sandip</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author></authors><title>Development of a multi-user handwriting recognition system using
  Tesseract open source OCR engine</title><categories>cs.CV</categories><comments>Proc. International Conference on C3IT (2009) 240-247</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of the paper is to recognize handwritten samples of lower case
Roman script using Tesseract open source Optical Character Recognition (OCR)
engine under Apache License 2.0. Handwritten data samples containing isolated
and free-flow text were collected from different users. Tesseract is trained
with user-specific data samples of both the categories of document pages to
generate separate user-models representing a unique language-set. Each such
language-set recognizes isolated and free-flow handwritten test samples
collected from the designated user. On a three user model, the system is
trained with 1844, 1535 and 1113 isolated handwritten character samples
collected from three different users and the performance is tested on 1133,
1186 and 1204 character samples, collected form the test sets of the three
users respectively. The user specific character level accuracies were obtained
as 87.92%, 81.53% and 65.71% respectively. The overall character-level accuracy
of the system is observed as 78.39%. The system fails to segment 10.96%
characters and erroneously classifies 10.65% characters on the overall dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5891</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5891</id><created>2010-03-30</created><authors><author><keyname>Rakshit</keyname><forenames>Sandip</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author></authors><title>Recognition of Handwritten Roman Script Using Tesseract Open source OCR
  Engine</title><categories>cs.CV</categories><comments>Proc. National Conference on NAQC (2008) 141-145</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present work, we have used Tesseract 2.01 open source Optical
Character Recognition (OCR) Engine under Apache License 2.0 for recognition of
handwriting samples of lower case Roman script. Handwritten isolated and
free-flow text samples were collected from multiple users. Tesseract is trained
to recognize user-specific handwriting samples of both the categories of
document pages. On a single user model, the system is trained with 1844
isolated handwritten characters and the performance is tested on 1133
characters, taken form the test set. The overall character-level accuracy of
the system is observed as 83.5%. The system fails to segment 5.56% characters
and erroneously classifies 10.94% characters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5893</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5893</id><created>2010-03-30</created><authors><author><keyname>Rakshit</keyname><forenames>Sandip</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Ikeda</keyname><forenames>Hisashi</forenames></author></authors><title>Recognition of Handwritten Textual Annotations using Tesseract Open
  Source OCR Engine for information Just In Time (iJIT)</title><categories>cs.CV</categories><comments>Proc. Int. Conf. on Information Technology and Business Intelligence
  (2009) 117-125</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Objective of the current work is to develop an Optical Character Recognition
(OCR) engine for information Just In Time (iJIT) system that can be used for
recognition of handwritten textual annotations of lower case Roman script.
Tesseract open source OCR engine under Apache License 2.0 is used to develop
user-specific handwriting recognition models, viz., the language sets, for the
said system, where each user is identified by a unique identification tag
associated with the digital pen. To generate the language set for any user,
Tesseract is trained with labeled handwritten data samples of isolated and
free-flow texts of Roman script, collected exclusively from that user. The
designed system is tested on five different language sets with free- flow
handwritten annotations as test samples. The system could successfully segment
and subsequently recognize 87.92%, 81.53%, 92.88%, 86.75% and 90.80%
handwritten characters in the test samples of five different users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5897</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5897</id><created>2010-03-30</created><authors><author><keyname>Rakshit</keyname><forenames>Sandip</forenames></author><author><keyname>Ghosal</keyname><forenames>Debkumar</forenames></author><author><keyname>Das</keyname><forenames>Tanmoy</forenames></author><author><keyname>Dutta</keyname><forenames>Subhrajit</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author></authors><title>Development of a Multi-User Recognition Engine for Handwritten Bangla
  Basic Characters and Digits</title><categories>cs.CV</categories><comments>Proc. (CD) Int. Conf. on Information Technology and Business
  Intelligence (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of the paper is to recognize handwritten samples of basic
Bangla characters using Tesseract open source Optical Character Recognition
(OCR) engine under Apache License 2.0. Handwritten data samples containing
isolated Bangla basic characters and digits were collected from different
users. Tesseract is trained with user-specific data samples of document pages
to generate separate user-models representing a unique language-set. Each such
language-set recognizes isolated basic Bangla handwritten test samples
collected from the designated users. On a three user model, the system is
trained with 919, 928 and 648 isolated handwritten character and digit samples
and the performance is tested on 1527, 14116 and 1279 character and digit
samples, collected form the test datasets of the three users respectively. The
user specific character/digit recognition accuracies were obtained as 90.66%,
91.66% and 96.87% respectively. The overall basic character-level and digit
level accuracy of the system is observed as 92.15% and 97.37%. The system fails
to segment 12.33% characters and 15.96% digits and also erroneously classifies
7.85% characters and 2.63% on the overall dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5898</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5898</id><created>2010-03-30</created><authors><author><keyname>Rakshit</keyname><forenames>Sandip</forenames></author><author><keyname>Kundu</keyname><forenames>Amitava</forenames></author><author><keyname>Maity</keyname><forenames>Mrinmoy</forenames></author><author><keyname>Mandal</keyname><forenames>Subhajit</forenames></author><author><keyname>Sarkar</keyname><forenames>Satwika</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author></authors><title>Recognition of handwritten Roman Numerals using Tesseract open source
  OCR engine</title><categories>cs.CV</categories><comments>Proc. Int. Conf. on Advances in Computer Vision and Information
  Technology (2009) 572-577</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of the paper is to recognize handwritten samples of Roman
numerals using Tesseract open source Optical Character Recognition (OCR)
engine. Tesseract is trained with data samples of different persons to generate
one user-independent language model, representing the handwritten Roman
digit-set. The system is trained with 1226 digit samples collected form the
different users. The performance is tested on two different datasets, one
consisting of samples collected from the known users (those who prepared the
training data samples) and the other consisting of handwritten data samples of
unknown users. The overall recognition accuracy is obtained as 92.1% and 86.59%
on these test datasets respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5899</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5899</id><created>2010-03-30</created><authors><author><keyname>Patyk</keyname><forenames>Agnieszka</forenames></author></authors><title>Geometric Algebra Model of Distributed Representations</title><categories>cs.AI</categories><comments>30 pages, 19 figures</comments><doi>10.1007/978-1-84996-108-0_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formalism based on GA is an alternative to distributed representation models
developed so far --- Smolensky's tensor product, Holographic Reduced
Representations (HRR) and Binary Spatter Code (BSC). Convolutions are replaced
by geometric products, interpretable in terms of geometry which seems to be the
most natural language for visualization of higher concepts. This paper recalls
the main ideas behind the GA model and investigates recognition test results
using both inner product and a clipped version of matrix representation. The
influence of accidental blade equality on recognition is also studied. Finally,
the efficiency of the GA model is compared to that of previously developed
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5907</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5907</id><created>2010-03-30</created><updated>2010-05-23</updated><authors><author><keyname>Madry</keyname><forenames>Aleksander</forenames></author></authors><title>Faster Approximation Schemes for Fractional Multicommodity Flow Problems
  via Dynamic Graph Algorithms</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We combine the work of Garg and Konemann, and Fleischer with ideas from
dynamic graph algorithms to obtain faster (1-eps)-approximation schemes for
various versions of the multicommodity flow problem. In particular, if eps is
moderately small and the size of every number used in the input instance is
polynomially bounded, the running times of our algorithms match - up to
poly-logarithmic factors and some provably optimal terms - the Omega(mn)
flow-decomposition barrier for single-commodity flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5954</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5954</id><created>2010-03-30</created><updated>2010-09-30</updated><authors><author><keyname>Megacz</keyname><forenames>Adam</forenames></author></authors><title>Multi-Stage Programs are Generalized Arrows</title><categories>cs.PL cs.LO math.CT</categories><comments>This paper is obsolete and has been superceded by {\it Multi-Level
  Programs are Generalized Arrows} available here:
  http://arxiv.org/pdf/1007.2885</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The lambda calculus, subject to typing restrictions, provides a syntax for
the internal language of cartesian closed categories. This paper establishes a
parallel result: staging annotations, subject to named level restrictions,
provide a syntax for the internal language of Freyd categories, which are known
to be in bijective correspondence with Arrows. The connection is made by
interpreting multi-stage type systems as indexed functors from polynomial
categories to their reindexings. This result applies only to multi-stage
languages which are (1) homogeneous, (2) allow cross-stage persistence and (3)
place no restrictions on the use of structural rules in typing derivations.
Removing these restrictions and repeating the construction yields generalized
arrows, of which Arrows are a particular case. A translation from well-typed
multi-stage programs to single-stage GArrow terms is provided. The translation
is defined by induction on the structure of the proof that the multi-stage
program is well-typed, relying on information encoded in the proof's use of
structural rules. Metalanguage designers can now factor out the syntactic
machinery of metaprogramming by providing a single translation from staging
syntax into expressions of generalized arrow type. Object language providers
need only implement the functions of the generalized arrow type class in
point-free style. Object language users may write metaprograms over these
object languages in a point-ful style, using the same binding, scoping,
abstraction, and application mechanisms in both the object language and
metalanguage. This paper's principal contributions are the GArrow definition of
Figures 2 and 3, the translation in Figure 5 and the category-theoretic
semantics of Definition 16. An accompanying Coq proof formalizes the type
system, translation procedure, and key theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5956</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5956</id><created>2010-03-30</created><updated>2012-03-01</updated><authors><author><keyname>Li</keyname><forenames>Lihong</forenames></author><author><keyname>Chu</keyname><forenames>Wei</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Wang</keyname><forenames>Xuanhui</forenames></author></authors><title>Unbiased Offline Evaluation of Contextual-bandit-based News Article
  Recommendation Algorithms</title><categories>cs.LG cs.AI cs.RO stat.ML</categories><comments>10 pages, 7 figures, revised from the published version at the WSDM
  2011 conference</comments><acm-class>H.3.5; I.2.6</acm-class><doi>10.1145/1935826.1935878</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contextual bandit algorithms have become popular for online recommendation
systems such as Digg, Yahoo! Buzz, and news recommendation in general.
\emph{Offline} evaluation of the effectiveness of new algorithms in these
applications is critical for protecting online user experiences but very
challenging due to their &quot;partial-label&quot; nature. Common practice is to create a
simulator which simulates the online environment for the problem at hand and
then run an algorithm against this simulator. However, creating simulator
itself is often difficult and modeling bias is usually unavoidably introduced.
In this paper, we introduce a \emph{replay} methodology for contextual bandit
algorithm evaluation. Different from simulator-based approaches, our method is
completely data-driven and very easy to adapt to different applications. More
importantly, our method can provide provably unbiased evaluations. Our
empirical results on a large-scale news article recommendation dataset
collected from Yahoo! Front Page conform well with our theoretical results.
Furthermore, comparisons between our offline replay and online bucket
evaluation of several contextual bandit algorithms show accuracy and
effectiveness of our offline evaluation method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5964</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5964</id><created>2010-03-30</created><updated>2011-05-05</updated><authors><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author></authors><title>Fast Convergence of MCMC Algorithms for Phylogenetic Reconstruction with
  Homogeneous Data on Closely Related Species</title><categories>q-bio.PE cs.DS</categories><comments>To appear in SIAM Journal of Discrete Mathematics (SIDMA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a Markov chain for phylogenetic reconstruction which uses
a popular transition between tree topologies known as subtree
pruning-and-regrafting (SPR). We analyze the Markov chain in the simpler
setting that the generating tree consists of very short edge lengths, short
enough so that each sample from the generating tree (or character in
phylogenetic terminology) is likely to have only one mutation, and that there
enough samples so that the data looks like the generating distribution. We
prove in this setting that the Markov chain is rapidly mixing, i.e., it quickly
converges to its stationary distribution, which is the posterior distribution
over tree topologies. Our proofs use that the leading term of the maximum
likelihood function of a tree T is the maximum parsimony score, which is the
size of the minimum cut in T needed to realize single edge cuts of the
generating tree. Our main contribution is a combinatorial proof that in our
simplified setting, SPR moves are guaranteed to converge quickly to the maximum
parsimony tree. Our results are in contrast to recent works showing examples
with heterogeneous data (namely, the data is generated from a mixture
distribution) where many natural Markov chains are exponentially slow to
converge to the stationary distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5966</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5966</id><created>2010-03-30</created><updated>2014-08-05</updated><authors><author><keyname>Zhan</keyname><forenames>Jiening</forenames></author><author><keyname>Nazer</keyname><forenames>Bobak</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>Integer-Forcing Linear Receivers</title><categories>cs.IT math.IT</categories><comments>40 pages, 16 figures, to appear in the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear receivers are often used to reduce the implementation complexity of
multiple-antenna systems. In a traditional linear receiver architecture, the
receive antennas are used to separate out the codewords sent by each transmit
antenna, which can then be decoded individually. Although easy to implement,
this approach can be highly suboptimal when the channel matrix is near
singular. This paper develops a new linear receiver architecture that uses the
receive antennas to create an effective channel matrix with integer-valued
entries. Rather than attempting to recover transmitted codewords directly, the
decoder recovers integer combinations of the codewords according to the entries
of the effective channel matrix. The codewords are all generated using the same
linear code which guarantees that these integer combinations are themselves
codewords. Provided that the effective channel is full rank, these integer
combinations can then be digitally solved for the original codewords. This
paper focuses on the special case where there is no coding across transmit
antennas and no channel state information at the transmitter(s), which
corresponds either to a multi-user uplink scenario or to single-user V-BLAST
encoding. In this setting, the proposed integer-forcing linear receiver
significantly outperforms conventional linear architectures such as the
zero-forcing and linear MMSE receiver. In the high SNR regime, the proposed
receiver attains the optimal diversity-multiplexing tradeoff for the standard
MIMO channel with no coding across transmit antennas. It is further shown that
in an extended MIMO model with interference, the integer-forcing linear
receiver achieves the optimal generalized degrees-of-freedom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5979</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5979</id><created>2010-03-31</created><authors><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author><author><keyname>Zhong</keyname><forenames>Yuan</forenames></author></authors><title>Qualitative Properties of alpha-Weighted Scheduling Policies</title><categories>cs.NI math.OC</categories><comments>13 pages</comments><acm-class>C.2.1; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a switched network, a fairly general constrained queueing network
model that has been used successfully to model the detailed packet-level
dynamics in communication networks, such as input-queued switches and wireless
networks. The main operational issue in this model is that of deciding which
queues to serve, subject to certain constraints. In this paper, we study
qualitative performance properties of the well known $\alpha$-weighted
scheduling policies. The stability, in the sense of positive recurrence, of
these policies has been well understood. We establish exponential upper bounds
on the tail of the steady-state distribution of the backlog. Along the way, we
prove finiteness of the expected steady-state backlog when $\alpha&lt;1$, a
property that was known only for $\alpha\geq 1$. Finally, we analyze the
excursions of the maximum backlog over a finite time horizon for $\alpha \geq
1$. As a consequence, for $\alpha \geq 1$, we establish the full state space
collapse property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5993</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5993</id><created>2010-03-31</created><authors><author><keyname>Zeng</keyname><forenames>Xiangyong</forenames></author><author><keyname>Shan</keyname><forenames>Jinyong</forenames></author><author><keyname>Hu</keyname><forenames>Lei</forenames></author></authors><title>A Triple-Error-Correcting Cyclic Code from the Gold and Kasami-Welch APN
  Power Functions</title><categories>cs.DM cs.IT math.IT</categories><comments>29 pages</comments><msc-class>94B</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on a sufficient condition proposed by Hollmann and Xiang for
constructing triple-error-correcting codes, the minimum distance of a binary
cyclic code $\mathcal{C}_{1,3,13}$ with three zeros $\alpha$, $\alpha^3$, and
$\alpha^{13}$ of length $2^m-1$ and the weight divisibility of its dual code
are studied, where $m\geq 5$ is odd and $\alpha$ is a primitive element of the
finite field $\mathbb{F}_{2^m}$. The code $\mathcal{C}_{1,3,13}$ is proven to
have the same weight distribution as the binary triple-error-correcting
primitive BCH code $\mathcal{C}_{1,3,5}$ of the same length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.5998</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.5998</id><created>2010-03-31</created><authors><author><keyname>H&#xe1;jek</keyname><forenames>Jaroslav</forenames></author><author><keyname>Sz&#xf6;ll&#xf6;s</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>&#x160;&#xed;stek</keyname><forenames>Jakub</forenames></author></authors><title>A New Mechanism for Maintaining Diversity of Pareto Archive in
  Multiobjective Optimization</title><categories>math.OC cs.NE</categories><comments>51 pages, 28 figures</comments><msc-class>90C27, 90C29</msc-class><journal-ref>Adv. Eng. Softw., 41(7-8):1031-1057, 2010</journal-ref><doi>10.1016/j.advengsoft.2010.03.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article introduces a new mechanism for selecting individuals to a Pareto
archive. It was combined with a micro-genetic algorithm and tested on several
problems. The ability of this approach to produce individuals uniformly
distributed along the Pareto set without negative impact on convergence is
demonstrated on presented results. The new concept was confronted with NSGA-II,
SPEA2, and IBEA algorithms from the PISA package. Another studied effect is the
size of population versus number of generations for small populations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6013</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6013</id><created>2010-03-31</created><updated>2011-07-28</updated><authors><author><keyname>Baicheva</keyname><forenames>Tsonka</forenames></author><author><keyname>Topalova</keyname><forenames>Svetlana</forenames></author></authors><title>Optimal (v, 4, 2, 1) optical orthogonal codes with small parameters</title><categories>cs.DM</categories><comments>This paper has been withdrawn by authors</comments><msc-class>94C30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal (v, 4, 2, 1) optical orthogonal codes (OOC) with $v&lt;=75$ and $v\ne
71$ are classified up to equivalence. One $(v, 4, 2, 1)$ OOC is presented for
all $v\le 181$, for which an optimal OOC exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6030</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6030</id><created>2010-03-31</created><authors><author><keyname>Ragini</keyname><forenames>K.</forenames><affiliation>G.Narayanamma Institute of Technology &amp; Science India</affiliation></author><author><keyname>Satyam</keyname><forenames>M.</forenames><affiliation>International Institute of Information Technology, India</affiliation></author><author><keyname>Jinaga</keyname><forenames>B. C.</forenames><affiliation>Jawaharlal Nehru Technology University, India</affiliation></author></authors><title>Variable Threshold MOSFET Approach (Through Dynamic Threshold MOSFET)
  For Universal Logic Gates</title><categories>cs.OH</categories><comments>11 Pages, VLSICS Journal</comments><journal-ref>International Journal Of VLSI Design &amp; Communication Systems 1.1
  (2010) 33-43</journal-ref><doi>10.5121/vlsic.2010.1104</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this article, we proposed a Variable threshold MOSFET(VTMOS)approach which
is realized from Dynamic Threshold MOSFET(DTMOS), suitable for sub-threshold
digital circuit operation. Basically the principle of sub- threshold logics is
operating MOSFET in sub-threshold region and using the leakage current in that
region for switching action, there by drastically decreasing power. To reduce
the power consumption of sub-threshold circuits further, a novel body biasing
technique termed VTMOS is introduced .VTMOS approach is realized from DTMOS
approach. Dynamic threshold MOS (DTMOS) circuits provide low leakage and high
current drive, compared to CMOS circuits, operated at lower voltages. The VTMOS
is based on operating the MOS devices with an appropriate substrate bias which
varies with gate voltage, by connecting a positive bias voltage between gate
and substrate for NMOS and negative bias voltage between gate and substrate for
PMOS. With VTMOS, there is a considerable reduction in operating current and
power dissipation, while the remaining characteristics are almost the same as
those of DTMOS. Results of our investigations show that VTMOS circuits improves
the power up to 50% when compared to CMOS and DTMOS circuits, in sub- threshold
region.. The performance analysis and comparison of VTMOS, DTMOS and CMOS is
made and test results of Power dissipation, Propagation delay and Power delay
product are presented to justify the superiority of VTMOS logic over
conventional sub-threshold logics using Hspice Tool. The dependency of these
parameters on frequency of operation has also been investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6036</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6036</id><created>2010-03-31</created><updated>2011-10-11</updated><authors><author><keyname>Spandl</keyname><forenames>Christoph</forenames></author></authors><title>Computational Complexity of Iterated Maps on the Interval</title><categories>cs.NA cs.MS math.DS</categories><acm-class>G.1.0; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The correct computation of orbits of discrete dynamical systems on the
interval is considered. Therefore, an arbitrary-precision floating-point
approach based on automatic error analysis is chosen and a general algorithm is
presented. The correctness of the algorithm is shown and the computational
complexity is analyzed. There are two main results. First, the computational
complexity measure considered here is related to the Lyapunov exponent of the
dynamical system under consideration. Second, the presented algorithm is
optimal with regard to that complexity measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6052</identifier>
 <datestamp>2015-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6052</id><created>2010-03-31</created><updated>2015-01-22</updated><authors><author><keyname>Saha</keyname><forenames>Satadal</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>Development of an automated Red Light Violation Detection System (RLVDS)
  for Indian vehicles</title><categories>cs.CV</categories><comments>National Conference on Computing and Communication Systems
  (COCOSYS-09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrated Traffic Management Systems (ITMS) are now implemented in different
cities in India to primarily address the concerns of road-safety and security.
An automated Red Light Violation Detection System (RLVDS) is an integral part
of the ITMS. In our present work we have designed and developed a complete
system for generating the list of all stop-line violating vehicle images
automatically from video snapshots of road-side surveillance cameras. The
system first generates adaptive background images for each camera view,
subtracts captured images from the corresponding background images and analyses
potential occlusions over the stop-line in a traffic signal. Considering
round-the-clock operations in a real-life test environment, the developed
system could successfully track 92% images of vehicles with violations on the
stop-line in a &quot;Red&quot; traffic signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6059</identifier>
 <datestamp>2015-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6059</id><created>2010-03-31</created><updated>2015-01-22</updated><authors><author><keyname>Saha</keyname><forenames>Satadal</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>A novel scheme for binarization of vehicle images using hierarchical
  histogram equalization technique</title><categories>cs.CV</categories><comments>International Conference on Computer, Communication, Control and
  Information Technology (C3IT 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic License Plate Recognition system is a challenging area of research
now-a-days and binarization is an integral and most important part of it. In
case of a real life scenario, most of existing methods fail to properly
binarize the image of a vehicle in a congested road, captured through a CCD
camera. In the current work we have applied histogram equalization technique
over the complete image and also over different hierarchy of image
partitioning. A novel scheme is formulated for giving the membership value to
each pixel for each hierarchy of histogram equalization. Then the image is
binarized depending on the net membership value of each pixel. The technique is
exhaustively evaluated on the vehicle image dataset as well as the license
plate dataset, giving satisfactory performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6069</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6069</id><created>2010-03-30</created><authors><author><keyname>Aileni</keyname><forenames>Anvesh</forenames></author></authors><title>A CF-Based Randomness Measure for Sequences</title><categories>cs.DM</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note examines the question of randomness in a sequence based on the
continued fraction (CF) representation of its corresponding representation as a
number, or as D sequence. We propose a randomness measure that is directly
equal to the number of components of the CF representation. This provides a
means of quantifying the randomness of the popular PN sequences as well. A
comparison is made of representation as a fraction and as a continued fraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6082</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6082</id><created>2010-03-31</created><updated>2013-10-20</updated><authors><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Steinberg</keyname><forenames>Yossef</forenames></author><author><keyname>Wigger</keyname><forenames>Michele</forenames></author></authors><title>Coding Schemes and Asymptotic Capacity of the Gaussian Broadcast and
  Interference Channels with Feedback</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coding scheme is proposed for the memoryless Gaussian broadcast channel
with correlated noises and feedback. For all noise correlations other than -1,
the gap between the sum-rate the scheme achieves and the full-cooperation bound
vanishes as the signal-to-noise ratio tends to infinity. When the correlation
coefficient is -1, the gains afforded by feedback are unbounded and the prelog
is doubled. When the correlation coefficient is +1 we demonstrate a dichotomy:
If the noise variances are equal, then feedback is useless, and otherwise,
feedback affords unbounded rate gains and doubles the prelog. The unbounded
feedback gains, however, require perfect (noiseless) feedback. When the
feedback links are noisy the feedback gains are bounded, unless the feedback
noise decays to zero sufficiently fast with the signal-to-noise ratio.
Extensions to more receivers are also discussed as is the memoryless Gaussian
interference channel with feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6091</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6091</id><created>2010-03-31</created><updated>2011-04-08</updated><authors><author><keyname>Goebel</keyname><forenames>Bernhard</forenames></author><author><keyname>Essiambre</keyname><forenames>Ren&#xe9;-Jean</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Winzer</keyname><forenames>Peter J.</forenames></author><author><keyname>Hanik</keyname><forenames>Norbert</forenames></author></authors><title>Calculation of Mutual Information for Partially Coherent Gaussian
  Channels with Applications to Fiber Optics</title><categories>cs.IT math.IT</categories><comments>30 pages, 9 figures, accepted for publication in IEEE Transactions on
  Information Theory</comments><journal-ref>IEEE Trans. Information Theory 57 (2011) 5720-5736</journal-ref><doi>10.1109/TIT.2011.2162187</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mutual information between a complex-valued channel input and its
complex-valued output is decomposed into four parts based on polar coordinates:
an amplitude term, a phase term, and two mixed terms. Numerical results for the
additive white Gaussian noise (AWGN) channel with various inputs show that, at
high signal-to-noise ratio (SNR), the amplitude and phase terms dominate the
mixed terms. For the AWGN channel with a Gaussian input, analytical expressions
are derived for high SNR. The decomposition method is applied to partially
coherent channels and a property of such channels called &quot;spectral loss&quot; is
developed. Spectral loss occurs in nonlinear fiber-optic channels and it may be
one effect that needs to be taken into account to explain the behavior of the
capacity of nonlinear fiber-optic channels presented in recent studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6096</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6096</id><created>2010-03-31</created><authors><author><keyname>Jakubuv</keyname><forenames>Jan</forenames></author><author><keyname>Wells</keyname><forenames>J. B.</forenames></author></authors><title>Expressiveness of Generic Process Shape Types</title><categories>cs.LO</categories><comments>Submitted to Trustworthy Global Computing (TGC) 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shape types are a general concept of process types which work for many
process calculi. We extend the previously published Poly* system of shape types
to support name restriction. We evaluate the expressiveness of the extended
system by showing that shape types are more expressive than an implicitly typed
pi-calculus and an explicitly typed Mobile Ambients. We demonstrate that the
extended system makes it easier to enjoy advantages of shape types which
include polymorphism, principal typings, and a type inference implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1003.6124</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1003.6124</id><created>2010-03-31</created><updated>2011-09-01</updated><authors><author><keyname>Altarelli</keyname><forenames>Fabrizio</forenames></author><author><keyname>Braunstein</keyname><forenames>Alfredo</forenames></author><author><keyname>Ramezanpour</keyname><forenames>Abolfazl</forenames></author><author><keyname>Zecchina</keyname><forenames>Riccardo</forenames></author></authors><title>Statistical physics of optimization under uncertainty</title><categories>cond-mat.stat-mech cs.DS</categories><comments>This article has been withdrawn because it was replaced by
  arXiv:1105.3657 with a different name</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization under uncertainty deals with the problem of optimizing
stochastic cost functions given some partial information on their inputs. These
problems are extremely difficult to solve and yet pervade all areas of
technological and natural sciences. We propose a general approach to solve such
large-scale stochastic optimization problems and a Survey Propagation based
algorithm that implements it. In the problems we consider some of the
parameters are not known at the time of the first optimization, but are
extracted later independently of each other from known distributions. As an
illustration, we apply our method to the stochastic bipartite matching problem,
in the two-stage and multi-stage cases. The efficiency of our approach, which
does not rely on sampling techniques, allows us to validate the analytical
predictions with large-scale numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0023</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0023</id><created>2010-03-31</created><authors><author><keyname>Karimi</keyname><forenames>Kamran</forenames></author><author><keyname>Dickson</keyname><forenames>Neil G.</forenames></author><author><keyname>Hamze</keyname><forenames>Firas</forenames></author></authors><title>High-Performance Physics Simulations Using Multi-Core CPUs and GPGPUs in
  a Volunteer Computing Context</title><categories>cs.DC cs.PF physics.comp-ph</categories><comments>15 pages, 9 figures, 3 tables. Accepted in the International Journal
  of High Performance Computing Applications</comments><doi>10.1177/1094342010372928</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents two conceptually simple methods for parallelizing a
Parallel Tempering Monte Carlo simulation in a distributed volunteer computing
context, where computers belonging to the general public are used. The first
method uses conventional multi-threading. The second method uses CUDA, a
graphics card computing system. Parallel Tempering is described, and challenges
such as parallel random number generation and mapping of Monte Carlo chains to
different threads are explained. While conventional multi-threading on CPUs is
well-established, GPGPU programming techniques and technologies are still
developing and present several challenges, such as the effective use of a
relatively large number of threads. Having multiple chains in Parallel
Tempering allows parallelization in a manner that is similar to the serial
algorithm. Volunteer computing introduces important constraints to high
performance computing, and we show that both versions of the application are
able to adapt themselves to the varying and unpredictable computing resources
of volunteers' computers, while leaving the machines responsive enough to use.
We present experiments to show the scalable performance of these two
approaches, and indicate that the efficiency of the methods increases with
bigger problem sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0024</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0024</id><created>2010-03-31</created><authors><author><keyname>Dickson</keyname><forenames>Neil G.</forenames></author><author><keyname>Karimi</keyname><forenames>Kamran</forenames></author><author><keyname>Hamze</keyname><forenames>Firas</forenames></author></authors><title>Importance of Explicit Vectorization for CPU and GPU Software
  Performance</title><categories>cs.DC cs.PF physics.comp-ph</categories><comments>17 pages, 17 figures</comments><doi>10.1016/j.jcp.2011.03.041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of the current focus in high-performance computing is on
multi-threading, multi-computing, and graphics processing unit (GPU) computing.
However, vectorization and non-parallel optimization techniques, which can
often be employed additionally, are less frequently discussed. In this paper,
we present an analysis of several optimizations done on both central processing
unit (CPU) and GPU implementations of a particular computationally intensive
Metropolis Monte Carlo algorithm. Explicit vectorization on the CPU and the
equivalent, explicit memory coalescing, on the GPU are found to be critical to
achieving good performance of this algorithm in both environments. The
fully-optimized CPU version achieves a 9x to 12x speedup over the original CPU
version, in addition to speedup from multi-threading. This is 2x faster than
the fully-optimized GPU version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0027</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0027</id><created>2010-03-31</created><authors><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Interference in Lattice Networks</title><categories>cs.IT math.IT</categories><comments>17 pages, 10 figures. Submitted to IEEE Trans. Comm.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattices are important as models for the node locations in wireless networks
for two main reasons: (1) When network designers have control over the
placement of the nodes, they often prefer a regular arrangement in a lattice
for coverage and interference reasons. (2) If nodes are randomly distributed or
mobile, good channel access schemes ensure that concurrent transmitters are
regularly spaced, hence the locations of the transmitting nodes are well
approximated by a lattice. In this paper, we introduce general interference
bounding techniques that permit the derivation of tight closed-form upper and
lower bounds for all lattice networks, and we present and analyze optimum or
near-optimum channel access schemes for one-dimensional, square, and triangular
lattices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0048</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0048</id><created>2010-03-31</created><authors><author><keyname>Das</keyname><forenames>Sudipto</forenames></author><author><keyname>Egecioglu</keyname><forenames>Omer</forenames></author><author><keyname>Abbadi</keyname><forenames>Amr El</forenames></author></authors><title>Anonimos: An LP based Approach for Anonymizing Weighted Social Network
  Graphs</title><categories>cs.DB</categories><comments>15 pages.</comments><acm-class>E.1; G.1.6; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing popularity of social networks has initiated a fertile research
area in information extraction and data mining. Anonymization of these social
graphs is important to facilitate publishing these data sets for analysis by
external entities. Prior work has concentrated mostly on node identity
anonymization and structural anonymization. But with the growing interest in
analyzing social networks as a weighted network, edge weight anonymization is
also gaining importance. We present An\'onimos, a Linear Programming based
technique for anonymization of edge weights that preserves linear properties of
graphs. Such properties form the foundation of many important graph-theoretic
algorithms such as shortest paths problem, k-nearest neighbors, minimum cost
spanning tree, and maximizing information spread. As a proof of concept, we
apply An\'onimos to the shortest paths problem and its extensions, prove the
correctness, analyze complexity, and experimentally evaluate it using real
social network data sets. Our experiments demonstrate that An\'onimos
anonymizes the weights, improves k-anonymity of the weights, and also scrambles
the relative ordering of the edges sorted by weights, thereby providing robust
and effective anonymization of the sensitive edge-weights. Additionally, we
demonstrate the composability of different models generated using An\'onimos, a
property that allows a single anonymized graph to preserve multiple linear
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0050</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0050</id><created>2010-04-01</created><authors><author><keyname>Arcia-Moret</keyname><forenames>Andres</forenames></author><author><keyname>Yang</keyname><forenames>Yubo</forenames></author><author><keyname>Montavont</keyname><forenames>Nicolas</forenames></author><author><keyname>Ros</keyname><forenames>David</forenames></author></authors><title>A Study of Bandwidth-Perception Management Mechanisms in IEEE 802.16
  Networks</title><categories>cs.NI</categories><comments>10 pages, 20 figs.</comments><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bandwidth request-grant mechanisms are used in 802.16 networks to manage the
uplink bandwidth needs of subscriber stations (SSs). Requests may be sent by
SSs to the base station (BS) by means of several mechanisms defined in the
standard. Based on the incoming requests, the BS (which handles most of the
bandwidth scheduling in the system) schedules the transmission of uplink
traffic, by assigning transmission opportunities to the SSs in an
implementation-dependent manner. In this paper we present a study of some
bandwidth allocation issues, arising from the management of the perception of
subscriber stations' bandwidth needs at the base station. We illustrate how the
bandwidth perception varies depending on the policy used to handle requests and
grants. By means of ns-2 simulations, we evaluate the potential impact of such
policies on the system's aggregate throughput when the traffic is composed of
Best-Effort TCP flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0056</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0056</id><created>2010-04-01</created><updated>2010-04-09</updated><authors><author><keyname>Le</keyname><forenames>Dai Tri Man</forenames></author></authors><title>A Characterization of Combined Traces Using Labeled Stratified Order
  Structures</title><categories>cs.DC cs.FL</categories><comments>22 pages, preliminary version, some typos fixed.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper defines a class of labeled stratified order structures that
characterizes exactly the notion of combined traces (i.e., comtraces) proposed
by Janicki and Koutny in 1995. Our main technical contributions are the
representation theorems showing that comtrace quotient monoid, combined
dependency graph (Kleijn and Koutny 2008) and our labeled stratified order
structure characterization are three different and yet equivalent ways to
represent comtraces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0062</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0062</id><created>2010-04-01</created><authors><author><keyname>Yasuoka</keyname><forenames>Hirotoshi</forenames></author><author><keyname>Terauchi</keyname><forenames>Tachio</forenames></author></authors><title>Quantitative Information Flow - Verification Hardness and Possibilities</title><categories>cs.CR</categories><comments>To appear in Computer Security Foundations 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers have proposed formal definitions of quantitative information flow
based on information theoretic notions such as the Shannon entropy, the min
entropy, the guessing entropy, and channel capacity. This paper investigates
the hardness and possibilities of precisely checking and inferring quantitative
information flow according to such definitions.
  We prove that, even for just comparing two programs on which has the larger
flow, none of the definitions is a k-safety property for any k, and therefore
is not amenable to the self-composition technique that has been successfully
applied to precisely checking non-interference. We also show a complexity
theoretic gap with non-interference by proving that, for loop-free boolean
programs whose non-interference is coNP-complete, the comparison problem is
#P-hard for all of the definitions.
  For positive results, we show that universally quantifying the distribution
in the comparison problem, that is, comparing two programs according to the
entropy based definitions on which has the larger flow for all distributions,
is a 2-safety problem in general and is coNP-complete when restricted for
loop-free boolean programs. We prove this by showing that the problem is
equivalent to a simple relation naturally expressing the fact that one program
is more secure than the other. We prove that the relation also refines the
channel-capacity based definition, and that it can be precisely checked via the
self-composition as well as the &quot;interleaved&quot; self-composition technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0084</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0084</id><created>2010-04-01</created><updated>2010-06-30</updated><authors><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Dingkang</forenames></author></authors><title>A New Proof for the Correctness of F5 (F5-Like) Algorithm</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The famous F5 algorithm for computing Gr\&quot;obner basis was presented by
Faug\`ere in 2002 without complete proofs for its correctness. The current
authors have simplified the original F5 algorithm into an F5 algorithm in
Buchberger's style (F5B algorithm), which is equivalent to original F5
algorithm and may deduce some F5-like versions. In this paper, the F5B
algorithm is briefly revisited and a new complete proof for the correctness of
F5B algorithm is proposed. This new proof is not limited to homogeneous systems
and does not depend on the strategy of selecting critical pairs (i.e. the
strategy deciding which critical pair is computed first) such that any strategy
could be utilized in F5B (F5) algorithm. From this new proof, we find that the
special reduction procedure (F5-reduction) is the key of F5 algorithm, so
maintaining this special reduction, various variation algorithms become
available. A natural variation of F5 algorithm, which transforms original F5
algorithm to a non-incremental algorithm, is presented and proved in this paper
as well. This natural variation has been implemented over the Boolean ring. The
two revised criteria in this natural variation are also able to reject almost
all unnecessary computations and few polynomials reduce to 0 in most examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0085</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0085</id><created>2010-04-01</created><authors><author><keyname>kimura</keyname><forenames>Akisato</forenames></author><author><keyname>Pang</keyname><forenames>Derek</forenames></author><author><keyname>Takeuchi</keyname><forenames>Tatsuto</forenames></author><author><keyname>Miyazato</keyname><forenames>Kouji</forenames></author><author><keyname>Yamato</keyname><forenames>Junji</forenames></author><author><keyname>Kashino</keyname><forenames>Kunio</forenames></author></authors><title>A stochastic model of human visual attention with a dynamic Bayesian
  network</title><categories>cs.CV cs.MM cs.NE stat.ML</categories><comments>24 pages, single-column, 13 figures excluding portlaits, submitted to
  IEEE Transactions on Pattern Analysis and Machine Intelligence.</comments><msc-class>68U10</msc-class><acm-class>I.4.8; I.4.10; I.5.1; I.6.8; I.2.10; I.4.4; I.2.9; I.3.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recent studies in the field of human vision science suggest that the human
responses to the stimuli on a visual display are non-deterministic. People may
attend to different locations on the same visual input at the same time. Based
on this knowledge, we propose a new stochastic model of visual attention by
introducing a dynamic Bayesian network to predict the likelihood of where
humans typically focus on a video scene. The proposed model is composed of a
dynamic Bayesian network with 4 layers. Our model provides a framework that
simulates and combines the visual saliency response and the cognitive state of
a person to estimate the most probable attended regions. Sample-based inference
with Markov chain Monte-Carlo based particle filter and stream processing with
multi-core processors enable us to estimate human visual attention in near real
time. Experimental results have demonstrated that our model performs
significantly better in predicting human visual attention compared to the
previous deterministic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0092</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0092</id><created>2010-04-01</created><authors><author><keyname>Hoffmann</keyname><forenames>Benjamin</forenames></author><author><keyname>Lifshits</keyname><forenames>Mikhail</forenames></author><author><keyname>Lifshits</keyname><forenames>Yury</forenames></author><author><keyname>Nowotka</keyname><forenames>Dirk</forenames></author></authors><title>Maximal Intersection Queries in Randomized Input Models</title><categories>cs.IR</categories><comments>18 pages</comments><journal-ref>Theory of Computing Systems, 46(1):104-119, 2010</journal-ref><doi>10.1007/s00224-008-9154-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a family of sets and a single set, called the query set. How can one
quickly find a member of the family which has a maximal intersection with the
query set? Time constraints on the query and on a possible preprocessing of the
set family make this problem challenging. Such maximal intersection queries
arise in a wide range of applications, including web search, recommendation
systems, and distributing on-line advertisements. In general, maximal
intersection queries are computationally expensive. We investigate two
well-motivated distributions over all families of sets and propose an algorithm
for each of them. We show that with very high probability an almost optimal
solution is found in time which is logarithmic in the size of the family.
Moreover, we point out a threshold phenomenon on the probabilities of
intersecting sets in each of our two input models which leads to the efficient
algorithms mentioned above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0105</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0105</id><created>2010-04-01</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Klauck</keyname><forenames>Hartmut</forenames></author><author><keyname>Santha</keyname><forenames>Miklos</forenames></author></authors><title>Optimal Direct Sum Results for Deterministic and Randomized Decision
  Tree Complexity</title><categories>cs.CC quant-ph</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Direct Sum Theorem holds in a model of computation, when solving some k
input instances together is k times as expensive as solving one. We show that
Direct Sum Theorems hold in the models of deterministic and randomized decision
trees for all relations. We also note that a near optimal Direct Sum Theorem
holds for quantum decision trees for boolean functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0152</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0152</id><created>2010-04-01</created><authors><author><keyname>Blomer</keyname><forenames>Joseph</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>Opportunistic Routing in Ad Hoc Networks: How many relays should there
  be? What rate should nodes use?</title><categories>cs.NI</categories><comments>5 pages, 8 figures, Submitted to IEEE GLOBECOM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic routing is a multi-hop routing scheme which allows for
selection of the best immediately available relay. In blind opportunistic
routing protocols, where transmitters blindly broadcast without knowledge of
the surrounding nodes, two fundamental design parameters are the node
transmission probability and the transmission spectral efficiency. In this
paper these parameters are selected to maximize end-to-end performance,
characterized by the product of transmitter density, hop distance and rate. Due
to the intractability of the problem as stated, an approximation function is
examined which proves reasonably accurate. Our results show how the above
design parameters should be selected based on inherent system parameters such
as the path loss exponent and the noise level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0180</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0180</id><created>2010-04-01</created><authors><author><keyname>Xie</keyname><forenames>Kai</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Jing</keyname><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname></author></authors><title>Precoded Turbo Equalizer for Power Line Communication Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power line communication continues to draw increasing interest by promising a
wide range of applications including cost-free last-mile communication
solution. However, signal transmitted through the power lines deteriorates
badly due to the presence of severe inter-symbol interference (ISI) and harsh
random pulse noise. This work proposes a new precoded turbo equalization scheme
specifically designed for the PLC channels. By introducing useful precoding to
reshape ISI, optimizing maximum {\it a posteriori} (MAP) detection to address
the non-Gaussian pulse noise, and performing soft iterative decision
refinement, the new equalizer demonstrates a gain significantly better than the
existing turbo equalizers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0202</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0202</id><created>2010-04-01</created><updated>2010-06-18</updated><authors><author><keyname>Chapoutot</keyname><forenames>Alexandre</forenames><affiliation>LIP6</affiliation></author></authors><title>Interval Slopes as Numerical Abstract Domain for Floating-Point
  Variables</title><categories>cs.PL cs.NA</categories><proxy>ccsd</proxy><doi>10.1007/978-3-642-15769-1_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of embedded control systems is mainly done with model-based tools
such as Matlab/Simulink. Numerical simulation is the central technique of
development and verification of such tools. Floating-point arithmetic, that is
well-known to only provide approximated results, is omnipresent in this
activity. In order to validate the behaviors of numerical simulations using
abstract interpretation-based static analysis, we present, theoretically and
with experiments, a new partially relational abstract domain dedicated to
floating-point variables. It comes from interval expansion of non-linear
functions using slopes and it is able to mimic all the behaviors of the
floating-point arithmetic. Hence it is adapted to prove the absence of run-time
errors or to analyze the numerical precision of embedded control systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0204</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0204</id><created>2010-04-01</created><authors><author><keyname>Henaut</keyname><forenames>Julien</forenames><affiliation>LAAS</affiliation></author><author><keyname>Lecointre</keyname><forenames>Aubin</forenames><affiliation>LAAS</affiliation></author><author><keyname>Dragomirescu</keyname><forenames>Daniela</forenames><affiliation>LAAS</affiliation></author><author><keyname>Plana</keyname><forenames>Robert</forenames><affiliation>LAAS</affiliation></author></authors><title>Radio Interface for High Data Rate Wireless Sensor Networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>International Conference on Computing, Communications and Control
  Technologies, Orlando, Fl : \'Etats-Unis d'Am\'erique (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives an overview of radio interfaces devoted for high data rate
Wireless Sensor Networks. Four aerospace applications of WSN are presented to
underline the importance of achieving high data rate. Then, two modulation
schemes by which High Data Rate can be achieved are compared : Multi carrier
approaches, represented by the popular Orthogonal Frequency Division
Multiplexing (OFDM) and Single carrier methods, represented by Single Carrier
Frequency division Equalization and its application for multiple access Single
Carrier Frequency division multiple Access (SC-FDMA). SC-FDMA, with a very low
Peak Average Power Ratio (PAPR), is as strong alternative to the OFDM scheme
for highly power constraint application. The Chosen radio interface will be,
finally, tested by a model based design approach based on Simulink and FPGA
realization. SC-FDMA, with a very low Peak Average Power Ratio (PAPR), is as
strong alternative to the OFDM scheme for highly power constraint application.
The Chosen radio interface will be, finally, tested by a model based design
approach based on Simulink and FPGA realization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0208</identifier>
 <datestamp>2012-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0208</id><created>2010-04-01</created><updated>2012-05-16</updated><authors><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Aldridge</keyname><forenames>Matthew</forenames></author><author><keyname>Piechocki</keyname><forenames>Robert</forenames></author></authors><title>Delay-rate tradeoff in ergodic interference alignment</title><categories>cs.IT math.IT math.PR</categories><comments>Extended version of a paper presented at the 2012 International
  Symposium on Information Theory. 7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ergodic interference alignment, as introduced by Nazer et al (NGJV), is a
technique that allows high-rate communication in n-user interference networks
with fast fading. It works by splitting communication across a pair of fading
matrices. However, it comes with the overhead of a long time delay until
matchable matrices occur: the delay is q^n^2 for field size q.
  In this paper, we outline two new families of schemes, called JAP and JAP-B,
that reduce the expected delay, sometimes at the cost of a reduction in rate
from the NGJV scheme. In particular, we give examples of good schemes for
networks with few users, and show that in large n-user networks, the delay
scales like q^T, where T is quadratic in n for a constant per-user rate and T
is constant for a constant sum-rate. We also show that half the single-user
rate can be achieved while reducing NGJV's delay from q^n^2 to q^(n-1)(n-2).
  This extended version includes complete proofs and more details of good
schemes for small n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0243</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0243</id><created>2010-04-01</created><authors><author><keyname>Drachen</keyname><forenames>Anders</forenames></author><author><keyname>Nacke</keyname><forenames>Lennart E.</forenames></author><author><keyname>Yannakakis</keyname><forenames>Georgios</forenames></author><author><keyname>Pedersen</keyname><forenames>Anja Lee</forenames></author></authors><title>Psychophysiological Correlations with Gameplay Experience Dimensions</title><categories>cs.HC cs.MM</categories><comments>CHI 2010 Workshop: Brain, Body, and Bytes</comments><msc-class>91E30</msc-class><acm-class>K.8.0; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we report a case study using two easy-to-deploy
psychophysiological measures - electrodermal activity (EDA) and heart rate (HR)
- and correlating them with a gameplay experience questionnaire (GEQ) in an
attempt to establish this mixed-methods approach for rapid application in a
commercial game development context. Results indicate that there is a
statistically significant correlation (p &lt; 0.01) between measures of
psychophysiological arousal (HR, EDA) and self-reported UX in games (GEQ), with
some variation between the EDA and HR measures. Results are consistent across
three major commercial First-Person Shooter (FPS) games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0248</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0248</id><created>2010-04-01</created><authors><author><keyname>Nacke</keyname><forenames>Lennart E.</forenames></author><author><keyname>Lindley</keyname><forenames>Craig A.</forenames></author></authors><title>Affective Ludology, Flow and Immersion in a First- Person Shooter:
  Measurement of Player Experience</title><categories>cs.HC cs.MM</categories><comments>21 pages</comments><msc-class>91-XX; 91E30</msc-class><acm-class>K.8.0; H.5.1; J.4; D.2.8</acm-class><journal-ref>Loading...: The Journal of the Canadian Game Studies Association.
  Vol 3, No 5 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gameplay research about experiential phenomena is a challenging undertaking,
given the variety of experiences that gamers encounter when playing and which
currently do not have a formal taxonomy, such as flow, immersion, boredom, and
fun. These informal terms require a scientific explanation. Ludologists also
acknowledge the need to understand cognition, emotion, and goal- oriented
behavior of players from a psychological perspective by establishing rigorous
methodologies. This paper builds upon and extends prior work in an area for
which we would like to coin the term &quot;affective ludology.&quot; The area is
concerned with the affective measurement of player-game interaction. The
experimental study reported here investigated different traits of gameplay
experience using subjective (i.e., questionnaires) and objective (i.e.,
psychophysiological) measures. Participants played three Half-Life 2 game level
design modifications while measures such as electromyography (EMG),
electrodermal activity (EDA) were taken and questionnaire responses were
collected. A level designed for combat-oriented flow experience demonstrated
significant high-arousal positive affect emotions. This method shows that
emotional patterns emerge from different level designs, which has great
potential for providing real-time emotional profiles of gameplay that may be
generated together with self- reported subjective player experience
descriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0256</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0256</id><created>2010-04-01</created><authors><author><keyname>Nacke</keyname><forenames>Lennart E.</forenames></author></authors><title>From Playability to a Hierarchical Game Usability Model</title><categories>cs.HC cs.MM</categories><comments>2 pages, 1 figure</comments><msc-class>97Rxx</msc-class><acm-class>K.8.0; H.5.1; J.4</acm-class><doi>10.1145/1639601.1639609</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a brief review of current game usability models. This
leads to the conception of a high-level game development-centered usability
model that integrates current usability approaches in game industry and game
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0258</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0258</id><created>2010-04-01</created><authors><author><keyname>Stellmach</keyname><forenames>Sophie</forenames></author><author><keyname>Nacke</keyname><forenames>Lennart E.</forenames></author><author><keyname>Dachselt</keyname><forenames>Raimund</forenames></author><author><keyname>Lindley</keyname><forenames>Craig A.</forenames></author></authors><title>Trends and Techniques in Visual Gaze Analysis</title><categories>cs.HC cs.CV cs.GR cs.MM</categories><comments>pages 89-93, The 5th Conference on Communication by Gaze Interaction
  - COGAIN 2009: Gaze Interaction For Those Who Want It Most, ISBN:
  978-87-643-0475-6</comments><msc-class>00A66</msc-class><acm-class>H.5.1; I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visualizing gaze data is an effective way for the quick interpretation of eye
tracking results. This paper presents a study investigation benefits and
limitations of visual gaze analysis among eye tracking professionals and
researchers. The results were used to create a tool for visual gaze analysis
within a Master's project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0259</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0259</id><created>2010-04-01</created><authors><author><keyname>Nacke</keyname><forenames>Lennart E.</forenames></author><author><keyname>Stellmach</keyname><forenames>Sophie</forenames></author><author><keyname>Sasse</keyname><forenames>Dennis</forenames></author><author><keyname>Lindley</keyname><forenames>Craig A.</forenames></author></authors><title>Gameplay experience in a gaze interaction game</title><categories>cs.HC cs.MM</categories><comments>pages 49-54, The 5th Conference on Communication by Gaze Interaction
  - COGAIN 2009: Gaze Interaction For Those Who Want It Most, ISBN:
  978-87-643-0475-6</comments><msc-class>91A90</msc-class><acm-class>I.4.8; H.5.1; K.8.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assessing gameplay experience for gaze interaction games is a challenging
task. For this study, a gaze interaction Half-Life 2 game modification was
created that allowed eye tracking control. The mod was deployed during an
experiment at Dreamhack 2007, where participants had to play with gaze
navigation and afterwards rate their gameplay experience. The results show low
tension and negative affects scores on the gameplay experience questionnaire as
well as high positive challenge, immersion and flow ratings. The correlation
between spatial presence and immersion for gaze interaction was high and yields
further investigation. It is concluded that gameplay experience can be
correctly assessed with the methodology presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0263</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0263</id><created>2010-04-01</created><authors><author><keyname>Pellegrini</keyname><forenames>Vincenzo</forenames></author><author><keyname>Rose</keyname><forenames>Luca</forenames></author><author><keyname>Di Dio</keyname><forenames>Mario</forenames></author></authors><title>On Memory Accelerated Signal Processing within Software Defined Radios</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since J. Mitola's work in 1992, Software Defined Radios (SDRs) have been
quite a hot topic in wireless systems research. Though many notable
achievements were reported in the field, the scarcity of computational power on
general purpose CPUs has always constrained their wide adoption in production
environments. If conveniently applied within an SDR context, classical concepts
known in computer science as space/time tradeoffs can be extremely helpful when
trying to mitigate this problem. Inspired by and building on those concepts,
this paper presents a novel SDR implementation technique which we call Memory
Acceleration (MA) that makes extensive use of the memory resources available on
a general purpose computing system, in order to accelerate signal computation.
MA can provide substantial acceleration factors when applied to conventional
SDRs without reducing their peculiar flexibility. As a practical proof of this,
an example of MA applied in the real world to the ETSI DVB-T Viterbi decoder is
provided. Actually MA is shown able to provide, when applied to such Viterbi
decoder, an acceleration factor of 10.4x, with no impact on error correction
performances of the decoder and by making no use of any other typical
performance enhancement techniques such as low level (Assembler) programming or
parallel computation, which though remain compatible with MA. Opportunity for
extending the MA approach to the entire radio system, thus implementing what we
call a Memory-Based Software Defined Radio (MB-SDR) is finally considered and
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0264</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0264</id><created>2010-04-01</created><updated>2011-03-11</updated><authors><author><keyname>Wu</keyname><forenames>Xiaodi</forenames></author></authors><title>Equilibrium Value Method for the Proof of QIP=PSPACE</title><categories>quant-ph cs.CC</categories><comments>21 pages; introduction rewritten, new results about computing the
  diamond norm added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an alternative proof of \class{QIP}=\class{PSPACE} to the recent
breakthrough result. Unlike solving some semidefinite programs that captures
the computational power of quantum interactive proofs, our method starts with
one \class{QIP}-Complete problem which computes the diamond norm between two
admissible quantum channels. The key observation is that we can convert the
computation of the diamond norm into the computation of some equilibrium value.
The later problem, different from the former semidefinite programs, is of
better form, easier to solve and could be interesting for its own sake. The
multiplicative weight update method is also applied to solve the equilibrium
value problem, however, in a relatively simpler way than the one in the
original proof. As a direct byproduct, we also provide a NC algorithm to
compute the diamond norm of a class of quantum channels. Furthermore, we
provide a generalized form of equilibrium value problems that can be solved in
the same way as well as comparisons to semidefinite programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0269</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0269</id><created>2010-04-01</created><authors><author><keyname>Laourine</keyname><forenames>Amine</forenames></author><author><keyname>Wagner</keyname><forenames>Aaron B.</forenames></author></authors><title>The Degraded Poisson Wiretap Channel</title><categories>cs.IT math.IT</categories><comments>29 pages, submitted to IEEE Transactions on Information Theory.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Providing security guarantees for wireless communication is critically
important for today's applications. While previous work in this area has
concentrated on radio frequency (RF) channels, providing security guarantees
for RF channels is inherently difficult because they are prone to rapid
variations due small scale fading. Wireless optical communication, on the other
hand, is inherently more secure than RF communication due to the intrinsic
aspects of the signal propagation in the optical and near-optical frequency
range. In this paper, secure communication over wireless optical links is
examined by studying the secrecy capacity of a direct detection system. For the
degraded Poisson wiretap channel, a closed-form expression of the secrecy
capacity is given. A complete characterization of the general rate-equivocation
region is also presented. For achievability, an optimal code is explicitly
constructed by using the structured code designed by Wyner for the Poisson
channel. The converse is proved in two different ways: the first method relies
only on simple properties of the conditional expectation and basic information
theoretical inequalities, whereas the second method hinges on the recent link
established between minimum mean square estimation and mutual information in
Poisson channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0313</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0313</id><created>2010-04-02</created><authors><author><keyname>Elayoubi</keyname><forenames>Salah Eddine</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Haddad</keyname><forenames>Majed</forenames></author><author><keyname>Altman</keyname><forenames>Zwi</forenames></author></authors><title>A hybrid decision approach for the association problem in heterogeneous
  networks</title><categories>cs.GT cs.NI</categories><comments>5 pages, 4 figures, IEEE Infocom, San Diego, USA, March 2010.</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The area of networking games has had a growing impact on wireless networks.
This reflects the recognition in the important scaling advantages that the
service providers can benefit from by increasing the autonomy of mobiles in
decision making. This may however result in inefficiencies that are inherent to
equilibria in non-cooperative games. Due to the concern for efficiency,
centralized protocols keep being considered and compared to decentralized ones.
From the point of view of the network architecture, this implies the
co-existence of network-centric and terminal centric radio resource management
schemes. Instead of taking part within the debate among the supporters of each
solution, we propose in this paper hybrid schemes where the wireless users are
assisted in their decisions by the network that broadcasts aggregated load
information. We derive the utilities related to the Quality of Service (QoS)
perceived by the users and develop a Bayesian framework to obtain the
equilibria. Numerical results illustrate the advantages of using our hybrid
game framework in an association problem in a network composed of HSDPA and 3G
LTE systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0334</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0334</id><created>2010-03-25</created><updated>2010-11-25</updated><authors><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author></authors><title>Approximation Algorithms for Campaign Management</title><categories>cs.GT cs.DS</categories><comments>19 pages</comments><acm-class>I.2.11; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study electoral campaign management scenarios in which an external party
can buy votes, i.e., pay the voters to promote its preferred candidate in their
preference rankings. The external party's goal is to make its preferred
candidate a winner while paying as little as possible. We describe a
2-approximation algorithm for this problem for a large class of electoral
systems known as scoring rules. Our result holds even for weighted voters, and
has applications for campaign management in commercial settings. We also give
approximation algorithms for our problem for two Condorcet-consistent rules,
namely, the Copeland rule and maximin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0346</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0346</id><created>2010-04-02</created><updated>2010-09-14</updated><authors><author><keyname>Joda</keyname><forenames>Roghayeh</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Network Code Design for Orthogonal Two-hop Network with Broadcasting
  Relay: A Joint Source-Channel-Network Coding Approach</title><categories>cs.IT math.IT</categories><comments>27 pages, 9 figures, Submited to IEEE Transaction on Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses network code design for robust transmission of sources
over an orthogonal two-hop wireless network with a broadcasting relay. The
network consists of multiple sources and destinations in which each
destination, benefiting the relay signal, intends to decode a subset of the
sources. Two special instances of this network are orthogonal broadcast relay
channel and the orthogonal multiple access relay channel. The focus is on
complexity constrained scenarios, e.g., for wireless sensor networks, where
channel coding is practically imperfect. Taking a source-channel and network
coding approach, we design the network code (mapping) at the relay such that
the average reconstruction distortion at the destinations is minimized. To this
end, by decomposing the distortion into its components, an efficient design
algorithm is proposed. The resulting network code is nonlinear and
substantially outperforms the best performing linear network code. A motivating
formulation of a family of structured nonlinear network codes is also
presented. Numerical results and comparison with linear network coding at the
relay and the corresponding distortion-power bound demonstrate the
effectiveness of the proposed schemes and a promising research direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0351</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0351</id><created>2010-04-02</created><authors><author><keyname>Srinivasagopalan</keyname><forenames>Srivathsan</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author><author><keyname>Iyengar</keyname><forenames>S. S.</forenames></author></authors><title>An Oblivious Spanning Tree for Buy-at-Bulk Network Design Problems</title><categories>cs.DS</categories><acm-class>E.1; C.2.1; F.2.2; G.1.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of constructing a single spanning tree for the
single-source buy-at-bulk network design problem for doubling-dimension graphs.
We compute a spanning tree to route a set of demands (or data) along a graph to
or from a designated root node. The demands could be aggregated at (or
symmetrically distributed to) intermediate nodes where the fusion-cost is
specified by a non-negative concave function $f$. We describe a novel approach
for developing an oblivious spanning tree in the sense that it is independent
of the number of data sources (or demands) and cost function at intermediate
nodes. To our knowledge, this is the first paper to propose a single spanning
tree solution to this problem (as opposed to multiple overlay trees). There has
been no prior work where the tree is oblivious to both the fusion cost function
and the set of sources (demands). We present a deterministic, polynomial-time
algorithm for constructing a spanning tree in low doubling graphs that
guarantees $\log^{3}D\cdot\log n$-approximation over the optimal cost, where
$D$ is the diameter of the graph and $n$ the total number of nodes. With
constant fusion-cost function our spanning tree gives a $O(\log^3
D)$-approximation for every Steiner tree to the root.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0366</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0366</id><created>2010-04-02</created><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author></authors><title>Dense Error-Correcting Codes in the Lee Metric</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several new applications and a number of new mathematical techniques have
increased the research on error-correcting codes in the Lee metric in the last
decade. In this work we consider several coding problems and constructions of
error-correcting codes in the Lee metric. First, we consider constructions of
dense error-correcting codes in relatively small dimensions over small
alphabets. The second problem we solve is construction of diametric perfect
codes with minimum distance four. We will construct such codes over various
lengths and alphabet sizes. The third problem is to transfer an n-dimensional
Lee sphere with large radius into a shape, with the same volume, located in a
relatively small box. Hadamard matrices play an essential role in the solutions
for all three problems. A construction of codes based on Hadamard matrices will
start our discussion. These codes approach the sphere packing bound for very
high rate range and appear to be the best known codes over some sets of
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0367</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0367</id><created>2010-04-01</created><authors><author><keyname>Hassan</keyname><forenames>Sk. Sarif</forenames></author><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>A Spatial Crypto Technique for Secure Data Transmission</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a spatial encryption technique for secured transmission
of data in networks. The algorithm is designed to break the ciphered data
packets into multiple data which are to be packaged into a spatial template. A
secure and efficient mechanism is provided to convey the information that is
necessary for obtaining the original data at the receiver-end from its parts in
the packets. An authentication code (MAC) is also used to ensure authenticity
of every packet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0377</identifier>
 <datestamp>2013-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0377</id><created>2010-04-02</created><updated>2013-10-22</updated><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Drucker</keyname><forenames>Andrew</forenames></author></authors><title>A Full Characterization of Quantum Advice</title><categories>quant-ph cs.CC</categories><comments>We fixed two significant issues: 1. The definition of YQP machines
  needed to be changed to preserve our results. The revised definition is more
  natural and has the same intuitive interpretation. 2. We needed properties of
  Local Hamiltonian reductions going beyond those proved in previous works
  (whose results we'd misstated). We now prove the needed properties. See p. 6
  for more on both points</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the following surprising result: given any quantum state rho on n
qubits, there exists a local Hamiltonian H on poly(n) qubits (e.g., a sum of
two-qubit interactions), such that any ground state of H can be used to
simulate rho on all quantum circuits of fixed polynomial size. In terms of
complexity classes, this implies that BQP/qpoly is contained in QMA/poly, which
supersedes the previous result of Aaronson that BQP/qpoly is contained in
PP/poly. Indeed, we can exactly characterize quantum advice, as equivalent in
power to untrusted quantum advice combined with trusted classical advice.
Proving our main result requires combining a large number of previous tools --
including a result of Alon et al. on learning of real-valued concept classes, a
result of Aaronson on the learnability of quantum states, and a result of
Aharonov and Regev on &quot;QMA+ super-verifiers&quot; -- and also creating some new
ones. The main new tool is a so-called majority-certificates lemma, which is
closely related to boosting in machine learning, and which seems likely to find
independent applications. In its simplest version, this lemma says the
following. Given any set S of Boolean functions on n variables, any function f
in S can be expressed as the pointwise majority of m=O(n) functions f1,...,fm
in S, such that each fi is the unique function in S compatible with O(log|S|)
input/output constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0378</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0378</id><created>2010-04-02</created><updated>2012-07-19</updated><authors><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Kiapour</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Safayani</keyname><forenames>Mehran</forenames></author><author><keyname>Manzuri</keyname><forenames>Mohammad T.</forenames></author><author><keyname>Shojaei</keyname><forenames>M.</forenames></author></authors><title>Facial Expression Representation and Recognition Using 2DHLDA, Gabor
  Wavelets, and Ensemble Learning</title><categories>cs.CV cs.LG</categories><comments>This paper has been withdrawn by the author due to an error in
  experimental results</comments><acm-class>I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel method for representation and recognition of the
facial expressions in two-dimensional image sequences is presented. We apply a
variation of two-dimensional heteroscedastic linear discriminant analysis
(2DHLDA) algorithm, as an efficient dimensionality reduction technique, to
Gabor representation of the input sequence. 2DHLDA is an extension of the
two-dimensional linear discriminant analysis (2DLDA) approach and it removes
the equal within-class covariance. By applying 2DHLDA in two directions, we
eliminate the correlations between both image columns and image rows. Then, we
perform a one-dimensional LDA on the new features. This combined method can
alleviate the small sample size problem and instability encountered by HLDA.
Also, employing both geometric and appearance features and using an ensemble
learning scheme based on data fusion, we create a classifier which can
efficiently classify the facial expressions. The proposed method is robust to
illumination changes and it can properly represent temporal information as well
as subtle changes in facial muscles. We provide experiments on Cohn-Kanade
database that show the superiority of the proposed method. KEYWORDS:
two-dimensional heteroscedastic linear discriminant analysis (2DHLDA), subspace
learning, facial expression analysis, Gabor wavelets, ensemble learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0381</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0381</id><created>2010-04-02</created><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Gossip and Distributed Kalman Filtering: Weak Consensus under Weak
  Detectability</title><categories>cs.IT math.DS math.IT math.OC math.PR</categories><comments>Submitted to the IEEE Transactions, 30 pages.</comments><doi>10.1109/TSP.2010.2100385</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents the gossip interactive Kalman filter (GIKF) for
distributed Kalman filtering for networked systems and sensor networks, where
inter-sensor communication and observations occur at the same time-scale. The
communication among sensors is random; each sensor occasionally exchanges its
filtering state information with a neighbor depending on the availability of
the appropriate network link. We show that under a weak distributed
detectability condition:
  1. the GIKF error process remains stochastically bounded, irrespective of the
instability properties of the random process dynamics; and
  2. the network achieves \emph{weak consensus}, i.e., the conditional
estimation error covariance at a (uniformly) randomly selected sensor converges
in distribution to a unique invariant measure on the space of positive
semi-definite matrices (independent of the initial state.)
  To prove these results, we interpret the filtered states (estimates and error
covariances) at each node in the GIKF as stochastic particles with local
interactions. We analyze the asymptotic properties of the error process by
studying as a random dynamical system the associated switched (random) Riccati
equation, the switching being dictated by a non-stationary Markov chain on the
network graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0382</identifier>
 <datestamp>2011-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0382</id><created>2010-04-02</created><updated>2011-04-03</updated><authors><author><keyname>Draganescu</keyname><forenames>Andrei</forenames></author><author><keyname>Petra</keyname><forenames>Cosmin</forenames></author></authors><title>Multigrid preconditioning of linear systems for interior point methods
  applied to a class of box-constrained optimal control problems</title><categories>math.NA cs.SY math.OC</categories><comments>29 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we construct and analyze multigrid preconditioners for
discretizations of operators of the form D+K* K, where D is the multiplication
with a relatively smooth positive function and K is a compact linear operator.
These systems arise when applying interior point methods to the minimization
problem min_u (||K u-f||^2 +b||u||^2) with box-constraints on the controls u.
The presented preconditioning technique is closely related to the one developed
by Draganescu and Dupont in [11] for the associated unconstrained problem, and
is intended for large-scale problems. As in [11], the quality of the resulting
preconditioners is shown to increase with increasing resolution but decreases
as the diagonal of D becomes less smooth. We test this algorithm first on a
Tikhonov-regularized backward parabolic equation with box-constraints on the
control, and then on a standard elliptic-constrained optimization problem. In
both cases it is shown that the number of linear iterations per optimization
step, as well as the total number of fine-scale matrix-vector multiplications
is decreasing with increasing resolution, thus showing the method to be
potentially very efficient for truly large-scale problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0383</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0383</id><created>2010-04-02</created><updated>2010-04-16</updated><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Multiuser Diversity Gain in Cognitive Networks</title><categories>cs.IT math.IT</categories><comments>32 pages, 3 figures, to appear in the IEEE/ACM Transactions on
  Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic allocation of resources to the \emph{best} link in large multiuser
networks offers considerable improvement in spectral efficiency. This gain,
often referred to as \emph{multiuser diversity gain}, can be cast as
double-logarithmic growth of the network throughput with the number of users.
In this paper we consider large cognitive networks granted concurrent spectrum
access with license-holding users. The primary network affords to share its
under-utilized spectrum bands with the secondary users. We assess the optimal
multiuser diversity gain in the cognitive networks by quantifying how the
sum-rate throughput of the network scales with the number of secondary users.
For this purpose we look at the optimal pairing of spectrum bands and secondary
users, which is supervised by a central entity fully aware of the instantaneous
channel conditions, and show that the throughput of the cognitive network
scales double-logarithmically with the number of secondary users ($N$) and
linearly with the number of available spectrum bands ($M$), i.e., $M\log\log
N$. We then propose a \emph{distributed} spectrum allocation scheme, which does
not necessitate a central controller or any information exchange between
different secondary users and still obeys the optimal throughput scaling law.
This scheme requires that \emph{some} secondary transmitter-receiver pairs
exchange $\log M$ information bits among themselves. We also show that the
aggregate amount of information exchange between secondary transmitter-receiver
pairs is {\em asymptotically} equal to $M\log M$. Finally, we show that our
distributed scheme guarantees fairness among the secondary users, meaning that
they are equally likely to get access to an available spectrum band.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0393</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0393</id><created>2010-04-02</created><updated>2011-02-28</updated><authors><author><keyname>Burdis</keyname><forenames>Joseph M.</forenames></author><author><keyname>Kogan</keyname><forenames>Irina A.</forenames></author></authors><title>Object-image correspondence for curves under finite and affine cameras</title><categories>cs.CV math.AG</categories><comments>19 pages, 2 figures. This version considers the case of rational
  algebraic curves</comments><msc-class>14H50, 14Q05, 68T45</msc-class><acm-class>I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide criteria for deciding whether a given planar curve is an image of
a given spatial curve, obtained by a central or a parallel projection with
unknown parameters. These criteria reduce the projection problem to a certain
modification of the equivalence problem of planar curves under affine and
projective transformations. The latter problem can be addressed using Cartan's
moving frame method. This leads to a novel algorithmic solution of the
projection problem for curves. The computational advantage of the algorithms
presented here, in comparison to algorithms based on a straightforward
solution, lies in a significant reduction of a number of real parameters that
has to be eliminated in order to establish existence or non-existence of a
projection that maps a given spatial curve to a given planar curve. The same
approach can be used to decide whether a given finite set of ordered points on
a plane is an image of a given finite set of ordered points in R^3. The
motivation comes from the problem of establishing a correspondence between an
object and an image, taken by a camera with unknown position and parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0395</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0395</id><created>2010-04-02</created><updated>2010-08-09</updated><authors><author><keyname>Menasche</keyname><forenames>Daniel S.</forenames></author><author><keyname>Rocha</keyname><forenames>Antonio A. A.</forenames></author><author><keyname>Silva</keyname><forenames>Edmundo A. de Souza e</forenames></author><author><keyname>Leao</keyname><forenames>Rosa M.</forenames></author><author><keyname>Towsley</keyname><forenames>Don</forenames></author><author><keyname>Venkataramani</keyname><forenames>Arun</forenames></author></authors><title>Estimating Self-Sustainability in Peer-to-Peer Swarming Systems</title><categories>cs.NI cs.PF</categories><comments>27 pages, 5 figures</comments><acm-class>C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer swarming is one of the \emph{de facto} solutions for distributed
content dissemination in today's Internet. By leveraging resources provided by
clients, swarming systems reduce the load on and costs to publishers. However,
there is a limit to how much cost savings can be gained from swarming; for
example, for unpopular content peers will always depend on the publisher in
order to complete their downloads. In this paper, we investigate this
dependence. For this purpose, we propose a new metric, namely \emph{swarm
self-sustainability}. A swarm is referred to as self-sustaining if all its
blocks are collectively held by peers; the self-sustainability of a swarm is
the fraction of time in which the swarm is self-sustaining. We pose the
following question: how does the self-sustainability of a swarm vary as a
function of content popularity, the service capacity of the users, and the size
of the file? We present a model to answer the posed question. We then propose
efficient solution methods to compute self-sustainability. The accuracy of our
estimates is validated against simulation. Finally, we also provide closed-form
expressions for the fraction of time that a given number of blocks is
collectively held by peers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0397</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0397</id><created>2010-04-02</created><authors><author><keyname>Leconte</keyname><forenames>Mathieu</forenames></author><author><keyname>Ni</keyname><forenames>Jian</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author></authors><title>Mixing Time of Glauber Dynamics With Parallel Updates and Heterogeneous
  Fugacities</title><categories>math.PR cs.DM cs.NI</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Glauber dynamics is a powerful tool to generate randomized, approximate
solutions to combinatorially difficult problems. Applications include Markov
Chain Monte Carlo (MCMC) simulation and distributed scheduling for wireless
networks. In this paper, we derive bounds on the mixing time of a
generalization of Glauber dynamics where multiple vertices are allowed to
update their states in parallel and the fugacity of each vertex can be
different. The results can be used to obtain various conditions on the system
parameters such as fugacities, vertex degrees and update probabilities, under
which the mixing time grows polynomially in the number of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0400</identifier>
 <datestamp>2012-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0400</id><created>2010-04-02</created><updated>2012-02-15</updated><authors><author><keyname>Dalai</keyname><forenames>Marco</forenames></author></authors><title>A new bound for the capacity of the deletion channel with high deletion
  probabilities</title><categories>cs.IT math.IT</categories><comments>ISIT 2011, the first draft contained an error in some expressions (a
  log(n) in place of log(n+1))</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $C(d)$ be the capacity of the binary deletion channel with deletion
probability $d$. It was proved by Drinea and Mitzenmacher that, for all $d$,
$C(d)/(1-d)\geq 0.1185 $. Fertonani and Duman recently showed that
$\limsup_{d\to 1}C(d)/(1-d)\leq 0.49$. In this paper, it is proved that
$\lim_{d\to 1}C(d)/(1-d)$ exists and is equal to $\inf_{d}C(d)/(1-d)$. This
result suggests the conjecture that the curve $C(d)$ my be convex in the
interval $d\in [0,1]$. Furthermore, using currently known bounds for $C(d)$, it
leads to the upper bound $\lim_{d\to 1}C(d)/(1-d)\leq 0.4143$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0402</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0402</id><created>2010-04-02</created><authors><author><keyname>Khajehnejad</keyname><forenames>M. Amin</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Avestimehr</keyname><forenames>Salman</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Improved Sparse Recovery Thresholds with Two-Step Reweighted $\ell_1$
  Minimization</title><categories>cs.IT math.IT</categories><comments>accepted in ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that $\ell_1$ minimization can be used to recover
sufficiently sparse unknown signals from compressed linear measurements. In
fact, exact thresholds on the sparsity, as a function of the ratio between the
system dimensions, so that with high probability almost all sparse signals can
be recovered from iid Gaussian measurements, have been computed and are
referred to as &quot;weak thresholds&quot; \cite{D}. In this paper, we introduce a
reweighted $\ell_1$ recovery algorithm composed of two steps: a standard
$\ell_1$ minimization step to identify a set of entries where the signal is
likely to reside, and a weighted $\ell_1$ minimization step where entries
outside this set are penalized. For signals where the non-sparse component has
iid Gaussian entries, we prove a &quot;strict&quot; improvement in the weak recovery
threshold. Simulations suggest that the improvement can be quite
impressive-over 20% in the example we consider.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0403</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0403</id><created>2010-04-02</created><authors><author><keyname>Colantonio</keyname><forenames>Alessandro</forenames></author><author><keyname>Di Pietro</keyname><forenames>Roberto</forenames></author></authors><title>CONCISE: Compressed 'n' Composable Integer Set</title><categories>cs.DS</categories><comments>Preprint submitted to Information Processing Letters, 7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bit arrays, or bitmaps, are used to significantly speed up set operations in
several areas, such as data warehousing, information retrieval, and data
mining, to cite a few. However, bitmaps usually use a large storage space, thus
requiring compression. Nevertheless, there is a space-time tradeoff among
compression schemes. The Word Aligned Hybrid (WAH) bitmap compression trades
some space to allow for bitwise operations without first decompressing bitmaps.
WAH has been recognized as the most efficient scheme in terms of computation
time. In this paper we present CONCISE (Compressed 'n' Composable Integer Set),
a new scheme that enjoys significatively better performances than those of WAH.
In particular, when compared to WAH, our algorithm is able to reduce the
required memory up to 50%, by having similar or better performance in terms of
computation time. Further, we show that CONCISE can be efficiently used to
manipulate bitmaps representing sets of integral numbers in lieu of well-known
data structures such as arrays, lists, hashtables, and self-balancing binary
search trees. Extensive experiments over synthetic data show the effectiveness
of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0411</identifier>
 <datestamp>2011-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0411</id><created>2010-04-02</created><updated>2011-06-21</updated><authors><author><keyname>Beigi</keyname><forenames>Salman</forenames></author><author><keyname>Shor</keyname><forenames>Peter W.</forenames></author><author><keyname>Watrous</keyname><forenames>John</forenames></author></authors><title>Quantum interactive proofs with short messages</title><categories>quant-ph cs.CC</categories><comments>15 pages, published version</comments><journal-ref>Theory of Computing 7, 101-117 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers three variants of quantum interactive proof systems in
which short (meaning logarithmic-length) messages are exchanged between the
prover and verifier. The first variant is one in which the verifier sends a
short message to the prover, and the prover responds with an ordinary, or
polynomial-length, message; the second variant is one in which any number of
messages can be exchanged, but where the combined length of all the messages is
logarithmic; and the third variant is one in which the verifier sends
polynomially many random bits to the prover, who responds with a short quantum
message. We prove that in all of these cases the short messages can be
eliminated without changing the power of the model, so the first variant has
the expressive power of QMA and the second and third variants have the
expressive power of BQP. These facts are proved through the use of quantum
state tomography, along with the finite quantum de Finetti theorem for the
first variant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0421</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0421</id><created>2010-04-03</created><authors><author><keyname>Norman</keyname><forenames>Jasmine</forenames><affiliation>Measi Institute of Information Technology, India</affiliation></author><author><keyname>Joseph</keyname><forenames>J. Paulraj</forenames><affiliation>Manonmaniam Sundaranar University, India and</affiliation></author><author><keyname>Roja</keyname><forenames>P. Prapoorna</forenames><affiliation>Jerusalem College of Engineering, India</affiliation></author></authors><title>A Faster Routing Scheme for Stationary Wireless Sensor Networks - A
  Hybrid Approach</title><categories>cs.NI</categories><comments>10 pages</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing 1.1
  (2010) 1-10</journal-ref><doi>10.5121/ijasuc.2010.1101</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A wireless sensor network consists of light-weight, low power, small size
sensor nodes. Routing in wireless sensor networks is a demanding task. This
demand has led to a number of routing protocols which efficiently utilize the
limited resources available at the sensor nodes. Most of these protocols are
either based on single hop routing or multi hop routing and typically find the
minimum energy path without addressing other issues such as time delay in
delivering a packet, load balancing, and redundancy of data. Response time is
very critical in environment monitoring sensor networks where typically the
sensors are stationary and transmit data to a base station or a sink node. In
this paper a faster load balancing routing protocol based on location with a
hybrid approach is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0422</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0422</id><created>2010-04-03</created><authors><author><keyname>Hossain</keyname><forenames>Anwar</forenames></author><author><keyname>Tarique</keyname><forenames>Mohammed</forenames></author><author><keyname>Islam</keyname><forenames>Rumana</forenames></author></authors><title>Shadowing Effects on Routing Protocol of Multihop Ad Hoc Networks</title><categories>cs.NI</categories><comments>16 Pages</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing 1.1
  (2010) 12-28</journal-ref><doi>10.5121/ijasuc.2010.1102</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Two-ray ground reflection model has been widely used as the propagation model
to investigate the performance of an ad hoc network. But two-ray model is too
simple to represent a real world network. A more realistic model namely
shadowing propagation model has been used in this investigation. Under
shadowing propagation model, a mobile node may receive a packet at a signal
level that is below a required threshold level. This low signal level affects
the routing protocol as well as the medium access control protocol of a
network. An analytical model has been presented in this paper to investigate
the shadowing effects on the network performance. The analytical model has been
verified via simulation results. Simulation results show that the performance
of a network becomes very poor if shadowing propagation model is used in
compare to the simple two-ray model. Two solutions have also been proposed in
this paper to overcome the effects of shadowing. One solution is a physical
layer solution and the other one is a Medium Access Control (MAC) layer
solution. Simulation results show that these two solutions reduce the shadowing
effect and improve network performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0424</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0424</id><created>2010-04-03</created><updated>2010-06-27</updated><authors><author><keyname>Clifford</keyname><forenames>Rapha&#xeb;l</forenames></author><author><keyname>Gotthilf</keyname><forenames>Zvi</forenames></author><author><keyname>Lewenstein</keyname><forenames>Moshe</forenames></author><author><keyname>Popa</keyname><forenames>Alexandru</forenames></author></authors><title>Restricted Common Superstring and Restricted Common Supersequence</title><categories>cs.DS</categories><comments>Submitted to WAOA 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The {\em shortest common superstring} and the {\em shortest common
supersequence} are two well studied problems having a wide range of
applications. In this paper we consider both problems with resource
constraints, denoted as the Restricted Common Superstring (shortly
\textit{RCSstr}) problem and the Restricted Common Supersequence (shortly
\textit{RCSseq}). In the \textit{RCSstr} (\textit{RCSseq}) problem we are given
a set $S$ of $n$ strings, $s_1$, $s_2$, $\ldots$, $s_n$, and a multiset $t =
\{t_1, t_2, \dots, t_m\}$, and the goal is to find a permutation $\pi : \{1,
\dots, m\} \to \{1, \dots, m\}$ to maximize the number of strings in $S$ that
are substrings (subsequences) of $\pi(t) = t_{\pi(1)}t_{\pi(2)}...t_{\pi(m)}$
(we call this ordering of the multiset, $\pi(t)$, a permutation of $t$). We
first show that in its most general setting the \textit{RCSstr} problem is {\em
NP-complete} and hard to approximate within a factor of $n^{1-\epsilon}$, for
any $\epsilon &gt; 0$, unless P = NP. Afterwards, we present two separate
reductions to show that the \textit{RCSstr} problem remains NP-Hard even in the
case where the elements of $t$ are drawn from a binary alphabet or for the case
where all input strings are of length two. We then present some approximation
results for several variants of the \textit{RCSstr} problem. In the second part
of this paper, we turn to the \textit{RCSseq} problem, where we present some
hardness results, tight lower bounds and approximation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0436</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0436</id><created>2010-04-03</created><authors><author><keyname>Zhang</keyname><forenames>Zhiqiang</forenames></author><author><keyname>Shi</keyname><forenames>Yaoyun</forenames></author></authors><title>On the parity complexity measures of Boolean functions</title><categories>cs.CC</categories><comments>submitted to TCS on 16-MAR-2009</comments><doi>10.1016/j.tcs.2010.03.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parity decision tree model extends the decision tree model by allowing
the computation of a parity function in one step. We prove that the
deterministic parity decision tree complexity of any Boolean function is
polynomially related to the non-deterministic complexity of the function or its
complement. We also show that they are polynomially related to an analogue of
the block sensitivity. We further study parity decision trees in their
relations with an intermediate variant of the decision trees, as well as with
communication complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0438</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0438</id><created>2010-04-03</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>User-driven applications</title><categories>cs.HC</categories><comments>33 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User-driven applications are the programs, in which the full control is given
to the users. Designers of such programs are responsible only for developing an
instrument for solving some task, but they do not enforce users to work with
this instrument according with the predefined scenario. Users' control of the
applications means that only users decide at any moment WHAT, WHEN, and HOW
must appear on the screen. Such applications can be constructed only on the
basis of moveable / resizable elements. Programs, based on such elements, have
very interesting features and open absolutely new possibilities. This article
describes the design of the user-driven applications and shows the consequences
of switching to such type of programs on the samples from different areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0456</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0456</id><created>2010-04-03</created><authors><author><keyname>H&#xe9;brail</keyname><forenames>Georges</forenames></author><author><keyname>Hugueney</keyname><forenames>Bernard</forenames></author><author><keyname>Lechevallier</keyname><forenames>Yves</forenames></author><author><keyname>Rossi</keyname><forenames>Fabrice</forenames></author></authors><title>Exploratory Analysis of Functional Data via Clustering and Optimal
  Segmentation</title><categories>stat.ML cs.LG</categories><journal-ref>Neurocomputing, Volume 73, Issues 7-9, March 2010, Pages 1125-1141</journal-ref><doi>10.1016/j.neucom.2009.11.022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose in this paper an exploratory analysis algorithm for functional
data. The method partitions a set of functions into $K$ clusters and represents
each cluster by a simple prototype (e.g., piecewise constant). The total number
of segments in the prototypes, $P$, is chosen by the user and optimally
distributed among the clusters via two dynamic programming algorithms. The
practical relevance of the method is shown on two real world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0458</identifier>
 <datestamp>2012-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0458</id><created>2010-04-03</created><updated>2012-06-25</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Hsieh</keyname><forenames>Min-Hsiu</forenames></author></authors><title>The quantum dynamic capacity formula of a quantum channel</title><categories>quant-ph cs.IT math.IT</categories><comments>24 pages, 3 figures; v2 has improved structure and minor corrections;
  v3 has correction regarding the optimization</comments><journal-ref>Quantum Information Processing, vol. 11, no. 6, pp. 1431-1463
  (2012)</journal-ref><doi>10.1007/s11128-011-0310-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamic capacity theorem characterizes the reliable communication rates
of a quantum channel when combined with the noiseless resources of classical
communication, quantum communication, and entanglement. In prior work, we
proved the converse part of this theorem by making contact with many previous
results in the quantum Shannon theory literature. In this work, we prove the
theorem with an &quot;ab initio&quot; approach, using only the most basic tools in the
quantum information theorist's toolkit: the Alicki-Fannes' inequality, the
chain rule for quantum mutual information, elementary properties of quantum
entropy, and the quantum data processing inequality. The result is a simplified
proof of the theorem that should be more accessible to those unfamiliar with
the quantum Shannon theory literature. We also demonstrate that the &quot;quantum
dynamic capacity formula&quot; characterizes the Pareto optimal trade-off surface
for the full dynamic capacity region. Additivity of this formula simplifies the
computation of the trade-off surface, and we prove that its additivity holds
for the quantum Hadamard channels and the quantum erasure channel. We then
determine exact expressions for and plot the dynamic capacity region of the
quantum dephasing channel, an example from the Hadamard class, and the quantum
erasure channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0459</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0459</id><created>2010-04-03</created><authors><author><keyname>Dey</keyname><forenames>Sandipan</forenames></author><author><keyname>Al-Qaheri</keyname><forenames>Hameed</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Embedding Secret Data in HTML Web Page</title><categories>cs.CR</categories><comments>10 Pages, 6 Figures, 2 Algorithms,1st International Conference on
  Image Processing and Communications, September 16-18, 2009, Bydgoszcz,
  Poland.</comments><journal-ref>Published in book: Image Processing &amp; Communications Challenges,
  Ed. Ryszard S. Choras and Antoni Zabtudowski, Academy Publishing House EXIT,
  Warsaw 2009, pp. 474-481. ISBN: 978-83-60434-62-8.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we suggest a novel data hiding technique in an HTML Web page.
HTML Tags are case insensitive and hence an alphabet in lowercase and one in
uppercase present inside an HTML tag are interpreted in the same manner by the
browser,i.e., change in case in an web page is imperceptible to the browser. We
basically exploit this redundancy and use it to embed secret data inside an web
page, with no changes visible to the user of the web page, so that he can not
even suspect about the data hiding. The embedded data can be recovered by
viewing the source of the HTML page. This technique can easily be extended to
embed secret message inside any piece of source-code where the standard
interpreter of that language is case-insensitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0477</identifier>
 <datestamp>2011-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0477</id><created>2010-04-03</created><updated>2011-02-03</updated><authors><author><keyname>Mazo</keyname><forenames>Manuel</forenames><suffix>Jr.</suffix></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>Decentralized event-triggered control over wireless sensor/actuator
  networks</title><categories>math.OC cs.SY</categories><comments>13 pages, 3 figures, journal submission</comments><msc-class>93C10, 93C30, 93C57, 93C95</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years we have witnessed a move of the major industrial automation
providers into the wireless domain. While most of these companies already offer
wireless products for measurement and monitoring purposes, the ultimate goal is
to be able to close feedback loops over wireless networks interconnecting
sensors, computation devices, and actuators. In this paper we present a
decentralized event-triggered implementation, over sensor/actuator networks, of
centralized nonlinear controllers. Event-triggered control has been recently
proposed as an alternative to the more traditional periodic execution of
control tasks. In a typical event-triggered implementation, the control signals
are kept constant until the violation of a condition on the state of the plant
triggers the re-computation of the control signals. The possibility of reducing
the number of re-computations, and thus of transmissions, while guaranteeing
desired levels of performance makes event-triggered control very appealing in
the context of sensor/actuator networks. In these systems the communication
network is a shared resource and event-triggered implementations of control
laws offer a flexible way to reduce network utilization. Moreover reducing the
number of times that a feedback control law is executed implies a reduction in
transmissions and thus a reduction in energy expenditures of battery powered
wireless sensor nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0512</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0512</id><created>2010-04-04</created><authors><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Kiapour</keyname><forenames>Mohammad Hadi</forenames></author><author><keyname>Manzuri-Shalmani</keyname><forenames>Mohammad T.</forenames></author><author><keyname>Kiaei</keyname><forenames>Ali A.</forenames></author></authors><title>Analysis, Interpretation, and Recognition of Facial Action Units and
  Expressions Using Neuro-Fuzzy Modeling</title><categories>cs.CV</categories><journal-ref>LNAI vol. 5998, pp. 161--172, Springer, Heidelberg (Proc. of 4th
  IAPR Workshop on Artificial Neural Networks in Pattern Recognition), 2010.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper an accurate real-time sequence-based system for representation,
recognition, interpretation, and analysis of the facial action units (AUs) and
expressions is presented. Our system has the following characteristics: 1)
employing adaptive-network-based fuzzy inference systems (ANFIS) and temporal
information, we developed a classification scheme based on neuro-fuzzy modeling
of the AU intensity, which is robust to intensity variations, 2) using both
geometric and appearance-based features, and applying efficient dimension
reduction techniques, our system is robust to illumination changes and it can
represent the subtle changes as well as temporal information involved in
formation of the facial expressions, and 3) by continuous values of intensity
and employing top-down hierarchical rule-based classifiers, we can develop
accurate human-interpretable AU-to-expression converters. Extensive experiments
on Cohn-Kanade database show the superiority of the proposed method, in
comparison with support vector machines, hidden Markov models, and neural
network classifiers. Keywords: biased discriminant analysis (BDA), classifier
design and evaluation, facial action units (AUs), hybrid learning, neuro-fuzzy
modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0514</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0514</id><created>2010-04-04</created><authors><author><keyname>Koppaka</keyname><forenames>Sisir</forenames></author><author><keyname>Hota</keyname><forenames>Ashish Ranjan</forenames></author></authors><title>Superior Exploration-Exploitation Balance with Quantum-Inspired Hadamard
  Walks</title><categories>cs.NE</categories><comments>2 pages, 2 figures, 1 table, late-breaking</comments><acm-class>I.2.8</acm-class><journal-ref>In Proceedings of the 12th annual conference companion on Genetic
  and evolutionary computation (GECCO '10). ACM, New York, NY, USA, 2093-2094</journal-ref><doi>10.1145/1830761.1830878</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends the analogies employed in the development of
quantum-inspired evolutionary algorithms by proposing quantum-inspired Hadamard
walks, called QHW. A novel quantum-inspired evolutionary algorithm, called
HQEA, for solving combinatorial optimization problems, is also proposed. The
novelty of HQEA lies in it's incorporation of QHW Remote Search and QHW Local
Search - the quantum equivalents of classical mutation and local search, that
this paper defines. The intuitive reasoning behind this approach, and the
exploration-exploitation balance thus occurring is explained. From the results
of the experiments carried out on the 0,1-knapsack problem, HQEA performs
significantly better than a conventional genetic algorithm, CGA, and two
quantum-inspired evolutionary algorithms - QEA and NQEA, in terms of
convergence speed and accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0515</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0515</id><created>2010-04-04</created><authors><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Manzuri-Shalmani</keyname><forenames>Mohammad T.</forenames></author><author><keyname>Kiapour</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Kiaei</keyname><forenames>Ali A.</forenames></author></authors><title>Recognizing Combinations of Facial Action Units with Different Intensity
  Using a Mixture of Hidden Markov Models and Neural Network</title><categories>cs.CV cs.LG</categories><journal-ref>LNCS vol. 5997, pp. 304--313, Springer, Heidelberg (Proc. of 9th
  IAPR Workshop on Multiple Classifier Systems), 2010.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facial Action Coding System consists of 44 action units (AUs) and more than
7000 combinations. Hidden Markov models (HMMs) classifier has been used
successfully to recognize facial action units (AUs) and expressions due to its
ability to deal with AU dynamics. However, a separate HMM is necessary for each
single AU and each AU combination. Since combinations of AU numbering in
thousands, a more efficient method will be needed. In this paper an accurate
real-time sequence-based system for representation and recognition of facial
AUs is presented. Our system has the following characteristics: 1) employing a
mixture of HMMs and neural network, we develop a novel accurate classifier,
which can deal with AU dynamics, recognize subtle changes, and it is also
robust to intensity variations, 2) although we use an HMM for each single AU
only, by employing a neural network we can recognize each single and
combination AU, and 3) using both geometric and appearance-based features, and
applying efficient dimension reduction techniques, our system is robust to
illumination changes and it can represent the temporal information involved in
formation of the facial expressions. Extensive experiments on Cohn-Kanade
database show the superiority of the proposed method, in comparison with other
classifiers. Keywords: classifier design and evaluation, data fusion, facial
action units (AUs), hidden Markov models (HMMs), neural network (NN).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0517</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0517</id><created>2010-04-04</created><authors><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author><author><keyname>Safayani</keyname><forenames>Mehran</forenames></author><author><keyname>Manzuri-Shalmani</keyname><forenames>Mohammad T.</forenames></author></authors><title>Multilinear Biased Discriminant Analysis: A Novel Method for Facial
  Action Unit Representation</title><categories>cs.CV cs.LG</categories><comments>Proc. of 16th Korea-Japan Joint Workshop on Frontiers of Computer
  Vision, Hiroshima, Japan, 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel efficient method for representation of facial action
units by encoding an image sequence as a fourth-order tensor is presented. The
multilinear tensor-based extension of the biased discriminant analysis (BDA)
algorithm, called multilinear biased discriminant analysis (MBDA), is first
proposed. Then, we apply the MBDA and two-dimensional BDA (2DBDA) algorithms,
as the dimensionality reduction techniques, to Gabor representations and the
geometric features of the input image sequence respectively. The proposed
scheme can deal with the asymmetry between positive and negative samples as
well as curse of dimensionality dilemma. Extensive experiments on Cohn-Kanade
database show the superiority of the proposed method for representation of the
subtle changes and the temporal information involved in formation of the facial
expressions. As an accurate tool, this representation can be applied to many
areas such as recognition of spontaneous and deliberate facial expressions,
multi modal/media human computer interaction and lie detection efforts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0526</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0526</id><created>2010-04-04</created><updated>2011-07-08</updated><authors><author><keyname>Crowston</keyname><forenames>R.</forenames></author><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Jones</keyname><forenames>M.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>A New Lower Bound on the Maximum Number of Satisfied Clauses in Max-SAT
  and its Algorithmic Applications</title><categories>cs.DS cs.DM</categories><doi>10.1007/978-3-642-17493-3_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pair of unit clauses is called conflicting if it is of the form $(x)$,
$(\bar{x})$. A CNF formula is unit-conflict free (UCF) if it contains no pair
of conflicting unit clauses. Lieberherr and Specker (J. ACM 28, 1981) showed
that for each UCF CNF formula with $m$ clauses we can simultaneously satisfy at
least $\pp m$ clauses, where $\pp =(\sqrt{5}-1)/2$. We improve the
Lieberherr-Specker bound by showing that for each UCF CNF formula $F$ with $m$
clauses we can find, in polynomial time, a subformula $F'$ with $m'$ clauses
such that we can simultaneously satisfy at least $\pp m+(1-\pp)m'+(2-3\pp)n&quot;/2$
clauses (in $F$), where $n&quot;$ is the number of variables in $F$ which are not in
$F'$.
  We consider two parameterized versions of MAX-SAT, where the parameter is the
number of satisfied clauses above the bounds $m/2$ and $m(\sqrt{5}-1)/2$. The
former bound is tight for general formulas, and the later is tight for UCF
formulas. Mahajan and Raman (J. Algorithms 31, 1999) showed that every instance
of the first parameterized problem can be transformed, in polynomial time, into
an equivalent one with at most $6k+3$ variables and $10k$ clauses. We improve
this to $4k$ variables and $(2\sqrt{5}+4)k$ clauses. Mahajan and Raman
conjectured that the second parameterized problem is fixed-parameter tractable
(FPT). We show that the problem is indeed FPT by describing a polynomial-time
algorithm that transforms any problem instance into an equivalent one with at
most $(7+3\sqrt{5})k$ variables. Our results are obtained using our improvement
of the Lieberherr-Specker bound above.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0534</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0534</id><created>2010-04-04</created><updated>2012-08-31</updated><authors><author><keyname>Pawe&#x142;czak</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Joshi</keyname><forenames>Shaunak</forenames></author><author><keyname>Addepalli</keyname><forenames>Sateesh</forenames></author><author><keyname>Villasenor</keyname><forenames>John</forenames></author><author><keyname>&#x10c;abri&#x107;</keyname><forenames>Danijela</forenames></author></authors><title>Impact of Connection Admission Process on the Direct Retry Load
  Balancing Algorithm in Cellular Network</title><categories>cs.NI cs.IT cs.PF math.IT</categories><comments>accepted to IEEE Transactions on Mobile Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analytical framework for modeling a priority-based load
balancing scheme in cellular networks based on a new algorithm called direct
retry with truncated offloading channel resource pool (DR$_{K}$). The model,
developed for a baseline case of two cell network, differs in many respects
from previous works on load balancing. Foremost, it incorporates the call
admission process, through random access. In specific, the proposed model
implements the Physical Random Access Channel used in 3GPP network standards.
Furthermore, the proposed model allows the differentiation of users based on
their priorities. The quantitative results illustrate that, for example,
cellular network operators can control the manner in which traffic is offloaded
between neighboring cells by simply adjusting the length of the random access
phase. Our analysis also allows for the quantitative determination of the
blocking probability individual users will experience given a specific length
of random access phase. Furthermore, we observe that the improvement in
blocking probability per shared channel for load balanced users using DR$_{K}$
is maximized at an intermediate number of shared channels, as opposed to the
maximum number of these shared resources. This occurs because a balance is
achieved between the number of users requesting connections and those that are
already admitted to the network. We also present an extension of our analytical
model to a multi-cell network (by means of an approximation) and an application
of the proposed load balancing scheme in the context of opportunistic spectrum
access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0542</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0542</id><created>2010-04-04</created><updated>2011-11-22</updated><authors><author><keyname>Levorato</keyname><forenames>Marco</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author><author><keyname>Zorzi</keyname><forenames>Michele</forenames></author></authors><title>Cognitive Interference Management in Retransmission-Based Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>accepted for publication on Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio methodologies have the potential to dramatically increase the
throughput of wireless systems. Herein, control strategies which enable the
superposition in time and frequency of primary and secondary user transmissions
are explored in contrast to more traditional sensing approaches which only
allow the secondary user to transmit when the primary user is idle. In this
work, the optimal transmission policy for the secondary user when the primary
user adopts a retransmission based error control scheme is investigated. The
policy aims to maximize the secondary users' throughput, with a constraint on
the throughput loss and failure probability of the primary user. Due to the
constraint, the optimal policy is randomized, and determines how often the
secondary user transmits according to the retransmission state of the packet
being served by the primary user. The resulting optimal strategy of the
secondary user is proven to have a unique structure. In particular, the optimal
throughput is achieved by the secondary user by concentrating its transmission,
and thus its interference to the primary user, in the first transmissions of a
primary user packet. The rather simple framework considered in this paper
highlights two fundamental aspects of cognitive networks that have not been
covered so far: (i) the networking mechanisms implemented by the primary users
(error control by means of retransmissions in the considered model) react to
secondary users' activity; (ii) if networking mechanisms are considered, then
their state must be taken into account when optimizing secondary users'
strategy, i.e., a strategy based on a binary active/idle perception of the
primary users' state is suboptimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0557</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0557</id><created>2010-04-04</created><updated>2010-04-07</updated><authors><author><keyname>Korada</keyname><forenames>Satish Babu</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Applications of Lindeberg Principle in Communications and Statistical
  Learning</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use a generalization of the Lindeberg principle developed by Sourav
Chatterjee to prove universality properties for various problems in
communications, statistical learning and random matrix theory. We also show
that these systems can be viewed as the limiting case of a properly defined
sparse system. The latter result is useful when the sparse systems are easier
to analyze than their dense counterparts. The list of problems we consider is
by no means exhaustive. We believe that the ideas can be used in many other
problems relevant for information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0558</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0558</id><created>2010-04-04</created><updated>2010-12-15</updated><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Das</keyname><forenames>Sandip</forenames></author><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author><author><keyname>Nandy</keyname><forenames>Subhas</forenames></author><author><keyname>Roy</keyname><forenames>Sasanka</forenames></author><author><keyname>Sarvattomananda</keyname><forenames>Swami</forenames></author></authors><title>Querying for the Largest Empty Geometric Object in a Desired Location</title><categories>cs.CG cs.DS</categories><comments>This version is a significant update of our earlier submission
  arXiv:1004.0558v1. Apart from new variants studied in Sections 3 and 4, the
  results have been improved in Section 5.Please note that the change in title
  and abstract indicate that we have expanded the scope of the problems we
  study</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study new types of geometric query problems defined as follows: given a
geometric set $P$, preprocess it such that given a query point $q$, the
location of the largest circle that does not contain any member of $P$, but
contains $q$ can be reported efficiently. The geometric sets we consider for
$P$ are boundaries of convex and simple polygons, and point sets. While we
primarily focus on circles as the desired shape, we also briefly discuss empty
rectangles in the context of point sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0567</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0567</id><created>2010-04-05</created><authors><author><keyname>Chen</keyname><forenames>Rung-Ching</forenames><affiliation>Chaoyang University of Technology, Taiwan</affiliation></author><author><keyname>Cheng</keyname><forenames>Kai-Fan</forenames><affiliation>Chaoyang University of Technology, Taiwan</affiliation></author><author><keyname>Hsieh</keyname><forenames>Chia-Fen</forenames><affiliation>Chaoyang University of Technology, Taiwan</affiliation></author></authors><title>Using Rough Set and Support Vector Machine for Network Intrusion
  Detection</title><categories>cs.LG cs.CR cs.NI</categories><comments>13 Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.1
  (2009) 1-13</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The main function of IDS (Intrusion Detection System) is to protect the
system, analyze and predict the behaviors of users. Then these behaviors will
be considered an attack or a normal behavior. Though IDS has been developed for
many years, the large number of return alert messages makes managers maintain
system inefficiently. In this paper, we use RST (Rough Set Theory) and SVM
(Support Vector Machine) to detect intrusions. First, RST is used to preprocess
the data and reduce the dimensions. Next, the features were selected by RST
will be sent to SVM model to learn and test respectively. The method is
effective to decrease the space density of data. The experiments will compare
the results with different methods and show RST and SVM schema could improve
the false positive rate and accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0570</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0570</id><created>2010-04-05</created><authors><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames><affiliation>Jackson State University</affiliation></author><author><keyname>Allam</keyname><forenames>Sumanth Reddy</forenames><affiliation>Jackson State University</affiliation></author><author><keyname>Moore</keyname><forenames>Loretta A.</forenames><affiliation>Jackson State University</affiliation></author></authors><title>Tools and techniques for Network Forensics</title><categories>cs.NI</categories><comments>12Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.1
  (2009) 14-25</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Network forensics deals with the capture, recording and analysis of network
events in order to discover evidential information about the source of security
attacks in a court of law. This paper discusses the different tools and
techniques available to conduct network forensics. Some of the tools discussed
include: eMailTrackerPro to identify the physical location of an email sender;
Web Historian to find the duration of each visit and the files uploaded and
downloaded from the visited website; packet sniffers like Etherea to capture
and analyze the data exchanged among the different computers in the network.
The second half of the paper presents a survey of different IP traceback
techniques like packet marking that help a forensic investigator to identify
the true sources of the attacking IP packets. We also discuss the use of
Honeypots and Honeynets that gather intelligence about the enemy and the tools
and tactics of network intruders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0571</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0571</id><created>2010-04-05</created><authors><author><keyname>Krishnamurthy</keyname><forenames>G. N.</forenames></author><author><keyname>Ramaswamy</keyname><forenames>V.</forenames></author></authors><title>Encryption Quality Analysis and Security Evaluation of CAST-128
  Algorithm and its Modified Version using Digital Images</title><categories>cs.CR</categories><comments>6Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.1
  (2009) 28-33</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  this paper demonstrates analysis of well known block cipher CAST-128 and its
modified version using avalanche criterion and other tests namely encryption
quality, correlation coefficient, histogram analysis and key sensitivity tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0574</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0574</id><created>2010-04-05</created><authors><author><keyname>Garg</keyname><forenames>Poonam</forenames><affiliation>Institute of Management Technology, India</affiliation></author></authors><title>A Comparison between Memetic algorithm and Genetic algorithm for the
  cryptanalysis of Simplified Data Encryption Standard algorithm</title><categories>cs.CR cs.NE</categories><comments>9Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.1
  (2009) 34-42</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Genetic algorithms are a population-based Meta heuristics. They have been
successfully applied to many optimization problems. However, premature
convergence is an inherent characteristic of such classical genetic algorithms
that makes them incapable of searching numerous solutions of the problem
domain. A memetic algorithm is an extension of the traditional genetic
algorithm. It uses a local search technique to reduce the likelihood of the
premature convergence. The cryptanalysis of simplified data encryption standard
can be formulated as NP-Hard combinatorial problem. In this paper, a comparison
between memetic algorithm and genetic algorithm were made in order to
investigate the performance for the cryptanalysis on simplified data encryption
standard problems(SDES). The methods were tested and various experimental
results show that memetic algorithm performs better than the genetic algorithms
for such type of NP-Hard combinatorial problem. This paper represents our first
effort toward efficient memetic algorithm for the cryptanalysis of SDES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0587</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0587</id><created>2010-04-05</created><authors><author><keyname>Roy</keyname><forenames>Debdutta Barman</forenames><affiliation>Calcutta Institute of Engineering and Management, India</affiliation></author><author><keyname>Chaki</keyname><forenames>Rituparna</forenames><affiliation>West Bengal University of Technology, India</affiliation></author><author><keyname>Chaki</keyname><forenames>Nabendu</forenames><affiliation>University of Calcutta, A.P.C. Road, India</affiliation></author></authors><title>A New Cluster-based Wormhole Intrusion detection algorithm for Mobile
  Ad-Hoc Networks</title><categories>cs.NI</categories><comments>9Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.1
  (2009) 44-52</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In multi-hop wireless systems, the need for cooperation among nodes to relay
each other's packets exposes them to a wide range of security attacks. A
particularly devastating attack is the wormhole attack, where a malicious node
records control traffic at one location and tunnels it to another compromised
node, possibly far away, which replays it locally. Routing security in ad hoc
networks is often equated with strong and feasible node authentication and
lightweight cryptography. Unfortunately, the wormhole attack can hardly be
defeated by crypto graphical measures, as wormhole attackers do not create
separate packets. They simply replay packets already existing on the network,
which pass the cryptographic checks. Existing works on wormhole detection have
often focused on detection using specialized hardware, such as directional
antennas, etc. In this paper, we present a cluster based counter-measure for
the wormhole attack, that alleviates these drawbacks and efficiently mitigates
the wormhole attack in MANET. Simulation results on MATLab exhibit the
effectiveness of the proposed algorithm in detecting wormhole attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0590</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0590</id><created>2010-04-05</created><authors><author><keyname>Zivic</keyname><forenames>Natasa</forenames></author></authors><title>Iterative method for improvement of coding and decryption</title><categories>cs.CR</categories><comments>15Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 1-15</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cryptographic check values (digital signatures, MACs and H-MACs) are useful
only if they are free of errors. For that reason all of errors in cryptographic
check values should be corrected after the transmission over a noisy channel
before their verification is performed. Soft Input Decryption is a method of
combining SISO convolutional decoding and decrypting of cryptographic check
values to improve the correction of errors in themselves. If Soft Input
Decryption is successful, i.e. all wrong bit of a cryptographic check value are
corrected, these bit are sent as feedback information to the channel decoder
for a next iteration. The bit of the next iteration are corrected by channel
decoding followed by another Soft Input Decryption. Iterative Soft Input
Decryption uses interleaved blocks. If one block can be corrected by Soft Input
Decryption, the decoding of the interleaved block is improved (serial scheme).
If Soft Input Decryption is applied on both blocks and one of the blocks can be
corrected, the corrected block is used for an improved decoding of the other
block (parallel scheme). Both schemes show significant coding gains compared to
convolutional decoding without iterative Soft Input Decryption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0591</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0591</id><created>2010-04-05</created><authors><author><keyname>Wang</keyname><forenames>Eric Ke</forenames></author><author><keyname>Hui</keyname><forenames>Lucas C. K.</forenames></author><author><keyname>Yiu</keyname><forenames>S. M.</forenames></author></authors><title>A new key establishment scheme for wireless sensor networks</title><categories>cs.CR cs.NI</categories><comments>11Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 17-27</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Traditional key management techniques, such as public key cryptography or key
distribution center (e.g., Kerberos), are often not effective for wireless
sensor networks for the serious limitations in terms of computational power,
energy supply, network bandwidth. In order to balance the security and
efficiency, we propose a new scheme by employing LU Composition techniques for
mutual authenticated pairwise key establishment and integrating LU Matrix with
Elliptic Curve Diffie-Hellman for anonymous pathkey establishment. At the
meantime, it is able to achieve efficient group key agreement and management.
Analysis shows that the new scheme has better performance and provides
authenticity and anonymity for sensor to establish multiple kinds of keys,
compared with previous related works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0594</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0594</id><created>2010-04-05</created><authors><author><keyname>Misbahuddin</keyname><forenames>Mohammed</forenames></author><author><keyname>Narayanan</keyname><forenames>Sachin</forenames></author><author><keyname>Ghosh</keyname><forenames>Bishwa Ranjan</forenames></author></authors><title>Dynamic IDP Signature processing by fast elimination using DFA</title><categories>cs.CR</categories><comments>10Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 29-38</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Intrusion Detection &amp; Prevention Systems generally aims at detecting /
preventing attacks against Information systems and networks. The basic task of
IDPS is to monitor network &amp; system traffic for any malicious packets/patterns
and hence to prevent any unwarranted incidents which leads the systems to
insecure state. The monitoring is done by checking each packet for its validity
against the signatures formulated for identified vulnerabilities. Since,
signatures are the heart &amp; soul of an Intrusion Detection and Prevention System
(IDPS), we, in this paper, discuss two methodologies we adapted in our research
effort to improve the current Intrusion Detection and Prevention (IDP) systems.
The first methodology RUDRAA is for formulating, verifying &amp; validating the
potential signatures to be used with IDPS. The second methodology DSP-FED is
aimed at processing the signatures in less time with our proposed fast
elimination method using DFA. The research objectives of this project are 1) To
formulate &amp; process potential IPS signatures to be used with Intrusion
prevention system. 2) To propose a DFA based approach for signature processing
which, upon a pattern match, could process the signatures faster else could
eliminate it efficiently if not matched
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0596</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0596</id><created>2010-04-05</created><authors><author><keyname>Tamilselvan</keyname><forenames>G. M.</forenames></author><author><keyname>Shanmugam</keyname><forenames>A.</forenames></author></authors><title>Effect of Inter Packet Delay in performance analysis of coexistence
  heterogeneous Wireless Packet Networks</title><categories>cs.NI</categories><comments>10Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 40-49</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  As the explosive growth of the ISM band usage continues, there are many
scenarios where different systems operate in the same place at the same time.
One of growing concerns is the coexistence of heterogeneous wireless network
systems. For the successful deployment of mission-critical systems such as
wireless sensor networks, it is required to provide a solution for the
coexistence. In this paper, we propose a new scheme using inter packet delay
for the coexistence of IEEE 802.15.4 LRWPAN and IEEE 802.11b WLAN. To evaluate
the effectiveness of the proposed scheme, measurement and simulation study are
conducted using Qualnet 4.5 simulation software. The simulation results show
that the proposed scheme is effective in performance improvement for
coexistence network of IEEE 802.15.4 for various topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0598</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0598</id><created>2010-04-05</created><authors><author><keyname>Abuhelaleh</keyname><forenames>Mohammed</forenames></author><author><keyname>Elleithy</keyname><forenames>Khaled</forenames></author><author><keyname>Mismar</keyname><forenames>Thabet</forenames></author></authors><title>Clustered Hierarchy in Sensor Networks: Performance and Security</title><categories>cs.NI</categories><comments>12Pages</comments><report-no>Vol 1, No 2, July 2009</report-no><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 51-62</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Many papers have been proposed in order to increase the wireless sensor
networks performance; This kind of network has limited resources, where the
energy in each sensor came from a small battery that sometime is hard to be
replaced or recharged. Transmission energy is the most concern part where the
higher energy consumption takes place. Clustered hierarchy has been proposed in
many papers; in most cases, it provides the network with better performance
than other protocols. In our paper, first we discuss some of techniques,
relates to this protocol, that have been proposed for energy efficiency; some
of them were proposed to provide the network with more security level. Our
proposal then suggests some modifications to some of these techniques to
provide the network with more energy saving that should lead to high
performance; also we apply our technique on an existing one that proposed to
increase the security level of cluster sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0599</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0599</id><created>2010-04-05</created><authors><author><keyname>Kanamori</keyname><forenames>Yoshito</forenames><affiliation>University of Alaska Anchorage, Alaska, USA</affiliation></author><author><keyname>Yoo</keyname><forenames>Seong-Moo</forenames><affiliation>The University of Alabama in Huntsville, Alabama, USA</affiliation></author></authors><title>Quantum Three-Pass protocol: Key distribution using quantum
  superposition states</title><categories>cs.CR</categories><comments>7Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 64-70</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This letter proposes a novel key distribution protocol with no key exchange
in advance, which is secure as the BB84 quantum key distribution protocol. Our
protocol utilizes a photon in superposition state for single-bit data
transmission instead of a classical electrical/optical signal. The security of
this protocol relies on the fact, that the arbitrary quantum state cannot be
cloned, known as the no-cloning theorem. This protocol can be implemented with
current technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0602</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0602</id><created>2010-04-05</created><authors><author><keyname>Jaisankar</keyname><forenames>N.</forenames><affiliation>VIT University, India</affiliation></author><author><keyname>Saravanan</keyname><forenames>R.</forenames><affiliation>VIT University, India</affiliation></author><author><keyname>Swamy</keyname><forenames>K. Durai</forenames><affiliation>Dean, K.S.R.C.T., Tiruchengodu, India</affiliation></author></authors><title>Intelligent Detection System framework using Mobile agents</title><categories>cs.NI cs.CR</categories><comments>17Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 72-88</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  An intrusion detection system framework using mobile agents is a layered
framework mechanism designed to support heterogeneous network environments to
identify intruders at its best. Traditional computer misuse detection
techniques can identify known attacks efficiently, but perform very poorly in
other cases. Anomaly detection has the potential to detect unknown attacks;
however, it is a very challenging task since its aim is to detect unknown
attacks without any priori knowledge about specific intrusions. This technology
is still at its early stage. The objective of this paper is that the system can
detect anomalous user activity. Existing research in this area focuses either
on user activity or on program operation but not on both simultaneously. In
this paper, an attempt to look at both concurrently is presented. Based on an
intrusion detection framework [1], a novel user anomaly detection system has
been implemented and conducted several intrusion detection experiments in a
simulated environment by analyzing user activity and program operation
activities. The proposed framework is a layered framework, which is designed to
satisfy the core purpose of IDS, and allows detecting the intrusion as quickly
as possible with available data using mobile agents. This framework was mainly
designed to provide security for the network using mobile agent mechanisms to
add mobility features to monitor the user processes from different
computational systems. The experimental results have shown that the system can
detect anomalous user activity effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0604</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0604</id><created>2010-04-05</created><authors><author><keyname>Sharma</keyname><forenames>Sugam</forenames><affiliation>Iowa State University, USA</affiliation></author><author><keyname>Cohly</keyname><forenames>Hari</forenames><affiliation>Jackson State University, USA</affiliation></author><author><keyname>Pei</keyname><forenames>Tzusheng</forenames><affiliation>Jackson State University, USA</affiliation></author></authors><title>On Generation of Firewall Log Status Reporter (SRr) Using Perl</title><categories>cs.SE</categories><comments>10Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 90-99</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Computer System Administration and Network Administration are few such areas
where Practical Extraction Reporting Language (Perl) has robust utilization
these days apart from Bioinformatics. The key role of a System/Network
Administrator is to monitor log files. Log file are updated every day. To scan
the summary of large log files and to quickly determine if there is anything
wrong with the server or network we develop a Firewall Log Status Reporter
(SRr). SRr helps to generate the reports based on the parameters of interest.
SRr provides the facility to admin to generate the individual firewall report
or all reports in one go. By scrutinizing the results of the reports admin can
trace how many times a particular request has been made from which source to
which destination and can track the errors easily. Perl scripts can be seen as
the UNIX script replacement in future arena and SRr is one development with the
same hope that we can believe in. SRr is a generalized and customizable utility
completely written in Perl and may be used for text mining and data mining
application in Bioinformatics research and development too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0605</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0605</id><created>2010-04-05</created><authors><author><keyname>Mink</keyname><forenames>Alan</forenames></author><author><keyname>Frankel</keyname><forenames>Sheila</forenames></author><author><keyname>Perlner</keyname><forenames>Ray</forenames></author></authors><title>Quantum Key Distribution (QKD) and Commodity Security Protocols:
  Introduction and Integration</title><categories>cs.CR</categories><comments>12Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.2
  (2009) 101-112</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present an overview of quantum key distribution (QKD), a secure key
exchange method based on the quantum laws of physics rather than computational
complexity. We also provide an overview of the two most widely used commodity
security protocols, IPsec and TLS. Pursuing a key exchange model, we propose
how QKD could be integrated into these security applications. For such a QKD
integration we propose a support layer that provides a set of common QKD
services between the QKD protocol and the security applications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0610</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0610</id><created>2010-04-05</created><authors><author><keyname>Kuske</keyname><forenames>Dietrich</forenames></author><author><keyname>Liu</keyname><forenames>Jiamou</forenames></author><author><keyname>Lohrey</keyname><forenames>Markus</forenames></author></authors><title>The Isomorphism Problem for omega-Automatic Trees</title><categories>cs.LO cs.FL</categories><msc-class>03C57; 03D05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main result of this paper is that the isomorphism for omega-automatic
trees of finite height is at least has hard as second-order arithmetic and
therefore not analytical. This strengthens a recent result by Hjorth,
Khoussainov, Montalban, and Nies showing that the isomorphism problem for
omega-automatic structures is not $\Sigma^1_2$. Moreover, assuming the
continuum hypothesis CH, we can show that the isomorphism problem for
omega-automatic trees of finite height is recursively equivalent with
second-order arithmetic. On the way to our main results, we show lower and
upper bounds for the isomorphism problem for omega-automatic trees of every
finite height: (i) It is decidable ($\Pi^0_1$-complete, resp,) for height 1 (2,
resp.), (ii) $\Pi^1_1$-hard and in $\Pi^1_2$ for height 3, and (iii)
$\Pi^1_{n-3}$- and $\Sigma^1_{n-3}$-hard and in $\Pi^1_{2n-4}$ (assuming CH)
for all n &gt; 3. All proofs are elementary and do not rely on theorems from set
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0653</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0653</id><created>2010-04-05</created><updated>2010-04-24</updated><authors><author><keyname>Kullmann</keyname><forenames>Oliver</forenames></author></authors><title>Exact Ramsey Theory: Green-Tao numbers and SAT</title><categories>cs.DM cs.DS</categories><comments>25 pages; a shortened version appears in LNCS (Springer), &quot;Theory and
  Applications of Satisfiability Testing - SAT 2010&quot;, editors O. Strichman and
  S. Szeider. Revision contains new van-der-Waerden and Green-Tao numbers,
  especially &quot;transversal numbers&quot;, corresponding to independence numbers of
  hypergraphs of arithmetic progressions. Some new comments discussing
  behaviour of vdW- and GT-numbers.</comments><msc-class>05D10, 11Y16</msc-class><acm-class>F.2.2; I.2.8</acm-class><journal-ref>Theory and Applications of Satisfiability Testing - SAT 2010, LNCS
  6175, 352-362</journal-ref><doi>10.1007/978-3-642-14186-7_32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the links between Ramsey theory in the integers, based on van der
Waerden's theorem, and (boolean, CNF) SAT solving. We aim at using the problems
from exact Ramsey theory, concerned with computing Ramsey-type numbers, as a
rich source of test problems, where especially methods for solving hard
problems can be developed. In order to control the growth of the problem
instances, we introduce &quot;transversal extensions&quot; as a natural way of
constructing mixed parameter tuples (k_1, ..., k_m) for van-der-Waerden-like
numbers N(k_1, ..., k_m), such that the growth of these numbers is guaranteed
to be linear. Based on Green-Tao's theorem we introduce the &quot;Green-Tao numbers&quot;
grt(k_1, ..., k_m), which in a sense combine the strict structure of van der
Waerden problems with the (pseudo-)randomness of the distribution of prime
numbers. Using standard SAT solvers (look-ahead, conflict-driven, and local
search) we determine the basic values. It turns out that already for this
single form of Ramsey-type problems, when considering the best-performing
solvers a wide variety of solver types is covered. For m &gt; 2 the problems are
non-boolean, and we introduce the &quot;generic translation scheme&quot;, which offers an
infinite variety of translations (&quot;encodings&quot;) and covers the known methods. In
most cases the special instance called &quot;nested translation&quot; proved to be far
superior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0658</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0658</id><created>2010-04-05</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>A new representation of Chaitin \Omega number based on compressible
  strings</title><categories>cs.IT cs.CC math.IT</categories><comments>12 pages, no figures, to appear in the Proceedings of the 9th
  International Conference on Unconventional Computation (UC 2010), The
  University of Tokyo, Japan, June 21-25, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1975 Chaitin introduced his \Omega number as a concrete example of random
real. The real \Omega is defined based on the set of all halting inputs for an
optimal prefix-free machine U, which is a universal decoding algorithm used to
define the notion of program-size complexity. Chaitin showed \Omega to be
random by discovering the property that the first n bits of the base-two
expansion of \Omega solve the halting problem of U for all binary inputs of
length at most n. In this paper, we introduce a new representation \Theta of
Chaitin \Omega number. The real \Theta is defined based on the set of all
compressible strings. We investigate the properties of \Theta and show that
\Theta is random. In addition, we generalize \Theta to two directions \Theta(T)
and \bar{\Theta}(T) with a real T&gt;0. We then study their properties. In
particular, we show that the computability of the real \Theta(T) gives a
sufficient condition for a real T in (0,1) to be a fixed point on partial
randomness, i.e., to satisfy the condition that the compression rate of T
equals to T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0727</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0727</id><created>2010-04-05</created><authors><author><keyname>Kim</keyname><forenames>Anthony</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Scalar-linear Solvability of Matroidal Networks Associated with
  Representable Matroids</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study matroidal networks introduced by Dougherty et al. We prove the
converse of the following theorem: If a network is scalar-linearly solvable
over some finite field, then the network is a matroidal network associated with
a representable matroid over a finite field. It follows that a network is
scalar-linearly solvable if and only if the network is a matroidal network
associated with a representable matroid over a finite field. We note that this
result combined with the construction method due to Dougherty et al. gives a
method for generating scalar-linearly solvable networks. Using the converse
implicitly, we demonstrate scalar-linear solvability of two classes of
matroidal networks: networks constructed from uniform matroids and those
constructed from graphic matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0728</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0728</id><created>2010-04-05</created><authors><author><keyname>Sriram</keyname><forenames>Ilango</forenames></author><author><keyname>Cliff</keyname><forenames>Dave</forenames></author></authors><title>Effects of component-subscription network topology on large-scale data
  centre performance scaling</title><categories>cs.DC</categories><journal-ref>in: &quot;Proceedings of the 15th IEEE International Conference on
  Engineering of Complex Computer Systems (ICECCS 2010)&quot;, R. Calinescu, R.
  Paige, M. Kwiatkowska (ed.); IEEE Computer Society, (2010), ISBN:
  978-0-7695-4015-3; pp. 72 - 81</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern large-scale date centres, such as those used for cloud computing
service provision, are becoming ever-larger as the operators of those data
centres seek to maximise the benefits from economies of scale. With these
increases in size comes a growth in system complexity, which is usually
problematic. There is an increased desire for automated &quot;self-star&quot;
configuration, management, and failure-recovery of the data-centre
infrastructure, but many traditional techniques scale much worse than linearly
as the number of nodes to be managed increases. As the number of nodes in a
median-sized data-centre looks set to increase by two or three orders of
magnitude in coming decades, it seems reasonable to attempt to explore and
understand the scaling properties of the data-centre middleware before such
data-centres are constructed. In [1] we presented SPECI, a simulator that
predicts aspects of large-scale data-centre middleware performance,
concentrating on the influence of status changes such as policy updates or
routine node failures. [...]. In [1] we used a first-approximation assumption
that such subscriptions are distributed wholly at random across the data
centre. In this present paper, we explore the effects of introducing more
realistic constraints to the structure of the internal network of
subscriptions. We contrast the original results [...] exploring the effects of
making the data-centre's subscription network have a regular lattice-like
structure, and also semi-random network structures resulting from parameterised
network generation functions that create &quot;small-world&quot; and &quot;scale-free&quot;
networks. We show that for distributed middleware topologies, the structure and
distribution of tasks carried out in the data centre can significantly
influence the performance overhead imposed by the middleware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0739</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0739</id><created>2010-04-05</created><updated>2011-04-14</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Jobstmann</keyname><forenames>Barbara</forenames></author><author><keyname>Singh</keyname><forenames>Rohit</forenames></author></authors><title>Measuring and Synthesizing Systems in Probabilistic Environments</title><categories>cs.LO cs.FL cs.GT</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often one has a preference order among the different systems that satisfy a
given specification. Under a probabilistic assumption about the possible
inputs, such a preference order is naturally expressed by a weighted automaton,
which assigns to each word a value, such that a system is preferred if it
generates a higher expected value. We solve the following optimal-synthesis
problem: given an omega-regular specification, a Markov chain that describes
the distribution of inputs, and a weighted automaton that measures how well a
system satisfies the given specification under the given input assumption,
synthesize a system that optimizes the measured value.
  For safety specifications and measures given by mean-payoff automata, the
optimal-synthesis problem amounts to finding a strategy in a Markov decision
process (MDP) that is optimal for a long-run average reward objective, which
can be done in polynomial time. For general omega-regular specifications, the
solution rests on a new, polynomial-time algorithm for computing optimal
strategies in MDPs with mean-payoff parity objectives.
  Our algorithm generates optimal strategies consisting of two memoryless
strategies and a counter. This counter is in general not bounded. To obtain a
finite-state system, we show how to construct an \epsilon-optimal strategy with
a bounded counter for any \epsilon&gt;0. We also show how to decide in polynomial
time if we can construct an optimal finite-state system (i.e., a system without
a counter) for a given specification.
  We have implemented our approach in a tool that takes qualitative and
quantitative specifications and automatically constructs a system that
satisfies the qualitative specification and optimizes the quantitative
specification, if such a system exists. We present experimental results showing
optimal systems that were generated in this way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0744</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0744</id><created>2010-04-05</created><authors><author><keyname>Brimkov</keyname><forenames>Valentin E.</forenames></author></authors><title>Patrolling a Street Network is Strongly NP-Complete but in P for Tree
  Structures</title><categories>cs.CG cs.CC cs.DM cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following problem: Given a finite set of straight line
segments in the plane, determine the positions of a minimal number of points on
the segments, from which guards can see all segments. This problem can be
interpreted as looking for a minimal number of locations of policemen, guards,
cameras or other sensors, that can observe a network of streets, corridors,
tunnels, tubes, etc. We show that the problem is strongly NP-complete even for
a set of segments with a cubic graph structure, but in P for tree structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0755</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0755</id><created>2010-04-05</created><authors><author><keyname>Safayani</keyname><forenames>Mehran</forenames></author><author><keyname>Manzuri-Shalmani</keyname><forenames>Mohammad T.</forenames></author><author><keyname>Khademi</keyname><forenames>Mahmoud</forenames></author></authors><title>Extended Two-Dimensional PCA for Efficient Face Representation and
  Recognition</title><categories>cs.CV cs.LG</categories><comments>Proc. of 4th International Conference on Intelligent Computer
  Communication and Processing (ICCP), Cluj-Napoca, Romania, pp. 295--298,
  2008.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a novel method called Extended Two-Dimensional PCA (E2DPCA) is
proposed which is an extension to the original 2DPCA. We state that the
covariance matrix of 2DPCA is equivalent to the average of the main diagonal of
the covariance matrix of PCA. This implies that 2DPCA eliminates some
covariance information that can be useful for recognition. E2DPCA instead of
just using the main diagonal considers a radius of r diagonals around it and
expands the averaging so as to include the covariance information within those
diagonals. The parameter r unifies PCA and 2DPCA. r = 1 produces the covariance
of 2DPCA, r = n that of PCA. Hence, by controlling r it is possible to control
the trade-offs between recognition accuracy and energy compression (fewer
coefficients), and between training and recognition complexity. Experiments on
ORL face database show improvement in both recognition accuracy and recognition
time over the original 2DPCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0762</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0762</id><created>2010-04-05</created><authors><author><keyname>Abid</keyname><forenames>Mohamed</forenames><affiliation>SudParis, Evry, France</affiliation></author><author><keyname>Song</keyname><forenames>Songbo</forenames><affiliation>SudParis, Evry, France</affiliation></author><author><keyname>Moustafa</keyname><forenames>Hassnaa</forenames><affiliation>SudParis, Evry, France</affiliation></author><author><keyname>Afifi</keyname><forenames>Hossam</forenames><affiliation>SudParis, Evry, France</affiliation></author></authors><title>Integrating identity-based cryptography in IMS service authentication</title><categories>cs.CR cs.MM</categories><comments>13Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 1-13</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Nowadays, the IP Multimedia Subsystem (IMS) is a promising research field.
Many ongoing works related to the security and the performances of its
employment are presented to the research community. Although, the security and
data privacy aspects are very important in the IMS global objectives, they
observe little attention so far. Secure access to multimedia services is based
on SIP and HTTP digest on top of IMS architecture. The standard deploys AKA-MD5
for the terminal authentication. The third Generation Partnership Project
(3GPP) provided Generic Bootstrapping Architecture (GBA) to authenticate the
subscriber before accessing multimedia services over HTTP. In this paper, we
propose a new IMS Service Authentication scheme using Identity Based
cryptography (IBC). This new scheme will lead to better performances when there
are simultaneous authentication requests using Identity-based Batch
Verification. We analyzed the security of our new protocol and we presented a
performance evaluation of its cryptographic operations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0763</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0763</id><created>2010-04-05</created><updated>2011-02-03</updated><authors><author><keyname>Mazo</keyname><forenames>Manuel</forenames><suffix>Jr.</suffix></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>Symbolic Approximate Time-Optimal Control</title><categories>math.OC cs.SY</categories><comments>17 pages, 2 figures, journal</comments><msc-class>93C10, 93C62, 93C30, 93A30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is an increasing demand for controller design techniques capable of
addressing the complex requirements of todays embedded applications. This
demand has sparked the interest in symbolic control where lower complexity
models of control systems are used to cater for complex specifications given by
temporal logics, regular languages, or automata. These specification mechanisms
can be regarded as qualitative since they divide the trajectories of the plant
into bad trajectories (those that need to be avoided) and good trajectories.
However, many applications require also the optimization of quantitative
measures of the trajectories retained by the controller, as specified by a cost
or utility function. As a first step towards the synthesis of controllers
reconciling both qualitative and quantitative specifications, we investigate in
this paper the use of symbolic models for time-optimal controller synthesis. We
consider systems related by approximate (alternating) simulation relations and
show how such relations enable the transfer of time-optimality information
between the systems. We then use this insight to synthesize approximately
time-optimal controllers for a control system by working with a lower
complexity symbolic model. The resulting approximately time-optimal controllers
are equipped with upper and lower bounds for the time to reach a target,
describing the quality of the controller. The results described in this paper
were implemented in the Matlab Toolbox Pessoa which we used to workout several
illustrative examples reported in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0765</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0765</id><created>2010-04-05</created><authors><author><keyname>Sathiyamoorthy</keyname><forenames>E.</forenames><affiliation>VIT University, India</affiliation></author><author><keyname>Iyenger</keyname><forenames>N. Ch. Sriman Narayana</forenames><affiliation>VIT University, India</affiliation></author><author><keyname>Ramachandran</keyname><forenames>V.</forenames><affiliation>VIT University, India</affiliation></author></authors><title>Agent Based Trust Management Model Based on Weight Value Model for
  Online Auctions</title><categories>cs.GT cs.CR</categories><comments>17Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 15-31</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper is aimed at the stipulations which arise in the traditional online
auctions as a result of various anomalies in the reputation and trust
calculation mechanism. We try to improve the scalability and efficiency of the
online auctions by providing efficient trust management methodology considering
several factors into consideration. A comparison between the performance of the
auctions system with and without the agent methodology is done with good
results
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0766</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0766</id><created>2010-04-05</created><authors><author><keyname>Mollah</keyname><forenames>Ayatullah Faruk</forenames></author><author><keyname>Basu</keyname><forenames>Subhadip</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Basu</keyname><forenames>Dipak Kumar</forenames></author></authors><title>Text/Graphics Separation for Business Card Images for Mobile Devices</title><categories>cs.GR</categories><comments>Proc. IAPR International Workshop on Graphics Recognition (2009)
  263-270</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separation of the text regions from background texture and graphics is an
important step of any optical character recognition sytem for the images
containg both texts and graphics. In this paper, we have presented a novel
text/graphics separation technique for business card images captured with a
cell-phone camera. At first, the background is eliminated at a coarse level
based on intensity variance. This makes the foreground components distinct from
each other. Then the non-text components are removed using various
characteristic features of text and graphics. Finally, the text regions are
skew corrected and binarized for further processing. Experimenting with
business card images of various resolutions, we have found an optimum
performance of 98.54% with 0.75 MP images, that takes 0.17 seconds processing
time and 1.1 MB peak memory on a moderately powerful computer (DualCore 1.73
GHz Processor, 1 GB RAM, 1 MB L2 Cache). The developed technique is
computationally efficient and consumes low memory so as to be applicable on
mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0767</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0767</id><created>2010-04-05</created><authors><author><keyname>Ahmed</keyname><forenames>Mohammed Aijaz</forenames><affiliation>GITAM University, Vishakapatnam</affiliation></author><author><keyname>Lakshmi</keyname><forenames>D. Rajya</forenames><affiliation>GITAM University, Vishakapatnam</affiliation></author><author><keyname>Sattar</keyname><forenames>Sayed Abdul</forenames><affiliation>J.N.T. University, Hyderabad</affiliation></author></authors><title>Cryptanalysis of a more efficient and secure dynamic id-based remote
  user authentication scheme</title><categories>cs.CR</categories><comments>6Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 32-37</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In 2004, Das, Saxena and Gulati proposed a dynamic ID-based remote user
authentication scheme which has many advantage such as no verifier table, user
freedom to choose and change password and so on. However the subsequent papers
have shown that this scheme is completely insecure and vulnerable to many
attacks. Since then many schemes with improvements to Das et al's scheme has
been proposed but each has its pros and cons. Recently Yan-yan Wang et al. have
proposed a scheme to overcome security weaknesses of Das et al.'s scheme.
However this scheme too is vulnerable to various security attacks such as
password guessing attack, masquerading attack, denial of service attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0769</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0769</id><created>2010-04-06</created><authors><author><keyname>Malkani</keyname><forenames>Yasir Arfat</forenames><affiliation>University of Sussex, Brighton, UK</affiliation></author><author><keyname>Dhomeja</keyname><forenames>Lachhman Das</forenames><affiliation>University of Sussex, Brighton, UK</affiliation></author></authors><title>PSIM: A tool for analysis of device pairing methods</title><categories>cs.NI</categories><comments>12Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 39-50</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Wireless networks are a common place nowadays and almost all of the modern
devices support wireless communication in some form. These networks differ from
more traditional computing systems due to the ad-hoc and spontaneous nature of
interactions among devices. These systems are prone to security risks, such as
eavesdropping and require different techniques as compared to traditional
security mechanisms. Recently, secure device pairing in wireless environments
has got substantial attention from many researchers. As a result, a significant
set of techniques and protocols have been proposed to deal with this issue.
Some of these techniques consider devices equipped with infrared, laser,
ultrasound transceivers or 802.11 network interface cards; while others require
embedded accelerometers, cameras and/or LEDs, displays, microphones and/or
speakers. However, many of the proposed techniques or protocols have not been
implemented at all; while others are implemented and evaluated in a stand-alone
manner without being compared with other related work [1]. We believe that it
is because of the lack of specialized tools that provide a common platform to
test the pairing methods. As a consequence, we designed such a tool. In this
paper, we are presenting design and development of the Pairing Simulator (PSim)
that can be used to perform the analysis of device pairing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0770</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0770</id><created>2010-04-06</created><authors><author><keyname>Kumar</keyname><forenames>M Prabu</forenames><affiliation>VIT University, India</affiliation></author><author><keyname>Yadav</keyname><forenames>K Praneesh Kumar</forenames><affiliation>VIT University, India</affiliation></author></authors><title>Data security in mobile devices by geo locking</title><categories>cs.CR cs.NI</categories><comments>10Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 52-61</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we present a way of hiding the data in mobile devices from
being compromised. We use two level data hiding technique, where in its first
level data is encrypted and stored in special records and the second level
being a typical password protection scheme. The second level is for secure
access of information from the device. In the first level, encryption of the
data is done using the location coordinates as key. Location Coordinates are
rounded up figures of longitude and latitude information. In the second phase
the password entry differs from conventional schemes. Here we have used the
patterns of traditional Rangoli for specifying the password and gaining access,
thus minimising the chances of data leak in hostile situations. The proposed
structure would be a better trade off in comparison with the previous models
which use Bio Metric authentication -- a relatively costly way of
authentication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0771</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0771</id><created>2010-04-06</created><authors><author><keyname>Girgis</keyname><forenames>Moheb R</forenames><affiliation>Minia University, Egypt</affiliation></author><author><keyname>Mahmoud</keyname><forenames>Tarek M</forenames><affiliation>Minia University, Egypt</affiliation></author><author><keyname>Takroni</keyname><forenames>Youssef S</forenames><affiliation>Minia University, Egypt</affiliation></author><author><keyname>Hassan</keyname><forenames>Hassan S</forenames><affiliation>Minia University, Egypt</affiliation></author></authors><title>Performance evaluation of a new route optimization technique for mobile
  IP</title><categories>cs.NI</categories><comments>11Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 63-73</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Mobile ip (mip) is an internet protocol that allows mobile nodes to have
continuous network connectivity to the internet without changing their ip
addresses while moving to other networks. The packets sent from correspondent
node (cn) to a mobile node (mn) go first through the mobile node's home agent
(ha), then the ha tunnels them to the mn's foreign network. One of the main
problems in the original mip is the triangle routing problem. Triangle routing
problem appears when the indirect path between cn and mn through the ha is
longer than the direct path. This paper proposes a new technique to improve the
performance of the original mip during the handoff. The proposed technique
reduces the delay, the packet loss and the registration time for all the
packets transferred between the cn and the mn. In this technique, tunneling
occurs at two levels above the ha in a hierarchical network. To show the
effectiveness of the proposed technique, it is compared with the original mip
and another technique for solving the same problem in which tunneling occurs at
one level above the ha. Simulation results presented in this paper are based on
the ns2 mobility software on linux platform. The simulations results show that
our proposed technique achieves better performance than the others, considering
the packet delay, the packet losses during handoffs and the registration time,
in different scenarios for the location of the mn with respect to the ha and
fas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0772</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0772</id><created>2010-04-06</created><authors><author><keyname>Lalande</keyname><forenames>Jean-Francois</forenames><affiliation>Ensi de Bourges, France</affiliation></author><author><keyname>Rodriguez</keyname><forenames>David</forenames><affiliation>Ensi de Bourges, France</affiliation></author><author><keyname>Toinard</keyname><forenames>Christian</forenames><affiliation>Ensi de Bourges, France</affiliation></author></authors><title>Security properties in an open peer-to-peer network</title><categories>cs.CR cs.NI</categories><comments>17Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 73-89</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper proposes to address new requirements of confidentiality, integrity
and availability properties fitting to peer-to-peer domains of resources. The
enforcement of security properties in an open peer-topeer network remains an
open problem as the literature have mainly proposed contribution on
availability of resources and anonymity of users. That paper proposes a novel
architecture that eases the administration of a peer-to-peer network. It
considers a network of safe peer-to-peer clients in the sense that it is a
commune client software that is shared by all the participants to cope with the
sharing of various resources associated with different security requirements.
However, our proposal deals with possible malicious peers that attempt to
compromise the requested security properties. Despite the safety of an open
peer-to-peer network cannot be formally guaranteed, since a end user has
privileges on the target host, our solution provides several advanced security
enforcement. First, it enables to formally define the requested security
properties of the various shared resources. Second, it evaluates the trust and
the reputation of the requesting peer by sending challenges that test the
fairness of its peer-to-peer security policy. Moreover, it proposes an advanced
Mandatory Access Control that enforces the required peer-to-peer security
properties through an automatic projection of the requested properties onto
SELinux policies. Thus, the SELinux system of the requesting peer is
automatically configured with respect to the required peer-to-peer security
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0774</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0774</id><created>2010-04-06</created><authors><author><keyname>Fonseca</keyname><forenames>Johnneth</forenames></author><author><keyname>Abdelouahab</keyname><forenames>Zair</forenames></author><author><keyname>Lopes</keyname><forenames>Denivaldo</forenames></author><author><keyname>Labidi</keyname><forenames>Sofiane</forenames></author></authors><title>A security framework for SOA applications in mobile environment</title><categories>cs.SE cs.CR cs.NI</categories><comments>18Pages</comments><journal-ref>International Journal of Network Security &amp; Its Applications 1.3
  (2009) 90-107</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A Rapid evolution of mobile technologies has led to the development of more
sophisticated mobile devices with better storage, processing and transmission
power. These factors enable support to many types of application but also give
rise to a necessity to find a model of service development. Actually, SOA
(Service Oriented Architecture) is a good option to support application
development. This paper presents a framework that allows the development of SOA
based application in mobile environment. The objective of the framework is to
give developers with tools for provision of services in this environment with
the necessary security characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0777</identifier>
 <datestamp>2012-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0777</id><created>2010-04-06</created><updated>2012-06-04</updated><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit</forenames><affiliation>Rajkot Gujarat, India</affiliation></author><author><keyname>Patel</keyname><forenames>Bhaskar N.</forenames><affiliation>Ganpat Vidyanagar, Kherava, Gujarat, India</affiliation></author><author><keyname>Prajapati</keyname><forenames>Satish G.</forenames><affiliation>Ganpat Vidyanagar, Kherava, Gujarat, India</affiliation></author><author><keyname>Jani</keyname><forenames>N. N.</forenames><affiliation>Kadi Vishvadiva Vidyalaya</affiliation></author></authors><title>Securing AODV for MANETs using Message Digest with Secret Key</title><categories>cs.NI</categories><comments>This article has been withdrawn by arXiv admins because it contains
  plagiarized content from International Conference on Computer Networks and
  Security (ICCNS 2008, September 27-28, 2008): &quot;Securing AODV for MANETs using
  Message Digest with Secret Key&quot;, by Sunil J. Soni and Prashant B. Swadas</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This article has been withdrawn by arXiv admins because it contains
plagiarized content from International Conference on Computer Networks and
Security (ICCNS 2008, September 27-28, 2008): &quot;Securing AODV for MANETs using
Message Digest with Secret Key&quot;, by Sunil J. Soni and Prashant B. Swadas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0785</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0785</id><created>2010-04-06</created><updated>2010-04-14</updated><authors><author><keyname>Akhlaghi</keyname><forenames>Soroush</forenames></author><author><keyname>Kiani</keyname><forenames>Abbas</forenames></author><author><keyname>Ghanavati</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Cost-Bandwidth Tradeoff In Distributed Storage Systems</title><categories>cs.IT cs.NI math.IT</categories><comments>8 pages,8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed storage systems are mainly justified due to the limited amount of
storage capacity and improving the reliability through distributing data over
multiple storage nodes. On the other hand, it may happen the data is stored in
unreliable nodes, while it is desired the end user to have a reliable access to
the stored data. So, in an event that a node is damaged, to prevent the system
reliability to regress, it is necessary to regenerate a new node with the same
amount of stored data as the damaged node to retain the number of storage
nodes, thereby having the previous reliability. This requires the new node to
connect to some of existing nodes and downloads the required information,
thereby occupying some bandwidth, called the repair bandwidth. On the other
hand, it is more likely the cost of downloading varies across different nodes.
This paper aims at investigating the theoretical cost-bandwidth tradeoff, and
more importantly, it is demonstrated that any point on this curve can be
achieved through the use of the so called generalized regenerating codes which
is an enhancement of the regeneration codes introduced by Dimakis et al. in
[1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0798</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0798</id><created>2010-04-06</created><authors><author><keyname>Salimi</keyname><forenames>Somayeh</forenames></author><author><keyname>Salmasizadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Generalized Secure Distributed Source Coding with Side Information</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, new inner and outer bounds on the achievable
compression-equivocation rate region for generalized secure data compression
with side information are given that do not match in general. In this setup,
two senders, Alice and Charlie intend to transmit information to Bob via
channels with limited capacity so that he can reliably reconstruct their
observations. The eavesdropper, Eve, has access to one of the channels at each
instant and is interested in the source of the same channel at the time. Bob
and Eve also have their own observations which are correlated with Alice's and
Charlie's observations. In this model, two equivocation and compression rates
are defined with respect to the sources of Alice and Charlie. Furthermore,
different special cases are discussed where the inner and outer bounds match.
Our model covers the previously obtained results as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0799</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0799</id><created>2010-04-06</created><authors><author><keyname>Salimi</keyname><forenames>Somayeh</forenames></author><author><keyname>Salmasizadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Rate Regions of Secret Key Sharing in a New Source Model</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A source model for secret key generation between terminals is considered. Two
users, namely users 1 and 2, at one side communicate with another user, namely
user 3, at the other side via a public channel where three users can observe
i.i.d. outputs of correlated sources. Each of users 1 and 2 intends to share a
secret key with user 3 where user 1 acts as a wiretapper for user 2 and vice
versa. In this model, two situations are considered: communication from users 1
and 2 to user 3 (the forward key strategy) and from user 3 to users 1 and 2
(the backward key strategy). In both situations, the goal is sharing a secret
key between user 1 and user 3 while leaking no effective information about that
key to user 2, and simultaneously, sharing another secret key between user 2
and user 3 while leaking no effective information about the latter key to user
1. This model is motivated by wireless communications when considering user 3
as a base station and users 1 and 2 as network users. In this paper, for both
the forward and backward key strategies, inner and outer bounds of secret key
capacity regions are derived. In special situations where one of users 1 and 2
is only interested in wiretapping and not key sharing, our results agree with
that of Ahlswede and Csiszar. Also, we investigate some special cases in which
the inner bound coincides with the outer bound and secret key capacity region
is deduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0803</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0803</id><created>2010-04-06</created><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Huang</keyname><forenames>Sangxia</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author></authors><title>From Holant To #CSP And Back: Dichotomy For Holant$^c$ Problems</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the intricate interdependent relationship among counting problems,
considered from three frameworks for such problems: Holant Problems, counting
CSP and weighted H-colorings. We consider these problems for general complex
valued functions that take boolean inputs. We show that results from one
framework can be used to derive results in another, and this happens in both
directions. Holographic reductions discover an underlying unity, which is only
revealed when these counting problems are investigated in the complex domain
$\mathbb{C}$. We prove three complexity dichotomy theorems, leading to a
general theorem for Holant$^c$ problems. This is the natural class of Holant
problems where one can assign constants 0 or 1. More specifically, given any
signature grid on $G=(V,E)$ over a set ${\mathscr F}$ of symmetric functions,
we completely classify the complexity to be in P or #P-hard, according to
${\mathscr F}$, of \[\sum_{\sigma: E \rightarrow \{0,1\}} \prod_{v\in V}
f_v(\sigma\mid_{E(v)}),\] where $f_v \in {\mathscr F} \cup \{{\bf 0}, {\bf
1}\}$ ({\bf 0}, {\bf 1} are the unary constant 0, 1 functions). Not only is
holographic reduction the main tool, but also the final dichotomy can be only
naturally stated in the language of holographic transformations. The proof goes
through another dichotomy theorem on boolean complex weighted #CSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0816</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0816</id><created>2010-04-06</created><updated>2012-10-18</updated><authors><author><keyname>Gayo-Avello</keyname><forenames>Daniel</forenames></author></authors><title>Nepotistic Relationships in Twitter and their Impact on Rank Prestige
  Algorithms</title><categories>cs.IR</categories><comments>40 pages, 17 tables, 14 figures. Paper has been restructured, new
  section &quot;3.2. The importance of reciprocal linking in Twitter spam&quot; was
  added, experiments with verified accounts in addition to spammers have bee
  conducted to show performance with relevant users and not only regarding spam
  demotion</comments><journal-ref>Information Processing &amp; Management Volume 49, Issue 6, November
  2013, Pages 1250-1280</journal-ref><doi>10.1016/j.ipm.2013.06.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Micro-blogging services such as Twitter allow anyone to publish anything,
anytime. Needless to say, many of the available contents can be diminished as
babble or spam. However, given the number and diversity of users, some valuable
pieces of information should arise from the stream of tweets. Thus, such
services can develop into valuable sources of up-to-date information (the
so-called real-time web) provided a way to find the most
relevant/trustworthy/authoritative users is available. Hence, this makes a
highly pertinent question for which graph centrality methods can provide an
answer. In this paper the author offers a comprehensive survey of feasible
algorithms for ranking users in social networks, he examines their
vulnerabilities to linking malpractice in such networks, and suggests an
objective criterion against which to compare such algorithms. Additionally, he
suggests a first step towards &quot;desensitizing&quot; prestige algorithms against
cheating by spammers and other abusive users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0817</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0817</id><created>2010-04-06</created><authors><author><keyname>Gavinsky</keyname><forenames>Dmitry</forenames></author><author><keyname>Sherstov</keyname><forenames>Alexander A.</forenames></author></authors><title>A Separation of NP and coNP in Multiparty Communication Complexity</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that NP differs from coNP and coNP is not a subset of MA in the
number-on-forehead model of multiparty communication complexity for up to k =
(1-\epsilon)log(n) players, where \epsilon&gt;0 is any constant. Specifically, we
construct a function F with co-nondeterministic complexity O(log(n)) and
Merlin-Arthur complexity n^{\Omega(1)}. The problem was open for k &gt; 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0838</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0838</id><created>2010-04-06</created><updated>2010-04-10</updated><authors><author><keyname>Bienvenu</keyname><forenames>Laurent</forenames></author><author><keyname>Stephan</keyname><forenames>Frank</forenames></author><author><keyname>Teutsch</keyname><forenames>Jason</forenames></author></authors><title>How powerful are integer-valued martingales?</title><categories>cs.GT math.LO</categories><comments>Long version of the CiE 2010 paper.</comments><doi>10.1007/978-3-642-13962-8_7</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In the theory of algorithmic randomness, one of the central notions is that
of computable randomness. An infinite binary sequence X is computably random if
no recursive martingale (strategy) can win an infinite amount of money by
betting on the values of the bits of X. In the classical model, the martingales
considered are real-valued, that is, the bets made by the martingale can be
arbitrary real numbers. In this paper, we investigate a more restricted model,
where only integer-valued martingales are considered, and we study the class of
random sequences induced by this model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0871</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0871</id><created>2010-04-06</created><authors><author><keyname>Dumrauf</keyname><forenames>Dominic</forenames></author><author><keyname>S&#xfc;&#xdf;</keyname><forenames>Tim</forenames></author></authors><title>On the Complexity of Local Search for Weighted Standard Set Problems</title><categories>cs.CC</categories><doi>10.1007/978-3-642-13962-8_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the complexity of computing locally optimal solutions
for weighted versions of standard set problems such as SetCover, SetPacking,
and many more. For our investigation, we use the framework of PLS, as defined
in Johnson et al., [JPY88]. We show that for most of these problems, computing
a locally optimal solution is already PLS-complete for a simple neighborhood of
size one. For the local search versions of weighted SetPacking and SetCover, we
derive tight bounds for a simple neighborhood of size two. To the best of our
knowledge, these are one of the very few PLS results about local search for
weighted standard set problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0891</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0891</id><created>2010-04-06</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Secure Communication over Fading Channels with Statistical QoS
  Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the secure transmission of information over an ergodic fading
channel is investigated in the presence of statistical quality of service (QoS)
constraints. We employ effective capacity, which provides the maximum constant
arrival rate that a given process can support while satisfying statistical
delay constraints, to measure the secure throughput of the system, i.e.,
effective secure throughput. We assume that the channel side information (CSI)
of the main channel is available at the transmitter side. Depending on the
availability of the CSI of the eavesdropper channel, we obtain the
corresponding optimal power control policies that maximize the effective secure
throughput. In particular, when the CSI of the eavesdropper channel is
available at the transmitter, the transmitter can no longer wait for
transmission when the main channel is much better than the eavesdropper channel
due to the introduction of QoS constraints. Moreover, the CSI of the
eavesdropper channel becomes useless as QoS constraints become stringent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0892</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0892</id><created>2010-04-06</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Secure Broadcasting over Fading Channels with Statistical QoS
  Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the fading broadcast channel with confidential messages is
studied in the presence of statistical quality of service (QoS) constraints in
the form of limitations on the buffer length. We employ the effective capacity
formulation to measure the throughput of the confidential and common messages.
We assume that the channel side information (CSI) is available at both the
transmitter and the receivers. Assuming average power constraints at the
transmitter side, we first define the effective secure throughput region, and
prove that the throughput region is convex. Then, we obtain the optimal power
control policies that achieve the boundary points of the effective secure
throughput region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0897</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0897</id><created>2010-04-06</created><authors><author><keyname>Chen</keyname><forenames>Qing</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Energy Efficiency Analysis in Amplify-and-Forward and Decode-and-Forward
  Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>Proc. IEEE WCNC2010, Sydney, Australia, April, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have studied the energy efficiency of cooperative networks
operating in either the fixed Amplifyand- Forward (AF) or the selective
Decode-and-Forward (DF) mode. We consider the optimization of the M-ary
quadrature amplitude modulation (MQAM) constellation size to minimize the bit
energy consumption under given bit error rate (BER) constraints. In the
computation of the energy expenditure, the circuit, transmission, and
retransmission energies are taken into account. The link reliabilities and
retransmission probabilities are determined through the outage probabilities
under the Rayleigh fading assumption. Several interesting observations with
practical implications are made. It is seen that while large constellations are
preferred at small transmission distances, constellation size should be
decreased as the distance increases; the cooperative gain is computed to
compare direct transmission and cooperative transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0899</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0899</id><created>2010-04-06</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Relay Beamforming Strategies for Physical-Layer Security</title><categories>cs.IT math.IT</categories><comments>Proc. of the 44th Annual Conference on Information Sciences and
  Systems, Princeton, March 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, collaborative use of relays to form a beamforming system and
provide physical-layer security is investigated. In particular,
amplify-and-forward (AF) relay beamforming designs under total and individual
relay power constraints are studied with the goal of maximizing the secrecy
rates when perfect channel state information (CSI) is available. In the AF
scheme, not having analytical solutions for the optimal beamforming design
under both total and individual power constraints, an iterative algorithm is
proposed to numerically obtain the optimal beamforming structure and maximize
the secrecy rates. Robust beamforming designs in the presence of imperfect CSI
are investigated for decode-and-forward (DF) based relay beamforming, and
optimization frameworks are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0902</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0902</id><created>2010-04-06</created><updated>2010-10-01</updated><authors><author><keyname>Fredriksson</keyname><forenames>Kimmo</forenames></author></authors><title>On building minimal automaton for subset matching queries</title><categories>cs.FL cs.DS cs.IR</categories><comments>Accepted to IPL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of building an index for a set $D$ of $n$ strings,
where each string location is a subset of some finite integer alphabet of size
$\sigma$, so that we can answer efficiently if a given simple query string
(where each string location is a single symbol) $p$ occurs in the set. That is,
we need to efficiently find a string $d \in D$ such that $p[i] \in d[i]$ for
every $i$. We show how to build such index in
$O(n^{\log_{\sigma/\Delta}(\sigma)}\log(n))$ average time, where $\Delta$ is
the average size of the subsets. Our methods have applications e.g.\ in
computational biology (haplotype inference) and music information retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0907</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0907</id><created>2010-04-06</created><authors><author><keyname>Akin</keyname><forenames>Sami</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>QoS Analysis of Cognitive Radio Channels with Perfect CSI at both
  Receiver and Transmitter</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, cognitive transmission under quality of service (QoS)
constraints is studied. In the cognitive radio channel model, it is assumed
that both the secondary receiver and the secondary transmitter know the channel
fading coefficients perfectly and optimize the power adaptation policy under
given constraints, depending on the channel activity of the primary users,
which is determined by channel sensing performed by the secondary users. The
transmission rates are equal to the instantaneous channel capacity values. A
state transition model with four states is constructed to model this cognitive
transmission channel. Statistical limitations on the buffer lengths are imposed
to take into account the QoS constraints. The maximum throughput under these
statistical QoS constraints is identified by finding the effective capacity of
the cognitive radio channel. The impact upon the effective capacity of several
system parameters, including the channel sensing duration, detection threshold,
detection and false alarm probabilities, and QoS parameters, is investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0914</identifier>
 <datestamp>2010-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0914</id><created>2010-04-06</created><authors><author><keyname>Zhang</keyname><forenames>Junwei</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Collaborative Relay Beamforming for Secure Broadcasting</title><categories>cs.IT math.IT</categories><comments>Proc. of the IEEE Wireless Communications and Networking Conference
  (WCNC) Sydney, Austria, April 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, collaborative use of relays to form a beamforming system with
the aid of perfect channel state information (CSI) and to provide communication
in physicallayer security between a transmitter and two receivers is
investigated. In particular, we describe decode-and-forward based null space
beamforming schemes and optimize the relay weights jointly to obtain the
largest secrecy rate region. Furthermore, the optimality of the proposed
schemes is investigated by comparing them with the outer bound secrecy rate
region
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0930</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0930</id><created>2010-04-06</created><authors><author><keyname>Blond</keyname><forenames>Stevens Le</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Fessant</keyname><forenames>Fabrice Le</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Kaafar</keyname><forenames>Mohamed Ali</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Spying the World from your Laptop -- Identifying and Profiling Content
  Providers and Big Downloaders in BitTorrent</title><categories>cs.NI</categories><proxy>ccsd</proxy><journal-ref>3rd USENIX Workshop on Large-Scale Exploits and Emergent Threats
  (LEET'10), San Jose, CA : United States (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a set of exploits an adversary can use to continuously
spy on most BitTorrent users of the Internet from a single machine and for a
long period of time. Using these exploits for a period of 103 days, we
collected 148 million IPs downloading 2 billion copies of contents. We identify
the IP address of the content providers for 70% of the BitTorrent contents we
spied on. We show that a few content providers inject most contents into
BitTorrent and that those content providers are located in foreign data
centers. We also show that an adversary can compromise the privacy of any peer
in BitTorrent and identify the big downloaders that we define as the peers who
subscribe to a large number of contents. This infringement on users' privacy
poses a significant impediment to the legal adoption of BitTorrent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0933</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0933</id><created>2010-04-06</created><updated>2010-04-19</updated><authors><author><keyname>Majumdar</keyname><forenames>Kaushik Kumar</forenames></author></authors><title>Indian policeman's dilemma: A game theoretic model</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on a one person game called Indian policeman's dilemma
(IPD). It represents the internal conflict between emotion and profession of a
typical Indian police officer. We have 'split' the game to be played
independently by different personality modules of the same player. Each module
then appears as an independent individual player of the game. None of the
players knows the exact payoff values of any of the others. Only greater than
or less than type of inequalities among the payoff values across the players
are to be inferred probabilistically. There are two Nash equilibrium (NE)
points in this game signifying two completely opposing behavior by the
policeman involved. With the help of the probabilistic inequalities probable
propensities of the different behaviors have been determined. The model
underscores the need for new surveys and data generation. A design of one such
survey to measure professionalism of the police personnel has been outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0944</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0944</id><created>2010-04-06</created><updated>2012-04-01</updated><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames></author><author><keyname>Mesnard</keyname><forenames>Fred</forenames></author><author><keyname>Pescetti</keyname><forenames>Andrea</forenames></author><author><keyname>Zaffanella</keyname><forenames>Enea</forenames></author></authors><title>The Automatic Synthesis of Linear Ranking Functions: The Complete
  Unabridged Version</title><categories>cs.PL cs.LO</categories><comments>47 pages, 3 tables</comments><acm-class>F.3.1; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical technique for proving termination of a generic sequential
computer program involves the synthesis of a ranking function for each loop of
the program. Linear ranking functions are particularly interesting because many
terminating loops admit one and algorithms exist to automatically synthesize
it. In this paper we present two such algorithms: one based on work dated 1991
by Sohn and Van Gelder; the other, due to Podelski and Rybalchenko, dated 2004.
Remarkably, while the two algorithms will synthesize a linear ranking function
under exactly the same set of conditions, the former is mostly unknown to the
community of termination analysis and its general applicability has never been
put forward before the present paper. In this paper we thoroughly justify both
algorithms, we prove their correctness, we compare their worst-case complexity
and experimentally evaluate their efficiency, and we present an open-source
implementation of them that will make it very easy to include
termination-analysis capabilities in automatic program verifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0992</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0992</id><created>2010-04-06</created><authors><author><keyname>Thurley</keyname><forenames>Marc</forenames></author></authors><title>The Complexity of Partition Functions on Hermitian Matrices</title><categories>cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partition functions of certain classes of &quot;spin glass&quot; models in statistical
physics show strong connections to combinatorial graph invariants. Also known
as homomorphism functions they allow for the representation of many such
invariants, for example, the number of independent sets of a graph or the
number nowhere zero k-flows. Contributing to recent developments on the
complexity of partition functions we study the complexity of partition
functions with complex values. These functions are usually determined by a
square matrix A and it was shown by Goldberg, Grohe, Jerrum, and Thurley that
for each real-valued symmetric matrix, the corresponding partition function is
either polynomial time computable or #P-hard. Extending this result, we give a
complete description of the complexity of partition functions definable by
Hermitian matrices. These can also be classified into polynomial time
computable and #P-hard ones. Although the criterion for polynomial time
computability is not describable in a single line, we give a clear account of
it in terms of structures associated with Abelian groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.0995</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.0995</id><created>2010-04-06</created><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Reishus</keyname><forenames>Dustin</forenames></author><author><keyname>Schweller</keyname><forenames>Robert T.</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author></authors><title>Strong Fault-Tolerance for Self-Assembly with Fuzzy Temperature</title><categories>cs.DS</categories><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of fault-tolerance in nanoscale algorithmic
self-assembly. We employ a variant of Winfree's abstract Tile Assembly Model
(aTAM), the two-handed aTAM, in which square &quot;tiles&quot; -- a model of molecules
constructed from DNA for the purpose of engineering self-assembled
nanostructures -- aggregate according to specific binding sites of varying
strengths, and in which large aggregations of tiles may attach to each other,
in contrast to the seeded aTAM, in which tiles aggregate one at a time to a
single specially-designated &quot;seed&quot; assembly. We focus on a major cause of
errors in tile-based self-assembly: that of unintended growth due to &quot;weak&quot;
strength-1 bonds, which if allowed to persist, may be stabilized by subsequent
attachment of neighboring tiles in the sense that at least energy 2 is now
required to break apart the resulting assembly; i.e., the errant assembly is
stable at temperature 2. We study a common self-assembly benchmark problem,
that of assembling an n x n square using O(log n) unique tile types, under the
two-handed model of self-assembly. Our main result achieves a much stronger
notion of fault-tolerance than those achieved previously. Arbitrary strength-1
growth is allowed (i.e., the temperature is &quot;fuzzy&quot; and may drift from 2 to 1
for arbitrarily long); however, any assembly that grows sufficiently to become
stable at temperature 2 is guaranteed to assemble at temperature 2 into the
correct final assembly of an n x n square. In other words, errors due to
insufficient attachment, which is the cause of errors studied in earlier papers
on fault-tolerance, are prevented absolutely in our main construction, rather
than only with high probability and for sufficiently small structures, as in
previous fault-tolerance studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1001</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1001</id><created>2010-04-07</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Neubauer</keyname><forenames>Peter</forenames></author></authors><title>The Graph Traversal Pattern</title><categories>cs.DS cs.DB</categories><acm-class>G.2.2; H.2.4</acm-class><journal-ref>chapter in Graph Data Management: Techniques and Applications,
  eds. S. Sakr, E. Pardede, 2011</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A graph is a structure composed of a set of vertices (i.e.nodes, dots)
connected to one another by a set of edges (i.e.links, lines). The concept of a
graph has been around since the late 19$^\text{th}$ century, however, only in
recent decades has there been a strong resurgence in both theoretical and
applied graph research in mathematics, physics, and computer science. In
applied computing, since the late 1960s, the interlinked table structure of the
relational database has been the predominant information storage and retrieval
model. With the growth of graph/network-based data and the need to efficiently
process such data, new data management systems have been developed. In contrast
to the index-intensive, set-theoretic operations of relational databases, graph
databases make use of index-free, local traversals. This article discusses the
graph traversal pattern and its use in computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1003</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1003</id><created>2010-04-07</created><authors><author><keyname>Kim</keyname><forenames>Byung-Hak</forenames></author><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Message-Passing Inference on a Factor Graph for Collaborative Filtering</title><categories>cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel message-passing (MP) framework for the
collaborative filtering (CF) problem associated with recommender systems. We
model the movie-rating prediction problem popularized by the Netflix Prize,
using a probabilistic factor graph model and study the model by deriving
generalization error bounds in terms of the training error. Based on the model,
we develop a new MP algorithm, termed IMP, for learning the model. To show
superiority of the IMP algorithm, we compare it with the closely related
expectation-maximization (EM) based algorithm and a number of other matrix
completion algorithms. Our simulation results on Netflix data show that, while
the methods perform similarly with large amounts of data, the IMP algorithm is
superior for small amounts of data. This improves the cold-start problem of the
CF systems in practice. Another advantage of the IMP algorithm is that it can
be analyzed using the technique of density evolution (DE) that was originally
developed for MP decoding of error-correcting codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1027</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1027</id><created>2010-04-07</created><authors><author><keyname>Arrighi</keyname><forenames>Pablo</forenames></author><author><keyname>Dowek</keyname><forenames>Gilles</forenames></author></authors><title>On the completeness of quantum computation models</title><categories>cs.CC cs.LO quant-ph</categories><comments>15 pages, LaTeX</comments><msc-class>68Q05; 68Q55; 03D10; 81P68</msc-class><acm-class>F.1.1; F.4.1; F.3.2</acm-class><journal-ref>6th conference on Computability in Europe, CiE 2010, Proceedings
  in LNCS</journal-ref><doi>10.1007/978-3-642-13962-8_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of computability is stable (i.e. independent of the choice of an
indexing) over infinite-dimensional vector spaces provided they have a finite
&quot;tensorial dimension&quot;. Such vector spaces with a finite tensorial dimension
permit to define an absolute notion of completeness for quantum computation
models and give a precise meaning to the Church-Turing thesis in the framework
of quantum theory. (Extra keywords: quantum programming languages, denotational
semantics, universality.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1042</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1042</id><created>2010-04-07</created><authors><author><keyname>van de Ven</keyname><forenames>P. M.</forenames></author><author><keyname>van Leeuwaarden</keyname><forenames>J. S. H.</forenames></author><author><keyname>Denteneer</keyname><forenames>D.</forenames></author><author><keyname>Janssen</keyname><forenames>A. J. E. M.</forenames></author></authors><title>Spatial fairness in linear wireless multi-access networks</title><categories>cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-access networks may exhibit severe unfairness in throughput. Recent
studies show that this unfairness is due to local differences in the
neighborhood structure: Nodes with less neighbors receive better access. We
study the unfairness in saturated linear networks, and adapt the multi-access
CSMA protocol to remove the unfairness completely, by choosing the activation
rates of nodes appropriately as a function of the number of neighbors. We then
investigate the consequences of this choice of activation rates on the
network-average saturated throughput, and we show that these rates perform well
in a non-saturated setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1045</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1045</id><created>2010-04-07</created><authors><author><keyname>Chen</keyname><forenames>Yifan</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>Double-Directional Information Azimuth Spectrum and Relay Network
  Tomography for a Decentralized Wireless Relay Network</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel channel representation for a two-hop decentralized wireless relay
network (DWRN) is proposed, where the relays operate in a completely
distributive fashion. The modeling paradigm applies an analogous approach to
the description method for a double-directional multipath propagation channel,
and takes into account the finite system spatial resolution and the extended
relay listening/transmitting time. Specifically, the double-directional
information azimuth spectrum (IAS) is formulated to provide a compact
representation of information flows in a DWRN. The proposed channel
representation is then analyzed from a geometrically-based statistical modeling
perspective. Finally, we look into the problem of relay network tomography
(RNT), which solves an inverse problem to infer the internal structure of a
DWRN by using the instantaneous doubledirectional IAS recorded at multiple
measuring nodes exterior to the relay region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1058</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1058</id><created>2010-04-07</created><authors><author><keyname>van de Ven</keyname><forenames>P. M.</forenames></author><author><keyname>Janssen</keyname><forenames>A. J. E. M.</forenames></author><author><keyname>van Leeuwaarden</keyname><forenames>J. S. H.</forenames></author></authors><title>Optimal Tradeoff Between Exposed and Hidden Nodes in Large Wireless
  Networks</title><categories>cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless networks equipped with the CSMA protocol are subject to collisions
due to interference. For a given interference range we investigate the tradeoff
between collisions (hidden nodes) and unused capacity (exposed nodes). We show
that the sensing range that maximizes throughput critically depends on the
activation rate of nodes. For infinite line networks, we prove the existence of
a threshold: When the activation rate is below this threshold the optimal
sensing range is small (to maximize spatial reuse). When the activation rate is
above the threshold the optimal sensing range is just large enough to preclude
all collisions. Simulations suggest that this threshold policy extends to more
complex linear and non-linear topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1061</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1061</id><created>2010-04-07</created><authors><author><keyname>Hou</keyname><forenames>Yuexian</forenames></author><author><keyname>Yan</keyname><forenames>Tingxu</forenames></author><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Song</keyname><forenames>Dawei</forenames></author><author><keyname>Li</keyname><forenames>Wenjie</forenames></author></authors><title>On Tsallis Entropy Bias and Generalized Maximum Entropy Models</title><categories>cs.LG cond-mat.stat-mech cs.AI cs.IT math.IT</categories><comments>29 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In density estimation task, maximum entropy model (Maxent) can effectively
use reliable prior information via certain constraints, i.e., linear
constraints without empirical parameters. However, reliable prior information
is often insufficient, and the selection of uncertain constraints becomes
necessary but poses considerable implementation complexity. Improper setting of
uncertain constraints can result in overfitting or underfitting. To solve this
problem, a generalization of Maxent, under Tsallis entropy framework, is
proposed. The proposed method introduces a convex quadratic constraint for the
correction of (expected) Tsallis entropy bias (TEB). Specifically, we
demonstrate that the expected Tsallis entropy of sampling distributions is
smaller than the Tsallis entropy of the underlying real distribution. This
expected entropy reduction is exactly the (expected) TEB, which can be
expressed by a closed-form formula and act as a consistent and unbiased
correction. TEB indicates that the entropy of a specific sampling distribution
should be increased accordingly. This entails a quantitative re-interpretation
of the Maxent principle. By compensating TEB and meanwhile forcing the
resulting distribution to be close to the sampling distribution, our
generalized TEBC Maxent can be expected to alleviate the overfitting and
underfitting. We also present a connection between TEB and Lidstone estimator.
As a result, TEB-Lidstone estimator is developed by analytically identifying
the rate of probability correction in Lidstone. Extensive empirical evaluation
shows promising performance of both TEBC Maxent and TEB-Lidstone in comparison
with various state-of-the-art density estimation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1077</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1077</id><created>2010-04-07</created><updated>2010-04-20</updated><authors><author><keyname>Bersani</keyname><forenames>Marcello M.</forenames></author><author><keyname>Frigeri</keyname><forenames>Achille</forenames></author><author><keyname>Morzenti</keyname><forenames>Angelo</forenames></author><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author><author><keyname>Rossi</keyname><forenames>Matteo</forenames></author><author><keyname>Pietro</keyname><forenames>Pierluigi San</forenames></author></authors><title>Bounded Reachability for Temporal Logic over Constraint Systems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present CLTLB(D), an extension of PLTLB (PLTL with both past and future
operators) augmented with atomic formulae built over a constraint system D.
Even for decidable constraint systems, satisfiability and Model Checking
problem of such logic can be undecidable. We introduce suitable restrictions
and assumptions that are shown to make the satisfiability problem for the
extended logic decidable. Moreover for a large class of constraint systems we
propose an encoding that realize an effective decision procedure for the
Bounded Reachability problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1086</identifier>
 <datestamp>2013-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1086</id><created>2010-04-05</created><updated>2013-01-22</updated><authors><author><keyname>King</keyname><forenames>Emily J.</forenames></author></authors><title>Grassmannian Fusion Frames</title><categories>cs.IT math.IT</categories><comments>13 pages</comments><msc-class>42C15, 15B34, 14M15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmitted data may be corrupted by both noise and data loss. Grassmannian
frames are in some sense optimal representations of data transmitted over a
noisy channel that may lose some of the transmitted coefficients. Fusion frame
(or frame of subspaces) theory is a new area that has potential to be applied
to problems in such fields as distributed sensing and parallel processing.
Grassmannian fusion frames combine elements from both theories. A simple, novel
construction of Grassmannian fusion frames with an extension to Grassmannian
fusion frames with local frames shall be presented. Some connections to sparse
representations shall also be discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1155</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1155</id><created>2010-04-07</created><authors><author><keyname>Mahajan</keyname><forenames>Aditya</forenames></author></authors><title>Optimal sequential transmission over broadcast channel with nested
  feedback</title><categories>cs.IT math.IT math.OC</categories><comments>Appeared in 47th annual Allerton conference on communication,
  control, and computing, pp. 795-802, Monticello, IL, September 30-Oct 2,
  2009. The PDF is missing from the proceedings.</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We consider the optimal design of sequential transmission over broadcast
channel with nested feedback. Nested feedback means that the channel output of
the outer channel is also available at the decoder of the inner channel. We
model the communication system as a decentralized team with three decision
makers---the encoder and the two decoders. Structure of encoding and decoding
strategies that minimize a total distortion measure over a finite horizon are
determined. The results are applicable for real-time communication as well as
for the information theoretic setup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1158</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1158</id><created>2010-04-07</created><authors><author><keyname>Guenda</keyname><forenames>Kenza</forenames></author></authors><title>New MDS Self-Dual Codes over Large Finite Fields</title><categories>cs.IT math.IT</categories><msc-class>20B05; 94B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct MDS Euclidean and Hermitian self-dual codes over large finite
fields of odd and even characteristics. Our codes arise from cyclic and
negacyclic duadic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1184</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1184</id><created>2010-04-07</created><authors><author><keyname>Zhang</keyname><forenames>Li</forenames></author><author><keyname>Lin</keyname><forenames>Shu</forenames></author><author><keyname>Abdel-Ghaffar</keyname><forenames>Khaled</forenames></author><author><keyname>Ding</keyname><forenames>Zhi</forenames></author><author><keyname>Zhou</keyname><forenames>Bo</forenames></author></authors><title>Circulant Arrays on Cyclic Subgroups of Finite Fields: Rank Analysis and
  Construction of Quasi-Cyclic LDPC Codes</title><categories>cs.IT math.IT</categories><comments>26 pages, 6 figures, submitted to IEEE Transaction on Communications</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper consists of three parts. The first part presents a large class of
new binary quasi-cyclic (QC)-LDPC codes with girth of at least 6 whose
parity-check matrices are constructed based on cyclic subgroups of finite
fields. Experimental results show that the codes constructed perform well over
the binary-input AWGN channel with iterative decoding using the sum-product
algorithm (SPA). The second part analyzes the ranks of the parity-check
matrices of codes constructed based on finite fields with characteristic of 2
and gives combinatorial expressions for these ranks. The third part identifies
a subclass of constructed QC-LDPC codes that have large minimum distances.
Decoding of codes in this subclass with the SPA converges very fast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1194</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1194</id><created>2010-04-07</created><authors><author><keyname>Hermelin</keyname><forenames>Danny</forenames></author><author><keyname>Landau</keyname><forenames>Gad M.</forenames></author><author><keyname>Landau</keyname><forenames>Shir</forenames></author><author><keyname>Weimann</keyname><forenames>Oren</forenames></author></authors><title>Unified Compression-Based Acceleration of Edit-Distance Computation</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The edit distance problem is a classical fundamental problem in computer
science in general, and in combinatorial pattern matching in particular. The
standard dynamic programming solution for this problem computes the
edit-distance between a pair of strings of total length O(N) in O(N^2) time. To
this date, this quadratic upper-bound has never been substantially improved for
general strings. However, there are known techniques for breaking this bound in
case the strings are known to compress well under a particular compression
scheme. The basic idea is to first compress the strings, and then to compute
the edit distance between the compressed strings. As it turns out, practically
all known o(N^2) edit-distance algorithms work, in some sense, under the same
paradigm described above. It is therefore natural to ask whether there is a
single edit-distance algorithm that works for strings which are compressed
under any compression scheme. A rephrasing of this question is to ask whether a
single algorithm can exploit the compressibility properties of strings under
any compression method, even if each string is compressed using a di?erent
compression. In this paper we set out to answer this question by using straight
line programs. These provide a generic platform for representing many popular
compression schemes including the LZ-family, Run-Length Encoding, Byte-Pair
Encoding, and dictionary methods. For two strings of total length N having
straight-line program representations of total size n, we present an algorithm
running in O(nN log(N/n)) time for computing the edit-distance of these two
strings under any rational scoring function, and an O(n^{2/3}N^{4/3}) time
algorithm for arbitrary scoring functions. Our new result, while providing a
signi cant speed up for highly compressible strings, does not surpass the
quadratic time bound even in the worst case scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1195</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1195</id><created>2010-04-07</created><authors><author><keyname>Akin</keyname><forenames>Sami</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Ergodic Capacity Analysis in Cognitive Radio Systems under Channel
  Uncertainty</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, pilot-symbol-assisted transmission in cognitive radio systems
over time selective flat fading channels is studied. It is assumed that causal
and noncausal Wiener filter estimators are used at the secondary receiver with
the aid of training symbols to obtain the channel side information (CSI) under
an interference power constraint. Cognitive radio model is described together
with detection and false alarm probabilities determined by using a
Neyman-Person detector for channel sensing. Subsequently, for both filters, the
variances of estimate errors are calculated from the Doppler power spectrum of
the channel, and achievable rate expressions are provided considering the
scenarios which are results of channel sensing. Numerical results are obtained
in Gauss-Markov modeled channels, and achievable rates obtained by using causal
and noncausal filters are compared and it is shown that the difference is
decreasing with increasing signal-to-noise ratio (SNR). Moreover, the optimal
probability of detection and false alarm values are shown, and the tradeoff
between these two parameters is discussed. Finally, optimal power distributions
are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1198</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1198</id><created>2010-04-07</created><authors><author><keyname>Nguyen</keyname><forenames>Dung Viet</forenames></author><author><keyname>Vasic</keyname><forenames>Bane</forenames></author><author><keyname>Marcellin</keyname><forenames>Michael</forenames></author><author><keyname>Chilappagari</keyname><forenames>Shashi Kiran</forenames></author></authors><title>Structured LDPC Codes from Permutation Matrices Free of Small Trapping
  Sets</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, submitted to ITW Dublin 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a class of structured lowdensity parity-check (LDPC)
codes whose parity check matrices are arrays of permutation matrices. The
permutation matrices are obtained from Latin squares and form a finite field
under some matrix operations. They are chosen so that the Tanner graphs do not
contain subgraphs harmful to iterative decoding algorithms. The construction of
column-weight-three codes is presented. Although the codes are optimized for
the Gallager A/B algorithm over the binary symmetric channel (BSC), their error
performance is very good on the additive white Gaussian noise channel (AWGNC)
as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1208</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1208</id><created>2010-04-07</created><authors><author><keyname>Tripathi</keyname><forenames>Pushkar</forenames></author></authors><title>A Deterministic Algorithm for the Vertex Connectivity Survivable Network
  Design Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the vertex connectivity survivable network design problem we are given an
undirected graph G = (V,E) and connectivity requirement r(u,v) for each pair of
vertices u,v. We are also given a cost function on the set of edges. Our goal
is to find the minimum cost subset of edges such that for every pair (u,v) of
vertices we have r(u,v) vertex disjoint paths in the graph induced by the
chosen edges. Recently, Chuzhoy and Khanna presented a randomized algorithm
that achieves a factor of O(k^3 log n) for this problem where k is the maximum
connectivity requirement. In this paper we derandomize their algorithm to get a
deterministic O(k^3 log n) factor algorithm. Another problem of interest is the
single source version of the problem, where there is a special vertex s and all
non-zero connectivity requirements must involve s. We also give a deterministic
O(k^2 log n) algorithm for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1211</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1211</id><created>2010-04-07</created><authors><author><keyname>Chaudhuri</keyname><forenames>Avik</forenames></author></authors><title>Liberalizing Dependency</title><categories>cs.PL cs.CR</categories><acm-class>F.3.1; D.4.6; F.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dependency core calculus (DCC), a simple extension of the computational
lambda calculus, captures a common notion of dependency that arises in many
programming language settings. This notion of dependency is closely related to
the notion of information flow in security; it is sensitive not only to data
dependencies that cause explicit flows, but also to control dependencies that
cause implicit flows. In this paper, we study variants of DCC in which the data
and control dependencies are decoupled. This allows us to consider settings
where a weaker notion of dependency---one that restricts only explicit
flows---may usefully coexist with DCC's stronger notion of dependency. In
particular, we show how strong, noninterference-based security may be
reconciled with weak, trace-based security within the same system, enhancing
soundness of the latter and completeness of the former.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1215</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1215</id><created>2010-04-07</created><authors><author><keyname>Shaked</keyname><forenames>Elad</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author></authors><title>Regularized Richardson-Lucy Algorithm for Sparse Reconstruction of
  Poissonian Images</title><categories>cs.CV</categories><comments>The paper was submitted for consideration of possible publication in
  the IEEE Transactions on Image Processing on April 7, 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restoration of digital images from their degraded measurements has always
been a problem of great theoretical and practical importance in numerous
applications of imaging sciences. A specific solution to the problem of image
restoration is generally determined by the nature of degradation phenomenon as
well as by the statistical properties of measurement noises. The present study
is concerned with the case in which the images of interest are corrupted by
convolutional blurs and Poisson noises. To deal with such problems, there
exists a range of solution methods which are based on the principles
originating from the fixed-point algorithm of Richardson and Lucy (RL). In this
paper, we provide conceptual and experimental proof that such methods tend to
converge to sparse solutions, which makes them applicable only to those images
which can be represented by a relatively small number of non-zero samples in
the spatial domain. Unfortunately, the set of such images is relatively small,
which restricts the applicability of RL-type methods. On the other hand,
virtually all practical images admit sparse representations in the domain of a
properly designed linear transform. To take advantage of this fact, it is
therefore tempting to modify the RL algorithm so as to make it recover
representation coefficients, rather than the values of their associated image.
Such modification is introduced in this paper. Apart from the generality of its
assumptions, the proposed method is also superior to many established
reconstruction approaches in terms of estimation accuracy and computational
complexity. This and other conclusions of this study are validated through a
series of numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1216</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1216</id><created>2010-04-07</created><authors><author><keyname>Xu</keyname><forenames>Zhi</forenames></author></authors><title>Multi-Shift de Bruijn Sequence</title><categories>cs.DM</categories><comments>9 pages</comments><msc-class>68R15</msc-class><acm-class>G.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A (non-circular) de Bruijn sequence w of order n is a word such that every
word of length n appears exactly once in w as a factor. In this paper, we
generalize the concept to a multi-shift setting: a multi-shift de Bruijn
sequence tau(m,n) of shift m and order n is a word such that every word of
length n appears exactly once in w as a factor that starts at index im+1 for
some integer i&gt;=0. We show the number of the multi-shift de Bruijn sequence
tau(m,n) is (a^n)!a^{(m-n)(a^n-1)} for 1&lt;=n&lt;=m and is (a^m!)^{a^{n-m}} for
1&lt;=m&lt;=n, where a=|Sigma|. We provide two algorithms for generating a tau(m,n).
The multi-shift de Bruijn sequence is important in solving the Frobenius
problem in a free monoid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1218</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1218</id><created>2010-04-07</created><authors><author><keyname>Donoho</keyname><forenames>David L.</forenames></author><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>The Noise-Sensitivity Phase Transition in Compressed Sensing</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>40 pages, 13 pdf figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the noisy underdetermined system of linear equations: y=Ax0 + z0,
with n x N measurement matrix A, n &lt; N, and Gaussian white noise z0 ~
N(0,\sigma^2 I). Both y and A are known, both x0 and z0 are unknown, and we
seek an approximation to x0. When x0 has few nonzeros, useful approximations
are obtained by l1-penalized l2 minimization, in which the reconstruction \hxl
solves min || y - Ax||^2/2 + \lambda ||x||_1.
  Evaluate performance by mean-squared error (MSE = E ||\hxl - x0||_2^2/N).
Consider matrices A with iid Gaussian entries and a large-system limit in which
n,N\to\infty with n/N \to \delta and k/n \to \rho. Call the ratio MSE/\sigma^2
the noise sensitivity. We develop formal expressions for the MSE of \hxl, and
evaluate its worst-case formal noise sensitivity over all types of k-sparse
signals. The phase space 0 &lt; \delta, \rho &lt; 1 is partitioned by curve \rho =
\rhoMSE(\delta) into two regions. Formal noise sensitivity is bounded
throughout the region \rho &lt; \rhoMSE(\delta) and is unbounded throughout the
region \rho &gt; \rhoMSE(\delta). The phase boundary \rho = \rhoMSE(\delta) is
identical to the previously-known phase transition curve for equivalence of l1
- l0 minimization in the k-sparse noiseless case. Hence a single phase boundary
describes the fundamental phase transitions both for the noiseless and noisy
cases. Extensive computational experiments validate the predictions of this
formalism, including the existence of game theoretical structures underlying
it. Underlying our formalism is the AMP algorithm introduced earlier by the
authors. Other papers by the authors detail expressions for the formal MSE of
AMP and its close connection to l1-penalized reconstruction. Here we derive the
minimax formal MSE of AMP and then read out results for l1-penalized
reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1220</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1220</id><created>2010-04-07</created><authors><author><keyname>Ron</keyname><forenames>Dorit</forenames></author><author><keyname>Safro</keyname><forenames>Ilya</forenames></author><author><keyname>Brandt</keyname><forenames>Achi</forenames></author></authors><title>Relaxation-based coarsening and multiscale graph organization</title><categories>cs.DS cs.NA</categories><report-no>ANL/MCS-P1696-1009</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we generalize and improve the multiscale organization of graphs
by introducing a new measure that quantifies the &quot;closeness&quot; between two nodes.
The calculation of the measure is linear in the number of edges in the graph
and involves just a small number of relaxation sweeps. A similar notion of
distance is then calculated and used at each coarser level. We demonstrate the
use of this measure in multiscale methods for several important combinatorial
optimization problems and discuss the multiscale graph organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1224</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1224</id><created>2010-04-07</created><updated>2010-04-12</updated><authors><author><keyname>Fatahi</keyname><forenames>Somayeh</forenames></author><author><keyname>Ghasem-Aghaee</keyname><forenames>Nasser</forenames></author></authors><title>Design and Implementation of an Intelligent Educational Model Based on
  Personality and Learner's Emotion</title><categories>cs.CY</categories><comments>IEEE Publication format,ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Personality and emotions are effective parameters in learning process.
Thus, virtual learning environments should pay attention to these parameters.
In this paper, a new e-learning model is designed and implemented according to
these parameters. The Virtual learning environment that is presented here uses
two agents: Virtual Tutor Agent (VTA), and Virtual Classmate Agent (VCA).
During the learning process and depending on events happening in the
environment, learner's emotions are changed. In this situation, learning style
should be revised according to the personality traits as well as the learner's
current emotions. VTA selects suitable learning style for the learners based on
their personality traits. To improve the learning process, the system uses VCA
in some of the learning steps. VCA is an intelligent agent and has its own
personality. It is designed so that it can present an attractive and real
learning environment in interaction with the learner. To recognize the
learner's personality, this system uses MBTI test and to obtain emotion values
uses OCC model. Finally, the results of system tested in real environments show
that considering the human features in interaction with the learner increases
learning quality and satisfies the learner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1227</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1227</id><created>2010-04-07</created><authors><author><keyname>Ismail</keyname><forenames>Ismail A.</forenames></author><author><keyname>Ramadan</keyname><forenames>Mohammed A.</forenames></author><author><keyname>danaf</keyname><forenames>Talaat S. El</forenames></author><author><keyname>Samak</keyname><forenames>Ahmed H.</forenames></author></authors><title>Signature Recognition using Multi Scale Fourier Descriptor And Wavelet
  Transform</title><categories>cs.CV</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010,</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper present a novel off-line signature recognition method based on
multi scale Fourier Descriptor and wavelet transform . The main steps of
constructing a signature recognition system are discussed and experiments on
real data sets show that the average error rate can reach 1%. Finally we
compare 8 distance measures between feature vectors with respect to the
recognition performance.
  Key words: signature recognition; Fourier Descriptor; Wavelet transform;
personal verification
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1229</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1229</id><created>2010-04-07</created><authors><author><keyname>AnandhaKumar</keyname><forenames>Dr. P.</forenames></author><author><keyname>Balamurugan</keyname><forenames>V.</forenames></author></authors><title>Feature-Based Adaptive Tolerance Tree (FATT): An Efficient Indexing
  Technique for Content-Based Image Retrieval Using Wavelet Transform</title><categories>cs.MM cs.DB</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010,</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper introduces a novel indexing and access method, called Feature-
Based Adaptive Tolerance Tree (FATT), using wavelet transform is proposed to
organize large image data sets efficiently and to support popular image access
mechanisms like Content Based Image Retrieval (CBIR).Conventional database
systems are designed for managing textual and numerical data and retrieving
such data is often based on simple comparisons of text or numerical values.
However, this method is no longer adequate for images, since the digital
presentation of images does not convey the reality of images. Retrieval of
images become difficult when the database is very large. This paper addresses
such problems and presents a novel indexing technique, Feature Based Adaptive
Tolerance Tree (FATT), which is designed to bring an effective solution
especially for indexing large databases. The proposed indexing scheme is then
used along with a query by image content, in order to achieve the ultimate goal
from the user point of view that is retrieval of all relevant images. FATT
indexing technique, features of the image is extracted using 2-dimensional
discrete wavelet transform (2DDWT) and index code is generated from the
determinant value of the features. Multiresolution analysis technique using
2D-DWT can decompose the image into components at different scales, so that the
coarest scale components carry the global approximation information while the
finer scale components contain the detailed information. Experimental results
show that the FATT outperforms M-tree upto 200%, Slim-tree up to 120% and HCT
upto 89%. FATT indexing technique is adopted to increase the efficiently of
data storage and retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1230</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1230</id><created>2010-04-07</created><authors><author><keyname>Waraporn</keyname><forenames>Phanu</forenames></author><author><keyname>Meesad</keyname><forenames>Phayung</forenames></author><author><keyname>Clayton</keyname><forenames>Gareth</forenames></author></authors><title>Ontology-supported processing of clinical text using medical knowledge
  integration for multi-label classification of diagnosis coding</title><categories>cs.LG cs.AI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010,</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper discusses the knowledge integration of clinical information
extracted from distributed medical ontology in order to ameliorate a machine
learning-based multi-label coding assignment system. The proposed approach is
implemented using a decision tree based cascade hierarchical technique on the
university hospital data for patients with Coronary Heart Disease (CHD). The
preliminary results obtained show a satisfactory finding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1232</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1232</id><created>2010-04-07</created><authors><author><keyname>Zeidanloo</keyname><forenames>Hossein Rouhani</forenames></author><author><keyname>Manaf</keyname><forenames>Azizah Bt Abdul</forenames></author></authors><title>Botnet Detection by Monitoring Similar Communication Patterns</title><categories>cs.CR</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Botnet is most widespread and occurs commonly in today's cyber attacks,
resulting in serious threats to our network assets and organization's
properties. Botnets are collections of compromised computers (Bots) which are
remotely controlled by its originator (BotMaster) under a common
Command-and-Control (C&amp;C) infrastructure. They are used to distribute commands
to the Bots for malicious activities such as distributed denial-of-service
(DDoS) attacks, spam and phishing. Most of the existing Botnet detection
approaches concentrate only on particular Botnet command and control (C&amp;C)
protocols (e.g., IRC,HTTP) and structures (e.g., centralized), and can become
ineffective as Botnets change their structure and C&amp;C techniques. In this paper
at first we provide taxonomy of Botnets C&amp;C channels and evaluate well-known
protocols which are being used in each of them. Then we proposed a new general
detection framework which currently focuses on P2P based and IRC based Botnets.
This proposed framework is based on definition of Botnets. Botnet has been
defined as a group of bots that perform similar communication and malicious
activity patterns within the same Botnet. The point that distinguishes our
proposed detection framework from many other similar works is that there is no
need for prior knowledge of Botnets such as Botnet signature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1236</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1236</id><created>2010-04-07</created><updated>2012-02-10</updated><authors><author><keyname>Kakhbod</keyname><forenames>Ali</forenames></author><author><keyname>Yazdi</keyname><forenames>S. M. Sadegh Tabatabaei</forenames></author></authors><title>On Describing the Routing Capacity Regions of Networks</title><categories>math.OC cs.IT cs.NI math.IT</categories><journal-ref>Mathematical Methods of Operations Research (MMOR), vol 72, no. 1,
  pp. 95-106, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The routing capacity region of networks with multiple unicast sessions can be
characterized using Farkas' lemma as an infinite set of linear inequalities. In
this paper this result is sharpened by exploiting properties of the solution
satisfied by each rate-tuple on the boundary of the capacity region, and a
finite description of the routing capacity region which depends on network
parameters is offered. For the special case of undirected ring networks
additional results on the complexity of the description are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1237</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1237</id><created>2010-04-07</created><updated>2010-05-07</updated><authors><author><keyname>Ahmed</keyname><forenames>Eslam Gamal</forenames></author><author><keyname>Shaaban</keyname><forenames>Eman</forenames></author><author><keyname>Hashem</keyname><forenames>Mohamed</forenames></author></authors><title>Lightweight Distance bound Protocol for Low Cost RFID Tags</title><categories>cs.CR</categories><comments>Results in paper questionable. Article withdrawn by authors.</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Almost all existing RFID authentication schemes (tag/reader) are vulnerable
to relay attacks, because of their inability to estimate the distance to the
tag. These attacks are very serious since it can be mounted without the notice
of neither the reader nor the tag and cannot be prevented by cryptographic
protocols that operate at the application layer. Distance bounding protocols
represent a promising way to thwart relay attacks, by measuring the round trip
time of short authenticated messages. All the existing distance bounding
protocols use random number generator and hash functions at the tag side which
make them inapplicable at low cost RFID tags. This paper proposes a lightweight
distance bound protocol for low cost RFID tags. The proposed protocol based on
modified version of Gossamer mutual authentication protocol. The implementation
of the proposed protocol meets the limited abilities of low-cost RFID tags.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1239</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1239</id><created>2010-04-07</created><authors><author><keyname>Basha</keyname><forenames>Saleem</forenames></author><author><keyname>Ponnurangam</keyname><forenames>Dhavachelvan</forenames></author></authors><title>Analysis of Empirical Software Effort Estimation Models</title><categories>cs.SE</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Reliable effort estimation remains an ongoing challenge to software
engineers. Accurate effort estimation is the state of art of software
engineering, effort estimation of software is the preliminary phase between the
client and the business enterprise. The relationship between the client and the
business enterprise begins with the estimation of the software. The credibility
of the client to the business enterprise increases with the accurate
estimation. Effort estimation often requires generalizing from a small number
of historical projects. Generalization from such limited experience is an
inherently under constrained problem. Accurate estimation is a complex process
because it can be visualized as software effort prediction, as the term
indicates prediction never becomes an actual. This work follows the basics of
the empirical software effort estimation models. The goal of this paper is to
study the empirical software effort estimation. The primary conclusion is that
no single technique is best for all situations, and that a careful comparison
of the results of several approaches is most likely to produce realistic
estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1249</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1249</id><created>2010-04-08</created><updated>2011-10-30</updated><authors><author><keyname>Schnaitter</keyname><forenames>Karl</forenames></author><author><keyname>Polyzotis</keyname><forenames>Neoklis</forenames></author></authors><title>Semi-Automatic Index Tuning: Keeping DBAs in the Loop</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To obtain good system performance, a DBA must choose a set of indices that is
appropriate for the workload. The system can aid in this challenging task by
providing recommendations for the index configuration. We propose a new index
recommendation technique, termed semi-automatic tuning, that keeps the DBA &quot;in
the loop&quot; by generating recommendations that use feedback about the DBA's
preferences. The technique also works online, which avoids the limitations of
commercial tools that require the workload to be known in advance. The
foundation of our approach is the Work Function Algorithm, which can solve a
wide variety of online optimization problems with strong competitive
guarantees. We present an experimental analysis that validates the benefits of
semi-automatic tuning in a wide variety of conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1253</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1253</id><created>2010-04-08</created><authors><author><keyname>Kannan</keyname><forenames>Ravindran</forenames></author></authors><title>Spectral Methods for Matrices and Tensors</title><categories>cs.DS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While Spectral Methods have long been used for Principal Component Analysis,
this survey focusses on work over the last 15 years with three salient
features: (i) Spectral methods are useful not only for numerical problems, but
also discrete optimization problems (Constraint Optimization Problems - CSP's)
like the max. cut problem and similar mathematical considerations underlie both
areas. (ii) Spectral methods can be extended to tensors. The theory and
algorithms for tensors are not as simple/clean as for matrices, but the survey
describes methods for low-rank approximation which extend to tensors. These
tensor approximations help us solve Max-$r$-CSP's for $r&gt;2$ as well as
numerical tensor problems. (iii) Sampling on the fly plays a prominent role in
these methods. A primary result is that for any matrix, a random submatrix of
rows/columns picked with probabilities proportional to the squared lengths (of
rows/columns), yields estimates of the singular values as well as an
approximation to the whole matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1257</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1257</id><created>2010-04-08</created><authors><author><keyname>Chitraa</keyname><forenames>V.</forenames></author><author><keyname>Davamani</keyname><forenames>Dr. Antony Selvdoss</forenames></author></authors><title>A Survey on Preprocessing Methods for Web Usage Data</title><categories>cs.IR</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  World Wide Web is a huge repository of web pages and links. It provides
abundance of information for the Internet users. The growth of web is
tremendous as approximately one million pages are added daily. Users' accesses
are recorded in web logs. Because of the tremendous usage of web, the web log
files are growing at a faster rate and the size is becoming huge. Web data
mining is the application of data mining techniques in web data. Web Usage
Mining applies mining techniques in log data to extract the behavior of users
which is used in various applications like personalized services, adaptive web
sites, customer profiling, prefetching, creating attractive web sites etc., Web
usage mining consists of three phases preprocessing, pattern discovery and
pattern analysis. Web log data is usually noisy and ambiguous and preprocessing
is an important process before mining. For discovering patterns sessions are to
be constructed efficiently. This paper reviews existing work done in the
preprocessing stage. A brief overview of various data mining techniques for
discovering patterns, and pattern analysis are discussed. Finally a glimpse of
various applications of web usage mining is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1262</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1262</id><created>2010-04-08</created><updated>2010-05-31</updated><authors><author><keyname>Julliand</keyname><forenames>Jacques</forenames><affiliation>LIFC</affiliation></author><author><keyname>Stouls</keyname><forenames>Nicolas</forenames><affiliation>CITI Insa Lyon / INRIA Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Bu&#xe9;</keyname><forenames>Pierre-Christophe</forenames><affiliation>LIFC</affiliation></author><author><keyname>Masson</keyname><forenames>Pierre-Alain</forenames><affiliation>LIFC</affiliation></author></authors><title>Syntactic Abstraction of B Models to Generate Tests</title><categories>cs.LO cs.SC cs.SE</categories><comments>Tests and Proofs 2010, Malaga : Spain (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a model-based testing approach as well as for the verification of
properties, B models provide an interesting solution. However, for industrial
applications, the size of their state space often makes them hard to handle. To
reduce the amount of states, an abstraction function can be used, often
combining state variable elimination and domain abstractions of the remaining
variables. This paper complements previous results, based on domain abstraction
for test generation, by adding a preliminary syntactic abstraction phase, based
on variable elimination. We define a syntactic transformation that suppresses
some variables from a B event model, in addition to a method that chooses
relevant variables according to a test purpose. We propose two methods to
compute an abstraction A of an initial model M. The first one computes A as a
simulation of M, and the second one computes A as a bisimulation of M. The
abstraction process produces a finite state system. We apply this abstraction
computation to a Model Based Testing process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1267</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1267</id><created>2010-04-08</created><authors><author><keyname>Blond</keyname><forenames>Stevens Le</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Manils</keyname><forenames>Pere</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Chaabane</keyname><forenames>Abdelberi</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Kaafar</keyname><forenames>Mohamed Ali</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Castellucia</keyname><forenames>Claude</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>De-anonymizing BitTorrent Users on Tor</title><categories>cs.NI cs.CR</categories><comments>Poster accepted at the 7th USENIX Symposium on Network Design and
  Implementation (NSDI '10), San Jose, CA : United States (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some BitTorrent users are running BitTorrent on top of Tor to preserve their
privacy. In this extended abstract, we discuss three different attacks to
reveal the IP address of BitTorrent users on top of Tor. In addition, we
exploit the multiplexing of streams from different applications into the same
circuit to link non-BitTorrent applications to revealed IP addresses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1276</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1276</id><created>2010-04-08</created><authors><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Shi</keyname><forenames>Weisong</forenames></author><author><keyname>Liang</keyname><forenames>Yi</forenames></author></authors><title>In Cloud, Can Scientific Communities Benefit from the Economies of
  Scale?</title><categories>cs.DC</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The basic idea behind Cloud computing is that resource providers offer
elastic resources to end users. In this paper, we intend to answer one key
question to the success of Cloud computing: in Cloud, can small or medium-scale
scientific computing communities benefit from the economies of scale? Our
research contributions are three-fold: first, we propose an enhanced scientific
public cloud model (ESP) that encourages small- or medium-scale organizations
to rent elastic resources from a public cloud provider; second, on a basis of
the ESP model, we design and implement the DawningCloud system that can
consolidate heterogeneous scientific workloads on a Cloud site; third, we
propose an innovative emulation methodology and perform a comprehensive
evaluation. We found that for two typical workloads: high throughput computing
(HTC) and many task computing (MTC), DawningCloud saves the resource
consumption maximally by 44.5% (HTC) and 72.6% (MTC) for service providers, and
saves the total resource consumption maximally by 47.3% for a resource provider
with respect to the previous two public Cloud solutions. To this end, we
conclude that for typical workloads: HTC and MTC, DawningCloud can enable
scientific communities to benefit from the economies of scale of public Clouds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1277</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1277</id><created>2010-04-08</created><authors><author><keyname>Sun</keyname><forenames>Xiaojun</forenames></author><author><keyname>Zhao</keyname><forenames>Chunming</forenames></author><author><keyname>Jiang</keyname><forenames>Ming</forenames></author></authors><title>Closed-Form Expressions for Relay Selection with Secrecy Constraints</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An opportunistic relay selection based on instantaneous knowledge of channels
is considered to increase security against eavesdroppers. The closed-form
expressions are derived for the average secrecy rates and the outage
probability when the cooperative networks use Decode-and-Forward (DF) or
Amplify-and-Forward (AF) strategy. These techniques are demonstrated
analytically and with simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1298</identifier>
 <datestamp>2010-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1298</id><created>2010-04-08</created><updated>2010-12-09</updated><authors><author><keyname>Marschall</keyname><forenames>Tobias</forenames></author></authors><title>Construction of minimal DFAs from biological motifs</title><categories>cs.FL q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deterministic finite automata (DFAs) are constructed for various purposes in
computational biology. Little attention, however, has been given to the
efficient construction of minimal DFAs. In this article, we define simple
non-deterministic finite automata (NFAs) and prove that the standard subset
construction transforms NFAs of this type into minimal DFAs. Furthermore, we
show how simple NFAs can be constructed from two types of patterns popular in
bioinformatics, namely (sets of) generalized strings and (generalized) strings
with a Hamming neighborhood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1304</identifier>
 <datestamp>2010-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1304</id><created>2010-04-08</created><authors><author><keyname>Yu</keyname><forenames>Gang</forenames></author><author><keyname>Ma</keyname><forenames>Xiaoxiao</forenames></author><author><keyname>Shen</keyname><forenames>Yong</forenames></author><author><keyname>Han</keyname><forenames>Wenbao</forenames></author></authors><title>Provable Secure Identity Based Generalized Signcryption Scheme</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to actual needs, generalized signcryption scheme can flexibly work
as an encryption scheme, a signature scheme or a signcryption scheme. In this
paper, firstly, we give a security model for identity based generalized
signcryption which is more complete than existing model. Secondly, we propose
an identity based generalized signcryption scheme. Thirdly, we give the
security proof of the new scheme in this complete model. Comparing with
existing identity based generalized signcryption, the new scheme has less
implementation complexity. Moreover, the new scheme has comparable computation
complexity with the existing normal signcryption schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1324</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1324</id><created>2010-04-08</created><authors><author><keyname>Burke</keyname><forenames>Michael</forenames></author><author><keyname>Audsley</keyname><forenames>Neil</forenames></author></authors><title>Distributed Fault-Tolerant Avionic Systems - A Real-Time Perspective</title><categories>cs.DC</categories><journal-ref>Proceedings of IEEE Aerospace, IEEE Computer Society Press, Aspen,
  U.S.A. (pp. 8.104.1 - 8.104.18)(1998)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the problem of introducing advanced forms of
fault-tolerance via reconfiguration into safety-critical avionic systems. This
is required to enable increased availability after fault occurrence in
distributed integrated avionic systems(compared to static federated systems).
The approach taken is to identify a migration path from current architectures
to those that incorporate re-configuration to a lesser or greater degree. Other
challenges identified include change of the development process; incremental
and flexible timing and safety analyses; configurable kernels applicable for
safety-critical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1367</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1367</id><created>2010-04-08</created><updated>2010-09-14</updated><authors><author><keyname>Effenberger</keyname><forenames>Felix</forenames></author><author><keyname>Spreer</keyname><forenames>Jonathan</forenames></author></authors><title>simpcomp -- A GAP toolbox for simplicial complexes</title><categories>math.CO cs.DM math.GT</categories><comments>4 pages</comments><msc-class>52-04, 57Q15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  simpcomp is an extension (a so called package) to GAP, the well known system
for computational discrete algebra. The package enables the user to compute
numerous properties of (abstract) simplicial complexes, provides functions to
construct new complexes from existing ones and an extensive library of
triangulations of manifolds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1379</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1379</id><created>2010-04-08</created><updated>2011-07-12</updated><authors><author><keyname>Blasiak</keyname><forenames>Anna</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author></authors><title>Index coding via linear programming</title><categories>cs.IT math.CO math.IT</categories><comments>31 pages, 2 figures</comments><msc-class>94A29, 90C35, 68P30, 05C35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Index Coding has received considerable attention recently motivated in part
by real-world applications and in part by its connection to Network Coding. The
basic setting of Index Coding encodes the problem input as an undirected graph
and the fundamental parameter is the broadcast rate $\beta$, the average
communication cost per bit for sufficiently long messages (i.e. the non-linear
vector capacity). Recent nontrivial bounds on $\beta$ were derived from the
study of other Index Coding capacities (e.g. the scalar capacity $\beta_1$) by
Bar-Yossef et al (2006), Lubetzky and Stav (2007) and Alon et al (2008).
However, these indirect bounds shed little light on the behavior of $\beta$:
there was no known polynomial-time algorithm for approximating $\beta$ in a
general network to within a nontrivial (i.e. $o(n)$) factor, and the exact
value of $\beta$ remained unknown for any graph where Index Coding is
nontrivial.
  Our main contribution is a direct information-theoretic analysis of the
broadcast rate $\beta$ using linear programs, in contrast to previous
approaches that compared $\beta$ with graph-theoretic parameters. This allows
us to resolve the aforementioned two open questions. We provide a
polynomial-time algorithm with a nontrivial approximation ratio for computing
$\beta$ in a general network along with a polynomial-time decision procedure
for recognizing instances with $\beta=2$. In addition, we pinpoint $\beta$
precisely for various classes of graphs (e.g. for various Cayley graphs of
cyclic groups) thereby simultaneously improving the previously known upper and
lower bounds for these graphs. Via this approach we construct graphs where the
difference between $\beta$ and its trivial lower bound is linear in the number
of vertices and ones where $\beta$ is uniformly bounded while its upper bound
derived from the naive encoding scheme is polynomially worse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1399</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1399</id><created>2010-04-08</created><updated>2010-07-13</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>A note on the entropy of repetitive sequences of symmetry group
  permutations</title><categories>cs.IT math.IT</categories><comments>Paper has been witdrawn pending corrections to equations and
  formalism; 3 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper makes the observation that all orders of information entropy are
equal in signals composed of repeating units of distinct symbols where the
units can be classified as a member of a symmetry group. This leads to an
improved metric for measuring the information content of higher order entropies
in data such as text, signals, or genetics and another measure of similarity to
compare the incremental information content across entropy orders when
comparing data of different sizes and symbol sets or when comparing entire
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1423</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1423</id><created>2010-04-08</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Strong Secrecy and Reliable Byzantine Detection in the Presence of an
  Untrusted Relay</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, March 2010. 35
  pages.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Gaussian two-hop network where the source and the destination
can communicate only via a relay node who is both an eavesdropper and a
Byzantine adversary. Both the source and the destination nodes are allowed to
transmit, and the relay receives a superposition of their transmitted signals.
We propose a new coding scheme that satisfies two requirements simultaneously:
the transmitted message must be kept secret from the relay node, and the
destination must be able to detect any Byzantine attack that the relay node
might launch reliably and fast. The three main components of the scheme are the
nested lattice code, the privacy amplification and the algebraic manipulation
detection (AMD)code. Specifically, for the Gaussian two-hop network, we show
that lattice coding can successfully pair with AMD codes enabling its first
application to a noisy channel model. We prove, using this new coding scheme,
that the probability that the Byzantine attack goes undetected decreases
exponentially fast with respect to the number of channel uses, while the loss
in the secrecy rate, compared to the rate achievable when the relay is honest,
can be made arbitrarily small. In addition, in contrast with prior work in
Gaussian channels, the notion of secrecy provided here is strong secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1434</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1434</id><created>2010-04-08</created><authors><author><keyname>Meyer</keyname><forenames>David A.</forenames></author><author><keyname>Pommersheim</keyname><forenames>James</forenames></author></authors><title>On the uselessness of quantum queries</title><categories>quant-ph cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a prior probability distribution over a set of possible oracle
functions, we define a number of queries to be useless for determining some
property of the function if the probability that the function has the property
is unchanged after the oracle responds to the queries. A familiar example is
the parity of a uniformly random Boolean-valued function over $\{1,2,...,N\}$,
for which $N-1$ classical queries are useless. We prove that if $2k$ classical
queries are useless for some oracle problem, then $k$ quantum queries are also
useless. For such problems, which include classical threshold secret sharing
schemes, our result also gives a new way to obtain a lower bound on the quantum
query complexity, even in cases where neither the function nor the property to
be determined is Boolean.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1437</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1437</id><created>2010-04-08</created><updated>2010-06-18</updated><authors><author><keyname>Feofiloff</keyname><forenames>Paulo</forenames></author><author><keyname>Fernandes</keyname><forenames>Cristina G.</forenames></author><author><keyname>Ferreira</keyname><forenames>Carlos E.</forenames></author><author><keyname>de Pina</keyname><forenames>Jose Coelho</forenames></author></authors><title>A note on Johnson, Minkoff and Phillips' algorithm for the
  Prize-Collecting Steiner Tree Problem</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primal-dual scheme has been used to provide approximation algorithms for
many problems. Goemans and Williamson gave a (2-1/(n-1))-approximation for the
Prize-Collecting Steiner Tree Problem that runs in O(n^3 log n) time. it
applies the primal-dual scheme once for each of the n vertices of the graph.
Johnson, Minkoff and Phillips proposed a faster implementation of Goemans and
Williamson's algorithm. We give a proof that the approximation ratio of this
implementation is exactly 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1447</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1447</id><created>2010-04-08</created><updated>2010-12-16</updated><authors><author><keyname>Chazelle</keyname><forenames>Bernard</forenames></author></authors><title>The Total s-Energy of a Multiagent System</title><categories>nlin.AO cs.MA math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the &quot;total s-energy&quot; of a multiagent system with time-dependent
links. This provides a new analytical lens on bidirectional agreement dynamics,
which we use to bound the convergence rates of dynamical systems for
synchronization, flocking, opinion dynamics, and social epistemology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1449</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1449</id><created>2010-04-08</created><updated>2010-11-08</updated><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author><author><keyname>Nisan</keyname><forenames>Noam</forenames></author></authors><title>Multi-Unit Auctions: Beyond Roberts</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit incentive compatible multi-unit auctions that are not affine
maximizers (i.e., are not of the VCG family) and yet approximate the social
welfare to within a factor of $1+\epsilon$. For the case of two-item two-bidder
auctions we show that these auctions, termed Triage auctions, are the only
scalable ones that give an approximation factor better than 2. &quot;Scalable&quot; means
that the allocation does not depend on the units in which the valuations are
measured. We deduce from this that any scalable computationally-efficient
incentive-compatible auction for $m$ items and $n \ge 2$ bidders cannot
approximate the social welfare to within a factor better than 2. This is in
contrast to arbitrarily good approximations that can be reached under
computational constraints alone, and in contrast to the fact that the optimal
social welfare can be obtained under incentive constraints alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1460</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1460</id><created>2010-04-09</created><authors><author><keyname>Stouls</keyname><forenames>Nicolas</forenames><affiliation>LSR - IMAG</affiliation></author><author><keyname>Potet</keyname><forenames>Marie-Laure</forenames><affiliation>LSR - IMAG, IMAG</affiliation></author></authors><title>Security Policy Enforcement Through Refinement Process</title><categories>cs.CR cs.LO</categories><proxy>ccsd</proxy><journal-ref>B 2007, besan\c{c}on : France (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the area of networks, a common method to enforce a security policy
expressed in a high-level language is based on an ad-hoc and manual rewriting
process. We argue that it is possible to build a formal link between concrete
and abstract terms, which can be dynamically computed from the environment
data. In order to progressively introduce configuration data and then simplify
the proof obligations, we use the B refinement process. We present a case study
modeling a network monitor. This program, described by refinement following the
layers of the TCP/IP suite protocol, has to warn for all observed events which
do not respect the security policy. To design this model, we use the event-B
method because it is suitable for modeling network concepts. This work has been
done within the framework of the POTESTAT project, based on the research of
network testing methods from a high-level security policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1461</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1461</id><created>2010-04-09</created><authors><author><keyname>Manils</keyname><forenames>Pere</forenames><affiliation>All - INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Abdelberri</keyname><forenames>Chaabane</forenames><affiliation>All - INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Blond</keyname><forenames>Stevens Le</forenames><affiliation>All - INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Kaafar</keyname><forenames>Mohamed Ali</forenames><affiliation>All - INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Castelluccia</keyname><forenames>Claude</forenames><affiliation>All - INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>All - INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Dabbous</keyname><forenames>Walid</forenames><affiliation>All - INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Compromising Tor Anonymity Exploiting P2P Information Leakage</title><categories>cs.NI cs.CR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy of users in P2P networks goes far beyond their current usage and is a
fundamental requirement to the adoption of P2P protocols for legal usage. In a
climate of cold war between these users and anti-piracy groups, more and more
users are moving to anonymizing networks in an attempt to hide their identity.
However, when not designed to protect users information, a P2P protocol would
leak information that may compromise the identity of its users. In this paper,
we first present three attacks targeting BitTorrent users on top of Tor that
reveal their real IP addresses. In a second step, we analyze the Tor usage by
BitTorrent users and compare it to its usage outside of Tor. Finally, we depict
the risks induced by this de-anonymization and show that users' privacy
violation goes beyond BitTorrent traffic and contaminates other protocols such
as HTTP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1472</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1472</id><created>2010-04-09</created><authors><author><keyname>Bert</keyname><forenames>Didier</forenames><affiliation>LSR - IMAG</affiliation></author><author><keyname>Potet</keyname><forenames>Marie-Laure</forenames><affiliation>LSR - IMAG</affiliation></author><author><keyname>Stouls</keyname><forenames>Nicolas</forenames><affiliation>LSR - IMAG</affiliation></author></authors><title>GeneSyst: a Tool to Reason about Behavioral Aspects of B Event
  Specifications. Application to Security Properties.</title><categories>cs.LO cs.CR</categories><proxy>ccsd</proxy><journal-ref>Formal Specification and Development in Z and B, 4th International
  Conference of B and Z Users, Guildford : United Kingdom (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a method and a tool to build symbolic labelled
transition systems from B specifications. The tool, called GeneSyst, can take
into account refinement levels and can visualize the decomposition of abstract
states in concrete hierarchical states. The resulting symbolic transition
system represents all the behaviors of the initial B event system. So, it can
be used to reason about them. We illustrate the use of GeneSyst to check
security properties on a model of electronic purse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1485</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1485</id><created>2010-04-09</created><authors><author><keyname>Ganian</keyname><forenames>Robert</forenames></author><author><keyname>Hlin&#x11b;n&#xfd;</keyname><forenames>Petr</forenames></author><author><keyname>Kneis</keyname><forenames>Joachim</forenames></author><author><keyname>Meister</keyname><forenames>Daniel</forenames></author><author><keyname>Obdr&#x17e;&#xe1;lek</keyname><forenames>Jan</forenames></author><author><keyname>Rossmanith</keyname><forenames>Peter</forenames></author><author><keyname>Sikdar</keyname><forenames>Somnath</forenames></author></authors><title>Are there any good digraph width measures?</title><categories>cs.DM cs.DS</categories><doi>10.1007/978-3-642-17493-3_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several different measures for digraph width have appeared in the last few
years. However, none of them shares all the &quot;nice&quot; properties of treewidth:
First, being \emph{algorithmically useful} i.e. admitting polynomial-time
algorithms for all $\MS1$-definable problems on digraphs of bounded width. And,
second, having nice \emph{structural properties} i.e. being monotone under
taking subdigraphs and some form of arc contractions. As for the former,
(undirected) $\MS1$ seems to be the least common denominator of all reasonably
expressive logical languages on digraphs that can speak about the edge/arc
relation on the vertex set.The latter property is a necessary condition for a
width measure to be characterizable by some version of the cops-and-robber game
characterizing the ordinary treewidth. Our main result is that \emph{any
reasonable} algorithmically useful and structurally nice digraph measure cannot
be substantially different from the treewidth of the underlying undirected
graph. Moreover, we introduce \emph{directed topological minors} and argue that
they are the weakest useful notion of minors for digraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1503</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1503</id><created>2010-04-09</created><updated>2014-07-08</updated><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>A New Construction for Constant Weight Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, to be presented in ISIT2014, melbourne, Australia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new construction for constant weight codes is presented. The codes are
constructed from $k$-dimensional subspaces of the vector space $\F_q^n$. These
subspaces form a constant dimension code in the Grassmannian space
$\cG_q(n,k)$. Some of the constructed codes are optimal constant weight codes
with parameters not known before. An efficient algorithm for error-correction
is given for the constructed codes. If the constant dimension code has an
efficient encoding and decoding algorithms then also the constructed constant
weight code has an efficient encoding and decoding algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1511</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1511</id><created>2010-04-09</created><authors><author><keyname>Tolhuizen</keyname><forenames>Ludo</forenames></author></authors><title>Bounds for codes for a non-symmetric ternary channel</title><categories>cs.IT math.IT</categories><comments>To be presented at 31st WIC Symposium on Information Theory in the
  Benelux, Rotterdam, the Netherlands, May 11-12, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide bounds for codes for a non-symmetric channel or, equivalently, for
ternary codes with the Manhattan distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1521</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1521</id><created>2010-04-09</created><updated>2010-06-15</updated><authors><author><keyname>Calude</keyname><forenames>Cristian S.</forenames></author><author><keyname>Dinneen</keyname><forenames>Michael J.</forenames></author><author><keyname>Dumitrescu</keyname><forenames>Monica</forenames></author><author><keyname>Svozil</keyname><forenames>Karl</forenames></author></authors><title>Experimental Evidence of Quantum Randomness Incomputability</title><categories>quant-ph cs.CC</categories><comments>23 pages, 5 figures, statistical analysis added, other sections
  greatly expanded</comments><journal-ref>Phys. Rev. A 82, 022102 (2010) [8 pages]</journal-ref><doi>10.1103/PhysRevA.82.022102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast with software-generated randomness (called pseudo-randomness),
quantum randomness is provable incomputable, i.e.\ it is not exactly
reproducible by any algorithm. We provide experimental evidence of
incomputability --- an asymptotic property --- of quantum randomness by
performing finite tests of randomness inspired by algorithmic information
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1540</identifier>
 <datestamp>2010-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1540</id><created>2010-04-09</created><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames><affiliation>UNM</affiliation></author><author><keyname>Dezert</keyname><forenames>Jean</forenames><affiliation>ONERA</affiliation></author></authors><title>Importance of Sources using the Repeated Fusion Method and the
  Proportional Conflict Redistribution Rules #5 and #6</title><categories>cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present in this paper some examples of how to compute by hand the PCR5
fusion rule for three sources, so the reader will better understand its
mechanism. We also take into consideration the importance of sources, which is
different from the classical discounting of sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1564</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1564</id><created>2010-04-09</created><updated>2010-04-12</updated><authors><author><keyname>Han</keyname><forenames>Te Sun</forenames></author></authors><title>Polymatroids with Network Coding</title><categories>cs.IT math.IT</categories><comments>19 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of network coding for multicasting a single source to multiple
sinks has first been studied by Ahlswede, Cai, Li and Yeung in 2000, in which
they have established the celebrated max-flow mini-cut theorem on non-physical
information flow over a network of independent channels. On the other hand, in
1980, Han has studied the case with correlated multiple sources and a single
sink from the viewpoint of polymatroidal functions in which a necessary and
sufficient condition has been demonstrated for reliable transmission over the
network. This paper presents an attempt to unify both cases, which leads to
establish a necessary and sufficient condition for reliable transmission over a
noisy network for multicasting all the correlated multiple sources to all the
multiple sinks. Furthermore, we address also the problem of transmitting
&quot;independent&quot; sources over a multiple-access-type of network as well as over a
broadcast-type of network, which reveals that the (co-) polymatroidal
structures are intrinsically involved in these types of network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1569</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1569</id><created>2010-04-09</created><updated>2010-10-28</updated><authors><author><keyname>Sharma</keyname><forenames>Gokarna</forenames></author><author><keyname>Busch</keyname><forenames>Costas</forenames></author><author><keyname>Tirthapura</keyname><forenames>Srikanta</forenames></author></authors><title>A Streaming Approximation Algorithm for Klee's Measure Problem</title><categories>cs.DS cs.DB</categories><comments>This paper has been withdrawn by the author due to a small technical
  error in Algorithm 3 and 4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficient estimation of frequency moments of a data stream in one-pass
using limited space and time per item is one of the most fundamental problem in
data stream processing. An especially important estimation is to find the
number of distinct elements in a data stream, which is generally referred to as
the zeroth frequency moment and denoted by $F_0$. In this paper, we consider
streams of rectangles defined over a discrete space and the task is to compute
the total number of distinct points covered by the rectangles. This is known as
the Klee's measure problem in 2 dimensions. We present and analyze a randomized
streaming approximation algorithm which gives an $(\epsilon,
\delta)$-approximation of $F_0$ for the total area of Klee's measure problem in
2 dimensions. Our algorithm achieves the following complexity bounds: (a) the
amortized processing time per rectangle is $O(\frac{1}{\epsilon^4}\log^3
n\log\frac{1}{\delta})$; (b) the space complexity is
$O(\frac{1}{\epsilon^2}\log n \log\frac{1}{\delta})$ bits; and (c) the time to
answer a query for $F_0$ is $O(\log\frac{1}{\delta})$, respectively. To our
knowledge, this is the first streaming approximation for the Klee's measure
problem that achieves sub-polynomial bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1578</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1578</id><created>2010-04-09</created><authors><author><keyname>Tan</keyname><forenames>Jinsong</forenames></author></authors><title>The Networked Common Goods Game</title><categories>cs.GT</categories><acm-class>J.4; I.2.11</acm-class><doi>10.1007/978-3-642-17461-2_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new class of games called the networked common goods game
(NCGG), which generalizes the well-known common goods game. We focus on a
fairly general subclass of the game where each agent's utility functions are
the same across all goods the agent is entitled to and satisfy certain natural
properties (diminishing return and smoothness). We give a comprehensive set of
technical results listed as follows.
  * We show the optimization problem faced by a single agent can be solved
efficiently in this subclass. The discrete version of the problem is however
NP-hard but admits an fully polynomial time approximation scheme (FPTAS).
  * We show uniqueness results of pure strategy Nash equilibrium of NCGG, and
that the equilibrium is fully characterized by the structure of the network and
independent of the choices and combinations of agent utility functions.
  * We show NCGG is a potential game, and give an implementation of best/better
response Nash dynamics that lead to fast convergence to an
$\epsilon$-approximate pure strategy Nash equilibrium.
  * Lastly, we show the price of anarchy of NCGG can be as large as
$\Omega(n^{1-\epsilon})$ (for any $\epsilon&gt;0$), which means selfish behavior
in NCGG can lead to extremely inefficient social outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1586</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1586</id><created>2010-04-09</created><updated>2012-07-11</updated><authors><author><keyname>Gamarnik</keyname><forenames>David</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wei</keyname><forenames>Yehua</forenames></author></authors><title>Belief Propagation for Min-cost Network Flow: Convergence and
  Correctness</title><categories>cs.DM cs.AI</categories><comments>This paper has been withdrawn as it is not up-to-date. The new
  version of this paper can be found at
  web.mit.edu/devavrat/www/OR-BP-Preprint.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Message passing type algorithms such as the so-called Belief Propagation
algorithm have recently gained a lot of attention in the statistics, signal
processing and machine learning communities as attractive algorithms for
solving a variety of optimization and inference problems. As a decentralized,
easy to implement and empirically successful algorithm, BP deserves attention
from the theoretical standpoint, and here not much is known at the present
stage. In order to fill this gap we consider the performance of the BP
algorithm in the context of the capacitated minimum-cost network flow problem -
the classical problem in the operations research field. We prove that BP
converges to the optimal solution in the pseudo-polynomial time, provided that
the optimal solution of the underlying problem is unique and the problem input
is integral. Moreover, we present a simple modification of the BP algorithm
which gives a fully polynomial-time randomized approximation scheme (FPRAS) for
the same problem, which no longer requires the uniqueness of the optimal
solution. This is the first instance where BP is proved to have
fully-polynomial running time. Our results thus provide a theoretical
justification for the viability of BP as an attractive method to solve an
important class of optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1588</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1588</id><created>2010-04-09</created><authors><author><keyname>Cheung</keyname><forenames>Yam Ki</forenames></author><author><keyname>Daescu</keyname><forenames>Ovidiu</forenames></author></authors><title>Approximate Point-to-Face Shortest Paths in R^3</title><categories>cs.CG</categories><comments>16 pages, Latex</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the point-to-face approximate shortest path problem in R: Given a
set of polyhedral obstacles with a total of n vertices, a source point s, an
obstacle face f, and a real positive parameter epsilon, compute a path from s
to f that avoids the interior of the obstacles and has length at most
(1+epsilon) times the length of the shortest obstacle avoiding path from s to
f. We present three approximation algorithms that take by extending three
well-known &quot;point-to-point&quot; shortest path algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1598</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1598</id><created>2010-04-09</created><updated>2012-11-16</updated><authors><author><keyname>Coecke</keyname><forenames>Bob</forenames><affiliation>Oxford University</affiliation></author><author><keyname>Perdrix</keyname><forenames>Simon</forenames><affiliation>IMAG Grenoble</affiliation></author></authors><title>Environment and classical channels in categorical quantum mechanics</title><categories>quant-ph cs.LO math-ph math.CT math.MP</categories><comments>26 pages, many pics; this third version has substantially more
  explanations than previous ones; Journal reference is of short 14 page
  version; Proceedings of the 19th EACSL Annual Conference on Computer Science
  Logic (CSL), Lecture Notes in Computer Science 6247, Springer-Verlag (2010)</comments><proxy>LMCS</proxy><acm-class>F.1.1, F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 4 (November
  19, 2012) lmcs:719</journal-ref><doi>10.2168/LMCS-8(4:14)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a both simple and comprehensive graphical calculus for quantum
computing. In particular, we axiomatize the notion of an environment, which
together with the earlier introduced axiomatic notion of classical structure
enables us to define classical channels, quantum measurements and classical
control. If we moreover adjoin the earlier introduced axiomatic notion of
complementarity, we obtain sufficient structural power for constructive
representation and correctness derivation of typical quantum informatic
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1614</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1614</id><created>2010-04-09</created><authors><author><keyname>Sarma</keyname><forenames>Anish Das</forenames></author><author><keyname>Jain</keyname><forenames>Alpa</forenames></author><author><keyname>Bohannon</keyname><forenames>Philip</forenames></author></authors><title>PROBER: Ad-Hoc Debugging of Extraction and Integration Pipelines</title><categories>cs.DB</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex information extraction (IE) pipelines assembled by plumbing together
off-the-shelf operators, specially customized operators, and operators re-used
from other text processing pipelines are becoming an integral component of most
text processing frameworks. A critical task faced by the IE pipeline user is to
run a post-mortem analysis on the output. Due to the diverse nature of
extraction operators (often implemented by independent groups), it is time
consuming and error-prone to describe operator semantics formally or
operationally to a provenance system. We introduce the first system that helps
IE users analyze pipeline semantics and infer provenance interactively while
debugging. This allows the effort to be proportional to the need, and to focus
on the portions of the pipeline under the greatest suspicion. We present a
generic debugger for running post-execution analysis of any IE pipeline
consisting of arbitrary types of operators. We propose an effective provenance
model for IE pipelines which captures a variety of operator types, ranging from
those for which full or no specifications are available. We present a suite of
algorithms to effectively build provenance and facilitate debugging. Finally,
we present an extensive experimental study on large-scale real-world
extractions from an index of ~500 million Web documents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1632</identifier>
 <datestamp>2010-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1632</id><created>2010-04-09</created><updated>2010-09-07</updated><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Thed N.</forenames></author><author><keyname>Visser</keyname><forenames>Martijn S.</forenames></author><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author></authors><title>Towards a new crown indicator: An empirical analysis</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an empirical comparison between two normalization mechanisms for
citation-based indicators of research performance. These mechanisms aim to
normalize citation counts for the field and the year in which a publication was
published. One mechanism is applied in the current so-called crown indicator of
our institute. The other mechanism is applied in the new crown indicator that
our institute is planning to adopt. We find that at high aggregation levels,
such as at the level of large research institutions or at the level of
countries, the differences between the two mechanisms are very small. At lower
aggregation levels, such as at the level of research groups or at the level of
journals, the differences between the two mechanisms are somewhat larger. We
pay special attention to the way in which recent publications are handled.
These publications typically have very low citation counts and should therefore
be handled with special care.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1654</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1654</id><created>2010-04-09</created><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author></authors><title>Approximate Euclidean Ramsey theorems</title><categories>math.CO cs.CG</categories><comments>11 pages, 1 figure.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to a classical result of Szemer\'{e}di, every dense subset of
$1,2,...,N$ contains an arbitrary long arithmetic progression, if $N$ is large
enough. Its analogue in higher dimensions due to F\&quot;urstenberg and Katznelson
says that every dense subset of $\{1,2,...,N\}^d$ contains an arbitrary large
grid, if $N$ is large enough. Here we generalize these results for separated
point sets on the line and respectively in the Euclidean space: (i) every dense
separated set of points in some interval $[0,L]$ on the line contains an
arbitrary long approximate arithmetic progression, if $L$ is large enough. (ii)
every dense separated set of points in the $d$-dimensional cube $[0,L]^d$ in
$\RR^d$ contains an arbitrary large approximate grid, if $L$ is large enough. A
further generalization for any finite pattern in $\RR^d$ is also established.
The separation condition is shown to be necessary for such results to hold. In
the end we show that every sufficiently large point set in $\RR^d$ contains an
arbitrarily large subset of almost collinear points. No separation condition is
needed in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1666</identifier>
 <datestamp>2010-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1666</id><created>2010-04-09</created><updated>2010-05-20</updated><authors><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>Optimal stochastic planarization</title><categories>cs.CG cs.DM cs.DS math.MG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown by Indyk and Sidiropoulos [IS07] that any graph of genus
g&gt;0 can be stochastically embedded into a distribution over planar graphs with
distortion 2^O(g). This bound was later improved to O(g^2) by Borradaile, Lee
and Sidiropoulos [BLS09]. We give an embedding with distortion O(log g), which
is asymptotically optimal. Apart from the improved distortion, another
advantage of our embedding is that it can be computed in polynomial time. In
contrast, the algorithm of [BLS09] requires solving an NP-hard problem. Our
result implies in particular a reduction for a large class of geometric
optimization problems from instances on genus-g graphs, to corresponding ones
on planar graphs, with a O(log g) loss factor in the approximation guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1672</identifier>
 <datestamp>2014-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1672</id><created>2010-04-09</created><updated>2014-06-02</updated><authors><author><keyname>Cao</keyname><forenames>Yixin</forenames></author><author><keyname>Chen</keyname><forenames>Jianer</forenames></author><author><keyname>Liu</keyname><forenames>Yang</forenames></author></authors><title>On Feedback Vertex Set: New Measure and New Structures</title><categories>cs.DS</categories><comments>Final version, to appear in Algorithmica</comments><acm-class>G.2.2; F.2.2</acm-class><doi>10.1007/s00453-014-9904-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new parameterized algorithm for the {feedback vertex set}
problem ({\sc fvs}) on undirected graphs. We approach the problem by
considering a variation of it, the {disjoint feedback vertex set} problem ({\sc
disjoint-fvs}), which finds a feedback vertex set of size $k$ that has no
overlap with a given feedback vertex set $F$ of the graph $G$. We develop an
improved kernelization algorithm for {\sc disjoint-fvs} and show that {\sc
disjoint-fvs} can be solved in polynomial time when all vertices in $G
\setminus F$ have degrees upper bounded by three. We then propose a new
branch-and-search process on {\sc disjoint-fvs}, and introduce a new
branch-and-search measure. The process effectively reduces a given graph to a
graph on which {\sc disjoint-fvs} becomes polynomial-time solvable, and the new
measure more accurately evaluates the efficiency of the process. These
algorithmic and combinatorial studies enable us to develop an
$O^*(3.83^k)$-time parameterized algorithm for the general {\sc fvs} problem,
improving all previous algorithms for the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1673</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1673</id><created>2010-04-09</created><authors><author><keyname>O.</keyname><forenames>Agushaka J.</forenames></author><author><keyname>M.</keyname><forenames>Lawal M.</forenames></author><author><keyname>Bagiwa</keyname></author><author><keyname>M.</keyname><forenames>A.</forenames></author><author><keyname>F</keyname><forenames>Abdullahi B.</forenames></author></authors><title>Effect of Weighting Scheme to QoS Properties in Web Service Discovery</title><categories>cs.OH</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><report-no>Computer Science ISSN 19475500</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Specifying QoS properties can limit the selection of some good web services
that the user will have considered; this is because the algorithm used strictly
ensures that there is a match between QoS properties of the consumer with that
of the available services. This is to say that, a situation may arise that some
services might not have all that the user specifies but are rated high in those
they have. With some tradeoffs specified in form of weight, these services will
be made available to the user for consideration. This assertion is from the
fact that, the user's requirements for the specified QoS properties are of
varying degree i.e. he will always prefer one ahead of the other. This can be
captured in form of weight i.e. the one preferred most will have the highest
weight. If a consumer specifies light weight for those QoS properties that a
web service is deficient in and high weight for those it has, this will
minimize the difference between them. Hence the service can be returned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1674</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1674</id><created>2010-04-09</created><authors><author><keyname>T</keyname><forenames>Adiline Macriga.</forenames></author><author><keyname>Kumar</keyname><forenames>Dr. P. Anandha</forenames></author></authors><title>Seamless Data Services for Real Time Communication in a Heterogeneous
  Networks using Network Tracking and Management</title><categories>cs.NI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 84-91</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Heterogeneous Networks is the integration of all existing networks under a
single environment with an understanding between the functional operations and
also includes the ability to make use of multiple broadband transport
technologies and to support generalized mobility. It is a challenging feature
for Heterogeneous networks to integrate several IP-based access technologies in
a seamless way. The focus of this paper is on the requirements of a mobility
management scheme for multimedia real-time communication services - Mobile
Video Conferencing. Nowadays, the range of available wireless access network
technologies includes cellular or wide-area wireless systems, such as cellular
networks (GSM/GPRS/UMTS) or Wi-Max, local area Network or personal area
wireless systems, comprising for example, WLAN (802.11 a/b/g) and Bluetooth. As
the mobile video conferencing is considered, the more advanced mobile terminals
are capable of having more than one interface active at the same time. In
addition, the heterogeneity of access technologies and also the seamless flow
of information will increase in the future, making the seamless integration of
the access network a key challenge for mobility management in a heterogeneous
network environment. Services must be provided to the user regardless of the
particular access technology and also the type of service provider or the
network used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1675</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1675</id><created>2010-04-09</created><authors><author><keyname>Shukla</keyname><forenames>Shailja</forenames></author><author><keyname>Tiwari</keyname><forenames>Mukesh</forenames></author></authors><title>Fuzzy Logic of Speed and Steering Control System for Three Dimensional
  Line Following of an Autonomous Vehicle</title><categories>cs.RO</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  ... This paper is to describe exploratory research on the design of a modular
autonomous mobile robot controller. The controller incorporates a fuzzy logic
[8] [9] approach for steering and speed control [37], a FL approach for
ultrasound sensing and an overall expert system for guidance. The advantages of
a modular system are related to portability and transportability, i.e. any
vehicle can become autonomous with minimal modifications. A mobile robot test
bed has been constructed in university of Cincinnati using a golf cart base.
This cart has full speed control with guidance provided by a vision system and
obstacle avoidance using ultrasonic sensors. The speed and steering fuzzy logic
controller is supervised through a multi-axis motion controller. The obstacle
avoidance system is based on a microcontroller interfaced with ultrasonic
transducers. This micro-controller independently handles all timing and
distance calculations and sends distance information back to the fuzzy logic
controller via the serial line. This design yields a portable independent
system in which high speed computer communication is not necessary. Vision
guidance has been accomplished with the use of CCD cameras judging the current
position of the robot.[34] [35][36] It will be generating a good image for
reducing an uncertain wrong command from ground coordinate to tackle the
parameter uncertainties of the system, and to obtain good WMR dynamic
response.[1] Here we Apply 3D line following mythology. It transforms from 3D
to 2D and also maps the image coordinates and vice versa, leading to the
improved accuracy of the WMR position. ...
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1676</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1676</id><created>2010-04-09</created><authors><author><keyname>Kumar</keyname><forenames>P. Mohan</forenames></author><author><keyname>Shunmuganathan</keyname><forenames>K. L.</forenames></author></authors><title>A reversible high embedding capacity data hiding technique for hiding
  secret data in images</title><categories>cs.MM</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  As the multimedia and internet technologies are growing fast, the
transmission of digital media plays an important role in communication. The
various digital media like audio, video and images are being transferred
through internet. There are a lot of threats for the digital data that are
transferred through internet. Also, a number of security techniques have been
employed to protect the data that is transferred through internet. This paper
proposes a new technique for sending secret messages securely, using
steganographic technique. Since the proposed system uses multiple level of
security for data hiding, where the data is hidden in an image file and the
stego file is again concealed in another image. Previously, the secret message
is being encrypted with the encryption algorithm which ensures the achievement
of high security enabled data transfer through internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1677</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1677</id><created>2010-04-09</created><authors><author><keyname>Renjit</keyname><forenames>J. Arokia</forenames></author><author><keyname>Shunmuganathan</keyname><forenames>K. L.</forenames></author></authors><title>Mining The Data From Distributed Database Using An Improved Mining
  Algorithm</title><categories>cs.DB</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Association rule mining is an active data mining research area and most ARM
algorithms cater to a centralized environment. Centralized data mining to
discover useful patterns in distributed databases isn't always feasible because
merging data sets from different sites incurs huge network communication costs.
In this paper, an Improved algorithm based on good performance level for data
mining is being proposed. In local sites, it runs the application based on the
improved LMatrix algorithm, which is used to calculate local support counts.
Local Site also finds a centre site to manage every message exchanged to obtain
all globally frequent item sets. It also reduces the time of scan of partition
database by using LMatrix which increases the performance of the algorithm.
Therefore, the research is to develop a distributed algorithm for
geographically distributed data sets that reduces communication costs, superior
running efficiency, and stronger scalability than direct application of a
sequential algorithm in distributed databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1678</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1678</id><created>2010-04-09</created><authors><author><keyname>Nanda</keyname><forenames>Arabinda</forenames></author><author><keyname>Rath</keyname><forenames>Amiya Kumar</forenames></author><author><keyname>Rout</keyname><forenames>Saroj Kumar</forenames></author></authors><title>Node Sensing &amp; Dynamic Discovering Routes for Wireless Sensor Networks</title><categories>cs.NI</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The applications of Wireless Sensor Networks (WSN) contain a wide variety of
scenarios. In most of them, the network is composed of a significant number of
nodes deployed in an extensive area in which not all nodes are directly
connected. Then, the data exchange is supported by multihop communications.
Routing protocols are in charge of discovering and maintaining the routes in
the network. However, the correctness of a particular routing protocol mainly
depends on the capabilities of the nodes and on the application requirements.
This paper presents a dynamic discover routing method for communication between
sensor nodes and a base station in WSN. This method tolerates failures of
arbitrary individual nodes in the network (node failure) or a small part of the
network (area failure). Each node in the network does only local routing
preservation, needs to record only its neighbor nodes' information, and incurs
no extra routing overhead during failure free periods. It dynamically discovers
new routes when an intermediate node or a small part of the network in the path
from a sensor node to a base station fails. In our planned method, every node
decides its path based only on local information, such as its parent node and
neighbor nodes' routing information. So, it is possible to form a loop in the
routing path. We believe that the loop problem in sensor network routing is not
as serious as that in the Internet routing or traditional mobile ad-hoc
routing. We are trying to find all possible loops and eliminate the loops as
far as possible in WSN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1679</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1679</id><created>2010-04-10</created><authors><author><keyname>Beevi</keyname><forenames>S. Zulaikha</forenames></author><author><keyname>Sathik</keyname><forenames>M. Mohammed</forenames></author><author><keyname>Senthamaraikannan</keyname><forenames>K.</forenames></author></authors><title>A Robust Fuzzy Clustering Technique with Spatial Neighborhood
  Information for Effective Medical Image Segmentation</title><categories>cs.CV</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Medical image segmentation demands an efficient and robust segmentation
algorithm against noise. The conventional fuzzy c-means algorithm is an
efficient clustering algorithm that is used in medical image segmentation. But
FCM is highly vulnerable to noise since it uses only intensity values for
clustering the images. This paper aims to develop a novel and efficient fuzzy
spatial c-means clustering algorithm which is robust to noise. The proposed
clustering algorithm uses fuzzy spatial information to calculate membership
value. The input image is clustered using proposed ISFCM algorithm. A
comparative study has been made between the conventional FCM and proposed
ISFCM. The proposed approach is found to be outperforming the conventional FCM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1680</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1680</id><created>2010-04-10</created><authors><author><keyname>Pang</keyname><forenames>Bijia</forenames></author><author><keyname>Pen</keyname><forenames>Ue-li</forenames></author><author><keyname>Perrone</keyname><forenames>Michael</forenames></author></authors><title>Magnetohydrodynamics on Heterogeneous architectures: a performance
  comparison</title><categories>cs.PF astro-ph.IM physics.comp-ph</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present magneto-hydrodynamic simulation results for heterogeneous systems.
Heterogeneous architectures combine high floating point performance many-core
units hosted in conventional server nodes. Examples include Graphics Processing
Units (GPU's) and Cell. They have potentially large gains in performance, at
modest power and monetary cost. We implemented a magneto-hydrodynamic (MHD)
simulation code on a variety of heterogeneous and multi-core architectures ---
multi-core x86, Cell, Nvidia and ATI GPU --- in different languages, FORTRAN,
C, Cell, CUDA and OpenCL. We present initial performance results for these
systems. To our knowledge, this is the widest comparison of heterogeneous
systems for MHD simulations. We review the different challenges faced in each
architecture, and potential bottlenecks. We conclude that substantial gains in
performance over traditional systems are possible, and in particular that is
possible to extract a greater percentage of peak theoretical performance from
some systems when compared to x86 architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1682</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1682</id><created>2010-04-10</created><authors><author><keyname>Begum</keyname><forenames>J. Nafeesa</forenames></author><author><keyname>Kumar</keyname><forenames>K.</forenames></author><author><keyname>Sumathy</keyname><forenames>V.</forenames></author></authors><title>Design And Implementation Of Multilevel Access Control In Medical Image
  Transmission Using Symmetric Polynomial Based Audio Steganography</title><categories>cs.MM</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  ...The steganography scheme makes it possible to hide the medical image in
different bit locations of host media without inviting suspicion. The Secret
file is embedded in a cover media with a key. At the receiving end the key can
be derived by all the classes which are higher in the hierarchy using symmetric
polynomial and the medical image file can be retrieved. The system is
implemented and found to be secure, fast and scalable. Simulation results show
that the system is dynamic in nature and allows any type of hierarchy. The
proposed approach performs better even during frequent member joins and leaves.
The computation cost is reduced as the same algorithm is used for key
computation and descendant key derivation. Steganographic technique used in
this paper does not use the conventional LSB's and uses two bit positions and
the hidden data occurs only from a frame which is dictated by the key that is
used. Hence the quality of stego data is improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1683</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1683</id><created>2010-04-10</created><authors><author><keyname>Sengan</keyname><forenames>Sudhakar</forenames></author><author><keyname>Pandian</keyname><forenames>S. Chenthur</forenames></author></authors><title>Enhanced Authentication and Locality Aided - Destination Mobility in
  Dynamic Routing Protocol for MANET</title><categories>cs.CR cs.NI</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In our proposed model, the route selection is a function of following
parameters: hop count, trust level of node and security level of application.
In this paper, to focus on secure neighbor detection, trust factor evaluation,
operational mode, route discovery and route selection. The paper mainly address
the security of geographic routing. The watchdog identifies misbehaving nodes,
while the Pathselector avoids routing packets through these nodes. The
watchdog, the pathselector is run by each server. In order to keep the source
informed about the destination's mobility, the destination keeps sending the
alert message to its previous hop telling that it has changed its position and
any reference to it for data packet forwarding be informed to the VHR server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1686</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1686</id><created>2010-04-10</created><authors><author><keyname>Kekre</keyname><forenames>H. B.</forenames></author><author><keyname>Sarode</keyname><forenames>Tanuja K.</forenames></author></authors><title>New Clustering Algorithm for Vector Quantization using Rotation of Error
  Vector</title><categories>cs.CV cs.IT math.IT</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper presents new clustering algorithm. The proposed algorithm gives
less distortion as compared to well known Linde Buzo Gray (LBG) algorithm and
Kekre's Proportionate Error (KPE) Algorithm. Constant error is added every time
to split the clusters in LBG, resulting in formation of cluster in one
direction which is 1350 in 2-dimensional case. Because of this reason
clustering is inefficient resulting in high MSE in LBG. To overcome this
drawback of LBG proportionate error is added to change the cluster orientation
in KPE. Though the cluster orientation in KPE is changed its variation is
limited to +/- 450 over 1350. The proposed algorithm takes care of this problem
by introducing new orientation every time to split the clusters. The proposed
method reduces PSNR by 2db to 5db for codebook size 128 to 1024 with respect to
LBG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1696</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1696</id><created>2010-04-10</created><updated>2012-11-12</updated><authors><author><keyname>Herrmann</keyname><forenames>Christian</forenames></author><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Computational Complexity of Quantum Satisfiability</title><categories>math.LO cs.CC</categories><comments>full version to extended abstract [HeZi11]</comments><msc-class>03G12, 03D40, 13P15, 68W30, 68Q25</msc-class><acm-class>F.4.1; F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum logic was introduced in 1936 by Garrett Birkhoff and John von Neumann
as a framework for capturing the logical peculiarities of quantum observables.
It generalizes, and on 1-dimensional Hilbert space coincides with, Boolean
propositional logic.
  We introduce the weak and strong satisfiability problem for quantum logic
terms. It turns out that in dimension two both are also NP-complete.
  For higher-dimensional spaces R^d and C^d with d&gt;2 fixed, on the other hand,
we show both problems to be complete for the nondeterministic Blum-Shub-Smale
model of real computation. This provides a unified view on both Turing and real
BSS complexity theory; and extends the still relatively scarce family of
NP_R-complete problems with one perhaps closest in spirit to the classical
Cook-Levin Theorem.
  Our investigations on the dimensions a term is weakly/strongly satisfiable in
lead to satisfiability problems in indefinite finite and finally in infinite
dimension. Here, strong satisfiability turns out as polynomial-time equivalent
to the feasibility of noncommutative integer polynomial equations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1697</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1697</id><created>2010-04-10</created><authors><author><keyname>Saeedi</keyname><forenames>Mehdi</forenames></author><author><keyname>Sedighi</keyname><forenames>Mehdi</forenames></author><author><keyname>Zamani</keyname><forenames>Morteza Saheb</forenames></author></authors><title>A Library-Based Synthesis Methodology for Reversible Logic</title><categories>quant-ph cs.ET</categories><comments>24 pages, 8 figures, Microelectronics Journal, Elsevier</comments><journal-ref>Mehdi Saeedi, Mehdi Sedighi, Morteza Saheb Zamani, ?A
  Library-Based Synthesis Methodology for Reversible Logic,? Microelectronics
  Journal, Elsevier, Volume 41, No. 4, pp. 185-194, 2010.</journal-ref><doi>10.1016/j.mejo.2010.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a library-based synthesis methodology for reversible circuits
is proposed where a reversible specification is considered as a permutation
comprising a set of cycles. To this end, a pre-synthesis optimization step is
introduced to construct a reversible specification from an irreversible
function. In addition, a cycle-based representation model is presented to be
used as an intermediate format in the proposed synthesis methodology. The
selected intermediate format serves as a focal point for all potential
representation models. In order to synthesize a given function, a library
containing seven building blocks is used where each building block is a cycle
of length less than 6. To synthesize large cycles, we also propose a
decomposition algorithm which produces all possible minimal and inequivalent
factorizations for a given cycle of length greater than 5. All decompositions
contain the maximum number of disjoint cycles. The generated decompositions are
used in conjunction with a novel cycle assignment algorithm which is proposed
based on the graph matching problem to select the best possible cycle pairs.
Then, each pair is synthesized by using the available components of the
library. The decomposition algorithm together with the cycle assignment method
are considered as a binding method which selects a building block from the
library for each cycle. Finally, a post-synthesis optimization step is
introduced to optimize the synthesis results in terms of different costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1701</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1701</id><created>2010-04-10</created><authors><author><keyname>Spaan</keyname><forenames>Jos AE</forenames></author></authors><title>The danger of pseudo science in Informetrics</title><categories>cs.DL physics.pop-ph physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two papers have been archived to which this letter is complementary: 1)
Opthof and Leydesdorff arxiv:1002.2769 2) Van Raan et al. arxiv:1003.2113 Van
Raan at all claims that the order of operations (first dividing then adding)
does not apply to citation analysis. In my contribution I discuss a few
analogues in Physics and Medicine and argue that in no other field of science
where quantities have physical or financial meaning, implying that that numbers
have a real unit of measure, it would be allowed to ignore the rule of
operations. Hence, the claim of CWTS that the order of operations is not
relevant brings studies ignoring this rule as done by CWTS in the category
'Pseudo Science'.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1706</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1706</id><created>2010-04-10</created><authors><author><keyname>Mallapur</keyname><forenames>Sujata V.</forenames></author><author><keyname>Terdal</keyname><forenames>Sujata</forenames></author></authors><title>Enhanced Ad-Hoc on Demand Multipath Distance Vector Routing protocol</title><categories>cs.NI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 166-170</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Due to mobility in Ad-Hoc network the topology of the network may change
randomly, rapidly and unexpectedly, because of these aspects, the routes in the
network often disappear and new to arise. To avoid frequent route discovery and
route failure EAOMDV was proposed based on existing routing protocol AOMDV. The
EAOMDV (Enhanced Ad-Hoc on Demand Multipath Distance Vector) Routing protocol
was proposed to solve the &quot;route failure&quot; problem in AOMDV. EAOMDV protocol
reduces the route failure problem by preemptively predicting the link failure
by the signal power received by the receiver (pr). This proposed protocol
controls overhead, increases throughput and reduces the delay. The EAOMDV
protocol was implemented on NS-2 and evaluation results show that the EAOMDV
outperformed AOMDV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1707</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1707</id><created>2010-04-10</created><authors><author><keyname>Seshaiah</keyname><forenames>C. V.</forenames></author><author><keyname>Nagarani</keyname><forenames>S.</forenames></author></authors><title>A Survey on Space-Time Turbo Codes</title><categories>cs.IT math.IT</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 171-177</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  As wireless communication systems look intently to compose the transition
from voice communication to interactive Internet data, achieving higher bit
rates becomes both increasingly desirable and challenging. Space-time coding
(STC) is a communications technique for wireless systems that inhabit multiple
transmit antennas and single or multiple receive antennas. Space-time codes
make use of advantage of both the spatial diversity provided by multiple
antennas and the temporal diversity available with time-varying fading.
Space-time codes can be divided into block codes and trellis codes. Space-time
trellis coding merges signal processing at the receiver with coding techniques
appropriate to multiple transmit antennas. The advantages of space-time codes
(STC) make it extremely remarkable for high-rate wireless applications. Initial
STC research efforts focused on narrowband flat-fading channels. The decoding
complexity of Space-time turbo codes STTC increases exponentially as a function
of the diversity level and transmission rate. This proposed paper provides an
over view on various techniques used for the design of space-time turbo codes.
This paper also discusses the techniques handled by researchers to built
encoder and decoder section for multiple transmits and receives antennas. In
addition the future enhancement gives a general idea for improvement and
development of various codes which will involve implementing viterbi decoder
with soft decoding in a multi-antenna scenario. In addition the space-time code
may be analyzed using some of the available metrics and finally to simulate it
for different receive antenna configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1708</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1708</id><created>2010-04-10</created><authors><author><keyname>Singh</keyname><forenames>Manoranjan Kumar</forenames></author><author><keyname>L</keyname><forenames>Rakesh.</forenames></author></authors><title>Mathematical Principles in Software Quality Engineering</title><categories>cs.SE</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 178-184</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Mathematics has many useful properties for developing of complex software
systems. One is that it can exactly describe a physical situation of the object
or outcome of an action. Mathematics support abstraction and this is an
excellent medium for modeling, since it is an exact medium there is a little
possibility of ambiguity. This paper demonstrates that mathematics provides a
high level of validation when it is used as a software medium. It also outlines
distinguishing characteristics of structural testing which is based on the
source code of the program tested. Structural testing methods are very amenable
to rigorous definition, mathematical analysis and precise measurement. Finally,
it also discusses functional and structural testing debate to have a sense of
complete testing. Any program can be considered to be a function in the sense
that program input forms its domain and program outputs form its range. In
general discrete mathematics is more applicable to functional testing, while
graph theory pertains more to structural testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1724</identifier>
 <datestamp>2010-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1724</id><created>2010-04-10</created><updated>2010-07-20</updated><authors><author><keyname>Bisi</keyname><forenames>Cinzia</forenames></author><author><keyname>Chiaselotti</keyname><forenames>Giampiero</forenames></author></authors><title>A Class of lattices and boolean functions related to a
  Manickam-Mikl\&quot;os-Singhi Conjecture</title><categories>math.CO cs.DM cs.FL</categories><comments>The title has been changed, automata sections have been removed, the
  global number of pages has been reduced noticeably. Paper submitted</comments><msc-class>05D05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to build a new family of lattices related to some
combinatorial extremal sum problems, in particular to a conjecture of Manickam,
Mikl\&quot;os and Singhi. We study the fundamentals properties of such lattices and
of a particular class of boolean functions defined on them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1729</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1729</id><created>2010-04-10</created><authors><author><keyname>Kurant</keyname><forenames>Maciej</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author><author><keyname>Thiran</keyname><forenames>Patrick</forenames></author></authors><title>On the bias of BFS</title><categories>cs.DM cs.DS cs.NI cs.SI stat.ME</categories><comments>9 pages</comments><journal-ref>International Teletraffic Congress (ITC 22), 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Breadth First Search (BFS) and other graph traversal techniques are widely
used for measuring large unknown graphs, such as online social networks. It has
been empirically observed that an incomplete BFS is biased toward high degree
nodes. In contrast to more studied sampling techniques, such as random walks,
the precise bias of BFS has not been characterized to date. In this paper, we
quantify the degree bias of BFS sampling. In particular, we calculate the node
degree distribution expected to be observed by BFS as a function of the
fraction of covered nodes, in a random graph $RG(p_k)$ with a given degree
distribution $p_k$. Furthermore, we also show that, for $RG(p_k)$, all commonly
used graph traversal techniques (BFS, DFS, Forest Fire, and Snowball Sampling)
lead to the same bias, and we show how to correct for this bias. To give a
broader perspective, we compare this class of exploration techniques to random
walks that are well-studied and easier to analyze. Next, we study by simulation
the effect of graph properties not captured directly by our model. We find that
the bias gets amplified in graphs with strong positive assortativity. Finally,
we demonstrate the above results by sampling the Facebook social network, and
we provide some practical guidelines for graph sampling in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1736</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1736</id><created>2010-04-10</created><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author></authors><title>An undecidable property of context-free languages</title><categories>cs.FL cs.DM</categories><msc-class>68Q42, 68Q45, 68Q55, 68Q70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that there exists no algorithm to decide whether the language
generated by a context-free grammar is dense with respect to the lexicographic
ordering. As a corollary to this result, we show that it is undecidable whether
the lexicographic orderings of the languages generated by two context-free
grammars have the same order type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1741</identifier>
 <datestamp>2012-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1741</id><created>2010-04-10</created><authors><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author></authors><title>Efficient multicore-aware parallelization strategies for iterative
  stencil computations</title><categories>cs.PF cs.DC</categories><comments>15 pages, 10 figures</comments><journal-ref>Journal of Computational Science 2, 130-137 (2011)</journal-ref><doi>10.1016/j.jocs.2011.01.010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stencil computations consume a major part of runtime in many scientific
simulation codes. As prototypes for this class of algorithms we consider the
iterative Jacobi and Gauss-Seidel smoothers and aim at highly efficient
parallel implementations for cache-based multicore architectures. Temporal
cache blocking is a known advanced optimization technique, which can reduce the
pressure on the memory bus significantly. We apply and refine this optimization
for a recently presented temporal blocking strategy designed to explicitly
utilize multicore characteristics. Especially for the case of Gauss-Seidel
smoothers we show that simultaneous multi-threading (SMT) can yield substantial
performance improvements for our optimized algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1743</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1743</id><created>2010-04-10</created><authors><author><keyname>Nathiya</keyname><forenames>G.</forenames></author><author><keyname>Punitha</keyname><forenames>S. C.</forenames></author><author><keyname>Punithavalli</keyname><forenames>M.</forenames></author></authors><title>An Analytical Study on Behavior of Clusters Using K Means, EM and K*
  Means Algorithm</title><categories>cs.LG cs.IR</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 185-190</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Clustering is an unsupervised learning method that constitutes a cornerstone
of an intelligent data analysis process. It is used for the exploration of
inter-relationships among a collection of patterns, by organizing them into
homogeneous clusters. Clustering has been dynamically applied to a variety of
tasks in the field of Information Retrieval (IR). Clustering has become one of
the most active area of research and the development. Clustering attempts to
discover the set of consequential groups where those within each group are more
closely related to one another than the others assigned to different groups.
The resultant clusters can provide a structure for organizing large bodies of
text for efficient browsing and searching. There exists a wide variety of
clustering algorithms that has been intensively studied in the clustering
problem. Among the algorithms that remain the most common and effectual, the
iterative optimization clustering algorithms have been demonstrated reasonable
performance for clustering, e.g. the Expectation Maximization (EM) algorithm
and its variants, and the well known k-means algorithm. This paper presents an
analysis on how partition method clustering techniques - EM, K -means and K*
Means algorithm work on heartspect dataset with below mentioned features -
Purity, Entropy, CPU time, Cluster wise analysis, Mean value analysis and inter
cluster distance. Thus the paper finally provides the experimental results of
datasets for five clusters to strengthen the results that the quality of the
behavior in clusters in EM algorithm is far better than k-means algorithm and
k*means algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1744</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1744</id><created>2010-04-10</created><authors><author><keyname>Kumar</keyname><forenames>A.</forenames></author><author><keyname>Chakrabarti</keyname><forenames>P.</forenames></author><author><keyname>Saini</keyname><forenames>P.</forenames></author></authors><title>Node inspection and analysis thereof in the light of area estimation and
  curve fitting</title><categories>cs.NI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 191-197</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we have given an idea of area specification and its
corresponding sensing of nodes in a dynamic network. We have applied the
concept of Monte Carlo methods in this respect. We have cited certain
statistical as well as artificial intelligence based techniques for realizing
the position of a node. We have also applied curve fitting concept for node
detection and relative verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1745</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1745</id><created>2010-04-10</created><authors><author><keyname>Taib</keyname><forenames>Nabil</forenames></author><author><keyname>Rekioua</keyname><forenames>Toufik</forenames></author><author><keyname>Francois</keyname><forenames>Bruno</forenames></author></authors><title>An Improved Fixed Switching Frequency Direct Torque Control of Induction
  Motor Drives Fed by Direct Matrix Converter</title><categories>cs.OH</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A few papers have been interested by the fixed switching frequency direct
torque control fed by direct matrix converters, where we can find just the use
of direct torque controlled space vector modulated method. In this present
paper, we present an improved method used for a fixed switching frequency
direct torque control (DTC) using a direct matrix converter (DMC). This method
is characterized by a simple structure, a fixed switching frequency which
causes minimal torque ripple and a unity input power factor. Using this
strategy, we combine the direct matrix converters advantages with those of
direct torque control (DTC) schemes. The used technique for constant frequency
is combined with the input current space vector to create the switching table
of direct matrix converter (DMC). Simulation results clearly demonstrate a
better dynamic and steady state performances of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1746</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1746</id><created>2010-04-10</created><authors><author><keyname>Qamar</keyname><forenames>S</forenames></author><author><keyname>Lal</keyname><forenames>Niranjan</forenames></author><author><keyname>Singh</keyname><forenames>Mrityunjay</forenames></author></authors><title>Internet ware cloud computing :Challenges</title><categories>cs.DC</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 206-210</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  After decades of engineering development and infrastructural investment,
Internet connections have become commodity product in many countries, and
Internet scale &quot;cloud computing&quot; has started to compete with traditional
software business through its technological advantages and economy of scale.
Cloud computing is a promising enabling technology of Internet ware Cloud
Computing is termed as the next big thing in the modern corporate world. Apart
from the present day software and technologies, cloud computing will have a
growing impact on enterprise IT and business activities in many large
organizations. This paper provides an insight to cloud computing, its impacts
and discusses various issues that business organizations face while
implementing cloud computing. Further, it recommends various strategies that
organizations need to adopt while migrating to cloud computing. The purpose of
this paper is to develop an understanding of cloud computing in the modern
world and its impact on organizations and businesses. Initially the paper
provides a brief description of the cloud computing model introduction and its
purposes. Further it discusses various technical and non-technical issues that
need to be overcome in order for the benefits of cloud computing to be realized
in corporate businesses and organizations. It then provides various
recommendations and strategies that businesses need to work on before stepping
into new technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1747</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1747</id><created>2010-04-10</created><authors><author><keyname>Sharma</keyname><forenames>Samidha Dwivedi</forenames></author><author><keyname>Kasana</keyname><forenames>Dr. R. S.</forenames></author></authors><title>Mobile Database System: Role of Mobility on the Query Processing</title><categories>cs.DB</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 211-216</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The rapidly expanding technology of mobile communication will give mobile
users capability of accessing information from anywhere and any time. The
wireless technology has made it possible to achieve continuous connectivity in
mobile environment. When the query is specified as continuous, the requesting
mobile user can obtain continuously changing result. In order to provide
accurate and timely outcome to requesting mobile user, the locations of moving
object has to be closely monitored. The objective of paper is to discuss the
problem related to the role of personal and terminal mobility and query
processing in the mobile environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1748</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1748</id><created>2010-04-10</created><authors><author><keyname>Revenkar</keyname><forenames>P. S.</forenames></author><author><keyname>Anjum</keyname><forenames>Anisa</forenames></author><author><keyname>Gandhare</keyname><forenames>W. Z.</forenames></author></authors><title>Secure Iris Authentication Using Visual Cryptography</title><categories>cs.CR</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 217-221</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Biometrics deal with automated methods of identifying a person or verifying
the identity of a person based on physiological or behavioral characteristics.
Visual cryptography is a secret sharing scheme where a secret image is
encrypted into the shares which independently disclose no information about the
original secret image. As biometric template are stored in the centralized
database, due to security threats biometric template may be modified by
attacker. If biometric template is altered authorized user will not be allowed
to access the resource. To deal this issue visual cryptography schemes can be
applied to secure the iris template. Visual cryptography provides great means
for helping such security needs as well as extra layer of authentication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1749</identifier>
 <datestamp>2012-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1749</id><created>2010-04-10</created><updated>2012-04-11</updated><authors><author><keyname>Sadeghi</keyname><forenames>Mohammad-Reza</forenames></author><author><keyname>Sakzad</keyname><forenames>Amin</forenames></author></authors><title>Capacity Achieving Low Density Parity Check Lattices</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to an error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept and existence of sphere-bound-achieving and capacity-achieving
lattices has been explained on AWGN channels by Forney. LDPC lattices,
introduced by Sadeghi, perform very well under iterative decoding algorithm. In
this work, we focus on an ensemble of regular LDPC lattices. We produce and
investigate an ensemble of LDPC lattices with known properties. It is shown
that these lattices are sphere-bound-achieving and capacity-achieving. As
byproducts we find the minimum distance, coding gain, kissing number and an
upper bound for probability of error for this special ensemble of regular LDPC
lattices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1752</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1752</id><created>2010-04-10</created><updated>2011-02-17</updated><authors><author><keyname>Duursma</keyname><forenames>Iwan</forenames></author><author><keyname>Kirov</keyname><forenames>Radoslav</forenames></author></authors><title>Improved Two-Point Codes on Hermitian Curves</title><categories>cs.IT math.AG math.IT math.NT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One-point codes on the Hermitian curve produce long codes with excellent
parameters. Feng and Rao introduced a modified construction that improves the
parameters while still using one-point divisors. A separate improvement of the
parameters was introduced by Matthews considering the classical construction
but with two-point divisors. Those two approaches are combined to describe an
elementary construction of two-point improved codes. Upon analysis of their
minimum distance and redundancy, it is observed that they improve on the
previous constructions for a large range of designed distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1755</identifier>
 <datestamp>2012-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1755</id><created>2010-04-10</created><authors><author><keyname>Arabzadeh</keyname><forenames>Mona</forenames></author><author><keyname>Saeedi</keyname><forenames>Mehdi</forenames></author><author><keyname>Zamani</keyname><forenames>Morteza Saheb</forenames></author></authors><title>Rule-Based Optimization of Reversible Circuits</title><categories>quant-ph cs.ET</categories><comments>12 pages, 15 figures, Asia and South Pacific Design Automation
  Conference, 2010</comments><journal-ref>Mona Arabzadeh, Mehdi Saeedi, Morteza Saheb Zamani, &quot;Rule-Based
  Optimization of Reversible Circuits,&quot; The 15th Asia and South Pacific Design
  Automation Conference (ASPDAC), pp. 849 - 854, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic has applications in various research areas including
low-power design and quantum computation. In this paper, a rule-based
optimization approach for reversible circuits is proposed which uses both
negative and positive control Toffoli gates during the optimization. To this
end, a set of rules for removing NOT gates and optimizing sub-circuits with
common-target gates are proposed. To evaluate the proposed approach, the
best-reported synthesized circuits and the results of a recent synthesis
algorithm which uses both negative and positive controls are used. Our
experiments reveal the potential of the proposed approach in optimizing
synthesized circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1757</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1757</id><created>2010-04-10</created><authors><author><keyname>Selvam</keyname><forenames>N. Saravana</forenames></author><author><keyname>Radhakrishnan</keyname><forenames>S.</forenames></author></authors><title>Processor Based Active Queue Management for providing QoS in Multimedia
  Application</title><categories>cs.NI cs.MM</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The objective of this paper is to implement the Active Network based Active
Queue Management Technique for providing Quality of Service (QoS) using Network
Processor(NP) based router to enhance multimedia applications. The performance
is evaluated using Intel IXP2400 NP Simulator. The results demonstrate that,
Active Network based Active Queue Management has better performance than RED
algorithm in case of congestion and is well suited to achieve high speed packet
classification to support multimedia applications with minimum delay and Queue
loss. Using simulation, we show that the proposed system can provide assurance
for prioritized flows with improved network utilization where bandwidth is
shared among the flows according to the levels of priority. We first analyze
the feasibility and optimality of the load distribution schemes and then
present separate solutions for non-delay sensitive streams and delay-sensitive
streams. Rigorous simulations and experiments have been carried out to evaluate
the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1768</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1768</id><created>2010-04-11</created><authors><author><keyname>Gomathi</keyname><forenames>M.</forenames></author><author><keyname>Thangaraj</keyname><forenames>P.</forenames></author></authors><title>A New Approach to Lung Image Segmentation using Fuzzy Possibilistic
  C-Means Algorithm</title><categories>cs.CV</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 222-228</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Image segmentation is a vital part of image processing. Segmentation has its
application widespread in the field of medical images in order to diagnose
curious diseases. The same medical images can be segmented manually. But the
accuracy of image segmentation using the segmentation algorithms is more when
compared with the manual segmentation. In the field of medical diagnosis an
extensive diversity of imaging techniques is presently available, such as
radiography, computed tomography (CT) and magnetic resonance imaging (MRI).
Medical image segmentation is an essential step for most consequent image
analysis tasks. Although the original FCM algorithm yields good results for
segmenting noise free images, it fails to segment images corrupted by noise,
outliers and other imaging artifact. This paper presents an image segmentation
approach using Modified Fuzzy C-Means (FCM) algorithm and Fuzzy Possibilistic
c-means algorithm (FPCM). This approach is a generalized version of standard
Fuzzy CMeans Clustering (FCM) algorithm. The limitation of the conventional FCM
technique is eliminated in modifying the standard technique. The Modified FCM
algorithm is formulated by modifying the distance measurement of the standard
FCM algorithm to permit the labeling of a pixel to be influenced by other
pixels and to restrain the noise effect during segmentation. Instead of having
one term in the objective function, a second term is included, forcing the
membership to be as high as possible without a maximum limit constraint of one.
Experiments are conducted on real images to investigate the performance of the
proposed modified FCM technique in segmenting the medical images. Standard FCM,
Modified FCM, Fuzzy Possibilistic CMeans algorithm (FPCM) are compared to
explore the accuracy of our proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1769</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1769</id><created>2010-04-11</created><authors><author><keyname>Selvamani</keyname><forenames>K.</forenames></author><author><keyname>Duraisamy</keyname><forenames>A.</forenames></author><author><keyname>Kannan</keyname><forenames>A.</forenames></author></authors><title>Protection of Web Applications from Cross-Site Scripting Attacks in
  Browser Side</title><categories>cs.CR</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 229-236</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cross Site Scripting (XSS) Flaws are currently the most popular security
problems in modern web applications. These Flaws make use of vulnerabilities in
the code of web-applications, resulting in serious consequences, such as theft
of cookies, passwords and other personal credentials. Cross-Site scripting
Flaws occur when accessing information in intermediate trusted sites. Client
side solution acts as a web proxy to mitigate Cross Site Scripting Flaws which
manually generated rules to mitigate Cross Site Scripting attempts. Client side
solution effectively protects against information leakage from the user's
environment. Cross Site Scripting Flaws are easy to execute, but difficult to
detect and prevent. This paper provides client-side solution to mitigate
cross-site scripting Flaws. The existing client-side solutions degrade the
performance of client's system resulting in a poor web surfing experience. In
this project provides a client side solution that uses a step by step approach
to protect cross site scripting, without degrading much the user's web browsing
experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1770</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1770</id><created>2010-04-11</created><authors><author><keyname>Deshpande</keyname><forenames>Neeta</forenames></author><author><keyname>Rajurkar</keyname><forenames>Archana</forenames></author><author><keyname>Manthalkar</keyname><forenames>R</forenames></author></authors><title>Review of Robust Video Watermarking Algorithms</title><categories>cs.MM</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 237-246</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  There has been a remarkable increase in the data exchange over web and the
widespread use of digital media. As a result, multimedia data transfers also
had a boost up. The mounting interest with reference to digital watermarking
throughout the last decade is certainly due to the increase in the need of
copyright protection of digital content. This is also enhanced due to
commercial prospective. Applications of video watermarking in copy control,
broadcast monitoring, fingerprinting, video authentication, copyright
protection etc is immensely rising. The main aspects of information hiding are
capacity, security and robustness. Capacity deals with the amount of
information that can be hidden. The skill of anyone detecting the information
is security and robustness refers to the resistance to modification of the
cover content before concealed information is destroyed. Video watermarking
algorithms normally prefers robustness. In a robust algorithm it is not
possible to eliminate the watermark without rigorous degradation of the cover
content. In this paper, we introduce the notion of Video Watermarking and the
features required to design a robust watermarked video for a valuable
application. We review several algorithms, and introduce frequently used key
techniques. The aim of this paper is to focus on the various domains of video
watermarking techniques. The majority of the reviewed methods based on video
watermarking emphasize on the notion of robustness of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1772</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1772</id><created>2010-04-11</created><authors><author><keyname>Inyaem</keyname><forenames>Uraiwan</forenames></author><author><keyname>Haruechaiyasak</keyname><forenames>Choochart</forenames></author><author><keyname>Meesad</keyname><forenames>Phayung</forenames></author><author><keyname>Tran</keyname><forenames>Dat</forenames></author></authors><title>Terrorism Event Classification Using Fuzzy Inference Systems</title><categories>cs.AI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 247-256</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Terrorism has led to many problems in Thai societies, not only property
damage but also civilian casualties. Predicting terrorism activities in advance
can help prepare and manage risk from sabotage by these activities. This paper
proposes a framework focusing on event classification in terrorism domain using
fuzzy inference systems (FISs). Each FIS is a decision-making model combining
fuzzy logic and approximate reasoning. It is generated in five main parts: the
input interface, the fuzzification interface, knowledge base unit, decision
making unit and output defuzzification interface. Adaptive neuro-fuzzy
inference system (ANFIS) is a FIS model adapted by combining the fuzzy logic
and neural network. The ANFIS utilizes automatic identification of fuzzy logic
rules and adjustment of membership function (MF). Moreover, neural network can
directly learn from data set to construct fuzzy logic rules and MF implemented
in various applications. FIS settings are evaluated based on two comparisons.
The first evaluation is the comparison between unstructured and structured
events using the same FIS setting. The second comparison is the model settings
between FIS and ANFIS for classifying structured events. The data set consists
of news articles related to terrorism events in three southern provinces of
Thailand. The experimental results show that the classification performance of
the FIS resulting from structured events achieves satisfactory accuracy and is
better than the unstructured events. In addition, the classification of
structured events using ANFIS gives higher performance than the events using
only FIS in the prediction of terrorism events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1773</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1773</id><created>2010-04-11</created><authors><author><keyname>Vengattaraman</keyname><forenames>T.</forenames></author><author><keyname>Dhavachelvan</keyname><forenames>P.</forenames></author><author><keyname>Baskaran</keyname><forenames>R.</forenames></author></authors><title>A Model of Cloud Based Application Environment for Software Testing</title><categories>cs.SE</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 257-260</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cloud computing is an emerging platform of service computing designed for
swift and dynamic delivery of assured computing resources. Cloud computing
provide Service-Level Agreements (SLAs) for guaranteed uptime availability for
enabling convenient and on-demand network access to the distributed and shared
computing resources. Though the cloud computing paradigm holds its potential
status in the field of distributed computing, cloud platforms are not yet to
the attention of majority of the researchers and practitioners. More
specifically, still the researchers and practitioners community has fragmented
and imperfect knowledge on cloud computing principles and techniques. In this
context, one of the primary motivations of the work presented in this paper is
to reveal the versatile merits of cloud computing paradigm and hence the
objective of this work is defined to bring out the remarkable significances of
cloud computing paradigm through an application environment. In this work, a
cloud computing model for software testing is developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1774</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1774</id><created>2010-04-11</created><authors><author><keyname>Valarmathi</keyname><forenames>K.</forenames></author><author><keyname>Malmurugan</keyname><forenames>N.</forenames></author></authors><title>Joint Design of Congestion Control Routing With Distributed Multi
  Channel Assignment in Wireless Mesh Networks</title><categories>cs.NI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 261-266</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In Wireless Mesh Networks (WMN), a channel assignment has to balance the
objectives of maintaining connectivity and increasing the aggregate bandwidth.
The main aim of the channel assignment algorithm is to assign the channels to
the network interfaces, from the given expected load on each virtual link. From
the existing work done so far, we can examine that there is no combined
solution of multi-channel assignment with routing and congestion control. In
this paper, we propose a congestion control routing protocol along with
multi-channel assignment. We use a traffic aware metric in this protocol in
order to provide quality of service. The proposed protocol can improve the
throughput and channel utilization to very high extent because it provides
solution for multi-channel assignment and congestion control. The proposed
algorithm assigns the channels in a way that, congestion is avoided and
co-channel interference levels among links with same channel are reduced. By
our simulation results in NS2, we show that the proposed protocol attains high
throughput and channel utilization along with reduced latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1778</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1778</id><created>2010-04-11</created><authors><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Li</keyname><forenames>Yiyang</forenames></author></authors><title>The asymptotic values of the general Zagreb and Randi\'c indices of
  trees with bounded maximum degree</title><categories>math.CO cs.DM</categories><comments>13 pages</comments><msc-class>05C05, 05C12, 05C30, 05D40, 05A15, 05A16, 92E10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathcal {T}^{\Delta}_n$ denote the set of trees of order $n$, in which
the degree of each vertex is bounded by some integer $\Delta$. Suppose that
every tree in $\mathcal {T}^{\Delta}_n$ is equally likely. We show that the
number of vertices of degree $j$ in $\mathcal {T}^{\Delta}_n$ is asymptotically
normal with mean $(\mu_j+o(1))n$ and variance $(\sigma_j+o(1))n$, where
$\mu_j$, $\sigma_j$ are some constants. As a consequence, we give estimate to
the value of the general Zagreb index for almost all trees in $\mathcal
{T}^{\Delta}_n$. Moreover, we obtain that the number of edges of type $(i,j)$
in $\mathcal {T}^{\Delta}_n$ also has mean $(\mu_{ij}+o(1))n$ and variance
$(\sigma_{ij}+o(1))n$, where an edge of type $(i,j)$ means that the edge has
one end of degree $i$ and the other of degree $j$, and $\mu_{ij}$,
$\sigma_{ij}$ are some constants. Then, we give estimate to the value of the
general Randi\'{c} index for almost all trees in $\mathcal {T}^{\Delta}_n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1788</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1788</id><created>2010-04-11</created><authors><author><keyname>Hamid</keyname><forenames>Nafiz Imtiaz Bin</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Zakir</forenames></author><author><keyname>Khandokar</keyname><forenames>Md. R. H.</forenames></author><author><keyname>Jamal</keyname><forenames>Taskin</forenames></author><author><keyname>Shoeb</keyname><forenames>Md. A.</forenames></author></authors><title>Mobile Broadband Possibilities considering the Arrival of IEEE 802.16m &amp;
  LTE with an Emphasis on South Asia</title><categories>cs.NI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 267-275</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper intends to look deeper into finding an ideal mobile broadband
solution. Special stress has been put in the South Asian region through some
comparative analysis. Proving their competency in numerous aspects, WiMAX and
LTE already have already made a strong position in telecommunication industry.
Both WiMAX and LTE are 4G technologies designed to move data rather than voice
having IP networks based on OFDM technology. So, they aren't like typical
technological rivals as of GSM and CDMA. But still a gesture of hostility seems
to outburst long before the stable commercial launch of LTE. In this paper
various aspects of WiMAX and LTE for deployment have been analyzed. Again, we
tried to make every possible consideration with respect to south Asia i.e. how
mass people of this region may be benefited. As a result, it might be regarded
as a good source in case of making major BWA deployment decisions in this
region. Besides these, it also opens the path for further research and in depth
thinking in this issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1789</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1789</id><created>2010-04-11</created><authors><author><keyname>Kekre</keyname><forenames>H. B.</forenames></author><author><keyname>Gharge</keyname><forenames>Saylee</forenames></author><author><keyname>Sarode</keyname><forenames>Tanuja K.</forenames></author></authors><title>SAR Image Segmentation using Vector Quantization Technique on Entropy
  Images</title><categories>cs.MM cs.CV</categories><comments>IEEE Publication format, International Journal of Computer Science
  and Information Security, IJCSIS, Vol. 7 No. 3, March 2010, USA. ISSN 1947
  5500, http://sites.google.com/site/ijcsis/</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The development and application of various remote sensing platforms result in
the production of huge amounts of satellite image data. Therefore, there is an
increasing need for effective querying and browsing in these image databases.
In order to take advantage and make good use of satellite images data, we must
be able to extract meaningful information from the imagery. Hence we proposed a
new algorithm for SAR image segmentation. In this paper we propose segmentation
using vector quantization technique on entropy image. Initially, we obtain
entropy image and in second step we use Kekre's Fast Codebook Generation (KFCG)
algorithm for segmentation of the entropy image. Thereafter, a codebook of size
128 was generated for the Entropy image. These code vectors were further
clustered in 8 clusters using same KFCG algorithm and converted into 8 images.
These 8 images were displayed as a result. This approach does not lead to over
segmentation or under segmentation. We compared these results with well known
Gray Level Co-occurrence Matrix. The proposed algorithm gives better
segmentation with less complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1791</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1791</id><created>2010-04-11</created><authors><author><keyname>Jinna</keyname><forenames>S. Kurshid</forenames></author><author><keyname>Ganesan</keyname><forenames>L.</forenames></author></authors><title>Reversible Image data Hiding using Lifting wavelet Transform and
  Histogram Shifting</title><categories>cs.MM</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 283-289</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A method of lossless data hiding in images using integer wavelet transform
and histogram shifting for gray scale images is proposed. The method shifts
part of the histogram, to create space for embedding the watermark information
bits. The method embeds watermark while maintaining the visual quality well.
The method is completely reversible. The original image and the watermark data
can be recovered without any loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1793</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1793</id><created>2010-04-11</created><authors><author><keyname>Nayak</keyname><forenames>S. K.</forenames></author><author><keyname>Thorat</keyname><forenames>S. B.</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author></authors><title>GIS: Geographic Information System An application for socio-economical
  data collection for rural area</title><categories>cs.CY</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 290-293</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The country India follows the planning through planning commission. This is
on the basis of information collected by traditional, tedious and manual method
which is too slow to sustain. Now we are in the age of 21th century. We have
seen in last few decades that the progress of information technology with leaps
and bounds, which have completely changed the way of life in the developed
nations. While internet has changed the established working practice and opened
new vistas and provided a platform to connect, this gives the opportunity for
collaborative work space that goes beyond the global boundary. We are living in
the global economy and India leading towards Liberalize Market Oriented Economy
(LMOE). Considering this things, focusing on GIS, we proposed a system for
collection of socio economic data and water resource management information of
rural area via internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1794</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1794</id><created>2010-04-11</created><authors><author><keyname>Kishore</keyname><forenames>T. Krishna</forenames></author><author><keyname>Vardhan</keyname><forenames>T. Sasi</forenames></author><author><keyname>Narayana</keyname><forenames>N. Lakshmi</forenames></author></authors><title>Probabilistic Semantic Web Mining Using Artificial Neural Analysis</title><categories>cs.AI</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 294-304</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Most of the web user's requirements are search or navigation time and getting
correctly matched result. These constrains can be satisfied with some
additional modules attached to the existing search engines and web servers.
This paper proposes that powerful architecture for search engines with the
title of Probabilistic Semantic Web Mining named from the methods used. With
the increase of larger and larger collection of various data resources on the
World Wide Web (WWW), Web Mining has become one of the most important
requirements for the web users. Web servers will store various formats of data
including text, image, audio, video etc., but servers can not identify the
contents of the data. These search techniques can be improved by adding some
special techniques including semantic web mining and probabilistic analysis to
get more accurate results. Semantic web mining technique can provide meaningful
search of data resources by eliminating useless information with mining
process. In this technique web servers will maintain Meta information of each
and every data resources available in that particular web server. This will
help the search engine to retrieve information that is relevant to user given
input string. This paper proposing the idea of combing these two techniques
Semantic web mining and Probabilistic analysis for efficient and accurate
search results of web mining. SPF can be calculated by considering both
semantic accuracy and syntactic accuracy of data with the input string. This
will be the deciding factor for producing results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1796</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1796</id><created>2010-04-11</created><authors><author><keyname>Gayathri</keyname><forenames>P. J.</forenames></author><author><keyname>Punitha</keyname><forenames>S. C.</forenames></author><author><keyname>Punithavalli</keyname><forenames>M.</forenames></author></authors><title>Document Clustering using Sequential Information Bottleneck Method</title><categories>cs.IR</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010, 305-312</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper illustrates the Principal Direction Divisive Partitioning (PDDP)
algorithm and describes its drawbacks and introduces a combinatorial framework
of the Principal Direction Divisive Partitioning (PDDP) algorithm, then
describes the simplified version of the EM algorithm called the spherical
Gaussian EM (sGEM) algorithm and Information Bottleneck method (IB) is a
technique for finding accuracy, complexity and time space. The PDDP algorithm
recursively splits the data samples into two sub clusters using the hyper plane
normal to the principal direction derived from the covariance matrix, which is
the central logic of the algorithm. However, the PDDP algorithm can yield poor
results, especially when clusters are not well separated from one another. To
improve the quality of the clustering results problem, it is resolved by
reallocating new cluster membership using the IB algorithm with different
settings. IB Method gives accuracy but time consumption is more. Furthermore,
based on the theoretical background of the sGEM algorithm and sequential
Information Bottleneck method(sIB), it can be obvious to extend the framework
to cover the problem of estimating the number of clusters using the Bayesian
Information Criterion. Experimental results are given to show the effectiveness
of the proposed algorithm with comparison to the existing algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1808</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1808</id><created>2010-04-11</created><updated>2013-06-18</updated><authors><author><keyname>Trofimov</keyname><forenames>Michael I.</forenames></author></authors><title>Polynomial Time Algorithm for Graph Isomorphism Testing</title><categories>cs.DS</categories><comments>20 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article deals with new polynomial time algorithm for graph isomorphism
testing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1814</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1814</id><created>2010-04-11</created><updated>2010-10-02</updated><authors><author><keyname>Manyem</keyname><forenames>Prabhu</forenames></author></authors><title>Existential Second Order Logic Expression With Horn First Order for
  Maximum Clique (Decision Version)</title><categories>cs.CC cs.LO math.LO</categories><comments>Manuscript withdrawn, because results are incorrect. If phi = phi_1
  AND phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and
  phi_2 are Horn formulae. Furthermore, the cardinality constraint CANNOT be
  expressed as a universal Horn sentence in ESO (NOT even when the structure is
  ordered). Graedel's theorem is valid at a lower (machine) level, but probably
  NOT at a higher level</comments><msc-class>03D15, 68Q15, 68Q17, 68Q19</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the maximum clique problem (decision version) can be expressed
in existential second order (ESO) logic, where the first order part is a Horn
formula in second-order quantified predicates. Without ordering, the first
order part is $\Pi_2$ Horn; if ordering is used, then it is universal Horn (in
which case, the second order variables can be determined in polynomial time).
UPDATE: Manuscript withdrawn, because results are incorrect. If phi = phi_1 AND
phi_2, and phi is a Horn formula, it does NOT mean that both phi_1 and phi_2
are Horn formulae. Furthermore, the cardinality constraint CANNOT be expressed
as a universal Horn sentence in ESO (NOT even when the structure is ordered).
Graedel's theorem is valid at a lower (machine) level, but probably NOT at a
higher level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1821</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1821</id><created>2010-04-11</created><authors><author><keyname>Blanchard</keyname><forenames>Jeffrey D.</forenames></author><author><keyname>Cartis</keyname><forenames>Coralia</forenames></author><author><keyname>Tanner</keyname><forenames>Jared</forenames></author><author><keyname>Thompson</keyname><forenames>Andrew</forenames></author></authors><title>Phase Transitions for Greedy Sparse Approximation Algorithms</title><categories>cs.IT math.IT</categories><comments>31 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major enterprise in compressed sensing and sparse approximation is the
design and analysis of computationally tractable algorithms for recovering
sparse, exact or approximate, solutions of underdetermined linear systems of
equations. Many such algorithms have now been proven to have optimal-order
uniform recovery guarantees using the ubiquitous Restricted Isometry Property
(RIP). However, it is unclear when the RIP-based sufficient conditions on the
algorithm are satisfied. We present a framework in which this task can be
achieved; translating these conditions for Gaussian measurement matrices into
requirements on the signal's sparsity level, length, and number of
measurements. We illustrate this approach on three of the state-of-the-art
greedy algorithms: CoSaMP, Subspace Pursuit (SP), and Iterative Hard
Thresholding (IHT). Designed to allow a direct comparison of existing theory,
our framework implies that, according to the best known bounds, IHT requires
the fewest number of compressed sensing measurements and has the lowest per
iteration computational cost of the three algorithms compared here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1823</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1823</id><created>2010-04-11</created><authors><author><keyname>Kumar</keyname><forenames>Amit</forenames></author><author><keyname>Kannan</keyname><forenames>Ravindran</forenames></author></authors><title>Clustering with Spectral Norm and the k-means Algorithm</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been much progress on efficient algorithms for clustering data
points generated by a mixture of $k$ probability distributions under the
assumption that the means of the distributions are well-separated, i.e., the
distance between the means of any two distributions is at least $\Omega(k)$
standard deviations. These results generally make heavy use of the generative
model and particular properties of the distributions. In this paper, we show
that a simple clustering algorithm works without assuming any generative
(probabilistic) model. Our only assumption is what we call a &quot;proximity
condition&quot;: the projection of any data point onto the line joining its cluster
center to any other cluster center is $\Omega(k)$ standard deviations closer to
its own center than the other center. Here the notion of standard deviations is
based on the spectral norm of the matrix whose rows represent the difference
between a point and the mean of the cluster to which it belongs. We show that
in the generative models studied, our proximity condition is satisfied and so
we are able to derive most known results for generative models as corollaries
of our main result. We also prove some new results for generative models -
e.g., we can cluster all but a small fraction of points only assuming a bound
on the variance. Our algorithm relies on the well known $k$-means algorithm,
and along the way, we prove a result of independent interest -- that the
$k$-means algorithm converges to the &quot;true centers&quot; even in the presence of
spurious points provided the initial (estimated) centers are close enough to
the corresponding actual centers and all but a small fraction of the points
satisfy the proximity condition. Finally, we present a new technique for
boosting the ratio of inter-center separation to standard deviation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1830</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1830</id><created>2010-04-11</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>About the embedding of one dimensional cellular automata into hyperbolic
  cellular automata</title><categories>cs.FL nlin.CG</categories><comments>19 pages, 9 figures</comments><msc-class>68R05</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we look at two ways to implement determinisitic one
dimensional cellular automata into hyperbolic cellular automata in three
contexts: the pentagrid, the heptagrid and the dodecagrid, these tilings being
classically denoted by $\{5,4\}$, $\{7,3\}$ and $\{5,3,4\}$ respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1836</identifier>
 <datestamp>2012-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1836</id><created>2010-04-11</created><updated>2012-02-07</updated><authors><author><keyname>Chebolu</keyname><forenames>Prasad</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Martin</keyname><forenames>Russell</forenames></author></authors><title>The Complexity of Approximately Counting Stable Matchings</title><categories>cs.CC cs.DM</categories><comments>Fixed typos, small revisions for clarification, etc</comments><msc-class>68Q15, 68Q25</msc-class><journal-ref>TCS 2012</journal-ref><doi>10.1016/j.tcs.2012.02.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the complexity of approximately counting stable matchings in
the $k$-attribute model, where the preference lists are determined by dot
products of &quot;preference vectors&quot; with &quot;attribute vectors&quot;, or by Euclidean
distances between &quot;preference points&quot; and &quot;attribute points&quot;. Irving and
Leather proved that counting the number of stable matchings in the general case
is $#P$-complete. Counting the number of stable matchings is reducible to
counting the number of downsets in a (related) partial order and is
interreducible, in an approximation-preserving sense, to a class of problems
that includes counting the number of independent sets in a bipartite graph
($#BIS$). It is conjectured that no FPRAS exists for this class of problems. We
show this approximation-preserving interreducibilty remains even in the
restricted $k$-attribute setting when $k \geq 3$ (dot products) or $k \geq 2$
(Euclidean distances). Finally, we show it is easy to count the number of
stable matchings in the 1-attribute dot-product setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1842</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1842</id><created>2010-04-11</created><authors><author><keyname>Zhao</keyname><forenames>Pengkai</forenames><affiliation>Electrical Engineering Department, University of California, Los Angeles, USA</affiliation></author><author><keyname>Daneshrad</keyname><forenames>Babak</forenames><affiliation>Electrical Engineering Department, University of California, Los Angeles, USA</affiliation></author></authors><title>Throughput Enhancement Using Multiple Antennas in OFDM-based Ad Hoc
  Networks under Transceiver Impairments</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Transceiver impairments, including phase noise, residual frequency offset,
and imperfect channel estimation, significantly affect the performance of
Multiple-Input Multiple-Output (MIMO) system. However, these impairments are
not well addressed when analyzing the throughput performance of MIMO Ad Hoc
networks. In this paper, we present an analytical framework to evaluate the
throughput of MIMO OFDM system under the impairments of phase noise, residual
frequency offset, and imperfect channel estimation. Using this framework, we
evaluate the Maximum Sum Throughput (MST) in Ad Hoc networks by optimizing the
power and modulation schemes of each user. Simulations are conducted to
demonstrate not only the improvement in the MST from using multiple antennas,
but also the loss in the MST due to the transceiver impairments. The proposed
analytical framework is further applied for the distributed implementation of
MST in Ad Hoc networks, where the loss caused by impairments is also evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1845</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1845</id><created>2010-04-11</created><authors><author><keyname>Br&#xfc;nnler</keyname><forenames>Kai</forenames></author></authors><title>Nested Sequents</title><categories>cs.LO math.LO</categories><msc-class>03F07, 03B45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We see how nested sequents, a natural generalisation of hypersequents, allow
us to develop a systematic proof theory for modal logics. As opposed to other
prominent formalisms, such as the display calculus and labelled sequents,
nested sequents stay inside the modal language and allow for proof systems
which enjoy the subformula property in the literal sense. In the first part we
study a systematic set of nested sequent systems for all normal modal logics
formed by some combination of the axioms for seriality, reflexivity, symmetry,
transitivity and euclideanness. We establish soundness and completeness and
some of their good properties, such as invertibility of all rules,
admissibility of the structural rules, termination of proof-search, as well as
syntactic cut-elimination. In the second part we study the logic of common
knowledge, a modal logic with a fixpoint modality. We look at two infinitary
proof systems for this logic: an existing one based on ordinary sequents, for
which no syntactic cut-elimination procedure is known, and a new one based on
nested sequents. We see how nested sequents, in contrast to ordinary sequents,
allow for syntactic cut-elimination and thus allow us to obtain an ordinal
upper bound on the length of proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1854</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1854</id><created>2010-04-11</created><updated>2011-04-20</updated><authors><author><keyname>Anshelevich</keyname><forenames>Elliot</forenames></author><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author></authors><title>Contribution Games in Social Networks</title><categories>cs.GT cs.DS cs.MA</categories><comments>36 pages, 2 figures</comments><journal-ref>Algorithmica, Volume 63, 1-2 (2012), pp. 51--90</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider network contribution games, where each agent in a social network
has a budget of effort that he can contribute to different collaborative
projects or relationships. Depending on the contribution of the involved agents
a relationship will flourish or drown, and to measure the success we use a
reward function for each relationship. Every agent is trying to maximize the
reward from all relationships that it is involved in. We consider pairwise
equilibria of this game, and characterize the existence, computational
complexity, and quality of equilibrium based on the types of reward functions
involved. For example, when all reward functions are concave, we prove that the
price of anarchy is at most 2. For convex functions the same only holds under
some special but very natural conditions. A special focus of the paper are
minimum effort games, where the reward of a relationship depends only on the
minimum effort of any of the participants. Finally, we show tight bounds for
approximate equilibria and convergence of dynamics in these games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1864</identifier>
 <datestamp>2010-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1864</id><created>2010-04-11</created><updated>2010-08-06</updated><authors><author><keyname>Zhao</keyname><forenames>Wenbing</forenames></author><author><keyname>Melliar-Smith</keyname><forenames>P. M.</forenames></author><author><keyname>Moser</keyname><forenames>L. E.</forenames></author></authors><title>The Low Latency Fault Tolerance System</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Low Latency Fault Tolerance (LLFT) system provides fault tolerance for
distributed applications, using the leader-follower replication technique. The
LLFT system provides application-transparent replication, with strong replica
consistency, for applications that involve multiple interacting processes or
threads. The LLFT system comprises a Low Latency Messaging Protocol, a
Leader-Determined Membership Protocol, and a Virtual Determinizer Framework.
The Low Latency Messaging Protocol provides reliable, totally ordered message
delivery by employing a direct group-to-group multicast, where the message
ordering is determined by the primary replica in the group. The
Leader-Determined Membership Protocol provides reconfiguration and recovery
when a replica becomes faulty and when a replica joins or leaves a group, where
the membership of the group is determined by the primary replica. The Virtual
Determinizer Framework captures the ordering information at the primary replica
and enforces the same ordering at the backup replicas for major sources of
non-determinism, including multi-threading, time-related operations and socket
communication. The LLFT system achieves low latency message delivery during
normal operation and low latency reconfiguration and recovery when a fault
occurs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1886</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1886</id><created>2010-04-12</created><authors><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author></authors><title>Feature Level Fusion of Face and Palmprint Biometrics by Isomorphic
  Graph-based Improved K-Medoids Partitioning</title><categories>cs.CV</categories><comments>13 pages, 4 figures</comments><acm-class>D.2.2; I.2.10</acm-class><journal-ref>ISA 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents a feature level fusion approach which uses the improved
K-medoids clustering algorithm and isomorphic graph for face and palmprint
biometrics. Partitioning around medoids (PAM) algorithm is used to partition
the set of n invariant feature points of the face and palmprint images into k
clusters. By partitioning the face and palmprint images with scale invariant
features SIFT points, a number of clusters is formed on both the images. Then
on each cluster, an isomorphic graph is drawn. In the next step, the most
probable pair of graphs is searched using iterative relaxation algorithm from
all possible isomorphic graphs for a pair of corresponding face and palmprint
images. Finally, graphs are fused by pairing the isomorphic graphs into
augmented groups in terms of addition of invariant SIFT points and in terms of
combining pair of keypoint descriptors by concatenation rule. Experimental
results obtained from the extensive evaluation show that the proposed feature
level fusion with the improved K-medoids partitioning algorithm increases the
performance of the system with utmost level of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1887</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1887</id><created>2010-04-12</created><authors><author><keyname>Gupta</keyname><forenames>Phalguni</forenames></author><author><keyname>Kisku</keyname><forenames>Dakshina Ranjan</forenames></author><author><keyname>Sing</keyname><forenames>Jamuna Kanta</forenames></author><author><keyname>Tistarelli</keyname><forenames>Massimo</forenames></author></authors><title>Maximized Posteriori Attributes Selection from Facial Salient Landmarks
  for Face Recognition</title><categories>cs.CV</categories><comments>8 pages, 2 figures</comments><acm-class>D.2.2; I.2.10</acm-class><journal-ref>ISA 2010</journal-ref><doi>10.1007/978-3-642-13365-7_1</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents a robust and dynamic face recognition technique based on
the extraction and matching of devised probabilistic graphs drawn on SIFT
features related to independent face areas. The face matching strategy is based
on matching individual salient facial graph characterized by SIFT features as
connected to facial landmarks such as the eyes and the mouth. In order to
reduce the face matching errors, the Dempster-Shafer decision theory is applied
to fuse the individual matching scores obtained from each pair of salient
facial features. The proposed algorithm is evaluated with the ORL and the IITK
face databases. The experimental results demonstrate the effectiveness and
potential of the proposed face recognition technique also in case of partially
occluded faces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1917</identifier>
 <datestamp>2010-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1917</id><created>2010-04-12</created><updated>2010-10-04</updated><authors><author><keyname>Pritchard</keyname><forenames>David</forenames></author></authors><title>k-Edge-Connectivity: Approximation and LP Relaxation</title><categories>cs.DM math.CO</categories><comments>Appeared at WAOA 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the k-edge-connected spanning subgraph problem we are given a graph (V, E)
and costs for each edge, and want to find a minimum-cost subset F of E such
that (V, F) is k-edge-connected. We show there is a constant eps &gt; 0 so that
for all k &gt; 1, finding a (1 + eps)-approximation for k-ECSS is NP-hard,
establishing a gap between the unit-cost and general-cost versions. Next, we
consider the multi-subgraph cousin of k-ECSS, in which we purchase a
multi-subset F of E, with unlimited parallel copies available at the same cost
as the original edge. We conjecture that a (1 + Theta(1/k))-approximation
algorithm exists, and we describe an approach based on graph decompositions
applied to its natural linear programming (LP) relaxation. The LP is
essentially equivalent to the Held-Karp LP for TSP and the undirected LP for
Steiner tree. We give a family of extreme points for the LP which are more
complex than those previously known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1938</identifier>
 <datestamp>2010-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1938</id><created>2010-04-12</created><updated>2010-07-25</updated><authors><author><keyname>Tamo</keyname><forenames>Itzhak</forenames></author><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>On Optimal Anticodes over Permutations with the Infinity Norm</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the set-antiset method for codes over permutations under the
infinity norm, we study anticodes under this metric. For half of the parameter
range we classify all the optimal anticodes, which is equivalent to finding the
maximum permanent of certain $(0,1)$-matrices. For the rest of the cases we
show constraints on the structure of optimal anticodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1946</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1946</id><created>2010-04-12</created><authors><author><keyname>Darji</keyname><forenames>Udayan B.</forenames></author><author><keyname>Seif</keyname><forenames>Steve W.</forenames></author></authors><title>A note on decidability of cellularity</title><categories>cs.FL</categories><msc-class>68Q80, 68Q45, 68Q15, 03D15.</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A regular language L is said to be cellular if there exists a 1-dimensional
cellular automaton CA such that L is the language consisting of the finite
blocks associated with CA. It is shown that cellularity of a regular language
is decidable using a new characterization of cellular languages formulated by
Freiling, Goldstein and Moews and implied by a deep result of Boyle in symbolic
dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1947</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1947</id><created>2010-04-12</created><updated>2010-06-22</updated><authors><author><keyname>Brown</keyname><forenames>Chad E.</forenames><affiliation>Saarland University</affiliation></author><author><keyname>Smolka</keyname><forenames>Gert</forenames><affiliation>Saarland University</affiliation></author></authors><title>Analytic Tableaux for Simple Type Theory and its First-Order Fragment</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>03B15</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 2 (June 23,
  2010) lmcs:1169</journal-ref><doi>10.2168/LMCS-6(2:4)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study simple type theory with primitive equality (STT) and its first-order
fragment EFO, which restricts equality and quantification to base types but
retains lambda abstraction and higher-order variables. As deductive system we
employ a cut-free tableau calculus. We consider completeness, compactness, and
existence of countable models. We prove these properties for STT with respect
to Henkin models and for EFO with respect to standard models. We also show that
the tableau system yields a decision procedure for three EFO fragments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1955</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1955</id><created>2010-04-12</created><updated>2010-08-08</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>An Achievable Rate for the MIMO Individual Channel</title><categories>cs.IT math.IT</categories><comments>to be presented at ITW2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of communicating over a multiple-input
multiple-output (MIMO) real valued channel for which no mathematical model is
specified, and achievable rates are given as a function of the channel input
and output sequences known a-posteriori. This paper extends previous results
regarding individual channels by presenting a rate function for the MIMO
individual channel, and showing its achievability in a fixed transmission rate
communication scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1956</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1956</id><created>2010-04-12</created><updated>2011-07-08</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>van Iersel</keyname><forenames>Leo</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>All Ternary Permutation Constraint Satisfaction Problems Parameterized
  Above Average Have Kernels with Quadratic Numbers of Variables</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A ternary Permutation-CSP is specified by a subset $\Pi$ of the symmetric
group $\mathcal S_3$. An instance of such a problem consists of a set of
variables $V$ and a multiset of constraints, which are ordered triples of
distinct variables of $V.$ The objective is to find a linear ordering $\alpha$
of $V$ that maximizes the number of triples whose ordering (under $\alpha$)
follows a permutation in $\Pi$. We prove that all ternary Permutation-CSPs
parameterized above average have kernels with quadratic numbers of variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1982</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1982</id><created>2010-04-09</created><authors><author><keyname>Garc&#xed;a-Garc&#xed;a</keyname><forenames>Dar&#xed;o</forenames></author><author><keyname>Parrado-Hern&#xe1;ndez</keyname><forenames>Emilio</forenames></author><author><keyname>D&#xed;az-de-Mar&#xed;a</keyname><forenames>Fernando</forenames></author></authors><title>State-Space Dynamics Distance for Clustering Sequential Data</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel similarity measure for clustering sequential
data. We first construct a common state-space by training a single
probabilistic model with all the sequences in order to get a unified
representation for the dataset. Then, distances are obtained attending to the
transition matrices induced by each sequence in that state-space. This approach
solves some of the usual overfitting and scalability issues of the existing
semi-parametric techniques, that rely on training a model for each sequence.
Empirical studies on both synthetic and real-world datasets illustrate the
advantages of the proposed similarity measure for clustering sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1983</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1983</id><created>2010-04-07</created><authors><author><keyname>Chakrabarti</keyname><forenames>P.</forenames></author></authors><title>Predictive Gain Estimation - A mathematical analysis</title><categories>cs.OH</categories><comments>IEEE Publication format, ISSN 1947 5500,
  http://sites.google.com/site/ijcsis/</comments><journal-ref>IJCSIS, Vol. 7 No. 3, March 2010</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In case of realization of successful business, gain analysis is essential. In
this paper we have cited some new techniques of gain expectation on the basis
of neural property of perceptron. Support rule and Sequence mining based
artificial intelligence oriented practices have also been done in this context.
In the view of above fuzzy and statistical based gain sensing is also pointed
out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1986</identifier>
 <datestamp>2012-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1986</id><created>2010-04-12</created><updated>2010-10-19</updated><authors><author><keyname>Goreinov</keyname><forenames>S. A.</forenames></author><author><keyname>Oseledets</keyname><forenames>I. V.</forenames></author><author><keyname>Savostyanov</keyname><forenames>D. V.</forenames></author></authors><title>Wedderburn rank reduction and Krylov subspace method for tensor
  approximation. Part 1: Tucker case</title><categories>math.NA cs.DS cs.NA</categories><comments>34 pages, 3 tables, 5 figures. Submitted to SIAM J. Scientific
  Computing</comments><msc-class>15A23, 15A69, 65F99</msc-class><acm-class>G.1.2; G.1.3</acm-class><journal-ref>SIAM J. Sci Comp, V 34(1), pp. A1-A27, 2012</journal-ref><doi>10.1137/100792056</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New algorithms are proposed for the Tucker approximation of a 3-tensor, that
access it using only the tensor-by-vector-by-vector multiplication subroutine.
In the matrix case, Krylov methods are methods of choice to approximate the
dominant column and row subspaces of a sparse or structured matrix given
through the matrix-by-vector multiplication subroutine. Using the Wedderburn
rank reduction formula, we propose an algorithm of matrix approximation that
computes Krylov subspaces and allows generalization to the tensor case. Several
variants of proposed tensor algorithms differ by pivoting strategies, overall
cost and quality of approximation. By convincing numerical experiments we show
that the proposed methods are faster and more accurate than the minimal Krylov
recursion, proposed recently by Elden and Savas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1995</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1995</id><created>2010-04-12</created><updated>2012-03-06</updated><authors><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Wischik</keyname><forenames>Damon</forenames></author></authors><title>Switched networks with maximum weight policies: Fluid approximation and
  multiplicative state space collapse</title><categories>math.PR cs.NI</categories><comments>Published in at http://dx.doi.org/10.1214/11-AAP759 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP759</report-no><journal-ref>Annals of Applied Probability 2012, Vol. 22, No. 1, 70-127</journal-ref><doi>10.1214/11-AAP759</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a queueing network in which there are constraints on which queues
may be served simultaneously; such networks may be used to model input-queued
switches and wireless networks. The scheduling policy for such a network
specifies which queues to serve at any point in time. We consider a family of
scheduling policies, related to the maximum-weight policy of Tassiulas and
Ephremides [IEEE Trans. Automat. Control 37 (1992) 1936--1948], for single-hop
and multihop networks. We specify a fluid model and show that fluid-scaled
performance processes can be approximated by fluid model solutions. We study
the behavior of fluid model solutions under critical load, and characterize
invariant states as those states which solve a certain network-wide
optimization problem. We use fluid model results to prove multiplicative state
space collapse. A notable feature of our results is that they do not assume
complete resource pooling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1997</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1997</id><created>2010-04-12</created><authors><author><keyname>Sha</keyname><forenames>Daohang</forenames></author><author><keyname>Bajic</keyname><forenames>Vladimir B.</forenames></author></authors><title>An optimized recursive learning algorithm for three-layer feedforward
  neural networks for mimo nonlinear system identifications</title><categories>cs.NE cs.DC cs.LG</categories><comments>15 pages, 5 figures</comments><journal-ref>Intelligent Automation and Soft Computing, Vol. 17, No. 2, pp.
  133-147, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Back-propagation with gradient method is the most popular learning algorithm
for feed-forward neural networks. However, it is critical to determine a proper
fixed learning rate for the algorithm. In this paper, an optimized recursive
algorithm is presented for online learning based on matrix operation and
optimization methods analytically, which can avoid the trouble to select a
proper learning rate for the gradient method. The proof of weak convergence of
the proposed algorithm also is given. Although this approach is proposed for
three-layer, feed-forward neural networks, it could be extended to multiple
layer feed-forward neural networks. The effectiveness of the proposed
algorithms applied to the identification of behavior of a two-input and
two-output non-linear dynamic system is demonstrated by simulation experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.1999</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.1999</id><created>2010-04-12</created><updated>2013-08-21</updated><authors><author><keyname>Murtra</keyname><forenames>Bernat Corominas</forenames></author><author><keyname>Andreu</keyname><forenames>Jordi Fortuny</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Ricard</forenames></author></authors><title>Towards a mathematical theory of meaningful communication</title><categories>cs.IT math.IT nlin.AO q-bio.OT</categories><comments>10 RevTex pages, 3 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite its obvious relevance, meaning has been outside most theoretical
approaches to information in biology. As a consequence, functional responses
based on an appropriate interpretation of signals has been replaced by a
probabilistic description of correlations between emitted and received symbols.
This assumption leads to potential paradoxes, such as the presence of a maximum
information associated to a channel that would actually create completely wrong
interpretations of the signals. Game-theoretic models of language evolution use
this view of Shannon's theory, but other approaches considering embodied
communicating agents show that the correct (meaningful) match resulting from
agent-agent exchanges is always achieved and natural systems obviously solve
the problem correctly. How can Shannon's theory be expanded in such a way that
meaning -at least, in its minimal referential form- is properly incorporated?
Inspired by the concept of {\em duality of the communicative sign} stated by
the swiss linguist Ferdinand de Saussure, here we present a complete
description of the minimal system necessary to measure the amount of
information that is consistently decoded. Several consequences of our
developments are investigated, such the uselessness of an amount of information
properly transmitted for communication among autonomous agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2003</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2003</id><created>2010-04-12</created><updated>2010-04-22</updated><authors><author><keyname>B&#xe1;tfai</keyname><forenames>Norbert</forenames></author></authors><title>The Socceral Force</title><categories>cs.AI cs.SE</categories><comments>20 pages, 13 figures, added FerSML 0.0.2</comments><msc-class>68T35</msc-class><acm-class>H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have an audacious dream, we would like to develop a simulation and virtual
reality system to support the decision making in European football (soccer). In
this review, we summarize the efforts that we have made to fulfil this dream
until recently. In addition, an introductory version of FerSML (Footballer and
Football Simulation Markup Language) is presented in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2008</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2008</id><created>2010-04-12</created><authors><author><keyname>Talwalkar</keyname><forenames>Ameet</forenames></author><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author></authors><title>Matrix Coherence and the Nystrom Method</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Nystrom method is an efficient technique to speed up large-scale learning
applications by generating low-rank approximations. Crucial to the performance
of this technique is the assumption that a matrix can be well approximated by
working exclusively with a subset of its columns. In this work we relate this
assumption to the concept of matrix coherence and connect matrix coherence to
the performance of the Nystrom method. Making use of related work in the
compressed sensing and the matrix completion literature, we derive novel
coherence-based bounds for the Nystrom method in the low-rank setting. We then
present empirical results that corroborate these theoretical bounds. Finally,
we present more general empirical results for the full-rank setting that
convincingly demonstrate the ability of matrix coherence to measure the degree
to which information can be extracted from a subset of columns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2027</identifier>
 <datestamp>2011-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2027</id><created>2010-04-12</created><updated>2011-09-06</updated><authors><author><keyname>Azar</keyname><forenames>Mohammad Gheshlaghi</forenames></author><author><keyname>Gomez</keyname><forenames>Vicenc</forenames></author><author><keyname>Kappen</keyname><forenames>Hilbert J.</forenames></author></authors><title>Dynamic Policy Programming</title><categories>cs.LG cs.AI cs.SY math.OC stat.ML</categories><comments>Submitted to Journal of Machine Learning Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel policy iteration method, called dynamic
policy programming (DPP), to estimate the optimal policy in the
infinite-horizon Markov decision processes. We prove the finite-iteration and
asymptotic l\infty-norm performance-loss bounds for DPP in the presence of
approximation/estimation error. The bounds are expressed in terms of the
l\infty-norm of the average accumulated error as opposed to the l\infty-norm of
the error in the case of the standard approximate value iteration (AVI) and the
approximate policy iteration (API). This suggests that DPP can achieve a better
performance than AVI and API since it averages out the simulation noise caused
by Monte-Carlo sampling throughout the learning process. We examine this
theoretical results numerically by com- paring the performance of the
approximate variants of DPP with existing reinforcement learning (RL) methods
on different problem domains. Our results show that, in all cases, DPP-based
algorithms outperform other RL methods by a wide margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2030</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2030</id><created>2010-04-12</created><updated>2014-12-12</updated><authors><author><keyname>Grabowski</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>On Turing dynamical systems and the Atiyah problem</title><categories>math.GR cs.CC math.DS math.OA</categories><comments>35 pages; essentially identical to the published version</comments><msc-class>20C07 (Primary) 37A30, 20L05 (Secondary)</msc-class><journal-ref>Invent. Math., 198(1):27-69, 2014</journal-ref><doi>10.1007/s00222-013-0497-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Main theorems of the article concern the problem of M. Atiyah on possible
values of l^2-Betti numbers. It is shown that all non-negative real numbers are
l^2-Betti numbers, and that &quot;many&quot; (for example all non-negative algebraic)
real numbers are l^2-Betti numbers of simply connected manifolds with respect
to a free cocompact action. Also an explicit example is constructed which leads
to a simply connected manifold with a transcendental l^2-Betti number with
respect to an action of the threefold direct product of the lamplighter group
Z/2 wr Z. The main new idea is embedding Turing machines into integral group
rings. The main tool developed generalizes known techniques of spectral
computations for certain random walk operators to arbitrary operators in
groupoid rings of discrete measured groupoids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2033</identifier>
 <datestamp>2012-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2033</id><created>2010-04-12</created><authors><author><keyname>Bonifaci</keyname><forenames>Vincenzo</forenames></author><author><keyname>Marchetti-Spaccamela</keyname><forenames>Alberto</forenames></author></authors><title>Feasibility Analysis of Sporadic Real-Time Multiprocessor Task Systems</title><categories>cs.DS</categories><msc-class>68Q25</msc-class><acm-class>F.2.2</acm-class><journal-ref>Algorithmica, 63(4):763-780, 2012</journal-ref><doi>10.1007/s00453-011-9505-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first algorithm for testing the feasibility of a system of
sporadic real-time tasks on a set of identical processors, solving one major
open problem in the area of multiprocessor real-time scheduling [S.K. Baruah
and K. Pruhs, Journal of Scheduling, 2009]. We also investigate the related
notion of schedulability and a notion that we call online feasibility. Finally,
we show that discrete-time schedules are as powerful as continuous-time
schedules, which answers another open question in the above mentioned survey.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2079</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2079</id><created>2010-04-12</created><updated>2011-12-06</updated><authors><author><keyname>Bayati</keyname><forenames>Mohsen</forenames></author><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer</forenames></author><author><keyname>Kanoria</keyname><forenames>Yashodhan</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Bargaining dynamics in exchange networks</title><categories>cs.GT cs.MA</categories><comments>47 pages, SODA 2011, invited to Journal of Economic Theory</comments><journal-ref>Proc. ACM-SIAM Symp. on Discrete Algorithms (2011) 1518-1537</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a one-sided assignment market or exchange network with
transferable utility and propose a model for the dynamics of bargaining in such
a market. Our dynamical model is local, involving iterative updates of 'offers'
based on estimated best alternative matches, in the spirit of pairwise Nash
bargaining. We establish that when a balanced outcome (a generalization of the
pairwise Nash bargaining solution to networks) exists, our dynamics converges
rapidly to such an outcome. We extend our results to the cases of (i) general
agent 'capacity constraints', i.e., an agent may be allowed to participate in
multiple matches, and (ii) 'unequal bargaining powers' (where we also find a
surprising change in rate of convergence).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2090</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2090</id><created>2010-04-12</created><updated>2010-10-01</updated><authors><author><keyname>Ma</keyname><forenames>Xiaodong</forenames></author><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Dingkang</forenames></author></authors><title>On Computing Groebner Basis in the Rings of Differential Operators</title><categories>cs.SC</categories><doi>10.1007/s11425-011-4176-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Insa and Pauer presented a basic theory of Groebner basis for differential
operators with coefficients in a commutative ring in 1998, and a criterion was
proposed to determine if a set of differential operators is a Groebner basis.
In this paper, we will give a new criterion such that Insa and Pauer's
criterion could be concluded as a special case and one could compute the
Groebner basis more efficiently by this new criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2091</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2091</id><created>2010-04-12</created><updated>2010-06-01</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author><author><keyname>Zimmermann</keyname><forenames>Paul</forenames></author></authors><title>An O(M(n) log n) algorithm for the Jacobi symbol</title><categories>cs.DS math.NT</categories><comments>Submitted to ANTS IX (Nancy, July 2010)</comments><msc-class>11Y16</msc-class><journal-ref>Proc. ANTS-IX (Nancy, 19-23 July 2010), Lecture Notes in Computer
  Science, Vol. 6197, Springer-Verlag, 2010, 83-95</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The best known algorithm to compute the Jacobi symbol of two n-bit integers
runs in time O(M(n) log n), using Sch\&quot;onhage's fast continued fraction
algorithm combined with an identity due to Gauss. We give a different O(M(n)
log n) algorithm based on the binary recursive gcd algorithm of Stehl\'e and
Zimmermann. Our implementation - which to our knowledge is the first to run in
time O(M(n) log n) - is faster than GMP's quadratic implementation for inputs
larger than about 10000 decimal digits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2102</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2102</id><created>2010-04-12</created><updated>2011-06-25</updated><authors><author><keyname>Hendrickx</keyname><forenames>Julien M.</forenames></author><author><keyname>Olshevsky</keyname><forenames>Alex</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Distributed anonymous discrete function computation</title><categories>math.OC cs.DC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model for deterministic distributed function computation by a
network of identical and anonymous nodes. In this model, each node has bounded
computation and storage capabilities that do not grow with the network size.
Furthermore, each node only knows its neighbors, not the entire graph. Our goal
is to characterize the class of functions that can be computed within this
model. In our main result, we provide a necessary condition for computability
which we show to be nearly sufficient, in the sense that every function that
satisfies this condition can at least be approximated. The problem of computing
suitably rounded averages in a distributed manner plays a central role in our
development; we provide an algorithm that solves it in time that grows
quadratically with the size of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2104</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2104</id><created>2010-04-13</created><updated>2010-06-27</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Sum Capacity of K User Gaussian Degraded Interference Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a family of genie-MAC (multiple access channel) outer
bounds for K-user Gaussian interference channels. This family is inspired by
existing genie-aided bounding mechanisms, but differs from current approaches
in its optimization problem formulation and application. The fundamental idea
behind these bounds is to create a group of genie receivers that form multiple
access channels that can decode a subset of the original interference channel's
messages. The MAC sum capacity of each of the genie receivers provides an outer
bound on the sum of rates for this subset. The genie-MAC outer bounds are used
to derive new sum-capacity results. In particular, this paper derives
sum-capacity in closed-form for the class of K-user Gaussian degraded
interference channels. The sum-capacity achieving scheme is shown to be a
successive interference cancellation scheme. This result generalizes a known
result for two-user channels to K-user channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2115</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2115</id><created>2010-04-13</created><updated>2010-04-14</updated><authors><author><keyname>Babenko</keyname><forenames>Maxim A.</forenames></author></authors><title>A Faster Algorithm for the Maximum Even Factor Problem</title><categories>math.CO cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a digraph $G = (VG,AG)$, an \emph{even factor} $M \subseteq AG$ is a
subset of arcs that decomposes into a collection of node-disjoint paths and
even cycles. Even factors in digraphs were introduced by Geleen and Cunningham
and generalize path matchings in undirected graphs. Finding an even factor of
maximum cardinality in a general digraph is known to be NP-hard but for the
class of \emph{odd-cycle symmetric} digraphs the problem is polynomially
solvable. So far, the only combinatorial algorithm known for this task is due
to Pap; it has the running time of $O(n^4)$ (hereinafter $n$ stands for the
number of nodes in $G$). In this paper we present a novel \emph{sparse
recovery} technique and devise an $O(n^3 \log n)$-time algorithm for finding a
maximum cardinality even factor in an odd-cycle symmetric digraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2131</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2131</id><created>2010-04-13</created><authors><author><keyname>Natarajan</keyname><forenames>Lakshmi Prasad</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A New Full-diversity Criterion and Low-complexity STBCs with Partial
  Interference Cancellation Decoding</title><categories>cs.IT math.IT</categories><comments>9 pages, 2 figures, 1 table.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Guo and Xia gave sufficient conditions for an STBC to achieve full
diversity when a PIC (Partial Interference Cancellation) or a PIC-SIC (PIC with
Successive Interference Cancellation) decoder is used at the receiver. In this
paper, we give alternative conditions for an STBC to achieve full diversity
with PIC and PIC-SIC decoders, which are equivalent to Guo and Xia's
conditions, but are much easier to check. Using these conditions, we construct
a new class of full diversity PIC-SIC decodable codes, which contain the
Toeplitz codes and a family of codes recently proposed by Zhang, Xu et. al. as
proper subclasses. With the help of the new criteria, we also show that a class
of PIC-SIC decodable codes recently proposed by Zhang, Shi et. al. can be
decoded with much lower complexity than what is reported, without compromising
on full diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2132</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2132</id><created>2010-04-13</created><authors><author><keyname>Juneja</keyname><forenames>Mamta</forenames></author><author><keyname>Sandhu</keyname><forenames>Parvinder singh</forenames></author></authors><title>Improved information security using robust Steganography system</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Steganography is an emerging area which is used for secured data transmission
over any public media.Steganography is a process that involves hiding a message
in an appropriate carrier like image or audio. It is of Greek origin and means
&quot;covered or hidden writing&quot;. The carrier can be sent to a receiver without any
one except the authenticated receiver knowing the existence of this
information. In this paper, a specific image based steganography technique for
communicating information more securely between two locations is proposed. The
author incorporated the idea of secret key and password security features for
authentication at both ends in order to achieve high level of security. As a
further improvement of security level, the information has been permuted,
encoded and then finally embedded on an image to form the stego image. In
addition segmented objects extraction and reassembly of the stego image through
normalized cut method has been carried out at the sender side and receiver side
respectively in order to prevent distortion of the Stego image during
transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2155</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2155</id><created>2010-04-13</created><authors><author><keyname>Malik</keyname><forenames>Ahmad Kamran</forenames></author><author><keyname>Qadir</keyname><forenames>Muhammad Abdul</forenames></author><author><keyname>Iftikhar</keyname><forenames>Nadeem</forenames></author><author><keyname>Usman</keyname><forenames>Muhammad</forenames></author></authors><title>Constraint-based Query Distribution Framework for an Integrated Global
  Schema</title><categories>cs.DB cs.DC cs.IR</categories><comments>The Proceedings of the 13th INMIC 2009), Dec. 14-15, 2009, Islamabad,
  Pakistan. Pages 1 - 6 Print ISBN: 978-1-4244-4872-2 INSPEC Accession Number:
  11072575 Date of Current Version : 15 January 2010</comments><acm-class>H.2.4; H.2.5; C.2.4; H.3.3</acm-class><doi>10.1109/INMIC.2009.5383089</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed heterogeneous data sources need to be queried uniformly using
global schema. Query on global schema is reformulated so that it can be
executed on local data sources. Constraints in global schema and mappings are
used for source selection, query optimization,and querying partitioned and
replicated data sources. The provided system is all XML-based which poses query
in XML form, transforms, and integrates local results in an XML document.
Contributions include the use of constraints in our existing global schema
which help in source selection and query optimization, and a global query
distribution framework for querying distributed heterogeneous data sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2159</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2159</id><created>2010-04-13</created><updated>2010-08-01</updated><authors><author><keyname>Tzameret</keyname><forenames>Iddo</forenames></author></authors><title>Algebraic Proofs over Noncommutative Formulas</title><categories>cs.CC</categories><comments>20 pages, full version. Changes: Changed definition of ordered
  formulas (to, essentially, &quot;syntactic&quot; ordered formulas); added some missing
  proofs of certain claims, and missing definitions of known concepts; improved
  introduction; other local/cosmetic changes</comments><msc-class>68Q17, 68Q15, 03F20, 03D15</msc-class><acm-class>F.1.3; F.2.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study possible formulations of algebraic propositional proof systems
operating with noncommutative formulas. We observe that a simple formulation
gives rise to systems at least as strong as Frege---yielding a semantic way to
define a Cook-Reckhow (i.e., polynomially verifiable) algebraic analog of Frege
proofs, different from that given in [BIKPRS96,GH03]. We then turn to an
apparently weaker system, namely, polynomial calculus (PC) where polynomials
are written as ordered formulas (PC over ordered formulas, for short): an
ordered polynomial is a noncommutative polynomial in which the order of
products in every monomial respects a fixed linear order on variables; an
algebraic formula is ordered if the polynomial computed by each of its
subformulas is ordered. We show that PC over ordered formulas is strictly
stronger than resolution, polynomial calculus and polynomial calculus with
resolution (PCR) and admits polynomial-size refutations for the pigeonhole
principle and the Tseitin's formulas. We conclude by proposing an approach for
establishing lower bounds on PC over ordered formulas proofs, and related
systems, based on properties of lower bounds on noncommutative formulas.
  The motivation behind this work is developing techniques incorporating rank
arguments (similar to those used in algebraic circuit complexity) for
establishing lower bounds on propositional proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2178</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2178</id><created>2010-04-13</created><authors><author><keyname>Morselli</keyname><forenames>Xavier</forenames><affiliation>LSR - IMAG</affiliation></author><author><keyname>Potet</keyname><forenames>Marie-Laure</forenames><affiliation>LSR - IMAG</affiliation></author><author><keyname>Stouls</keyname><forenames>Nicolas</forenames><affiliation>LSR - IMAG</affiliation></author></authors><title>G\'en\'eSyst : G\'en\'eration d'un syst\`eme de transitions
  \'etiquet\'ees \`a partir d'une sp\'ecification B \'ev\'enementiel</title><categories>cs.SE</categories><proxy>ccsd</proxy><journal-ref>Approches Formelles dans l'Assistance au D\'eveloppement de
  Logiciels (AFADL'04), besan\c{c}on : France (2004)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most expensive source of errors and the more difficult to detect in a
formal development is the error during specification. Hence, the first step in
a formal development usually consists in exhibiting the set of all behaviors of
the specification, for instance with an automaton. Starting from this
observation, many researches are about the generation of a B machine from a
behavioral specification, such as UML. However, no backward verification are
done. This is why, we propose the GeneSyst tool, which aims at generating an
automaton describing at least all behaviors of the specification. The
refinement step is considered and appears as sub-automatons in the produced
SLTS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2189</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2189</id><created>2010-04-09</created><authors><author><keyname>Ahadpour</keyname><forenames>S.</forenames></author><author><keyname>Sadra</keyname><forenames>Y.</forenames></author></authors><title>Randomness criteria in binary visibility graph perspective</title><categories>nlin.CD cs.DS physics.data-an</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By means of a binary visibility graph, we present a novel method to study
random binary sequences. The behavior of the some topological properties of the
binary visibility graph, such as the degree distribution, the clustering
coefficient, and the mean path length have been investigated. Several examples
are then provided to show that the numerical simulations confirm the accuracy
of the theorems for finite random binary sequences. Finally, in this paper we
propose, for the first time, three topological properties of the binary
visibility graph as a randomness criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2210</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2210</id><created>2010-04-13</created><authors><author><keyname>Huang</keyname><forenames>Xiaofei</forenames></author></authors><title>Equilibrium Point in Quantum Physics and its Inspiration to Game Theory</title><categories>cs.GT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of atoms and molecule found in nature are capable of evolving towards
and staying at their ground states, the lowest energy states. This paper offers
a global optimization approach to understand the ground state as the
equilibrium point of an $n$-player game under cooperation. With the same
approach, Nash equilibrium can be viewed as the equilibrium point under
competition. The former can offer higher payoffs and stability of game playing
than the later. It is truly an inspiration from nature for us to build
societies for quality and stability under cooperation rather than competition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2222</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2222</id><created>2010-04-13</created><authors><author><keyname>Gwizdka</keyname><forenames>Jacek</forenames></author></authors><title>What a Difference a Tag Cloud Makes: Effects of Tasks and Cognitive
  Abilities on Search Results Interface Use</title><categories>cs.HC cs.IR</categories><journal-ref>Information Research 14(4), 2009, paper 414.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this study is to expand our understanding of the relationships
between selected tasks, cognitive abilities and search result interfaces. The
underlying objective is to understand how to select search results presentation
for tasks and user contexts. Twenty three participants conducted four search
tasks of two types and used two interfaces (List and Overview) to refine and
examine search results. Clickthrough data were recorded. This controlled study
employed a mixed model design with two within-subject factors (task and
interface) and two between-subject factors (two cognitive abilities: memory
span and verbal closure). Quantitative analyses were carried out by means of
the statistical package SPSS. Specifically, multivariate analysis of variance
with repeated measures and non-parametric tests were performed on the collected
data. The overview of search results appeared to have benefited searchers in
several ways. It made them faster; it facilitated formulation of more effective
queries and helped to assess search results. Searchers with higher cognitive
abilities were faster in the Overview interface and in less demanding
situations (on simple tasks), while at the same time they issued about the same
number of queries as lower-ability searchers. In more demanding situations (on
complex tasks and in the List interface), the higher ability searchers expended
more search effort, although they were not significantly slower than the lower
ability people in these situations. The higher search effort, however, did not
result in a measurable improvement of task outcomes for high-ability searchers.
These findings have implications for the design of search interfaces. They
suggest benefits of providing result overviews. They also suggest the
importance of considering cognitive abilities in the design of search results'
presentation and interaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2226</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2226</id><created>2010-04-13</created><authors><author><keyname>Choi</keyname><forenames>Vicky</forenames></author></authors><title>Adiabatic Quantum Algorithms for the NP-Complete Maximum-Weight
  Independent Set, Exact Cover and 3SAT Problems</title><categories>quant-ph cs.CC</categories><comments>20 pages, 7 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem Hamiltonian of the adiabatic quantum algorithm for the
maximum-weight independent set problem (MIS) that is based on the reduction to
the Ising problem (as described in [Choi08]) has flexible parameters. We show
that by choosing the parameters appropriately in the problem Hamiltonian
(without changing the problem to be solved) for MIS on CK graphs, we can
prevent the first order quantum phase transition and significantly change the
minimum spectral gap. We raise the basic question about what the appropriate
formulation of adiabatic running time should be. We also describe adiabatic
quantum algorithms for Exact Cover and 3SAT in which the problem Hamiltonians
are based on the reduction to MIS. We point out that the argument in Altshuler
et al.(arXiv:0908.2782 [quant-ph]) that their adiabatic quantum algorithm
failed with high probability for randomly generated instances of Exact Cover
does not carry over to this new algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2228</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2228</id><created>2010-04-13</created><authors><author><keyname>Hofmann</keyname><forenames>Dirk</forenames></author><author><keyname>Waszkiewicz</keyname><forenames>Pawel</forenames></author></authors><title>Approximation in quantale-enriched categories</title><categories>math.CT cs.LO math.GN</categories><comments>17 pages</comments><msc-class>06B35, 06D10, 06F07, 18B35, 18D20, 68Q55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work is a fundamental study of the notion of approximation in
V-categories and in (U,V)-categories, for a quantale V and the ultrafilter
monad U. We introduce auxiliary, approximating and Scott-continuous
distributors, the way-below distributor, and continuity of V- and
(U,V)-categories. We fully characterize continuous V-categories (resp.
(U,V)-categories) among all cocomplete V-categories (resp. (U,V)-categories) in
the same ways as continuous domains are characterized among all dcpos. By
varying the choice of the quantale V and the notion of ideals, and by further
allowing the ultrafilter monad to act on the quantale, we obtain a flexible
theory of continuity that applies to partial orders and to metric and
topological spaces. We demonstrate on examples that our theory unifies some
major approaches to quantitative domain theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2242</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2242</id><created>2010-04-13</created><updated>2011-01-26</updated><authors><author><keyname>Daskin</keyname><forenames>Anmer</forenames></author><author><keyname>Kais</keyname><forenames>Sabre</forenames></author></authors><title>Group Leaders Optimization Algorithm</title><categories>cs.NE math.OC</categories><journal-ref>Molecular Physics, Volume 109, Issue 5 March 2011 , pages 761 -
  772</journal-ref><doi>10.1080/00268976.2011.552444</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new global optimization algorithm in which the influence of the
leaders in social groups is used as an inspiration for the evolutionary
technique which is designed into a group architecture. To demonstrate the
efficiency of the method, a standard suite of single and multidimensional
optimization functions along with the energies and the geometric structures of
Lennard-Jones clusters are given as well as the application of the algorithm on
quantum circuit design problems. We show that as an improvement over previous
methods, the algorithm scales as N^2.5 for the Lennard-Jones clusters of
N-particles. In addition, an efficient circuit design is shown for two qubit
Grover search algorithm which is a quantum algorithm providing quadratic
speed-up over the classical counterpart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2280</identifier>
 <datestamp>2010-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2280</id><created>2010-04-13</created><updated>2010-09-23</updated><authors><author><keyname>Burger</keyname><forenames>John Robert</forenames></author></authors><title>XOR at a Single Vertex -- Artificial Dendrites</title><categories>cs.NE q-bio.NC</categories><comments>Edited for clarity; added Kandel reference</comments><acm-class>B.6.1; C.1.3; I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New to neuroscience with implications for AI, the exclusive OR, or any other
Boolean gate may be biologically accomplished within a single region where
active dendrites merge. This is demonstrated below using dynamic circuit
analysis. Medical knowledge aside, this observation points to the possibility
of specially coated conductors to accomplish artificial dendrites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2285</identifier>
 <datestamp>2010-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2285</id><created>2010-04-13</created><updated>2010-09-13</updated><authors><author><keyname>Johnson</keyname><forenames>Jason K.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>A Majorization-Minimization Approach to Design of Power Transmission
  Networks</title><categories>math.OC cs.CE</categories><comments>8 pages, 3 figures. To appear in Proc. 49th IEEE Conference on
  Decision and Control (CDC '10)</comments><report-no>LANL LA-UR 10-02039</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an optimization approach to design cost-effective electrical power
transmission networks. That is, we aim to select both the network structure and
the line conductances (line sizes) so as to optimize the trade-off between
network efficiency (low power dissipation within the transmission network) and
the cost to build the network. We begin with a convex optimization method based
on the paper ``Minimizing Effective Resistance of a Graph'' [Ghosh, Boyd \&amp;
Saberi]. We show that this (DC) resistive network method can be adapted to the
context of AC power flow. However, that does not address the combinatorial
aspect of selecting network structure. We approach this problem as selecting a
subgraph within an over-complete network, posed as minimizing the (convex)
network power dissipation plus a non-convex cost on line conductances that
encourages sparse networks where many line conductances are set to zero. We
develop a heuristic approach to solve this non-convex optimization problem
using: (1) a continuation method to interpolate from the smooth, convex problem
to the (non-smooth, non-convex) combinatorial problem, (2) the
majorization-minimization algorithm to perform the necessary intermediate
smooth but non-convex optimization steps. Ultimately, this involves solving a
sequence of convex optimization problems in which we iteratively reweight a
linear cost on line conductances to fit the actual non-convex cost. Several
examples are presented which suggest that the overall method is a good
heuristic for network design. We also consider how to obtain sparse networks
that are still robust against failures of lines and/or generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2291</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2291</id><created>2010-04-13</created><updated>2010-08-27</updated><authors><author><keyname>Goel</keyname><forenames>Ashish</forenames></author><author><keyname>Post</keyname><forenames>Ian</forenames></author></authors><title>One Tree Suffices: A Simultaneous O(1)-Approximation for Single-Sink
  Buy-at-Bulk</title><categories>cs.DS cs.DM</categories><comments>16 pages. To appear in FOCS 2010. Version 2 incorporates reviewer
  feedback and has updated references. The approximation ratio in Theorem 4.4
  is slightly improved, and Corollary 3.3 and Theorem 4.5 are new</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the single-sink buy-at-bulk problem with an unknown cost function.
We wish to route flow from a set of demand nodes to a root node, where the cost
of routing x total flow along an edge is proportional to f(x) for some concave,
non-decreasing function f satisfying f(0)=0. We present a simple, fast,
combinatorial algorithm that takes a set of demands and constructs a single
tree T such that for all f the cost f(T) is a 47.45-approximation of the
optimal cost for that f. This is within a factor of 2.33 of the best
approximation ratio currently achievable when the tree can be optimized for a
specific function. Trees achieving simultaneous O(1)-approximations for all
concave functions were previously not known to exist regardless of computation
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2299</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2299</id><created>2010-04-13</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author><author><keyname>Kellett</keyname><forenames>Christopher M.</forenames></author></authors><title>An Optimal Coding Strategy for the Binary Multi-Way Relay Channel</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Communications Letters, Vol. 14, No. 4, pp. 330-332, Apr.
  2010</journal-ref><doi>10.1109/LCOMM.2010.04.092427</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive the capacity of the binary multi-way relay channel, in which
multiple users exchange messages at a common rate through a relay. The capacity
is achieved using a novel functional-decode-forward coding strategy. In the
functional-decode-forward coding strategy, the relay decodes functions of the
users' messages without needing to decode individual messages. The functions to
be decoded by the relay are defined such that when the relay broadcasts the
functions back to the users, every user is able to decode the messages of all
other users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2300</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2300</id><created>2010-04-13</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Kellett</keyname><forenames>Christopher M.</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author></authors><title>Capacity Theorems for the AWGN Multi-Way Relay Channel</title><categories>cs.IT math.IT</categories><comments>accepted and to be presented at ISIT 2010</comments><journal-ref>Proceedings of the 2010 IEEE International Sysmposium on
  Information Theory (ISIT 2010), Austin, USA, pp. 664-668, June 13-18, 2010</journal-ref><doi>10.1109/ISIT.2010.5513576</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The L-user additive white Gaussian noise multi-way relay channel is
considered, where multiple users exchange information through a single relay at
a common rate. Existing coding strategies, i.e., complete-decode-forward and
compress-forward are shown to be bounded away from the cut-set upper bound at
high signal-to-noise ratios (SNR). It is known that the gap between the
compress-forward rate and the capacity upper bound is a constant at high SNR,
and that between the complete-decode-forward rate and the upper bound increases
with SNR at high SNR. In this paper, a functional-decode-forward coding
strategy is proposed. It is shown that for L &gt;= 3, complete-decode-forward
achieves the capacity when SNR &lt;= 0 dB, and functional-decode-forward achieves
the capacity when SNR &gt;= 0 dB. For L=$, functional-decode-forward achieves the
capacity asymptotically as SNR increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2303</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2303</id><created>2010-04-13</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Johnson</keyname><forenames>Sarah J.</forenames></author><author><keyname>Kellett</keyname><forenames>Christopher M.</forenames></author></authors><title>The Binary-Symmetric Parallel-Relay Network</title><categories>cs.IT math.IT</categories><comments>accepted and to be presented at ISIT 2010</comments><journal-ref>Proceedings of the 2010 IEEE International Sysmposium on
  Information Theory (ISIT 2010), Austin, USA, pp. 654-658, June 13-18, 2010</journal-ref><doi>10.1109/ISIT.2010.5513571</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present capacity results of the binary-symmetric parallel-relay network,
where there is one source, one destination, and K relays in parallel. We show
that forwarding relays, where the relays merely transmit their received
signals, achieve the capacity in two ways: with coded transmission at the
source and a finite number of relays, or uncoded transmission at the source and
a sufficiently large number of relays. On the other hand, decoding relays,
where the relays decode the source message, re-encode, and forward it to the
destination, achieve the capacity when the number of relays is small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2304</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2304</id><created>2010-04-13</created><authors><author><keyname>Harrington</keyname><forenames>Patrick L.</forenames><suffix>Jr.</suffix></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames><suffix>III</suffix></author></authors><title>Spatio-Temporal Graphical Model Selection</title><categories>stat.ML cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating the topology of spatial interactions in
a discrete state, discrete time spatio-temporal graphical model where the
interactions affect the temporal evolution of each agent in a network. Among
other models, the susceptible, infected, recovered ($SIR$) model for
interaction events fall into this framework. We pose the problem as a structure
learning problem and solve it using an $\ell_1$-penalized likelihood convex
program. We evaluate the solution on a simulated spread of infectious over a
complex network. Our topology estimates outperform those of a standard spatial
Markov random field graphical model selection using $\ell_1$-regularized
logistic regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2308</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2308</id><created>2010-04-13</created><authors><author><keyname>Wolinsky</keyname><forenames>David Isaac</forenames></author><author><keyname>Juste</keyname><forenames>Pierre St.</forenames></author><author><keyname>Boykin</keyname><forenames>P. Oscar</forenames></author><author><keyname>Figueiredo</keyname><forenames>Renato</forenames></author></authors><title>Addressing the P2P Bootstrap Problem for Small Networks</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  P2P overlays provide a framework for building distributed applications
consisting of few to many resources with features including self-configuration,
scalability, and resilience to node failures. Such systems have been
successfully adopted in large-scale services for content delivery networks,
file sharing, and data storage. In small-scale systems, they can be useful to
address privacy concerns and for network applications that lack dedicated
servers. The bootstrap problem, finding an existing peer in the overlay,
remains a challenge to enabling these services for small-scale P2P systems. In
large networks, the solution to the bootstrap problem has been the use of
dedicated services, though creating and maintaining these systems requires
expertise and resources, which constrain their usefulness and make them
unappealing for small-scale systems. This paper surveys and summarizes
requirements that allow peers potentially constrained by network connectivity
to bootstrap small-scale overlays through the use of existing public overlays.
In order to support bootstrapping, a public overlay must support the following
requirements: a method for reflection in order to obtain publicly reachable
addresses, so peers behind network address translators and firewalls can
receive incoming connection requests; communication relaying to share public
addresses and communicate when direct communication is not feasible; and
rendezvous for discovering remote peers, when the overlay lacks stable
membership. After presenting a survey of various public overlays, we identify
two overlays that match the requirements: XMPP overlays, such as Google Talk
and Live Journal Talk, and Brunet, a structured overlay based upon Symphony. We
present qualitative experiences with prototypes that demonstrate the ability to
bootstrap small-scale private structured overlays from public Brunet or XMPP
infrastructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2312</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2312</id><created>2010-04-14</created><authors><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Sun</keyname><forenames>Yuefang</forenames></author></authors><title>Note on the Rainbow $k$-Connectivity of Regular Complete Bipartite
  Graphs</title><categories>math.CO cs.DM</categories><comments>6 pages</comments><msc-class>05C15, 05C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A path in an edge-colored graph $G$, where adjacent edges may be colored the
same, is called a rainbow path if no two edges of the path are colored the
same. For a $\kappa$-connected graph $G$ and an integer $k$ with $1\leq k\leq
\kappa$, the rainbow $k$-connectivity $rc_k(G)$ of $G$ is defined as the
minimum integer $j$ for which there exists a $j$-edge-coloring of $G$ such that
any two distinct vertices of $G$ are connected by $k$ internally disjoint
rainbow paths. Denote by $K_{r,r}$ an $r$-regular complete bipartite graph.
Chartrand et al. in &quot;G. Chartrand, G.L. Johns, K.A. McKeon, P. Zhang, The
rainbow connectivity of a graph, Networks 54(2009), 75-81&quot; left an open
question of determining an integer $g(k)$ for which the rainbow
$k$-connectivity of $K_{r,r}$ is 3 for every integer $r\geq g(k)$. This short
note is to solve this question by showing that $rc_k(K_{r,r})=3$ for every
integer $r\geq 2k\lceil\frac{k}{2}\rceil$, where $k\geq 2$ is a positive
integer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2316</identifier>
 <datestamp>2010-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2316</id><created>2010-04-14</created><updated>2010-10-13</updated><authors><author><keyname>Watanabe</keyname><forenames>Sumio</forenames></author></authors><title>Asymptotic Equivalence of Bayes Cross Validation and Widely Applicable
  Information Criterion in Singular Learning Theory</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In regular statistical models, the leave-one-out cross-validation is
asymptotically equivalent to the Akaike information criterion. However, since
many learning machines are singular statistical models, the asymptotic behavior
of the cross-validation remains unknown. In previous studies, we established
the singular learning theory and proposed a widely applicable information
criterion, the expectation value of which is asymptotically equal to the
average Bayes generalization loss. In the present paper, we theoretically
compare the Bayes cross-validation loss and the widely applicable information
criterion and prove two theorems. First, the Bayes cross-validation loss is
asymptotically equivalent to the widely applicable information criterion as a
random variable. Therefore, model selection and hyperparameter optimization
using these two values are asymptotically equivalent. Second, the sum of the
Bayes generalization error and the Bayes cross-validation error is
asymptotically equal to $2\lambda/n$, where $\lambda$ is the real log canonical
threshold and $n$ is the number of training samples. Therefore the relation
between the cross-validation error and the generalization error is determined
by the algebraic geometrical structure of a learning machine. We also clarify
that the deviance information criteria are different from the Bayes
cross-validation and the widely applicable information criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2322</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2322</id><created>2010-04-14</created><authors><author><keyname>Wu</keyname><forenames>Guowei</forenames></author><author><keyname>Lin</keyname><forenames>Chi</forenames></author><author><keyname>Xia</keyname><forenames>Feng</forenames></author><author><keyname>Yao</keyname><forenames>Lin</forenames></author><author><keyname>Zhang</keyname><forenames>He</forenames></author><author><keyname>Liu</keyname><forenames>Bing</forenames></author></authors><title>Dynamical Jumping Real-Time Fault-Tolerant Routing Protocol for Wireless
  Sensor Networks</title><categories>cs.NI cs.DC</categories><comments>22 pages, 9 figures</comments><msc-class>68M10</msc-class><acm-class>C.2.4</acm-class><journal-ref>Sensors, 10(3):2416-2437, 2010</journal-ref><doi>10.3390/s100302416</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In time-critical wireless sensor network (WSN) applications, a high degree of
reliability is commonly required. A dynamical jumping real-time fault-tolerant
routing protocol (DMRF) is proposed in this paper. Each node utilizes the
remaining transmission time of the data packets and the state of the forwarding
candidate node set to dynamically choose the next hop. Once node failure,
network congestion or void region occurs, the transmission mode will switch to
jumping transmission mode, which can reduce the transmission time delay,
guaranteeing the data packets to be sent to the destination node within the
specified time limit. By using feedback mechanism, each node dynamically
adjusts the jumping probabilities to increase the ratio of successful
transmission. Simulation results show that DMRF can not only efficiently reduce
the effects of failure nodes, congestion and void region, but also yield higher
ratio of successful transmission, smaller transmission delay and reduced number
of control packets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2338</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2338</id><created>2010-04-14</created><authors><author><keyname>Lin</keyname><forenames>Chun-Cheng</forenames></author><author><keyname>Yen</keyname><forenames>Hsu-Chun</forenames></author><author><keyname>Poon</keyname><forenames>Sheung-Hung</forenames></author><author><keyname>Fan</keyname><forenames>Jia-Hao</forenames></author></authors><title>Complexity Analysis of Balloon Drawing for Rooted Trees</title><categories>cs.CG cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a balloon drawing of a tree, all the children under the same parent are
placed on the circumference of the circle centered at their parent, and the
radius of the circle centered at each node along any path from the root
reflects the number of descendants associated with the node. Among various
styles of tree drawings reported in the literature, the balloon drawing enjoys
a desirable feature of displaying tree structures in a rather balanced fashion.
For each internal node in a balloon drawing, the ray from the node to each of
its children divides the wedge accommodating the subtree rooted at the child
into two sub-wedges. Depending on whether the two sub-wedge angles are required
to be identical or not, a balloon drawing can further be divided into two
types: even sub-wedge and uneven sub-wedge types. In the most general case, for
any internal node in the tree there are two dimensions of freedom that affect
the quality of a balloon drawing: (1) altering the order in which the children
of the node appear in the drawing, and (2) for the subtree rooted at each child
of the node, flipping the two sub-wedges of the subtree. In this paper, we give
a comprehensive complexity analysis for optimizing balloon drawings of rooted
trees with respect to angular resolution, aspect ratio and standard deviation
of angles under various drawing cases depending on whether the tree is of even
or uneven sub-wedge type and whether (1) and (2) above are allowed. It turns
out that some are NP-complete while others can be solved in polynomial time. We
also derive approximation algorithms for those that are intractable in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2342</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2342</id><created>2010-04-14</created><updated>2011-05-19</updated><authors><author><keyname>Gast</keyname><forenames>Nicolas</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble, EPFL</affiliation></author><author><keyname>Gaujal</keyname><forenames>Bruno</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LIG laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Boudec</keyname><forenames>Jean-Yves Le</forenames><affiliation>EPFL</affiliation></author></authors><title>Mean field for Markov Decision Processes: from Discrete to Continuous
  Optimization</title><categories>cs.AI cs.PF cs.SY math.OC math.PR</categories><proxy>ccsd</proxy><report-no>RR-7239, RR-7239</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the convergence of Markov Decision Processes made of a large number
of objects to optimization problems on ordinary differential equations (ODE).
We show that the optimal reward of such a Markov Decision Process, satisfying a
Bellman equation, converges to the solution of a continuous
Hamilton-Jacobi-Bellman (HJB) equation based on the mean field approximation of
the Markov Decision Process. We give bounds on the difference of the rewards,
and a constructive algorithm for deriving an approximating solution to the
Markov Decision Process from a solution of the HJB equations. We illustrate the
method on three examples pertaining respectively to investment strategies,
population dynamics control and scheduling in queues are developed. They are
used to illustrate and justify the construction of the controlled ODE and to
show the gain obtained by solving a continuous HJB equation rather than a large
discrete Bellman equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2354</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2354</id><created>2010-04-14</created><authors><author><keyname>Pessoles</keyname><forenames>Xavier</forenames><affiliation>ICA</affiliation></author><author><keyname>Landon</keyname><forenames>Yann</forenames><affiliation>ICA</affiliation></author><author><keyname>Rubio</keyname><forenames>Walter</forenames><affiliation>ICA</affiliation></author></authors><title>Kinematic modelling of a 3-axis NC machine tool in linear and circular
  interpolation</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>The International Journal of Advanced Manufacturing Technology 47,
  5-8 (2010) 639-655</journal-ref><doi>10.1007/s00170-009-2236-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machining time is a major performance criterion when it comes to high-speed
machining. CAM software can help in estimating that time for a given strategy.
But in practice, CAM-programmed feed rates are rarely achieved, especially
where complex surface finishing is concerned. This means that machining time
forecasts are often more than one step removed from reality. The reason behind
this is that CAM routines do not take either the dynamic performances of the
machines or their specific machining tolerances into account. The present
article seeks to improve simulation of high-speed NC machine dynamic behaviour
and machining time prediction, offering two models. The first contributes
through enhanced simulation of three-axis paths in linear and circular
interpolation, taking high-speed machine accelerations and jerks into account.
The second model allows transition passages between blocks to be integrated in
the simulation by adding in a polynomial transition path that caters for the
true machining environment tolerances. Models are based on respect for path
monitoring. Experimental validation shows the contribution of polynomial
modelling of the transition passage due to the absence of a leap in
acceleration. Simulation error on the machining time prediction remains below
1%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2364</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2364</id><created>2010-04-14</created><authors><author><keyname>Wang</keyname><forenames>Daoshun</forenames></author><author><keyname>Dong</keyname><forenames>Lin</forenames></author><author><keyname>Li</keyname><forenames>Xiaobo</forenames></author></authors><title>Towards Shift Tolerant Visual Secret Sharing Schemes</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In (k, n) visual secret sharing (VSS) scheme, secret image can be visually
reconstructed when k or more participants printing theirs shares on
transparencies and stack them together. No secret is revealed with fewer than k
shares. The alignment of the transparencies is important to the visual quality
of the reconstructed secret image. In VSS scheme, each pixel of the original
secret image is expanded to m sub-pixels in a share image. If a share image is
printed on paper with the same size as the original secret image, the alignment
or the registration of the sub-pixels, which is only m times smaller than that
in the original secret, could be troublesome. Liu et al. [4] has noticed this
alignment problem and observed that some information of the secret image may
still be revealed even when the shares are not precisely registered in the
horizontal direction. Yang et al. [9] introduced a general approach to
construct a misalignment tolerant (k, n)-VSS scheme using big and small blocks
for the situation where the original secret image has a certain degree of
redundancy in shape accuracy. In this paper, we propose a (2, n)-VSS scheme
that allows a relative shift between the shares in the horizontal direction and
vertical direction. When the shares are perfectly aligned, the contrast of the
reconstructed image is equal to that of traditional VSS shceme. When there is a
shift, average contrast in the reconstructed image is higher than that of the
traditional VSS scheme, and the scheme can still work in the cases where very
little shape redundancy presents in the image. The trade-off is that our method
involves a larger pixel expansion. The basic building block of our scheme is
duplication and concatenation of certain rows or columns of the basic matrices.
This seemingly simple but very powerful construction principle can be easily
used to create more general (k, n)-VSS schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2367</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2367</id><created>2010-04-14</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Jobstmann</keyname><forenames>Barbara</forenames></author><author><keyname>Radhakrishna</keyname><forenames>Arjun</forenames></author></authors><title>GIST: A Solver for Probabilistic Games</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gist is a tool that (a) solves the qualitative analysis problem of turn-based
probabilistic games with {\omega}-regular objectives; and (b) synthesizes
reasonable environment assumptions for synthesis of unrealizable
specifications. Our tool provides the first and efficient implementations of
several reduction-based techniques to solve turn-based probabilistic games, and
uses the analysis of turn-based probabilistic games for synthesizing
environment assumptions for unrealizable specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2372</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2372</id><created>2010-04-14</created><authors><author><keyname>Bex</keyname><forenames>Geert Jan</forenames></author><author><keyname>Gelade</keyname><forenames>Wouter</forenames></author><author><keyname>Neven</keyname><forenames>Frank</forenames></author><author><keyname>Vansummeren</keyname><forenames>Stijn</forenames></author></authors><title>Learning Deterministic Regular Expressions for the Inference of Schemas
  from XML Data</title><categories>cs.DB cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring an appropriate DTD or XML Schema Definition (XSD) for a given
collection of XML documents essentially reduces to learning deterministic
regular expressions from sets of positive example words. Unfortunately, there
is no algorithm capable of learning the complete class of deterministic regular
expressions from positive examples only, as we will show. The regular
expressions occurring in practical DTDs and XSDs, however, are such that every
alphabet symbol occurs only a small number of times. As such, in practice it
suffices to learn the subclass of deterministic regular expressions in which
each alphabet symbol occurs at most k times, for some small k. We refer to such
expressions as k-occurrence regular expressions (k-OREs for short). Motivated
by this observation, we provide a probabilistic algorithm that learns k-OREs
for increasing values of k, and selects the deterministic one that best
describes the sample based on a Minimum Description Length argument. The
effectiveness of the method is empirically validated both on real world and
synthetic data. Furthermore, the method is shown to be conservative over the
simpler classes of expressions considered in previous work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2374</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2374</id><created>2010-04-14</created><authors><author><keyname>Wang</keyname><forenames>Qianxue</forenames></author><author><keyname>Guyeux</keyname><forenames>Christophe</forenames></author><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author></authors><title>A novel pseudo-random number generator based on discrete chaotic
  iterations</title><categories>cs.CR</categories><comments>The First International Conference on Evolving Internet:Internet 2009
  pp.71--76 http://dx.doi.org/10.1109/INTERNET.2009.18</comments><doi>10.1109/INTERNET.2009.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security of information transmitted through the Internet, against passive or
active attacks is an international concern. The use of a chaos-based
pseudo-random bit sequence to make it unrecognizable by an intruder, is a field
of research in full expansion. This mask of useful information by modulation or
encryption is a fundamental part of the TLS Internet exchange protocol. In this
paper, a new method using discrete chaotic iterations to generate pseudo-random
numbers is presented. This pseudo-random number generator has successfully
passed the NIST statistical test suite (NIST SP800-22). Security analysis shows
its good characteristics. The application for secure image transmission through
the Internet is proposed at the end of the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2392</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2392</id><created>2010-04-14</created><authors><author><keyname>Ryan</keyname><forenames>&#xd8;.</forenames></author></authors><title>On the optimal stacking of noisy observations</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing. 10 pages, 5
  figures.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Observations where additive noise is present can for many models be grouped
into a compound observation matrix, adhering to the same type of model. There
are many ways the observations can be stacked, for instance vertically,
horizontally, or quadratically. An estimator for the spectrum of the underlying
model can be formulated for each stacking scenario in the case of Gaussian
noise. We compare these spectrum estimators for the different stacking
scenarios, and show that all kinds of stacking actually decreases the variance
when compared to just taking an average of the observations. We show that,
regardless of the number of observations, the variance of the estimator is
smallest when the compound observation matrix is made as square as possible.
When the number of observations grow, however, it is shown that the difference
between the estimators is marginal: Two stacking scenarios where the number of
columns and rows grow to infinity are shown to have the same variance
asymptotically, even if the asymptotic matrix aspect ratios differ. Only the
cases of vertical and horizontal stackings display different behaviour, giving
a higher variance asymptotically. Models where not all kinds of stackings are
possible are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2393</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2393</id><created>2010-04-14</created><updated>2010-09-16</updated><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Gravin</keyname><forenames>Nick</forenames></author></authors><title>On the Continuous CNN Problem</title><categories>cs.DS</categories><report-no>MR2781393</report-no><journal-ref>Algorithms and computation. Part II. 2010 LNCS 6507, pp. 254-265</journal-ref><doi>10.1007/978-3-642-17514-5_22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the (discrete) CNN problem, online requests appear as points in
$\mathbb{R}^2$. Each request must be served before the next one is revealed. We
have a server that can serve a request simply by aligning either its $x$ or $y$
coordinate with the request. The goal of the online algorithm is to minimize
the total $L_1$ distance traveled by the server to serve all the requests. The
best known competitive ratio for the discrete version is 879 (due to Sitters
and Stougie).
  We study the continuous version, in which, the request can move continuously
in $\mathbb{R}^2$ and the server must continuously serve the request. A simple
adversarial argument shows that the lower bound on the competitive ratio of any
online algorithm for the continuous CNN problem is 3. Our main contribution is
an online algorithm with competitive ratio $3+2 \sqrt{3} \approx 6.464$. Our
analysis is tight. The continuous version generalizes the discrete orthogonal
CNN problem, in which every request must be $x$ or $y$ aligned with the
previous request. Therefore, Our result improves upon the previous best
competitive ratio of 9 (due to Iwama and Yonezawa).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2418</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2418</id><created>2010-04-14</created><authors><author><keyname>Bohman</keyname><forenames>Tom</forenames></author><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author></authors><title>A note on the random greedy triangle-packing algorithm</title><categories>math.CO cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random greedy algorithm for constructing a large partial
Steiner-Triple-System is defined as follows. We begin with a complete graph on
$n$ vertices and proceed to remove the edges of triangles one at a time, where
each triangle removed is chosen uniformly at random from the collection of all
remaining triangles. This stochastic process terminates once it arrives at a
triangle-free graph. In this note we show that with high probability the number
of edges in the final graph is at most $ O\big( n^{7/4}\log^{5/4}n \big) $.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2425</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2425</id><created>2010-04-14</created><authors><author><keyname>Rathi</keyname><forenames>Vishwambhar</forenames></author><author><keyname>Aurell</keyname><forenames>Erik</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Bounds on Thresholds Related to Maximum Satisfiability of Regular Random
  Formulas</title><categories>cs.IT cs.CC cs.DM math.IT</categories><comments>6th International symposium on turbo codes &amp; iterative information
  processing, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the regular balanced model of formula generation in conjunctive
normal form (CNF) introduced by Boufkhad, Dubois, Interian, and Selman. We say
that a formula is $p$-satisfying if there is a truth assignment satisfying
$1-2^{-k}+p 2^{-k}$ fraction of clauses. Using the first moment method we
determine upper bound on the threshold clause density such that there are no
$p$-satisfying assignments with high probability above this upper bound. There
are two aspects in deriving the lower bound using the second moment method. The
first aspect is, given any $p \in (0,1)$ and $k$, evaluate the lower bound on
the threshold. This evaluation is numerical in nature. The second aspect is to
derive the lower bound as a function of $p$ for large enough $k$. We address
the first aspect and evaluate the lower bound on the $p$-satisfying threshold
using the second moment method. We observe that as $k$ increases the lower
bound seems to converge to the asymptotically derived lower bound for uniform
model of formula generation by Achlioptas, Naor, and Peres.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2426</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2426</id><created>2010-04-14</created><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames></author><author><keyname>Maletti</keyname><forenames>Andreas</forenames></author></authors><title>Simulation vs. Equivalence</title><categories>cs.FL</categories><msc-class>68Q45, 68Q70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For several semirings S, two weighted finite automata with multiplicities in
S are equivalent if and only if they can be connected by a chain of
simulations. Such a semiring S is called &quot;proper&quot;. It is known that the Boolean
semiring, the semiring of natural numbers, the ring of integers, all finite
commutative positively ordered semirings and all fields are proper. The
semiring S is Noetherian if every subsemimodule of a finitely generated
S-semimodule is finitely generated. First, it is shown that all Noetherian
semirings and thus all commutative rings and all finite semirings are proper.
Second, the tropical semiring is shown not to be proper. So far there has not
been any example of a semiring that is not proper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2434</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2434</id><created>2010-04-14</created><updated>2012-02-27</updated><authors><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>The Multi-way Relay Channel</title><categories>cs.IT math.IT</categories><comments>Revised version of our submission to the Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiuser communication channel, in which multiple users exchange
information with the help of a relay terminal, termed the multi-way relay
channel (mRC), is introduced. In this model, multiple interfering clusters of
users communicate simultaneously, where the users within the same cluster wish
to exchange messages among themselves. It is assumed that the users cannot
receive each other's signals directly, and hence the relay terminal in this
model is the enabler of communication. In particular, restricted encoders,
which ignore the received channel output and use only the corresponding
messages for generating the channel input, are considered. Achievable rate
regions and an outer bound are characterized for the Gaussian mRC, and their
comparison is presented in terms of exchange rates in a symmetric Gaussian
network scenario. It is shown that the compress-and-forward (CF) protocol
achieves exchange rates within a constant bit offset of the exchange capacity
independent of the power constraints of the terminals in the network. A finite
bit gap between the exchange rates achieved by the CF and the
amplify-and-forward (AF) protocols is also shown. The two special cases of the
mRC, the full data exchange model, in which every user wants to receive
messages of all other users, and the pairwise data exchange model which
consists of multiple two-way relay channels, are investigated in detail. In
particular for the pairwise data exchange model, in addition to the proposed
random coding based achievable schemes, a nested lattice coding based scheme is
also presented and is shown to achieve exchange rates within a constant bit gap
of the exchange capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2436</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2436</id><created>2010-04-13</created><authors><author><keyname>Chutchev</keyname><forenames>Evgeny</forenames></author></authors><title>Some Mathematicians Are Not Turing Machines</title><categories>cs.LO</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A certain mathematician M, considering some hypothesis H, conclusion C and
text P, can arrive at one of the following judgments: (1) P does not convince M
of the fact that since H, it follows that C; (2) P is the proof that since H,
it follows that C (judgment of the type &quot;Proved&quot;). Is it possible to replace
such a mathematician with an arbitrary Turing machine? The paper provides a
proof that the answer to the question is negative under the two following
conditions: (1) M is faultless, namely his judgment &quot;Proved&quot; always implies
that since H, it actually follows that C; (2) M recognizes a certain P' as the
correct proof of the fact that for certain H' and C', if H', then C' (where P',
H', and C' are stated in the paper).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2447</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2447</id><created>2010-04-14</created><authors><author><keyname>Faden</keyname><forenames>J.</forenames></author><author><keyname>Weigel</keyname><forenames>R. S.</forenames></author><author><keyname>Merka</keyname><forenames>J.</forenames></author><author><keyname>Friedel</keyname><forenames>R. H. W.</forenames></author></authors><title>Autoplot: A browser for scientific data on the web</title><categories>cs.GR physics.data-an physics.space-ph</categories><comments>16 pages</comments><doi>10.1007/s12145-010-0049-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autoplot is software developed for the Virtual Observatories in Heliophysics
to provide intelligent and automated plotting capabilities for many typical
data products that are stored in a variety of file formats or databases.
Autoplot has proven to be a flexible tool for exploring, accessing, and viewing
data resources as typically found on the web, usually in the form of a
directory containing data files with multiple parameters contained in each
file. Data from a data source is abstracted into a common internal data model
called QDataSet. Autoplot is built from individually useful components, and can
be extended and reused to create specialized data handling and analysis
applications and is being used in a variety of science visualization and
analysis applications. Although originally developed for viewing
heliophysics-related time series and spectrograms, its flexible and generic
data representation model makes it potentially useful for the Earth sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2484</identifier>
 <datestamp>2014-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2484</id><created>2010-04-14</created><updated>2014-02-04</updated><authors><author><keyname>Liu</keyname><forenames>An</forenames><affiliation>Eugene</affiliation></author><author><keyname>Youjian</keyname><affiliation>Eugene</affiliation></author><author><keyname>Liu</keyname></author><author><keyname>Xiang</keyname><forenames>Haige</forenames></author><author><keyname>Luo</keyname><forenames>Wu</forenames></author></authors><title>Duality, Polite Water-filling, and Optimization for MIMO B-MAC
  Interference Networks and iTree Networks</title><categories>cs.IT math.IT</categories><comments>63 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives the long sought network version of water-filling named as
polite water-filling. Unlike in single-user MIMO channels, where no one uses
general purpose optimization algorithms in place of the simple and optimal
water-filling for transmitter optimization, the traditional water-filling is
generally far from optimal in networks as simple as MIMO multiaccess channels
(MAC) and broadcast channels (BC), where steepest ascent algorithms have been
used except for the sum-rate optimization. This is changed by the polite
water-filling that is optimal for all boundary points of the capacity regions
of MAC and BC and for all boundary points of a set of achievable regions of a
more general class of MIMO B-MAC interference networks, which is a combination
of multiple interfering broadcast channels, from the transmitter point of view,
and multiaccess channels, from the receiver point of view, including MAC, BC,
interference channels, X networks, and most practical wireless networks as
special case. It is polite because it strikes an optimal balance between
reducing interference to others and maximizing a link's own rate. Employing it,
the related optimizations can be vastly simplified by taking advantage of the
structure of the problems. Deeply connected to the polite water-filling, the
rate duality is extended to the forward and reverse links of the B-MAC
networks. As a demonstration, weighted sum-rate maximization algorithms based
on polite water-filling and duality with superior performance and low
complexity are designed for B-MAC networks and are analyzed for Interference
Tree (iTree) Networks, a sub-class of the B-MAC networks that possesses
promising properties for further information theoretic study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2515</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2515</id><created>2010-04-14</created><authors><author><keyname>Williams</keyname><forenames>Paul L.</forenames></author><author><keyname>Beer</keyname><forenames>Randall D.</forenames></author></authors><title>Nonnegative Decomposition of Multivariate Information</title><categories>cs.IT math-ph math.IT math.MP physics.bio-ph physics.data-an q-bio.NC q-bio.QM</categories><comments>14 pages, 9 figures</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Of the various attempts to generalize information theory to multiple
variables, the most widely utilized, interaction information, suffers from the
problem that it is sometimes negative. Here we reconsider from first principles
the general structure of the information that a set of sources provides about a
given variable. We begin with a new definition of redundancy as the minimum
information that any source provides about each possible outcome of the
variable, averaged over all possible outcomes. We then show how this measure of
redundancy induces a lattice over sets of sources that clarifies the general
structure of multivariate information. Finally, we use this redundancy lattice
to propose a definition of partial information atoms that exhaustively
decompose the Shannon information in a multivariate system in terms of the
redundancy between synergies of subsets of the sources. Unlike interaction
information, the atoms of our partial information decomposition are never
negative and always support a clear interpretation as informational quantities.
Our analysis also demonstrates how the negativity of interaction information
can be explained by its confounding of redundancy and synergy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2519</identifier>
 <datestamp>2011-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2519</id><created>2010-04-14</created><updated>2011-09-22</updated><authors><author><keyname>Levy</keyname><forenames>Bernard C.</forenames></author><author><keyname>Nikoukhah</keyname><forenames>Ramine</forenames></author></authors><title>Robust State Space Filtering under Incremental Model Perturbations
  Subject to a Relative Entropy Tolerance</title><categories>math.OC cs.IT cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers robust filtering for a nominal Gaussian state-space
model, when a relative entropy tolerance is applied to each time increment of a
dynamical model. The problem is formulated as a dynamic minimax game where the
maximizer adopts a myopic strategy. This game is shown to admit a saddle point
whose structure is characterized by applying and extending results presented
earlier in [1] for static least-squares estimation. The resulting minimax
filter takes the form of a risk-sensitive filter with a time varying risk
sensitivity parameter, which depends on the tolerance bound applied to the
model dynamics and observations at the corresponding time index. The
least-favorable model is constructed and used to evaluate the performance of
alternative filters. Simulations comparing the proposed risk-sensitive filter
to a standard Kalman filter show a significant performance advantage when
applied to the least-favorable model, and only a small performance loss for the
nominal model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2522</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2522</id><created>2010-04-14</created><updated>2010-06-19</updated><authors><author><keyname>Malladi</keyname><forenames>Sreekanth</forenames></author></authors><title>How to prevent type-flaw and multi-protocol attacks on cryptographic
  protocols under Exclusive-OR</title><categories>cs.CR cs.LO</categories><comments>37 pages plus 14 pages in the Appendix</comments><report-no>DSU-BIS-IA-Mall2010A</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Type-flaw attacks and multi-protocol attacks on security protocols have been
frequently reported in the literature. Heather et al. and Guttman et al. have
proven that these could be prevented by tagging encrypted components with
distinct constants in a standard protocol model with free message algebra and
perfect encryption. However, most &quot;real-world&quot; protocols such as SSL 3.0 are
designed with the Exclusive-OR (XOR) operator that possesses algebraic
properties, breaking the free algebra assumption. These algebraic properties
induce equational theories that need to be considered when analyzing protocols
that use the operator. This is the problem we consider in this paper: We prove
that, under certain assumptions, tagging encrypted components still prevents
type-flaw and multi-protocol attacks even in the presence of the XOR operator
and its algebraic properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2523</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2523</id><created>2010-04-14</created><authors><author><keyname>Ko</keyname><forenames>Youngwook</forenames></author><author><keyname>~Vorobyov</keyname><forenames>Sergiy~A.</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author></authors><title>How Much Multiuser Diversity is Required for Energy Limited Multiuser
  Systems?</title><categories>cs.IT math.IT</categories><comments>28 pages, 9 figures, submitted to IEEE Trans. Signal Processing in
  Oct. 2009</comments><journal-ref>Y. Ko, S.A. Vorobyov, and M. Ardakani, &quot;How much multiuser
  diversity is required for energy limited multiuser systems?&quot; IEEE Trans.
  Signal Processing, vol. 58, no. 8, pp. 4367-4378, Aug. 2010</journal-ref><doi>10.1109/TSP.2010.2049108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiuser diversity (MUDiv) is one of the central concepts in multiuser (MU)
systems. In particular, MUDiv allows for scheduling among users in order to
eliminate the negative effects of unfavorable channel fading conditions of some
users on the system performance. Scheduling, however, consumes energy (e.g.,
for making users' channel state information available to the scheduler). This
extra usage of energy, which could potentially be used for data transmission,
can be very wasteful, especially if the number of users is large. In this
paper, we answer the question of how much MUDiv is required for energy limited
MU systems. Focusing on uplink MU wireless systems, we develop MU scheduling
algorithms which aim at maximizing the MUDiv gain. Toward this end, we
introduce a new realistic energy model which accounts for scheduling energy and
describes the distribution of the total energy between scheduling and data
transmission stages. Using the fact that such energy distribution can be
controlled by varying the number of active users, we optimize this number by
either (i) minimizing the overall system bit error rate (BER) for a fixed total
energy of all users in the system or (ii) minimizing the total energy of all
users for fixed BER requirements. We find that for a fixed number of available
users, the achievable MUDiv gain can be improved by activating only a subset of
users. Using asymptotic analysis and numerical simulations, we show that our
approach benefits from MUDiv gains higher than that achievable by generic
greedy access algorithm, which is the optimal scheduling method for energy
unlimited systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2526</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2526</id><created>2010-04-14</created><authors><author><keyname>Hunter</keyname><forenames>A. H.</forenames></author><author><keyname>Pippenger</keyname><forenames>Nicholas</forenames></author></authors><title>Local versus Global Search in Channel Graphs</title><categories>cs.CC math.PR</categories><comments>i+13 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous studies of search in channel graphs has assumed that the search is
global; that is, that the status of any link can be probed by the search
algorithm at any time. We consider for the first time local search, for which
only links to which an idle path from the source has already been established
may be probed. We show that some well known channel graphs may require
exponentially more probes, on the average, when search must be local than when
it may be global.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2542</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2542</id><created>2010-04-14</created><authors><author><keyname>Luo</keyname><forenames>Zhifeng</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Wong</keyname><forenames>Albert Kai-sun</forenames></author><author><keyname>Qiu</keyname><forenames>Shuisheng</forenames></author></authors><title>Relay-Assisted Partial Packet Recovery with IDMA Method in CDMA Wireless
  Network</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic Repeat Request (ARQ) is an effective technique for reliable
transmission of packets in wireless networks. In ARQ, however, only a few
erroneous bits in a packet will cause the entire packet to be discarded at the
receiver. In this case, it's wasteful to retransmit the correct bit in the
received packet. The partial packet recovery only retransmits the unreliable
decoded bits in order to increase the throughput of network. In addition, the
cooperative transmission based on Interleave-division multiple-access (IDMA)
can obtain diversity gains with multiple relays with different locations for
multiple sources simultaneously. By exploring the diversity from the channel
between relay and destination, we propose a relay-assisted partial packet
recovery in CDMA wireless network to improve the performance of throughput. In
the proposed scheme, asynchronous IDMA iterative chip-by-chip multiuser
detection is utilized as a method of multiple partial recovery, which can be a
complementarity in a current CDMA network. The confidence values' concept is
applied to detect unreliable decoded bits. According to the result of
unreliable decoded bits' position, we use a recursive algorithm based on cost
evaluation to decide a feedback strategy. Then the feedback request with
minimum cost can be obtained. The simulation results show that the performance
of throughput can be significantly improved with our scheme, compared with
traditional ARQ scheme. The upper bound with our scheme is provided in our
simulation. Moreover, we show how relays' location affects the performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2550</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2550</id><created>2010-04-15</created><authors><author><keyname>Cassez</keyname><forenames>Franck</forenames></author></authors><title>The Complexity of Codiagnosability for Discrete Event and Timed Systems</title><categories>cs.FL</categories><comments>24 pages.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the fault codiagnosis problem for discrete event
systems given by finite automata (FA) and timed systems given by timed automata
(TA). We provide a uniform characterization of codiagnosability for FA and TA
which extends the necessary and sufficient condition that characterizes
diagnosability. We also settle the complexity of the codiagnosability problems
both for FA and TA and show that codiagnosability is PSPACE-complete in both
cases. For FA this improves on the previously known bound (EXPTIME) and for TA
it is a new result. Finally we address the codiagnosis problem for TA under
bounded resources and show it is 2EXPTIME-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2560</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2560</id><created>2010-04-15</created><authors><author><keyname>Lakhtaria</keyname><forenames>Kamaljit I.</forenames></author><author><keyname>Patel</keyname><forenames>Paresh</forenames></author><author><keyname>Gandhi</keyname><forenames>Ankita</forenames></author></authors><title>Enhancing Curriculum Acceptance among Students with E-learning 2.0</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E-learning; enhanced by communicating and interacting is becoming
increasingly accepted and this puts Web 2.0 at the center of the new
educational technologies. E-Learning 2.0 emerges as an innovative method of
online learning for its incorporation of Web 2.0 tools. For any academic study,
the curriculum provides overview of intact learning area. The Curriculum
provides overview to content of the Subject. Many institutions place student
interaction as a priority of their online curriculum design. It is proved that
interaction has a great effect on the students' involvement in learning and
acceptance of Curriculum. Students are accepting curriculum that is designed by
teacher; whereas E-learning 2.0 enabled Curriculum management system allows
student to involve in learning activities. It works as a stimulus and increases
their dedication to the Curriculum. While Institute adapts E-Learning 2.0 as
Learning Management System, it also provides Social Networking services and
provides direct and transparent interaction between students and teachers. This
view of the e-Learning 2.0 shifts its focus from LMS to the students, equipping
them, with the means to become ever more autonomous, accepting them to make use
of these means in solving problems on their own initiative. Curriculum usage
will empower student involvement and enhancing E-learning 2.0 spreading. This
paper, analyzing implementation E-learning 2.0 for Curriculum management and
discusses Opportunities &amp; Challenges for Curriculum over Web 2.0.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2565</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2565</id><created>2010-04-15</created><updated>2010-04-16</updated><authors><author><keyname>Chen</keyname><forenames>Ning</forenames></author><author><keyname>Deng</keyname><forenames>Xiaotie</forenames></author><author><keyname>Ghosh</keyname><forenames>Arpita</forenames></author></authors><title>Competitive Equilibria in Matching Markets with Budgets</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study competitive equilibria in the classic Shapley-Shubik assignment
model with indivisible goods and unit-demand buyers, with budget constraints:
buyers can specify a maximum price they are willing to pay for each item,
beyond which they cannot afford the item. This single discontinuity introduced
by the budget constraint fundamentally changes the properties of equilibria: in
the assignment model without budget constraints, a competitive equilibrium
always exists, and corresponds exactly to a stable matching. With budgets, a
competitive equilibrium need not always exist. In addition, there are now two
distinct notions of stability, depending on whether both or only one of the
buyer and seller can strictly benefit in a blocking pair, that no longer
coincide due to the budget-induced discontinuity. We define weak and strong
stability for the assignment model with transferable utilities, and show that
competitive equilibria correspond exactly to strongly stable matchings.
  We consider the algorithmic question of efficiently computing competitive
equilibria in an extension of the assignment model with budgets, where each
buyer specifies his preferences over items using utility functions $u_{ij}$,
where $u_{ij}(p_j)$ is the utility of buyer $i$ for item $j$ when its price is
$p_j$. Our main result is a strongly polynomial time algorithm that decides
whether or not a competitive equilibrium exists and if yes, computes a minimum
one, for a general class of utility functions $u_{ij}$. This class of utility
functions includes the standard quasi-linear utility model with a budget
constraint, and in addition, allows modeling marketplaces where, for example,
buyers only have a preference ranking amongst items subject to a maximum
payment limit for each item, or where buyers want to optimize return on
investment (ROI) instead of a quasi-linear utility and only know items'
relative values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2593</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2593</id><created>2010-04-15</created><updated>2012-04-30</updated><authors><author><keyname>Marichal</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Mathonet</keyname><forenames>Pierre</forenames></author></authors><title>Symmetric approximations of pseudo-Boolean functions with applications
  to influence indexes</title><categories>math.OC cs.DM math.ST stat.TH</categories><msc-class>41A10, 93E24 (Primary) 62G30, 90B25, 91A12 (Secondary)</msc-class><journal-ref>Applied Mathematics Letters 25 (8) (2012) 1121-1126</journal-ref><doi>10.1016/j.aml.2012.02.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an index for measuring the influence of the k-th smallest
variable on a pseudo-Boolean function. This index is defined from a weighted
least squares approximation of the function by linear combinations of order
statistic functions. We give explicit expressions for both the index and the
approximation and discuss some properties of the index. Finally, we show that
this index subsumes the concept of system signature in engineering reliability
and that of cardinality index in decision making.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2616</identifier>
 <datestamp>2013-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2616</id><created>2010-04-15</created><authors><author><keyname>Farsani</keyname><forenames>Reza K.</forenames></author><author><keyname>Akhbari</keyname><forenames>Bahareh</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Achievable Rate Regions for Dirty Tape Channels and &quot;Joint Writing on
  Dirty Paper and Dirty Tape&quot;</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Gaussian Dirty Tape Channel (DTC) Y=X+S+Z, where S is an
additive Gaussian interference known causally to the transmitter. The general
expression [max]\_top(P_U,f(.),X=f(U,S))I(U;Y) is presented for the capacity of
this channel. For linear assignment to f(.), i.e. X=U-{\beta}S, this expression
leads to the compensation strategy proposed previously by Willems to obtain an
achievable rate for the DTC. We show that linear assignment to f(.) is optimal,
under the condition that there exists a real number {\beta}^* such that the
pair (X+{\beta}^* S,U) is independent of interference S. Furthermore, by
applying a time-sharing technique to the achievable rate derived by linear
assignment to f(.), an improved lower bound on the capacity of DTC is obtained.
We also consider the Gaussian multiple access channel with additive
interference, and study two different scenarios for this system. In the first
case, both transmitters know interference causally while in the second, one
transmitter has access to the interference noncausally and the other causally.
Achievable rate regions for these two scenarios are then established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2624</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2624</id><created>2010-04-15</created><authors><author><keyname>Heule</keyname><forenames>Marijn</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Symmetry within Solutions</title><categories>cs.AI</categories><comments>AAAI 2010, Proceedings of Twenty-Fourth AAAI Conference on Artificial
  Intelligence</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the concept of an internal symmetry. This is a symmety within a
solution of a constraint satisfaction problem. We compare this to solution
symmetry, which is a mapping between different solutions of the same problem.
We argue that we may be able to exploit both types of symmetry when finding
solutions. We illustrate the potential of exploiting internal symmetries on two
benchmark domains: Van der Waerden numbers and graceful graphs. By identifying
internal symmetries we are able to extend the state of the art in both cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2626</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2626</id><created>2010-04-15</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Quimper</keyname><forenames>Claude-Guy</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Propagating Conjunctions of AllDifferent Constraints</title><categories>cs.AI</categories><comments>AAAI 2010, Proceedings of the Twenty-Fourth AAAI Conference on
  Artificial Intelligence</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study propagation algorithms for the conjunction of two AllDifferent
constraints. Solutions of an AllDifferent constraint can be seen as perfect
matchings on the variable/value bipartite graph. Therefore, we investigate the
problem of finding simultaneous bipartite matchings. We present an extension of
the famous Hall theorem which characterizes when simultaneous bipartite
matchings exists. Unfortunately, finding such matchings is NP-hard in general.
However, we prove a surprising result that finding a simultaneous matching on a
convex bipartite graph takes just polynomial time. Based on this theoretical
result, we provide the first polynomial time bound consistency algorithm for
the conjunction of two AllDifferent constraints. We identify a pathological
problem on which this propagator is exponentially faster compared to existing
propagators. Our experiments show that this new propagator can offer
significant benefits over existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2628</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2628</id><created>2010-04-15</created><updated>2010-07-08</updated><authors><author><keyname>Cappellari</keyname><forenames>Lorenzo</forenames></author></authors><title>Lossy Source Compression of Non-Uniform Binary Sources Using GQ-LDGM
  Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures; final version to appear in the ITW 2010 Dublin
  Proc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the use of GF(q)-quantized LDGM codes for binary
source coding. By employing quantization, it is possible to obtain binary
codewords with a non-uniform distribution. The obtained statistics is hence
suitable for optimal, direct quantization of non-uniform Bernoulli sources. We
employ a message-passing algorithm combined with a decimation procedure in
order to perform compression. The experimental results based on GF(q)-LDGM
codes with regular degree distributions yield performances quite close to the
theoretical rate-distortion bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2637</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2637</id><created>2010-04-15</created><authors><author><keyname>Altisen</keyname><forenames>Karine</forenames></author><author><keyname>Liu</keyname><forenames>Yanhong</forenames></author><author><keyname>Moy</keyname><forenames>Matthieu</forenames></author></authors><title>Performance Evaluation of Components Using a Granularity-based Interface
  Between Real-Time Calculus and Timed Automata</title><categories>cs.PF</categories><comments>QAPL 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To analyze complex and heterogeneous real-time embedded systems, recent works
have proposed interface techniques between real-time calculus (RTC) and timed
automata (TA), in order to take advantage of the strengths of each technique
for analyzing various components. But the time to analyze a state-based
component modeled by TA may be prohibitively high, due to the state space
explosion problem. In this paper, we propose a framework of granularity-based
interfacing to speed up the analysis of a TA modeled component. First, we
abstract fine models to work with event streams at coarse granularity. We
perform analysis of the component at multiple coarse granularities and then
based on RTC theory, we derive lower and upper bounds on arrival patterns of
the fine output streams using the causality closure algorithm. Our framework
can help to achieve tradeoffs between precision and analysis time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2642</identifier>
 <datestamp>2014-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2642</id><created>2010-04-15</created><updated>2014-04-03</updated><authors><author><keyname>Chapelle</keyname><forenames>Mathieu</forenames></author></authors><title>W[1]-hardness of some domination-like problems parameterized by
  tree-width</title><categories>cs.CC cs.DM</categories><comments>Updated and corrected version; submitted to Theoretical Computer
  Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of generalized domination unifies well-known variants of
domination-like and independence problems, such as Dominating Set, Independent
Set, Perfect Code, etc. A generalized domination (also called
$[\sigma,\rho]$-Dominating Set}) problem consists in finding a subset of
vertices in a graph such that every vertex is satisfied with respect to two
given sets of constraints $\sigma$ and $\rho$. Very few problems are known not
to be FPT when parameterized by tree-width, as usually this restriction allows
one to write efficient algorithms to solve the considered problems. The main
result of this article is a proof that for some (infinitely many) sets $\sigma$
and $\rho$, the problem $\exists[\sigma,\rho]$-Dominating Set} is W[1]-hard
when parameterized by the tree-width of the input graph. This contrasts with
the current knowledge on the parameterized complexity of this problem when
parameterized by tree-width, which had only been studied for finite and
cofinite sets $\sigma$ and $\rho$ and for which it has been shown to be FPT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2648</identifier>
 <datestamp>2013-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2648</id><created>2010-04-15</created><updated>2013-12-03</updated><authors><author><keyname>Tian</keyname><forenames>Chao</forenames><affiliation>Shitz</affiliation></author><author><keyname>Chen</keyname><forenames>Jun</forenames><affiliation>Shitz</affiliation></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Optimality and Approximate Optimality of Source-Channel Separation in
  Networks</title><categories>cs.IT math.IT</categories><comments>revised version with some new figures; significantly shortened; typos
  corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the source-channel separation architecture for lossy source
coding in communication networks. It is shown that the separation approach is
optimal in two general scenarios, and is approximately optimal in a third
scenario. The two scenarios for which separation is optimal complement each
other: the first is when the memoryless sources at source nodes are arbitrarily
correlated, each of which is to be reconstructed at possibly multiple
destinations within certain distortions, but the channels in this network are
synchronized, orthogonal and memoryless point-to-point channels; the second is
when the memoryless sources are mutually independent, each of which is to be
reconstructed only at one destination within a certain distortion, but the
channels are general, including multi-user channels such as multiple access,
broadcast, interference and relay channels, possibly with feedback. The third
scenario, for which we demonstrate approximate optimality of source-channel
separation, generalizes the second scenario by allowing each source to be
reconstructed at multiple destinations with different distortions. For this
case, the loss from optimality by using the separation approach can be
upper-bounded when a &quot;difference&quot; distortion measure is taken, and in the
special case of quadratic distortion measure, this leads to universal constant
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2652</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2652</id><created>2010-04-13</created><updated>2010-06-20</updated><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Khatri</keyname><forenames>Sunil</forenames></author><author><keyname>Peper</keyname><forenames>Ferdinand</forenames></author></authors><title>Instantaneous noise-based logic</title><categories>cs.OH physics.data-an</categories><comments>Accepted for publication in Fluctuation and Noise Letters (December
  2010 issue)</comments><journal-ref>Fluctuation and Noise Letters 9 (2010) pp. 323-330</journal-ref><doi>10.1142/S0219477510000253</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show two universal, Boolean, deterministic logic schemes based on binary
noise timefunctions that can be realized without time-averaging units. The
first scheme is based on a new bipolar random telegraph wave scheme and the
second one makes use of the recent noise-based logic which is conjectured to be
the brain's method of logic operations [Physics Letters A 373 (2009)
2338-2342]. Error propagation and error removal issues are also addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2683</identifier>
 <datestamp>2010-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2683</id><created>2010-04-15</created><authors><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author><author><keyname>Gagnon</keyname><forenames>Francois</forenames></author><author><keyname>Kostina</keyname><forenames>Victoria</forenames></author></authors><title>Error Rates of Capacity-Achieving Codes Are Convex</title><categories>cs.IT math.IT</categories><comments>accepted by ISIT-10</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by a wide-spread use of convex optimization techniques, convexity
properties of bit error rate of the maximum likelihood detector operating in
the AWGN channel are studied for arbitrary constellations and bit mappings,
which also includes coding under maximum-likelihood decoding. Under this
generic setting, the pairwise probability of error and bit error rate are shown
to be convex functions of the SNR and noise power in the high SNR/low noise
regime with explicitly-determined boundary. Any code, including
capacity-achieving ones, whose decision regions include the hardened noise
spheres (from the noise sphere hardening argument in the channel coding
theorem) satisfies this high SNR requirement and thus has convex error rates in
both SNR and noise power. We conjecture that all capacity-achieving codes have
convex error rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2697</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2697</id><created>2010-04-15</created><updated>2011-11-12</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Raman</keyname><forenames>Vishwanath</forenames></author></authors><title>Assume-Guarantee Synthesis for Digital Contract Signing</title><categories>cs.LO cs.CR cs.GT cs.PL</categories><comments>40 pages, 1 figure, 3 tables and 3 algorithms</comments><acm-class>F.1.2; F.3.1; I.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the automatic synthesis of fair non-repudiation protocols, a class
of fair exchange protocols, used for digital contract signing. First, we show
how to specify the objectives of the participating agents and the trusted third
party (TTP) as path formulas in LTL and prove that the satisfaction of these
objectives imply fairness; a property required of fair exchange protocols. We
then show that weak (co-operative) co-synthesis and classical (strictly
competitive) co-synthesis fail, whereas assume-guarantee synthesis (AGS)
succeeds. We demonstrate the success of assume-guarantee synthesis as follows:
(a) any solution of assume-guarantee synthesis is attack-free; no subset of
participants can violate the objectives of the other participants; (b) the
Asokan-Shoup-Waidner (ASW) certified mail protocol that has known
vulnerabilities is not a solution of AGS; (c) the Kremer-Markowitch (KM)
non-repudiation protocol is a solution of AGS; and (d) AGS presents a new and
symmetric fair non-repudiation protocol that is attack-free. To our knowledge
this is the first application of synthesis to fair non-repudiation protocols,
and our results show how synthesis can both automatically discover
vulnerabilities in protocols and generate correct protocols. The solution to
assume-guarantee synthesis can be computed efficiently as the secure
equilibrium solution of three-player graph games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2717</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2717</id><created>2010-04-15</created><authors><author><keyname>Schr&#xf6;der</keyname><forenames>Lutz</forenames></author><author><keyname>Venema</keyname><forenames>Yde</forenames></author></authors><title>Flat coalgebraic fixed point logics</title><categories>cs.LO</categories><acm-class>F.4.1</acm-class><journal-ref>Proc. 21st International Conference on Concurrency Theory, CONCUR
  2010, Vol. 6269 of Lecture Notes in Computer Science, Springer, 2010, pp.
  524-538</journal-ref><doi>10.1007/978-3-642-15375-4_36</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fixed point logics have a wide range of applications in computer science, in
particular in artificial intelligence and concurrency. The most expressive
logics of this type are the mu-calculus and its relatives. However, popular
fixed point logics tend to trade expressivity for simplicity and readability,
and in fact often live within the single variable fragment of the mu-calculus.
The family of such flat fixed point logics includes, e.g., CTL, the
*-nesting-free fragment of PDL, and the logic of common knowledge. Here, we
extend this notion to the generic semantic framework of coalgebraic logic, thus
covering a wide range of logics beyond the standard mu-calculus including,
e.g., flat fragments of the graded mu-calculus and the alternating-time
mu-calculus (such as ATL), as well as probabilistic and monotone fixed point
logics. Our main results are completeness of the Kozen-Park axiomatization and
a timed-out tableaux method that matches EXPTIME upper bounds inherited from
the coalgebraic mu-calculus but avoids using automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2719</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2719</id><created>2010-04-15</created><authors><author><keyname>Klein</keyname><forenames>Martin</forenames></author><author><keyname>Shipman</keyname><forenames>Jeffery</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author></authors><title>Is This a Good Title?</title><categories>cs.IR</categories><comments>10 pages, 8 figures, 4 tables, 37 references, accepted for
  publication at Hypertext 2010 in Toronto, Canada</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Missing web pages, URIs that return the 404 &quot;Page Not Found&quot; error or the
HTTP response code 200 but dereference unexpected content, are ubiquitous in
today's browsing experience. We use Internet search engines to relocate such
missing pages and provide means that help automate the rediscovery process. We
propose querying web pages' titles against search engines. We investigate the
retrieval performance of titles and compare them to lexical signatures which
are derived from the pages' content. Since titles naturally represent the
content of a document they intuitively change over time. We measure the edit
distance between current titles and titles of copies of the same pages obtained
from the Internet Archive and display their evolution. We further investigate
the correlation between title changes and content modifications of a web page
over time. Lastly we provide a predictive model for the quality of any given
web page title in terms of its discovery performance. Our results show that
titles return more than 60% URIs top ranked and further relevant content
returned in the top 10 results. We show that titles decay slowly but are far
more stable than the pages' content. We further distill stop titles than can
help identify insufficiently performing search engine queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2735</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2735</id><created>2010-04-15</created><authors><author><keyname>Erd&#x151;s</keyname><forenames>P&#xe9;ter L.</forenames></author><author><keyname>Soukup</keyname><forenames>Lajos</forenames></author><author><keyname>Stoye</keyname><forenames>Jens</forenames></author></authors><title>Balanced Vertices in Trees and a Simpler Algorithm to Compute the
  Genomic Distance</title><categories>cs.DM math.CO</categories><comments>6 pages, submitted</comments><msc-class>68R10, 05C05, 92D15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a short and transparent solution for the covering cost of
white-grey trees which play a crucial role in the algorithm of Bergeron {\it et
al.}\ to compute the rearrangement distance between two multichromosomal
genomes in linear time ({\it Theor. Comput. Sci.}, 410:5300-5316, 2009). In the
process it introduces a new {\em center} notion for trees, which seems to be
interesting on its own.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2757</identifier>
 <datestamp>2011-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2757</id><created>2010-04-16</created><updated>2011-02-15</updated><authors><author><keyname>Rebelatto</keyname><forenames>Jo&#xe3;o Luiz</forenames></author><author><keyname>Uch&#xf4;a-Filho</keyname><forenames>Bartolomeu F.</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Multi-User Cooperative Diversity through Network Coding Based on
  Classical Coding Theory</title><categories>cs.IT math.IT</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose and analyze a generalized construction of
distributed network codes for a network consisting of $M$ users sending
different information to a common base station through independent block fading
channels. The aim is to increase the diversity order of the system without
reducing its throughput. The proposed scheme, called generalized
dynamic-network codes (GDNC), is a generalization of the dynamic-network codes
(DNC) recently proposed by Xiao and Skoglund. The design of the network codes
that maximize the diversity order is recognized as equivalent to the design of
linear block codes over a nonbinary finite field under the Hamming metric. We
prove that adopting a systematic generator matrix of a maximum distance
separable block code over a sufficiently large finite field as the network
transfer matrix is a sufficient condition for full diversity order under link
failure model. The proposed generalization offers a much better tradeoff
between rate and diversity order compared to the DNC. An outage probability
analysis showing the improved performance is carried out, and computer
simulations results are shown to agree with the analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2764</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2764</id><created>2010-04-16</created><authors><author><keyname>Cassez</keyname><forenames>Franck</forenames></author></authors><title>A Note on Fault Diagnosis Algorithms</title><categories>cs.LO cs.FL</categories><comments>Note: This paper is an extended version of the paper published in the
  proceedings of CDC'09, 48th IEEE Conference on Decision and Control and 28th
  Chinese Control Conference, Shanghai, P.R. China, December 2009.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we review algorithms for checking diagnosability of
discrete-event systems and timed automata. We point out that the diagnosability
problems in both cases reduce to the emptiness problem for (timed) B\&quot;uchi
automata. Moreover, it is known that, checking whether a discrete-event system
is diagnosable, can also be reduced to checking bounded diagnosability. We
establish a similar result for timed automata. We also provide a synthesis of
the complexity results for the different fault diagnosis problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2772</identifier>
 <datestamp>2010-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2772</id><created>2010-04-16</created><updated>2010-05-04</updated><authors><author><keyname>Laarman</keyname><forenames>Alfons</forenames></author><author><keyname>van de Pol</keyname><forenames>Jaco</forenames></author><author><keyname>Weber</keyname><forenames>Michael</forenames></author></authors><title>Boosting Multi-Core Reachability Performance with Shared Hash Tables</title><categories>cs.DC</categories><comments>preliminary report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on data structures for multi-core reachability, which is a
key component in model checking algorithms and other verification methods. A
cornerstone of an efficient solution is the storage of visited states. In
related work, static partitioning of the state space was combined with
thread-local storage and resulted in reasonable speedups, but left open whether
improvements are possible. In this paper, we present a scaling solution for
shared state storage which is based on a lockless hash table implementation.
The solution is specifically designed for the cache architecture of modern
CPUs. Because model checking algorithms impose loose requirements on the hash
table operations, their design can be streamlined substantially compared to
related work on lockless hash tables. Still, an implementation of the hash
table presented here has dozens of sensitive performance parameters (bucket
size, cache line size, data layout, probing sequence, etc.). We analyzed their
impact and compared the resulting speedups with related tools. Our
implementation outperforms two state-of-the-art multi-core model checkers (SPIN
and DiVinE) by a substantial margin, while placing fewer constraints on the
load balancing and search algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2773</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2773</id><created>2010-04-16</created><authors><author><keyname>Shi</keyname><forenames>Long</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>High-Rate and Full-Diversity Space-Time Block Codes with Low Complexity
  Partial Interference Cancellation Group Decoding</title><categories>cs.IT math.IT</categories><comments>25 pages, 3 figures, submitted to IEEE Trans. Commun. on 23 March
  2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a systematic design of space-time block codes
(STBC) which can achieve high rate and full diversity when the partial
interference cancellation (PIC) group decoding is used at receivers. The
proposed codes can be applied to any number of transmit antennas and admit a
low decoding complexity while achieving full diversity. For M transmit
antennas, in each codeword real and imaginary parts of PM complex information
symbols are parsed into P diagonal layers and then encoded, respectively. With
PIC group decoding, it is shown that the decoding complexity can be reduced to
a joint decoding of M/2 real symbols. In particular, for 4 transmit antennas,
the code has real symbol pairwise (i.e., single complex symbol) decoding that
achieves full diversity and the code rate is 4/3. Simulation results
demonstrate that the full diversity is offered by the newly proposed STBC with
the PIC group decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2778</identifier>
 <datestamp>2011-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2778</id><created>2010-04-16</created><updated>2010-10-29</updated><authors><author><keyname>Allamigeon</keyname><forenames>Xavier</forenames></author><author><keyname>Gaubert</keyname><forenames>Stephane</forenames></author><author><keyname>Katz</keyname><forenames>Ricardo D.</forenames></author></authors><title>Tropical polar cones, hypergraph transversals, and mean payoff games</title><categories>math.CO cs.DM math.OC</categories><comments>27 pages, 6 figures, revised version</comments><msc-class>14T05 (Primary) 15A80, 52A01, 16Y60, 06A07 (Secondary)</msc-class><journal-ref>Linear Algebra and its Applications, Volume 435, Issue 7, 1
  October 2011, Pages 1549-1574</journal-ref><doi>10.1016/j.laa.2011.02.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the tropical analogues of several basic questions of convex
duality. In particular, the polar of a tropical polyhedral cone represents the
set of linear inequalities that its elements satisfy. We characterize the
extreme rays of the polar in terms of certain minimal set covers which may be
thought of as weighted generalizations of minimal transversals in hypergraphs.
We also give a tropical analogue of Farkas lemma, which allows one to check
whether a linear inequality is implied by a finite family of linear
inequalities. Here, the certificate is a strategy of a mean payoff game. We
discuss examples, showing that the number of extreme rays of the polar of the
tropical cyclic polyhedral cone is polynomially bounded, and that there is no
unique minimal system of inequalities defining a given tropical polyhedral
cone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2780</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2780</id><created>2010-04-16</created><authors><author><keyname>Balabonski</keyname><forenames>Thibaut</forenames></author><author><keyname>Haucourt</keyname><forenames>Emmanuel</forenames></author></authors><title>A Geometric Approach to the Problem of Unique Decomposition of Processes</title><categories>cs.LO</categories><comments>15 pages</comments><doi>10.1007/978-3-642-15375-4_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a geometric solution to the problem of prime
decomposability of concurrent processes first explored by R. Milner and F.
Moller in [MM93]. Concurrent programs are given a geometric semantics using
cubical areas, for which a unique factorization theorem is proved. An effective
factorization method which is correct and complete with respect to the
geometric semantics is derived from the factorization theorem. This algorithm
is implemented in the static analyzer ALCOOL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2795</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2795</id><created>2010-04-16</created><updated>2010-07-12</updated><authors><author><keyname>Cruz</keyname><forenames>Romar dela</forenames></author><author><keyname>Meyer</keyname><forenames>Annika</forenames></author><author><keyname>Sol&#xe9;</keyname><forenames>Patrick</forenames></author></authors><title>An extension of Massey scheme for secret sharing</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to ITW 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an extension of Massey's construction of secret sharing schemes
using linear codes. We describe the access structure of the scheme and show its
connection to the dual code. We use the $g$-fold weight enumerator and
invariant theory to study the access structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2802</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2802</id><created>2010-04-16</created><updated>2016-03-04</updated><authors><author><keyname>Chambart</keyname><forenames>Pierre</forenames></author><author><keyname>Finkel</keyname><forenames>Alain</forenames></author><author><keyname>Schmitz</keyname><forenames>Sylvain</forenames></author></authors><title>Forward Analysis and Model Checking for Trace Bounded WSTS</title><categories>cs.LO</categories><report-no>RR-LSV-10-08</report-no><acm-class>D.2.4; F.4.1; F.4.3</acm-class><journal-ref>32nd International Conference on Application and Theory of Petri
  Nets, volume 6709 of Lecture Notes in Computer Science, pages 49--68.
  Springer Heidelberg</journal-ref><doi>10.1007/978-3-642-21834-7_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a subclass of well-structured transition systems (WSTS), the
bounded---in the sense of Ginsburg and Spanier (Trans. AMS 1964)---complete
deterministic ones, which we claim provide an adequate basis for the study of
forward analyses as developed by Finkel and Goubault-Larrecq (Logic. Meth.
Comput. Sci. 2012). Indeed, we prove that, unlike other conditions considered
previously for the termination of forward analysis, boundedness is decidable.
Boundedness turns out to be a valuable restriction for WSTS verification, as we
show that it further allows to decide all $\omega$-regular properties on the
set of infinite traces of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2810</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2810</id><created>2010-04-16</created><authors><author><keyname>Cassez</keyname><forenames>Franck</forenames></author><author><keyname>Tripakis</keyname><forenames>Stavros</forenames></author></authors><title>Fault Diagnosis with Dynamic Observers</title><categories>cs.FL</categories><comments>Extented version of the paper that appeared in Proc. of the 9th
  Workshop on Discrete Event Systems (WODES'08)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we review some recent results about the use of dynamic
observers for fault diagnosis of discrete event systems. Fault diagnosis
consists in synthesizing a diagnoser that observes a given plant and identifies
faults in the plant as soon as possible after their occurrence. Existing
literature on this problem has considered the case of fixed static observers,
where the set of observable events is fixed and does not change during
execution of the system. In this paper, we consider dynamic observers: an
observer can &quot;switch&quot; sensors on or off, thus dynamically changing the set of
events it wishes to observe. It is known that checking diagnosability (i.e.,
whether a given observer is capable of identifying faults) can be solved in
polynomial time for static observers, and we show that the same is true for
dynamic ones. We also solve the problem of dynamic observers' synthesis and
prove that a most permissive observer can be computed in doubly exponential
time, using a game-theoretic approach. We further investigate optimization
problems for dynamic observers and define a notion of cost of an observer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2818</identifier>
 <datestamp>2012-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2818</id><created>2010-04-16</created><updated>2012-06-11</updated><authors><author><keyname>Goubault</keyname><forenames>Eric</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>Mimram</keyname><forenames>Samuel</forenames><affiliation>CEA LIST</affiliation></author></authors><title>Formal Relationships Between Geometrical and Classical Models for
  Concurrency</title><categories>cs.DC cs.LO</categories><proxy>ccsd</proxy><journal-ref>Electronic Notes in Theoretical Computer Science 283 (2012) 77-109</journal-ref><doi>10.1016/j.entcs.2012.05.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wide variety of models for concurrent programs has been proposed during the
past decades, each one focusing on various aspects of computations: trace
equivalence, causality between events, conflicts and schedules due to resource
accesses, etc. More recently, models with a geometrical flavor have been
introduced, based on the notion of cubical set. These models are very rich and
expressive since they can represent commutation between any bunch of events,
thus generalizing the principle of true concurrency. While they seem to be very
promising - because they make possible the use of techniques from algebraic
topology in order to study concurrent computations - they have not yet been
precisely related to the previous models, and the purpose of this paper is to
fill this gap. In particular, we describe an adjunction between Petri nets and
cubical sets which extends the previously known adjunction between Petri nets
and asynchronous transition systems by Nielsen and Winskel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2839</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2839</id><created>2010-04-16</created><updated>2010-05-11</updated><authors><author><keyname>Kao</keyname><forenames>Mong-Jen</forenames></author><author><keyname>Chen</keyname><forenames>Han-Lin</forenames></author></authors><title>Approximation Algorithms for the Capacitated Domination Problem</title><categories>cs.DM</categories><doi>10.1007/978-3-642-14553-7_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the {\em Capacitated Domination} problem, which models a
service-requirement assignment scenario and is also a generalization of the
well-known {\em Dominating Set} problem. In this problem, given a graph with
three parameters defined on each vertex, namely cost, capacity, and demand, we
want to find an assignment of demands to vertices of least cost such that the
demand of each vertex is satisfied subject to the capacity constraint of each
vertex providing the service. In terms of polynomial time approximations, we
present logarithmic approximation algorithms with respect to different demand
assignment models for this problem on general graphs, which also establishes
the corresponding approximation results to the well-known approximations of the
traditional {\em Dominating Set} problem. Together with our previous work, this
closes the problem of generally approximating the optimal solution. On the
other hand, from the perspective of parameterization, we prove that this
problem is {\it W[1]}-hard when parameterized by a structure of the graph
called treewidth. Based on this hardness result, we present exact
fixed-parameter tractable algorithms when parameterized by treewidth and
maximum capacity of the vertices. This algorithm is further extended to obtain
pseudo-polynomial time approximation schemes for planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2844</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2844</id><created>2010-04-16</created><updated>2011-05-22</updated><authors><author><keyname>Jithamithra</keyname><forenames>G. R.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Minimizing the Complexity of Fast Sphere Decoding of STBCs</title><categories>cs.IT math.IT</categories><comments>10 pages. To be presented in ISIT 2011. Added definition of FSD
  complexity. Expanded algorithm to order variables for conditionally group
  decodable and fast group decodable codes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decoding of linear space-time block codes (STBCs) with sphere-decoding (SD)
is well known. A fast-version of the SD known as fast sphere decoding (FSD) has
been recently studied by Biglieri, Hong and Viterbo. Viewing a linear STBC as a
vector space spanned by its defining weight matrices over the real number
field, we define a quadratic form (QF), called the Hurwitz-Radon QF (HRQF), on
this vector space and give a QF interpretation of the FSD complexity of a
linear STBC. It is shown that the FSD complexity is only a function of the
weight matrices defining the code and their ordering, and not of the channel
realization (even though the equivalent channel when SD is used depends on the
channel realization) or the number of receive antennas. It is also shown that
the FSD complexity is completely captured into a single matrix obtained from
the HRQF. Moreover, for a given set of weight matrices, an algorithm to obtain
a best ordering of them leading to the least FSD complexity is presented. The
well known classes of low FSD complexity codes (multi-group decodable codes,
fast decodable codes and fast group decodable codes) are presented in the
framework of HRQF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2850</identifier>
 <datestamp>2011-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2850</id><created>2010-04-16</created><updated>2011-03-25</updated><authors><author><keyname>Fulek</keyname><forenames>Radoslav</forenames></author><author><keyname>Suk</keyname><forenames>Andrew</forenames></author></authors><title>On disjoint crossing families in geometric graphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A geometric graph is a graph drawn in the plane with vertices represented by
points and edges as straight-line segments. A geometric graph contains a
(k,l)-crossing family if there is a pair of edge subsets E_1,E_2 such that
|E_1| = k and |E_2| = l, the edges in E_1 are pairwise crossing, the edges in
E_2 are pairwise crossing, and every edges in E_1 is disjoint to every edge in
E_2. We conjecture that for any fixed k,l, every n-vertex geometric graph with
no (k,l)-crossing family has at most c_{k,l}n edges, where c_{k,l} is a
constant that depends only on k and l. In this note, we show that every
n-vertex geometric graph with no (k,k)-crossing family has at most c_kn\log n
edges, where c_k is a constant that depends only on k, by proving a more
general result which relates extremal function of a geometric graph F with
extremal function of two completely disjoint copies of F. We also settle the
conjecture for geometric graphs with no (2,1)-crossing family. As a direct
application, this implies that for any circle graph F on 3 vertices, every
n-vertex geometric graph that does not contain a matching whose intersection
graph is F has at most O(n) edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2854</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2854</id><created>2010-04-16</created><authors><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Experimenting with Innate Immunity</title><categories>cs.AI cs.NE</categories><comments>8 pages, 5 figures, 4 tables, Workshop on Artificial Immune Systems
  and Immune System Modelling (AISB06)</comments><journal-ref>Proceedings of the Workshop on Artificial Immune Systems and
  Immune System Modelling (AISB06), Bristol, UK, p 18-19, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper the authors argued the case for incorporating ideas from
innate immunity into artificial immune systems (AISs) and presented an outline
for a conceptual framework for such systems. A number of key general properties
observed in the biological innate and adaptive immune systems were highlighted,
and how such properties might be instantiated in artificial systems was
discussed in detail. The next logical step is to take these ideas and build a
software system with which AISs with these properties can be implemented and
experimentally evaluated. This paper reports on the results of that step - the
libtissue system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2860</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2860</id><created>2010-04-16</created><authors><author><keyname>Al-Hammadi</keyname><forenames>Yousof</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Behavioural Correlation for Detecting P2P Bots</title><categories>cs.AI cs.CR cs.NE</categories><comments>5 pages, 1 table, 1 algorithm, Second International Conference on
  Future Networks (ICFN 2010)</comments><journal-ref>Proceedings of the Second International Conference on Future
  Networks (ICFN 2010), Sanya, Hainan, China, p 323-327, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few years, IRC bots, malicious programs which are remotely
controlled by the attacker through IRC servers, have become a major threat to
the Internet and users. These bots can be used in different malicious ways such
as issuing distributed denial of services attacks to shutdown other networks
and services, keystrokes logging, spamming, traffic sniffing cause serious
disruption on networks and users. New bots use peer to peer (P2P) protocols
start to appear as the upcoming threat to Internet security due to the fact
that P2P bots do not have a centralized point to shutdown or traceback, thus
making the detection of P2P bots is a real challenge. In response to these
threats, we present an algorithm to detect an individual P2P bot running on a
system by correlating its activities. Our evaluation shows that correlating
different activities generated by P2P bots within a specified time period can
detect these kind of bots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2868</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2868</id><created>2010-04-16</created><updated>2010-08-31</updated><authors><author><keyname>Ensslin</keyname><forenames>Torsten A.</forenames></author><author><keyname>Weig</keyname><forenames>Cornelius</forenames></author></authors><title>Inference with minimal Gibbs free energy in information field theory</title><categories>astro-ph.IM cs.IT hep-th math.IT physics.data-an stat.ME</categories><comments>14 pages</comments><report-no>J-MPA2648e</report-no><doi>10.1103/PhysRevE.82.051112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-linear and non-Gaussian signal inference problems are difficult to
tackle. Renormalization techniques permit us to construct good estimators for
the posterior signal mean within information field theory (IFT), but the
approximations and assumptions made are not very obvious. Here we introduce the
simple concept of minimal Gibbs free energy to IFT, and show that previous
renormalization results emerge naturally. They can be understood as being the
Gaussian approximation to the full posterior probability, which has maximal
cross information with it. We derive optimized estimators for three
applications, to illustrate the usage of the framework: (i) reconstruction of a
log-normal signal from Poissonian data with background counts and point spread
function, as it is needed for gamma ray astronomy and for cosmography using
photometric galaxy redshifts, (ii) inference of a Gaussian signal with unknown
spectrum and (iii) inference of a Poissonian log-normal signal with unknown
spectrum, the combination of (i) and (ii). Finally we explain how Gaussian
knowledge states constructed by the minimal Gibbs free energy principle at
different temperatures can be combined into a more accurate surrogate of the
non-Gaussian posterior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2870</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2870</id><created>2010-03-19</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Nurse Rostering with Genetic Algorithms</title><categories>cs.AI cs.NE</categories><comments>22 pages, Young Operational Research Conference 12</comments><journal-ref>Young Operational Research Conference 12, 1998</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years genetic algorithms have emerged as a useful tool for the
heuristic solution of complex discrete optimisation problems. In particular
there has been considerable interest in their use in tackling problems arising
in the areas of scheduling and timetabling. However, the classical genetic
algorithm paradigm is not well equipped to handle constraints and successful
implementations usually require some sort of modification to enable the search
to exploit problem specific knowledge in order to overcome this shortcoming.
This paper is concerned with the development of a family of genetic algorithms
for the solution of a nurse rostering problem at a major UK hospital. The
hospital is made up of wards of up to 30 nurses. Each ward has its own group of
nurses whose shifts have to be scheduled on a weekly basis. In addition to
fulfilling the minimum demand for staff over three daily shifts, nurses' wishes
and qualifications have to be taken into account. The schedules must also be
seen to be fair, in that unpopular shifts have to be spread evenly amongst all
nurses, and other restrictions, such as team nursing and special conditions for
senior staff, have to be satisfied. The basis of the family of genetic
algorithms is a classical genetic algorithm consisting of n-point crossover,
single-bit mutation and a rank-based selection. The solution space consists of
all schedules in which each nurse works the required number of shifts, but the
remaining constraints, both hard and soft, are relaxed and penalised in the
fitness function. The talk will start with a detailed description of the
problem and the initial implementation and will go on to highlight the
shortcomings of such an approach, in terms of the key element of balancing
feasibility, i.e. covering the demand and work regulations, and quality, as
measured by the nurses' preferences. A series of experiments involving
parameter adaptation, niching, intelligent weights, delta coding, local hill
climbing, migration and special selection rules will then be outlined and it
will be shown how a series of these enhancements were able to eradicate these
difficulties. Results based on several months' real data will be used to
measure the impact of each modification, and to show that the final algorithm
is able to compete with a tabu search approach currently employed at the
hospital. The talk will conclude with some observations as to the overall
quality of this approach to this and similar problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2873</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2873</id><created>2010-04-16</created><authors><author><keyname>Bersani</keyname><forenames>Marcello M.</forenames></author><author><keyname>Cavallaro</keyname><forenames>Luca</forenames></author><author><keyname>Frigeri</keyname><forenames>Achille</forenames></author><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author><author><keyname>Rossi</keyname><forenames>Matteo</forenames></author></authors><title>SMT-based Verification of LTL Specifications with Integer Constraints
  and its Application to Runtime Checking of Service Substitutability</title><categories>cs.LO cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important problem that arises during the execution of service-based
applications concerns the ability to determine whether a running service can be
substituted with one with a different interface, for example if the former is
no longer available. Standard Bounded Model Checking techniques can be used to
perform this check, but they must be able to provide answers very quickly, lest
the check hampers the operativeness of the application, instead of aiding it.
The problem becomes even more complex when conversational services are
considered, i.e., services that expose operations that have Input/Output data
dependencies among them. In this paper we introduce a formal verification
technique for an extension of Linear Temporal Logic that allows users to
include in formulae constraints on integer variables. This technique applied to
the substitutability problem for conversational services is shown to be
considerably faster and with smaller memory footprint than existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2880</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2880</id><created>2010-04-16</created><authors><author><keyname>Di Mauro</keyname><forenames>Nicola</forenames></author><author><keyname>Basile</keyname><forenames>Teresa M. A.</forenames></author><author><keyname>Ferilli</keyname><forenames>Stefano</forenames></author><author><keyname>Esposito</keyname><forenames>Floriana</forenames></author></authors><title>GRASP for the Coalition Structure Formation Problem</title><categories>cs.AI cs.MA</categories><comments>12 pages, Submitted to an International Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The coalition structure formation problem represents an active research area
in multi-agent systems. A coalition structure is defined as a partition of the
agents involved in a system into disjoint coalitions. The problem of finding
the optimal coalition structure is NP-complete. In order to find the optimal
solution in a combinatorial optimization problem it is theoretically possible
to enumerate the solutions and evaluate each. But this approach is infeasible
since the number of solutions often grows exponentially with the size of the
problem. In this paper we present a greedy adaptive search procedure (GRASP) to
efficiently search the space of coalition structures in order to find an
optimal one. Experiments and comparisons to other algorithms prove the validity
of the proposed method in solving this hard combinatorial problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2882</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2882</id><created>2010-04-16</created><authors><author><keyname>Palazuelos</keyname><forenames>C.</forenames></author><author><keyname>Perez-Garcia</keyname><forenames>D.</forenames></author><author><keyname>Villanueva</keyname><forenames>I.</forenames></author></authors><title>The communication complexity of XOR games via summing operators</title><categories>cs.CC quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrepancy method is widely used to find lower bounds for communication
complexity of XOR games. It is well known that these bounds can be far from
optimal. In this context Disjointness is usually mentioned as a case where the
method fails to give good bounds, because the increment of the value of the
game is linear (rather than exponential) in the number of communicated bits. We
show in this paper the existence of XOR games where the discrepancy method
yields bounds as poor as one desires. Indeed, we show the existence of such
games with any previously prescribed value. To prove this result we apply the
theory of p-summing operators, a central topic in Banach space theory. We show
in the paper other applications of this theory to the study of the
communication complexity of XOR games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2884</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2884</id><created>2010-04-16</created><updated>2010-12-30</updated><authors><author><keyname>Jhala</keyname><forenames>Ranjit</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author><author><keyname>Rybalchenko</keyname><forenames>Andrey</forenames></author></authors><title>HMC: Verifying Functional Programs Using Abstract Interpreters</title><categories>cs.PL cs.LO</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Hindley-Milner-Cousots (HMC), an algorithm that allows any
interprocedural analysis for first-order imperative programs to be used to
verify safety properties of typed higher-order functional programs. HMC works
as follows. First, it uses the type structure of the functional program to
generate a set of logical refinement constraints whose satisfaction implies the
safety of the source program. Next, it transforms the logical refinement
constraints into a simple first-order imperative program that is safe iff the
constraints are satisfiable. Thus, in one swoop, HMC makes tools for invariant
generation, e.g., based on abstract domains, predicate abstraction,
counterexample-guided refinement, and Craig interpolation be directly
applicable to verify safety properties of modern functional languages in a
fully automatic manner. We have implemented HMC and describe preliminary
experimental results using two imperative checkers -- ARMC and InterProc -- to
verify OCaml programs. Thus, by composing type-based reasoning grounded in
program syntax and state-based reasoning grounded in abstract interpretation,
HMC opens the door to automatic verification of programs written in modern
programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2888</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2888</id><created>2010-04-16</created><updated>2011-03-14</updated><authors><author><keyname>Nissim</keyname><forenames>Kobbi</forenames></author><author><keyname>Smorodinsky</keyname><forenames>Rann</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Approximately Optimal Mechanism Design via Differential Privacy</title><categories>cs.GT cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the implementation challenge in an abstract
interdependent values model and an arbitrary objective function. We design a
mechanism that allows for approximate optimal implementation of insensitive
objective functions in ex-post Nash equilibrium. If, furthermore, values are
private then the same mechanism is strategy proof. We cast our results onto two
specific models: pricing and facility location. The mechanism we design is
optimal up to an additive factor of the order of magnitude of one over the
square root of the number of agents and involves no utility transfers.
  Underlying our mechanism is a lottery between two auxiliary mechanisms: with
high probability we actuate a mechanism that reduces players' influence on the
choice of the social alternative, while choosing the optimal outcome with high
probability. This is where the recent notion of differential privacy is
employed. With the complementary probability we actuate a mechanism that is
typically far from optimal but is incentive compatible. The joint mechanism
inherits the desired properties from both.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2889</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2889</id><created>2010-04-16</created><authors><author><keyname>Ernst</keyname><forenames>Neil A.</forenames></author><author><keyname>Easterbrook</keyname><forenames>Steve</forenames></author><author><keyname>Mylopoulos</keyname><forenames>John</forenames></author></authors><title>Code forking in open-source software: a requirements perspective</title><categories>cs.SE</categories><comments>16 pages; 4 figures; based on work done in 2006</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To fork a project is to copy the existing code base and move in a direction
different than that of the erstwhile project leadership. Forking provides a
rapid way to address new requirements by adapting an existing solution.
However, it can also create a plethora of similar tools, and fragment the
developer community. Hence, it is not always clear whether forking is the right
strategy. In this paper, we describe a mixed-methods exploratory case study
that investigated the process of forking a project. The study concerned the
forking of an open-source tool for managing software projects, Trac. Trac was
forked to address differing requirements in an academic setting. The paper
makes two contributions to our understanding of code forking. First, our
exploratory study generated several theories about code forking in open source
projects, for further research. Second, we investigated one of these theories
in depth, via a quantitative study. We conjectured that the features of the OSS
forking process would allow new requirements to be addressed. We show that the
forking process in this case was successful at fulfilling the new projects
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2891</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2891</id><created>2010-04-16</created><authors><author><keyname>Kasperski</keyname><forenames>Adam</forenames></author><author><keyname>Zielinski</keyname><forenames>Pawel</forenames></author></authors><title>On the approximability of robust spanning tree problems</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the minimum spanning tree problem with uncertain edge costs is
discussed. In order to model the uncertainty a discrete scenario set is
specified and a robust framework is adopted to choose a solution. The min-max,
min-max regret and 2-stage min-max versions of the problem are discussed. The
complexity and approximability of all these problems are explored. It is proved
that the min-max and min-max regret versions with nonnegative edge costs are
hard to approximate within $O(\log^{1-\epsilon} n)$ for any $\epsilon&gt;0$ unless
the problems in NP have quasi-polynomial time algorithms. Similarly, the
2-stage min-max problem cannot be approximated within $O(\log n)$ unless the
problems in NP have quasi-polynomial time algorithms. In this paper randomized
LP-based approximation algorithms with performance ratio of $O(\log^2 n)$ for
min-max and 2-stage min-max problems are also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2899</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2899</id><created>2010-04-16</created><updated>2010-06-21</updated><authors><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Thaler</keyname><forenames>Justin</forenames></author></authors><title>Streaming Graph Computations with a Helpful Advisor</title><categories>cs.DS cs.CC</categories><comments>17 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the trend to outsource work to commercial cloud computing
services, we consider a variation of the streaming paradigm where a streaming
algorithm can be assisted by a powerful helper that can provide annotations to
the data stream. We extend previous work on such {\em annotation models} by
considering a number of graph streaming problems. Without annotations,
streaming algorithms for graph problems generally require significant memory;
we show that for many standard problems, including all graph problems that can
be expressed with totally unimodular integer programming formulations, only a
constant number of hash values are needed for single-pass algorithms given
linear-sized annotations. We also obtain a protocol achieving \textit{optimal}
tradeoffs between annotation length and memory usage for matrix-vector
multiplication; this result contributes to a trend of recent research on
numerical linear algebra in streaming models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2908</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2908</id><created>2010-04-16</created><updated>2010-04-20</updated><authors><author><keyname>Hell</keyname><forenames>Pavol</forenames></author><author><keyname>Rafiey</keyname><forenames>Arash</forenames></author></authors><title>The Dichotomy of List Homomorphisms for Digraphs</title><categories>cs.CC math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dichotomy Conjecture for constraint satisfaction problems has been
verified for conservative problems (or, equivalently, for list homomorphism
problems) by Andrei Bulatov. An earlier case of this dichotomy, for list
homomorphisms to undirected graphs, came with an elegant structural distinction
between the tractable and intractable cases. Such structural characterization
is absent in Bulatov's classification, and Bulatov asked whether one can be
found. We provide an answer in the case of digraphs; the technique will apply
in a broader context. The key concept we introduce is that of a digraph
asteroidal triple (DAT). The dichotomy then takes the following form. If a
digraph H has a DAT, then the list homomorphism problem for H is NP-complete;
and a DAT-free digraph H has a polynomial time solvable list homomorphism
problem. DAT-free graphs can be recognized in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2924</identifier>
 <datestamp>2011-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2924</id><created>2010-04-16</created><authors><author><keyname>Schindelar</keyname><forenames>Kristina</forenames></author><author><keyname>Levandovskyy</keyname><forenames>Viktor</forenames></author><author><keyname>Zerz</keyname><forenames>Eva</forenames></author></authors><title>Exact linear modeling using Ore algebras</title><categories>math.OC cs.SC math.RA</categories><msc-class>13P10, 93B25, 68W30, 93A30</msc-class><journal-ref>Journal of Symbolic Computation 46(2011) 1189-1204</journal-ref><doi>10.1016/j.jsc.2011.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear exact modeling is a problem coming from system identification: Given a
set of observed trajectories, the goal is find a model (usually, a system of
partial differential and/or difference equations) that explains the data as
precisely as possible. The case of operators with constant coefficients is well
studied and known in the systems theoretic literature, whereas the operators
with varying coefficients were addressed only recently. This question can be
tackled either using Gr\&quot;obner bases for modules over Ore algebras or by
following the ideas from differential algebra and computing in commutative
rings. In this paper, we present algorithmic methods to compute &quot;most powerful
unfalsified models&quot; (MPUM) and their counterparts with variable coefficients
(VMPUM) for polynomial and polynomial-exponential signals. We also study the
structural properties of the resulting models, discuss computer algebraic
techniques behind algorithms and provide several examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2926</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2926</id><created>2010-04-16</created><authors><author><keyname>Calderbank</keyname><forenames>Robert</forenames></author><author><keyname>Howard</keyname><forenames>Stephen</forenames></author><author><keyname>Jafarpour</keyname><forenames>Sina</forenames></author></authors><title>Sparse Reconstruction via The Reed-Muller Sieve</title><categories>cs.IT math.IT</categories><comments>To appear in ISIT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the Reed Muller Sieve, a deterministic measurement
matrix for compressed sensing. The columns of this matrix are obtained by
exponentiating codewords in the quaternary second order Reed Muller code of
length $N$. For $k=O(N)$, the Reed Muller Sieve improves upon prior methods for
identifying the support of a $k$-sparse vector by removing the requirement that
the signal entries be independent. The Sieve also enables local detection; an
algorithm is presented with complexity $N^2 \log N$ that detects the presence
or absence of a signal at any given position in the data domain without
explicitly reconstructing the entire signal. Reconstruction is shown to be
resilient to noise in both the measurement and data domains; the $\ell_2 /
\ell_2$ error bounds derived in this paper are tighter than the $\ell_2 /
\ell_1$ bounds arising from random ensembles and the $\ell_1 /\ell_1$ bounds
arising from expander-based ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2931</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2931</id><created>2010-04-16</created><authors><author><keyname>Horton</keyname><forenames>John J.</forenames></author><author><keyname>Rand</keyname><forenames>David G.</forenames></author><author><keyname>Zeckhauser</keyname><forenames>Richard J.</forenames></author></authors><title>The Online Laboratory: Conducting Experiments in a Real Labor Market</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online labor markets have great potential as platforms for conducting
experiments, as they provide immediate access to a large and diverse subject
pool and allow researchers to conduct randomized controlled trials. We argue
that online experiments can be just as valid---both internally and
externally---as laboratory and field experiments, while requiring far less
money and time to design and to conduct. In this paper, we first describe the
benefits of conducting experiments in online labor markets; we then use one
such market to replicate three classic experiments and confirm their results.
We confirm that subjects (1) reverse decisions in response to how a
decision-problem is framed, (2) have pro-social preferences (value payoffs to
others positively), and (3) respond to priming by altering their choices. We
also conduct a labor supply field experiment in which we confirm that workers
have upward sloping labor supply curves. In addition to reporting these
results, we discuss the unique threats to validity in an online setting and
propose methods for coping with these threats. We also discuss the external
validity of results from online domains and explain why online results can have
external validity equal to or even better than that of traditional methods,
depending on the research question. We conclude with our views on the potential
role that online experiments can play within the social sciences, and then
recommend software development priorities and best practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2958</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2958</id><created>2010-04-17</created><updated>2012-11-13</updated><authors><author><keyname>Bhattacharya</keyname><forenames>Bhaswar B.</forenames></author></authors><title>On the Fermat-Weber Point of a Polygonal Chain</title><categories>math.MG cs.CG</categories><comments>Revised and expanded, typos corrected, new references added. 12
  pages, 3 figures</comments><msc-class>90B85, 90C27, 68U05</msc-class><journal-ref>Fundamenta Informaticae, Vol. 107 (4), 331-343, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the properties of the Fermat-Weber point for a set of
fixed points, whose arrangement coincides with the vertices of a regular
polygonal chain. A $k$-chain of a regular $n$-gon is the segment of the
boundary of the regular $n$-gon formed by a set of $k(\leq n)$ consecutive
vertices of the regular $n$-gon. We show that for every odd positive integer
$k$, there exists an integer $N(k)$, such that the Fermat-Weber point of a set
of $k$ fixed points lying on the vertices a $k$-chain of a $n$-gon coincides
with a vertex of the chain whenever $n\geq N(k)$. We also show that $\lceil\pi
m(m+1)-\pi^2/4\rceil \leq N(k) \leq \lfloor\pi m(m+1)+1\rfloor$, where $k
(=2m+1)$ is any odd positive integer. We then extend this result to a more
general family of point set, and give an $O(hk\log k)$ time algorithm for
determining whether a given set of $k$ points, having $h$ points on the convex
hull, belongs to such a family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2968</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2968</id><created>2010-04-17</created><updated>2010-04-21</updated><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Yi</keyname><forenames>Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>Clustering with diversity</title><categories>cs.DS</categories><comments>Extended abstract accepted in ICALP 2010. Keywords: Approximation
  algorithm, k-center, k-anonymity, l-diversity</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the {\em clustering with diversity} problem: given a set of
colored points in a metric space, partition them into clusters such that each
cluster has at least $\ell$ points, all of which have distinct colors.
  We give a 2-approximation to this problem for any $\ell$ when the objective
is to minimize the maximum radius of any cluster. We show that the
approximation ratio is optimal unless $\mathbf{P=NP}$, by providing a matching
lower bound. Several extensions to our algorithm have also been developed for
handling outliers. This problem is mainly motivated by applications in
privacy-preserving data publication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2972</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2972</id><created>2010-04-17</created><updated>2011-08-01</updated><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Michal</forenames></author><author><keyname>Wojtaszczyk</keyname><forenames>Jakub Onufry</forenames></author></authors><title>Subset feedback vertex set is fixed parameter tractable</title><categories>cs.DS cs.CC</categories><comments>full version of a paper presented at ICALP'11</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical Feedback Vertex Set problem asks, for a given undirected graph
G and an integer k, to find a set of at most k vertices that hits all the
cycles in the graph G. Feedback Vertex Set has attracted a large amount of
research in the parameterized setting, and subsequent kernelization and
fixed-parameter algorithms have been a rich source of ideas in the field.
  In this paper we consider a more general and difficult version of the
problem, named Subset Feedback Vertex Set (SUBSET-FVS in short) where an
instance comes additionally with a set S ? V of vertices, and we ask for a set
of at most k vertices that hits all simple cycles passing through S. Because of
its applications in circuit testing and genetic linkage analysis SUBSET-FVS was
studied from the approximation algorithms perspective by Even et al.
[SICOMP'00, SIDMA'00].
  The question whether the SUBSET-FVS problem is fixed-parameter tractable was
posed independently by Kawarabayashi and Saurabh in 2009. We answer this
question affirmatively. We begin by showing that this problem is
fixed-parameter tractable when parametrized by |S|. Next we present an
algorithm which reduces the given instance to 2^k n^O(1) instances with the
size of S bounded by O(k^3), using kernelization techniques such as the
2-Expansion Lemma, Menger's theorem and Gallai's theorem. These two facts allow
us to give a 2^O(k log k) n^O(1) time algorithm solving the Subset Feedback
Vertex Set problem, proving that it is indeed fixed-parameter tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.2993</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.2993</id><created>2010-04-17</created><authors><author><keyname>Pushp</keyname><forenames>Saumay</forenames></author><author><keyname>Ranjan</keyname><forenames>Priya</forenames></author></authors><title>Hybrid CDN structure with a P2P based streaming protocol</title><categories>cs.NI</categories><comments>9 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decade, internet has seen an exponential increase in its
growth.With more and more people using it, efficient data delivery over the
internet has become a key issue. Peer-to-peer (P2P)/seed sharing based networks
have several desirable features for content distribution, such as low costs,
scalability, and fault tolerance. While the invention of each of such
specialized systems has improved the user experience, some fundamental
shortcomings of these systems have often been neglected. These shortcomings of
content distribution systems have become severe bottlenecks in scalability of
the internet.In order to combine the desired features of classical Content
Distribution Networks (CDNs) and P2P/seed sharing based networks, we propose a
hybrid CDN structure with a P2P/seed sharing based streaming protocol in the
access network . In this work, we focus on the problem of data redundancy (at
each node) and show how severely it impacts the network economics and the
experience of end-user and hence leads to low traffic load and redundancy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3006</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3006</id><created>2010-04-18</created><authors><author><keyname>Donoho</keyname><forenames>David L.</forenames></author><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author></authors><title>Microlocal Analysis of the Geometric Separation Problem</title><categories>math.FA cs.IT math.IT math.NA</categories><comments>59 pages, 9 figures</comments><report-no>Technical Report No. 2010-01, Statistics Department, Stanford
  University</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image data are often composed of two or more geometrically distinct
constituents; in galaxy catalogs, for instance, one sees a mixture of pointlike
structures (galaxy superclusters) and curvelike structures (filaments). It
would be ideal to process a single image and extract two geometrically `pure'
images, each one containing features from only one of the two geometric
constituents. This seems to be a seriously underdetermined problem, but recent
empirical work achieved highly persuasive separations. We present a theoretical
analysis showing that accurate geometric separation of point and curve
singularities can be achieved by minimizing the $\ell_1$ norm of the
representing coefficients in two geometrically complementary frames: wavelets
and curvelets. Driving our analysis is a specific property of the ideal (but
unachievable) representation where each content type is expanded in the frame
best adapted to it. This ideal representation has the property that important
coefficients are clustered geometrically in phase space, and that at fine
scales, there is very little coherence between a cluster of elements in one
frame expansion and individual elements in the complementary frame. We formally
introduce notions of cluster coherence and clustered sparsity and use this
machinery to show that the underdetermined systems of linear equations can be
stably solved by $\ell_1$ minimization; microlocal phase space helps organize
the calculations that cluster coherence requires.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3018</identifier>
 <datestamp>2010-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3018</id><created>2010-04-18</created><updated>2010-07-01</updated><authors><author><keyname>Ranestad</keyname><forenames>Kristian</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author></authors><title>The Convex Hull of a Variety</title><categories>math.AG cs.CG</categories><comments>12 pages, 2 figures</comments><msc-class>14N05, 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a characterization, in terms of projective biduality, for the
hypersurfaces appearing in the boundary of the convex hull of a compact real
algebraic variety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3020</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3020</id><created>2010-04-18</created><authors><author><keyname>Strozecki</keyname><forenames>Yann</forenames></author></authors><title>Enumeration of the Monomials of a Polynomial and Related Complexity
  Classes</title><categories>cs.CC</categories><doi>10.1007/978-3-642-15155-2_55</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of generating monomials of a polynomial in the context
of enumeration complexity. In this setting, the complexity measure is the delay
between two solutions and the total time. We present two new algorithms for
restricted classes of polynomials, which have a good delay and the same global
running time as the classical ones. Moreover they are simple to describe, use
little evaluation points and one of them is parallelizable. We introduce three
new complexity classes, TotalPP, IncPP and DelayPP, which are probabilistic
counterparts of the most common classes for enumeration problems, hoping that
randomization will be a tool as strong for enumeration as it is for decision.
Our interpolation algorithms proves that a lot of interesting problems are in
these classes like the enumeration of the spanning hypertrees of a 3-uniform
hypergraph.
  Finally we give a method to interpolate a degree 2 polynomials with an
acceptable (incremental) delay. We also prove that finding a specified monomial
in a degree 2 polynomial is hard unless RP = NP. It suggests that there is no
algorithm with a delay as good (polynomial) as the one we achieve for
multilinear polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3037</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3037</id><created>2010-04-18</created><updated>2010-09-26</updated><authors><author><keyname>Jiang</keyname><forenames>Shaoquan</forenames></author></authors><title>Persistent Asymmetric Password-Based Key Exchange</title><categories>cs.CR</categories><comments>22 pages</comments><msc-class>68P25</msc-class><acm-class>E.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymmetric password based key exchange is a key exchange protocol where a
client and a server share a low entropic password while the server additionally
owns a high entropic secret for a public key. There are simple solutions for
this (e.g. Halevi and Krawczyk (ACM TISSEC 1999) and its improvement by
Boyarsky (CCS 1999)). In this paper, we consider a new threat to this type of
protocol: if a server's high entropic secret gets compromised (e.g., due to
cryptanalysis, virus attack or a poor management), the adversary might {\em
quickly} break lots of passwords and cause uncountable damage. In this case,
one should not expect the protocol to be secure against an off-line dictionary
attack since, otherwise, the protocol is in fact a secure password-only key
exchange where the server also only has a password (by making the server high
entropic secret public). Of course a password-only key exchange does not suffer
from this threat as the server does not have a high entropic secret at all.
However, known password-only key exchange are not very efficient (note: we only
consider protocols without random oracles). This motivates us to study
efficient and secure asymmetric password key exchange that avoids the new
threat. In this paper, we first provide a formal model for the new threat,
where essentially we require that the active adversary can break $\ell$
passwords in $\alpha\ell |{\cal D}|$ steps (for $\alpha&lt;1/2$) only with a
probability negligibly close to $\exp(-\beta\ell)$ for some $\beta&gt;0$. Then, we
construct a framework of asymmetric password based key exchange. We prove that
our protocol is secure in the usual sense. We also show that it prevents the
new threat. To do this, we introduce a new technique by abstracting a
probabilistic experiment from the main proof and providing a neat analysis of
it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3040</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3040</id><created>2010-04-18</created><authors><author><keyname>Kopsinis</keyname><forenames>Yannis</forenames></author><author><keyname>Slavakis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Theodoridis</keyname><forenames>Sergios</forenames></author></authors><title>Online Sparse System Identification and Signal Reconstruction using
  Projections onto Weighted $\ell_1$ Balls</title><categories>cs.IT math.IT</categories><comments>Extented version of preprint submitted to IEEE trans. on Signal
  Processing</comments><doi>10.1109/TSP.2010.2090874</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel projection-based adaptive algorithm for sparse
signal and system identification. The sequentially observed data are used to
generate an equivalent sequence of closed convex sets, namely hyperslabs. Each
hyperslab is the geometric equivalent of a cost criterion, that quantifies
&quot;data mismatch&quot;. Sparsity is imposed by the introduction of appropriately
designed weighted $\ell_1$ balls. The algorithm develops around projections
onto the sequence of the generated hyperslabs as well as the weighted $\ell_1$
balls. The resulting scheme exhibits linear dependence, with respect to the
unknown system's order, on the number of multiplications/additions and an
$\mathcal{O}(L\log_2L)$ dependence on sorting operations, where $L$ is the
length of the system/signal to be estimated. Numerical results are also given
to validate the performance of the proposed method against the LASSO algorithm
and two very recently developed adaptive sparse LMS and LS-type of adaptive
algorithms, which are considered to belong to the same algorithmic family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3051</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3051</id><created>2010-04-18</created><authors><author><keyname>Grandoni</keyname><forenames>Fabrizio</forenames></author><author><keyname>Rothvoss</keyname><forenames>Thomas</forenames></author></authors><title>Prizing on Paths: A PTAS for the Highway Problem</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the highway problem, we are given an n-edge line graph (the highway), and
a set of paths (the drivers), each one with its own budget. For a given
assignment of edge weights (the tolls), the highway owner collects from each
driver the weight of the associated path, when it does not exceed the budget of
the driver, and zero otherwise. The goal is choosing weights so as to maximize
the profit.
  A lot of research has been devoted to this apparently simple problem. The
highway problem was shown to be strongly NP-hard only recently
[Elbassioni,Raman,Ray-'09]. The best-known approximation is O(\log n/\log\log
n) [Gamzu,Segev-'10], which improves on the previous-best O(\log n)
approximation [Balcan,Blum-'06].
  In this paper we present a PTAS for the highway problem, hence closing the
complexity status of the problem. Our result is based on a novel randomized
dissection approach, which has some points in common with Arora's quadtree
dissection for Euclidean network design [Arora-'98]. The basic idea is
enclosing the highway in a bounding path, such that both the size of the
bounding path and the position of the highway in it are random variables. Then
we consider a recursive O(1)-ary dissection of the bounding path, in subpaths
of uniform optimal weight. Since the optimal weights are unknown, we construct
the dissection in a bottom-up fashion via dynamic programming, while computing
the approximate solution at the same time. Our algorithm can be easily
derandomized. We demonstrate the versatility of our technique by presenting
PTASs for two variants of the highway problem: the tollbooth problem with a
constant number of leaves and the maximum-feasibility subsystem problem on
interval matrices. In both cases the previous best approximation factors are
polylogarithmic [Gamzu,Segev-'10,Elbassioni,Raman,Ray,Sitters-'09].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3057</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3057</id><created>2010-04-18</created><authors><author><keyname>Corrigan-Gibbs</keyname><forenames>Henry</forenames><affiliation>Yale University</affiliation></author><author><keyname>Ford</keyname><forenames>Bryan</forenames><affiliation>Yale University</affiliation></author></authors><title>Accountable Anonymous Group Messaging</title><categories>cs.CR</categories><comments>12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Users often wish to participate in online groups anonymously, but misbehaving
users may abuse this anonymity to spam or disrupt the group. Messaging
protocols such as Mix-nets and DC-nets leave online groups vulnerable to
denial-of-service and Sybil attacks, while accountable voting protocols are
unusable or inefficient for general anonymous messaging.
  We present the first general messaging protocol that offers provable
anonymity with accountability for moderate-size groups, and efficiently handles
unbalanced loads where few members have much data to transmit in a given round.
The N group members first cooperatively shuffle an NxN matrix of pseudorandom
seeds, then use these seeds in N &quot;pre-planned&quot; DC-nets protocol runs. Each
DC-nets run transmits the variable-length bulk data comprising one member's
message, using the minimum number of bits required for anonymity under our
attack model. The protocol preserves message integrity and one-to-one
correspondence between members and messages, makes denial-of-service attacks by
members traceable to the culprit, and efficiently handles large and unbalanced
message loads. A working prototype demonstrates the protocol's practicality for
anonymous messaging in groups of 40+ member nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3071</identifier>
 <datestamp>2011-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3071</id><created>2010-04-18</created><updated>2011-10-18</updated><authors><author><keyname>Lee</keyname><forenames>Kiryung</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author><author><keyname>Junge</keyname><forenames>Marius</forenames></author></authors><title>Subspace Methods for Joint Sparse Recovery</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE transactions on Information Theory, revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose robust and efficient algorithms for the joint sparse recovery
problem in compressed sensing, which simultaneously recover the supports of
jointly sparse signals from their multiple measurement vectors obtained through
a common sensing matrix. In a favorable situation, the unknown matrix, which
consists of the jointly sparse signals, has linearly independent nonzero rows.
In this case, the MUSIC (MUltiple SIgnal Classification) algorithm, originally
proposed by Schmidt for the direction of arrival problem in sensor array
processing and later proposed and analyzed for joint sparse recovery by Feng
and Bresler, provides a guarantee with the minimum number of measurements. We
focus instead on the unfavorable but practically significant case of
rank-defect or ill-conditioning. This situation arises with limited number of
measurement vectors, or with highly correlated signal components. In this case
MUSIC fails, and in practice none of the existing methods can consistently
approach the fundamental limit. We propose subspace-augmented MUSIC (SA-MUSIC),
which improves on MUSIC so that the support is reliably recovered under such
unfavorable conditions. Combined with subspace-based greedy algorithms also
proposed and analyzed in this paper, SA-MUSIC provides a computationally
efficient algorithm with a performance guarantee. The performance guarantees
are given in terms of a version of restricted isometry property. In particular,
we also present a non-asymptotic perturbation analysis of the signal subspace
estimation that has been missing in the previous study of MUSIC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3085</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3085</id><created>2010-04-18</created><authors><author><keyname>Kuzuoka</keyname><forenames>Shigeaki</forenames></author><author><keyname>Kimura</keyname><forenames>Akisato</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author></authors><title>Universal Coding of Ergodic Sources for Multiple Decoders with Side
  Information</title><categories>cs.IT math.IT</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multiterminal lossy coding problem, which includes various problems such as
the Wyner-Ziv problem and the complementary delivery problem as special cases,
is considered. It is shown that any point in the achievable rate-distortion
region can be attained even if the source statistics are not known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3105</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3105</id><created>2010-04-19</created><updated>2010-04-19</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>Fast normal random number generators on vector processors</title><categories>cs.DS math.NA stat.CO</categories><comments>An old Technical Report, not published elsewhere. 6 pages. For
  details see http://wwwmaths.anu.edu.au/~brent/pub/pub141.html</comments><report-no>Technical Report TR-CS-93-04, Computer Sciences Laboratory,
  Australian National University, March 1993.</report-no><msc-class>11K45</msc-class><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider pseudo-random number generators suitable for vector processors.
In particular, we describe vectorised implementations of the Box-Muller and
Polar methods, and show that they give good performance on the Fujitsu VP2200.
We also consider some other popular methods, e.g. the Ratio method of Kinderman
and Monahan (1977) (as improved by Leva (1992)), and the method of Von Neumann
and Forsythe, and show why they are unlikely to be competitive with the Polar
method on vector processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3108</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3108</id><created>2010-04-19</created><updated>2010-04-19</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>Uses of randomness in computation</title><categories>cs.DS math.CO math.NT</categories><comments>An old Technical Report, not published elsewhere. 14 pages. For
  further details see http://wwwmaths.anu.edu.au/~brent/pub/pub147.html</comments><report-no>Technical Report TR-CS-94-06, Computer Sciences Laboratory,
  Australian National University, June 1994</report-no><msc-class>68W20 (Primary) 68Q25 (Secondary)</msc-class><acm-class>F.2.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random number generators are widely used in practical algorithms. Examples
include simulation, number theory (primality testing and integer
factorization), fault tolerance, routing, cryptography, optimization by
simulated annealing, and perfect hashing. Complexity theory usually considers
the worst-case behaviour of deterministic algorithms, but it can also consider
average-case behaviour if it is assumed that the input data is drawn randomly
from a given distribution. Rabin popularised the idea of &quot;probabilistic&quot;
algorithms, where randomness is incorporated into the algorithm instead of
being assumed in the input data. Yao showed that there is a close connection
between the complexity of probabilistic algorithms and the average-case
complexity of deterministic algorithms. We give examples of the uses of
randomness in computation, discuss the contributions of Rabin, Yao and others,
and mention some open questions. This is the text of an invited talk presented
at &quot;Theory Day&quot;, University of NSW, Sydney, 22 April 1994.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3109</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3109</id><created>2010-04-19</created><authors><author><keyname>Wang</keyname><forenames>Yue</forenames></author></authors><title>Applying Stochastic Network Calculus to 802.11 Backlog and Delay
  Analysis</title><categories>cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic network calculus provides an elegant way to characterize traffic
and service processes. However, little effort has been made on applying it to
multi-access communication systems such as 802.11. In this paper, we take the
first step to apply it to the backlog and delay analysis of an 802.11 wireless
local network. In particular, we address the following questions: In applying
stochastic network calculus, under what situations can we derive stable backlog
and delay bounds? How to derive the backlog and delay bounds of an 802.11
wireless node? And how tight are these bounds when compared with simulations?
To answer these questions, we first derive the general stability condition of a
wireless node (not restricted to 802.11). From this, we give the specific
stability condition of an 802.11 wireless node. Then we derive the backlog and
delay bounds of an 802.11 node based on an existing model of 802.11. We observe
that the derived bounds are loose when compared with ns-2 simulations,
indicating that improvements are needed in the current version of stochastic
network calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3114</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3114</id><created>2010-04-19</created><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>A fast vectorised implementation of Wallace's normal random number
  generator</title><categories>cs.DS math.NA stat.CO</categories><comments>An old Technical Report, not published elsewhere. 9 pages. For
  further details see http://wwwmaths.anu.edu.au/~brent/pub/pub170.html</comments><report-no>Technical Report TR-CS-97-07, Computer Sciences Laboratory,
  Australian National University, April 1997</report-no><msc-class>11K45</msc-class><acm-class>G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wallace has proposed a new class of pseudo-random generators for normal
variates. These generators do not require a stream of uniform pseudo-random
numbers, except for initialisation. The inner loops are essentially
matrix-vector multiplications and are very suitable for implementation on
vector processors or vector/parallel processors such as the Fujitsu VPP300. In
this report we outline Wallace's idea, consider some variations on it, and
describe a vectorised implementation RANN4 which is more than three times
faster than its best competitors (the Polar and Box-Muller methods) on the
Fujitsu VP2200 and VPP300.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3115</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3115</id><created>2010-04-19</created><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>Some long-period random number generators using shifts and xors</title><categories>cs.DS math.NT stat.CO</categories><comments>11 pages</comments><msc-class>11K45</msc-class><acm-class>G.3</acm-class><journal-ref>ANZIAM Journal 48 (CTAC2006), C188-C202, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Marsaglia recently introduced a class of xorshift random number generators
(RNGs) with periods 2n-1 for n = 32, 64, etc. Here we give a generalisation of
Marsaglia's xorshift generators in order to obtain fast and high-quality RNGs
with extremely long periods. RNGs based on primitive trinomials may be
unsatisfactory because a trinomial has very small weight. In contrast, our
generators can be chosen so that their minimal polynomials have large weight
(number of nonzero terms). A computer search using Magma has found good
generators for n a power of two up to 4096. These have been implemented in a
free software package xorgens.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3128</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3128</id><created>2010-04-19</created><authors><author><keyname>Bolognesi</keyname><forenames>Tommaso</forenames></author></authors><title>Causal sets from simple models of computation</title><categories>physics.comp-ph cs.CC gr-qc nlin.CG</categories><comments>33 pages, 47 figures</comments><report-no>CNR/ISTI TR-011-2010</report-no><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Causality among events is widely recognized as a most fundamental structure
of spacetime, and causal sets have been proposed as discrete models of the
latter in the context of quantum gravity theories, notably in the Causal Set
Programme. In the rather different context of what might be called the
'Computational Universe Programme' -- one which associates the complexity of
physical phenomena to the emergent features of models such as cellular automata
-- a choice problem arises with respect to the variety of formal systems that,
in virtue of their computational universality (Turing-completeness), qualify as
equally good candidates for a computational, unified theory of physics. This
paper proposes Causal Sets as the only objects of physical significance and
relevance to be considered under the 'computational universe' perspective, and
as the appropriate abstraction for shielding the unessential details of the
many different computationally universal candidate models. At the same time, we
propose a fully deterministic, radical alternative to the probabilistic
techniques currently considered in the Causal Set Programme for growing
discrete spacetimes. We investigate a number of computation models by grouping
them into two broad classes, based on the support on which they operate; in one
case this is linear, like a tape or a string of symbols; in the other, it is a
two-dimensional grid or a planar graph. For each model we identify the
causality relation among computation events, implement it, and conduct a
possibly exhaustive exploration of the associated causal set space, while
examining quantitative and qualitative features such as dimensionality,
curvature, planarity, emergence of pseudo-randomness, causal set substructures
and particles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3134</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3134</id><created>2010-04-19</created><authors><author><keyname>Mimram</keyname><forenames>Samuel</forenames><affiliation>LIST</affiliation></author></authors><title>Focusing in Asynchronous Games</title><categories>cs.LO cs.GT</categories><proxy>ccsd</proxy><journal-ref>6th Conference on Computability in Europe 6158 (2010)</journal-ref><doi>10.1007/978-3-642-13962-8_37</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game semantics provides an interactive point of view on proofs, which enables
one to describe precisely their dynamical behavior during cut elimination, by
considering formulas as games on which proofs induce strategies. We are
specifically interested here in relating two such semantics of linear logic, of
very different flavor, which both take in account concurrent features of the
proofs: asynchronous games and concurrent games. Interestingly, we show that
associating a concurrent strategy to an asynchronous strategy can be seen as a
semantical counterpart of the focusing property of linear logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3135</identifier>
 <datestamp>2010-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3135</id><created>2010-04-19</created><authors><author><keyname>Mimram</keyname><forenames>Samuel</forenames><affiliation>LIST</affiliation></author></authors><title>Computing Critical Pairs in 2-Dimensional Rewriting Systems</title><categories>cs.FL math.CT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rewriting systems on words are very useful in the study of monoids. In good
cases, they give finite presentations of the monoids, allowing their
manipulation by a computer. Even better, when the presentation is confluent and
terminating, they provide one with a notion of canonical representative for the
elements of the presented monoid. Polygraphs are a higher-dimensional
generalization of this notion of presentation, from the setting of monoids to
the much more general setting of n-categories. Here, we are interested in
proving confluence for polygraphs presenting 2-categories, which can be seen as
a generalization of term rewriting systems. For this purpose, we propose an
adaptation of the usual algorithm for computing critical pairs. Interestingly,
this framework is much richer than term rewriting systems and requires the
elaboration of a new theoretical framework for representing critical pairs,
based on contexts in compact 2-categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3147</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3147</id><created>2010-04-19</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Genetic Algorithms for Multiple-Choice Problems</title><categories>cs.NE cs.AI cs.CE</categories><comments>258 pages, PhD thesis, University of Wales (Swansea)</comments><journal-ref>PhD thesis, University of Wales (Swansea), 1999</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis investigates the use of problem-specific knowledge to enhance a
genetic algorithm approach to multiple-choice optimisation problems.It shows
that such information can significantly enhance performance, but that the
choice of information and the way it is included are important factors for
success.Two multiple-choice problems are considered.The first is constructing a
feasible nurse roster that considers as many requests as possible.In the second
problem, shops are allocated to locations in a mall subject to constraints and
maximising the overall income.Genetic algorithms are chosen for their
well-known robustness and ability to solve large and complex discrete
optimisation problems.However, a survey of the literature reveals room for
further research into generic ways to include constraints into a genetic
algorithm framework.Hence, the main theme of this work is to balance
feasibility and cost of solutions.In particular, co-operative co-evolution with
hierarchical sub-populations, problem structure exploiting repair schemes and
indirect genetic algorithms with self-adjusting decoder functions are
identified as promising approaches.The research starts by applying standard
genetic algorithms to the problems and explaining the failure of such
approaches due to epistasis.To overcome this, problem-specific information is
added in a variety of ways, some of which are designed to increase the number
of feasible solutions found whilst others are intended to improve the quality
of such solutions.As well as a theoretical discussion as to the underlying
reasons for using each operator,extensive computational experiments are carried
out on a variety of data.These show that the indirect approach relies less on
problem structure and hence is easier to implement and superior in solution
quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3164</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3164</id><created>2010-04-19</created><authors><author><keyname>Ammar</keyname><forenames>Waleed</forenames></author><author><keyname>ElDawy</keyname><forenames>Ahmed</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Secure Localization in Wireless Sensor Networks: A Survey</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) have gained researchers' attention in the
last several years. Small sensors powered by miniaturized microprocessors are
capable of supporting several applications for civil and military domains.
Determining the location of sensors is a basic and essential knowledge for most
WSN algorithms and protocols including data tagging, routing, node
identification, among others. This paper surveys the different algorithms that
have been proposed to securely determine the location of a sensor node. By
&quot;secure&quot;, we mean that adversaries cannot easily affect the accuracy of the
localized sensors. In other words, the localization algorithm must be robust
under several attacks. We provide a taxonomy for classifying different secure
localization schemes and describe possible attacks that can harm localization.
In addition, we survey different secure localization schemes and show how they
map to the proposed taxonomy. We also give a comparison between the different
schemes, showing the attacks addressed by each.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3165</identifier>
 <datestamp>2014-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3165</id><created>2010-04-19</created><updated>2014-07-10</updated><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Nayak</keyname><forenames>Ashwin</forenames></author></authors><title>The space complexity of recognizing well-parenthesized expressions in
  the streaming model: the Index function revisited</title><categories>cs.CC cs.IT math.IT quant-ph</categories><comments>36 pages. Added more explanations for information cost, the proofs,
  and the notation; introduced abbreviations for random variables in Section 2
  to simplify expressions; corrected typos and minor errors; updated
  references. To appear in IEEE Transactions on Information Theory</comments><msc-class>94A17, 94A15, 81P45, 68P30</msc-class><acm-class>F.2.2; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show an Omega(sqrt{n}/T) lower bound for the space required by any
unidirectional constant-error randomized T-pass streaming algorithm that
recognizes whether an expression over two types of parenthesis is
well-parenthesized. This proves a conjecture due to Magniez, Mathieu, and Nayak
(2009) and rigorously establishes that bidirectional streams are exponentially
more efficient in space usage as compared with unidirectional ones. We obtain
the lower bound by establishing the minimum amount of information that is
necessarily revealed by the players about their respective inputs in a
two-party communication protocol for a variant of the Index function, namely
Augmented Index. The information cost trade-off is obtained by a novel
application of the conceptually simple and familiar ideas such as average
encoding and the cut-and-paste property of randomized protocols.
  Motivated by recent examples of exponential savings in space by streaming
quantum algorithms, we also study quantum protocols for Augmented Index.
Defining an appropriate notion of information cost for quantum protocols
involves a delicate balancing act between its applicability and the ease with
which we can analyze it. We define a notion of quantum information cost which
reflects some of the non-intuitive properties of quantum information and give a
trade-off for this notion. While this trade-off demonstrates the strength of
our proof techniques, it does not lead to a space lower bound for checking
parentheses. We leave such an implication for quantum streaming algorithms as
an intriguing open question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3169</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3169</id><created>2010-04-19</created><updated>2010-04-19</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author><author><keyname>Montgomery</keyname><forenames>Peter L.</forenames></author><author><keyname>Riele</keyname><forenames>Herman J. J. te</forenames></author></authors><title>Factorizations of Cunningham numbers with bases 13 to 99</title><categories>math.NT cs.DS</categories><comments>A Technical Report (December 2000) not published elsewhere, submitted
  for archival reasons. vi + 463 pages. For further details see
  http://wwwmaths.anu.edu.au/~brent/pub/pub200.html</comments><report-no>PRG TR-14-00</report-no><msc-class>11Y05 (Primary), 11-04 (Secondary)</msc-class><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This Report updates the tables of factorizations of a^n +- 1 for 13 &lt; a &lt;
100, previously published as CWI Report NM-R9212 (June 1992) and updated in CWI
Report NM-R9419 (Update 1, September 1994) and CWI Report NM-R9609 (Update 2,
March 1996). A total of 951 new entries in the tables are given here. The
factorizations are now complete for n &lt; 76, and there are no composite
cofactors smaller than 10^102.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3173</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3173</id><created>2010-04-19</created><updated>2010-04-19</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>MP users guide</title><categories>cs.MS math.NA math.NT</categories><comments>MP Users Guide (fourth edition), 73 pages. A technical report that
  was not published elsewhere, submitted for archival purposes. For further
  information see http://wwwmaths.anu.edu.au/~brent/pub/pub035.html</comments><report-no>TR-CS-81-08, Department of Computer Science, Australian National
  University (June 1981)</report-no><msc-class>97N80 (Primary), 11-04 (Secondary)</msc-class><acm-class>G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MP is a package of ANSI Standard Fortran (ANS X3.9-1966) subroutines for
performing multiple-precision floating-point arithmetic and evaluating
elementary and special functions. The subroutines are machine independent and
the precision is arbitrary, subject to storage limitations. The User's Guide
describes the routines and their calling sequences, example and test programs,
use of the Augment precompiler, and gives installation instructions for the
package.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3174</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3174</id><created>2010-04-19</created><authors><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author><author><keyname>Yosef</keyname><forenames>Mohamed Amir</forenames></author><author><keyname>El-Derini</keyname><forenames>Mohamed</forenames></author></authors><title>GAC: Energy-Efficient Hybrid GPS-Accelerometer-Compass GSM Localization</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adding location to the available information enables a new category of
applications. With the constrained battery on cell phones, energy-efficient
localization becomes an important challenge. In this paper we introduce a
low-energy calibration-free localization scheme based on the available internal
sensors in many of today's phones. We start by energy profiling the different
sensors that can be used for localization. Based on that, we propose GAC: a
hybrid GPS/accelerometer/compass scheme that depends mainly on using the
low-energy accelerometer and compass sensors and uses the GPS infrequently for
synchronization. We implemented our system on Android-enabled cell phones and
evaluated it in both highways and intra-city driving environments. Our results
show that the proposed hybrid scheme has an exponential saving in energy, with
a linear loss in accuracy compared to the GPS accuracy. We also evaluate the
effect of the different parameters on the energy-accuracy tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3175</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3175</id><created>2010-04-19</created><authors><author><keyname>Kranz</keyname><forenames>Eva</forenames></author></authors><title>Structural Stability and Immunogenicity of Peptides</title><categories>q-bio.BM cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigated the role of peptide folding stability in peptide
immunogenicity. It was the aim of this thesis to implement a stability
criterion based on energy computations using an AMBER force field, and to test
the implementation with a large dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3178</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3178</id><created>2010-04-19</created><authors><author><keyname>Ibrahim</keyname><forenames>Mohamed</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>CellSense: A Probabilistic RSSI-based GSM Positioning System</title><categories>cs.NI</categories><comments>6 pages, 6 figures, Submitted to Globe-com 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-aware applications have been gaining huge interest in the last few
years. With cell phones becoming ubiquitous computing devices, cell phone
localization has become an important research problem. In this paper, we
present CellSense, a prob- abilistic RSSI-based fingerprinting location
determina- tion system for GSM phones.We discuss the challenges of implementing
a probabilistic fingerprinting local- ization technique in GSM networks and
present the details of the CellSense system and how it addresses the
challenges. To evaluate our proposed system, we implemented CellSense on
Android-based phones. Re- sults for two different testbeds, representing urban
and rural environments, show that CellSense provides at least 23.8% enhancement
in accuracy in rural areas and at least 86.4% in urban areas compared to other
RSSI-based GSMlocalization systems. This comes with a minimal increase in
computational requirements. We also evaluate the effect of changing the
different system parameters on the accuracy-complexity tradeoff.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3183</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3183</id><created>2010-04-19</created><updated>2011-07-01</updated><authors><author><keyname>Moreno</keyname><forenames>Juan-Manuel Torres</forenames></author><author><keyname>Fernandez</keyname><forenames>Silvia</forenames></author><author><keyname>SanJuan</keyname><forenames>Eric</forenames></author></authors><title>Statistical Physics for Natural Language Processing</title><categories>cs.CL cond-mat.stat-mech cs.IR</categories><comments>This paper has been withdrawn</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3196</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3196</id><created>2010-04-19</created><authors><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author></authors><title>Introducing Dendritic Cells as a Novel Immune-Inspired Algorithm for
  Anomoly Detection</title><categories>cs.AI cs.NE</categories><comments>14 pages, 4 figures, 4 tables, 4th International Conference on
  Artificial Immune Systems (ICARIS2005)</comments><journal-ref>Proceedings of the 4th International Conference on Artificial
  Immune Systems (ICARIS2005), Lecture Notes in Computer Science 3627, Banff,
  Canada, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dendritic cells are antigen presenting cells that provide a vital link
between the innate and adaptive immune system. Research into this family of
cells has revealed that they perform the role of coordinating T-cell based
immune responses, both reactive and for generating tolerance. We have derived
an algorithm based on the functionality of these cells, and have used the
signals and differentiation pathways to build a control mechanism for an
artificial immune system. We present our algorithmic details in addition to
some preliminary results, where the algorithm was applied for the purpose of
anomaly detection. We hope that this algorithm will eventually become the key
component within a large, distributed immune system, based on sound
immunological concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3205</identifier>
 <datestamp>2011-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3205</id><created>2010-04-19</created><updated>2011-01-19</updated><authors><author><keyname>Roth</keyname><forenames>Aaron</forenames></author></authors><title>Differential Privacy and the Fat-Shattering Dimension of Linear Queries</title><categories>cs.DS</categories><comments>Appears in APPROX 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the task of answering linear queries under the
constraint of differential privacy. This is a general and well-studied class of
queries that captures other commonly studied classes, including predicate
queries and histogram queries. We show that the accuracy to which a set of
linear queries can be answered is closely related to its fat-shattering
dimension, a property that characterizes the learnability of real-valued
functions in the agnostic-learning setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3236</identifier>
 <datestamp>2013-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3236</id><created>2010-04-19</created><updated>2013-04-23</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Introduction to clarithmetic II</title><categories>cs.LO cs.CC math.LO math.NT</categories><msc-class>03F50, 03D75, 03D15, 68Q10, 68T27, 68T30</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The earlier paper &quot;Introduction to clarithmetic I&quot; constructed an axiomatic
system of arithmetic based on computability logic (see
http://www.cis.upenn.edu/~giorgi/cl.html), and proved its soundness and
extensional completeness with respect to polynomial time computability. The
present paper elaborates three additional sound and complete systems in the
same style and sense: one for polynomial space computability, one for
elementary recursive time (and/or space) computability, and one for primitive
recursive time (and/or space) computability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3241</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3241</id><created>2010-04-19</created><authors><author><keyname>Cheney</keyname><forenames>James</forenames></author></authors><title>Causality and the semantics of provenance</title><categories>cs.PL</categories><comments>Workshop submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Provenance, or information about the sources, derivation, custody or history
of data, has been studied recently in a number of contexts, including
databases, scientific workflows and the Semantic Web. Many provenance
mechanisms have been developed, motivated by informal notions such as
influence, dependence, explanation and causality. However, there has been
little study of whether these mechanisms formally satisfy appropriate policies
or even how to formalize relevant motivating concepts such as causality. We
contend that mathematical models of these concepts are needed to justify and
compare provenance techniques. In this paper we review a theory of causality
based on structural models that has been developed in artificial intelligence,
and describe work in progress on a causal semantics for provenance graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3246</identifier>
 <datestamp>2011-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3246</id><created>2010-04-19</created><updated>2010-06-23</updated><authors><author><keyname>Olschewski</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Ummels</keyname><forenames>Michael</forenames></author></authors><title>The Complexity of Finding Reset Words in Finite Automata</title><categories>cs.FL cs.CC</categories><comments>16 pages, revised version</comments><doi>10.1007/978-3-642-15155-2_50</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study several problems related to finding reset words in deterministic
finite automata. In particular, we establish that the problem of deciding
whether a shortest reset word has length k is complete for the complexity class
DP. This result answers a question posed by Volkov. For the search problems of
finding a shortest reset word and the length of a shortest reset word, we
establish membership in the complexity classes FP^NP and FP^NP[log],
respectively. Moreover, we show that both these problems are hard for
FP^NP[log]. Finally, we observe that computing a reset word of a given length
is FNP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3250</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3250</id><created>2010-04-19</created><authors><author><keyname>Akbar</keyname><forenames>Zaenal</forenames></author></authors><title>Watermarking Java Programs using Dummy Methods with Dynamically Opaque
  Predicates</title><categories>cs.CR cs.SE</categories><comments>95 pages, In Indonesia, Master Thesis, Sepuluh November Institute of
  Technology, Indonesia, February 2004</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software piracy, the illegal using, copying, and resale of applications is a
major concern for anyone develops software. Software developers also worry
about their applications being reverse engineered by extracting data structures
and algorithms from an application and incorporated into competitor's code. A
defense against software piracy is watermarking, a process that embeds a secret
message in a cover software. Watermarking is a method that does not aim to stop
piracy copying, but to prove ownership of the software and possibly even the
data structures and algorithms used in the software. The language Java was
designed to be compiled into a platform independent bytecode format. Much of
the information contained in the source code remains in the bytecode, which
means that decompilation is easier than with traditional native codes. In this
thesis, we present a technique for watermarking Java programs by using a
never-executed dummy method (Monden et.al., 2000) combined with opaque
predicates (Collberg et.al., 1998; Arboit, 2002) and improved with dynamically
opaque predicates (Palsberg et.al., 2000). This work presents a method to
construct a dynamic opaque predicates by grouping two or more opaque predicates
according to predefined rules. Any software watermarking technique will exhibit
a trade-off between resilience, data rate, cost, and stealth. To evaluate the
quality of a watermarking scheme we must also know how well it stands up to
different types of attacks. Ideally, we would like our watermarks to survive
translation (compilation, decompilation, and binary translation), optimization,
and obfuscation. Add a single watermark will increasing source code approximate
3.854 bytes with dummy method that cover up to 15 characters, two dynamic data
structures, two threads and two opaque predicates. Application loading-time
increase approximate 6108 milliseconds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3254</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3254</id><created>2010-04-19</created><authors><author><keyname>De Giusti</keyname><forenames>Laura</forenames></author><author><keyname>Chichizola</keyname><forenames>Franco</forenames></author><author><keyname>Naiouf</keyname><forenames>Marcelo</forenames></author><author><keyname>De Giusti</keyname><forenames>Armando</forenames></author><author><keyname>Luque</keyname><forenames>Emilio</forenames></author></authors><title>Automatic Mapping Tasks to Cores - Evaluating AMTHA Algorithm in
  Multicore Architectures</title><categories>cs.PF</categories><comments>http://ijcsi.org/articles/Automatic-Mapping-Tasks-to-Cores-Evaluating-AMTHA-Algorithm-in-Multicore-Architectures.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The AMTHA (Automatic Mapping Task on Heterogeneous Architectures) algorithm
for task-to-processors assignment and the MPAHA (Model of Parallel Algorithms
on Heterogeneous Architectures) model are presented. The use of AMTHA is
analyzed for multicore processor-based architectures, considering the
communication model among processes in use. The results obtained in the tests
carried out are presented, comparing the real execution times on multicores of
a set of synthetic applications with the predictions obtained with AMTHA.
Finally current lines of research are presented, focusing on clusters of
multicores and hybrid programming paradigms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3256</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3256</id><created>2010-04-19</created><authors><author><keyname>Belouadha</keyname><forenames>Fatima-Zahra</forenames></author><author><keyname>Omrana</keyname><forenames>Hajar</forenames></author><author><keyname>Roudies</keyname><forenames>Ounsa</forenames></author></authors><title>A model-driven approach for composing SAWSDL semantic Web services</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues at
  http://ijcsi.org/articles/A-model-driven-approach-for-composing-SAWSDL-semantic-Web-services.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Composing Web services is a convenient means of dealing with complex
requests. However, the number of Web services on the Internet is increasing.
This explains the growing interest in composing Web services automatically.
Nevertheless, the Web services' semantics is necessary for any dynamic
composition process. In this article, we present an MDA approach to develop and
compose SAWSDL semantic Web services. To model Web services, we use a UML
profile which is independent of the description standards. The SAWSDL interface
files are generated by using transformation rules. To model the behavior of a
composite Web service and generate its executable BPEL file, we use the BPMN
notation in a platform of modeling and implementing business process. The main
contribution of this work is the easy and extensible solution to a model-driven
development of the semantic atomic and composite Web services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3257</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3257</id><created>2010-04-19</created><authors><author><keyname>Kala</keyname><forenames>Rahul</forenames></author><author><keyname>Vazirani</keyname><forenames>Harsh</forenames></author><author><keyname>Shukla</keyname><forenames>Anupam</forenames></author><author><keyname>Tiwari</keyname><forenames>Ritu</forenames></author></authors><title>Offline Handwriting Recognition using Genetic Algorithm</title><categories>cs.CV</categories><comments>International Journal of Computer Science Issues at
  http://ijcsi.org/articles/Offline-Handwriting-Recognition-using-Genetic-Algorithm.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handwriting Recognition enables a person to scribble something on a piece of
paper and then convert it into text. If we look into the practical reality
there are enumerable styles in which a character may be written. These styles
can be self combined to generate more styles. Even if a small child knows the
basic styles a character can be written, he would be able to recognize
characters written in styles intermediate between them or formed by their
mixture. This motivates the use of Genetic Algorithms for the problem. In order
to prove this, we made a pool of images of characters. We converted them to
graphs. The graph of every character was intermixed to generate styles
intermediate between the styles of parent character. Character recognition
involved the matching of the graph generated from the unknown character image
with the graphs generated by mixing. Using this method we received an accuracy
of 98.44%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3258</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3258</id><created>2010-04-19</created><authors><author><keyname>Mosavi</keyname><forenames>A.</forenames></author></authors><title>Multiple Criteria Decision-Making Preprocessing Using Data Mining Tools</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues at
  http://ijcsi.org/articles/Multiple-Criteria-Decision-Making-Preprocessing-Using-Data-Mining-Tools.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-life engineering optimization problems need Multiobjective Optimization
(MOO) tools. These problems are highly nonlinear. As the process of Multiple
Criteria Decision-Making (MCDM) is much expanded most MOO problems in different
disciplines can be classified on the basis of it. Thus MCDM methods have gained
wide popularity in different sciences and applications. Meanwhile the
increasing number of involved components, variables, parameters, constraints
and objectives in the process, has made the process very complicated. However
the new generation of MOO tools has made the optimization process more
automated, but still initializing the process and setting the initial value of
simulation tools and also identifying the effective input variables and
objectives in order to reach the smaller design space are still complicated. In
this situation adding a preprocessing step into the MCDM procedure could make a
huge difference in terms of organizing the input variables according to their
effects on the optimization objectives of the system. The aim of this paper is
to introduce the classification task of data mining as an effective option for
identifying the most effective variables of the MCDM systems. To evaluate the
effectiveness of the proposed method an example has been given for 3D wing
design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3260</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3260</id><created>2010-04-19</created><authors><author><keyname>Mohemad</keyname><forenames>Rosmayati</forenames></author><author><keyname>Hamdan</keyname><forenames>Abdul Razak</forenames></author><author><keyname>Othman</keyname><forenames>Zulaiha Ali</forenames></author><author><keyname>Noor</keyname><forenames>Noor Maizura Mohamad</forenames></author></authors><title>Decision Support Systems (DSS) in Construction Tendering Processes</title><categories>cs.AI</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Decision-Support-Systems-DSS-in-Construction-Tendering-Processes.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The successful execution of a construction project is heavily impacted by
making the right decision during tendering processes. Managing tender
procedures is very complex and uncertain involving coordination of many tasks
and individuals with different priorities and objectives. Bias and inconsistent
decision are inevitable if the decision-making process is totally depends on
intuition, subjective judgement or emotion. In making transparent decision and
healthy competition tendering, there exists a need for flexible guidance tool
for decision support. Aim of this paper is to give a review on current
practices of Decision Support Systems (DSS) technology in construction
tendering processes. Current practices of general tendering processes as
applied to the most countries in different regions such as United States,
Europe, Middle East and Asia are comprehensively discussed. Applications of
Web-based tendering processes is also summarised in terms of its properties.
Besides that, a summary of Decision Support System (DSS) components is included
in the next section. Furthermore, prior researches on implementation of DSS
approaches in tendering processes are discussed in details. Current issues
arise from both of paper-based and Web-based tendering processes are outlined.
Finally, conclusion is included at the end of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3262</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3262</id><created>2010-04-19</created><updated>2014-09-15</updated><authors><author><keyname>Rama</keyname><forenames>N.</forenames></author><author><keyname>Lakshmanan</keyname><forenames>Meenakshi</forenames></author></authors><title>A Computational Algorithm for Metrical Classification of Verse</title><categories>cs.OH</categories><comments>IJCSI, Volume 7, Issue 2, March 2010, International Journal of
  Computer Science Issues online at
  http://ijcsi.org/articles/A-Computational-Algorithm-for-Metrical-Classification-of-Verse.php</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The science of versification and analysis of verse in Sanskrit is governed by
rules of metre or chandas. Such metre-wise classification of verses has
numerous uses for scholars and researchers alike, such as in the study of poets
and their style of Sanskrit poetical works. This paper presents a comprehensive
computational scheme and set of algorithms to identify the metre of verses
given as Sanskrit (Unicode) or English E-text (Latin Unicode). The paper also
demonstrates the use of euphonic conjunction rules to correct verses in which
these conjunctions, which are compulsory in verse, have erroneously not been
implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3263</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3263</id><created>2010-04-19</created><authors><author><keyname>Berrahou</keyname><forenames>Aissam</forenames></author><author><keyname>Rafi</keyname><forenames>Mourad</forenames></author><author><keyname>Eleuldj</keyname><forenames>Mohsine</forenames></author></authors><title>DRMS Co-design by F4MS</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/DRMS-Co-design-by-F4MS.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present Digital Rights Management systems (DRMS) which are
becoming more and more complex due to technology revolution in relation with
telecommunication networks, multimedia applications and the reading equipments
(Mobile Phone, IPhone, PDA, DVD Player,..). The complexity of the DRMS,
involves the use of new tools and methodologies that support software
components and hardware components coupled design. The traditional systems
design approach has been somewhat hardware first in that the software
components are designed after the hardware has been designed and prototyped.
This leaves little flexibility in evaluating different design options and
hardware-software mappings. The key of codesign is to avoid isolation between
hardware and software designs to proceed in parallel, with feedback and
interaction between the two as the design progresses, in order to achieve high
quality designs with a reduced design time. In this paper, we present the F4MS
(Framework for Mixed Systems) which is a unified framework for software and
hardware design environment, simulation and aided execution of mixed systems.
To illustrate this work we propose an implementation of DRMS business model
based on F4MS framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3265</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3265</id><created>2010-04-19</created><authors><author><keyname>Raj</keyname><forenames>Nikhil</forenames></author><author><keyname>Sharma</keyname><forenames>R. K.</forenames></author></authors><title>Modelling of Human Glottis in VLSI for Low Power Architectures</title><categories>cs.OH</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Modelling-of-Human-Glottis-in-VLSI-for-Low-Power-Architectures.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Glottal Source is an important component of voice as it can be considered
as the excitation signal to the voice apparatus. Nowadays, new techniques of
speech processing such as speech recognition and speech synthesis use the
glottal closure and opening instants. Current models of the glottal waves
derive their shape from approximate information rather than from exactly
measured data. General method concentrate on assessment of the glottis opening
using optical, acoustical methods, or on visualization of the larynx position
using ultrasound, computer tomography or magnetic resonance imaging techniques.
In this work, circuit model of Human Glottis using MOS is designed by
exploiting fluid volume velocity to current, fluid pressure to voltage, and
linear and nonlinear mechanical impedances to linear and nonlinear electrical
impedances. The glottis modeled as current source includes linear, non-linear
impedances to represent laminar and turbulent flow respectively, in vocal
tract. The MOS modelling and simulation results of glottal circuit has been
carried out on BSIM 3v3 model in TSMC 0.18 micrometer technology using ELDO
simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3267</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3267</id><created>2010-04-19</created><authors><author><keyname>Havangi</keyname><forenames>Ramazan</forenames></author><author><keyname>Nekoui</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Teshnehlab</keyname><forenames>Mohammad</forenames></author></authors><title>Adaptive Neuro-Fuzzy Extended Kalman Filtering for Robot Localization</title><categories>cs.OH</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Adaptive-Neuro-Fuzzy-Extended-Kalman-Filtering-for-Robot-Localization.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extended Kalman Filter (EKF) has been a popular approach to localization a
mobile robot. However, the performance of the EKF and the quality of the
estimation depends on the correct a priori knowledge of process and measurement
noise covariance matrices (Qk and Rk, respectively). Imprecise knowledge of
these statistics can cause significant degradation in performance. This paper
proposed the development of an Adaptive Neuro- Fuzzy Extended Kalman Filtering
(ANFEKF) for localization of robot. The Adaptive Neuro-Fuzzy attempts to
estimate the elements of Qk and Rk matrices of the EKF algorithm, at each
sampling instant when measurement update step is carried out. The ANFIS
supervises the performance of the EKF with the aim of reducing the mismatch
between the theoretical and actual covariance of the innovation sequences. The
free parameters of ANFIS are trained using the steepest gradient descent (SD)
to minimize the differences of the actual value of the covariance of the
residual with its theoretical value as much possible. The simulation results
show the effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3268</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3268</id><created>2010-04-19</created><authors><author><keyname>Mollanejad</keyname><forenames>Amir</forenames></author><author><keyname>Khanli</keyname><forenames>Leili Mohammad</forenames></author><author><keyname>Zeynali</keyname><forenames>Mohammad</forenames></author></authors><title>DBSR: Dynamic base station Repositioning using Genetic algorithm in
  wireless sensor network</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/DBSR-Dynamic-base-station-Repositioning-using-Genetic-algorithm-in-wireless-sensor-network.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) are commonly used in various ubiquitous and
pervasive applications. Due to limited power resources, the optimal dynamic
base station (BS) replacement could be Prolong the sensor network lifetime. In
this paper we'll present a dynamic optimum method for base station replacement
so that can save energy in sensors and increases network lifetime. Because
positioning problem is a NPhard problem [1], therefore we'll use genetic
algorithm to solve positioning problem. We've considered energy and distance
parameters for finding BS optimized position. In our represented algorithm base
station position is fixed just during each round and its positioning is done at
the start of next round then it'll be placed in optimized position. Evaluating
our proposed algorithm, we'll execute DBSR algorithm on LEACH &amp; HEED Protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3270</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3270</id><created>2010-04-19</created><authors><author><keyname>Sharma</keyname><forenames>Vishal</forenames></author><author><keyname>Verma</keyname><forenames>Harsh Kumar</forenames></author></authors><title>Optimized Fuzzy Logic Based Framework for Effort Estimation in Software
  Development</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Optimized-Fuzzy-Logic-Based-Framework-for-Effort-Estimation-in-Software-Development.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software effort estimation at early stages of project development holds great
significance for the industry to meet the competitive demands of today's world.
Accuracy, reliability and precision in the estimates of effort are quite
desirable. The inherent imprecision present in the inputs of the algorithmic
models like Constructive Cost Model (COCOMO) yields imprecision in the output,
resulting in erroneous effort estimation. Fuzzy logic based cost estimation
models are inherently suitable to address the vagueness and imprecision in the
inputs, to make reliable and accurate estimates of effort. In this paper, we
present an optimized fuzzy logic based framework for software development
effort prediction. The said framework tolerates imprecision, incorporates
experts knowledge, explains prediction rationale through rules, offers
transparency in the prediction system, and could adapt to changing environments
with the availability of new data. The traditional cost estimation model COCOMO
is extended in the proposed study by incorporating the concept of fuzziness
into the measurements of size, mode of development for projects and the cost
drivers contributing to the overall development effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3271</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3271</id><created>2010-04-19</created><authors><author><keyname>Cimino</keyname><forenames>Antonio</forenames></author><author><keyname>Longo</keyname><forenames>Francesco</forenames></author><author><keyname>Mirabelli</keyname><forenames>Giovanni</forenames></author></authors><title>A General Simulation Framework for Supply Chain Modeling: State of the
  Art and Case Study</title><categories>cs.OH</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/A-General-Simulation-Framework-for-Supply-Chain-Modeling-State-of-the-Art-and-Case-Study.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays there is a large availability of discrete event simulation software
that can be easily used in different domains: from industry to supply chain,
from healthcare to business management, from training to complex systems
design. Simulation engines of commercial discrete event simulation software use
specific rules and logics for simulation time and events management.
Difficulties and limitations come up when commercial discrete event simulation
software are used for modeling complex real world-systems (i.e. supply chains,
industrial plants). The objective of this paper is twofold: first a state of
the art on commercial discrete event simulation software and an overview on
discrete event simulation models development by using general purpose
programming languages are presented; then a Supply Chain Order Performance
Simulator (SCOPS, developed in C++) for investigating the inventory management
problem along the supply chain under different supply chain scenarios is
proposed to readers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3272</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3272</id><created>2010-04-19</created><authors><author><keyname>Pannurat</keyname><forenames>Nattapon</forenames></author><author><keyname>Kerdprasop</keyname><forenames>Nittaya</forenames></author><author><keyname>Kerdprasop</keyname><forenames>Kittisak</forenames></author></authors><title>Database Reverse Engineering based on Association Rule Mining</title><categories>cs.DB</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Database-Reverse-Engineering-based-on-Association-Rule-Mining.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintaining a legacy database is a difficult task especially when system
documentation is poor written or even missing. Database reverse engineering is
an attempt to recover high-level conceptual design from the existing database
instances. In this paper, we propose a technique to discover conceptual schema
using the association mining technique. The discovered schema corresponds to
the normalization at the third normal form, which is a common practice in many
business organizations. Our algorithm also includes the rule filtering
heuristic to solve the problem of exponential growth of discovered rules
inherited with the association mining technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3273</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3273</id><created>2010-04-19</created><authors><author><keyname>Hegde</keyname><forenames>Chinmay</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Sampling and Recovery of Pulse Streams</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2010.2103067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive Sensing (CS) is a new technique for the efficient acquisition of
signals, images, and other data that have a sparse representation in some
basis, frame, or dictionary. By sparse we mean that the N-dimensional basis
representation has just K&lt;&lt;N significant coefficients; in this case, the CS
theory maintains that just M = K log N random linear signal measurements will
both preserve all of the signal information and enable robust signal
reconstruction in polynomial time. In this paper, we extend the CS theory to
pulse stream data, which correspond to S-sparse signals/images that are
convolved with an unknown F-sparse pulse shape. Ignoring their convolutional
structure, a pulse stream signal is K=SF sparse. Such signals figure
prominently in a number of applications, from neuroscience to astronomy. Our
specific contributions are threefold. First, we propose a pulse stream signal
model and show that it is equivalent to an infinite union of subspaces. Second,
we derive a lower bound on the number of measurements M required to preserve
the essential information present in pulse streams. The bound is linear in the
total number of degrees of freedom S + F, which is significantly smaller than
the naive bound based on the total signal sparsity K=SF. Third, we develop an
efficient signal recovery algorithm that infers both the shape of the impulse
response as well as the locations and amplitudes of the pulses. The algorithm
alternatively estimates the pulse locations and the pulse shape in a manner
reminiscent of classical deconvolution algorithms. Numerical experiments on
synthetic and real data demonstrate the advantages of our approach over
standard CS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3274</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3274</id><created>2010-04-19</created><authors><author><keyname>Sarkar</keyname><forenames>Kamal</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author><author><keyname>Ghose</keyname><forenames>Suranjan</forenames></author></authors><title>A New Approach to Keyphrase Extraction Using Neural Networks</title><categories>cs.IR</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/A-New-Approach-to-Keyphrase-Extraction-Using-Neural-Networks.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Keyphrases provide a simple way of describing a document, giving the reader
some clues about its contents. Keyphrases can be useful in a various
applications such as retrieval engines, browsing interfaces, thesaurus
construction, text mining etc.. There are also other tasks for which keyphrases
are useful, as we discuss in this paper. This paper describes a neural network
based approach to keyphrase extraction from scientific articles. Our results
show that the proposed method performs better than some state-of-the art
keyphrase extraction approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3275</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3275</id><created>2010-04-19</created><authors><author><keyname>Dangarwala</keyname><forenames>Kruti</forenames></author><author><keyname>Shah</keyname><forenames>Jigar</forenames></author></authors><title>C Implementation &amp; comparison of companding &amp; silence audio compression
  techniques</title><categories>cs.MM</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/C-Implementation-comparison-of-companding-silence-audio-compression-techniques.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Just about all the newest living room audio-video electronics and PC
multimedia products being designed today will incorporate some form of
compressed digitized-audio processing capability. Audio compression reduces the
bit rate required to represent an analog audio signal while maintaining the
perceived audio quality. Discarding inaudible data reduces the storage,
transmission and compute requirements of handling high-quality audio files.
This paper covers wave audio file format &amp; algorithm of silence compression
method and companding method to compress and decompress wave audio file. Then
it compares the result of these two methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3276</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3276</id><created>2010-04-19</created><authors><author><keyname>Kharate</keyname><forenames>G. K.</forenames></author><author><keyname>Patil</keyname><forenames>V. H.</forenames></author></authors><title>Color Image Compression Based On Wavelet Packet Best Tree</title><categories>cs.CV</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Color-Image-Compression-Based-On-Wavelet-Packet-Best-Tree.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Image Compression, the researchers' aim is to reduce the number of bits
required to represent an image by removing the spatial and spectral
redundancies. Recently discrete wavelet transform and wavelet packet has
emerged as popular techniques for image compression. The wavelet transform is
one of the major processing components of image compression. The result of the
compression changes as per the basis and tap of the wavelet used. It is
proposed that proper selection of mother wavelet on the basis of nature of
images, improve the quality as well as compression ratio remarkably. We suggest
the novel technique, which is based on wavelet packet best tree based on
Threshold Entropy with enhanced run-length encoding. This method reduces the
time complexity of wavelet packets decomposition as complete tree is not
decomposed. Our algorithm selects the sub-bands, which include significant
information based on threshold entropy. The enhanced run length encoding
technique is suggested provides better results than RLE. The result when
compared with JPEG-2000 proves to be better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3277</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3277</id><created>2010-04-19</created><authors><author><keyname>Okike</keyname><forenames>Ezekiel</forenames></author></authors><title>A Pedagogical Evaluation and Discussion about the Lack of Cohesion in
  Method (LCOM) Metric Using Field Experiment</title><categories>cs.SE</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/A-Pedagogical-Evaluation-and-Discussion-about-the-Lack-of-Cohesion-in-Method-LCOM-Metric-Using-Field-Experiment.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chidamber and Kemerer first defined a cohesion measure for object-oriented
software - the Lack of Cohesion in Methods (LCOM) metric. This paper presents a
pedagogic evaluation and discussion about the LCOM metric using field data from
three industrial systems. System 1 has 34 classes, System 2 has 383 classes and
System 3 has 1055 classes. The main objectives of the study were to determine
if the LCOM metric was appropriate in the measurement of class cohesion and the
determination of properly and improperly designed classes in the studied
systems. Chidamber and Kemerer's suite of metric was used as metric tool.
Descriptive statistics was used to analyze results. The result of the study
showed that in System 1, 78.8% (26 classes) were cohesive; System 2 54% (207
classes) were cohesive; System 3 30% (317 classes) were cohesive. We suggest
that the LCOM metric measures class cohesiveness and was appropriate in the
determination of properly and improperly designed classes in the studied
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3282</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3282</id><created>2010-04-19</created><authors><author><keyname>Topakkaya</keyname><forenames>Hakan</forenames></author><author><keyname>Wang</keyname><forenames>Zhengdao</forenames></author></authors><title>Wireless Network Code Design and Performance Analysis using
  Diversity-Multiplexing Tradeoff</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding and cooperative communication have received considerable
attention from the research community recently in order to mitigate the adverse
effects of fading in wireless transmissions and at the same time to achieve
high throughput and better spectral efficiency. In this work, we design and
analyze deterministic and random network coding schemes for a cooperative
communication setup with multiple sources and destinations. We show that our
schemes outperform conventional cooperation in terms of the
diversity-multiplexing tradeoff (DMT). Specifically, it achieves the
full-diversity order at the expense of a slightly reduced multiplexing rate. We
establish the link between the parity-check matrix for a $(N+M,M,N+1)$
systematic MDS code and the network coding coefficients in a cooperative
communication system of $N$ source-destination pairs and $M$ relays. We present
two ways to generate the network coding matrix: using the Cauchy matrices and
the Vandermonde matrices, and establish that they both offer the maximum
diversity order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3304</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3304</id><created>2010-04-19</created><authors><author><keyname>Chakrabarti</keyname><forenames>Amit</forenames></author><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Kondapally</keyname><forenames>Ranganath</forenames></author><author><keyname>McGregor</keyname><forenames>Andrew</forenames></author></authors><title>Information Cost Tradeoffs for Augmented Index and Streaming Language
  Recognition</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper makes three main contributions to the theory of communication
complexity and stream computation. First, we present new bounds on the
information complexity of AUGMENTED-INDEX. In contrast to analogous results for
INDEX by Jain, Radhakrishnan and Sen [J. ACM, 2009], we have to overcome the
significant technical challenge that protocols for AUGMENTED-INDEX may violate
the &quot;rectangle property&quot; due to the inherent input sharing. Second, we use
these bounds to resolve an open problem of Magniez, Mathieu and Nayak [STOC,
2010] that asked about the multi-pass complexity of recognizing Dyck languages.
This results in a natural separation between the standard multi-pass model and
the multi-pass model that permits reverse passes. Third, we present the first
passive memory checkers that verify the interaction transcripts of priority
queues, stacks, and double-ended queues. We obtain tight upper and lower bounds
for these problems, thereby addressing an important sub-class of the memory
checking framework of Blum et al. [Algorithmica, 1994].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3314</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3314</id><created>2010-04-19</created><updated>2011-06-26</updated><authors><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author></authors><title>A Fast Approach to Creative Telescoping</title><categories>cs.SC math.CO</categories><comments>9 pages, 1 table, final version as it appeared in the journal</comments><msc-class>33F10, 68W30</msc-class><journal-ref>Mathematics in Computer Science 4(2-3), pp. 259-266, 2010</journal-ref><doi>10.1007/s11786-010-0055-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we reinvestigate the task of computing creative telescoping
relations in differential-difference operator algebras. Our approach is based
on an ansatz that explicitly includes the denominators of the delta parts. We
contribute several ideas of how to make an implementation of this approach
reasonably fast and provide such an implementation. A selection of examples
shows that it can be superior to existing methods by a large factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3320</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3320</id><created>2010-04-19</created><authors><author><keyname>Gibson</keyname><forenames>Matt</forenames></author><author><keyname>Pirwani</keyname><forenames>Imran A.</forenames></author></authors><title>Approximation Algorithms for Dominating Set in Disk Graphs</title><categories>cs.CG cs.DS</categories><comments>12 pages, 4 figures</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding a lowest cost dominating set in a given
disk graph containing $n$ disks. The problem has been extensively studied on
subclasses of disk graphs, yet the best known approximation for disk graphs has
remained $O(\log n)$ -- a bound that is asymptotically no better than the
general case. We improve the status quo in two ways: for the unweighted case,
we show how to obtain a PTAS using the framework recently proposed
(independently)by Mustafa and Ray [SoCG 09] and by Chan and Har-Peled [SoCG
09]; for the weighted case where each input disk has an associated rational
weight with the objective of finding a minimum cost dominating set, we give a
randomized algorithm that obtains a dominating set whose weight is within a
factor $2^{O(\log^* n)}$ of a minimum cost solution, with high probability --
the technique follows the framework proposed recently by Varadarajan [STOC 10].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3327</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3327</id><created>2010-04-19</created><updated>2011-06-26</updated><authors><author><keyname>Chakraborty</keyname><forenames>Ayon</forenames></author><author><keyname>Mitra</keyname><forenames>Swarup Kumar</forenames></author><author><keyname>Naskar</keyname><forenames>M. K.</forenames></author></authors><title>An Efficient Hybrid Data Gathering Scheme in Wireless Sensor Networks</title><categories>cs.NI cs.DC</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</comments><journal-ref>T. Janowski, H. Mohanty, and E. Estevez (Eds.): ICDCIT 2010, LNCS
  5966, pp. 98-103, 2010. copyright Springer-Verlag Berlin Heidelberg 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial sign error in
equation 1
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3332</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3332</id><created>2010-04-19</created><authors><author><keyname>Guo</keyname><forenames>Dongning</forenames><affiliation>Shitz</affiliation></author><author><keyname>Wu</keyname><forenames>Yihong</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Verdu</keyname><forenames>Sergio</forenames></author></authors><title>Estimation in Gaussian Noise: Properties of the Minimum Mean-Square
  Error</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, revised.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the minimum mean-square error (MMSE) of estimating an arbitrary
random variable from its observation contaminated by Gaussian noise. The MMSE
can be regarded as a function of the signal-to-noise ratio (SNR) as well as a
functional of the input distribution (of the random variable to be estimated).
It is shown that the MMSE is concave in the input distribution at any given
SNR. For a given input distribution, the MMSE is found to be infinitely
differentiable at all positive SNR, and in fact a real analytic function in SNR
under mild conditions. The key to these regularity results is that the
posterior distribution conditioned on the observation through Gaussian channels
always decays at least as quickly as some Gaussian density. Furthermore, simple
expressions for the first three derivatives of the MMSE with respect to the SNR
are obtained. It is also shown that, as functions of the SNR, the curves for
the MMSE of a Gaussian input and that of a non-Gaussian input cross at most
once over all SNRs. These properties lead to simple proofs of the facts that
Gaussian inputs achieve both the secrecy capacity of scalar Gaussian wiretap
channels and the capacity of scalar Gaussian broadcast channels, as well as a
simple proof of the entropy power inequality in the special case where one of
the variables is Gaussian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3334</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3334</id><created>2010-04-19</created><authors><author><keyname>Karimi</keyname><forenames>Kamran</forenames></author><author><keyname>Hamilton</keyname><forenames>Howard J.</forenames></author></authors><title>Generation and Interpretation of Temporal Decision Rules</title><categories>cs.LG</categories><comments>17 pages, 3 figures, 4 tables. Accepted in the International Journal
  of Computational Intelligence Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a solution to the problem of understanding a system that produces
a sequence of temporally ordered observations. Our solution is based on
generating and interpreting a set of temporal decision rules. A temporal
decision rule is a decision rule that can be used to predict or retrodict the
value of a decision attribute, using condition attributes that are observed at
times other than the decision attribute's time of observation. A rule set,
consisting of a set of temporal decision rules with the same decision
attribute, can be interpreted by our Temporal Investigation Method for
Enregistered Record Sequences (TIMERS) to signify an instantaneous, an acausal
or a possibly causal relationship between the condition attributes and the
decision attribute. We show the effectiveness of our method, by describing a
number of experiments with both synthetic and real temporal data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3351</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3351</id><created>2010-04-20</created><authors><author><keyname>Shi</keyname><forenames>Xiaolin</forenames></author><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>McFarland</keyname><forenames>Daniel A.</forenames></author></authors><title>Citing for High Impact</title><categories>cs.DL</categories><comments>10 pages, 6 figures, 1 table</comments><acm-class>H.3.7; H.4.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question of citation behavior has always intrigued scientists from
various disciplines. While general citation patterns have been widely studied
in the literature we develop the notion of citation projection graphs by
investigating the citations among the publications that a given paper cites. We
investigate how patterns of citations vary between various scientific
disciplines and how such patterns reflect the scientific impact of the paper.
We find that idiosyncratic citation patterns are characteristic for low impact
papers; while narrow, discipline-focused citation patterns are common for
medium impact papers. Our results show that crossing-community, or bridging
citation patters are high risk and high reward since such patterns are
characteristic for both low and high impact papers. Last, we observe that
recently citation networks are trending toward more bridging and
interdisciplinary forms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3361</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3361</id><created>2010-04-20</created><updated>2011-02-28</updated><authors><author><keyname>Nonnenmacher</keyname><forenames>St&#xe9;phane</forenames><affiliation>IPHT</affiliation></author><author><keyname>Sjoestrand</keyname><forenames>Johannes</forenames><affiliation>IMB</affiliation></author><author><keyname>Zworski</keyname><forenames>Maciej</forenames><affiliation>UC Berkeley Maths</affiliation></author></authors><title>From open quantum systems to open quantum maps</title><categories>math.AP cs.LG math-ph math.DS math.MP nlin.CD</categories><comments>53 pages, 8 figures</comments><proxy>ccsd</proxy><doi>10.1007/s00220-011-1214-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a class of quantized open chaotic systems satisfying a natural dynamical
assumption, we show that the study of the resolvent, and hence of scattering
and resonances, can be reduced to the study of a family of open quantum maps,
that is of finite dimensional operators obtained by quantizing the Poincar\'e
map associated with the flow near the set of trapped trajectories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3363</identifier>
 <datestamp>2012-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3363</id><created>2010-04-20</created><updated>2012-06-12</updated><authors><author><keyname>Fakcharoenphol</keyname><forenames>Jittat</forenames></author><author><keyname>Laekhanukit</keyname><forenames>Bundit</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author></authors><title>Faster Algorithms for Semi-Matching Problems</title><categories>cs.DS</categories><comments>ICALP 2010</comments><report-no>TALG-2011-0044.R2</report-no><msc-class>05C85, 68P05, 90B35</msc-class><acm-class>G.2.2; E.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding \textit{semi-matching} in bipartite graphs
which is also extensively studied under various names in the scheduling
literature. We give faster algorithms for both weighted and unweighted case.
  For the weighted case, we give an $O(nm\log n)$-time algorithm, where $n$ is
the number of vertices and $m$ is the number of edges, by exploiting the
geometric structure of the problem. This improves the classical $O(n^3)$
algorithms by Horn [Operations Research 1973] and Bruno, Coffman and Sethi
[Communications of the ACM 1974].
  For the unweighted case, the bound could be improved even further. We give a
simple divide-and-conquer algorithm which runs in $O(\sqrt{n}m\log n)$ time,
improving two previous $O(nm)$-time algorithms by Abraham [MSc thesis,
University of Glasgow 2003] and Harvey, Ladner, Lov\'asz and Tamir [WADS 2003
and Journal of Algorithms 2006]. We also extend this algorithm to solve the
\textit{Balance Edge Cover} problem in $O(\sqrt{n}m\log n)$ time, improving the
previous $O(nm)$-time algorithm by Harada, Ono, Sadakane and Yamashita [ISAAC
2008].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3366</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3366</id><created>2010-04-20</created><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>Some integer factorization algorithms using elliptic curves</title><categories>math.NT cs.DS</categories><comments>Corrected version of a paper that appeared in Australian Computer
  Science Communications 8 (1986), with postscript added 1998. For further
  details see http://wwwmaths.anu.edu.au/~brent/pub/pub102.html</comments><msc-class>11A51 (Primary) 11Y16, 68Q25(Secondary)</msc-class><acm-class>F.2.1</acm-class><journal-ref>Australian Computer Science Communications 8 (1986), 149-163</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lenstra's integer factorization algorithm is asymptotically one of the
fastest known algorithms, and is ideally suited for parallel computation. We
suggest a way in which the algorithm can be speeded up by the addition of a
second phase. Under some plausible assumptions, the speedup is of order log(p),
where p is the factor which is found. In practice the speedup is significant.
We mention some refinements which give greater speedup, an alternative way of
implementing a second phase, and the connection with Pollard's &quot;p-1&quot;
factorization algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3371</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3371</id><created>2010-04-20</created><authors><author><keyname>Boudin</keyname><forenames>Florian</forenames></author><author><keyname>Torres-Moreno</keyname><forenames>Juan-Manuel</forenames></author><author><keyname>El-B&#xe8;ze</keyname><forenames>Marc</forenames></author></authors><title>Improving Update Summarization by Revisiting the MMR Criterion</title><categories>cs.IR</categories><comments>20 pages, 3 figures and 8 tables.</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a method for multi-document update summarization that
relies on a double maximization criterion. A Maximal Marginal Relevance like
criterion, modified and so called Smmr, is used to select sentences that are
close to the topic and at the same time, distant from sentences used in already
read documents. Summaries are then generated by assembling the high ranked
material and applying some ruled-based linguistic post-processing in order to
obtain length reduction and maintain coherency. Through a participation to the
Text Analysis Conference (TAC) 2008 evaluation campaign, we have shown that our
method achieves promising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3372</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3372</id><created>2010-04-20</created><updated>2010-04-30</updated><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir R.</forenames></author><author><keyname>Schober</keyname><forenames>Steffen</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor V.</forenames></author></authors><title>Adaptive Single-Trial Error/Erasure Decoding for Binary Codes</title><categories>cs.IT math.IT</categories><comments>Submitted to the 2010 International Symposium on Information Theory
  and its Applications, Taichung, Taiwan, October 17 - 20, 2010. 6 pages, 4
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate adaptive single-trial error/erasure decoding of binary codes
whose decoder is able to correct e errors and t erasures if le+t&lt;=d-1. Thereby,
d is the minimum Hamming distance of the code and 1&lt;l&lt;=2 is the tradeoff
parameter between errors and erasures. The error/erasure decoder allows to
exploit soft information by treating a set of most unreliable received symbols
as erasures. The obvious question here is, how this erasing should be
performed, i.e. how the unreliable symbols which must be erased to obtain the
smallest possible residual codeword error probability are determined. In a
previous paper, we answer this question for the case of fixed erasing, where
only the channel state and not the individual symbol reliabilities are taken
into consideration. In this paper, we address the adaptive case, where the
optimal erasing strategy is determined for every given received vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3374</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3374</id><created>2010-04-20</created><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>On the precision attainable with various floating-point number systems</title><categories>cs.NA math.NA</categories><comments>Corrected version of an old paper (predating the IEEE floating point
  standard). For details see http://wwwmaths.anu.edu.au/~brent/pub/pub017.html</comments><report-no>Report TR RC 3751, IBM Research, Yorktown Heights, New York
  (February 1972), 28 pages</report-no><msc-class>65Y04</msc-class><acm-class>G.1.0</acm-class><journal-ref>IEEE Transactions on Computers C-22 (1973), 601-607</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For scientific computations on a digital computer the set of real number is
usually approximated by a finite set F of &quot;floating-point&quot; numbers. We compare
the numerical accuracy possible with difference choices of F having
approximately the same range and requiring the same word length. In particular,
we compare different choices of base (or radix) in the usual floating-point
systems. The emphasis is on the choice of F, not on the details of the number
representation or the arithmetic, but both rounded and truncated arithmetic are
considered. Theoretical results are given, and some simulations of typical
floating-point computations (forming sums, solving systems of linear equations,
finding eigenvalues) are described. If the leading fraction bit of a normalized
base 2 number is not stored explicitly (saving a bit), and the criterion is to
minimize the mean square roundoff error, then base 2 is best. If unnormalized
numbers are allowed, so the first bit must be stored explicitly, then base 4
(or sometimes base 8) is the best of the usual systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3381</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3381</id><created>2010-04-20</created><updated>2010-08-02</updated><authors><author><keyname>Werner</keyname><forenames>Daniel</forenames></author><author><keyname>Lenz</keyname><forenames>Matthias</forenames></author></authors><title>Polynomial Bounds on the Slicing Number</title><categories>cs.CG math.CO</categories><comments>Withdrawn, because we found out that most of the results were already
  known (under a different name). See updated abstract for details</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NOTE: Unfortunately, most of the results mentioned here were already known
under the name of &quot;d-separated interval piercing&quot;. The result that T_d(m)
exists was first proved by Gya\'rfa\'s and Lehel in 1970, see [5]. Later, the
result was strengthened by Ka\'rolyi and Tardos [9] to match our result.
Moreover, their proof (in a different notation, of course) uses ideas very
similar to ours and leads to a similar recurrence. Also, our conjecture turns
out to be right and was proved for the 2-dimensional case by Tardos and for the
general case by Kaiser [8]. An excellent survey article (&quot;Transversals of
d-intervals') is available on http://www.renyi.hu/~tardos. Still, we leave this
paper available to the public on http://page.mi.fu-berlin.de/dawerner, also
because one might find the references useful.
  -----
  We study the following Gallai-type of problem: Assume that we are given a
family X of convex objects in R^d such that among any subset of size m, there
is an axis-parallel hyperplane intersecting at least two of the objects. What
can we say about the number of axis-parallel hyperplanes that sufficient to
intersect all sets in the family?
  In this paper, we show that this number T_d(m) exists, i.e., depends only on
m and the dimension d, but not on the size of the set X. First, we derive a
very weak super-exponential bound. Using this result, by a simple proof we are
able to show that this number is even polynomially bounded for any fixed d.
  We partly answer open problem 74 on http://maven.smith.edu/~orourke/TOPP/,
where the planar case is considered, by improving the best known exponential
bound to O(m^2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3385</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3385</id><created>2010-04-20</created><authors><author><keyname>Amendola</keyname><forenames>Gennaro</forenames></author><author><keyname>Settepanella</keyname><forenames>Simona</forenames></author></authors><title>Modularity and Optimality in Social Choice</title><categories>math.CO cs.DM math.AT physics.soc-ph</categories><comments>42 pages, 4 figures, 8 tables, 1 algorithm.</comments><msc-class>05C20, 05C85, 52C35</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Marengo and the second author have developed in the last years a geometric
model of social choice when this takes place among bundles of interdependent
elements, showing that by bundling and unbundling the same set of constituent
elements an authority has the power of determining the social outcome. In this
paper we will tie the model above to tournament theory, solving some of the
mathematical problems arising in their work and opening new questions which are
interesting not only from a mathematical and a social choice point of view, but
also from an economic and a genetic one. In particular, we will introduce the
notion of u-local optima and we will study it from both a theoretical and a
numerical/probabilistic point of view; we will also describe an algorithm that
computes the universal basin of attraction of a social outcome in O(M^3 logM)
time (where M is the number of social outcomes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3390</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3390</id><created>2010-04-20</created><authors><author><keyname>David</keyname><forenames>Catalin</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author><author><keyname>Lange</keyname><forenames>Christoph</forenames></author><author><keyname>Rabe</keyname><forenames>Florian</forenames></author><author><keyname>Zhiltsov</keyname><forenames>Nikita</forenames></author><author><keyname>Zholudev</keyname><forenames>Vyacheslav</forenames></author></authors><title>Publishing Math Lecture Notes as Linked Data</title><categories>cs.DL cs.AI math.HO</categories><comments>7th Extended Semantic Web Conference (http://www.eswc2010.org), Demo
  Track</comments><msc-class>68T35, 68T30</msc-class><acm-class>H.2.4; H.2.8; H.3.5; G.4; F.4.m; H.5.3; H.5.4; J.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We mark up a corpus of LaTeX lecture notes semantically and expose them as
Linked Data in XHTML+MathML+RDFa. Our application makes the resulting documents
interactively browsable for students. Our ontology helps to answer queries from
students and lecturers, and paves the path towards an integration of our corpus
with external sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3392</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3392</id><created>2010-04-20</created><authors><author><keyname>Tazari</keyname><forenames>Siamak</forenames></author></authors><title>Faster Approximation Schemes and Parameterized Algorithms on
  H-Minor-Free and Odd-Minor-Free Graphs</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2; G.2.2</acm-class><doi>10.1007/978-3-642-15155-2_56</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve the running time of the general algorithmic technique known as
Baker's approach (1994) on H-minor-free graphs from O(n^{f(|H|)}) to O(f(|H|)
n^{O(1)}). The numerous applications include e.g. a 2-approximation for
coloring and PTASes for various problems such as dominating set and max-cut,
where we obtain similar improvements.
  On classes of odd-minor-free graphs, which have gained significant attention
in recent time, we obtain a similar acceleration for a variant of the
structural decomposition theorem proved by Demaine et al. (2010). We use these
algorithms to derive faster 2-approximations; furthermore, we present the first
PTASes and subexponential FPT-algorithms for independent set and vertex cover
on these graph classes using a novel dynamic programming technique.
  We also introduce a technique to derive (nearly) subexponential parameterized
algorithms on H-minor-free graphs. Our technique applies, in particular, to
problems such as Steiner tree, (directed) subgraph with a property, (directed)
longest path, and (connected/independent) dominating set, on some or all proper
minor-closed graph classes. We obtain as a corollary that all problems with a
minor-monotone subexponential kernel and amenable to our technique can be
solved in subexponential FPT-time on H-minor free graphs. This results in a
general methodology for subexponential parameterized algorithms outside the
framework of bidimensionality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3395</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3395</id><created>2010-04-20</created><authors><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Michail</keyname><forenames>Othon</forenames></author><author><keyname>Nikolaou</keyname><forenames>Stavros</forenames></author><author><keyname>Pavlogiannis</keyname><forenames>Andreas</forenames></author><author><keyname>Spirakis</keyname><forenames>Paul G.</forenames></author></authors><title>Passively Mobile Communicating Logarithmic Space Machines</title><categories>cs.DC</categories><comments>22 pages</comments><report-no>FRONTS-TR-2010-16</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new theoretical model for passively mobile Wireless Sensor
Networks. We call it the PALOMA model, standing for PAssively mobile
LOgarithmic space MAchines. The main modification w.r.t. the Population
Protocol model is that agents now, instead of being automata, are Turing
Machines whose memory is logarithmic in the population size n. Note that the
new model is still easily implementable with current technology. We focus on
complete communication graphs. We define the complexity class PLM, consisting
of all symmetric predicates on input assignments that are stably computable by
the PALOMA model. We assume that the agents are initially identical.
Surprisingly, it turns out that the PALOMA model can assign unique consecutive
ids to the agents and inform them of the population size! This allows us to
give a direct simulation of a Deterministic Turing Machine of O(nlogn) space,
thus, establishing that any symmetric predicate in SPACE(nlogn) also belongs to
PLM. We next prove that the PALOMA model can simulate the Community Protocol
model, thus, improving the previous lower bound to all symmetric predicates in
NSPACE(nlogn). Going one step further, we generalize the simulation of the
deterministic TM to prove that the PALOMA model can simulate a Nondeterministic
TM of O(nlogn) space. Although providing the same lower bound, the important
remark here is that the bound is now obtained in a direct manner, in the sense
that it does not depend on the simulation of a TM by a Pointer Machine.
Finally, by showing that a Nondeterministic TM of O(nlogn) space decides any
language stably computable by the PALOMA model, we end up with an exact
characterization for PLM: it is precisely the class of all symmetric predicates
in NSPACE(nlogn).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3398</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3398</id><created>2010-04-20</created><authors><author><keyname>Erd&#xe9;lyi</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Piras</keyname><forenames>Lena</forenames></author><author><keyname>Rothe</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>Control Complexity in Fallback Voting</title><categories>cs.GT cs.CC</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the control complexity of fallback voting. Like manipulation and
bribery, electoral control describes ways of changing the outcome of an
election; unlike manipulation or bribery attempts, control actions---such as
adding/deleting/partitioning either candidates or voters---modify the
participative structure of an election. Via such actions one can try to either
make a favorite candidate win (&quot;constructive control&quot;) or prevent a despised
candidate from winning (&quot;destructive control&quot;). Computational complexity can be
used to protect elections from control attempts, i.e., proving an election
system resistant to some type of control shows that the success of the
corresponding control action, though not impossible, is computationally
prohibitive. We show that fallback voting, an election system combining
approval with majority voting, is resistant to each of the common types of
candidate control and to each common type of constructive control. Among
natural election systems with a polynomial-time winner problem, only plurality
and sincere-strategy preference-based approval voting (SP-AV) were previously
known to be fully resistant to candidate control, and only Copeland voting and
SP-AV were previously known to be fully resistant to constructive control.
However, plurality has fewer resistances to voter control, Copeland voting has
fewer resistances to destructive control, and SP-AV (which like fallback voting
has 19 out of 22 proven control resistances) is arguably less natural a system
than fallback voting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3407</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3407</id><created>2010-04-20</created><updated>2011-06-26</updated><authors><author><keyname>Chakraborty</keyname><forenames>Ayon</forenames></author><author><keyname>Chakraborty</keyname><forenames>Kaushik</forenames></author><author><keyname>Mitra</keyname><forenames>Swarup Kumar</forenames></author><author><keyname>Naskar</keyname><forenames>M. K.</forenames></author></authors><title>An Optimized Lifetime Enhancement Scheme for Data Gathering in Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</comments><journal-ref>Proceedings ICWCSN - 2009, 978-1-4244-5877-06/09, 41-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial sign error in
equation 1
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3408</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3408</id><created>2010-04-20</created><updated>2011-06-26</updated><authors><author><keyname>Chakraborty</keyname><forenames>Ayon</forenames></author><author><keyname>Chakraborty</keyname><forenames>Kaushik</forenames></author><author><keyname>Mitra</keyname><forenames>Swarup Kumar</forenames></author><author><keyname>Naskar</keyname><forenames>M. K.</forenames></author></authors><title>An Energy Efficient Scheme for Data Gathering in Wireless Sensor
  Networks Using Particle Swarm Optimization</title><categories>cs.NI cs.DC cs.NE</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</comments><journal-ref>Journal of Applied Computer Science, no. 6 (3) /2009, Suceava</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial sign error in
equation 1
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3412</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3412</id><created>2010-04-20</created><updated>2010-05-29</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>Multiple-precision zero-finding methods and the complexity of elementary
  function evaluation</title><categories>cs.NA cs.CC cs.DS math.NA</categories><comments>An old (1975) paper with a postscript describing more recent
  developments. See also http://wwwmaths.anu.edu.au/~brent/pub/pub028.html</comments><report-no>Interim Report ADA014059, Department of Computer Science,
  Carnegie-Mellon University (July 1975), ii+26 pages</report-no><msc-class>11Y60 (Primary) 65Y20 (Secondary)</msc-class><acm-class>F.2.1; G.1.0</acm-class><journal-ref>Analytic Computational Complexity (edited by J. F. Traub),
  Academic Press, New York, 1975, 151-176</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider methods for finding high-precision approximations to simple zeros
of smooth functions. As an application, we give fast methods for evaluating the
elementary functions log(x), exp(x), sin(x) etc. to high precision. For
example, if x is a positive floating-point number with an n-bit fraction, then
(under rather weak assumptions) an n-bit approximation to log(x) or exp(x) may
be computed in time asymptotically equal to 13M(n)lg(n), where M(n) is the time
required to multiply floating-point numbers with n-bit fractions. Similar
results are given for the other elementary functions. Some analogies with
operations on formal power series (over a field of characteristic zero) are
discussed. In particular, it is possible to compute the first n terms in log(1
+ a_1.x + ...) or exp(a_1.x + ...) in time O(M(n)), where M(n) is the time
required to multiply two polynomials of degree n - 1. It follows that the first
n terms in a q-th power (1 + a_1.x + ...)^q can be computed in time O(M(n)),
independent of q. One of the results of this paper is the &quot;Gauss-Legendre&quot; or
&quot;Brent-Salamin&quot; algorithm for computing pi. This is the first quadratically
convergent algorithm for pi. It was also published in Brent [J. ACM 23 (1976),
242-251], and independently by Salamin [Math. Comp. 30 (1976), 565-570].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3427</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3427</id><created>2010-04-20</created><updated>2010-04-22</updated><authors><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author><author><keyname>Chia</keyname><forenames>Yeow-Khiang</forenames></author></authors><title>An Achievability Scheme for the Compound Channel with State Noncausally
  Available at the Encoder</title><categories>cs.IT math.IT</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new achievability scheme for the compound channel with discrete memoryless
(DM) state noncausally available at the encoder is established. Achievability
is proved using superposition coding, Marton coding, joint typicality encoding,
and indirect decoding. The scheme is shown to achieve strictly higher rate than
the straightforward extension of the Gelfand-Pinsker coding scheme for a single
DMC with DM state, and is optimal for some classes of channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3452</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3452</id><created>2010-04-20</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Deac</keyname><forenames>Vasile</forenames></author><author><keyname>Tipa</keyname><forenames>Stelian</forenames></author></authors><title>Towards Providing Low-Risk and Economically Feasible Network Data
  Transfer Services</title><categories>cs.NI cs.DC cs.DS</categories><comments>Proceedings of the 9th WSEAS International Conference on Multimedia,
  Internet &amp; Video Technologies (MIV), Budapest, Hungary, 3-5 September, 2009.
  (ISBN: 978-960-474-114-4 / ISSN: 1790-5109)</comments><msc-class>68M10, 68M12, 68M14, 68R10, 90B18</msc-class><acm-class>C.2.1; C.2.2; C.2.4; G.2.1; G.2.2</acm-class><journal-ref>Recent Advances in Signals &amp; Systems, pp. 204-209, 2009. (ISBN:
  978-960-474-114-4 / ISSN: 1790-5109)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the first part of this paper we present the first steps towards providing
low-risk and economically feasible network data transfer services. We introduce
three types of data transfer services and present general guidelines and
algorithms for managing service prices, risks and schedules. In the second part
of the paper we solve two packet scheduling cost optimization problems and
present efficient algorithms for identifying maximum weight (k-level-)
caterpillar subtrees in tree networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3458</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3458</id><created>2010-04-20</created><updated>2010-06-14</updated><authors><author><keyname>Boyer</keyname><forenames>Laurent</forenames><affiliation>LAMA</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LAMA</affiliation></author></authors><title>On Factor Universality in Symbolic Spaces</title><categories>cs.DM nlin.CG</categories><proxy>ccsd</proxy><doi>10.1007/978-3-642-15155-2_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of factoring relations between subshifts or cellular automata is
central in symbolic dynamics. Besides, a notion of intrinsic universality for
cellular automata based on an operation of rescaling is receiving more and more
attention in the literature. In this paper, we propose to study the factoring
relation up to rescalings, and ask for the existence of universal objects for
that simulation relation. In classical simulations of a system S by a system T,
the simulation takes place on a specific subset of configurations of T
depending on S (this is the case for intrinsic universality). Our setting,
however, asks for every configurations of T to have a meaningful interpretation
in S. Despite this strong requirement, we show that there exists a cellular
automaton able to simulate any other in a large class containing arbitrarily
complex ones. We also consider the case of subshifts and, using arguments from
recursion theory, we give negative results about the existence of universal
objects in some classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3460</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3460</id><created>2010-04-20</created><authors><author><keyname>Gu</keyname><forenames>Feng</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Oates</keyname><forenames>Robert</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>PCA 4 DCA: The Application Of Principal Component Analysis To The
  Dendritic Cell Algorithm</title><categories>cs.AI cs.NE</categories><comments>6 pages, 4 figures, 3 tables, (UKCI 2009)</comments><journal-ref>Proceedings of the 9th Annual Workshop on Computational
  Intelligence (UKCI 2009), Nottingham, UK, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As one of the newest members in the ?field of arti?cial immune systems (AIS),
the Dendritic Cell Algorithm (DCA) is based on behavioural models of natural
dendritic cells (DCs). Unlike other AIS, the DCA does not rely on training
data, instead domain or expert knowledge is required to predetermine the
mapping between input signals from a particular instance to the three
categories used by the DCA. This data preprocessing phase has received the
criticism of having manually over-?tted the data to the algorithm, which is
undesirable. Therefore, in this paper we have attempted to ascertain if it is
possible to use principal component analysis (PCA) techniques to automatically
categorise input data while still generating useful and accurate classication
results. The integrated system is tested with a biometrics dataset for the
stress recognition of automobile drivers. The experimental results have shown
the application of PCA to the DCA for the purpose of automated data
preprocessing is successful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3478</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3478</id><created>2010-04-20</created><updated>2010-04-27</updated><authors><author><keyname>Lorenzetti</keyname><forenames>Carlos M.</forenames></author><author><keyname>Maguitman</keyname><forenames>Ana G.</forenames></author></authors><title>Learning Better Context Characterizations: An Intelligent Information
  Retrieval Approach</title><categories>cs.IR cs.AI</categories><comments>10 pages, 3 figures, CLEI 2008</comments><msc-class>68P20</msc-class><acm-class>H.3.3</acm-class><journal-ref>XXXIV Conferencia Latinoamericana de Inform\'{a}tica, pp. 200-209,
  2008</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper proposes an incremental method that can be used by an intelligent
system to learn better descriptions of a thematic context. The method starts
with a small number of terms selected from a simple description of the topic
under analysis and uses this description as the initial search context. Using
these terms, a set of queries are built and submitted to a search engine. New
documents and terms are used to refine the learned vocabulary. Evaluations
performed on a large number of topics indicate that the learned vocabulary is
much more effective than the original one at the time of constructing queries
to retrieve relevant material.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3486</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3486</id><created>2010-04-20</created><authors><author><keyname>Wu</keyname><forenames>Jyh-Yang</forenames></author><author><keyname>Chi</keyname><forenames>Mei-Hsiu</forenames></author><author><keyname>Chen</keyname><forenames>Sheng-Gwo</forenames></author></authors><title>Convergent discrete Laplace-Beltrami operators over surfaces</title><categories>cs.CG cs.NA math.NA</categories><comments>13 pages and 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The convergence problem of the Laplace-Beltrami operators plays an essential
role in the convergence analysis of the numerical simulations of some important
geometric partial differential equations which involve the operator. In this
note we present a new effective and convergent algorithm to compute discrete
Laplace-Beltrami operators acting on functions over surfaces. We prove a
convergence theorem for our discretization. To our knowledge, this is the first
convergent algorithm of discrete Laplace-Beltrami operators over surfaces for
functions on general surfaces. Our algorithm is conceptually simple and easy to
compute. Indeed, the convergence rate of our new algorithm of discrete
Laplace-Beltrami operators over surfaces is $O(r)$ where r represents the size
of the mesh of discretization of the surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3504</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3504</id><created>2010-04-20</created><authors><author><keyname>Patra</keyname><forenames>Arpita</forenames></author><author><keyname>Rangan</keyname><forenames>C. Pandu</forenames></author></authors><title>Communication and Round Efficient Information Checking Protocol</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a very important primitive called Information
Checking Protocol (ICP) which plays an important role in constructing
statistical Verifiable Secret Sharing (VSS) and Weak Secret Sharing (WSS)
protocols. Informally, ICP is a tool for authenticating messages in the
presence of computationally unbounded corrupted parties. Here we extend the
basic bare-bone definition of ICP, introduced by Rabin et al. and then present
an ICP that attains the best communication complexity and round complexity
among all the existing ICPs in the literature. We also show that our ICP
satisfies several interesting properties such as linearity property which is an
important requirement in many applications of ICP. Though not presented in this
paper, we can design communication and round efficient statistical (i.e
involves negligible error probability in computation) VSS and Multiparty
Computation (MPC) protocol using our new ICP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3517</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3517</id><created>2010-04-20</created><authors><author><keyname>Krahmer</keyname><forenames>Felix</forenames></author><author><keyname>Ward</keyname><forenames>Rachel</forenames></author></authors><title>Lower bounds for the error decay incurred by coarse quantization schemes</title><categories>cs.IT math.IT</categories><comments>15 pages, one figure</comments><msc-class>37N99, 41A25, 41A44, 41A46, 42A61, 60C05, 94C99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several analog-to-digital conversion methods for bandlimited signals used in
applications, such as Sigma Delta quantization schemes, employ coarse
quantization coupled with oversampling. The standard mathematical model for the
error accrued from such methods measures the performance of a given scheme by
the rate at which the associated reconstruction error decays as a function of
the oversampling ratio L &gt; 1. It was recently shown that exponential accuracy
of the form O(2(-r L)) can be achieved by appropriate one-bit Sigma Delta
modulation schemes. However, the best known achievable rate constants r in this
setting differ significantly from the general information theoretic lower
bound. In this paper, we provide the first lower bound specific to coarse
quantization, thus narrowing the gap between existing upper and lower bounds.
In particular, our results imply a quantitative correspondence between the
maximal signal amplitude and the best possible error decay rate. Our method
draws from the theory of large deviations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3521</identifier>
 <datestamp>2012-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3521</id><created>2010-04-20</created><updated>2012-03-19</updated><authors><author><keyname>Toorani</keyname><forenames>M.</forenames></author><author><keyname>Beheshti</keyname><forenames>A. A.</forenames></author></authors><title>Cryptanalysis of an Elliptic Curve-based Signcryption Scheme</title><categories>cs.CR</categories><comments>6 Pages, 2 Figures</comments><msc-class>94Axx</msc-class><acm-class>E.3; K.6.5; D.4.6; K.6.m</acm-class><journal-ref>International Journal of Network Security, Vol. 10, No. 1, pp.
  51-56, Jan. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The signcryption is a relatively new cryptographic technique that is supposed
to fulfill the functionalities of encryption and digital signature in a single
logical step. Although several signcryption schemes are proposed over the
years, some of them are proved to have security problems. In this paper, the
security of Han et al.'s signcryption scheme is analyzed, and it is proved that
it has many security flaws and shortcomings. Several devastating attacks are
also introduced to the mentioned scheme whereby it fails all the desired and
essential security attributes of a signcryption scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3523</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3523</id><created>2010-04-20</created><authors><author><keyname>ParandehGheibi</keyname><forenames>Ali</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author></authors><title>Access-Network Association Policies for Media Streaming in Heterogeneous
  Environments</title><categories>math.OC cs.MM</categories><comments>submitted to CDC 2010</comments><report-no>LIDS report 2837</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the design of media streaming applications in the presence of
multiple heterogeneous wireless access methods with different throughputs and
costs. Our objective is to analytically characterize the trade-off between the
usage cost and the Quality of user Experience (QoE), which is represented by
the probability of interruption in media playback and the initial waiting time.
We model each access network as a server that provides packets to the user
according to a Poisson process with a certain rate and cost. Blocks are coded
using random linear codes to alleviate the duplicate packet reception problem.
Users must take decisions on how many packets to buffer before playout, and
which networks to access during playout. We design, analyze and compare several
control policies with a threshold structure. We formulate the problem of
finding the optimal control policy as an MDP with a probabilistic constraint.
We present the HJB equation for this problem by expanding the state space, and
exploit it as a verification method for optimality of the proposed control law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3524</identifier>
 <datestamp>2011-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3524</id><created>2010-04-20</created><updated>2011-01-13</updated><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>From Local Measurements to Network Spectral Properties: Beyond Degree
  Distributions</title><categories>math.OC cs.DM cs.MA</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that the behavior of many dynamical processes running on
networks is intimately related to the eigenvalue spectrum of the network. In
this paper, we address the problem of inferring global information regarding
the eigenvalue spectrum of a network from a set of local samples of its
structure. In particular, we find explicit relationships between the so-called
spectral moments of a graph and the presence of certain small subgraphs, also
called motifs, in the network. Since the eigenvalues of the network have a
direct influence on the network dynamical behavior, our result builds a bridge
between local network measurements (i.e., the presence of small subgraphs) and
global dynamical behavior (via the spectral moments). Furthermore, based on our
result, we propose a novel decentralized scheme to compute the spectral moments
of a network by aggregating local measurements of the network topology. Our
final objective is to understand the relationships between the behavior of
dynamical processes taking place in a large-scale complex network and its local
topological properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3527</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3527</id><created>2010-04-20</created><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Tahbaz-Salehi</keyname><forenames>Alireza</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author></authors><title>On Asymptotic Consensus Value in Directed Random Networks</title><categories>cs.MA math.OC</categories><comments>8 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymptotic properties of distributed consensus algorithms over
switching directed random networks. More specifically, we focus on consensus
algorithms over independent and identically distributed, directed random
graphs, where each agent can communicate with any other agent with some
exogenously specified probability. While different aspects of consensus
algorithms over random switching networks have been widely studied, a complete
characterization of the distribution of the asymptotic value for general
\textit{asymmetric} random consensus algorithms remains an open problem. In
this paper, we derive closed-form expressions for the mean and an upper bound
for the variance of the asymptotic consensus value, when the underlying network
evolves according to an i.i.d. \textit{directed} random graph process. We also
provide numerical simulations that illustrate our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3531</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3531</id><created>2010-04-20</created><authors><author><keyname>Bhatnagar</keyname><forenames>Nayantara</forenames></author><author><keyname>Sly</keyname><forenames>Allan</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Reconstruction Threshold for the Hardcore Model</title><categories>math.PR cs.DM math.CO</categories><comments>14 pages, 2 figures</comments><journal-ref>In Proceedings of the 14th International Conference on
  Randomization and Computation (RANDOM), volume 6302 of Lecture Notes in
  Computer Science, pages 434-447. Springer, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the reconstruction problem on the tree for the
hardcore model. We determine new bounds for the non-reconstruction regime on
the k-regular tree showing non-reconstruction when lambda &lt; (ln
2-o(1))ln^2(k)/(2 lnln(k)) improving the previous best bound of lambda &lt; e-1.
This is almost tight as reconstruction is known to hold when lambda&gt;
(e+o(1))ln^2(k). We discuss the relationship for finding large independent sets
in sparse random graphs and to the mixing time of Markov chains for sampling
independent sets on trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3534</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3534</id><created>2010-04-20</created><authors><author><keyname>Rabieyan</keyname><forenames>Reza</forenames></author></authors><title>Propose a Fuzzy Queuing Maximal Benefit Location Problem</title><categories>cs.OH</categories><comments>27 pages,5 figure,&amp; table</comments><msc-class>queuing theory</msc-class><acm-class>B.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a fuzzy queuing location model for congested system. In a
queuing system there are different criteria that are not constant such as
service rate, service rate demand, queue length, the occupancy probability of a
service center and Probability of joining the queue line. In this paper with
fuzzifying all of these variables, will try to reach an accurate real problem.
Finally we change the problem to a single objective function and as far as this
model is in NP-Hard classification we will use genetic algorithm for solving it
and ant colony for comparison is used for their results and run time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3539</identifier>
 <datestamp>2010-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3539</id><created>2010-04-20</created><authors><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>Lang</keyname><forenames>Kevin J.</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>Empirical Comparison of Algorithms for Network Community Detection</title><categories>cs.DS physics.soc-ph</categories><acm-class>H.5.8</acm-class><journal-ref>WWW 2010: ACM WWW International Conference on World Wide Web, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting clusters or communities in large real-world graphs such as large
social or information networks is a problem of considerable interest. In
practice, one typically chooses an objective function that captures the
intuition of a network cluster as set of nodes with better internal
connectivity than external connectivity, and then one applies approximation
algorithms or heuristics to extract sets of nodes that are related to the
objective function and that &quot;look like&quot; good communities for the application of
interest. In this paper, we explore a range of network community detection
methods in order to compare them and to understand their relative performance
and the systematic biases in the clusters they identify. We evaluate several
common objective functions that are used to formalize the notion of a network
community, and we examine several different classes of approximation algorithms
that aim to optimize such objective functions. In addition, rather than simply
fixing an objective and asking for an approximation to the best cluster of any
size, we consider a size-resolved version of the optimization problem.
Considering community quality as a function of its size provides a much finer
lens with which to examine community detection algorithms, since objective
functions and approximation algorithms often have non-obvious size-dependent
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3547</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3547</id><created>2010-04-20</created><authors><author><keyname>Leskovec</keyname><forenames>Jure</forenames></author><author><keyname>Huttenlocher</keyname><forenames>Daniel</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author></authors><title>Governance in Social Media: A case study of the Wikipedia promotion
  process</title><categories>physics.soc-ph cs.CY</categories><journal-ref>ICWSM 2010 - International AAAI Conference on Weblogs and Social
  Media</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social media sites are often guided by a core group of committed users
engaged in various forms of governance. A crucial aspect of this type of
governance is deliberation, in which such a group reaches decisions on issues
of importance to the site. Despite its crucial --- though subtle --- role in
how a number of prominent social media sites function, there has been
relatively little investigation of the deliberative aspects of social media
governance. Here we explore this issue, investigating a particular deliberative
process that is extensive, public, and recorded: the promotion of Wikipedia
admins, which is determined by elections that engage committed members of the
Wikipedia community. We find that the group decision-making at the heart of
this process exhibits several fundamental forms of relative assessment. First
we observe that the chance that a voter will support a candidate is strongly
dependent on the relationship between characteristics of the voter and the
candidate. Second we investigate how both individual voter decisions and
overall election outcomes can be based on models that take into account the
sequential, public nature of the voting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3549</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3549</id><created>2010-04-20</created><authors><author><keyname>Al-Mahadeen</keyname><forenames>Bassam</forenames></author><author><keyname>AlTarawneh</keyname><forenames>Mokhled S.</forenames></author><author><keyname>AlTarawneh</keyname><forenames>Islam H.</forenames></author></authors><title>Signature Region of Interest using Auto cropping</title><categories>cs.CV</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Signature-Region-of-Interest-using-Auto-cropping.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new approach for signature region of interest pre-processing was presented.
It used new auto cropping preparation on the basis of the image content, where
the intensity value of pixel is the source of cropping. This approach provides
both the possibility of improving the performance of security systems based on
signature images, and also the ability to use only the region of interest of
the used image to suit layout design of biometric systems. Underlying the
approach is a novel segmentation method which identifies the exact region of
foreground of signature for feature extraction usage. Evaluation results of
this approach shows encouraging prospects by eliminating the need for false
region isolating, reduces the time cost associated with signature false points
detection, and addresses enhancement issues. A further contribution of this
paper is an automated cropping stage in bio-secure based systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3555</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3555</id><created>2010-04-20</created><authors><author><keyname>Bamber</keyname><forenames>Sukhvinder S.</forenames></author><author><keyname>Sharma</keyname><forenames>Ajay K.</forenames></author></authors><title>Comparative Performance Investigations of different scenarios for
  802.15.4 WPAN</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Comparative-Performance-Investigations-of-different-scenarios-for-802-15-4-WPAN.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the performance of WPAN based on various topological
scenarios like: cluster, star and ring. The comparative results have been
reported for the performance metrics like: Throughput, Traffic sent, Traffic
received and Packets dropped. Cluster topology is best in comparison with star
and ring topologies as it has been shown that the throughput in case of cluster
topology (79.887 kbits / sec) as compared to star (31.815 kbits / sec) and ring
(1.179 kbits / sec).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3556</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3556</id><created>2010-04-20</created><authors><author><keyname>Gerami</keyname><forenames>Mohsen</forenames></author></authors><title>Policies and Economics of Digital Multimedia Transmission</title><categories>cs.MM</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Policies-and-Economics-of-Digital-Multimedia-Transmission.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are different Standards of digital multimedia transmission, for example
DVB in Europe and ISDB in Japan and DMB in Korea, with different delivery
system (example MPEG-2, MPEG-4).This paper describe an overview of Digital
Multimedia Transmission (DMT) technologies. The economic aspects of digital
content &amp; software solution industry as a strategic key in the future will be
discussed. The study then focuses on some important policy and technology
issues, such S-DMB, T-DMB, Digital Video Broadcasting Handheld (DVB-H) and
concludes DMT policies for convergence of telecommunications and broadcasting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3557</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3557</id><created>2010-04-20</created><authors><author><keyname>Volna</keyname><forenames>Eva</forenames></author></authors><title>Neuroevolutionary optimization</title><categories>cs.NE</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Neuroevolutionary-optimization.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an application of evolutionary search procedures to
artificial neural networks. Here, we can distinguish among three kinds of
evolution in artificial neural networks, i.e. the evolution of connection
weights, of architectures, and of learning rules. We review each kind of
evolution in detail and analyse critical issues related to different
evolutions. This article concentrates on finding the suitable way of using
evolutionary algorithms for optimizing the artificial neural network
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3560</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3560</id><created>2010-04-20</created><authors><author><keyname>Nikolov</keyname><forenames>Angel Vassilev</forenames></author><author><keyname>Lerato</keyname><forenames>Lerato</forenames></author></authors><title>Comparison of the Performance of Two Service Disciplines for a Shared
  Bus Multiprocessor with Private Caches</title><categories>cs.PF</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Comparison-of-the-Performance-of-Two-Service-Disciplines-for-a-Shared-Bus-Multiprocessor-with-Private-Caches.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we compare two analytical models for evaluation of cache
coherence overhead of a shared bus multiprocessor with private caches. The
models are based on a closed queuing network with different service
disciplines. We find that the priority discipline can be used as a lower-level
bound. Some numerical results are shown graphically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3563</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3563</id><created>2010-04-20</created><authors><author><keyname>S.</keyname><forenames>Ramesh Babu H.</forenames></author><author><keyname>Gowrishankar</keyname></author><author><keyname>S</keyname><forenames>Satyanarayana P.</forenames></author></authors><title>A QoS Provisioning Recurrent Neural Network based Call Admission Control
  for beyond 3G Networks</title><categories>cs.NI</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/A-QoS-Provisioning-Recurrent-Neural-Network-based-Call-Admission-Control-for-beyond-3G-Networks.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Call admission control (CAC) is one of the Radio Resource Management
(RRM) techniques that plays influential role in ensuring the desired Quality of
Service (QoS) to the users and applications in next generation networks. This
paper proposes a fuzzy neural approach for making the call admission control
decision in multi class traffic based Next Generation Wireless Networks (NGWN).
The proposed Fuzzy Neural call admission control (FNCAC) scheme is an
integrated CAC module that combines the linguistic control capabilities of the
fuzzy logic controller and the learning capabilities of the neural networks.
The model is based on recurrent radial basis function networks which have
better learning and adaptability that can be used to develop intelligent system
to handle the incoming traffic in an heterogeneous network environment. The
simulation results are optimistic and indicates that the proposed FNCAC
algorithm performs better than the other two methods and the call blocking
probability is minimal when compared to other two methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3565</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3565</id><created>2010-04-20</created><authors><author><keyname>Velvadivu</keyname><forenames>P.</forenames></author><author><keyname>Duraisamy</keyname><forenames>K.</forenames></author></authors><title>An Optimized Weighted Association Rule Mining On Dynamic Content</title><categories>cs.DB</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/An-Optimized-Weighted-Association-Rule-Mining-On-Dynamic-Content.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Association rule mining aims to explore large transaction databases for
association rules. Classical Association Rule Mining (ARM) model assumes that
all items have the same significance without taking their weight into account.
It also ignores the difference between the transactions and importance of each
and every itemsets. But, the Weighted Association Rule Mining (WARM) does not
work on databases with only binary attributes. It makes use of the importance
of each itemset and transaction. WARM requires each item to be given weight to
reflect their importance to the user. The weights may correspond to special
promotions on some products, or the profitability of different items. This
research work first focused on a weight assignment based on a directed graph
where nodes denote items and links represent association rules. A generalized
version of HITS is applied to the graph to rank the items, where all nodes and
links are allowed to have weights. This research then uses enhanced HITS
algorithm by developing an online eigenvector calculation method that can
compute the results of mutual reinforcement voting in case of frequent updates.
For Example in Share Market Shares price may go down or up. So we need to
carefully watch the market and our association rule mining has to produce the
items that have undergone frequent changes. These are done by estimating the
upper bound of perturbation and postponing of the updates whenever possible.
Next we prove that enhanced algorithm is more efficient than the original HITS
under the context of dynamic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3566</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3566</id><created>2010-04-20</created><authors><author><keyname>Murugesan</keyname><forenames>G.</forenames></author><author><keyname>Chellappan</keyname><forenames>C.</forenames></author></authors><title>An Economic-based Resource Management and Scheduling for Grid Computing
  Applications</title><categories>cs.DC</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/An-Economic-based-Resource-Management-and-Scheduling-for-Grid-Computing-Applications.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resource management and scheduling plays a crucial role in achieving high
utilization of resources in grid computing environments. Due to heterogeneity
of resources, scheduling an application is significantly complicated and
challenging task in grid system. Most of the researches in this area are mainly
focused on to improve the performance of the grid system. There were some
allocation model has been proposed based on divisible load theory with
different type of workloads and a single originating processor. In this paper
we introduce a new resource allocation model with multiple load originating
processors as an economic model. Solutions for an optimal allocation of
fraction of loads to nodes obtained to minimize the cost of the grid users via
linear programming approach. It is found that the resource allocation model can
efficiently and effectively allocate workloads to proper resources.
Experimental results showed that the proposed model obtained the better
solution in terms of cost and time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3568</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3568</id><created>2010-04-20</created><authors><author><keyname>Singh</keyname><forenames>Vikram</forenames></author><author><keyname>Nagpal</keyname><forenames>Sapna</forenames></author></authors><title>Integrating User's Domain Knowledge with Association Rule Mining</title><categories>cs.DB cs.AI</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Integrating-Users-Domain-Knowledge-with-Association-Rule-Mining.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a variation of Apriori algorithm that includes the role
of domain expert to guide and speed up the overall knowledge discovery task.
Usually, the user is interested in finding relationships between certain
attributes instead of the whole dataset. Moreover, he can help the mining
algorithm to select the target database which in turn takes less time to find
the desired association rules. Variants of the standard Apriori and Interactive
Apriori algorithms have been run on artificial datasets. The results show that
incorporating user's preference in selection of target attribute helps to
search the association rules efficiently both in terms of space and time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3571</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3571</id><created>2010-04-20</created><authors><author><keyname>Gupta</keyname><forenames>Vikas</forenames></author><author><keyname>Kasana</keyname><forenames>K. S.</forenames></author><author><keyname>Tandon</keyname><forenames>Puneet</forenames></author></authors><title>Computer Aided Design Modeling for Heterogeneous Objects</title><categories>cs.CE</categories><comments>International Journal of Computer Science Issues online at
  http://ijcsi.org/articles/Computer-Aided-Design-Modeling-for-Heterogeneous-Objects.php</comments><journal-ref>IJCSI, Volume 7, Issue 2, March 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous object design is an active research area in recent years. The
conventional CAD modeling approaches only provide geometry and topology of the
object, but do not contain any information with regard to the materials of the
object and so can not be used for the fabrication of heterogeneous objects (HO)
through rapid prototyping. Current research focuses on computer-aided design
issues in heterogeneous object design. A new CAD modeling approach is proposed
to integrate the material information into geometric regions thus model the
material distributions in the heterogeneous object. The gradient references are
used to represent the complex geometry heterogeneous objects which have
simultaneous geometry intricacies and accurate material distributions. The
gradient references helps in flexible manipulability and control to
heterogeneous objects, which guarantees the local control over gradient regions
of developed heterogeneous objects. A systematic approach on data flow,
processing, computer visualization, and slicing of heterogeneous objects for
rapid prototyping is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3580</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3580</id><created>2010-04-20</created><updated>2010-04-25</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Opthof</keyname><forenames>Tobias</forenames></author></authors><title>Scopus's Source Normalized Impact per Paper (SNIP) versus a Journal
  Impact Factor based on Fractional Counting of Citations</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Impact factors (and similar measures such as the Scimago Journal Rankings)
suffer from two problems: (i) citation behavior varies among fields of science
and therefore leads to systematic differences, and (ii) there are no statistics
to inform us whether differences are significant. The recently introduced SNIP
indicator of Scopus tries to remedy the first of these two problems, but a
number of normalization decisions are involved which makes it impossible to
test for significance. Using fractional counting of citations-based on the
assumption that impact is proportionate to the number of references in the
citing documents-citations can be contextualized at the paper level and
aggregated impacts of sets can be tested for their significance. It can be
shown that the weighted impact of Annals of Mathematics (0.247) is not so much
lower than that of Molecular Cell (0.386) despite a five-fold difference
between their impact factors (2.793 and 13.156, respectively).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3608</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3608</id><created>2010-04-20</created><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>The complexity of multiple-precision arithmetic</title><categories>cs.CC cs.NA math.NA</categories><comments>An old (1976) paper with a postscript (1999) describing more recent
  developments. 30 pages. For further details, see
  http://wwwmaths.anu.edu.au/~brent/pub/pub032.html</comments><msc-class>03D15 (Primary) 68Q17, 68Q25 (Secondary)</msc-class><acm-class>F.2.1; G.1.0</acm-class><journal-ref>The Complexity of Computational Problem Solving (edited by R. S.
  Anderssen and R. P. Brent), University of Queensland Press, Brisbane, 1976,
  126-165</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In studying the complexity of iterative processes it is usually assumed that
the arithmetic operations of addition, multiplication, and division can be
performed in certain constant times. This assumption is invalid if the
precision required increases as the computation proceeds. We give upper and
lower bounds on the number of single-precision operations required to perform
various multiple-precision operations, and deduce some interesting consequences
concerning the relative efficiencies of methods for solving nonlinear equations
using variable-length multiple-precision arithmetic. A postscript describes
more recent developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3617</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3617</id><created>2010-04-21</created><authors><author><keyname>Song</keyname><forenames>Qingshuo</forenames></author><author><keyname>Chen</keyname><forenames>Guanrong</forenames></author><author><keyname>Ho</keyname><forenames>Daniel W. C.</forenames></author></authors><title>Consensus over a Random Network Generated by i.i.d. Stochastic Matrices</title><categories>cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our goal is to find a necessary and sufficient condition on the consensus
over a random network, generated by i.i.d. stochastic matrices. We show that
the consensus problem in three different convergence modes (almost surely, in
probability, and in L1) are equivalent, thus have the same necessary and
sufficient condition. We obtain the necessary and sufficient condition through
the stability in a projected subspace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3621</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3621</id><created>2010-04-21</created><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author></authors><title>Unrestricted algorithms for elementary and special functions</title><categories>math.NA cs.NA</categories><comments>Corrected and updated version of a paper first published in 1980. 13
  pages. For further details see
  http://wwwmaths.anu.edu.au/~brent/pub/pub052.html</comments><msc-class>65Y20 (Primary) 68Q25 (Secondary)</msc-class><acm-class>G.1.0</acm-class><journal-ref>Information Processing 80 (edited by S. H. Lavington),
  North-Holland, Amsterdam, 1980, 613-619</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe some &quot;unrestricted&quot; algorithms which are useful for the
computation of elementary and special functions when the precision required is
not known in advance. Several general classes of algorithms are identified and
illustrated by examples. The topics include: power series methods, use of
halving identities, asymptotic expansions, continued fractions, recurrence
relations, Newton's method, numerical contour integration, and the
arithmetic-geometric mean. Most of the algorithms discussed are implemented in
the MP package (arXiv:1004.3173).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3629</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3629</id><created>2010-04-21</created><authors><author><keyname>Inagaki</keyname><forenames>Yuya</forenames></author><author><keyname>Inoue</keyname><forenames>Jun-ichi</forenames></author></authors><title>Simultaneous Bayesian inference of motion velocity fields and
  probabilistic models in successive video-frames described by spatio-temporal
  MRFs</title><categories>cs.CV</categories><comments>10 pages, 21 figures, using IEEEtran.cls</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We numerically investigate a mean-field Bayesian approach with the assistance
of the Markov chain Monte Carlo method to estimate motion velocity fields and
probabilistic models simultaneously in consecutive digital images described by
spatio-temporal Markov random fields. Preliminary to construction of our
procedure, we find that mean-field variables in the iteration diverge due to
improper normalization factor of regularization terms appearing in the
posterior. To avoid this difficulty, we rescale the regularization term by
introducing a scaling factor and optimizing it by means of minimization of the
mean-square error. We confirm that the optimal scaling factor stabilizes the
mean-field iterative process of the motion velocity estimation. We next attempt
to estimate the optimal values of hyper-parameters including the regularization
term, which define our probabilistic model macroscopically, by using the
Boltzmann-machine type learning algorithm based on gradient descent of marginal
likelihood (type-II likelihood) with respect to the hyper-parameters. In our
framework, one can estimate both the probabilistic model (hyper-parameters) and
motion velocity fields simultaneously. We find that our motion estimation is
much better than the result obtained by Zhang and Hanouer (1995) in which the
hyper-parameters are set to some ad-hoc values without any theoretical
justification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3630</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3630</id><created>2010-04-21</created><updated>2015-11-15</updated><authors><author><keyname>Babaioff</keyname><forenames>Moshe</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert D.</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Truthful Mechanisms with Implicit Payment Computation</title><categories>cs.GT cs.DS</categories><comments>This is a full version of the conference paper from ACM EC 2010,
  merged with a multi-parameter extension (Section 8) from the follow-up paper
  in ACM EC 2013 by the same authors. Apart from the revised presentation, this
  version is updated to reflect the follow-up work and the current status of
  open questions. The current version (v5) contains several minor bug fixes in
  the proof of Lemma 7.10. J. of the ACM (JACM), Volume 62, Issue 2, May 2015</comments><acm-class>J.4, K.4.4, F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is widely believed that computing payments needed to induce truthful
bidding is somehow harder than simply computing the allocation. We show that
the opposite is true: creating a randomized truthful mechanism is essentially
as easy as a single call to a monotone allocation rule. Our main result is a
general procedure to take a monotone allocation rule for a single-parameter
domain and transform it (via a black-box reduction) into a randomized mechanism
that is truthful in expectation and individually rational for every
realization. The mechanism implements the same outcome as the original
allocation rule with probability arbitrarily close to 1, and requires
evaluating that allocation rule only once. We also provide an extension of this
result to multi-parameter domains and cycle-monotone allocation rules, under
mild star-convexity and non-negativity hypotheses on the type space and
allocation rule, respectively.
  Because our reduction is simple, versatile, and general, it has many
applications to mechanism design problems in which re-evaluating the allocation
rule is either burdensome or informationally impossible. Applying our result to
the multi-armed bandit problem, we obtain truthful randomized mechanisms whose
regret matches the information-theoretic lower bound up to logarithmic factors,
even though prior work showed this is impossible for truthful deterministic
mechanisms. We also present applications to offline mechanism design, showing
that randomization can circumvent a communication complexity lower bound for
deterministic payments computation, and that it can also be used to create
truthful shortest path auctions that approximate the welfare of the VCG
allocation arbitrarily well, while having the same running time complexity as
Dijkstra's algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3635</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3635</id><created>2010-04-21</created><authors><author><keyname>Masopust</keyname><forenames>Tomas</forenames></author></authors><title>Comparison of Two Context-Free Rewriting Systems with Simple
  Context-Checking Mechanisms</title><categories>cs.FL</categories><comments>Unpublished as a stronger result is under consideration.</comments><msc-class>68Q42, 68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper solves an open problem concerning the generative power of
nonerasing context-free rewriting systems using a simple mechanism for checking
for context dependencies, in the literature known as semi-conditional grammars
of degree (1,1). In these grammars, two nonterminal symbols are attached to
each context-free production, and such a production is applicable if one of the
two attached symbols occurs in the current sentential form, while the other
does not. Specifically, this paper demonstrates that the family of languages
generated by semi-conditional grammars of degree (1,1) coincides with the
family of random context languages. In addition, it shows that the normal form
proved by Mayer for random context grammars with erasing productions holds for
random context grammars without erasing productions, too. It also discusses two
possible definitions of the relation of the direct derivation step used in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3640</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3640</id><created>2010-04-21</created><authors><author><keyname>Kiwelekar</keyname><forenames>Arvind W.</forenames></author><author><keyname>Joshi</keyname><forenames>Rushikesh K.</forenames></author></authors><title>An Object-Oriented Metamodel for Bunge-Wand-Weber Ontology</title><categories>cs.SE</categories><comments>8 Pages, 7 Tables, 8 Figures</comments><acm-class>D.2.11</acm-class><journal-ref>Kiwelekar, A.W., Joshi, R.K.: An object oriented metamodel for
  bunge-wand- weber ontology. In: In Proc. of SWeCKa 2007, Workshop on Semantic
  Web for Collaborative Knowledge Acquisition at IJCAI 2007. (January 2007)</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A UML based metamodel for Bunge-Wand-Weber (BWW) ontology is presented. BWW
ontology is a generic framework for analysis and conceptualization of real
world objects. It includes categories that can be applied to analyze and
classify objects found in an information system. In the context of BWW
ontology, the metamodel is a representation of the ontological categories and
relationships among them. An objective behind developing an object-oriented
metamodel has been to model BWW ontology in terms of widely used notions in
software development. The main contributions of this paper are a classification
for ontological categories, a description template, and representations through
UML and typed based models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3655</identifier>
 <datestamp>2010-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3655</id><created>2010-04-21</created><authors><author><keyname>Tasson</keyname><forenames>Christine</forenames><affiliation>PPS</affiliation></author><author><keyname>Vaux</keyname><forenames>Lionel</forenames><affiliation>IML</affiliation></author></authors><title>Transport of finiteness structures and applications</title><categories>cs.LO math.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a general construction of finiteness spaces which subsumes the
interpretations of all positive connectors of linear logic. We then show how to
apply this construction to prove the existence of least fixpoints for
particular functors in the category of finiteness spaces: these include the
functors involved in a relational interpretation of lazy recursive algebraic
datatypes along the lines of the coherence semantics of system T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3659</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3659</id><created>2010-04-21</created><authors><author><keyname>Erd&#xe9;lyi</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Fellows</keyname><forenames>Michael</forenames></author></authors><title>Parameterized Control Complexity in Fallback Voting</title><categories>cs.CC</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the parameterized control complexity of fallback voting, a voting
system that combines preference-based with approval voting. Electoral control
is one of many different ways for an external agent to tamper with the outcome
of an election. We show that adding and deleting candidates in fallback voting
are W[2]-hard for both the constructive and destructive case, parameterized by
the amount of action taken by the external agent. Furthermore, we show that
adding and deleting voters in fallback voting are W[2]-hard for the
constructive case, parameterized by the amount of action taken by the external
agent, and are in FPT for the destructive case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3668</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3668</id><created>2010-04-21</created><updated>2010-09-02</updated><authors><author><keyname>Nguyen</keyname><forenames>Viet Hung</forenames></author></authors><title>Approximating the minimum directed tree cover</title><categories>cs.DS cs.DM math.OC</categories><comments>13 pages</comments><msc-class>90C27, 90C59</msc-class><doi>10.1007/978-3-642-17461-2_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a directed graph $G$ with non negative cost on the arcs, a directed
tree cover of $G$ is a rooted directed tree such that either head or tail (or
both of them) of every arc in $G$ is touched by $T$. The minimum directed tree
cover problem (DTCP) is to find a directed tree cover of minimum cost. The
problem is known to be $NP$-hard. In this paper, we show that the weighted Set
Cover Problem (SCP) is a special case of DTCP. Hence, one can expect at best to
approximate DTCP with the same ratio as for SCP. We show that this expectation
can be satisfied in some way by designing a purely combinatorial approximation
algorithm for the DTCP and proving that the approximation ratio of the
algorithm is $\max\{2, \ln(D^+)\}$ with $D^+$ is the maximum outgoing degree of
the nodes in $G$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3687</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3687</id><created>2010-04-21</created><authors><author><keyname>Yomsi</keyname><forenames>Patrick Meumeu</forenames></author><author><keyname>Nelis</keyname><forenames>Vincent</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author></authors><title>Scheduling Multi-Mode Real-Time Systems upon Uniform Multiprocessor
  Platforms</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the scheduling problem of multi-mode real-time
systems upon uniform multiprocessor platforms. We propose two transition
protocols, specified together with their schedulability test, and provide the
reader with two distinct upper bounds for the length of the transient phases
during mode transitions, respectively for the cases where jobs priorities are
known and unknown beforehand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3692</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3692</id><created>2010-04-21</created><authors><author><keyname>Barbour</keyname><forenames>A. D.</forenames></author><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>Ioannis</forenames></author><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author></authors><title>Compound Poisson Approximation via Information Functionals</title><categories>math.PR cs.IT math.IT</categories><comments>27 pages</comments><journal-ref>Electronic Journal of Probability, Vol 15, Paper no. 42, pages
  1344-1369, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An information-theoretic development is given for the problem of compound
Poisson approximation, which parallels earlier treatments for Gaussian and
Poisson approximation. Let $P_{S_n}$ be the distribution of a sum $S_n=\Sumn
Y_i$ of independent integer-valued random variables $Y_i$. Nonasymptotic bounds
are derived for the distance between $P_{S_n}$ and an appropriately chosen
compound Poisson law. In the case where all $Y_i$ have the same conditional
distribution given $\{Y_i\neq 0\}$, a bound on the relative entropy distance
between $P_{S_n}$ and the compound Poisson distribution is derived, based on
the data-processing property of relative entropy and earlier Poisson
approximation results. When the $Y_i$ have arbitrary distributions,
corresponding bounds are derived in terms of the total variation distance. The
main technical ingredient is the introduction of two &quot;information functionals,&quot;
and the analysis of their properties. These information functionals play a role
analogous to that of the classical Fisher information in normal approximation.
Detailed comparisons are made between the resulting inequalities and related
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3702</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3702</id><created>2010-04-12</created><updated>2015-11-29</updated><authors><author><keyname>Du</keyname><forenames>Lizhi</forenames></author></authors><title>A Polynomial time Algorithm for Hamilton Cycle and Its detailed proof</title><categories>cs.DS</categories><comments>22 pages. This time, we did some revisions to make the proof easier
  to understand</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popular algorithms to find a Hamilton circle in an undirected graph are
generally based on the Rotation-Extension method developed by Posa. However,
due to the deficiencies of Posa's method, such algorithms are only efficient
for graphs that are either very dense or sparse but regular. This article
introduces a method called &quot;Enlarged Rotation-Extension&quot; that modifies and
extends Posa's method, overcoming its deficiencies. Based on this technique,
our algorithm is polynomial and we give a detailed proof for it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3708</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3708</id><created>2010-04-21</created><authors><author><keyname>Ji</keyname><forenames>Yongnan</forenames></author><author><keyname>Herve</keyname><forenames>Pierre-Yves</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Pitiot</keyname><forenames>Alain</forenames></author></authors><title>Parcellation of fMRI Datasets with ICA and PLS-A Data Driven Approach</title><categories>cs.CV cs.AI cs.NE</categories><comments>8 pages, 5 figures, P12th International Conference of Medical Image
  Computing and Computer-Assisted Intervention (MICCAI 2009)</comments><journal-ref>Proceedings of the 12th International Conference of Medical Image
  Computing and Computer-Assisted Intervention (MICCAI 2009), Part I, Lecture
  Notes in Computer Science 5761, London, UK, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inter-subject parcellation of functional Magnetic Resonance Imaging (fMRI)
data based on a standard General Linear Model (GLM)and spectral clustering was
recently proposed as a means to alleviate the issues associated with spatial
normalization in fMRI. However, for all its appeal, a GLM-based parcellation
approach introduces its own biases, in the form of a priori knowledge about the
shape of Hemodynamic Response Function (HRF) and task-related signal changes,
or about the subject behaviour during the task. In this paper, we introduce a
data-driven version of the spectral clustering parcellation, based on
Independent Component Analysis (ICA) and Partial Least Squares (PLS) instead of
the GLM. First, a number of independent components are automatically selected.
Seed voxels are then obtained from the associated ICA maps and we compute the
PLS latent variables between the fMRI signal of the seed voxels (which covers
regional variations of the HRF) and the principal components of the signal
across all voxels. Finally, we parcellate all subjects data with a spectral
clustering of the PLS latent variables. We present results of the application
of the proposed method on both single-subject and multi-subject fMRI datasets.
Preliminary experimental results, evaluated with intra-parcel variance of GLM
t-values and PLS derived t-values, indicate that this data-driven approach
offers improvement in terms of parcellation accuracy over GLM based techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3714</identifier>
 <datestamp>2013-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3714</id><created>2010-04-21</created><updated>2011-12-23</updated><authors><author><keyname>Chen</keyname><forenames>Yuxin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>An Upper Bound on Multi-hop Transmission Capacity with Dynamic Routing
  Selection</title><categories>cs.IT math.IT</categories><comments>14 pages, 5 figures, accepted to IEEE Transactions on Information
  Theory, 2012</comments><journal-ref>IEEE Transactions on Information Theory, vol.58, no.6,
  pp.3751-3765, June 2012</journal-ref><doi>10.1109/TIT.2012.2184843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops upper bounds on the end-to-end transmission capacity of
multi-hop wireless networks. Potential source-destination paths are dynamically
selected from a pool of randomly located relays, from which a closed-form lower
bound on the outage probability is derived in terms of the expected number of
potential paths. This is in turn used to provide an upper bound on the number
of successful transmissions that can occur per unit area, which is known as the
transmission capacity. The upper bound results from assuming independence among
the potential paths, and can be viewed as the maximum diversity case. A useful
aspect of the upper bound is its simple form for an arbitrary-sized network,
which allows insights into how the number of hops and other network parameters
affect spatial throughput in the non-asymptotic regime. The outage probability
analysis is then extended to account for retransmissions with a maximum number
of allowed attempts. In contrast to prevailing wisdom, we show that
predetermined routing (such as nearest-neighbor) is suboptimal, since more hops
are not useful once the network is interference-limited. Our results also make
clear that randomness in the location of relay sets and dynamically varying
channel states is helpful in obtaining higher aggregate throughput, and that
dynamic route selection should be used to exploit path diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3715</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3715</id><created>2010-04-21</created><authors><author><keyname>Lupu</keyname><forenames>Irina</forenames><affiliation>U.L.B</affiliation></author><author><keyname>Courbin</keyname><forenames>Pierre</forenames><affiliation>ECE</affiliation></author><author><keyname>George</keyname><forenames>Laurent</forenames><affiliation>ECE</affiliation></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames><affiliation>U.L.B</affiliation></author></authors><title>Multi-Criteria Evaluation of Partitioning Schemes for Real-Time Systems</title><categories>cs.OS</categories><journal-ref>IEEE International Conference on Emerging Technologies and Factory
  Automation, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the partitioning approach for multiprocessor real-time
scheduling. This approach seems to be the easiest since, once the partitioning
of the task set has been done, the problem reduces to well understood
uniprocessor issues. Meanwhile, there is no optimal and polynomial solution to
partition tasks on processors. In this paper we analyze partitioning algorithms
from several points of view such that for a given task set and specific
constraints (processor number, task set type, etc.) we should be able to
identify the best heuristic and the best schedulability test. We also analyze
the influence of the heuristics on the performance of the uniprocessor tests
and the impact of a specific task order on the schedulability. A study on
performance difference between Fixed Priority schedulers and EDF in the case of
partitioning scheduling is also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3716</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3716</id><created>2010-04-21</created><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author><author><keyname>Luk</keyname><forenames>Franklin T.</forenames></author><author><keyname>Kung</keyname><forenames>H. T.</forenames></author></authors><title>Some linear-time algorithms for systolic arrays</title><categories>cs.DS cs.DC math.NA</categories><comments>Corrected version of an old (1983) paper. 23 pages. For further
  details, see http://wwwmaths.anu.edu.au/~brent/pub/pub079.html</comments><report-no>Report TR-CS-82-15, DCS, Australian National University, December
  1982</report-no><msc-class>65Y05 (Primary) 37B15, 68Q10, 68Q80 (Secondary)</msc-class><acm-class>G.1.3; B.6.1; C.1.3</acm-class><journal-ref>Information Processing 83 (edited by R.E.A. Mason), North-Holland,
  Amsterdam, 1983, 865-876</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey some results on linear-time algorithms for systolic arrays. In
particular, we show how the greatest common divisor (GCD) of two polynomials of
degree n over a finite field can be computed in time O(n) on a linear systolic
array of O(n) cells; similarly for the GCD of two n-bit binary numbers. We show
how n * n Toeplitz systems of linear equations can be solved in time O(n) on a
linear array of O(n) cells, each of which has constant memory size (independent
of n). Finally, we outline how a two-dimensional square array of O(n)* O(n)
cells can be used to solve (to working accuracy) the eigenvalue problem for a
symmetric real n* n matrix in time O(nS(n)). Here S(n) is a slowly growing
function of n; for practical purposes S(n) can be regarded as a constant. In
addition to their theoretical interest, these results have potential
applications in the areas of error-correcting codes, symbolic and algebraic
computations, signal processing and image processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3719</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3719</id><created>2010-04-21</created><authors><author><keyname>Boyer</keyname><forenames>Brice</forenames><affiliation>LJK</affiliation></author><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Giorgi</keyname><forenames>Pascal</forenames><affiliation>LIRMM</affiliation></author></authors><title>Exact Sparse Matrix-Vector Multiplication on GPU's and Multicore
  Architectures</title><categories>cs.DC cs.MS cs.SC</categories><proxy>ccsd</proxy><journal-ref>International Symposium on Parallel Symbolic Computation, Grenoble
  : France (2010)</journal-ref><doi>10.1145/1837210.1837224</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose different implementations of the sparse matrix--dense vector
multiplication (\spmv{}) for finite fields and rings $\Zb/m\Zb$. We take
advantage of graphic card processors (GPU) and multi-core architectures. Our
aim is to improve the speed of \spmv{} in the \linbox library, and henceforth
the speed of its black box algorithms. Besides, we use this and a new
parallelization of the sigma-basis algorithm in a parallel block Wiedemann rank
implementation over finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3725</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3725</id><created>2010-04-21</created><authors><author><keyname>Kitagata</keyname><forenames>Manabu</forenames></author><author><keyname>Inoue</keyname><forenames>Jun-ichi</forenames></author></authors><title>A Gibbs distribution that learns from GA dynamics</title><categories>cs.NE</categories><comments>14 pages, 19 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general procedure of average-case performance evaluation for population
dynamics such as genetic algorithms (GAs) is proposed and its validity is
numerically examined. We introduce a learning algorithm of Gibbs distributions
from training sets which are gene configurations (strings) generated by GA in
order to figure out the statistical properties of GA from the view point of
thermodynamics. The learning algorithm is constructed by means of minimization
of the Kullback-Leibler information between a parametric Gibbs distribution and
the empirical distribution of gene configurations. The formulation is applied
to the solvable probabilistic models having multi-valley energy landscapes,
namely, the spin glass chain and the Sherrington-Kirkpatrick model. By using
computer simulations, we discuss the asymptotic behaviour of the effective
temperature scheduling and the residual energy induced by the GA dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3732</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3732</id><created>2010-04-21</created><updated>2010-06-06</updated><authors><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Liu</keyname><forenames>Chuang</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Solving the Cold-Start Problem in Recommender Systems with Social Tags</title><categories>cs.IR physics.soc-ph</categories><doi>10.1016/j.eswa.2012.03.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, based on the user-tag-object tripartite graphs, we propose a
recommendation algorithm, which considers social tags as an important role for
information retrieval. Besides its low cost of computational time, the
experiment results of two real-world data sets, \emph{Del.icio.us} and
\emph{MovieLens}, show it can enhance the algorithmic accuracy and diversity.
Especially, it can obtain more personalized recommendation results when users
have diverse topics of tags. In addition, the numerical results on the
dependence of algorithmic accuracy indicates that the proposed algorithm is
particularly effective for small degree objects, which reminds us of the
well-known \emph{cold-start} problem in recommender systems. Further empirical
study shows that the proposed algorithm can significantly solve this problem in
social tagging systems with heterogeneous object degree distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3742</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3742</id><created>2010-04-21</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Measson</keyname><forenames>Cyril</forenames></author><author><keyname>Richardson</keyname><forenames>Tom</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>Threshold Saturation on BMS Channels via Spatial Coupling</title><categories>cs.IT math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider spatially coupled code ensembles. A particular instance are
convolutional LDPC ensembles. It was recently shown that, for transmission over
the binary erasure channel, this coupling increases the belief propagation
threshold of the ensemble to the maximum a-priori threshold of the underlying
component ensemble. We report on empirical evidence which suggest that the same
phenomenon also occurs when transmission takes place over a general binary
memoryless symmetric channel. This is confirmed both by simulations as well as
by computing EBP GEXIT curves and by comparing the empirical BP thresholds of
coupled ensembles to the empirically determined MAP thresholds of the
underlying regular ensembles. We further consider ways of reducing the
rate-loss incurred by such constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3745</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3745</id><created>2010-04-21</created><authors><author><keyname>Moussa</keyname><forenames>M. Ibrahim</forenames><affiliation>Benha University, Benha, Egypt</affiliation></author></authors><title>An Algorithm for Odd Graceful Labeling of the Union of Paths and Cycles</title><categories>cs.IT cs.NI math.IT</categories><comments>9 Pages, JGraph-Hoc Journal</comments><report-no>0007736</report-no><msc-class>68</msc-class><acm-class>G.2; G.3; H.1.1</acm-class><journal-ref>Vol.2, No.1, March 2010</journal-ref><doi>10.5121/jgraphhoc.2010.2108</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In 1991, Gnanajothi [4] proved that the path graph P_n with n vertex and n-1
edge is odd graceful, and the cycle graph C_m with m vertex and m edges is odd
graceful if and only if m even, she proved the cycle graph is not graceful if m
odd. In this paper, firstly, we studied the graph C_m $\cup$ P_m when m = 4,
6,8,10 and then we proved that the graph C_ $\cup$ P_n is odd graceful if m is
even. Finally, we described an algorithm to label the vertices and the edges of
the vertex set V(C_m $\cup$ P_n) and the edge set E(C_m $\cup$ P_n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3755</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3755</id><created>2010-04-21</created><authors><author><keyname>Morgenshtern</keyname><forenames>Veniamin I.</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>The SIMO Pre-Log Can Be Larger Than the SISO Pre-Log</title><categories>cs.IT math.IT</categories><journal-ref>nformation Theory, 2009. ISIT 2009. IEEE International Symposium
  on , vol., no., pp.2174-2178, June 28 2009-July 3 2009</journal-ref><doi>10.1109/ISIT.2009.5205806</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a lower bound on the noncoherent capacity pre-log of a
temporally correlated Rayleigh block-fading single-input multiple-output (SIMO)
channel. Surprisingly, when the covariance matrix of the channel satisfies a
certain technical condition related to the cardinality of its smallest set of
linearly dependent rows, this lower bound reveals that the capacity pre-log in
the SIMO case is larger than that in the single-input single-output (SISO)
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3770</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3770</id><created>2010-04-21</created><updated>2010-09-30</updated><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Pythagorean Triples and Cryptographic Coding</title><categories>cs.CR math.HO</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper summarizes basic properties of PPTs and shows that each PPT
belongs to one of six different classes. Mapping an ordered sequence of PPTs
into a corresponding sequence of these six classes makes it possible to use
them in cryptography. We pose problems whose solution would facilitate such
cryptographic application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3774</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3774</id><created>2010-04-21</created><updated>2011-01-24</updated><authors><author><keyname>Couvreur</keyname><forenames>Alain</forenames></author></authors><title>Incidence structures from the blown-up plane and LDPC codes</title><categories>cs.IT math.AG math.CO math.IT</categories><comments>31 pages, 10 figures</comments><msc-class>51E99, 05B20, 94B27, 14H50</msc-class><journal-ref>IEEE, Trans. Inform. Theory, volume 57(7), Pages 4401 - 4416, 2011</journal-ref><doi>10.1109/TIT.2011.2146490</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, new regular incidence structures are presented. They arise
from sets of conics in the affine plane blown-up at its rational points. The
LDPC codes given by these incidence matrices are studied. These sparse
incidence matrices turn out to be redundant, which means that their number of
rows exceeds their rank. Such a feature is absent from random LDPC codes and is
in general interesting for the efficiency of iterative decoding. The
performance of some codes under iterative decoding is tested. Some of them turn
out to perform better than regular Gallager codes having similar rate and row
weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3777</identifier>
 <datestamp>2010-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3777</id><created>2010-04-21</created><authors><author><keyname>Austrin</keyname><forenames>Per</forenames></author></authors><title>Improved Inapproximability For Submodular Maximization</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that it is Unique Games-hard to approximate the maximum of a
submodular function to within a factor 0.695, and that it is Unique Games-hard
to approximate the maximum of a symmetric submodular function to within a
factor 0.739. These results slightly improve previous results by Feige,
Mirrokni and Vondr\'ak (FOCS 2007) who showed that these problems are NP-hard
to approximate to within $3/4 + \epsilon \approx 0.750$ and $5/6 + \epsilon
\approx 0.833$, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3782</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3782</id><created>2010-04-21</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author></authors><title>On Practical Algorithms for Entropy Estimation and the Improved Sample
  Complexity of Compressed Counting</title><categories>cs.DS stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the p-th frequency moment of data stream is a very heavily studied
problem. The problem is actually trivial when p = 1, assuming the strict
Turnstile model. The sample complexity of our proposed algorithm is essentially
O(1) near p=1. This is a very large improvement over the previously believed
O(1/eps^2) bound. The proposed algorithm makes the long-standing problem of
entropy estimation an easy task, as verified by the experiments included in the
appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3806</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3806</id><created>2010-04-21</created><authors><author><keyname>Wolper</keyname><forenames>James S.</forenames></author></authors><title>Information Theory and Quadrature Rules</title><categories>cs.IT math.IT math.NA</categories><msc-class>94A15, 65D32</msc-class><acm-class>H.1.1; G.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quadrature rules estimate the value of an integral when the function is given
by a table of values. Every binary string defines a quadrature rule by choosing
which endpoint of each interval represents the interval. The standard rules,
such as Simpson's Rule, correspond to strings of low Kolmogorov complexity,
making it possible to define new quadrature rules with no smoothness
assumptions, as well as in higher dimensions. Error results depend on concepts
from compressed sensing. Good quadrature rules exist for &quot;sparse&quot; functions,
which also satisfy an error--information duality principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3807</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3807</id><created>2010-04-21</created><updated>2010-11-08</updated><authors><author><keyname>Li</keyname><forenames>Liangbin</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>Interference Cancellation at the Relay for Multi-User Wireless
  Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transaction on Wireless Communication</comments><journal-ref>Wireless Communications, IEEE Transactions on , vol.10, no.3,
  pp.930-939, March 2011</journal-ref><doi>10.1109/TWC.2010.011111.100640</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study multi-user transmission and detection schemes for a multi-access
relay network (MARN) with linear constraints at all nodes. In a $(J, J_a, R_a,
M)$ MARN, $J$ sources, each equipped with $J_a$ antennas, communicate to one
$M$-antenna destination through one $R_a$-antenna relay. A new protocol called
IC-Relay-TDMA is proposed which takes two phases. During the first phase,
symbols of different sources are transmitted concurrently to the relay. At the
relay, interference cancellation (IC) techniques, previously proposed for
systems with direct transmission, are applied to decouple the information of
different sources without decoding. During the second phase, symbols of
different sources are forwarded to the destination in a time division
multi-access (TDMA) fashion. At the destination, the maximum-likelihood (ML)
decoding is performed source-by-source. The protocol of IC-Relay-TDMA requires
the number of relay antennas no less than the number of sources, i.e., $R_a\ge
J$. Through outage analysis, the achievable diversity gain of the proposed
scheme is shown to be $\min\{J_a(R_a-J+1),R_aM\}$. When {\small$M\le
J_a\left(1-\frac{J-1}{R_a}\right)$}, the proposed scheme achieves the maximum
interference-free (int-free) diversity gain $R_aM$. Since concurrent
transmission is allowed during the first phase, compared to full TDMA
transmission, the proposed scheme achieves the same diversity, but with a
higher symbol rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3808</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3808</id><created>2010-04-21</created><updated>2010-10-18</updated><authors><author><keyname>Hawblitzel</keyname><forenames>Chris</forenames><affiliation>Microsoft</affiliation></author><author><keyname>Petrank</keyname><forenames>Erez</forenames><affiliation>Technion</affiliation></author></authors><title>Automated Verification of Practical Garbage Collectors</title><categories>cs.PL</categories><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 3 (August 18,
  2010) lmcs:1039</journal-ref><doi>10.2168/LMCS-6(3:6)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Garbage collectors are notoriously hard to verify, due to their low-level
interaction with the underlying system and the general difficulty in reasoning
about reachability in graphs. Several papers have presented verified
collectors, but either the proofs were hand-written or the collectors were too
simplistic to use on practical applications. In this work, we present two
mechanically verified garbage collectors, both practical enough to use for
real-world C# benchmarks. The collectors and their associated allocators
consist of x86 assembly language instructions and macro instructions, annotated
with preconditions, postconditions, invariants, and assertions. We used the
Boogie verification generator and the Z3 automated theorem prover to verify
this assembly language code mechanically. We provide measurements comparing the
performance of the verified collector with that of the standard Bartok
collectors on off-the-shelf C# benchmarks, demonstrating their competitiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3809</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3809</id><created>2010-04-21</created><authors><author><keyname>Khalil</keyname><forenames>Khaled M.</forenames></author><author><keyname>Abdel-Aziz</keyname><forenames>M.</forenames></author><author><keyname>Nazmy</keyname><forenames>Taymour T.</forenames></author><author><keyname>Salem</keyname><forenames>Abdel-Badeeh M.</forenames></author></authors><title>Artificial Immune Systems Metaphor for Agent Based Modeling of Crisis
  Response Operations</title><categories>cs.MA cs.AI cs.CY</categories><comments>12 pages, 5 figures, and 5 tables. Submitted to MATES2010: Eighth
  German Conference on Multi-Agents System Technologies, September 21,
  2010-September 23, 2010 in Karlsruhe, Germany.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crisis response requires information intensive efforts utilized for reducing
uncertainty, calculating and comparing costs and benefits, and managing
resources in a fashion beyond those regularly available to handle routine
problems. This paper presents an Artificial Immune Systems (AIS) metaphor for
agent based modeling of crisis response operations. The presented model
proposes integration of hybrid set of aspects (multi-agent systems, built-in
defensive model of AIS, situation management, and intensity-based learning) for
crisis response operations. In addition, the proposed response model is applied
on the spread of pandemic influenza in Egypt as a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3811</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3811</id><created>2010-04-21</created><updated>2010-04-23</updated><authors><author><keyname>Blocki</keyname><forenames>Jeremiah</forenames></author><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Resolving the Complexity of Some Data Privacy Problems</title><categories>cs.CC cs.DB</categories><comments>Full Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formally study two methods for data sanitation that have been used
extensively in the database community: k-anonymity and l-diversity. We settle
several open problems concerning the difficulty of applying these methods
optimally, proving both positive and negative results:
  1. 2-anonymity is in P.
  2. The problem of partitioning the edges of a triangle-free graph into
4-stars (degree-three vertices) is NP-hard. This yields an alternative proof
that 3-anonymity is NP-hard even when the database attributes are all binary.
  3. 3-anonymity with only 27 attributes per record is MAX SNP-hard.
  4. For databases with n rows, k-anonymity is in O(4^n poly(n)) time for all k
&gt; 1.
  5. For databases with n rows and l &lt;= log_{2c+2} log n attributes over an
alphabet of cardinality c = O(1), k-anonymity is in P. Assuming c, l = O(1),
k-anonymity is in O(n).
  6. 3-diversity with binary attributes is NP-hard, with one sensitive
attribute.
  7. 2-diversity with binary attributes is NP-hard, with three sensitive
attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3814</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3814</id><created>2010-04-21</created><authors><author><keyname>Gupta</keyname><forenames>Mithun Das</forenames></author><author><keyname>Huang</keyname><forenames>Thomas S.</forenames></author></authors><title>Bregman Distance to L1 Regularized Logistic Regression</title><categories>cs.LG</categories><comments>8 pages, 3 images, shorter version published in ICPR 2008 by same
  authors.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we investigate the relationship between Bregman distances and
regularized Logistic Regression model. We present a detailed study of Bregman
Distance minimization, a family of generalized entropy measures associated with
convex functions. We convert the L1-regularized logistic regression into this
more general framework and propose a primal-dual method based algorithm for
learning the parameters. We pose L1-regularized logistic regression into
Bregman distance minimization and then apply non-linear constrained
optimization techniques to estimate the parameters of the logistic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3824</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3824</id><created>2010-04-21</created><authors><author><keyname>Biscani</keyname><forenames>Francesco</forenames></author><author><keyname>Izzo</keyname><forenames>Dario</forenames></author><author><keyname>Yam</keyname><forenames>Chit Hong</forenames></author></authors><title>A Global Optimisation Toolbox for Massively Parallel Engineering
  Optimisation</title><categories>cs.DC math.OC</categories><comments>To be presented at 'ICATT 2010: International Conference on
  Astrodynamics Tools and Techniques'</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A software platform for global optimisation, called PaGMO, has been developed
within the Advanced Concepts Team (ACT) at the European Space Agency, and was
recently released as an open-source project. PaGMO is built to tackle
high-dimensional global optimisation problems, and it has been successfully
used to find solutions to real-life engineering problems among which the
preliminary design of interplanetary spacecraft trajectories - both chemical
(including multiple flybys and deep-space maneuvers) and low-thrust (limited,
at the moment, to single phase trajectories), the inverse design of
nano-structured radiators and the design of non-reactive controllers for
planetary rovers. Featuring an arsenal of global and local optimisation
algorithms (including genetic algorithms, differential evolution, simulated
annealing, particle swarm optimisation, compass search, improved harmony
search, and various interfaces to libraries for local optimisation such as
SNOPT, IPOPT, GSL and NLopt), PaGMO is at its core a C++ library which employs
an object-oriented architecture providing a clean and easily-extensible
optimisation framework. Adoption of multi-threaded programming ensures the
efficient exploitation of modern multi-core architectures and allows for a
straightforward implementation of the island model paradigm, in which multiple
populations of candidate solutions asynchronously exchange information in order
to speed-up and improve the optimisation process. In addition to the C++
interface, PaGMO's capabilities are exposed to the high-level language Python,
so that it is possible to easily use PaGMO in an interactive session and take
advantage of the numerous scientific Python libraries available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3833</identifier>
 <datestamp>2011-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3833</id><created>2010-04-21</created><updated>2011-02-03</updated><authors><author><keyname>Al-Bashabsheh</keyname><forenames>Ali</forenames></author><author><keyname>Mao</keyname><forenames>Yongyi</forenames></author></authors><title>Normal Factor Graphs and Holographic Transformations</title><categories>cs.IT math.IT</categories><comments>To appear IEEE Trans. Inform. Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 2, Feb.
  2011, pp. 752-763</journal-ref><doi>10.1109/TIT.2010.2094870</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper stands at the intersection of two distinct lines of research. One
line is &quot;holographic algorithms,&quot; a powerful approach introduced by Valiant for
solving various counting problems in computer science; the other is &quot;normal
factor graphs,&quot; an elegant framework proposed by Forney for representing codes
defined on graphs. We introduce the notion of holographic transformations for
normal factor graphs, and establish a very general theorem, called the
generalized Holant theorem, which relates a normal factor graph to its
holographic transformation. We show that the generalized Holant theorem on the
one hand underlies the principle of holographic algorithms, and on the other
hand reduces to a general duality theorem for normal factor graphs, a special
case of which was first proved by Forney. In the course of our development, we
formalize a new semantics for normal factor graphs, which highlights various
linear algebraic properties that potentially enable the use of normal factor
graphs as a linear algebraic tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3842</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3842</id><created>2010-04-22</created><updated>2011-05-23</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Dalmau</keyname><forenames>Victor</forenames></author><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author><author><keyname>Pinsker</keyname><forenames>Michael</forenames></author></authors><title>Distance Constraint Satisfaction Problems</title><categories>cs.CC cs.LO math.LO</categories><comments>21 pages, 2 figures</comments><doi>10.1007/978-3-642-15155-2_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of constraint satisfaction problems for templates
Gamma that are first-order definable in (Z; succ), the integers with the
successor relation. Assuming a widely believed conjecture from finite domain
constraint satisfaction (we require the tractability conjecture by Bulatov,
Jeavons and Krokhin in the special case of transitive finite templates), we
provide a full classification for the case that Gamma is locally finite (i.e.,
the Gaifman graph of Gamma has finite degree). We show that one of the
following is true: The structure Gamma is homomorphically equivalent to a
structure with a certain majority polymorphism (which we call modular median)
and CSP(Gamma) can be solved in polynomial time, or Gamma is homomorphically
equivalent to a finite transitive structure, or CSP(Gamma) is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3878</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3878</id><created>2010-04-22</created><authors><author><keyname>Kuppinger</keyname><forenames>Patrick</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Where is Randomness Needed to Break the Square-Root Bottleneck?</title><categories>cs.IT math.IT</categories><comments>to appear at ISIT 2010, Austin, Texas</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As shown by Tropp, 2008, for the concatenation of two orthonormal bases
(ONBs), breaking the square-root bottleneck in compressed sensing does not
require randomization over all the positions of the nonzero entries of the
sparse coefficient vector. Rather the positions corresponding to one of the two
ONBs can be chosen arbitrarily. The two-ONB structure is, however, restrictive
and does not reveal the property that is responsible for allowing to break the
bottleneck with reduced randomness. For general dictionaries we show that if a
sub-dictionary with small enough coherence and large enough cardinality can be
isolated, the bottleneck can be broken under the same probabilistic model on
the sparse coefficient vector as in the two-ONB case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3884</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3884</id><created>2010-04-22</created><authors><author><keyname>Wilson</keyname><forenames>WIlliam</forenames></author><author><keyname>Birkin</keyname><forenames>Phil</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Oil Price Trackers Inspired by Immune Memory</title><categories>cs.AI cs.NE</categories><comments>2 pages, Workshop on Artificial Immune Systems and Immune System
  Modelling (AISB06), Bristol, UK</comments><journal-ref>Proceedings of the Workshop on Artificial Immune Systems and
  Immune System Modelling (AISB06), Bristol, UK, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We outline initial concepts for an immune inspired algorithm to evaluate and
predict oil price time series data. The proposed solution evolves a short term
pool of trackers dynamically, with each member attempting to map trends and
anticipate future price movements. Successful trackers feed into a long term
memory pool that can generalise across repeating trend patterns. The resulting
sequence of trackers, ordered in time, can be used as a forecasting tool.
Examination of the pool of evolving trackers also provides valuable insight
into the properties of the crude oil market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3887</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3887</id><created>2010-04-22</created><authors><author><keyname>Wilson</keyname><forenames>William</forenames></author><author><keyname>Birkin</keyname><forenames>Phil</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Motif Detection Inspired by Immune Memory</title><categories>cs.AI cs.NE q-bio.QM</categories><comments>12 pages, 4 figures, (ICARIS2007),</comments><journal-ref>Proceedings of the 6th International Conference on Artificial
  Immune Systems (ICARIS2007), Lecture Notes in Computer Science 4628, Santos,
  Brazil, 2007, p 276-287</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search for patterns or motifs in data represents an area of key interest
to many researchers. In this paper we present the Motif Tracking Algorithm, a
novel immune inspired pattern identification tool that is able to identify
variable length unknown motifs which repeat within time series data. The
algorithm searches from a completely neutral perspective that is independent of
the data being analysed and the underlying motifs. In this paper we test the
flexibility of the motif tracking algorithm by applying it to the search for
patterns in two industrial data sets. The algorithm is able to identify a
population of motifs successfully in both cases, and the value of these motifs
is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3890</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3890</id><created>2010-04-22</created><updated>2010-07-31</updated><authors><author><keyname>Ullah</keyname><forenames>Sana</forenames></author><author><keyname>Shen</keyname><forenames>Bin</forenames></author><author><keyname>Islam</keyname><forenames>S. M. Riazul</forenames></author><author><keyname>Khan</keyname><forenames>Pervez</forenames></author><author><keyname>Saleem</keyname><forenames>Shahnaz</forenames></author><author><keyname>Kwak</keyname><forenames>Kyung Sup</forenames></author></authors><title>A Study of Medium Access Control Protocols for Wireless Body Area
  Networks</title><categories>cs.NI</categories><comments>13 pages, 8 figures, 7 tables</comments><journal-ref>Sensors, vol. 10, no. 1, pp. 128-145, 2010</journal-ref><doi>10.3390/s100100128</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The seamless integration of low-power, miniaturised, invasive/non-invasive
lightweight sensor nodes have contributed to the development of a proactive and
unobtrusive Wireless Body Area Network (WBAN). A WBAN provides long-term health
monitoring of a patient without any constraint on his/her normal dailylife
activities. This monitoring requires low-power operation of
invasive/non-invasive sensor nodes. In other words, a power-efficient Medium
Access Control (MAC) protocol is required to satisfy the stringent WBAN
requirements including low-power consumption. In this paper, we first outline
the WBAN requirements that are important for the design of a low-power MAC
protocol. Then we study low-power MAC protocols proposed/investigated for WBAN
with emphasis on their strengths and weaknesses. We also review different
power-efficient mechanisms for WBAN. In addition, useful suggestions are given
to help the MAC designers to develop a low-power MAC protocol that will satisfy
the stringent WBAN requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3919</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3919</id><created>2010-04-22</created><authors><author><keyname>Al-Hammadi</keyname><forenames>Yousof</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author></authors><title>Performance Evaluation of DCA and SRC on a Single Bot Detection</title><categories>cs.AI cs.CR cs.NE</categories><comments>11 pages, 4 figures, 6 tables, Journal of Information Assurance and
  Security</comments><journal-ref>Journal of Information Assurance and Security, 5(1), p265-275,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malicious users try to compromise systems using new techniques. One of the
recent techniques used by the attacker is to perform complex distributed
attacks such as denial of service and to obtain sensitive data such as password
information. These compromised machines are said to be infected with malicious
software termed a &quot;bot&quot;. In this paper, we investigate the correlation of
behavioural attributes such as keylogging and packet flooding behaviour to
detect the existence of a single bot on a compromised machine by applying (1)
Spearman's rank correlation (SRC) algorithm and (2) the Dendritic Cell
Algorithm (DCA). We also compare the output results generated from these two
methods to the detection of a single bot. The results show that the DCA has a
better performance in detecting malicious activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3932</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3932</id><created>2010-04-21</created><authors><author><keyname>Garret</keyname><forenames>Simon</forenames></author><author><keyname>Robbins</keyname><forenames>Martin</forenames></author><author><keyname>Walker</keyname><forenames>Joanne</forenames></author><author><keyname>Wilson</keyname><forenames>William</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Modelling Immunological Memory</title><categories>cs.AI cs.NE q-bio.CB</categories><comments>26 pages, In Silico Immunology</comments><journal-ref>In Silico Immunology, 83-108, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate immunological models offer the possibility of performing
highthroughput experiments in silico that can predict, or at least suggest, in
vivo phenomena. In this chapter, we compare various models of immunological
memory. We first validate an experimental immunological simulator, developed by
the authors, by simulating several theories of immunological memory with known
results. We then use the same system to evaluate the predicted effects of a
theory of immunological memory. The resulting model has not been explored
before in artificial immune systems research, and we compare the simulated in
silico output with in vivo measurements. Although the theory appears valid, we
suggest that there are a common set of reasons why immunological memory models
are a useful support tool; not conclusive in themselves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3939</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3939</id><created>2010-04-22</created><authors><author><keyname>Wilson</keyname><forenames>William</forenames></author><author><keyname>Birkin</keyname><forenames>Phil</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Price Trackers Inspired by Immune Memory</title><categories>cs.AI cs.NE physics.data-an q-fin.PM</categories><comments>14 pages, 5 figures, 3 tables, 5th International Conference on
  Artificial Immune Systems (ICARIS2006)</comments><journal-ref>Proceedings of the 5th International Conference on Artificial
  Immune Systems (ICARIS2006), Lecture Notes in Computer Science 4163,
  p362-375, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we outline initial concepts for an immune inspired algorithm to
evaluate price time series data. The proposed solution evolves a short term
pool of trackers dynamically through a process of proliferation and mutation,
with each member attempting to map to trends in price movements. Successful
trackers feed into a long term memory pool that can generalise across repeating
trend patterns. Tests are performed to examine the algorithm's ability to
successfully identify trends in a small data set. The influence of the long
term memory pool is then examined. We find the algorithm is able to identify
price trends presented successfully and efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3966</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3966</id><created>2010-04-22</created><authors><author><keyname>Karimi</keyname><forenames>Mehdi</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>A Message-Passing Algorithm for Counting Short Cycles in a Graph</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Inform. Theory, April 21, 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A message-passing algorithm for counting short cycles in a graph is
presented. For bipartite graphs, which are of particular interest in coding,
the algorithm is capable of counting cycles of length g, g +2,..., 2g - 2,
where g is the girth of the graph. For a general (non-bipartite) graph, cycles
of length g; g + 1, ..., 2g - 1 can be counted. The algorithm is based on
performing integer additions and subtractions in the nodes of the graph and
passing extrinsic messages to adjacent nodes. The complexity of the proposed
algorithm grows as $O(g|E|^2)$, where $|E|$ is the number of edges in the
graph. For sparse graphs, the proposed algorithm significantly outperforms the
existing algorithms in terms of computational complexity and memory
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3980</identifier>
 <datestamp>2010-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3980</id><created>2010-04-22</created><authors><author><keyname>Gupta</keyname><forenames>Mithun Das</forenames></author></authors><title>Hashing Image Patches for Zooming</title><categories>cs.CV</categories><comments>7 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a Bayesian image zooming/super-resolution algorithm
based on a patch based representation. We work on a patch based model with
overlap and employ a Locally Linear Embedding (LLE) based approach as our data
fidelity term in the Bayesian inference. The image prior imposes continuity
constraints across the overlapping patches. We apply an error back-projection
technique, with an approximate cross bilateral filter. The problem of nearest
neighbor search is handled by a variant of the locality sensitive hashing (LSH)
scheme. The novelty of our work lies in the speed up achieved by the hashing
scheme and the robustness and inherent modularity and parallel structure
achieved by the LLE setup. The ill-posedness of the image reconstruction
problem is handled by the introduction of regularization priors which encode
the knowledge present in vast collections of natural images. We present
comparative results for both run-time as well as visual image quality based
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.3993</identifier>
 <datestamp>2015-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.3993</id><created>2010-04-22</created><authors><author><keyname>Doty</keyname><forenames>David</forenames></author></authors><title>An Oracle Strongly Separating Deterministic Time from Nondeterministic
  Time, via Kolmogorov Complexity</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hartmanis used Kolmogorov complexity to provide an alternate proof of the
classical result of Baker, Gill, and Solovay that there is an oracle relative
to which P is not NP. We refine the technique to strengthen the result,
constructing an oracle relative to which a conjecture of Lipton is false.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4005</identifier>
 <datestamp>2010-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4005</id><created>2010-04-22</created><updated>2010-06-04</updated><authors><author><keyname>Rabe</keyname><forenames>Markus</forenames></author><author><keyname>Schewe</keyname><forenames>Sven</forenames></author></authors><title>Finite Optimal Control for Time-Bounded Reachability in CTMDPs and
  Continuous-Time Markov Games</title><categories>cs.FL</categories><acm-class>G.3; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the existence of optimal scheduling strategies for time-bounded
reachability in continuous-time Markov decision processes, and of co-optimal
strategies for continuous-time Markov games. Furthermore, we show that optimal
control does not only exist, but has a surprisingly simple structure: The
optimal schedulers from our proofs are deterministic and timed-positional, and
the bounded time can be divided into a finite number of intervals, in which the
optimal strategies are positional. That is, we demonstrate the existence of
finite optimal control. Finally, we show that these pleasant properties of
Markov decision processes extend to the more general class of continuous-time
Markov games, and that both early and late schedulers show this behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4017</identifier>
 <datestamp>2013-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4017</id><created>2010-04-22</created><updated>2013-02-28</updated><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Smith</keyname><forenames>Adam</forenames></author></authors><title>Optimal-Rate Code Constructions for Computationally Simple Channels</title><categories>cs.IT cs.CC math.IT</categories><comments>39 pages,1 figure. This version presents a simpler and stronger
  result for time-bounded channels, which subsumes two results in the previous
  versions (for log-space and poly-time channels)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider coding schemes for computationally bounded channels, which can
introduce an arbitrary set of errors as long as (a) the fraction of errors is
bounded with high probability by a parameter $p$ and (b) the process which adds
the errors can be described by a sufficiently simple circuit. Codes for such
channel models are attractive since, like codes for standard adversarial
errors, they can handle channels whose true behavior is unknown or varying over
time.
  For two classes of channels, we provide explicit, efficiently
encodable/decodable codes of optimal rate where only inefficiently decodable
codes were previously known. In each case, we provide one encoder/decoder that
works for every channel in the class. The encoders are randomized, and
probabilities are taken over the (local, unknown to the decoder) coins of the
encoder and those of the channel.
  (1) Unique decoding for additive errors: We give the first construction of a
polynomial-time encodable/decodable code for additive (a.k.a. oblivious)
channels that achieve the Shannon capacity $1-H(p)$. These channels add an
arbitrary error vector $e\in\{0,1\}^N$ of weight at most $pN$ to the
transmitted word; the vector $e$ can depend on the code but not on the
particular transmitted word.
  (2) List-decoding for polynomial-time channels: For every constant $c&gt;0$, we
give a Monte Carlo construction of an code with optimal rate (arbitrarily close
to $1-H(p)$) that efficiently recovers a short list containing the correct
message with high probability for channels describable by circuits of size at
most $N^c$. We justify the relaxation to list-decoding by showing that even
with bounded channels, uniquely decodable codes cannot have positive rate for
$p&gt;1/4$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4020</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4020</id><created>2010-04-22</created><authors><author><keyname>Lechner</keyname><forenames>Gottfried</forenames></author><author><keyname>Pedersen</keyname><forenames>Troels</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Analysis and Design of Binary Message-Passing Decoders</title><categories>cs.IT math.IT</categories><comments>8 pages, 6 figures, submitted to the IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Binary message-passing decoders for low-density parity-check (LDPC) codes are
studied by using extrinsic information transfer (EXIT) charts. The channel
delivers hard or soft decisions and the variable node decoder performs all
computations in the L-value domain. A hard decision channel results in the
well-know Gallager B algorithm, and increasing the output alphabet from hard
decisions to two bits yields a gain of more than 1.0 dB in the required signal
to noise ratio when using optimized codes. The code optimization requires
adapting the mixing property of EXIT functions to the case of binary
message-passing decoders. Finally, it is shown that errors on cycles consisting
only of degree two and three variable nodes cannot be corrected and a necessary
and sufficient condition for the existence of a cycle-free subgraph is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4022</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4022</id><created>2010-04-22</created><authors><author><keyname>Lesov</keyname><forenames>Paul</forenames></author></authors><title>Database Security: A Historical Perspective</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of security in database research has greatly increased over
the years as most of critical functionality of the business and military
enterprises became digitized. Database is an integral part of any information
system and they often hold sensitive data. The security of the data depends on
physical security, OS security and DBMS security. Database security can be
compromised by obtaining sensitive data, changing data or degrading
availability of the database. Over the last 30 years the information technology
environment have gone through many changes of evolution and the database
research community have tried to stay a step ahead of the upcoming threats to
the database security. The database research community has thoughts about these
issues long before they were address by the implementations. This paper will
examine the different topics pertaining to database security and see the
adaption of the research to the changing environment. Some short term database
research trends will be ascertained at the conclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4024</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4024</id><created>2010-04-22</created><authors><author><keyname>Osipov</keyname><forenames>Vitaly</forenames></author><author><keyname>Sanders</keyname><forenames>Peter</forenames></author></authors><title>n-Level Graph Partitioning</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a multi-level graph partitioning algorithm based on the extreme
idea to contract only a single edge on each level of the hierarchy. This
obviates the need for a matching algorithm and promises very good partitioning
quality since there are very few changes between two levels. Using an efficient
data structure and new flexible ways to break local search improvements early,
we obtain an algorithm that scales to large inputs and produces the best known
partitioning results for many inputs. For example, in Walshaw's well known
benchmark tables we achieve 155 improvements dominating the entries for large
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4025</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4025</id><created>2010-04-22</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>Computers and the Conservation of Energy</title><categories>cs.CY</categories><comments>28 Pages, Five Figures, Three Tables; Dept. Computer Science, Brunel
  University, April 1980</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this report is to show that computer and allied technologies
can be used to increase energy efficiency. The report is divided into
transport, industrial, commercial and domestic sections, which correspond to
the major energy consuming sectors of the economy. Each section considers the
various ways in which energy can be saved by the use of the computer. The
report concludes that it is economic to incorporate computer based energy
management systems in a wide variety of applications and that it is important
that this capability is realised on a large scale. A comprehensive reference
list and a bibliography are included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4044</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4044</id><created>2010-04-22</created><authors><author><keyname>Som</keyname><forenames>Subhojit</forenames></author><author><keyname>Potter</keyname><forenames>Lee C</forenames></author></authors><title>Sparsity Pattern Recovery in Bernoulli-Gaussian Signal Model</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In compressive sensing, sparse signals are recovered from underdetermined
noisy linear observations. One of the interesting problems which attracted a
lot of attention in recent times is the support recovery or sparsity pattern
recovery problem. The aim is to identify the non-zero elements in the original
sparse signal. In this article we consider the sparsity pattern recovery
problem under a probabilistic signal model where the sparse support follows a
Bernoulli distribution and the signal restricted to this support follows a
Gaussian distribution. We show that the energy in the original signal
restricted to the missed support of the MAP estimate is bounded above and this
bound is of the order of energy in the projection of the noise signal to the
subspace spanned by the active coefficients. We also derive sufficient
conditions for no misdetection and no false alarm in support recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4057</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4057</id><created>2010-04-23</created><authors><author><keyname>Deshpande</keyname><forenames>Amit</forenames></author><author><keyname>Rademacher</keyname><forenames>Luis</forenames></author></authors><title>Efficient volume sampling for row/column subset selection</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give efficient algorithms for volume sampling, i.e., for picking
$k$-subsets of the rows of any given matrix with probabilities proportional to
the squared volumes of the simplices defined by them and the origin (or the
squared volumes of the parallelepipeds defined by these subsets of rows). This
solves an open problem from the monograph on spectral algorithms by Kannan and
Vempala. Our first algorithm for volume sampling $k$-subsets of rows from an
$m$-by-$n$ matrix runs in $O(kmn^{\omega} \log n)$ arithmetic operations and a
second variant of it for $(1+\epsilon)$-approximate volume sampling runs in
$O(mn \log m \cdot k^{2}/\epsilon^{2} + m \log^{\omega} m \cdot
k^{2\omega+1}/\epsilon^{2\omega} \cdot \log(k \epsilon^{-1} \log m))$
arithmetic operations, which is almost linear in the size of the input (i.e.,
the number of entries) for small $k$. Our efficient volume sampling algorithms
imply several interesting results for low-rank matrix approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4063</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4063</id><created>2010-04-23</created><updated>2011-06-17</updated><authors><author><keyname>Delmas</keyname><forenames>Olivier</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Gravier</keyname><forenames>Sylvain</forenames><affiliation>IF</affiliation></author><author><keyname>Montassier</keyname><forenames>Mickael</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Parreau</keyname><forenames>Aline</forenames><affiliation>IF</affiliation></author></authors><title>On two variations of identifying codes</title><categories>cs.DM cs.IT math.CO math.IT</categories><proxy>ccsd</proxy><journal-ref>Discrete Mathematics 311, 17 (2011) 1948-1956</journal-ref><doi>10.1016/j.disc.2011.05.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying codes have been introduced in 1998 to model fault-detection in
multiprocessor systems. In this paper, we introduce two variations of
identifying codes: weak codes and light codes. They correspond to
fault-detection by successive rounds. We give exact bounds for those two
definitions for the family of cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1004.4070</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1004.4070</id><created>2010-04-23</created><authors><author><keyname>Cheng</keyname><forenames>Jay</forenames></author><author><keyname>Chang</keyname><forenames>Cheng-Shang</forenames></author><author><keyname>Yang</keyname><forenames>Sheng-Hua</forenames></author><author><keyname>Chao</keyname><forenames>Tsz-Hsuan</forenames></author><author><keyname>Lee</keyname><forenames>Duan-Shin</forenames></author><author><keyname>Lien</keyname><forenames>Ching-Min</forenames></author></authors><title>Constructions of Optical Queues With a Limited Number of
  Recirculations--Part I: Greedy Constructions</title><categories>cs.IT math.IT math.NT</categories><comments>59 pages; 1 figure; This paper was presented in part at the IEEE
  International Conference on Computer Communications (INFOCOM'08), Phoenix,
  AZ, USA, April~13--18, 2008. This paper has been submitted to IEEE
  Transactions on Information Theory for possible publication.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this two-part paper, we consider SDL constructions of optical queues with
a limited number of recirculations through the optical switches and the fiber
delay lines. We show that the constructions of certain types of optical queues,
including linear compressors, linear decompressors, and 2-to-1 FIFO
multiplexers, under a simple packet routing scheme and under the constraint of
a limited number of recirculations can be transformed into equivalent integer
representation problems under a corresponding constraint. Given $M$ and $k$,
the problem of finding an \emph{optimal} construction, in the sense of
maximizing the maximum delay (resp., buffer size), among our constructions of
linear compressors/decompressors (resp., 2-to-1 FIFO multiplexers) is
equivalent to the problem of finding an optimal sequence ${\dbf^*}_1^M$ in
$\Acal_M$ (resp., $\Bcal_M$) such that $B({\dbf^*}_1^M;k)=\max_{\dbf_1^M\in
\Acal_M}B(\dbf_1^M;k)$ (resp., $B({\dbf^*}_1^M;k)=\max_{\dbf_1^M\in
\Bcal_M}B(\dbf_1^M;k)$), where $\Acal_M$ (resp., $\Bcal_M$) is the set of all
sequences of fiber delays allowed in our constructions of linear
compressors/decompressors (resp., 2-to-1 FIFO multiplexers). In Part I, we
propose a class of \emph{greedy} constructions of linear
compressors/decompressors and 2-to-1 FIFO multiplexers by specifying a class
$\Gcal_{M,k}$ of sequences such that $\Gcal_{M,k}\subseteq \Bcal_M\subseteq
\Acal_M$ and each sequence in $\Gcal_{M,k}$ is obtained recursively in a greedy
manner. We then show that every optimal construction must be a greedy
construction. In Part II, we further show that there are at most two optimal
constructions and give a simple algorithm to obtain the optimal
construction(s).
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="12000" completeListSize="102538">1122234|13001</resumptionToken>
</ListRecords>
</OAI-PMH>
