<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T01:01:32Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|33001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4866</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4866</id><created>2012-06-21</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>Portraits of Julius Caesar: a proposal for 3D analysis</title><categories>cs.CV</categories><comments>Key-words: Image processing, 3D Scanner, 3D visualization, Ancient
  Rome, Julius Caesar</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here I suggest the use of a 3D scanning and rendering to create some virtual
copies of ancient artifacts to study and compare them. In particular, this
approach could be interesting for some roman marble busts, two of which are
portraits of Julius Caesar, and the third is a realistic portrait of a man
recently found at Arles, France. The comparison of some images indicates that a
three-dimensional visualization is necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4880</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4880</id><created>2012-05-20</created><authors><author><keyname>Revathy</keyname><forenames>K.</forenames></author><author><keyname>Jayamohan</keyname><forenames>M.</forenames></author></authors><title>Dynamic Domain Classification for Fractal Image Compression</title><categories>cs.CV cs.GR</categories><comments>8 pages, 4 tables, 1 figure</comments><doi>10.5121/ijcsit.2012.4208</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractal image compression is attractive except for its high encoding time
requirements. The image is encoded as a set of contractive affine
transformations. The image is partitioned into non-overlapping range blocks,
and a best matching domain block larger than the range block is identified.
There are many attempts on improving the encoding time by reducing the size of
search pool for range-domain matching. But these methods are attempting to
prepare a static domain pool that remains unchanged throughout the encoding
process. This paper proposes dynamic preparation of separate domain pool for
each range block. This will result in significant reduction in the encoding
time. The domain pool for a particular range block can be selected based upon a
parametric value. Here we use classification based on local fractal dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4883</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4883</id><created>2012-06-21</created><authors><author><keyname>Elberrichi</keyname><forenames>Zakaria</forenames></author><author><keyname>Taibi</keyname><forenames>Malika</forenames></author><author><keyname>Belaggoun</keyname><forenames>Amel</forenames></author></authors><title>Multilingual Medical Documents Classification Based on MesH Domain
  Ontology</title><categories>cs.IR</categories><comments>IJCSI International Journal of Computer Science Issues, Vol. 9, Issue
  2, No 2, March 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article deals with the semantic Web and ontologies. It addresses the
issue of the classification of multilingual Web documents, based on domain
ontology. The objective is being able, using a model, to classify documents in
different languages. We will try to solve this problematic using two different
approaches. The two approaches will have two elementary stages: the creation of
the model using machine learning algorithms on a labeled corpus, then the
classification of documents after detecting their languages and mapping their
terms into the concepts of the language of reference (English). But each one
will deal with the multilingualism with a different approach. One supposes the
ontology is monolingual, whereas the other considers it multilingual. To show
the feasibility and the importance of our work, we implemented it on a domain
that attracts nowadays a lot of attention from the data mining community: the
biomedical domain. The selected documents are from the biomedical benchmark
corpus Ohsumed, and the associated ontology is the thesaurus MeSH (Medical
Subject Headings). The main idea in our work is a new document representation,
the masterpiece of all good classification, based on concept. The experimental
results show that the recommended ideas are promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4886</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4886</id><created>2012-06-21</created><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Guha</keyname><forenames>Saikat</forenames></author></authors><title>Information trade-offs for optical quantum communication</title><categories>quant-ph cs.IT math.IT</categories><comments>6 pages, 2 figures, see related, longer article at arXiv:1105.0119</comments><journal-ref>Physical Review Letters 108, 140501 (2012)</journal-ref><doi>10.1103/PhysRevLett.108.140501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has precisely characterized the achievable trade-offs between
three key information processing tasks---classical communication (generation or
consumption), quantum communication (generation or consumption), and shared
entanglement (distribution or consumption), measured in bits, qubits, and ebits
per channel use, respectively. Slices and corner points of this
three-dimensional region reduce to well-known protocols for quantum channels. A
trade-off coding technique can attain any point in the region and can
outperform time-sharing between the best-known protocols for accomplishing each
information processing task by itself. Previously, the benefits of trade-off
coding that had been found were too small to be of practical value (viz., for
the dephasing and the universal cloning machine channels). In this letter, we
demonstrate that the associated performance gains are in fact remarkably high
for several physically relevant bosonic channels that model free-space /
fiber-optic links, thermal-noise channels, and amplifiers. We show that
significant performance gains from trade-off coding also apply when trading
photon-number resources between transmitting public and private classical
information simultaneously over secret-key-assisted bosonic channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4898</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4898</id><created>2012-06-21</created><authors><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author><author><keyname>Sidiropoulos</keyname><forenames>Anastasios</forenames></author></authors><title>Planarizing an Unknown Surface</title><categories>cs.DS cs.CG</categories><comments>The conference version of this paper will appear in the Proceedings
  of APPROX 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been recently shown that any graph of genus g&gt;0 can be stochastically
embedded into a distribution over planar graphs, with distortion Olog (g+1))
[Sidiropoulos, FOCS 2010]. This embedding can be computed in polynomial time,
provided that a drawing of the input graph into a genus-g surface is given.
  We show how to compute the above embedding without having such a drawing.
This implies a general reduction for solving problems on graphs of small genus,
even when the drawing into a small genus surface is unknown. To the best of our
knowledge, this is the first result of this type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4900</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4900</id><created>2012-06-21</created><authors><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Robust Power System State Estimation for the Nonlinear AC Flow Model</title><categories>stat.AP cs.SY</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important monitoring task for power systems is accurate estimation of the
system operation state. Under the nonlinear AC power flow model, the state
estimation (SE) problem is inherently nonconvex giving rise to many local
optima. In addition to nonconvexity, SE is challenged by data integrity and
cyber-security issues. Unfortunately, existing robust (R-) SE schemes employed
routinely in practice rely on iterative solvers, which are sensitive to
initialization and cannot ensure global optimality. A novel R-SE approach is
formulated here by capitalizing on the sparsity of an overcomplete outlier
vector model. Observability and identifiability issues of this model are
investigated, and neat links are established between R-SE and error control
coding. The \emph{convex} semidefinite relaxation (SDR) technique is further
pursued to render the nonconvex R-SE problem efficiently solvable. The
resultant algorithm markedly outperforms existing iterative alternatives, as
corroborated through numerical tests on the standard IEEE 30-bus system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4912</identifier>
 <datestamp>2013-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4912</id><created>2012-06-21</created><updated>2013-09-26</updated><authors><author><keyname>Fomin</keyname><forenames>Fedor V.</forenames></author><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Michal</forenames></author></authors><title>Preprocessing Subgraph and Minor Problems: When Does a Small Vertex
  Cover Help?</title><categories>cs.DS cs.CC</categories><comments>To appear in the Journal of Computer and System Sciences</comments><msc-class>05C85, 68R10, 68W05</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a number of results around kernelization of problems parameterized
by the size of a given vertex cover of the input graph. We provide three sets
of simple general conditions characterizing problems admitting kernels of
polynomial size. Our characterizations not only give generic explanations for
the existence of many known polynomial kernels for problems like q-Coloring,
Odd Cycle Transversal, Chordal Deletion, Eta Transversal, or Long Path,
parameterized by the size of a vertex cover, but also imply new polynomial
kernels for problems like F-Minor-Free Deletion, which is to delete at most k
vertices to obtain a graph with no minor from a fixed finite set F.
  While our characterization captures many interesting problems, the
kernelization complexity landscape of parameterizations by vertex cover is much
more involved. We demonstrate this by several results about induced subgraph
and minor containment testing, which we find surprising. While it was known
that testing for an induced complete subgraph has no polynomial kernel unless
NP is in coNP/poly, we show that the problem of testing if a graph contains a
complete graph on t vertices as a minor admits a polynomial kernel. On the
other hand, it was known that testing for a path on t vertices as a minor
admits a polynomial kernel, but we show that testing for containment of an
induced path on t vertices is unlikely to admit a polynomial kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4914</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4914</id><created>2012-06-21</created><authors><author><keyname>Castrillon</keyname><forenames>Mario A.</forenames></author><author><keyname>Morero</keyname><forenames>Damian A.</forenames></author><author><keyname>Hueda</keyname><forenames>Mario R.</forenames></author></authors><title>Joint Demapping and Decoding for DQPSK Optical Coherent Receivers</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a low-complexity joint demapper-decoder scheme for coherent
optical receivers with DQPSK modulation. The new technique reduces to 0.7dB the
gap between QPSK and DQPSK in 100Gb/s coherent optical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4927</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4927</id><created>2012-06-21</created><updated>2015-01-26</updated><authors><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>CNRS and LIRMM, France</affiliation></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames><affiliation>CNRS and LIRMM, France</affiliation></author></authors><title>Topological arguments for Kolmogorov complexity</title><categories>cs.DM cs.CC cs.IT math.IT</categories><comments>Extended version</comments><proxy>EPTCS</proxy><acm-class>F.1.1; F.1.2; F.1.3</acm-class><doi>10.4204/EPTCS.90.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several application of simple topological arguments in problems of
Kolmogorov complexity. Basically we use the standard fact from topology that
the disk is simply connected. It proves to be enough to construct strings with
some nontrivial algorithmic properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4933</identifier>
 <datestamp>2014-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4933</id><created>2012-06-21</created><updated>2014-07-03</updated><authors><author><keyname>Inoue</keyname><forenames>Hiroyasu</forenames></author></authors><title>A two-layer team-assembly model for invention networks</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Companies are exposed to rigid competition, so they seek how best to improve
the capabilities of their innovations. One strategy is to collaborate with
other companies in order to speed up their own innovations. Such inter-company
collaborations are conducted by inventors belonging to the companies. At the
same time, the inventors also seem to be affected by past collaborations
between companies. Therefore, interdependency of two networks, namely inventor
and company networks, exists.
  This paper discusses a model that replicates two-layer networks extracted
from patent data of Japan and the United States in terms of degree
distributions. The model replicates two-layer networks with the
interdependency. Moreover it is the only model that uses local information,
while other models have to use overall information, which is unrealistic. In
addition, the proposed model replicates empirical data better than other
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4935</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4935</id><created>2012-06-21</created><updated>2012-07-29</updated><authors><author><keyname>Kupke</keyname><forenames>Clemens</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Kurz</keyname><forenames>Alexander</forenames><affiliation>University of Leicester</affiliation></author><author><keyname>Venema</keyname><forenames>Yde</forenames><affiliation>University of Amsterdam</affiliation></author></authors><title>Completeness for the coalgebraic cover modality</title><categories>cs.LO math.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, I.2.4, F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (July 31,
  2012) lmcs:896</journal-ref><doi>10.2168/LMCS-8(3:2)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the finitary version of the coalgebraic logic introduced by L. Moss.
The syntax of this logic, which is introduced uniformly with respect to a
coalgebraic type functor, required to preserve weak pullbacks, extends that of
classical propositional logic with a so-called coalgebraic cover modality
depending on the type functor. Its semantics is defined in terms of a
categorically defined relation lifting operation. As the main contributions of
our paper we introduce a derivation system, and prove that it provides a sound
and complete axiomatization for the collection of coalgebraically valid
inequalities. Our soundness and completeness proof is algebraic, and we employ
Pattinson's stratification method, showing that our derivation system can be
stratified in countably many layers, corresponding to the modal depth of the
formulas involved. In the proof of our main result we identify some new
concepts and obtain some auxiliary results of independent interest. We survey
properties of the notion of relation lifting, induced by an arbitrary but fixed
set functor. We introduce a category of Boolean algebra presentations, and
establish an adjunction between it and the category of Boolean algebras. Given
the fact that our derivation system involves only formulas of depth one, it can
be encoded as a endo-functor on Boolean algebras. We show that this functor is
finitary and preserves embeddings, and we prove that the Lindenbaum-Tarski
algebra of our logic can be identified with the initial algebra for this
functor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4952</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4952</id><created>2012-06-20</created><authors><author><keyname>Ahmed</keyname><forenames>Nesreen K.</forenames></author><author><keyname>Neville</keyname><forenames>Jennifer</forenames></author><author><keyname>Kompella</keyname><forenames>Ramana</forenames></author></authors><title>Space-Efficient Sampling from Social Activity Streams</title><categories>cs.SI cs.DB physics.soc-ph stat.AP</categories><comments>BigMine 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to efficiently study the characteristics of network domains and
support development of network systems (e.g. algorithms, protocols that operate
on networks), it is often necessary to sample a representative subgraph from a
large complex network. Although recent subgraph sampling methods have been
shown to work well, they focus on sampling from memory-resident graphs and
assume that the sampling algorithm can access the entire graph in order to
decide which nodes/edges to select. Many large-scale network datasets, however,
are too large and/or dynamic to be processed using main memory (e.g., email,
tweets, wall posts). In this work, we formulate the problem of sampling from
large graph streams. We propose a streaming graph sampling algorithm that
dynamically maintains a representative sample in a reservoir based setting. We
evaluate the efficacy of our proposed methods empirically using several
real-world data sets. Across all datasets, we found that our method produce
samples that preserve better the original graph distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4955</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4955</id><created>2012-06-21</created><authors><author><keyname>Ha</keyname><forenames>Bach Q.</forenames></author><author><keyname>Hartline</keyname><forenames>Jason D.</forenames></author></authors><title>The Biased Sampling Profit Extraction Auction</title><categories>cs.GT</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an auction for downward-closed environments that generalizes the
random sampling profit extraction auction for digital goods of Fiat et al.
(2002). The mechanism divides the agents in to a market and a sample using a
biased coin and attempts to extract the optimal revenue from the sample from
the market. The latter step is done with the downward-closed profit extractor
of Ha and Hartline (2012). The auction is a 11-approximation to the envyfree
benchmark in downward-closed permutation environments. This is an improvement
on the previously best known results of 12.5 for matroid and 30.4 for
downward-closed permutation environments that are due to Devanur et al. (2012)
and Ha and Hartline (2012), respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4958</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4958</id><created>2012-06-21</created><authors><author><keyname>Song</keyname><forenames>Peiyou</forenames></author><author><keyname>Shu</keyname><forenames>Anhei</forenames></author><author><keyname>Zhou</keyname><forenames>Anyu</forenames></author><author><keyname>Wallach</keyname><forenames>Dan</forenames></author><author><keyname>Crandall</keyname><forenames>Jedidiah R.</forenames></author></authors><title>A Pointillism Approach for Natural Language Processing of Social Media</title><categories>cs.IR cs.CL cs.SI</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Chinese language poses challenges for natural language processing based
on the unit of a word even for formal uses of the Chinese language, social
media only makes word segmentation in Chinese even more difficult. In this
document we propose a pointillism approach to natural language processing.
Rather than words that have individual meanings, the basic unit of a
pointillism approach is trigrams of characters. These grams take on meaning in
aggregate when they appear together in a way that is correlated over time.
  Our results from three kinds of experiments show that when words and topics
do have a meme-like trend, they can be reconstructed from only trigrams. For
example, for 4-character idioms that appear at least 99 times in one day in our
data, the unconstrained precision (that is, precision that allows for deviation
from a lexicon when the result is just as correct as the lexicon version of the
word or phrase) is 0.93. For longer words and phrases collected from
Wiktionary, including neologisms, the unconstrained precision is 0.87. We
consider these results to be very promising, because they suggest that it is
feasible for a machine to reconstruct complex idioms, phrases, and neologisms
with good precision without any notion of words. Thus the colorful and baroque
uses of language that typify social media in challenging languages such as
Chinese may in fact be accessible to machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4968</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4968</id><created>2012-06-21</created><authors><author><keyname>Akimoto</keyname><forenames>Youhei</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Auger</keyname><forenames>Anne</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Hansen</keyname><forenames>Nikolaus</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author></authors><title>Convergence of the Continuous Time Trajectories of Isotropic Evolution
  Strategies on Monotonic C^2-composite Functions</title><categories>cs.NE math.OC</categories><comments>PPSN - 12th International Conference on Parallel Problem Solving from
  Nature - 2012 (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Information-Geometric Optimization (IGO) has been introduced as a unified
framework for stochastic search algorithms. Given a parametrized family of
probability distributions on the search space, the IGO turns an arbitrary
optimization problem on the search space into an optimization problem on the
parameter space of the probability distribution family and defines a natural
gradient ascent on this space. From the natural gradients defined over the
entire parameter space we obtain continuous time trajectories which are the
solutions of an ordinary differential equation (ODE). Via discretization, the
IGO naturally defines an iterated gradient ascent algorithm. Depending on the
chosen distribution family, the IGO recovers several known algorithms such as
the pure rank-\mu update CMA-ES. Consequently, the continuous time
IGO-trajectory can be viewed as an idealization of the original algorithm. In
this paper we study the continuous time trajectories of the IGO given the
family of isotropic Gaussian distributions. These trajectories are a
deterministic continuous time model of the underlying evolution strategy in the
limit for population size to infinity and change rates to zero. On functions
that are the composite of a monotone and a convex-quadratic function, we prove
the global convergence of the solution of the ODE towards the global optimum.
We extend this result to composites of monotone and twice continuously
differentiable functions and prove local convergence towards local optima.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4969</identifier>
 <datestamp>2012-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4969</id><created>2012-06-21</created><updated>2012-11-08</updated><authors><author><keyname>van Gennip</keyname><forenames>Yves</forenames></author><author><keyname>Hunter</keyname><forenames>Blake</forenames></author><author><keyname>Ahn</keyname><forenames>Raymond</forenames></author><author><keyname>Elliott</keyname><forenames>Peter</forenames></author><author><keyname>Luh</keyname><forenames>Kyle</forenames></author><author><keyname>Halvorson</keyname><forenames>Megan</forenames></author><author><keyname>Reid</keyname><forenames>Shannon</forenames></author><author><keyname>Valasik</keyname><forenames>Matt</forenames></author><author><keyname>Wo</keyname><forenames>James</forenames></author><author><keyname>Tita</keyname><forenames>George E.</forenames></author><author><keyname>Bertozzi</keyname><forenames>Andrea L.</forenames></author><author><keyname>Brantingham</keyname><forenames>P. Jeffrey</forenames></author></authors><title>Community detection using spectral clustering on sparse geosocial data</title><categories>stat.AP cs.SI physics.soc-ph</categories><comments>22 pages, 6 figures (with subfigures)</comments><msc-class>62H30, 91C20, 91D30, 94C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we identify social communities among gang members in the
Hollenbeck policing district in Los Angeles, based on sparse observations of a
combination of social interactions and geographic locations of the individuals.
This information, coming from LAPD Field Interview cards, is used to construct
a similarity graph for the individuals. We use spectral clustering to identify
clusters in the graph, corresponding to communities in Hollenbeck, and compare
these with the LAPD's knowledge of the individuals' gang membership. We discuss
different ways of encoding the geosocial information using a graph structure
and the influence on the resulting clusterings. Finally we analyze the
robustness of this technique with respect to noisy and incomplete data, thereby
providing suggestions about the relative importance of quantity versus quality
of collected data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4973</identifier>
 <datestamp>2012-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4973</id><created>2012-06-21</created><authors><author><keyname>Chakroun</keyname><forenames>Imen</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Melab</keyname><forenames>Nouredine</forenames><affiliation>LIFL</affiliation></author></authors><title>An Adaptative Multi-GPU based Branch-and-Bound. A Case Study: the
  Flow-Shop Scheduling Problem</title><categories>cs.DC cs.RO</categories><comments>14th IEEE International Conference on High Performance Computing and
  Communications, HPCC 2012 (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solving exactly Combinatorial Optimization Problems (COPs) using a
Branch-and-Bound (B&amp;B) algorithm requires a huge amount of computational
resources. Therefore, we recently investigated designing B&amp;B algorithms on top
of graphics processing units (GPUs) using a parallel bounding model. The
proposed model assumes parallelizing the evaluation of the lower bounds on
pools of sub-problems. The results demonstrated that the size of the evaluated
pool has a significant impact on the performance of B&amp;B and that it depends
strongly on the problem instance being solved. In this paper, we design an
adaptative parallel B&amp;B algorithm for solving permutation-based combinatorial
optimization problems such as FSP (Flow-shop Scheduling Problem) on GPU
accelerators. To do so, we propose a dynamic heuristic for parameter
auto-tuning at runtime. Another challenge of this work is to exploit larger
degrees of parallelism by using the combined computational power of multiple
GPU devices. The approach has been applied to the permutation flow-shop
problem. Extensive experiments have been carried out on well-known FSP
benchmarks using an Nvidia Tesla S1070 Computing System equipped with two Tesla
T10 GPUs. Compared to a CPU-based execution, accelerations up to 105 are
achieved for large problem instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4976</identifier>
 <datestamp>2012-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4976</id><created>2012-06-21</created><updated>2012-08-31</updated><authors><author><keyname>Zeh</keyname><forenames>Alexander</forenames><affiliation>INRIA Saclay - Ile de France, INT - University of Ulm.</affiliation></author><author><keyname>Bezzateev</keyname><forenames>Sergey</forenames><affiliation>SUAI</affiliation></author></authors><title>A New Bound on the Minimum Distance of Cyclic Codes Using
  Small-Minimum-Distance Cyclic Codes</title><categories>cs.IT math.IT</categories><comments>Designs, Codes and Cryptography (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new bound on the minimum distance of q-ary cyclic codes is proposed. It is
based on the description by another cyclic code with small minimum distance.
The connection to the BCH bound and the Hartmann--Tzeng (HT) bound is
formulated explicitly. We show that for many cases our approach improves the HT
bound. Furthermore, we refine our bound for several families of cyclic codes.
We define syndromes and formulate a Key Equation that allows an efficient
decoding up to our bound with the Extended Euclidean Algorithm. It turns out
that lowest-code-rate cyclic codes with small minimum distances are useful for
our approach. Therefore, we give a sufficient condition for binary cyclic codes
of arbitrary length to have minimum distance two or three and lowest code-rate
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.4987</identifier>
 <datestamp>2012-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.4987</id><created>2012-06-21</created><authors><author><keyname>Orman</keyname><forenames>G&#xfc;nce</forenames><affiliation>Le2i, BIT Lab</affiliation></author><author><keyname>Labatut</keyname><forenames>Vincent</forenames><affiliation>Le2i</affiliation></author><author><keyname>Cherifi</keyname><forenames>Hocine</forenames><affiliation>Le2i</affiliation></author></authors><title>Comparative Evaluation of Community Detection Algorithms: A Topological
  Approach</title><categories>cs.SI physics.soc-ph</categories><proxy>ccsd</proxy><journal-ref>Journal of Statistical Mechanics: Theory and Experiment,
  (2012):P08001</journal-ref><doi>10.1088/1742-5468/2012/08/P08001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection is one of the most active fields in complex networks
analysis, due to its potential value in practical applications. Many works
inspired by different paradigms are devoted to the development of algorithmic
solutions allowing to reveal the network structure in such cohesive subgroups.
Comparative studies reported in the literature usually rely on a performance
measure considering the community structure as a partition (Rand Index,
Normalized Mutual information, etc.). However, this type of comparison neglects
the topological properties of the communities. In this article, we present a
comprehensive comparative study of a representative set of community detection
methods, in which we adopt both types of evaluation. Community-oriented
topological measures are used to qualify the communities and evaluate their
deviation from the reference structure. In order to mimic real-world systems,
we use artificially generated realistic networks. It turns out there is no
equivalence between both approaches: a high performance does not necessarily
correspond to correct topological properties, and vice-versa. They can
therefore be considered as complementary, and we recommend applying both of
them in order to perform a complete and accurate assessment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5021</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5021</id><created>2012-06-21</created><authors><author><keyname>Dobos</keyname><forenames>L&#xe1;szl&#xf3;</forenames></author><author><keyname>Budav&#xe1;ri</keyname><forenames>Tam&#xe1;s</forenames></author><author><keyname>Li</keyname><forenames>Nolan</forenames></author><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author><author><keyname>Csabai</keyname><forenames>Istv&#xe1;n</forenames></author></authors><title>SkyQuery: An Implementation of a Parallel Probabilistic Join Engine for
  Cross-Identification of Multiple Astronomical Databases</title><categories>cs.DB astro-ph.IM cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-wavelength astronomical studies require cross-identification of
detections of the same celestial objects in multiple catalogs based on
spherical coordinates and other properties. Because of the large data volumes
and spherical geometry, the symmetric N-way association of astronomical
detections is a computationally intensive problem, even when sophisticated
indexing schemes are used to exclude obviously false candidates. Legacy
astronomical catalogs already contain detections of more than a hundred million
objects while the ongoing and future surveys will produce catalogs of billions
of objects with multiple detections of each at different times. The varying
statistical error of position measurements, moving and extended objects, and
other physical properties make it necessary to perform the cross-identification
using a mathematically correct, proper Bayesian probabilistic algorithm,
capable of including various priors. One time, pair-wise cross-identification
of these large catalogs is not sufficient for many astronomical scenarios.
Consequently, a novel system is necessary that can cross-identify multiple
catalogs on-demand, efficiently and reliably. In this paper, we present our
solution based on a cluster of commodity servers and ordinary relational
databases. The cross-identification problems are formulated in a language based
on SQL, but extended with special clauses. These special queries are
partitioned spatially by coordinate ranges and compiled into a complex workflow
of ordinary SQL queries. Workflows are then executed in a parallel framework
using a cluster of servers hosting identical mirrors of the same data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5033</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5033</id><created>2012-06-21</created><updated>2013-02-21</updated><authors><author><keyname>Simpson-Porco</keyname><forenames>John W.</forenames></author><author><keyname>D&#xf6;rfler</keyname><forenames>Florian</forenames></author><author><keyname>Bullo</keyname><forenames>Francesco</forenames></author></authors><title>Synchronization and Power Sharing for Droop-Controlled Inverters in
  Islanded Microgrids</title><categories>math.OC cs.SY math.DS nlin.AO</categories><comments>10.5 Pages, 5 figures. Provisionally accepted for publication</comments><journal-ref>Automatica, Volume 49, Issue 9, September 2013, Pages 2603--2611</journal-ref><doi>10.1016/j.automatica.2013.05.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the recent and growing interest in smart grid technology, we
study the operation of DC/AC inverters in an inductive microgrid. We show that
a network of loads and DC/AC inverters equipped with power-frequency droop
controllers can be cast as a Kuramoto model of phase-coupled oscillators. This
novel description, together with results from the theory of coupled
oscillators, allows us to characterize the behavior of the network of inverters
and loads. Specifically, we provide a necessary and sufficient condition for
the existence of a synchronized solution that is unique and locally
exponentially stable. We present a selection of controller gains leading to a
desirable sharing of power among the inverters, and specify the set of loads
which can be serviced without violating given actuation constraints. Moreover,
we propose a distributed integral controller based on averaging algorithms
which dynamically regulates the system frequency in the presence of a
time-varying load. Remarkably, this distributed-averaging integral controller
has the additional property that it maintains the power sharing properties of
the primary droop controller. Our results hold without assumptions on identical
line characteristics or voltage magnitudes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5036</identifier>
 <datestamp>2012-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5036</id><created>2012-06-21</created><updated>2012-09-06</updated><authors><author><keyname>Yuan</keyname><forenames>Lin</forenames></author><author><keyname>Kirshner</keyname><forenames>Sergey</forenames></author><author><keyname>Givan</keyname><forenames>Robert</forenames></author></authors><title>Estimating Densities with Non-Parametric Exponential Families</title><categories>stat.ML cs.LG</categories><comments>22 pages, 5 figures</comments><report-no>TR12-02, Department of Statistics, Purdue University</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel approach for density estimation with exponential families
for the case when the true density may not fall within the chosen family. Our
approach augments the sufficient statistics with features designed to
accumulate probability mass in the neighborhood of the observed points,
resulting in a non-parametric model similar to kernel density estimators. We
show that under mild conditions, the resulting model uses only the sufficient
statistics if the density is within the chosen exponential family, and
asymptotically, it approximates densities outside of the chosen exponential
family. Using the proposed approach, we modify the exponential random graph
model, commonly used for modeling small-size graph distributions, to address
the well-known issue of model degeneracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5048</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5048</id><created>2012-06-21</created><authors><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author></authors><title>The Planetary Project: Towards eMath3.0</title><categories>cs.DL</categories><comments>Intelligent Computer Mathematics, Johan Jeuring, John A. Campbell,
  Jacques Carette, Gabriel Dos Reis, Petr Sojka, Makarius Wenzel, and Volker
  Sorge, eds, Springer Verlag LNAI 7362, 2012</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The Planetary project develops a general framework - the Planetary system -
for social semantic portals that support users in interacting with STEM
(Science/Technology/Engineering/Mathematics) documents. Developed from an
initial attempt to replace the aging portal of PlanetMath.org with a mashup of
existing MKM technologies, the Planetary system is now in a state, where it can
serve as a basis for various eMath3.0 portals, ranging from eLearning systems
over scientific archives to semantic help systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5054</identifier>
 <datestamp>2012-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5054</id><created>2012-06-22</created><updated>2012-12-17</updated><authors><author><keyname>Yun</keyname><forenames>Se-Young</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author></authors><title>Medium Access over Time-varying Channels with Limited Sensing Cost</title><categories>cs.NI</categories><comments>This paper has been withdrawn because of some paper issues</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn because of some paper issues. Recent studies on
MAC scheduling have shown that carrier sense multiple access (CSMA) can be
controlled to be achieve optimality in terms of throughput or utility. These
results imply that just a simple MAC algorithm without message passing is
possible to achieve high performance guarantee. However, such studies are
conducted only on the assumption that channel conditions are static. Noting
that the main drive for achieving optimality in optimal CSMA is to let it run a
good schedule for some time, formally referred to as the mixing time, it is
under-explored how such optimal CSMA performs for time-varying channel
conditions. In this paper, under the practical constraint of restricted
back-off rates (i.e., limited sensing speed), we consider two versions of
CSMAs: (i) channel-unaware CSMA (U-CSMA) and (ii) channel-aware CSMA (A-CSMA),
each of which is characterized as its ability of tracking channel conditions.
We first show that for fast channel variations, A-CSMA achieves almost zero
throughput, implying that incomplete tracking of channel conditions may
seriously degrade performance, whereas U-CSMA, accessing the media without
explicit consideration of channel conditions, has positive worst-case guarantee
in throughput, where the ratio of guarantee depends on network topology. On the
other hand, for slow channel variations, we prove that A-CSMA is
throughput-optimal for any network topology. Our results provide the precise
trade-off between sensing costs and performances of CSMA algorithms, which
guides a robust design on MAC scheduling under highly time-varying scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5057</identifier>
 <datestamp>2012-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5057</id><created>2012-06-22</created><updated>2012-10-11</updated><authors><author><keyname>Gao</keyname><forenames>Qinghuai</forenames></author></authors><title>The Robustness and Super-Robustness of L^p Estimation, when p &lt; 1</title><categories>cs.LG math.ST stat.TH</categories><comments>In v4, fix the issues in the proof of the general cases: proof the
  strict robustness on translation when di has general or uniform distribution.
  Format changes in v5</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In robust statistics, the breakdown point of an estimator is the percentage
of outliers with which an estimator still generates reliable estimation. The
upper bound of breakdown point is 50%, which means it is not possible to
generate reliable estimation with more than half outliers.
  In this paper, it is shown that for majority of experiences, when the
outliers exceed 50%, but if they are distributed randomly enough, it is still
possible to generate a reliable estimation from minority good observations. The
phenomenal of that the breakdown point is larger than 50% is named as super
robustness. And, in this paper, a robust estimator is called strict robust if
it generates a perfect estimation when all the good observations are perfect.
  More specifically, the super robustness of the maximum likelihood estimator
of the exponential power distribution, or L^p estimation, where p&lt;1, is
investigated. This paper starts with proving that L^p (p&lt;1) is a strict robust
location estimator. Further, it is proved that L^p (p &lt; 1)has the property of
strict super-robustness on translation, rotation, scaling transformation and
robustness on Euclidean transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5065</identifier>
 <datestamp>2013-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5065</id><created>2012-06-22</created><authors><author><keyname>Zaidenberg</keyname><forenames>Sofia</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Boulay</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Bremond</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>A generic framework for video understanding applied to group behavior
  recognition</title><categories>cs.CV</categories><comments>(20/03/2012)</comments><proxy>ccsd</proxy><journal-ref>9th IEEE International Conference on Advanced Video and
  Signal-Based Surveillance (AVSS 2012) (2012) 136 -142</journal-ref><doi>10.1109/AVSS.2012.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approach to detect and track groups of people in
video-surveillance applications, and to automatically recognize their behavior.
This method keeps track of individuals moving together by maintaining a spacial
and temporal group coherence. First, people are individually detected and
tracked. Second, their trajectories are analyzed over a temporal window and
clustered using the Mean-Shift algorithm. A coherence value describes how well
a set of people can be described as a group. Furthermore, we propose a formal
event description language. The group events recognition approach is
successfully validated on 4 camera views from 3 datasets: an airport, a subway,
a shopping center corridor and an entrance hall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5082</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5082</id><created>2012-06-22</created><updated>2013-05-05</updated><authors><author><keyname>Liu</keyname><forenames>Ching-Hao</forenames></author><author><keyname>Kloks</keyname><forenames>Ton</forenames></author><author><keyname>Poon</keyname><forenames>Sheung-Hung</forenames></author></authors><title>Independent sets in edge-clique graphs II</title><categories>math.CO cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:1206.1993</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that edge-clique graphs of cocktail party graphs have unbounded
rankwidth. This, and other observations lead us to conjecture that the
edge-clique cover problem is NP-complete for cographs. We show that the
independent set problem on edge-clique graphs of cographs. We show that the
independent set problem on edge-clique graphs of graphs without odd wheels
remains NP-complete. We present a PTAS for planar graphs and show that the
problem is polynomial for planar graphs without triangle separators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5102</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5102</id><created>2012-06-22</created><authors><author><keyname>Volant</keyname><forenames>Stevenn</forenames></author><author><keyname>B&#xe9;rard</keyname><forenames>Caroline</forenames></author><author><keyname>Martin-Magniette</keyname><forenames>Marie-Laure</forenames></author><author><keyname>Robin</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Hidden Markov Models with mixtures as emission distributions</title><categories>stat.ML cs.LG stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In unsupervised classification, Hidden Markov Models (HMM) are used to
account for a neighborhood structure between observations. The emission
distributions are often supposed to belong to some parametric family. In this
paper, a semiparametric modeling where the emission distributions are a mixture
of parametric distributions is proposed to get a higher flexibility. We show
that the classical EM algorithm can be adapted to infer the model parameters.
For the initialisation step, starting from a large number of components, a
hierarchical method to combine them into the hidden states is proposed. Three
likelihood-based criteria to select the components to be combined are
discussed. To estimate the number of hidden states, BIC-like criteria are
derived. A simulation study is carried out both to determine the best
combination between the merging criteria and the model selection criteria and
to evaluate the accuracy of classification. The proposed method is also
illustrated using a biological dataset from the model plant Arabidopsis
thaliana. A R package HMMmix is freely available on the CRAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5104</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5104</id><created>2012-06-22</created><authors><author><keyname>Costa</keyname><forenames>Ulisses Araujo</forenames></author><author><keyname>da Cruz</keyname><forenames>Daniela</forenames></author><author><keyname>Henriques</keyname><forenames>Pedro Rangel</forenames></author></authors><title>Automatic Test Generation for Space</title><categories>cs.SE</categories><acm-class>D.2.5</acm-class><doi>10.4230/OASIcs.SLATE.2012.185</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The European Space Agency (ESA) uses an engine to perform tests in the Ground
Segment infrastructure, specially the Operational Simulator. This engine uses
many different tools to ensure the development of regression testing
infrastructure and these tests perform black-box testing to the C++ simulator
implementation. VST (VisionSpace Technologies) is one of the companies that
provides these services to ESA and they need a tool to infer automatically
tests from the existing C++ code, instead of writing manually scripts to
perform tests. With this motivation in mind, this paper explores automatic
testing approaches and tools in order to propose a system that satisfies VST
needs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5106</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5106</id><created>2012-06-22</created><authors><author><keyname>Enright</keyname><forenames>Jessica</forenames></author><author><keyname>Stewart</keyname><forenames>Lorna</forenames></author><author><keyname>Tardos</keyname><forenames>Gabor</forenames></author></authors><title>On List Colouring and List Homomorphism of Permutation and Interval
  Graphs</title><categories>cs.DM</categories><msc-class>05C15, 05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  List colouring is an NP-complete decision problem even if the total number of
colours is three. It is hard even on planar bipartite graphs. We give a
polynomial-time algorithm for solving list colouring of permutation graphs with
a bounded total number of colours. More generally we give a polynomial-time
algorithm that solves the list-homomorphism problem to any fixed target graph
for a large class of input graphs including all permutation and interval
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5112</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5112</id><created>2012-06-22</created><authors><author><keyname>Bono</keyname><forenames>Viviana</forenames></author><author><keyname>Benke</keyname><forenames>Marcin</forenames></author><author><keyname>Schubert</keyname><forenames>Aleksy</forenames></author></authors><title>Lucretia - a type system for objects in languages with reflection</title><categories>cs.PL cs.LO</categories><comments>21 pages</comments><acm-class>F.3.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented scripting languages such as JavaScript or Python gain in
popularity due to their flexibility. Still, the growing code bases written in
the languages call for methods that make possible to automatically control the
properties of the programs that ensure their stability in the running time. We
propose a type system, called Lucretia, that makes possible to control the
object structure of languages with reflection. Subject reduction and soundness
of the type system with respect to the semantics of the language is proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5120</identifier>
 <datestamp>2013-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5120</id><created>2012-06-22</created><updated>2013-10-15</updated><authors><author><keyname>Meunier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Pradeau</keyname><forenames>Thomas</forenames></author></authors><title>The uniqueness property for networks with several origin-destination
  pairs</title><categories>cs.GT</categories><comments>21 pages, 10 figures</comments><msc-class>91A10, 91A43, 05C57</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider congestion games on networks with nonatomic users and
user-specific costs. We are interested in the uniqueness property defined by
Milchtaich [Milchtaich, I. 2005. Topological conditions for uniqueness of
equilibrium in networks. Math. Oper. Res. 30 225-244] as the uniqueness of
equilibrium flows for all assignments of strictly increasing cost functions. He
settled the case with two-terminal networks. As a corollary of his result, it
is possible to prove that some other networks have the uniqueness property as
well by adding common fictitious origin and destination.
  In the present work, we find a necessary condition for networks with several
origin-destination pairs to have the uniqueness property in terms of excluded
minors or subgraphs. As a key result, we characterize completely bidirectional
rings for which the uniqueness property holds: it holds precisely for nine
networks and those obtained from them by elementary operations. For other
bidirectional rings, we exhibit affine cost functions yielding to two distinct
equilibrium flows. Related results are also proven. For instance, we
characterize networks having the uniqueness property for any choice of
origin-destination pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5124</identifier>
 <datestamp>2015-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5124</id><created>2012-06-22</created><updated>2015-10-21</updated><authors><author><keyname>M&#xe1;rquez-Corbella</keyname><forenames>Irene</forenames></author><author><keyname>Mart&#xed;nez-Moro</keyname><forenames>Edgar</forenames></author><author><keyname>Su&#xe1;rez-Canedo</keyname><forenames>Emilio</forenames></author></authors><title>On the ideal associated to a linear code</title><categories>cs.IT math.AC math.CO math.IT</categories><msc-class>13P10, 94B05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article aims to explore the bridge between the algebraic structure of a
linear code and the complete decoding process. To this end, we associate a
specific binomial ideal $I_+(\mathcal C)$ to an arbitrary linear code. The
binomials involved in the reduced Gr\&quot;obner basis of such an ideal relative to
a degree-compatible ordering induce a uniquely defined test-set for the code,
and this allows the description of a Hamming metric decoding procedure.
Moreover, the binomials involved in the Graver basis of $I_+(\mathcal C)$
provide a universal test-set which turns out to be a set containing the set of
codewords of minimal support of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5132</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5132</id><created>2012-06-22</created><updated>2012-09-20</updated><authors><author><keyname>Wasif</keyname><forenames>M. Nisar</forenames></author><author><keyname>Munir</keyname><forenames>Ehsan Ullah</forenames></author><author><keyname>Shad</keyname><forenames>Shafqat Ali</forenames></author></authors><title>Usage and Impact of ICT in Education Sector; A Study of Pakistan</title><categories>cs.OH</categories><journal-ref>Australian Journal of Basic and Applied Sciences, 5, 12, (2011)
  578-583</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many countries, information and communication technology (ICT) has a lucid
impact on the development of educational curriculum. This is the era of
Information Communication Technology, so to perk up educational planning it is
indispensable to implement the ICT in Education sector. Student can perform
well throughout the usage of ICT. ICT helps the students to augment their
knowledge skills as well as to improve their learning skills. To know with
reference to the usage and Impact of ICT in Education sector of Pakistan, we
accumulate data from 429 respondents from 5 colleges and universities, we use
convenient sampling to accumulate the data from district Rawalpindi of
Pakistan. The consequences show that Availability and Usage of ICT improves the
knowledge and learning skills of students. This indicates that existence of ICT
is improving the educational efficiency as well as obliging for making policies
regarding education sector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5135</identifier>
 <datestamp>2013-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5135</id><created>2012-06-22</created><authors><author><keyname>Lord</keyname><forenames>Phillip</forenames></author><author><keyname>Cockell</keyname><forenames>Simon</forenames></author><author><keyname>Stevens</keyname><forenames>Robert</forenames></author></authors><title>Three Steps to Heaven: Semantic Publishing in a Real World Workflow</title><categories>cs.DL</categories><comments>Published as part of SePublica 2012</comments><doi>10.3390/fi4041004</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Semantic publishing offers the promise of computable papers, enriched
visualisation and a realisation of the linked data ideal. In reality, however,
the publication process contrives to prevent richer semantics while culminating
in a `lumpen' PDF. In this paper, we discuss a web-first approach to
publication, and describe a three-tiered approach which integrates with the
existing authoring tooling. Critically, although it adds limited semantics, it
does provide value to all the participants in the process: the author, the
reader and the machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5144</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5144</id><created>2012-06-22</created><authors><author><keyname>Hong</keyname><forenames>Mingyi</forenames></author><author><keyname>Luo</keyname><forenames>Zhi-Quan</forenames></author></authors><title>Signal Processing and Optimal Resource Allocation for the Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>To appear in E-Reference Signal Processing, R. Chellapa and S.
  Theodoridis, Eds., Elsevier, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we examine several design and complexity aspects of the
optimal physical layer resource allocation problem for a generic interference
channel (IC). The latter is a natural model for multi-user communication
networks. In particular, we characterize the computational complexity, the
convexity as well as the duality of the optimal resource allocation problem.
Moreover, we summarize various existing algorithms for resource allocation and
discuss their complexity and performance tradeoff. We also mention various open
research problems throughout the article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5157</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5157</id><created>2012-06-22</created><authors><author><keyname>Katyal</keyname><forenames>Vini</forenames></author><author><keyname>Aviral</keyname></author></authors><title>Leaf vein segmentation using Odd Gabor filters and morphological
  operations</title><categories>cs.CV cs.AI</categories><comments>International Journal of Advanced Research in Computer Science Volume
  3, No. 3, May-June 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leaf vein forms the basis of leaf characterization and classification.
Different species have different leaf vein patterns. It is seen that leaf vein
segmentation will help in maintaining a record of all the leaves according to
their specific pattern of veins thus provide an effective way to retrieve and
store information regarding various plant species in database as well as
provide an effective means to characterize plants on the basis of leaf vein
structure which is unique for every species. The algorithm proposes a new way
of segmentation of leaf veins with the use of Odd Gabor filters and the use of
morphological operations for producing a better output. The Odd Gabor filter
gives an efficient output and is robust and scalable as compared with the
existing techniques as it detects the fine fiber like veins present in leaves
much more efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5159</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5159</id><created>2012-06-22</created><authors><author><keyname>Chaplick</keyname><forenames>Steven</forenames></author><author><keyname>Jel&#xed;nek</keyname><forenames>V&#xed;t</forenames></author><author><keyname>Kratochv&#xed;l</keyname><forenames>Jan</forenames></author><author><keyname>Vysko&#x10d;il</keyname><forenames>Tom&#xe1;&#x161;</forenames></author></authors><title>Bend-Bounded Path Intersection Graphs: Sausages, Noodles, and Waffles on
  a Grill</title><categories>cs.CG cs.DM math.CO</categories><comments>17 pages, 14 figures, to appear in the proceedings of WG 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study properties of intersection graphs of k-bend paths in
the rectangular grid. A k-bend path is a path with at most k 90 degree turns.
The class of graphs representable by intersections of k-bend paths is denoted
by B_k-VPG. We show here that for every fixed k, B_k-VPG is a proper subset of
B_{k+1}-VPG and that recognition of graphs from B_k-VPG is NP-complete even
when the input graph is given by a B_{k+1}-VPG representation. We also show
that the class B_k-VPG (for k&gt;0) is in no inclusion relation with the class of
intersection graphs of straight line segments in the plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5162</identifier>
 <datestamp>2012-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5162</id><created>2012-06-22</created><updated>2012-12-04</updated><authors><author><keyname>Hensman</keyname><forenames>James</forenames></author><author><keyname>Rattray</keyname><forenames>Magnus</forenames></author><author><keyname>Lawrence</keyname><forenames>Neil D.</forenames></author></authors><title>Fast Variational Inference in the Conjugate Exponential Family</title><categories>cs.LG stat.ML</categories><comments>Accepted at NIPS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general method for deriving collapsed variational inference
algo- rithms for probabilistic models in the conjugate exponential family. Our
method unifies many existing approaches to collapsed variational inference. Our
collapsed variational inference leads to a new lower bound on the marginal
likelihood. We exploit the information geometry of the bound to derive much
faster optimization methods based on conjugate gradients for these models. Our
approach is very general and is easily applied to any model where the mean
field update equations have been derived. Empirically we show significant
speed-ups for probabilistic models optimized using our bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5166</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5166</id><created>2012-06-22</created><authors><author><keyname>Ameller</keyname><forenames>David</forenames></author><author><keyname>Franch</keyname><forenames>Xavier</forenames></author></authors><title>Linking Quality Attributes and Constraints with Architectural Decisions</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality attributes and constraints are among the main drivers of
architectural decision making. The quality attributes are improved or damaged
by the architectural decisions, while restrictions directly include or exclude
parts of the architecture (for example, the logical components or
technologies). We can determine the impact of a decision of architecture in
software quality, or which parts of the architecture are affected by a
constraint, but the difficult problem is whether we are respecting the quality
requirements (requirements on quality attributes) and constraints with all the
architectural decisions made. Currently, the common practice is that architects
use their own experience to design architectures that meet the quality
requirements and restrictions, but at the end, especially for the crucial
decisions, the architect has to deal with complex trade-offs between quality
attributes and juggle possible incompatibilities raised by the constraints. In
this paper we present Quark, a computer-aided method to support architects in
software architecture decision making.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5167</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5167</id><created>2012-06-22</created><authors><author><keyname>Faigle</keyname><forenames>Ulrich</forenames></author><author><keyname>Kern</keyname><forenames>Walter</forenames></author><author><keyname>Peis</keyname><forenames>Britta</forenames></author></authors><title>Max-Flow on Regular Spaces</title><categories>math.CO cs.DM</categories><msc-class>90C27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The max-flow and max-coflow problem on directed graphs is studied in the
common generalization to regular spaces, i.e., to kernels or row spaces of
totally unimodular matrices. Exhibiting a submodular structure of the family of
paths within this model we generalize the Edmonds-Karp variant of the classical
Ford-Fulkerson method and show that the number of augmentations is
quadratically bounded if augmentations are chosen along shortest possible
augmenting paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5170</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5170</id><created>2012-05-03</created><authors><author><keyname>Ghosh</keyname><forenames>Arnab</forenames></author><author><keyname>Ghosh</keyname><forenames>Avishek</forenames></author><author><keyname>Chowdhury</keyname><forenames>Arkabandhu</forenames></author><author><keyname>Konar</keyname><forenames>Amit</forenames></author><author><keyname>Janarthanan</keyname><forenames>R.</forenames></author></authors><title>Multi-robot Cooperative Box-pushing problem using Multi-objective
  Particle Swarm Optimization Technique</title><categories>cs.RO cs.NE</categories><comments>6 Pages, 4 Figures (Accepted at MNCAPPS 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present work provides a new approach to solve the well-known multi-robot
co-operative box pushing problem as a multi objective optimization problem
using modified Multi-objective Particle Swarm Optimization. The method proposed
here allows both turning and translation of the box, during shift to a desired
goal position. We have employed local planning scheme to determine the
magnitude of the forces applied by the two mobile robots perpendicularly at
specific locations on the box to align and translate it in each distinct step
of motion of the box, for minimization of both time and energy. Finally the
results are compared with the results obtained by solving the same problem
using Non-dominated Sorting Genetic Algorithm-II (NSGA-II). The proposed scheme
is found to give better results compared to NSGA-II.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5174</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5174</id><created>2012-06-22</created><updated>2013-11-03</updated><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Piterman</keyname><forenames>Nir</forenames></author></authors><title>Obligation Blackwell Games and p-Automata</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We recently introduced p-automata, automata that read discrete-time Markov
chains. We used turn-based stochastic parity games to define acceptance of
Markov chains by a subclass of p-automata. Definition of acceptance required a
cumbersome and complicated reduction to a series of turn-based stochastic
parity games. The reduction could not support acceptance by general p-automata,
which was left undefined as there was no notion of games that supported it.
  Here we generalize two-player games by adding a structural acceptance
condition called obligations. Obligations are orthogonal to the linear winning
conditions that define winning. Obligations are a declaration that player 0 can
achieve a certain value from a configuration. If the obligation is met, the
value of that configuration for player 0 is 1.
  One cannot define value in obligation games by the standard mechanism of
considering the measure of winning paths on a Markov chain and taking the
supremum of the infimum of all strategies. Mainly because obligations need
definition even for Markov chains and the nature of obligations has the flavor
of an infinite nesting of supremum and infimum operators. We define value via a
reduction to turn-based games similar to Martin's proof of determinacy of
Blackwell games with Borel objectives. Based on this definition, we show that
games are determined. We show that for Markov chains with Borel objectives and
obligations, and finite turn-based stochastic parity games with obligations
there exists an alternative and simpler characterization of the value function.
Based on this simpler definition we give an exponential time algorithm to
analyze finite turn-based stochastic parity games with obligations. Finally, we
show that obligation games provide the necessary framework for reasoning about
p-automata and that they generalize the previous definition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5184</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5184</id><created>2012-06-22</created><authors><author><keyname>Zimand</keyname><forenames>Marius</forenames></author></authors><title>Symmetry of Information: A Closer Look</title><categories>cs.IT math.IT</categories><comments>Revised form of a paper communicated at WTCS 2012, Feb. 2012,
  Auckland, New Zealand</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetry of information establishes a relation between the information that x
has about y (denoted I(x : y)) and the information that y has about x (denoted
I(y : x)). In classical information theory, the two are exactly equal, but in
algorithmical information theory, there is a small excess quantity of
information that differentiates the two terms, caused by the necessity of
packaging information in a way that makes it accessible to algorithms. It was
shown in [Zim11] that in the case of strings with simple complexity (that is
the Kolmogorov complexity of their Kolmogorov complexity is small), the
relevant information can be packed in a very economical way, which leads to a
tighter relation between I(x : y) and I(y : x) than the one provided in the
classical symmetry-of-information theorem of Kolmogorov and Levin. We give here
a simpler proof of this result, using a suggestion of Alexander Shen. This
result implies a van Lambalgen- type theorem for finite strings and plain
complexity: If x is c-random and y is c-random relative to x, then xy is
O(c)-random. We show that a similar result holds for prefix-free complexity and
weak-K-randomness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5198</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5198</id><created>2012-06-22</created><authors><author><keyname>South</keyname><forenames>David M.</forenames></author></authors><title>Data Preservation and Long Term Analysis in High Energy Physics</title><categories>hep-ex cs.DL</categories><comments>Proceedings of plenary talk given at the 2012 International
  Conference on Computing in High Energy and Nuclear Physics (CHEP 2012). 8
  pages, 4 figures</comments><doi>10.1088/1742-6596/396/6/062018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several important and unique experimental high-energy physics programmes at a
variety of facilities are coming to an end, including those at HERA, the
B-factories and the Tevatron. The wealth of physics data from these experiments
is the result of a significant financial and human effort, and yet until
recently no coherent strategy existed for data preservation and re-use. To
address this issue, an inter-experimental study group on data preservation and
long-term analysis in high-energy physics was convened at the end of 2008,
publishing an interim report in 2009. The membership of the study group has
since expanded, including the addition of the LHC experiments, and a full
status report has now been released. This report greatly expands on the ideas
contained in the original publication and provides a more solid set of
recommendations, not only concerning data preservation and its implementation
in high-energy physics, but also the future direction and organisational model
of the study group. The main messages of the status report were presented for
the first time at the 2012 International Conference on Computing in High Energy
and Nuclear Physics and are summarised in these proceedings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5200</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5200</id><created>2012-06-22</created><authors><author><keyname>South</keyname><forenames>David M.</forenames></author><author><keyname>Steder</keyname><forenames>Michael</forenames></author></authors><title>The H1 Data Preservation Project</title><categories>physics.data-an cs.DL hep-ex</categories><comments>Proceedings of poster shown at the 2012 International Conference on
  Computing in High Energy and Nuclear Physics (CHEP 2012). 6 pages, 5 figures</comments><doi>10.1088/1742-6596/396/6/062019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The H1 data preservation project was started in 2009 as part of the global
data preservation initiative in high-energy physics, DPHEP. In order to retain
the full potential for future improvements, the H1 Collaboration aims for level
4 of the DPHEP recommendations, which requires the full simulation and
reconstruction chain as well as the data to be preserved for future analysis. A
major goal of the H1 project is therefore to provide secure, long-lived and
validated access to the H1 data and analysis software, which is realised in
collaboration with DESY-IT using virtualisation techniques. By implementing
such a system, it is hoped that the lifetime of the unique ep collision data
from HERA will be extended, providing the possibility for novel analysis in the
future. The preservation of the data and software is performed alongside a
consolidation programme of digital and non-digital documentation, some of which
dates back to the early 1980s. A new organisational model of the H1
Collaboration, reflecting the change to the long term phase, is to be adopted
in July 2012.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5210</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5210</id><created>2012-06-22</created><updated>2012-06-25</updated><authors><author><keyname>Keshavarz</keyname><forenames>Hassan</forenames></author><author><keyname>Abdulwahed</keyname><forenames>Ghaith A.</forenames></author><author><keyname>Salleh</keyname><forenames>Rosli</forenames></author><author><keyname>Wahid</keyname><forenames>Laeth A. Abdul</forenames></author></authors><title>Eliminating Scanning Delay using Advanced Neighbor Discovery with
  Caching (ANDWC)</title><categories>cs.NI</categories><comments>13 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The advance in wireless technologies and portable devices such as smart
phones has made the Wireless Local Area Networks (WLANs) popular in the recent
years. Nowadays, WLANs have become widely accepted in both private and public
sectors due to ease of installation, reasonable prices and high data rates that
can support real time applications. However, fast handoff required for such
real-time applications is not provided in the current IEEE 802.11
specifications. Consequently, providing seamless mobility in these WLANs is an
important issue. To solve this problem, a new fast handoff scheme called
Advanced Neighbor Discovery with Caching (ANDWC) is proposed. This new
mechanism is based on the user's mobility between two or more different Basic
Service Sets (Layer 2 mobility). ANDWC can eliminate scanning delay (which
contributes up to 90% of the total handoff latency) to provide seamless handoff
by using pre-neighbor-discovery and caching mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5232</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5232</id><created>2012-06-22</created><updated>2012-10-07</updated><authors><author><keyname>Molkaraie</keyname><forenames>Mehdi</forenames></author><author><keyname>Loeliger</keyname><forenames>Hans-Andrea</forenames></author></authors><title>Extending Monte Carlo Methods to Factor Graphs with Negative and Complex
  Factors</title><categories>stat.CO cs.IT math.IT stat.AP</categories><comments>Proc. IEEE Information Theory Workshop (ITW), Lausanne, Switzerland,
  Sept. 3-7, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The partition function of a factor graph can sometimes be accurately
estimated by Monte Carlo methods. In this paper, such methods are extended to
factor graphs with negative and complex factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5236</identifier>
 <datestamp>2013-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5236</id><created>2012-06-22</created><updated>2013-02-27</updated><authors><author><keyname>Kliuchnikov</keyname><forenames>Vadym</forenames></author><author><keyname>Maslov</keyname><forenames>Dmitri</forenames></author><author><keyname>Mosca</keyname><forenames>Michele</forenames></author></authors><title>Fast and efficient exact synthesis of single qubit unitaries generated
  by Clifford and T gates</title><categories>quant-ph cs.ET</categories><comments>23 pages, 3 figures, added the proof of T-optimality of the circuits
  synthesized by Algorithm 1</comments><journal-ref>Quantum Information and Computation, Vol. 13, No. 7,8 pp. 607-630
  (2013)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show the equivalence of the set of unitaries computable by
the circuits over the Clifford and T library and the set of unitaries over the
ring $\mathbb{Z}[\frac{1}{\sqrt{2}},i]$, in the single-qubit case. We report an
efficient synthesis algorithm, with an exact optimality guarantee on the number
of Hadamard and T gates used. We conjecture that the equivalence of the sets of
unitaries implementable by circuits over the Clifford and T library and
unitaries over the ring $\mathbb{Z}[\frac{1}{\sqrt{2}},i]$ holds in the
$n$-qubit case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5239</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5239</id><created>2012-06-20</created><authors><author><keyname>Hamze</keyname><forenames>Firas</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Large-Flip Importance Sampling</title><categories>stat.CO cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-167-174</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new Monte Carlo algorithm for complex discrete distributions.
The algorithm is motivated by the N-Fold Way, which is an ingenious
event-driven MCMC sampler that avoids rejection moves at any specific state.
The N-Fold Way can however get &quot;trapped&quot; in cycles. We surmount this problem by
modifying the sampling process. This correction does introduce bias, but the
bias is subsequently corrected with a carefully engineered importance sampler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5240</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5240</id><created>2012-06-20</created><authors><author><keyname>Haffari</keyname><forenames>Gholam Reza</forenames></author><author><keyname>Sarkar</keyname><forenames>Anoop</forenames></author></authors><title>Analysis of Semi-Supervised Learning with the Yarowsky Algorithm</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-159-166</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Yarowsky algorithm is a rule-based semi-supervised learning algorithm
that has been successfully applied to some problems in computational
linguistics. The algorithm was not mathematically well understood until (Abney
2004) which analyzed some specific variants of the algorithm, and also proposed
some new algorithms for bootstrapping. In this paper, we extend Abney's work
and show that some of his proposed algorithms actually optimize (an upper-bound
on) an objective function based on a new definition of cross-entropy which is
based on a particular instantiation of the Bregman distance between probability
distributions. Moreover, we suggest some new algorithms for rule-based
semi-supervised learning and show connections with harmonic functions and
minimum multi-way cuts in graph-based semi-supervised learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5241</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5241</id><created>2012-06-20</created><authors><author><keyname>Grosse</keyname><forenames>Roger</forenames></author><author><keyname>Raina</keyname><forenames>Rajat</forenames></author><author><keyname>Kwong</keyname><forenames>Helen</forenames></author><author><keyname>Ng</keyname><forenames>Andrew Y.</forenames></author></authors><title>Shift-Invariance Sparse Coding for Audio Classification</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-149-158</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse coding is an unsupervised learning algorithm that learns a succinct
high-level representation of the inputs given only unlabeled data; it
represents each input as a sparse linear combination of a set of basis
functions. Originally applied to modeling the human visual cortex, sparse
coding has also been shown to be useful for self-taught learning, in which the
goal is to solve a supervised classification task given access to additional
unlabeled data drawn from different classes than that in the supervised
learning problem. Shift-invariant sparse coding (SISC) is an extension of
sparse coding which reconstructs a (usually time-series) input using all of the
basis functions in all possible shifts. In this paper, we present an efficient
algorithm for learning SISC bases. Our method is based on iteratively solving
two large convex optimization problems: The first, which computes the linear
coefficients, is an L1-regularized linear least squares problem with
potentially hundreds of thousands of variables. Existing methods typically use
a heuristic to select a small subset of the variables to optimize, but we
present a way to efficiently compute the exact solution. The second, which
solves for bases, is a constrained linear least squares problem. By optimizing
over complex-valued variables in the Fourier domain, we reduce the coupling
between the different variables, allowing the problem to be solved efficiently.
We show that SISC's learned high-level representations of speech and music
provide useful features for classification tasks within those domains. When
applied to classification, under certain conditions the learned features
outperform state of the art spectral and cepstral features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5242</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5242</id><created>2012-06-20</created><authors><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author><author><keyname>Bidyuk</keyname><forenames>Bozhena</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>Studies in Lower Bounding Probabilities of Evidence using the Markov
  Inequality</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-141-148</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the probability of evidence even with known error bounds is
NP-hard. In this paper we address this hard problem by settling on an easier
problem. We propose an approximation which provides high confidence lower
bounds on probability of evidence but does not have any guarantees in terms of
relative or absolute error. Our proposed approximation is a randomized
importance sampling scheme that uses the Markov inequality. However, a
straight-forward application of the Markov inequality may lead to poor lower
bounds. We therefore propose several heuristic measures to improve its
performance in practice. Empirical evaluation of our scheme with state-of-
the-art lower bounding schemes reveals the promise of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5243</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5243</id><created>2012-06-20</created><authors><author><keyname>Globerson</keyname><forenames>Amir</forenames></author><author><keyname>Jaakkola</keyname><forenames>Tommi S.</forenames></author></authors><title>Convergent Propagation Algorithms via Oriented Trees</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-133-140</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference problems in graphical models are often approximated by casting them
as constrained optimization problems. Message passing algorithms, such as
belief propagation, have previously been suggested as methods for solving these
optimization problems. However, there are few convergence guarantees for such
algorithms, and the algorithms are therefore not guaranteed to solve the
corresponding optimization problem. Here we present an oriented tree
decomposition algorithm that is guaranteed to converge to the global optimum of
the Tree-Reweighted (TRW) variational problem. Our algorithm performs local
updates in the convex dual of the TRW problem - an unconstrained generalized
geometric program. Primal updates, also local, correspond to oriented
reparametrization operations that leave the distribution intact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5244</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5244</id><created>2012-06-20</created><authors><author><keyname>Galand</keyname><forenames>Lucie</forenames></author><author><keyname>Perny</keyname><forenames>Patrice</forenames></author></authors><title>Search for Choquet-optimal paths under uncertainty</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-125-132</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Choquet expected utility (CEU) is one of the most sophisticated decision
criteria used in decision theory under uncertainty. It provides a
generalisation of expected utility enhancing both descriptive and prescriptive
possibilities. In this paper, we investigate the use of CEU for path-planning
under uncertainty with a special focus on robust solutions. We first recall the
main features of the CEU model and introduce some examples showing its
descriptive potential. Then we focus on the search for Choquet-optimal paths in
multivalued implicit graphs where costs depend on different scenarios. After
discussing complexity issues, we propose two different heuristic search
algorithms to solve the problem. Finally, numerical experiments are reported,
showing the practical efficiency of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5245</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5245</id><created>2012-06-20</created><authors><author><keyname>Feelders</keyname><forenames>Ad</forenames></author></authors><title>A new parameter Learning Method for Bayesian Networks with Qualitative
  Influences</title><categories>cs.AI cs.LG stat.ME</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-117-124</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for parameter learning in Bayesian networks with
qualitative influences. This method extends our previous work from networks of
binary variables to networks of discrete variables with ordered values. The
specified qualitative influences correspond to certain order restrictions on
the parameters in the network. These parameters may therefore be estimated
using constrained maximum likelihood estimation. We propose an alternative
method, based on the isotonic regression. The constrained maximum likelihood
estimates are fairly complicated to compute, whereas computation of the
isotonic regression estimates only requires the repeated application of the
Pool Adjacent Violators algorithm for linear orders. Therefore, the isotonic
regression estimator is to be preferred from the viewpoint of computational
complexity. Through experiments on simulated and real data, we show that the
new learning method is competitive in performance to the constrained maximum
likelihood estimator, and that both estimators improve on the standard
estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5246</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5246</id><created>2012-06-20</created><authors><author><keyname>Eichler</keyname><forenames>Michael</forenames></author><author><keyname>Didelez</keyname><forenames>Vanessa</forenames></author></authors><title>Causal Reasoning in Graphical Time Series Models</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-109-116</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a definition of causality for time series in terms of the effect
of an intervention in one component of a multivariate time series on another
component at some later point in time. Conditions for identifiability,
comparable to the back-door and front-door criteria, are presented and can also
be verified graphically. Computation of the causal effect is derived and
illustrated for the linear case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5247</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5247</id><created>2012-06-20</created><authors><author><keyname>Eaton</keyname><forenames>Daniel</forenames></author><author><keyname>Murphy</keyname><forenames>Kevin</forenames></author></authors><title>Bayesian structure learning using dynamic programming and MCMC</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-101-108</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MCMC methods for sampling from the space of DAGs can mix poorly due to the
local nature of the proposals that are commonly used. It has been shown that
sampling from the space of node orders yields better results [FK03, EW06].
Recently, Koivisto and Sood showed how one can analytically marginalize over
orders using dynamic programming (DP) [KS04, Koi06]. Their method computes the
exact marginal posterior edge probabilities, thus avoiding the need for MCMC.
Unfortunately, there are four drawbacks to the DP technique: it can only use
modular priors, it can only compute posteriors over modular features, it is
difficult to compute a predictive density, and it takes exponential time and
space. We show how to overcome the first three of these problems by using the
DP algorithm as a proposal distribution for MCMC in DAG space. We show that
this hybrid technique converges to the posterior faster than other methods,
resulting in more accurate structure learning and higher predictive likelihoods
on test data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5248</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5248</id><created>2012-06-20</created><authors><author><keyname>Dillon</keyname><forenames>Joshua</forenames></author><author><keyname>Mao</keyname><forenames>Yi</forenames></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author><author><keyname>Zhang</keyname><forenames>Jian</forenames></author></authors><title>Statistical Translation, Heat Kernels and Expected Distances</title><categories>cs.LG cs.CV cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-93-100</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High dimensional structured data such as text and images is often poorly
understood and misrepresented in statistical modeling. The standard histogram
representation suffers from high variance and performs poorly in general. We
explore novel connections between statistical translation, heat kernels on
manifolds and graphs, and expected distances. These connections provide a new
framework for unsupervised metric learning for text documents. Experiments
indicate that the resulting distances are generally superior to their more
standard counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5249</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5249</id><created>2012-06-20</created><authors><author><keyname>Deshpande</keyname><forenames>Ashwin</forenames></author><author><keyname>Milch</keyname><forenames>Brian</forenames></author><author><keyname>Zettlemoyer</keyname><forenames>Luke S.</forenames></author><author><keyname>Kaelbling</keyname><forenames>Leslie Pack</forenames></author></authors><title>Learning Probabilistic Relational Dynamics for Multiple Tasks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-83-92</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ways in which an agent's actions affect the world can often be modeled
compactly using a set of relational probabilistic planning rules. This paper
addresses the problem of learning such rule sets for multiple related tasks. We
take a hierarchical Bayesian approach, in which the system learns a prior
distribution over rule sets. We present a class of prior distributions
parameterized by a rule set prototype that is stochastically modified to
produce a task-specific rule set. We also describe a coordinate ascent
algorithm that iteratively optimizes the task-specific rule sets and the prior
distribution. Experiments using this algorithm show that transferring
information from related tasks significantly reduces the amount of training
data required to predict action effects in blocks-world domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5250</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5250</id><created>2012-06-20</created><authors><author><keyname>Dereszynski</keyname><forenames>Ethan W.</forenames></author><author><keyname>Dietterich</keyname><forenames>Thomas G.</forenames></author></authors><title>Probabilistic Models for Anomaly Detection in Remote Sensor Data Streams</title><categories>cs.AI stat.AP</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-75-82</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Remote sensors are becoming the standard for observing and recording
ecological data in the field. Such sensors can record data at fine temporal
resolutions, and they can operate under extreme conditions prohibitive to human
access. Unfortunately, sensor data streams exhibit many kinds of errors ranging
from corrupt communications to partial or total sensor failures. This means
that the raw data stream must be cleaned before it can be used by domain
scientists. In our application environment|the H.J. Andrews Experimental
Forest|this data cleaning is performed manually. This paper introduces a
Dynamic Bayesian Network model for analyzing sensor observations and
distinguishing sensor failures from valid data for the case of air temperature
measured at 15 minute time resolution. The model combines an accurate
distribution of long-term and short-term temperature variations with a single
generalized fault model. Experiments with historical data show that the
precision and recall of the method is comparable to that of the domain expert.
The system is currently being deployed to perform real-time automated data
cleaning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5251</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5251</id><created>2012-06-20</created><authors><author><keyname>Choi</keyname><forenames>Arthur</forenames></author><author><keyname>Chavira</keyname><forenames>Mark</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>Node Splitting: A Scheme for Generating Upper Bounds in Bayesian
  Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-57-66</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate in this paper the mini-bucket algorithm for approximate
inference in terms of exact inference on an approximate model produced by
splitting nodes in a Bayesian network. The new formulation leads to a number of
theoretical and practical implications. First, we show that branchand- bound
search algorithms that use minibucket bounds may operate in a drastically
reduced search space. Second, we show that the proposed formulation inspires
new minibucket heuristics and allows us to analyze existing heuristics from a
new perspective. Finally, we show that this new formulation allows mini-bucket
approximations to benefit from recent advances in exact inference, allowing one
to significantly increase the reach of these approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5252</identifier>
 <datestamp>2012-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5252</id><created>2012-06-20</created><authors><author><keyname>Chen</keyname><forenames>Yiling</forenames></author><author><keyname>Pennock</keyname><forenames>David M</forenames></author></authors><title>A Utility Framework for Bounded-Loss Market Makers</title><categories>cs.GT q-fin.TR</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-49-56</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a class of utility-based market makers that always accept orders
at their risk-neutral prices. We derive necessary and sufficient conditions for
such market makers to have bounded loss. We prove that hyperbolic absolute risk
aversion utility market makers are equivalent to weighted pseudospherical
scoring rule market makers. In particular, Hanson's logarithmic scoring rule
market maker corresponds to a negative exponential utility market maker in our
framework. We describe a third equivalent formulation based on maintaining a
cost function that seems most natural for implementation purposes, and we
illustrate how to translate among the three equivalent formulations. We examine
the tradeoff between the market's liquidity and the market maker's worst-case
loss. For a fixed bound on worst-case loss, some market makers exhibit greater
liquidity near uniform prices and some exhibit greater liquidity near extreme
prices, but no market maker can exhibit uniformly greater liquidity in all
regimes. For a fixed minimum liquidity level, we give the lower bound of market
maker's worst-case loss under some regularity conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5253</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5253</id><created>2012-06-20</created><authors><author><keyname>Chang</keyname><forenames>Allen</forenames></author><author><keyname>Amir</keyname><forenames>Eyal</forenames></author></authors><title>Reachability Under Uncertainty</title><categories>cs.DS cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-41-48</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a new network reachability problem where the goal
is to find the most reliable path between two nodes in a network, represented
as a directed acyclic graph. Individual edges within this network may fail
according to certain probabilities, and these failure probabilities may depend
on the values of one or more hidden variables. This problem may be viewed as a
generalization of shortest-path problems for finding minimum cost paths or
Viterbi-type problems for finding highest-probability sequences of states,
where the addition of the hidden variables introduces correlations that are not
handled by previous algorithms. We give theoretical results characterizing this
problem including an NP-hardness proof. We also give an exact algorithm and a
more efficient approximation algorithm for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5255</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5255</id><created>2012-06-20</created><authors><author><keyname>Braziunas</keyname><forenames>Darius</forenames></author><author><keyname>Boutilier</keyname><forenames>Craig</forenames></author></authors><title>Minimax regret based elicitation of generalized additive utilities</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-25-32</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the semantic foundations for elicitation of generalized
additively independent (GAI) utilities using the minimax regret criterion, and
propose several new query types and strategies for this purpose. Computational
feasibility is obtained by exploiting the local GAI structure in the model. Our
results provide a practical approach for implementing preference-based
constrained configuration optimization as well as effective search in
multiattribute product databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5256</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5256</id><created>2012-06-20</created><authors><author><keyname>Bockhorst</keyname><forenames>Joseph</forenames></author><author><keyname>Jojic</keyname><forenames>Nebojsa</forenames></author></authors><title>Discovering Patterns in Biological Sequences by Optimal Segmentation</title><categories>cs.CE cs.LG q-bio.QM stat.AP</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-17-24</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational methods for discovering patterns of local correlations in
sequences are important in computational biology. Here we show how to determine
the optimal partitioning of aligned sequences into non-overlapping segments
such that positions in the same segment are strongly correlated while positions
in different segments are not. Our approach involves discovering the hidden
variables of a Bayesian network that interact with observed sequences so as to
form a set of independent mixture models. We introduce a dynamic program to
efficiently discover the optimal segmentation, or equivalently the optimal set
of hidden variables. We evaluate our approach on two computational biology
tasks. One task is related to the design of vaccines against polymorphic
pathogens and the other task involves analysis of single nucleotide
polymorphisms (SNPs) in human DNA. We show how common tasks in these problems
naturally correspond to inference procedures in the learned models. Error rates
of our learned models for the prediction of missing SNPs are up to 1/3 less
than the error rates of a state-of-the-art SNP prediction method. Source code
is available at www.uwm.edu/~joebock/segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5257</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5257</id><created>2012-06-20</created><authors><author><keyname>Bhattacharjya</keyname><forenames>Debarun</forenames></author><author><keyname>Shachter</keyname><forenames>Ross D.</forenames></author></authors><title>Evaluating influence diagrams with decision circuits</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-9-16</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although a number of related algorithms have been developed to evaluate
influence diagrams, exploiting the conditional independence in the diagram, the
exact solution has remained intractable for many important problems. In this
paper we introduce decision circuits as a means to exploit the local structure
usually found in decision problems and to improve the performance of influence
diagram analysis. This work builds on the probabilistic inference algorithms
using arithmetic circuits to represent Bayesian belief networks [Darwiche,
2003]. Once compiled, these arithmetic circuits efficiently evaluate
probabilistic queries on the belief network, and methods have been developed to
exploit both the global and local structure of the network. We show that
decision circuits can be constructed in a similar fashion and promise similar
benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5258</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5258</id><created>2012-06-20</created><authors><author><keyname>Amato</keyname><forenames>Christopher</forenames></author><author><keyname>Bernstein</keyname><forenames>Daniel S</forenames></author><author><keyname>Zilberstein</keyname><forenames>Shlomo</forenames></author></authors><title>Optimizing Memory-Bounded Controllers for Decentralized POMDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-1-8</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a memory-bounded optimization approach for solving
infinite-horizon decentralized POMDPs. Policies for each agent are represented
by stochastic finite state controllers. We formulate the problem of optimizing
these policies as a nonlinear program, leveraging powerful existing nonlinear
optimization techniques for solving the problem. While existing solvers only
guarantee locally optimal solutions, we show that our formulation produces
higher quality controllers than the state-of-the-art approach. We also
incorporate a shared source of randomness in the form of a correlation device
to further increase solution quality with only a limited increase in space and
time. Our experimental results show that nonlinear optimization can be used to
provide high quality, concise solutions to decentralized decision problems
under uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5259</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5259</id><created>2012-06-20</created><authors><author><keyname>Sarkar</keyname><forenames>Purnamrita</forenames></author><author><keyname>Moore</keyname><forenames>Andrew</forenames></author></authors><title>A Tractable Approach to Finding Closest Truncated-commute-time Neighbors
  in Large Graphs</title><categories>cs.SI cs.DS physics.soc-ph</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-335-343</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there has been much interest in graph-based learning, with
applications in collaborative filtering for recommender networks, link
prediction for social networks and fraud detection. These networks can consist
of millions of entities, and so it is very important to develop highly
efficient techniques. We are especially interested in accelerating random walk
approaches to compute some very interesting proximity measures of these kinds
of graphs. These measures have been shown to do well empirically (Liben-Nowell
&amp; Kleinberg, 2003; Brand, 2005). We introduce a truncated variation on a
well-known measure, namely commute times arising from random walks on graphs.
We present a very novel algorithm to compute all interesting pairs of
approximate nearest neighbors in truncated commute times, without computing it
between all pairs. We show results on both simulated and real graphs of size up
to 100; 000 entities, which indicate near-linear scaling in computation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5260</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5260</id><created>2012-06-20</created><authors><author><keyname>Saria</keyname><forenames>Suchi</forenames></author><author><keyname>Nodelman</keyname><forenames>Uri</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author></authors><title>Reasoning at the Right Time Granularity</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-326-334</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most real-world dynamic systems are composed of different components that
often evolve at very different rates. In traditional temporal graphical models,
such as dynamic Bayesian networks, time is modeled at a fixed granularity,
generally selected based on the rate at which the fastest component evolves.
Inference must then be performed at this fastest granularity, potentially at
significant computational cost. Continuous Time Bayesian Networks (CTBNs) avoid
time-slicing in the representation by modeling the system as evolving
continuously over time. The expectation-propagation (EP) inference algorithm of
Nodelman et al. (2005) can then vary the inference granularity over time, but
the granularity is uniform across all parts of the system, and must be selected
in advance. In this paper, we provide a new EP algorithm that utilizes a
general cluster graph architecture where clusters contain distributions that
can overlap in both space (set of variables) and time. This architecture allows
different parts of the system to be modeled at very different time
granularities, according to their current rate of evolution. We also provide an
information-theoretic criterion for dynamically re-partitioning the clusters
during inference to tune the level of approximation to the current rate of
evolution. This avoids the need to hand-select the appropriate granularity, and
allows the granularity to adapt as information is transmitted across the
network. We present experiments demonstrating that this approach can result in
significant computational savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5261</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5261</id><created>2012-06-20</created><authors><author><keyname>Rosenberg</keyname><forenames>David S.</forenames></author><author><keyname>Klein</keyname><forenames>Dan</forenames></author><author><keyname>Taskar</keyname><forenames>Ben</forenames></author></authors><title>Mixture-of-Parents Maximum Entropy Markov Models</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-318-325</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the mixture-of-parents maximum entropy Markov model (MoP-MEMM), a
class of directed graphical models extending MEMMs. The MoP-MEMM allows
tractable incorporation of long-range dependencies between nodes by restricting
the conditional distribution of each node to be a mixture of distributions
given the parents. We show how to efficiently compute the exact marginal
posterior node distributions, regardless of the range of the dependencies. This
enables us to model non-sequential correlations present within text documents,
as well as between interconnected documents, such as hyperlinked web pages. We
apply the MoP-MEMM to a named entity recognition task and a web page
classification task. In each, our model shows significant improvement over the
basic MEMM, and is competitive with other long-range sequence models that use
approximate inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5263</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5263</id><created>2012-06-20</created><authors><author><keyname>Pena</keyname><forenames>Jose M.</forenames></author></authors><title>Reading Dependencies from Polytree-Like Bayesian Networks</title><categories>cs.AI cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-303-309</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a graphical criterion for reading dependencies from the minimal
directed independence map G of a graphoid p when G is a polytree and p
satisfies composition and weak transitivity. We prove that the criterion is
sound and complete. We argue that assuming composition and weak transitivity is
not too restrictive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5264</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5264</id><created>2012-06-20</created><authors><author><keyname>Neu</keyname><forenames>Gergely</forenames></author><author><keyname>Szepesvari</keyname><forenames>Csaba</forenames></author></authors><title>Apprenticeship Learning using Inverse Reinforcement Learning and
  Gradient Methods</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-295-302</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel gradient algorithm to learn a policy from an
expert's observed behavior assuming that the expert behaves optimally with
respect to some unknown reward function of a Markovian Decision Problem. The
algorithm's aim is to find a reward function such that the resulting optimal
policy matches well the expert's observed behavior. The main difficulty is that
the mapping from the parameters to policies is both nonsmooth and highly
redundant. Resorting to subdifferentials solves the first difficulty, while the
second one is over- come by computing natural gradients. We tested the proposed
method in two artificial domains and found it to be more reliable and efficient
than some previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5265</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5265</id><created>2012-06-20</created><authors><author><keyname>Meila</keyname><forenames>Marina</forenames></author><author><keyname>Phadnis</keyname><forenames>Kapil</forenames></author><author><keyname>Patterson</keyname><forenames>Arthur</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author></authors><title>Consensus ranking under the exponential model</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-285-294</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the generalized Mallows model, a popular exponential model over
rankings. Estimating the central (or consensus) ranking from data is NP-hard.
We obtain the following new results: (1) We show that search methods can
estimate both the central ranking pi0 and the model parameters theta exactly.
The search is n! in the worst case, but is tractable when the true distribution
is concentrated around its mode; (2) We show that the generalized Mallows model
is jointly exponential in (pi0; theta), and introduce the conjugate prior for
this model class; (3) The sufficient statistics are the pairwise marginal
probabilities that item i is preferred to item j. Preliminary experiments
confirm the theoretical predictions and compare the new algorithm and existing
heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5266</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5266</id><created>2012-06-20</created><authors><author><keyname>Mateescu</keyname><forenames>Robert</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>AND/OR Multi-Valued Decision Diagrams (AOMDDs) for Weighted Graphical
  Models</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-276-284</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compiling graphical models has recently been under intense investigation,
especially for probabilistic modeling and processing. We present here a novel
data structure for compiling weighted graphical models (in particular,
probabilistic models), called AND/OR Multi-Valued Decision Diagram (AOMDD).
This is a generalization of our previous work on constraint networks, to
weighted models. The AOMDD is based on the frameworks of AND/OR search spaces
for graphical models, and Ordered Binary Decision Diagrams (OBDD). The AOMDD is
a canonical representation of a graphical model, and its size and compilation
time are bounded exponentially by the treewidth of the graph, rather than
pathwidth as is known for OBDDs. We discuss a Variable Elimination schedule for
compilation, and present the general APPLY algorithm that combines two weighted
AOMDDs, and also present a search based method for compilation method. The
preliminary experimental evaluation is quite encouraging, showing the potential
of the AOMDD data structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5267</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5267</id><created>2012-06-20</created><authors><author><keyname>Marlin</keyname><forenames>Benjamin</forenames></author><author><keyname>Zemel</keyname><forenames>Richard S.</forenames></author><author><keyname>Roweis</keyname><forenames>Sam</forenames></author><author><keyname>Slaney</keyname><forenames>Malcolm</forenames></author></authors><title>Collaborative Filtering and the Missing at Random Assumption</title><categories>cs.LG cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-267-275</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rating prediction is an important application, and a popular research topic
in collaborative filtering. However, both the validity of learning algorithms,
and the validity of standard testing procedures rest on the assumption that
missing ratings are missing at random (MAR). In this paper we present the
results of a user study in which we collect a random sample of ratings from
current users of an online radio service. An analysis of the rating data
collected in the study shows that the sample of random ratings has markedly
different properties than ratings of user-selected songs. When asked to report
on their own rating behaviour, a large number of users indicate they believe
their opinion of a song does affect whether they choose to rate that song, a
violation of the MAR condition. Finally, we present experimental results
showing that incorporating an explicit model of the missing data mechanism can
lead to significant improvements in prediction performance on the random sample
of ratings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5268</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5268</id><created>2012-06-20</created><authors><author><keyname>Marinescu</keyname><forenames>Radu</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>Best-First AND/OR Search for Most Probable Explanations</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-259-266</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper evaluates the power of best-first search over AND/OR search spaces
for solving the Most Probable Explanation (MPE) task in Bayesian networks. The
main virtue of the AND/OR representation of the search space is its sensitivity
to the structure of the problem, which can translate into significant time
savings. In recent years depth-first AND/OR Branch-and- Bound algorithms were
shown to be very effective when exploring such search spaces, especially when
using caching. Since best-first strategies are known to be superior to
depth-first when memory is utilized, exploring the best-first control strategy
is called for. The main contribution of this paper is in showing that a recent
extension of AND/OR search algorithms from depth-first Branch-and-Bound to
best-first is indeed very effective for computing the MPE in Bayesian networks.
We demonstrate empirically the superiority of the best-first search approach on
various probabilistic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5269</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5269</id><created>2012-06-20</created><authors><author><keyname>Listgarden</keyname><forenames>Jennifer</forenames></author><author><keyname>Heckerman</keyname><forenames>David</forenames></author></authors><title>Determining the Number of Non-Spurious Arcs in a Learned DAG Model:
  Investigation of a Bayesian and a Frequentist Approach</title><categories>stat.AP cs.CE</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-251-258</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many application domains, such as computational biology, the goal of
graphical model structure learning is to uncover discrete relationships between
entities. For example, in our problem of interest concerning HIV vaccine
design, we want to infer which HIV peptides interact with which immune system
molecules (HLA molecules). For problems of this nature, we are interested in
determining the number of nonspurious arcs in a learned graphical model. We
describe both a Bayesian and frequentist approach to this problem. In the
Bayesian approach, we use the posterior distribution over model structures to
compute the expected number of true arcs in a learned model. In the frequentist
approach, we develop a method based on the concept of the False Discovery Rate.
On synthetic data sets generated from models similar to the ones learned, we
find that both the Bayesian and frequentist approaches yield accurate estimates
of the number of non-spurious arcs. In addition, we speculate that the
frequentist approach, which is non-parametric, may outperform the parametric
Bayesian approach in situations where the models learned are less
representative of the data. Finally, we apply the frequentist approach to our
problem of HIV vaccine design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5270</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5270</id><created>2012-06-20</created><authors><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Blei</keyname><forenames>David</forenames></author><author><keyname>McCallum</keyname><forenames>Andrew</forenames></author></authors><title>Nonparametric Bayes Pachinko Allocation</title><categories>cs.IR cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-243-250</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in topic models have explored complicated structured
distributions to represent topic correlation. For example, the pachinko
allocation model (PAM) captures arbitrary, nested, and possibly sparse
correlations between topics using a directed acyclic graph (DAG). While PAM
provides more flexibility and greater expressive power than previous models
like latent Dirichlet allocation (LDA), it is also more difficult to determine
the appropriate topic structure for a specific dataset. In this paper, we
propose a nonparametric Bayesian prior for PAM based on a variant of the
hierarchical Dirichlet process (HDP). Although the HDP can capture topic
correlations defined by nested data structure, it does not automatically
discover such correlations from unstructured data. By assuming an HDP-based
prior for PAM, we are able to learn both the number of topics and how the
topics are correlated. We evaluate our model on synthetic and real-world text
datasets, and show that nonparametric PAM achieves performance matching the
best of PAM without manually tuning the number of topics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5271</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5271</id><created>2012-06-20</created><authors><author><keyname>Lantz</keyname><forenames>Eric</forenames></author><author><keyname>Ray</keyname><forenames>Soumya</forenames></author><author><keyname>Page</keyname><forenames>David</forenames></author></authors><title>Learning Bayesian Network Structure from Correlation-Immune Data</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-235-242</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Searching the complete space of possible Bayesian networks is intractable for
problems of interesting size, so Bayesian network structure learning
algorithms, such as the commonly used Sparse Candidate algorithm, employ
heuristics. However, these heuristics also restrict the types of relationships
that can be learned exclusively from data. They are unable to learn
relationships that exhibit &quot;correlation-immunity&quot;, such as parity. To learn
Bayesian networks in the presence of correlation-immune relationships, we
extend the Sparse Candidate algorithm with a technique called &quot;skewing&quot;. This
technique uses the observation that relationships that are correlation-immune
under a specific input distribution may not be correlation-immune under
another, sufficiently different distribution. We show that by extending Sparse
Candidate with this technique we are able to discover relationships between
random variables that are approximately correlation-immune, with a
significantly lower computational cost than the alternative of considering
multiple parents of a node at a time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5272</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5272</id><created>2012-06-20</created><authors><author><keyname>Kuroki</keyname><forenames>Manabu</forenames></author><author><keyname>Cai</keyname><forenames>Zhihong</forenames></author></authors><title>Evaluation of the Causal Effect of Control Plans in Nonrecursive
  Structural Equation Models</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-227-234</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When observational data is available from practical studies and a directed
cyclic graph for how various variables affect each other is known based on
substantive understanding of the process, we consider a problem in which a
control plan of a treatment variable is conducted in order to bring a response
variable close to a target value with variation reduction. We formulate an
optimal control plan concerning a certain treatment variable through path
coefficients in the framework of linear nonrecursive structural equation
models. Based on the formulation, we clarify the properties of causal effects
when conducting a control plan. The results enable us to evaluate the effect of
a control plan on the variance from observational data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5273</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5273</id><created>2012-06-20</created><authors><author><keyname>Kroc</keyname><forenames>Lukas</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashish</forenames></author><author><keyname>Selman</keyname><forenames>Bart</forenames></author></authors><title>Survey Propagation Revisited</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-217-226</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Survey propagation (SP) is an exciting new technique that has been remarkably
successful at solving very large hard combinatorial problems, such as
determining the satisfiability of Boolean formulas. In a promising attempt at
understanding the success of SP, it was recently shown that SP can be viewed as
a form of belief propagation, computing marginal probabilities over certain
objects called covers of a formula. This explanation was, however, shortly
dismissed by experiments suggesting that non-trivial covers simply do not exist
for large formulas. In this paper, we show that these experiments were
misleading: not only do covers exist for large hard random formulas, SP is
surprisingly accurate at computing marginals over these covers despite the
existence of many cycles in the formulas. This re-opens a potentially simpler
line of reasoning for understanding SP, in contrast to some alternative lines
of explanation that have been proposed assuming covers do not exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5274</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5274</id><created>2012-06-20</created><authors><author><keyname>Kapoor</keyname><forenames>Ashish</forenames></author><author><keyname>Horvitz</keyname><forenames>Eric J.</forenames></author></authors><title>On Discarding, Caching, and Recalling Samples in Active Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-209-216</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address challenges of active learning under scarce informational resources
in non-stationary environments. In real-world settings, data labeled and
integrated into a predictive model may become invalid over time. However, the
data can become informative again with switches in context and such changes may
indicate unmodeled cyclic or other temporal dynamics. We explore principles for
discarding, caching, and recalling labeled data points in active learning based
on computations of value of information. We review key concepts and study the
value of the methods via investigations of predictive performance and costs of
acquiring data for simulated and real-world data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5275</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5275</id><created>2012-06-20</created><authors><author><keyname>Kang</keyname><forenames>Changsung</forenames></author><author><keyname>Tian</keyname><forenames>Jin</forenames></author></authors><title>Polynomial Constraints in Causal Bayesian Networks</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-200-208</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the implicitization procedure to generate polynomial equality
constraints on the set of distributions induced by local interventions on
variables governed by a causal Bayesian network with hidden variables. We show
how we may reduce the complexity of the implicitization problem and make the
problem tractable in certain causal Bayesian networks. We also show some
preliminary results on the algebraic structure of polynomial constraints. The
results have applications in distinguishing between causal models and in
testing causal models with combined observational and experimental data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5276</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5276</id><created>2012-06-20</created><authors><author><keyname>Jaimovich</keyname><forenames>Ariel</forenames></author><author><keyname>Meshi</keyname><forenames>Ofer</forenames></author><author><keyname>Friedman</keyname><forenames>Nir</forenames></author></authors><title>Template Based Inference in Symmetric Relational Markov Random Fields</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-191-199</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relational Markov Random Fields are a general and flexible framework for
reasoning about the joint distribution over attributes of a large number of
interacting entities. The main computational difficulty in learning such models
is inference. Even when dealing with complete data, where one can summarize a
large domain by sufficient statistics, learning requires one to compute the
expectation of the sufficient statistics given different parameter choices. The
typical solution to this problem is to resort to approximate inference
procedures, such as loopy belief propagation. Although these procedures are
quite efficient, they still require computation that is on the order of the
number of interactions (or features) in the model. When learning a large
relational model over a complex domain, even such approximations require
unrealistic running time. In this paper we show that for a particular class of
relational MRFs, which have inherent symmetry, we can perform the inference
needed for learning procedures using a template-level belief propagation. This
procedure's running time is proportional to the size of the relational model
rather than the size of the domain. Moreover, we show that this computational
procedure is equivalent to sychronous loopy belief propagation. This enables a
dramatic speedup in inference and learning time. We use this procedure to learn
relational MRFs for capturing the joint distribution of large protein-protein
interaction networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5277</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5277</id><created>2012-06-20</created><authors><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author></authors><title>Accuracy Bounds for Belief Propagation</title><categories>cs.AI cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-183-190</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The belief propagation (BP) algorithm is widely applied to perform
approximate inference on arbitrary graphical models, in part due to its
excellent empirical properties and performance. However, little is known
theoretically about when this algorithm will perform well. Using recent
analysis of convergence and stability properties in BP and new results on
approximations in binary systems, we derive a bound on the error in BP's
estimates for pairwise Markov random fields over discrete valued random
variables. Our bound is relatively simple to compute, and compares favorably
with a previous method of bounding the accuracy of BP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5278</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5278</id><created>2012-06-20</created><authors><author><keyname>Holmes</keyname><forenames>Michael P.</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author><author><keyname>Isbell</keyname><forenames>Charles Lee</forenames></author></authors><title>Fast Nonparametric Conditional Density Estimation</title><categories>stat.ME cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-175-182</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional density estimation generalizes regression by modeling a full
density f(yjx) rather than only the expected value E(yjx). This is important
for many tasks, including handling multi-modality and generating prediction
intervals. Though fundamental and widely applicable, nonparametric conditional
density estimators have received relatively little attention from statisticians
and little or none from the machine learning community. None of that work has
been applied to greater than bivariate data, presumably due to the
computational difficulty of data-driven bandwidth selection. We describe the
double kernel conditional density estimator and derive fast dual-tree-based
algorithms for bandwidth selection using a maximum likelihood criterion. These
techniques give speedups of up to 3.8 million in our experiments, and enable
the first applications to previously intractable large multivariate datasets,
including a redshift prediction problem from the Sloan Digital Sky Survey.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5279</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5279</id><created>2012-06-20</created><authors><author><keyname>Goldszmidt</keyname><forenames>Moises</forenames></author></authors><title>Making life better one large system at a time: Challenges for UAI
  research</title><categories>cs.SE cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-475-481</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid growth and diversity in service offerings and the ensuing
complexity of information technology ecosystems present numerous management
challenges (both operational and strategic). Instrumentation and measurement
technology is, by and large, keeping pace with this development and growth.
However, the algorithms, tools, and technology required to transform the data
into relevant information for decision making are not. The claim in this paper
(and the invited talk) is that the line of research conducted in Uncertainty in
Artificial Intelligence is very well suited to address the challenges and close
this gap. I will support this claim and discuss open problems using recent
examples in diagnosis, model discovery, and policy optimization on three real
life distributed systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5280</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5280</id><created>2012-06-20</created><authors><author><keyname>Zuk</keyname><forenames>Or</forenames></author><author><keyname>Ein-Dor</keyname><forenames>Liat</forenames></author><author><keyname>Domany</keyname><forenames>Eytan</forenames></author></authors><title>Ranking Under Uncertainty</title><categories>cs.AI stat.AP</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-466-473</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ranking objects is a simple and natural procedure for organizing data. It is
often performed by assigning a quality score to each object according to its
relevance to the problem at hand. Ranking is widely used for object selection,
when resources are limited and it is necessary to select a subset of most
relevant objects for further processing. In real world situations, the object's
scores are often calculated from noisy measurements, casting doubt on the
ranking reliability. We introduce an analytical method for assessing the
influence of noise levels on the ranking reliability. We use two similarity
measures for reliability evaluation, Top-K-List overlap and Kendall's tau
measure, and show that the former is much more sensitive to noise than the
latter. We apply our method to gene selection in a series of microarray
experiments of several cancer types. The results indicate that the reliability
of the lists obtained from these experiments is very poor, and that experiment
sizes which are necessary for attaining reasonably stable Top-K-Lists are much
larger than those currently available. Simulations support our analytical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5281</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5281</id><created>2012-06-20</created><authors><author><keyname>Ziebart</keyname><forenames>Brian D.</forenames></author><author><keyname>Dey</keyname><forenames>Anind K.</forenames></author><author><keyname>Bagnell</keyname><forenames>J Andrew</forenames></author></authors><title>Learning Selectively Conditioned Forest Structures with Applications to
  DBNs and Classification</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-458-465</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dealing with uncertainty in Bayesian Network structures using maximum a
posteriori (MAP) estimation or Bayesian Model Averaging (BMA) is often
intractable due to the superexponential number of possible directed, acyclic
graphs. When the prior is decomposable, two classes of graphs where efficient
learning can take place are tree structures, and fixed-orderings with limited
in-degree. We show how MAP estimates and BMA for selectively conditioned
forests (SCF), a combination of these two classes, can be computed efficiently
for ordered sets of variables. We apply SCFs to temporal data to learn Dynamic
Bayesian Networks having an intra-timestep forest and inter-timestep limited
in-degree structure, improving model accuracy over DBNs without the combination
of structures. We also apply SCFs to Bayes Net classification to learn
selective forest augmented Naive Bayes classifiers. We argue that the built-in
feature selection of selective augmented Bayes classifiers makes them
preferable to similar non-selective classifiers based on empirical evidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5282</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5282</id><created>2012-06-20</created><authors><author><keyname>Zhang</keyname><forenames>Jiji</forenames></author></authors><title>A Characterization of Markov Equivalence Classes for Directed Acyclic
  Graphs with Latent Variables</title><categories>stat.ME cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-450-457</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different directed acyclic graphs (DAGs) may be Markov equivalent in the
sense that they entail the same conditional independence relations among the
observed variables. Meek (1995) characterizes Markov equivalence classes for
DAGs (with no latent variables) by presenting a set of orientation rules that
can correctly identify all arrow orientations shared by all DAGs in a Markov
equivalence class, given a member of that class. For DAG models with latent
variables, maximal ancestral graphs (MAGs) provide a neat representation that
facilitates model search. Earlier work (Ali et al. 2005) has identified a set
of orientation rules sufficient to construct all arrowheads common to a Markov
equivalence class of MAGs. In this paper, we provide extra rules sufficient to
construct all common tails as well. We end up with a set of orientation rules
sound and complete for identifying commonalities across a Markov equivalence
class of MAGs, which is particularly useful for causal inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5283</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5283</id><created>2012-06-20</created><authors><author><keyname>Yang</keyname><forenames>Liu</forenames></author><author><keyname>Jin</keyname><forenames>Rong</forenames></author><author><keyname>Sukthankar</keyname><forenames>Rahul</forenames></author></authors><title>Bayesian Active Distance Metric Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-442-449</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance metric learning is an important component for many tasks, such as
statistical classification and content-based image retrieval. Existing
approaches for learning distance metrics from pairwise constraints typically
suffer from two major problems. First, most algorithms only offer point
estimation of the distance metric and can therefore be unreliable when the
number of training examples is small. Second, since these algorithms generally
select their training examples at random, they can be inefficient if labeling
effort is limited. This paper presents a Bayesian framework for distance metric
learning that estimates a posterior distribution for the distance metric from
labeled pairwise constraints. We describe an efficient algorithm based on the
variational method for the proposed Bayesian approach. Furthermore, we apply
the proposed Bayesian framework to active distance metric learning by selecting
those unlabeled example pairs with the greatest uncertainty in relative
distance. Experiments in classification demonstrate that the proposed framework
achieves higher classification accuracy and identifies more informative
training examples than the non-Bayesian approach and state-of-the-art distance
metric learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5284</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5284</id><created>2012-06-20</created><authors><author><keyname>Yaman</keyname><forenames>Fusun</forenames></author><author><keyname>desJardins</keyname><forenames>Marie</forenames></author></authors><title>More-or-Less CP-Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-434-441</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preferences play an important role in our everyday lives. CP-networks, or
CP-nets in short, are graphical models for representing conditional qualitative
preferences under ceteris paribus (&quot;all else being equal&quot;) assumptions. Despite
their intuitive nature and rich representation, dominance testing with CP-nets
is computationally complex, even when the CP-nets are restricted to
binary-valued preferences. Tractable algorithms exist for binary CP-nets, but
these algorithms are incomplete for multi-valued CPnets. In this paper, we
identify a class of multivalued CP-nets, which we call more-or-less CPnets,
that have the same computational complexity as binary CP-nets. More-or-less
CP-nets exploit the monotonicity of the attribute values and use intervals to
aggregate values that induce similar preferences. We then present a search
control rule for dominance testing that effectively prunes the search space
while preserving completeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5285</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5285</id><created>2012-06-20</created><authors><author><keyname>Wexler</keyname><forenames>Ydo</forenames></author><author><keyname>Geiger</keyname><forenames>Dan</forenames></author></authors><title>Importance Sampling via Variational Optimization</title><categories>stat.CO cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-426-433</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing the exact likelihood of data in large Bayesian networks consisting
of thousands of vertices is often a difficult task. When these models contain
many deterministic conditional probability tables and when the observed values
are extremely unlikely even alternative algorithms such as variational methods
and stochastic sampling often perform poorly. We present a new importance
sampling algorithm for Bayesian networks which is based on variational
techniques. We use the updates of the importance function to predict whether
the stochastic sampling converged above or below the true likelihood, and
change the proposal distribution accordingly. The validity of the method and
its contribution to convergence is demonstrated on hard networks of large
genetic linkage analysis tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5286</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5286</id><created>2012-06-20</created><authors><author><keyname>Weiss</keyname><forenames>Yair</forenames></author><author><keyname>Yanover</keyname><forenames>Chen</forenames></author><author><keyname>Meltzer</keyname><forenames>Talya</forenames></author></authors><title>MAP Estimation, Linear Programming and Belief Propagation with Convex
  Free Energies</title><categories>cs.AI cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-416-425</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding the most probable assignment (MAP) in a general graphical model is
known to be NP hard but good approximations have been attained with max-product
belief propagation (BP) and its variants. In particular, it is known that using
BP on a single-cycle graph or tree reweighted BP on an arbitrary graph will
give the MAP solution if the beliefs have no ties. In this paper we extend the
setting under which BP can be used to provably extract the MAP. We define
Convex BP as BP algorithms based on a convex free energy approximation and show
that this class includes ordinary BP with single-cycle, tree reweighted BP and
many other BP variants. We show that when there are no ties, fixed-points of
convex max-product BP will provably give the MAP solution. We also show that
convex sum-product BP at sufficiently small temperatures can be used to solve
linear programs that arise from relaxing the MAP problem. Finally, we derive a
novel condition that allows us to derive the MAP solution even if some of the
convex BP beliefs have ties. In experiments, we show that our theorems allow us
to find the MAP in many real-world instances of graphical models where exact
inference using junction-tree is impossible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5287</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5287</id><created>2012-06-20</created><authors><author><keyname>Wang</keyname><forenames>Chenggang</forenames></author><author><keyname>Khardon</keyname><forenames>Roni</forenames></author></authors><title>Policy Iteration for Relational MDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-408-415</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relational Markov Decision Processes are a useful abstraction for complex
reinforcement learning problems and stochastic planning problems. Recent work
developed representation schemes and algorithms for planning in such problems
using the value iteration algorithm. However, exact versions of more complex
algorithms, including policy iteration, have not been developed or analyzed.
The paper investigates this potential and makes several contributions. First we
observe two anomalies for relational representations showing that the value of
some policies is not well defined or cannot be calculated for restricted
representation schemes used in the literature. On the other hand, we develop a
variant of policy iteration that can get around these anomalies. The algorithm
includes an aspect of policy improvement in the process of policy evaluation
and thus differs from the original algorithm. We show that despite this
difference the algorithm converges to the optimal policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5288</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5288</id><created>2012-06-20</created><authors><author><keyname>Vorobeychik</keyname><forenames>Yevgeniy</forenames></author><author><keyname>Reeves</keyname><forenames>Daniel</forenames></author><author><keyname>Wellman</keyname><forenames>Michael P.</forenames></author></authors><title>Constrained Automated Mechanism Design for Infinite Games of Incomplete
  Information</title><categories>cs.GT cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-400-407</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a functional framework for automated mechanism design based on a
two-stage game model of strategic interaction between the designer and the
mechanism participants, and apply it to several classes of two-player infinite
games of incomplete information. At the core of our framework is a black-box
optimization algorithm which guides the selection process of candidate
mechanisms. Our approach yields optimal or nearly optimal mechanisms in several
application domains using various objective functions. By comparing our results
with known optimal mechanisms, and in some cases improving on the best known
mechanisms, we provide evidence that ours is a promising approach to parametric
design of indirect mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5289</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5289</id><created>2012-06-20</created><authors><author><keyname>Tian</keyname><forenames>Jin</forenames></author></authors><title>A Criterion for Parameter Identification in Structural Equation Models</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-392-399</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of identifying direct causal effects in
recursive linear structural equation models. The paper establishes a sufficient
criterion for identifying individual causal effects and provides a procedure
computing identified causal effects in terms of observed covariance matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5290</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5290</id><created>2012-06-20</created><authors><author><keyname>Syed</keyname><forenames>Umar</forenames></author><author><keyname>Schapire</keyname><forenames>Robert E.</forenames></author></authors><title>Imitation Learning with a Value-Based Prior</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-384-391</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of imitation learning is for an apprentice to learn how to behave in
a stochastic environment by observing a mentor demonstrating the correct
behavior. Accurate prior knowledge about the correct behavior can reduce the
need for demonstrations from the mentor. We present a novel approach to
encoding prior knowledge about the correct behavior, where we assume that this
prior knowledge takes the form of a Markov Decision Process (MDP) that is used
by the apprentice as a rough and imperfect model of the mentor's behavior.
Specifically, taking a Bayesian approach, we treat the value of a policy in
this modeling MDP as the log prior probability of the policy. In other words,
we assume a priori that the mentor's behavior is likely to be a high value
policy in the modeling MDP, though quite possibly different from the optimal
policy. We describe an efficient algorithm that, given a modeling MDP and a set
of demonstrations by a mentor, provably converges to a stationary point of the
log posterior of the mentor's policy, where the posterior is computed with
respect to the &quot;value based&quot; prior. We also present empirical evidence that
this prior does in fact speed learning of the mentor's policy, and is an
improvement in our experiments over similar previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5291</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5291</id><created>2012-06-20</created><authors><author><keyname>Sutton</keyname><forenames>Charles</forenames></author><author><keyname>McCallum</keyname><forenames>Andrew</forenames></author></authors><title>Improved Dynamic Schedules for Belief Propagation</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-376-383</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Belief propagation and its variants are popular methods for approximate
inference, but their running time and even their convergence depend greatly on
the schedule used to send the messages. Recently, dynamic update schedules have
been shown to converge much faster on hard networks than static schedules,
namely the residual BP schedule of Elidan et al. [2006]. But that RBP algorithm
wastes message updates: many messages are computed solely to determine their
priority, and are never actually performed. In this paper, we show that
estimating the residual, rather than calculating it directly, leads to
significant decreases in the number of messages required for convergence, and
in the total running time. The residual is estimated using an upper bound based
on recent work on message errors in BP. On both synthetic and real-world
networks, this dramatically decreases the running time of BP, in some cases by
a factor of five, without affecting the quality of the solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5292</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5292</id><created>2012-06-20</created><authors><author><keyname>Singla</keyname><forenames>Parag</forenames></author><author><keyname>Domingos</keyname><forenames>Pedro</forenames></author></authors><title>Markov Logic in Infinite Domains</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-368-375</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining first-order logic and probability has long been a goal of AI.
Markov logic (Richardson &amp; Domingos, 2006) accomplishes this by attaching
weights to first-order formulas and viewing them as templates for features of
Markov networks. Unfortunately, it does not have the full power of first-order
logic, because it is only defined for finite domains. This paper extends Markov
logic to infinite domains, by casting it in the framework of Gibbs measures
(Georgii, 1988). We show that a Markov logic network (MLN) admits a Gibbs
measure as long as each ground atom has a finite number of neighbors. Many
interesting cases fall in this category. We also show that an MLN admits a
unique measure if the weights of its non-unit clauses are small enough. We then
examine the structure of the set of consistent measures in the non-unique case.
Many important phenomena, including systems with phase transitions, are
represented by MLNs with non-unique measures. We relate the problem of
satisfiability in first-order logic to the properties of MLN measures, and
discuss how Markov logic relates to previous infinite models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5293</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5293</id><created>2012-06-20</created><authors><author><keyname>Silander</keyname><forenames>Tomi</forenames></author><author><keyname>Kontkanen</keyname><forenames>Petri</forenames></author><author><keyname>Myllymaki</keyname><forenames>Petri</forenames></author></authors><title>On Sensitivity of the MAP Bayesian Network Structure to the Equivalent
  Sample Size Parameter</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-360-367</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BDeu marginal likelihood score is a popular model selection criterion for
selecting a Bayesian network structure based on sample data. This
non-informative scoring criterion assigns same score for network structures
that encode same independence statements. However, before applying the BDeu
score, one must determine a single parameter, the equivalent sample size alpha.
Unfortunately no generally accepted rule for determining the alpha parameter
has been suggested. This is disturbing, since in this paper we show through a
series of concrete experiments that the solution of the network structure
optimization problem is highly sensitive to the chosen alpha parameter value.
Based on these results, we are able to give explanations for how and why this
phenomenon happens, and discuss ideas for solving this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5294</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5294</id><created>2012-06-20</created><authors><author><keyname>Shpitser</keyname><forenames>Ilya</forenames></author><author><keyname>Pearl</keyname><forenames>Judea</forenames></author></authors><title>What Counterfactuals Can Be Tested</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-352-359</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Counterfactual statements, e.g., &quot;my headache would be gone had I taken an
aspirin&quot; are central to scientific discourse, and are formally interpreted as
statements derived from &quot;alternative worlds&quot;. However, since they invoke
hypothetical states of affairs, often incompatible with what is actually known
or observed, testing counterfactuals is fraught with conceptual and practical
difficulties. In this paper, we provide a complete characterization of
&quot;testable counterfactuals,&quot; namely, counterfactual statements whose
probabilities can be inferred from physical experiments. We provide complete
procedures for discerning whether a given counterfactual is testable and, if
so, expressing its probability in terms of experimental data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5295</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5295</id><created>2012-06-20</created><authors><author><keyname>Seuken</keyname><forenames>Sven</forenames></author><author><keyname>Zilberstein</keyname><forenames>Shlomo</forenames></author></authors><title>Improved Memory-Bounded Dynamic Programming for Decentralized POMDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-344-351</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memory-Bounded Dynamic Programming (MBDP) has proved extremely effective in
solving decentralized POMDPs with large horizons. We generalize the algorithm
and improve its scalability by reducing the complexity with respect to the
number of observations from exponential to polynomial. We derive error bounds
on solution quality with respect to this new approximation and analyze the
convergence behavior. To evaluate the effectiveness of the improvements, we
introduce a new, larger benchmark problem. Experimental results show that
despite the high complexity of decentralized POMDPs, scalable solution
techniques such as MBDP perform surprisingly well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5313</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5313</id><created>2012-06-22</created><authors><author><keyname>El-Dosuky</keyname><forenames>M. A.</forenames></author><author><keyname>Rashad</keyname><forenames>M. Z.</forenames></author><author><keyname>Hamza</keyname><forenames>T. T.</forenames></author><author><keyname>EL-Bassiouny</keyname><forenames>A. H.</forenames></author></authors><title>Go Heuristics for Coverage of Dense Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper collects heuristics of Go Game and employs them to achieve
coverage of dense wireless sensor networks. In this paper, we propose an
algorithm based on Go heuristics and validate it. Investigations show that it
is very promising and could be seen as a good optimization. Keywords: Go
Heuristics, Wireless Sensor Networks, Coverage, Density
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5327</identifier>
 <datestamp>2015-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5327</id><created>2012-06-22</created><updated>2013-02-18</updated><authors><author><keyname>Ramli</keyname><forenames>Carroline Dewi Puspa Kencana</forenames></author><author><keyname>Nielson</keyname><forenames>Hanne Riis</forenames></author><author><keyname>Nielson</keyname><forenames>Flemming</forenames></author></authors><title>XACML 3.0 in Answer Set Programming</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a systematic technique for transforming XACML 3.0 policies in
Answer Set Programming (ASP). We show that the resulting logic program has a
unique answer set that directly corresponds to our formalisation of the
standard semantics of XACML 3.0 from Ramli et. al. We demonstrate how our
results make it possible to use off-the-shelf ASP solvers to formally verify
properties of access control policies represented in XACML, such as checking
the completeness of a set of access control policies and verifying policy
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5333</identifier>
 <datestamp>2014-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5333</id><created>2012-06-22</created><updated>2014-05-25</updated><authors><author><keyname>UzZaman</keyname><forenames>Naushad</forenames></author><author><keyname>Llorens</keyname><forenames>Hector</forenames></author><author><keyname>Allen</keyname><forenames>James</forenames></author><author><keyname>Derczynski</keyname><forenames>Leon</forenames></author><author><keyname>Verhagen</keyname><forenames>Marc</forenames></author><author><keyname>Pustejovsky</keyname><forenames>James</forenames></author></authors><title>TempEval-3: Evaluating Events, Time Expressions, and Temporal Relations</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We describe the TempEval-3 task which is currently in preparation for the
SemEval-2013 evaluation exercise. The aim of TempEval is to advance research on
temporal information processing. TempEval-3 follows on from previous TempEval
events, incorporating: a three-part task structure covering event, temporal
expression and temporal relation extraction; a larger dataset; and single
overall task quality scores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5335</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5335</id><created>2012-06-22</created><updated>2012-06-26</updated><authors><author><keyname>Khan</keyname><forenames>Sayandeep</forenames></author></authors><title>The McDougal Cave and Counting issues</title><categories>cs.DS math.GM</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper I investigate the problem of tagging elements of a set, and the
elements of those elements, uniquely, when they admit an order, and two
boundary elements are tagged. A heuristic sorting algorithm is also
investigated. (Updated grammar and spellings.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5336</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5336</id><created>2012-06-22</created><updated>2013-07-13</updated><authors><author><keyname>Barbay</keyname><forenames>J&#xe9;r&#xe9;my</forenames></author><author><keyname>Gupta</keyname><forenames>Ankur</forenames></author><author><keyname>Rao</keyname><forenames>S. Srinivasa</forenames></author><author><keyname>Sorenson</keyname><forenames>Jonathan</forenames></author></authors><title>Near-Optimal Online Multiselection in Internal and External Memory</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an online version of the multiselection problem, in which q
selection queries are requested on an unsorted array of n elements. We provide
the first online algorithm that is 1-competitive with Kaligosi et al. [ICALP
2005] in terms of comparison complexity. Our algorithm also supports online
search queries efficiently.
  We then extend our algorithm to the dynamic setting, while retaining online
functionality, by supporting arbitrary insertions and deletions on the array.
Assuming that the insertion of an element is immediately preceded by a search
for that element, we show that our dynamic online algorithm performs an optimal
number of comparisons, up to lower order terms and an additive O(n) term.
  For the external memory model, we describe the first online multiselection
algorithm that is O(1)-competitive. This result improves upon the work of
Sibeyn [Journal of Algorithms 2006] when q &gt; m, where m is the number of blocks
that can be stored in main memory. We also extend it to support searches,
insertions, and deletions of elements efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5343</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5343</id><created>2012-06-22</created><authors><author><keyname>Farnoud</keyname><forenames>Farzad</forenames><affiliation>Hassanzadeh</affiliation></author><author><keyname>Touri</keyname><forenames>Behrouz</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Nonuniform Vote Aggregation Algorithms</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of non-uniform vote aggregation, and in particular,
the algorithmic aspects associated with the aggregation process. For a novel
class of weighted distance measures on votes, we present two different
aggregation methods. The first algorithm is based on approximating the weighted
distance measure by Spearman's footrule distance, with provable constant
approximation guarantees. The second algorithm is based on a non-uniform Markov
chain method inspired by PageRank, for which currently only heuristic
guarantees are known. We illustrate the performance of the proposed algorithms
on a number of distance measures for which the optimal solution may be easily
computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5345</identifier>
 <datestamp>2012-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5345</id><created>2012-06-22</created><updated>2012-10-26</updated><authors><author><keyname>Tehrani</keyname><forenames>Pouya</forenames></author><author><keyname>Zhai</keyname><forenames>Yixuan</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>Dynamic Pricing under Finite Space Demand Uncertainty: A Multi-Armed
  Bandit with Dependent Arms</title><categories>cs.LG</categories><comments>21 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a dynamic pricing problem under unknown demand models. In this
problem a seller offers prices to a stream of customers and observes either
success or failure in each sale attempt. The underlying demand model is unknown
to the seller and can take one of N possible forms. In this paper, we show that
this problem can be formulated as a multi-armed bandit with dependent arms. We
propose a dynamic pricing policy based on the likelihood ratio test. We show
that the proposed policy achieves complete learning, i.e., it offers a bounded
regret where regret is defined as the revenue loss with respect to the case
with a known demand model. This is in sharp contrast with the logarithmic
growing regret in multi-armed bandit with independent arms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5348</identifier>
 <datestamp>2014-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5348</id><created>2012-06-22</created><updated>2013-02-23</updated><authors><author><keyname>Liu</keyname><forenames>Chun-Hung</forenames></author><author><keyname>Yu</keyname><forenames>Gexin</forenames></author></authors><title>Linear colorings of subcubic graphs</title><categories>math.CO cs.DM</categories><msc-class>05C15, 05C85</msc-class><journal-ref>European Journal of Combinatorics, Volume 34, Issue 6, August
  2013, Pages 1040-1050</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A linear coloring of a graph is a proper coloring of the vertices of the
graph so that each pair of color classes induce a union of disjoint paths. In
this paper, we prove that for every connected graph with maximum degree at most
three and every assignment of lists of size four to the vertices of the graph,
there exists a linear coloring such that the color of each vertex belongs to
the list assigned to that vertex and the neighbors of every degree-two vertex
receive different colors, unless the graph is $C_5$ or $K_{3,3}$. This confirms
a conjecture raised by Esperet, Montassier, and Raspaud. Our proof is
constructive and yields a linear-time algorithm to find such a coloring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5349</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5349</id><created>2012-06-22</created><updated>2012-11-11</updated><authors><author><keyname>Arora</keyname><forenames>Sanjeev</forenames></author><author><keyname>Ge</keyname><forenames>Rong</forenames></author><author><keyname>Moitra</keyname><forenames>Ankur</forenames></author><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author></authors><title>Provable ICA with Unknown Gaussian Noise, and Implications for Gaussian
  Mixtures and Autoencoders</title><categories>cs.LG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for Independent Component Analysis (ICA) which has
provable performance guarantees. In particular, suppose we are given samples of
the form $y = Ax + \eta$ where $A$ is an unknown $n \times n$ matrix and $x$ is
a random variable whose components are independent and have a fourth moment
strictly less than that of a standard Gaussian random variable and $\eta$ is an
$n$-dimensional Gaussian random variable with unknown covariance $\Sigma$: We
give an algorithm that provable recovers $A$ and $\Sigma$ up to an additive
$\epsilon$ and whose running time and sample complexity are polynomial in $n$
and $1 / \epsilon$. To accomplish this, we introduce a novel &quot;quasi-whitening&quot;
step that may be useful in other contexts in which the covariance of Gaussian
noise is not known in advance. We also give a general framework for finding all
local optima of a function (given an oracle for approximately finding just one)
and this is a crucial step in our algorithm, one that has been overlooked in
previous attempts, and allows us to control the accumulation of error when we
find the columns of $A$ one by one via local search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5352</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5352</id><created>2012-06-22</created><updated>2012-09-17</updated><authors><author><keyname>Goc</keyname><forenames>Daniel</forenames></author><author><keyname>Schaeffer</keyname><forenames>Luke</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Subword Complexity and k-Synchronization</title><categories>cs.FL cs.DM math.CO</categories><comments>Some new results and better exposition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the subword complexity function p_x(n), which counts the number
of distinct factors of length n of a sequence x, is k-synchronized in the sense
of Carpi if x is k-automatic. As an application, we generalize recent results
of Goldstein. We give analogous results for the number of distinct factors of
length n that are primitive words or powers. In contrast, we show that the
function that counts the number of unbordered factors of length n is not
necessarily k-synchronized for k-automatic sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5360</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5360</id><created>2012-06-23</created><authors><author><keyname>Nandy</keyname><forenames>Sudarshan</forenames></author><author><keyname>Sarkar</keyname><forenames>Partha Pratim</forenames></author><author><keyname>Das</keyname><forenames>Achintya</forenames></author></authors><title>Analysis of a Nature Inspired Firefly Algorithm based Back-propagation
  Neural Network Training</title><categories>cs.AI cs.NE</categories><comments>9 pages, 10 figures, Published with International Journal of Computer
  Applications (IJCA)</comments><journal-ref>International Journal of Computer Applications 43(22):8-16, April
  2012. Published by Foundation of Computer Science, New York, USA</journal-ref><doi>10.5120/6401-8339</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization algorithms are normally influenced by meta-heuristic approach.
In recent years several hybrid methods for optimization are developed to find
out a better solution. The proposed work using meta-heuristic Nature Inspired
algorithm is applied with back-propagation method to train a feed-forward
neural network. Firefly algorithm is a nature inspired meta-heuristic
algorithm, and it is incorporated into back-propagation algorithm to achieve
fast and improved convergence rate in training feed-forward neural network. The
proposed technique is tested over some standard data set. It is found that
proposed method produces an improved convergence within very few iteration.
This performance is also analyzed and compared to genetic algorithm based
back-propagation. It is observed that proposed method consumes less time to
converge and providing improved convergence rate with minimum feed-forward
neural network design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5361</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5361</id><created>2012-06-23</created><authors><author><keyname>Hussain</keyname><forenames>Ijaz</forenames></author><author><keyname>Riaz</keyname><forenames>Muhammad</forenames></author><author><keyname>Rehan</keyname><forenames>Muhammad</forenames></author><author><keyname>Ahmed</keyname><forenames>Shakeel</forenames></author></authors><title>Regional System Identification and Computer Based Switchable Control of
  a Nonlinear Hot Air Blower System</title><categories>cs.SY</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper describes the design and implementation of linear controllers with
a switching condition for a nonlinear hot air blower system (HABS) process
trainer PT326. The system is interfaced with a computer through a USB based
data acquisition module and interfacing circuitry. A calibration equation is
implemented through computer in order to convert the amplified output of the
sensor to temperature. Overall plant is nonlinear; therefore, system
identification is performed in three different regions depending upon the plant
input. For these three regions, three linear controllers are designed with
closed-loop system having small rise time, settling time and overshoot.
Switching of controllers is based on regions defined by plant input. In order
to avoid the effect of discontinuity, due to switching of linear controllers,
parameters of all linear controllers are taken closer to each other. Finally,
discretized controllers along with switching condition are implemented for the
plant through computer and practical results are demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5365</identifier>
 <datestamp>2014-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5365</id><created>2012-06-23</created><updated>2014-02-06</updated><authors><author><keyname>Yang</keyname><forenames>Shenghao</forenames></author><author><keyname>Yeung</keyname><forenames>Raymond W.</forenames></author></authors><title>Batched Sparse Codes</title><categories>cs.IT math.IT</categories><comments>51 pages, 12 figures, submitted to IEEE Transactions on Information
  Theory</comments><journal-ref>Information Theory, IEEE Transactions on , vol.60, no.9,
  pp.5322-5346, Sept. 2014</journal-ref><doi>10.1109/TIT.2014.2334315</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding can significantly improve the transmission rate of
communication networks with packet loss compared with routing. However, using
network coding usually incurs high computational and storage costs in the
network devices and terminals. For example, some network coding schemes require
the computational and/or storage capacities of an intermediate network node to
increase linearly with the number of packets for transmission, making such
schemes difficult to be implemented in a router-like device that has only
constant computational and storage capacities. In this paper, we introduce
BATched Sparse code (BATS code), which enables a digital fountain approach to
resolve the above issue. BATS code is a coding scheme that consists of an outer
code and an inner code. The outer code is a matrix generation of a fountain
code. It works with the inner code that comprises random linear coding at the
intermediate network nodes. BATS codes preserve such desirable properties of
fountain codes as ratelessness and low encoding/decoding complexity. The
computational and storage capacities of the intermediate network nodes required
for applying BATS codes are independent of the number of packets for
transmission. Almost capacity-achieving BATS code schemes are devised for
unicast networks, two-way relay networks, tree networks, a class of three-layer
networks, and the butterfly network. For general networks, under different
optimization criteria, guaranteed decoding rates for the receiving nodes can be
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5384</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5384</id><created>2012-06-23</created><authors><author><keyname>El-Shishtawy</keyname><forenames>Tarek</forenames></author><author><keyname>El-Ghannam</keyname><forenames>Fatma</forenames></author></authors><title>Keyphrase Based Arabic Summarizer (KPAS)</title><categories>cs.CL cs.AI</categories><comments>INFOS 2012, The 8th INFOS2012 International Conference on Informatics
  and Systems, 14-16 May, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a computationally inexpensive and efficient generic
summarization algorithm for Arabic texts. The algorithm belongs to extractive
summarization family, which reduces the problem into representative sentences
identification and extraction sub-problems. Important keyphrases of the
document to be summarized are identified employing combinations of statistical
and linguistic features. The sentence extraction algorithm exploits keyphrases
as the primary attributes to rank a sentence. The present experimental work,
demonstrates different techniques for achieving various summarization goals
including: informative richness, coverage of both main and auxiliary topics,
and keeping redundancy to a minimum. A scoring scheme is then adopted that
balances between these summarization goals. To evaluate the resulted Arabic
summaries with well-established systems, aligned English/Arabic texts are used
through the experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5386</identifier>
 <datestamp>2014-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5386</id><created>2012-06-23</created><authors><author><keyname>Dunfield</keyname><forenames>Joshua</forenames></author></authors><title>Elaborating Intersection and Union Types</title><categories>cs.PL</categories><comments>13 pages, 12 figures, to appear in International Conference on
  Functional Programming (ICFP) 2012</comments><doi>10.1017/S0956796813000270</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing and implementing typed programming languages is hard. Every new
type system feature requires extending the metatheory and implementation, which
are often complicated and fragile. To ease this process, we would like to
provide general mechanisms that subsume many different features.
  In modern type systems, parametric polymorphism is fundamental, but
intersection polymorphism has gained little traction in programming languages.
Most practical intersection type systems have supported only refinement
intersections, which increase the expressiveness of types (more precise
properties can be checked) without altering the expressiveness of terms;
refinement intersections can simply be erased during compilation. In contrast,
unrestricted intersections increase the expressiveness of terms, and can be
used to encode diverse language features, promising an economy of both theory
and implementation.
  We describe a foundation for compiling unrestricted intersection and union
types: an elaboration type system that generates ordinary lambda-calculus
terms. The key feature is a Forsythe-like merge construct. With this construct,
not all reductions of the source program preserve types; however, we prove that
ordinary call-by-value evaluation of the elaborated program corresponds to a
type-preserving evaluation of the source program.
  We also describe a prototype implementation and applications of unrestricted
intersections and unions: records, operator overloading, and simulating dynamic
typing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5389</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5389</id><created>2012-06-23</created><updated>2014-02-02</updated><authors><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>Information Networks with in-Block Memory</title><categories>cs.IT math.IT</categories><comments>Paper to appear in the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of channels is introduced for which there is memory inside blocks of
a specified length and no memory across the blocks. The multi-user model is
called an information network with in-block memory (NiBM). It is shown that
block-fading channels, channels with state known causally at the encoder, and
relay networks with delays are NiBMs. A cut-set bound is developed for NiBMs
that unifies, strengthens, and generalizes existing cut bounds for discrete
memoryless networks. The bound gives new finite-letter capacity expressions for
several classes of networks including point-to-point channels, and certain
multiaccess, broadcast, and relay channels. Cardinality bounds on the random
coding alphabets are developed that improve on existing bounds for channels
with action-dependent state available causally at the encoder and for relays
without delay. Finally, quantize-forward network coding is shown to achieve
rates within an additive gap of the new cut-set bound for linear, additive,
Gaussian noise channels, symmetric power constraints, and a multicast session.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5392</identifier>
 <datestamp>2014-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5392</id><created>2012-06-23</created><updated>2014-05-21</updated><authors><author><keyname>Chiplunkar</keyname><forenames>Ashish</forenames></author><author><keyname>Vishwanathan</keyname><forenames>Sundar</forenames></author></authors><title>Metrical Service Systems with Multiple Servers</title><categories>cs.DS</categories><comments>18 pages; accepted for publication at COCOON 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of metrical service systems with multiple servers
(MSSMS), which generalizes two well-known problems -- the $k$-server problem,
and metrical service systems. The MSSMS problem is to service requests, each of
which is an $l$-point subset of a metric space, using $k$ servers, with the
objective of minimizing the total distance traveled by the servers.
  Feuerstein initiated a study of this problem by proving upper and lower
bounds on the deterministic competitive ratio for uniform metric spaces. We
improve Feuerstein's analysis of the upper bound and prove that his algorithm
achieves a competitive ratio of $k({{k+l}\choose{l}}-1)$. In the randomized
online setting, for uniform metric spaces, we give an algorithm which achieves
a competitive ratio $\mathcal{O}(k^3\log l)$, beating the deterministic lower
bound of ${{k+l}\choose{l}}-1$. We prove that any randomized algorithm for
MSSMS on uniform metric spaces must be $\Omega(\log kl)$-competitive. We then
prove an improved lower bound of ${{k+2l-1}\choose{k}}-{{k+l-1}\choose{k}}$ on
the competitive ratio of any deterministic algorithm for $(k,l)$-MSSMS, on
general metric spaces. In the offline setting, we give a pseudo-approximation
algorithm for $(k,l)$-MSSMS on general metric spaces, which achieves an
approximation ratio of $l$ using $kl$ servers. We also prove a matching
hardness result, that a pseudo-approximation with less than $kl$ servers is
unlikely, even for uniform metric spaces. For general metric spaces, we
highlight the limitations of a few popular techniques, that have been used in
algorithm design for the $k$-server problem and metrical service systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5396</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5396</id><created>2012-06-23</created><updated>2012-06-28</updated><authors><author><keyname>Niepert</keyname><forenames>Mathias</forenames></author></authors><title>Markov Chains on Orbits of Permutation Groups</title><categories>cs.AI math.CO stat.CO</categories><comments>To appear in Proceedings of UAI2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to detecting and utilizing symmetries in
probabilistic graphical models with two main contributions. First, we present a
scalable approach to computing generating sets of permutation groups
representing the symmetries of graphical models. Second, we introduce orbital
Markov chains, a novel family of Markov chains leveraging model symmetries to
reduce mixing times. We establish an insightful connection between model
symmetries and rapid mixing of orbital Markov chains. Thus, we present the
first lifted MCMC algorithm for probabilistic graphical models. Both analytical
and empirical results demonstrate the effectiveness and efficiency of the
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5397</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5397</id><created>2012-06-23</created><updated>2012-12-31</updated><authors><author><keyname>Krithika</keyname><forenames>R.</forenames></author><author><keyname>Mathew</keyname><forenames>Rogers</forenames></author><author><keyname>Narayanaswamy</keyname><forenames>N. S.</forenames></author><author><keyname>Sadagopan</keyname><forenames>N.</forenames></author></authors><title>A Dirac-type Characterization of k-chordal Graphs</title><categories>math.CO cs.DM</categories><comments>3 pages</comments><msc-class>05C75</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Characterization of k-chordal graphs based on the existence of a &quot;simplicial
path&quot; was shown in [Chv{\'a}tal et al. Note: Dirac-type characterizations of
graphs without long chordless cycles. Discrete Mathematics, 256, 445-448,
2002]. We give a characterization of k-chordal graphs which is a generalization
of the known characterization of chordal graphs due to [G. A. Dirac. On rigid
circuit graphs. Abh. Math. Sem. Univ. Hamburg, 25, 71-76, 1961] that use
notions of a &quot;simplicial vertex&quot; and a &quot;simplicial ordering&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5401</identifier>
 <datestamp>2014-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5401</id><created>2012-06-23</created><updated>2014-04-20</updated><authors><author><keyname>Vituri</keyname><forenames>Shlomi</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Dispersion of Infinite Constellations in Fast Fading Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we extend the setting of communication without power constraint,
proposed by Poltyrev, to fast fading channels with channel state information
(CSI) at the receiver. The optimal codewords density, or actually the optimal
normalized log density (NLD), is considered. Poltyrev's capacity for this
channel is the highest achievable NLD, at possibly large block length, that
guarantees a vanishing error probability. For a given finite block length n and
a fixed error probability, there is a gap between the highest achievable NLD
and Poltyrev's capacity. As in other channels, this gap asymptotically vanishes
as the square root of the channel dispersion V over n, multiplied by the
inverse Q-function of the allowed error probability. This dispersion, derived
in the paper, equals the dispersion of the power constrained fast fading
channel at the high SNR regime. Connections to the error exponent of the peak
power constrained fading channel are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5421</identifier>
 <datestamp>2013-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5421</id><created>2012-06-23</created><updated>2013-02-19</updated><authors><author><keyname>Zhu</keyname><forenames>Kai</forenames></author><author><keyname>Ying</keyname><forenames>Lei</forenames></author></authors><title>Information Source Detection in the SIR Model: A Sample Path Based
  Approach</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of detecting the information source in a
network in which the spread of information follows the popular
Susceptible-Infected-Recovered (SIR) model. We assume all nodes in the network
are in the susceptible state initially except the information source which is
in the infected state. Susceptible nodes may then be infected by infected
nodes, and infected nodes may recover and will not be infected again after
recovery. Given a snapshot of the network, from which we know all infected
nodes but cannot distinguish susceptible nodes and recovered nodes, the problem
is to find the information source based on the snapshot and the network
topology. We develop a sample path based approach where the estimator of the
information source is chosen to be the root node associated with the sample
path that most likely leads to the observed snapshot. We prove for
infinite-trees, the estimator is a node that minimizes the maximum distance to
the infected nodes. A reverse-infection algorithm is proposed to find such an
estimator in general graphs. We prove that for $g$-regular trees such that
$gq&gt;1,$ where $g$ is the node degree and $q$ is the infection probability, the
estimator is within a constant distance from the actual source with a high
probability, independent of the number of infected nodes and the time the
snapshot is taken. Our simulation results show that for tree networks, the
estimator produced by the reverse-infection algorithm is closer to the actual
source than the one identified by the closeness centrality heuristic. We then
further evaluate the performance of the reverse infection algorithm on several
real world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5426</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5426</id><created>2012-06-23</created><authors><author><keyname>Chen</keyname><forenames>Jinyuan</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author></authors><title>Imperfect Delayed CSIT can be as Useful as Perfect Delayed CSIT: DoF
  Analysis and Constructions for the BC</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1205.3474</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the setting of the two-user broadcast channel, where a two-antenna
transmitter communicates information to two single-antenna receivers, recent
work by Maddah-Ali and Tse has shown that perfect knowledge of delayed channel
state information at the transmitter (perfect delayed CSIT) can be useful, even
in the absence of any knowledge of current CSIT. Similar benefits of perfect
delayed CSIT were revealed in recent work by Kobayashi et al., Yang et al., and
Gou and Jafar, which extended the above to the case of perfect delayed CSIT and
imperfect current CSIT.
  The work here considers the general problem of communicating, over the
aforementioned broadcast channel, with imperfect delayed and imperfect current
CSIT, and reveals that even substantially degraded and imperfect delayed-CSIT
is in fact sufficient to achieve the aforementioned gains previously associated
to perfect delayed CSIT. The work proposes novel multi-phase broadcasting
schemes that properly utilize knowledge of imperfect delayed and imperfect
current CSIT, to match in many cases the optimal degrees-of-freedom (DoF)
region achieved with perfect delayed CSIT. In addition to the theoretical
limits and explicitly constructed precoders, the work applies towards gaining
practical insight as to when it is worth improving CSIT quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5430</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5430</id><created>2012-06-23</created><authors><author><keyname>Arbaoui</keyname><forenames>Selma</forenames><affiliation>Prisme</affiliation></author><author><keyname>Cislo</keyname><forenames>N.</forenames></author><author><keyname>Smith-Guerin</keyname><forenames>N.</forenames></author></authors><title>Home Healthcare Process: Challenges and Open Issues</title><categories>cs.SE</categories><proxy>ccsd</proxy><journal-ref>Conference on Operational Research Applied to Health Service,
  ORAHS'2007, saint etienne : France (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Home healthcare is part of the most critical research and development
healthcare areas. The objective is to decentralize healthcare, leading to a
shift from in-hospital care to more advanced home healthcare, while improving
efficiency, individualisation, equity and quality of healthcare delivery and
limiting financial resources. In this paper, we adopt a process approach to
tackle the home healthcare domain in order to highlight the importance of
organisational aspects in the success of an ICT-home healthcare project. Such
projects should be supported by an automated system, called in this paper, Home
Healthcare support system. We examine HH processes from two selected
perspectives (complexity and dynamics) to illustrate the requirements of a HH
support system. We advocate that satisfying these requirements is part of the
most important challenges in the home healthcare research domain and we propose
first track of solutions by attempting to benefit from past experiences in 3
process research communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5451</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5451</id><created>2012-06-23</created><authors><author><keyname>Lamb</keyname><forenames>Christopher C.</forenames></author><author><keyname>Heileman</keyname><forenames>Gregory L.</forenames></author><author><keyname>Jamkhedkar</keyname><forenames>Pramod A.</forenames></author></authors><title>Usage Management of Personal Health Records</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personal health record (PHR) management is under new scrutiny as private
companies move into the market and government agencies actively address
perceived health care distribution inequalities and inefficiencies. Current
systems are coarse-grained and provide consumers very little actual control
over their data. Herein, we propose an alternative system for managing the use
of healthcare information. This novel system is finer grained, allows for data
mining and repackaging, and gives users more control over their data, allowing
it to be distributed to their specifications. In this paper, we outline the
characteristics of such a system in different contexts, present relevant
background information and research leading to the system design, and cover
specific usage scenarios supported by this system that are difficult to control
using simpler access control strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5459</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5459</id><created>2012-06-23</created><authors><author><keyname>Kuhn</keyname><forenames>N.</forenames></author><author><keyname>Lochin</keyname><forenames>E.</forenames></author><author><keyname>Lacan</keyname><forenames>J.</forenames></author><author><keyname>Boreli</keyname><forenames>R.</forenames></author><author><keyname>Bes</keyname><forenames>C.</forenames></author><author><keyname>Clarac</keyname><forenames>L.</forenames></author></authors><title>CLIFT: a Cross-Layer InFormation Tool to perform cross-layer analysis
  based on real physical traces</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering real physical (MAC/PHY) traces inside network simulations is a
complex task that might lead to complex yet approximated models. However,
realistic cross-layer analysis with the upper layer and in particular the
transport layer cannot be driven without considering the MAC/PHY level. In this
paper, we propose to cope with this problem by introducing a software that
translates real physical events from a given trace in order to be used inside a
network simulator such as $ns$-2. The main objective is to accurately perform
analysis of the impact of link layer reliability schemes (obtained by the use
of real physical traces) on transport layer performance. We detail the internal
mechanisms and the benefits of this software with a focus on 4G satellite
communications scenarios and present the resulting metrics provided by CLIFT to
perform consistent cross-layer analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5467</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5467</id><created>2012-06-24</created><authors><author><keyname>Florek</keyname><forenames>Jan</forenames></author></authors><title>Arc-Disjoint Cycles and Feedback Arc Sets</title><categories>math.CO cs.DM</categories><comments>5 pages, 3 figures</comments><msc-class>05C20, 05C38</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Isaak posed the following problem. Suppose $T$ is a tournament having a
minimum feedback arc set which induces an acyclic digraph with a hamiltonian
path. Is it true that the maximum number of arc-disjoint cycles in $T$ equals
the cardinality of minimum feedback arc set of $T$? We prove that the answer to
the problem is in the negative. Further, we study the number of arc-disjoint
cycles through a vertex $v$ of the minimum out-degree in an oriented graph $D$.
We prove that if $v$ is adjacent to all other vertices, then $v$ belongs to
$\delta^+(D)$ arc-disjoint cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5468</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5468</id><created>2012-06-24</created><authors><author><keyname>Modares</keyname><forenames>Hero</forenames><affiliation>Corresponding author</affiliation></author><author><keyname>Salleh</keyname><forenames>Rosli</forenames></author><author><keyname>Moravejosharieh</keyname><forenames>Amirhosein</forenames></author><author><keyname>Keshavarz</keyname><forenames>Hassan</forenames></author><author><keyname>Shahgoli</keyname><forenames>Majid Talebi</forenames></author></authors><title>A Survey on Cloud Computing Security</title><categories>cs.NI cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Computation encounter the new approach of cloud computing which maybe keeps
the world and possibly can prepare all the human's necessities. In other words,
cloud computing is the subsequent regular step in the evolution of on-demand
information technology services and products. The Cloud is a metaphor for the
Internet and is a concept for the covered complicated infrastructure; it also
depends on sketching in computer network diagrams. In this paper we will focus
on concept of cloud computing, cloud deployment models, cloud security
challenges encryption and data protection, privacy and security and data
management and movement from grid to cloud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5469</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5469</id><created>2012-06-24</created><authors><author><keyname>Aamir</keyname><forenames>Muhammad</forenames></author><author><keyname>Zaidi</keyname><forenames>Mustafa</forenames></author><author><keyname>Mansoor</keyname><forenames>Husnain</forenames></author></authors><title>Performance Analysis of DiffServ based Quality of Service in a
  Multimedia Wired Network and VPN effect using OPNET</title><categories>cs.NI</categories><comments>09 pages, 13 figures, 02 tables</comments><journal-ref>International Journal of Computer Science Issues (IJCSI), Vol. 9,
  Issue 3, May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality of Service (QoS) techniques are applied in IP networks to utilize
available network resources in the most efficient manner to minimize delays and
delay variations (jitters) in network traffic having multiple type of services.
Multimedia services may include voice, video and database. Researchers have
done considerable work on queuing disciplines to analyze and improve QoS
performance in wired and wireless IP networks. This paper highlights QoS
analysis in a wired IP network with more realistic enterprise modeling and
presents simulation results of a few statistics not presented and discussed
before. Four different applications are used i.e. FTP, Database, Voice over IP
(VoIP) and Video Conferencing (VC). Two major queuing disciplines are evaluated
i.e. 'Priority Queuing' and 'Weighted Fair Queuing' for packet identification
under Differentiated Services Code Point (DSCP). The simulation results show
that WFQ has an edge over PQ in terms of queuing delays and jitters experienced
by low priority services. For high priority traffic, dependency of 'Traffic
Drop', 'Buffer Usage' and 'Packet Delay Variation' on selected buffer sizes is
simulated and discussed to evaluate QoS deeper. In the end, it is also analyzed
how network's database service with applied Quality of Service may be affected
in terms of throughput (average rate of data received) for internal network
users when the server is also accessed by external user(s) through Virtual
Private Network (VPN).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5483</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5483</id><created>2012-06-24</created><authors><author><keyname>Verbaas</keyname><forenames>Jorg</forenames></author></authors><title>It takes two to tango. A Review of the Empirical Literature on
  Information Technology Outsourcing Relationship Satisfaction</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is growing recognition that the overall client-vendor relationship, and
not only the contract, plays a critical role in Information Technology
Outsourcing (ITO) success. However, our understanding of how ITO relationships
function is limited. This paper contributes to this understanding by reviewing
empirical literature on ITO success in terms of relationship satisfaction. A
key finding is that the majority of reviewed studies concentrates on client
satisfaction, thus neglecting the vendor perspective. We argue that this raises
questions about the construct validity of these studies. Consequently, concerns
exist about the validity and reliability of their empirical findings. Some
scholars have acknowledged the problem and use a dyadic perspective. However, a
review of these studies reveals that the authors have underestimated their
contributions and do not explain why there is a problem. Therefore, the purpose
of this paper is to highlight their contributions by comparing the findings of
the dyadic perspective studies with those of the &quot;client perspective&quot; research.
In doing so, we assess whether the dyadic studies produce better explanations
for ITO success than the client-oriented studies. We argue that this is indeed
the case, by producing a better view on how underlying mechanisms of ITO
relationships work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5487</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5487</id><created>2012-06-24</created><authors><author><keyname>Hussein</keyname><forenames>Sari Haj</forenames></author></authors><title>A Precise Information Flow Measure from Imprecise Probabilities</title><categories>cs.CR</categories><comments>10 pages. Appeared in the 6th International Conference on Software
  Security and Reliability (SERE 2012), Washington D.C., The United States,
  Proceedings of the 6th International Conference on Software Security and
  Reliability (SERE 2012), Washington D.C., The United States</comments><doi>10.1109/SERE.2012.25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dempster-Shafer theory of imprecise probabilities has proved useful to
incorporate both nonspecificity and conflict uncertainties in an inference
mechanism. The traditional Bayesian approach cannot differentiate between the
two, and is unable to handle non-specific, ambiguous, and conflicting
information without making strong assumptions. This paper presents a
generalization of a recent Bayesian-based method of quantifying information
flow in Dempster-Shafer theory. The generalization concretely enhances the
original method removing all its weaknesses that are highlighted in this paper.
In so many words, our generalized method can handle any number of secret inputs
to a program, it enables the capturing of an attacker's beliefs in all kinds of
sets (singleton or not), and it supports a new and precise quantitative
information flow measure whose reported flow results are plausible in that they
are bounded by the size of a program's secret input, and can be easily
associated with the exhaustive search effort needed to uncover a program's
secret information, unlike the results reported by the original metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5501</identifier>
 <datestamp>2012-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5501</id><created>2012-06-24</created><updated>2012-08-28</updated><authors><author><keyname>Lysikov</keyname><forenames>Vladimir</forenames></author></authors><title>On bilinear algorithms for multiplication in quaternion algebras</title><categories>cs.CC</categories><comments>2 pages, LaTeX; grammar fix</comments><journal-ref>Proceedings of the XI international seminar &quot;Discrete mathematics
  and its applications&quot;, pp. 141--144 (in Russian).
  http://mech.math.msu.su/department/dm/dmmc/CONF/sbornik_2012.pdf</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the bilinear complexity of multiplication in a non-split
quaternion algebra over a field of characteristic distinct from 2 is 8. This
question is motivated by the problem of characterising algebras of almost
minimal rank studied by Blaeser and de Voltaire in [1].
  This paper is a translation of a report submitted by the author to the XI
international seminar &quot;Discrete mathematics and applications&quot; (in Russian).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5503</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5503</id><created>2012-06-24</created><updated>2015-02-14</updated><authors><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author><author><keyname>Mitrovic-Minic</keyname><forenames>Snezana</forenames></author><author><keyname>Malladi</keyname><forenames>Krishna T.</forenames></author><author><keyname>Punnen</keyname><forenames>Abraham P.</forenames></author></authors><title>Satellite downlink scheduling problem: A case study</title><categories>math.OC cs.DM</categories><comments>23 pages</comments><journal-ref>Omega 53 (2015) 115-123</journal-ref><doi>10.1016/j.omega.2015.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The synthetic aperture radar (SAR) technology enables satellites to
efficiently acquire high quality images of the Earth surface. This generates
significant communication traffic from the satellite to the ground stations,
and, thus, image downlinking often becomes the bottleneck in the efficiency of
the whole system. In this paper we address the downlink scheduling problem for
Canada's Earth observing SAR satellite, RADARSAT-2. Being an applied problem,
downlink scheduling is characterised with a number of constraints that make it
difficult not only to optimise the schedule but even to produce a feasible
solution. We propose a fast schedule generation procedure that abstracts the
problem specific constraints and provides a simple interface to optimisation
algorithms. By comparing empirically several standard meta-heuristics applied
to the problem, we select the most suitable one and show that it is clearly
superior to the approach currently in use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5505</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5505</id><created>2012-06-24</created><authors><author><keyname>Monisha</keyname><forenames>J. Hannah</forenames></author><author><keyname>Uthariaraj</keyname><forenames>V. Rhymend</forenames></author></authors><title>Enhanced MAC Parameters to Support Hybrid Dynamic Prioritization in
  MANETs</title><categories>cs.NI</categories><comments>7 pages</comments><journal-ref>International Journal of Computer Applications 45(18):35-41, May
  2012</journal-ref><doi>10.5120/7021-9754</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality of Service (QoS) for MANETs becomes a necessity because of its
applications in decisive situations such as battle fields, flood and earth
quake. Users belonging to diverse hierarchical category demanding various
levels of QoS use MANETs. Sometimes, even a low category user may need to send
an urgent message in time critical applications. Hence providing prioritization
based on user category and urgency of the message the user is sending becomes
necessary. In this paper we propose Enhanced MAC parameters to support Hybrid
Dynamic priority in MANETs(H-MAC). It combines both prioritization based on
user categorization and dynamic exigency. Order Statistics is used to implement
dynamic priority. We propose dynamic TXOP, Proportional AIFS and Proportional
dynamic Backoff timers based on weights and collision, to avoid packet dropping
and starvation of lower priorities. The model is simulated in ns2. We compare
our results with IEEE 802.11e and show that, 16% more throughput is achieved by
H-MAC during extensive collision. We also observe that starvation and packet
drops are reduced with proportionate bandwidth sharing compared to the existing
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5520</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5520</id><created>2012-06-24</created><authors><author><keyname>Zinoviev</keyname><forenames>Dmitry</forenames></author><author><keyname>Stefanescu</keyname><forenames>Dan</forenames></author><author><keyname>Swenson</keyname><forenames>Lance</forenames></author><author><keyname>Fireman</keyname><forenames>Gary</forenames></author></authors><title>Semantic Networks of Interests in Online NSSI Communities</title><categories>cs.SI</categories><comments>5 pages, 3 figures. Presented at Words and Networks: Language Use in
  Socio-Technical Networks (workshop at 2012 ACM Web Science Conference)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Persons who engage in non-suicidal self-injury (NSSI), often conceal their
practices which limits the examination and understanding of those who engage in
NSSI. The goal of this research is to utilize public online social networks
(namely, in LiveJournal, a major blogging network) to observe the NSSI
population's communication in a naturally occurring setting. Specifically,
LiveJournal users can publicly declare their interests. We collected the
self-declared interests of 22,000 users who are members of or participate in 43
NSSI-related communities. We extracted a bimodal socio-semantic network of
users and interests based on their similarity. The semantic subnetwork of
interests contains NSSI terms (such as &quot;self-injury&quot; and &quot;razors&quot;), references
to music performers (such as &quot;Nine Inch Nails&quot;), and general daily life and
creativity related terms (such as &quot;poetry&quot; and &quot;boys&quot;). Assuming users are
genuine in their declarations, the words reveal distinct patterns of interest
and may signal keys to NSSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5525</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5525</id><created>2012-06-24</created><authors><author><keyname>Alizadeh</keyname><forenames>Alireza</forenames></author><author><keyname>Hodtani</keyname><forenames>Ghosheh Abed</forenames></author></authors><title>Analysis of Coverage Region for MIMO Relay Channel</title><categories>cs.IT math.IT</categories><comments>To appear in 9th IEEE International Symposium on Wireless
  Communication Systems (ISWCS'2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the optimal relay location in the sense of
maximizing suitably defined coverage region for MIMO relay channel. We consider
the general Rayleigh fading case and assume that the channel state information
is only available at the receivers (CSIR), which is an important practical case
in applications such as cooperative vehicular communications. In order to
overcome the mathematical difficulty regarding determination of the optimal
relay location, we provide two analytical solutions, and show that it is
possible to determine the optimal relay location (for a desired transmission
rate) at which the coverage region is maximum. Monte Carlo simulations confirm
the validity of the analytical results. Numerical results indicate that using
multiple antennas increases coverage region for a fixed transmission rate, and
also increases the transmission rate linearly for a fixed coverage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5533</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5533</id><created>2012-06-24</created><updated>2012-09-16</updated><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Practical recommendations for gradient-based training of deep
  architectures</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning algorithms related to artificial neural networks and in particular
for Deep Learning may seem to involve many bells and whistles, called
hyper-parameters. This chapter is meant as a practical guide with
recommendations for some of the most commonly used hyper-parameters, in
particular in the context of learning algorithms based on back-propagated
gradient and gradient-based optimization. It also discusses how to deal with
the fact that more interesting results can be obtained when allowing one to
adjust many hyper-parameters. Overall, it describes elements of the practice
used to successfully and efficiently train and debug large-scale and often deep
multi-layer neural networks. It closes with open questions about the training
difficulties observed with deeper architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5538</identifier>
 <datestamp>2014-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5538</id><created>2012-06-24</created><updated>2014-04-23</updated><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames></author></authors><title>Representation Learning: A Review and New Perspectives</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The success of machine learning algorithms generally depends on data
representation, and we hypothesize that this is because different
representations can entangle and hide more or less the different explanatory
factors of variation behind the data. Although specific domain knowledge can be
used to help design representations, learning with generic priors can also be
used, and the quest for AI is motivating the design of more powerful
representation-learning algorithms implementing such priors. This paper reviews
recent work in the area of unsupervised feature learning and deep learning,
covering advances in probabilistic models, auto-encoders, manifold learning,
and deep networks. This motivates longer-term unanswered questions about the
appropriate objectives for learning good representations, for computing
representations (i.e., inference), and the geometrical connections between
representation learning, density estimation and manifold learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5548</identifier>
 <datestamp>2015-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5548</id><created>2012-06-24</created><authors><author><keyname>Cain</keyname><forenames>Alan J.</forenames></author><author><keyname>Ru&#x161;kuc</keyname><forenames>Nik</forenames></author></authors><title>Subalgebras of FA-presentable algebras</title><categories>math.LO cs.FL</categories><comments>19 pages, 6 figures</comments><msc-class>08A30 (Primary) 03D45, 68Q45 (Secondary)</msc-class><journal-ref>Algebra Universalis, 72, no. 2 (October 2014), pp. 101--123</journal-ref><doi>10.1007/s00012-014-0293-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatic presentations, also called FA-presentations, were introduced to
extend finite model theory to infinite structures whilst retaining the
solubility of fundamental decision problems. This paper studies FA-presentable
algebras. First, an example is given to show that the class of finitely
generated FA-presentable algebras is not closed under forming finitely
generated subalgebras, even within the class of algebras with only unary
operations. However, it is proven that a finitely generated subalgebra of an
FA-presentable algebra with a single unary operation is itself FA-presentable.
Furthermore, it is proven that the class of unary FA-presentable algebras is
closed under forming finitely generated subalgebras, and that the membership
problem for such subalgebras is decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5559</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5559</id><created>2012-06-24</created><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>Speeding up the construction of slow adaptive walks</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm (bliss) is proposed to speed up the construction of slow
adaptive walks. Slow adaptive walks are adaptive walks biased towards closer
points or smaller move steps. They were previously introduced to explore a
search space, e.g. to detect potential local optima or to assess the ruggedness
of a fitness landscape. To avoid the quadratic cost of computing Hamming
distance (HD) for all-pairs of strings in a set in order to find the set of
closest strings for each string, strings are sorted and clustered by bliss such
that similar strings are more likely to get paired off for HD computation. To
efficiently arrange the strings by similarity, bliss employs the idea of shared
non-overlapping position specific subsequences between strings which is
inspired by an alignment-free protein sequence comparison algorithm. Tests are
performed to evaluate the quality of b-walks, i.e. slow adaptive walks
constructed from the output of bliss, on enumerated search spaces. Finally,
b-walks are applied to explore larger search spaces with the help of
Wang-Landau sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5580</identifier>
 <datestamp>2014-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5580</id><created>2012-06-25</created><updated>2014-03-15</updated><authors><author><keyname>Moeller</keyname><forenames>John</forenames></author><author><keyname>Raman</keyname><forenames>Parasaran</forenames></author><author><keyname>Saha</keyname><forenames>Avishek</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>A Geometric Algorithm for Scalable Multiple Kernel Learning</title><categories>cs.LG stat.ML</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a geometric formulation of the Multiple Kernel Learning (MKL)
problem. To do so, we reinterpret the problem of learning kernel weights as
searching for a kernel that maximizes the minimum (kernel) distance between two
convex polytopes. This interpretation combined with novel structural insights
from our geometric formulation allows us to reduce the MKL problem to a simple
optimization routine that yields provable convergence as well as quality
guarantees. As a result our method scales efficiently to much larger data sets
than most prior methods can handle. Empirical evaluation on eleven datasets
shows that we are significantly faster and even compare favorably with a
uniform unweighted combination of kernels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5582</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5582</id><created>2012-06-25</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Chougule</keyname><forenames>Archana</forenames></author></authors><title>A Survey on Web Service Discovery Approaches</title><categories>cs.IR</categories><comments>12 pages, 1 figure</comments><journal-ref>Advances in Computer Science, Eng. &amp; Appl., AISC 166, pp.
  1001-1012, Springerlink, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web services are playing an important role in e-business and e-commerce
applications. As web service applications are interoperable and can work on any
platform, large scale distributed systems can be developed easily using web
services. Finding most suitable web service from vast collection of web
services is very crucial for successful execution of applications. Traditional
web service discovery approach is a keyword based search using UDDI. Various
other approaches for discovering web services are also available. Some of the
discovery approaches are syntax based while other are semantic based. Having
system for service discovery which can work automatically is also the concern
of service discovery approaches. As these approaches are different, one
solution may be better than another depending on requirements. Selecting a
specific service discovery system is a hard task. In this paper, we give an
overview of different approaches for web service discovery described in
literature. We present a survey of how these approaches differ from each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5584</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5584</id><created>2012-06-25</created><authors><author><keyname>Sinha</keyname><forenames>Sukanta</forenames></author><author><keyname>Duttagupta</keyname><forenames>Rana</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author></authors><title>Web-page Prediction for Domain Specific Web-search using Boolean Bit
  Mask</title><categories>cs.IR</categories><comments>10 pages, 3 figures</comments><journal-ref>Advances in Computer Science, Eng. &amp; Appl., AISC 167, pp. 211-220,
  Springerlink, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search Engine is a Web-page retrieval tool. Nowadays Web searchers utilize
their time using an efficient search engine. To improve the performance of the
search engine, we are introducing a unique mechanism which will give Web
searchers more prominent search results. In this paper, we are going to discuss
a domain specific Web search prototype which will generate the predicted
Web-page list for user given search string using Boolean bit mask.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5587</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5587</id><created>2012-06-25</created><updated>2012-09-20</updated><authors><author><keyname>Shad</keyname><forenames>Shafqat Ali</forenames></author><author><keyname>Chen</keyname><forenames>Enhong</forenames></author></authors><title>Spatial Outlier Detection from GSM Mobility Data</title><categories>cs.NI</categories><journal-ref>International Journal of Advanced Research in Computer Science,
  vol. 3, no. 3, pp. 68-74, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors. With the rigorous growth of
cellular network many mobility datasets are available publically, which
attracted researchers to study human mobility fall under spatio-temporal
phenomenon. Mobility profile building is main task in spatio-temporal trend
analysis which can be extracted from the location information available in the
dataset. The location information is usually gathered through the GPS, service
provider assisted faux GPS and Cell Global Identity (CGI). Because of high
power consumption and extra resource installation requirement in GPS related
methods, Cell Global Identity is most inexpensive method and readily available
solution for location information. CGI location information is four set head
i.e. Mobile country code (MCC), Mobile network code (MNC), Location area code
(LAC) and Cell ID, location information is retrieved in form of longitude and
latitude coordinates through any of publically available Cell Id databases e.g.
Google location API using CGI. However due to of fast growth in GSM network,
change in topology by the GSM service provider and technology shift toward 3G
exact spatial extraction is somehow a problem in it, so location extraction
must dealt with spatial outlier's problem first for mobility building. In this
paper we proposed a methodology for the detection of spatial outliers from GSM
CGI data, the proposed methodology is hierarchical clustering based and used
the basic GSM network architecture properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5617</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5617</id><created>2012-06-25</created><authors><author><keyname>Gavili</keyname><forenames>Adnan</forenames></author><author><keyname>Kenari</keyname><forenames>Masoumeh Nasiri</forenames></author></authors><title>Robust Downlink Throughput Maximization in MIMO Cognitive Network with
  more Realistic Conditions: Imperfect Channel Information &amp; Presence of
  Primary Transmitter</title><categories>cs.IT math.IT</categories><comments>37 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing an efficient scheme in physical layer enables cognitive radio (CR)
users to efficiently utilize resources dedicated to primary users (PUs). In
this paper in order to maximize the SU's throughput, the SU's transceivers
beamforming is designed through new model considering the presence of the PU's
transmitter. Since presence of primary transmitter basically degrades CR's
system performance; proposed beamforming design considers intra-system
interference between PUs and SUs. An optimization problem based on maximizing
CR network throughput subject to controlling interference power from SU
transmitter to PU receiver has been formulated. Due to limited cooperation
between PU and SU network, channel state information (CSI) between two networks
are assumed to be partially available, subsequently conventional CSI
uncertainty model known as norm bounded error model has been employed. The
proposed optimization problem, which is basically difficult to solve, has been
converted to a semi definite program which can be efficiently solved by
optimization toolbox software e.g., CVX-Mathlab. Furthermore, alternative time
efficient and close form solutions are derived. The superiority of the proposed
approach in comparison with the previous works has been confirmed through the
simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5637</identifier>
 <datestamp>2013-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5637</id><created>2012-06-25</created><updated>2013-08-02</updated><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author></authors><title>What you can do with Coordinated Samples</title><categories>cs.DB math.ST stat.TH</categories><comments>4 figures, 21 pages, Extended Abstract appeared in RANDOM 2013</comments><acm-class>G.3; E.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sample coordination, where similar instances have similar samples, was
proposed by statisticians four decades ago as a way to maximize overlap in
repeated surveys. Coordinated sampling had been since used for summarizing
massive data sets.
  The usefulness of a sampling scheme hinges on the scope and accuracy within
which queries posed over the original data can be answered from the sample. We
aim here to gain a fundamental understanding of the limits and potential of
coordination. Our main result is a precise characterization, in terms of simple
properties of the estimated function, of queries for which estimators with
desirable properties exist. We consider unbiasedness, nonnegativity, finite
variance, and bounded estimates.
  Since generally a single estimator can not be optimal (minimize variance
simultaneously) for all data, we propose {\em variance competitiveness}, which
means that the expectation of the square on any data is not too far from the
minimum one possible for the data. Surprisingly perhaps, we show how to
construct, for any function for which an unbiased nonnegative estimator exists,
a variance competitive estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5648</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5648</id><created>2012-06-25</created><updated>2013-09-19</updated><authors><author><keyname>Trudel</keyname><forenames>Marco</forenames></author><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Nordio</keyname><forenames>Martin</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author><author><keyname>Oriol</keyname><forenames>Manuel</forenames></author></authors><title>C to O-O Translation: Beyond the Easy Stuff</title><categories>cs.PL</categories><journal-ref>Proceedings of the 19th Working Conference on Reverse Engineering
  (WCRE'12). Pgg. 19--28, IEEE Computer Society, October 2012</journal-ref><doi>10.1109/WCRE.2012.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can we reuse some of the huge code-base developed in C to take advantage of
modern programming language features such as type safety, object-orientation,
and contracts? This paper presents a source-to-source translation of C code
into Eiffel, a modern object-oriented programming language, and the supporting
tool C2Eif. The translation is completely automatic and supports the entire C
language (ANSI, as well as many GNU C Compiler extensions, through CIL) as used
in practice, including its usage of native system libraries and inlined
assembly code. Our experiments show that C2Eif can handle C applications and
libraries of significant size (such as vim and libgsl), as well as challenging
benchmarks such as the GCC torture tests. The produced Eiffel code is
functionally equivalent to the original C code, and takes advantage of some of
Eiffel's object-oriented features to produce safe and easy-to-debug
translations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5651</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5651</id><created>2012-06-25</created><updated>2012-07-14</updated><authors><author><keyname>Ramamurthy</keyname><forenames>Garimella</forenames></author><author><keyname>Nischal</keyname><forenames>Bondalapati</forenames></author></authors><title>Optimization of Real, Hermitian Quadratic Forms: Real, Complex
  Hopfield-Amari Neural Network</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research paper, the problem of optimization of quadratic forms
associated with the dynamics of Hopfield-Amari neural network is considered. An
elegant (and short) proof of the states at which local/global minima of
quadratic form are attained is provided. A theorem associated with local/global
minimization of quadratic energy function using the Hopfield-Amari neural
network is discussed. The results are generalized to a &quot;Complex Hopfield neural
network&quot; dynamics over the complex hypercube (using a &quot;complex signum
function&quot;). It is also reasoned through two theorems that there is no loss of
generality in assuming the threshold vector to be a zero vector in the case of
real as well as a &quot;Complex Hopfield neural network&quot;. Some structured quadratic
forms like Toeplitz form and Complex Toeplitz form are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5655</identifier>
 <datestamp>2014-02-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5655</id><created>2012-06-25</created><authors><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author><author><keyname>Satoh</keyname><forenames>Takahiko</forenames></author><author><keyname>Ladd</keyname><forenames>Thaddeus D.</forenames></author><author><keyname>Munro</keyname><forenames>William J.</forenames></author><author><keyname>Nemoto</keyname><forenames>Kae</forenames></author></authors><title>Path Selection for Quantum Repeater Networks</title><categories>quant-ph cs.ET cs.NI</categories><comments>12 pages, 8 figures</comments><journal-ref>Networking Science, December 2013, Volume 3, Issue 1-4, pp 82-95</journal-ref><doi>10.1007/s13119-013-0026-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum networks will support long-distance quantum key distribution (QKD)
and distributed quantum computation, and are an active area of both
experimental and theoretical research. Here, we present an analysis of
topologically complex networks of quantum repeaters composed of heterogeneous
links. Quantum networks have fundamental behavioral differences from classical
networks; the delicacy of quantum states makes a practical path selection
algorithm imperative, but classical notions of resource utilization are not
directly applicable, rendering known path selection mechanisms inadequate. To
adapt Dijkstra's algorithm for quantum repeater networks that generate
entangled Bell pairs, we quantify the key differences and define a link cost
metric, seconds per Bell pair of a particular fidelity, where a single Bell
pair is the resource consumed to perform one quantum teleportation. Simulations
that include both the physical interactions and the extensive classical
messaging confirm that Dijkstra's algorithm works well in a quantum context.
Simulating about three hundred heterogeneous paths, comparing our path cost and
the total work along the path gives a coefficient of determination of 0.88 or
better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5669</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5669</id><created>2012-06-25</created><authors><author><keyname>Abrego</keyname><forenames>Bernardo M.</forenames></author><author><keyname>Aichholzer</keyname><forenames>Oswin</forenames></author><author><keyname>Fernandez-Merchant</keyname><forenames>Silvia</forenames></author><author><keyname>Ramos</keyname><forenames>Pedro</forenames></author><author><keyname>Salazar</keyname><forenames>Gelasio</forenames></author></authors><title>The 2-page crossing number of $K_n$</title><categories>math.CO cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Around 1958, Hill described how to draw the complete graph $K_n$ with [Z(n)
:=1/4\lfloor \frac{n}{2}\rfloor \lfloor \frac{n-1}{2}\rfloor \lfloor
\frac{n-2}{2}% \rfloor \lfloor \frac{n-3}{2}\rfloor] crossings, and conjectured
that the crossing number $\crg (K_{n})$ of $K_n$ is exactly Z(n). This is also
known as Guy's conjecture as he later popularized it. Towards the end of the
century, substantially different drawings of $K_{n}$ with Z(n) crossings were
found. These drawings are \emph{2-page book drawings}, that is, drawings where
all the vertices are on a line $\ell$ (the spine) and each edge is fully
contained in one of the two half-planes (pages) defined by $\ell$. The
\emph{2-page crossing number} of $K_{n} $, denoted by $\nu_{2}(K_{n})$, is the
minimum number of crossings determined by a 2-page book drawing of $K_{n}% $.
Since $\crg(K_{n}) \le\nu_{2}(K_{n})$ and $\nu_{2}(K_{n}) \le Z(n)$, a natural
step towards Hill's Conjecture is the %(formally) weaker conjecture
$\nu_{2}(K_{n}) = Z(n)$, popularized by Vrt'o. %As far as we know, this natural
%conjecture was first raised by Imrich Vrt'o in 2007. %Prior to this paper,
results known for $\nu_2(K_n)$ were basically %the same as for $\crg (K_n)$.
Here In this paper we develop a novel and innovative technique to investigate
crossings in drawings of $K_{n}$, and use it to prove that $\nu_{2}(K_{n}) =
Z(n) $. To this end, we extend the inherent geometric definition of $k$-edges
for finite sets of points in the plane to topological drawings of $K_{n}$. We
also introduce the concept of ${\leq}{\leq}k$-edges as a useful generalization
of ${\leq}k$-edges and extend a powerful theorem that expresses the number of
crossings in a rectilinear drawing of $K_{n}$ in terms of its number of $(\le
k)$-edges to the topological setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5673</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5673</id><created>2012-06-22</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Nain</keyname><forenames>Philippe</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Yechiali</keyname><forenames>Uri</forenames></author></authors><title>A retrial system with two input streams and two orbit queues</title><categories>cs.DM</categories><comments>N&amp;deg; RR-7999 (2012)</comments><proxy>ccsd</proxy><report-no>RR-7999</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two independent Poisson streams of jobs flow into a single-server service
system having a limited common buffer that can hold at most one job. If a
type-i job (i=1,2) finds the server busy, it is blocked and routed to a
separate type-i retrial (orbit) queue that attempts to re-dispatch its jobs at
its specific Poisson rate. This creates a system with three dependent queues.
Such a queueing system serves as a model for two competing job streams in a
carrier sensing multiple access system. We study the queueing system using
multi-dimensional probability generating functions, and derive its necessary
and sufficient stability conditions while solving a boundary value problem.
Various performance measures are calculated and numerical results are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5674</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5674</id><created>2012-06-22</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Piunovskiy</keyname><forenames>Alexei</forenames></author><author><keyname>Yi</keyname><forenames>Zhang</forenames></author></authors><title>Markov Processes with Restart</title><categories>math.PR cs.DM</categories><comments>N&amp;deg; RR-8000 (2012)</comments><proxy>ccsd</proxy><report-no>RR-8000</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general honest homogeneous continuous-time Markov process with
restarts. The process is forced to restart from a given distribution at time
moments generated by an independent Poisson process. The motivation to study
such processes comes from modeling human and animal mobility patterns, restart
processes in communication protocols, and from application of restarting random
walks in information retrieval. We provide a connection between the transition
probability functions of the original Markov process and the modified process
with restarts. We give closed-form expressions for the invariant probability
measure of the modified process. When the process evolves on the Euclidean
space there is also a closed-form expression for the moments of the modified
process. We show that the modified process is always positive Harris recurrent
and exponentially ergodic with the index equal to (or bigger than) the rate of
restarts. Finally, we illustrate the general results by the standard and
geometric Brownian motions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5689</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5689</id><created>2012-06-25</created><authors><author><keyname>Gilbers</keyname><forenames>Alexander</forenames></author><author><keyname>Klein</keyname><forenames>Rolf</forenames></author></authors><title>A New Upper Bound for the VC-Dimension of Visibility Regions</title><categories>cs.CG</categories><comments>25 pages, 18 Figures. An extended abstract of this paper appeared at
  SoCG '11</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are proving the following fact. Let P be an arbitrary simple
polygon, and let S be an arbitrary set of 15 points inside P. Then there exists
a subset T of S that is not &quot;visually discernible&quot;, that is, T is not equal to
the intersection of S with the visibility region vis(v) of any point v in P. In
other words, the VC-dimension d of visibility regions in a simple polygon
cannot exceed 14. Since Valtr proved in 1998 that d \in [6,23] holds, no
progress has been made on this bound. By epsilon-net theorems our reduction
immediately implies a smaller upper bound to the number of guards needed to
cover P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5691</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5691</id><created>2012-06-25</created><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Superactivation of Quantum Channels is Limited by the Quantum Relative
  Entropy Function</title><categories>quant-ph cs.IT math.IT</categories><comments>14 pages, Journal-ref: Quantum Information Processing (accepted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we prove that the possibility of superactivation of quantum
channel capacities is determined by the mathematical properties of the quantum
relative entropy function. Before our work this fundamental and purely
mathematical connection between the quantum relative entropy function and the
superactivation effect was completely unrevealed. We demonstrate the results
for the quantum capacity; however the proposed theorems and connections hold
for all other channel capacities of quantum channels for which the
superactivation is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5693</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5693</id><created>2012-06-25</created><updated>2012-08-02</updated><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author><author><keyname>Imre</keyname><forenames>Sandor</forenames></author></authors><title>Quasi-Superactivation of Classical Capacity of Zero-Capacity Quantum
  Channels</title><categories>quant-ph cs.IT math.IT</categories><comments>52 pages, 6 figures, Journal-ref: Journal of Modern Optics, published
  version (minor typo fixed)</comments><doi>10.1080/09500340.2012.711491</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most surprising recent results in quantum Shannon theory is the
superactivation of the quantum capacity of a quantum channel. This phenomenon
has its roots in the extreme violation of additivity of the channel capacity
and enables to reliably transmit quantum information over zero-capacity quantum
channels. In this work we demonstrate a similar effect for the classical
capacity of a quantum channel which previously was thought to be impossible. We
show that a nonzero classical capacity can be achieved for all zero-capacity
quantum channels and it only requires the assistance of an elementary
photon-atom interaction process - the stimulated emission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5694</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5694</id><created>2012-06-25</created><updated>2012-08-09</updated><authors><author><keyname>Nishida</keyname><forenames>Naoki</forenames><affiliation>Nagoya University</affiliation></author><author><keyname>Sakai</keyname><forenames>Masahiko</forenames><affiliation>Nagoya University</affiliation></author><author><keyname>Sakabe</keyname><forenames>Toshiki</forenames><affiliation>Nagoya University</affiliation></author></authors><title>Soundness of Unravelings for Conditional Term Rewriting Systems via
  Ultra-Properties Related to Linearity</title><categories>cs.LO</categories><comments>49 pages, 1 table, publication in Special Issue: Selected papers of
  the &quot;22nd International Conference on Rewriting Techniques and Applications
  (RTA'11)&quot;</comments><proxy>LMCS</proxy><acm-class>F.4.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 10,
  2012) lmcs:669</journal-ref><doi>10.2168/LMCS-8(3:4)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unravelings are transformations from a conditional term rewriting system
(CTRS, for short) over an original signature into an unconditional term
rewriting systems (TRS, for short) over an extended signature. They are not
sound w.r.t. reduction for every CTRS, while they are complete w.r.t.
reduction. Here, soundness w.r.t. reduction means that every reduction sequence
of the corresponding unraveled TRS, of which the initial and end terms are over
the original signature, can be simulated by the reduction of the original CTRS.
In this paper, we show that an optimized variant of Ohlebusch's unraveling for
a deterministic CTRS is sound w.r.t. reduction if the corresponding unraveled
TRS is left-linear or both right-linear and non-erasing. We also show that
soundness of the variant implies that of Ohlebusch's unraveling. Finally, we
show that soundness of Ohlebusch's unraveling is the weakest in soundness of
the other unravelings and a transformation, proposed by Serbanuta and Rosu, for
(normal) deterministic CTRSs, i.e., soundness of them respectively implies that
of Ohlebusch's unraveling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5698</identifier>
 <datestamp>2013-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5698</id><created>2012-06-25</created><authors><author><keyname>Grzes</keyname><forenames>Marek</forenames></author><author><keyname>Hoey</keyname><forenames>Jesse</forenames></author><author><keyname>Khan</keyname><forenames>Shehroz</forenames></author><author><keyname>Mihailidis</keyname><forenames>Alex</forenames></author><author><keyname>Czarnuch</keyname><forenames>Stephen</forenames></author><author><keyname>Jackson</keyname><forenames>Dan</forenames></author><author><keyname>Monk</keyname><forenames>Andrew</forenames></author></authors><title>Relational Approach to Knowledge Engineering for POMDP-based Assistance
  Systems as a Translation of a Psychological Model</title><categories>cs.AI</categories><doi>10.1016/j.ijar.2013.03.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assistive systems for persons with cognitive disabilities (e.g. dementia) are
difficult to build due to the wide range of different approaches people can
take to accomplishing the same task, and the significant uncertainties that
arise from both the unpredictability of client's behaviours and from noise in
sensor readings. Partially observable Markov decision process (POMDP) models
have been used successfully as the reasoning engine behind such assistive
systems for small multi-step tasks such as hand washing. POMDP models are a
powerful, yet flexible framework for modelling assistance that can deal with
uncertainty and utility. Unfortunately, POMDPs usually require a very labour
intensive, manual procedure for their definition and construction. Our previous
work has described a knowledge driven method for automatically generating POMDP
activity recognition and context sensitive prompting systems for complex tasks.
We call the resulting POMDP a SNAP (SyNdetic Assistance Process). The
spreadsheet-like result of the analysis does not correspond to the POMDP model
directly and the translation to a formal POMDP representation is required. To
date, this translation had to be performed manually by a trained POMDP expert.
In this paper, we formalise and automate this translation process using a
probabilistic relational model (PRM) encoded in a relational database. We
demonstrate the method by eliciting three assistance tasks from non-experts. We
validate the resulting POMDP models using case-based simulations to show that
they are reasonable for the domains. We also show a complete case study of a
designer specifying one database, including an evaluation in a real-life
experiment with a human actor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5710</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5710</id><created>2012-06-25</created><updated>2012-06-28</updated><authors><author><keyname>Emmerich</keyname><forenames>Thorsten</forenames></author><author><keyname>Bunde</keyname><forenames>Armin</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Guanlian</keyname><forenames>Li</forenames></author><author><keyname>Daqing</keyname><forenames>Li</forenames></author></authors><title>Complex networks embedded in space: Dimension and scaling relations
  between mass, topological distance and Euclidean distance</title><categories>physics.soc-ph cs.SI</categories><comments>17 pages, 11 figures</comments><doi>10.1103/PhysRevE.87.032802</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real networks are embedded in space, where in some of them the links
length decay as a power law distribution with distance. Indications that such
systems can be characterized by the concept of dimension were found recently.
Here, we present further support for this claim, based on extensive numerical
simulations for model networks embedded on lattices of dimensions $d_e=1$ and
$d_e=2$.
  We evaluate the dimension $d$ from the power law scaling of (a) the mass of
the network with the Euclidean radius $r$ and (b) the probability of return to
the origin with the distance $r$ travelled by the random walker. Both
approaches yield the same dimension. For networks with $\delta &lt; d_e$, $d$ is
infinity, while for $\delta &gt; 2d_e$, $d$ obtains the value of the embedding
dimension $d_e$. In the intermediate regime of interest $d_e \leq \delta &lt; 2
d_e$, our numerical results suggest that $d$ decreases continously from $d =
\infty$ to $d_e$, with $d - d_e \sim (\delta - d_e)^{-1}$ for $\delta$ close to
$d_e$. Finally, we discuss the scaling of the mass $M$ and the Euclidean
distance $r$ with the topological distance $\ell$. Our results suggest that in
the intermediate regime $d_e \leq \delta &lt; 2 d_e$, $M(\ell)$ and $r(\ell)$ do
not increase with $\ell$ as a power law but with a stretched exponential,
$M(\ell) \sim \exp [A \ell^{\delta' (2 - \delta')}]$ and $r(\ell) \sim \exp [B
\ell^{\delta' (2 - \delta')}]$, where $\delta' = \delta/d_e$. The parameters
$A$ and $B$ are related to $d$ by $d = A/B$, such that $M(\ell) \sim
r(\ell)^d$. For $\delta &lt; d_e$, $M$ increases exponentially with $\ell$, as
known for $\delta=0$, while $r$ is constant and independent of $\ell$. For
$\delta \geq 2d_e$, we find power law scaling, $M(\ell) \sim \ell^{d_\ell}$ and
$r(\ell) \sim \ell^{1/d_{min}}$, with $d_\ell \cdot d_{min} = d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5725</identifier>
 <datestamp>2012-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5725</id><created>2012-06-25</created><authors><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author><author><keyname>Nguyen</keyname><forenames>Huy</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>On Deterministic Sketching and Streaming for Sparse Recovery and Norm
  Estimation</title><categories>cs.DS cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study classic streaming and sparse recovery problems using deterministic
linear sketches, including l1/l1 and linf/l1 sparse recovery problems (the
latter also being known as l1-heavy hitters), norm estimation, and approximate
inner product. We focus on devising a fixed matrix A in R^{m x n} and a
deterministic recovery/estimation procedure which work for all possible input
vectors simultaneously. Our results improve upon existing work, the following
being our main contributions:
  * A proof that linf/l1 sparse recovery and inner product estimation are
equivalent, and that incoherent matrices can be used to solve both problems.
Our upper bound for the number of measurements is m=O(eps^{-2}*min{log n, (log
n / log(1/eps))^2}). We can also obtain fast sketching and recovery algorithms
by making use of the Fast Johnson-Lindenstrauss transform. Both our running
times and number of measurements improve upon previous work. We can also obtain
better error guarantees than previous work in terms of a smaller tail of the
input vector.
  * A new lower bound for the number of linear measurements required to solve
l1/l1 sparse recovery. We show Omega(k/eps^2 + klog(n/k)/eps) measurements are
required to recover an x' with |x - x'|_1 &lt;= (1+eps)|x_{tail(k)}|_1, where
x_{tail(k)} is x projected onto all but its largest k coordinates in magnitude.
  * A tight bound of m = Theta(eps^{-2}log(eps^2 n)) on the number of
measurements required to solve deterministic norm estimation, i.e., to recover
|x|_2 +/- eps|x|_1.
  For all the problems we study, tight bounds are already known for the
randomized complexity from previous work, except in the case of l1/l1 sparse
recovery, where a nearly tight bound is known. Our work thus aims to study the
deterministic complexities of these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5726</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5726</id><created>2012-06-25</created><authors><author><keyname>Pedroche</keyname><forenames>Francisco</forenames></author><author><keyname>Rebollo</keyname><forenames>Miguel</forenames></author><author><keyname>Carrascosa</keyname><forenames>Carlos</forenames></author><author><keyname>Palomares</keyname><forenames>Alberto</forenames></author></authors><title>L-RCM: a method to detect connected components in undirected graphs by
  using the Laplacian matrix and the RCM algorithm</title><categories>cs.DM cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider undirected graphs with no loops and multiple edges,
consisting of k connected components. In these cases, it is well known that one
can find a numbering of the vertices such that the adjacency matrix A is block
diagonal with k blocks. This also holds for the (unnormalized) Laplacian matrix
L= D-A, with D a diagonal matrix with the degrees of the nodes. In this paper
we propose to use the Reverse Cuthill-McKee (RCM) algorithm to obtain a block
diagonal form of L that reveals the number of connected components of the
graph. We present some theoretical results about the irreducibility of the
Laplacian matrix ordered by the RCM algorithm. As a practical application we
present a very efficient method to detect connected components with a
computational cost of O(m+n), being m the number of edges and n the number of
nodes. The RCM method is implemented in some comercial packages like MATLAB and
Mathematica. We make the computations by using the function symrcm of MATLAB.
Some numerical results are shown
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5754</identifier>
 <datestamp>2015-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5754</id><created>2012-06-25</created><updated>2015-07-15</updated><authors><author><keyname>Vanhatalo</keyname><forenames>Jarno</forenames></author><author><keyname>Riihim&#xe4;ki</keyname><forenames>Jaakko</forenames></author><author><keyname>Hartikainen</keyname><forenames>Jouni</forenames></author><author><keyname>Jyl&#xe4;nki</keyname><forenames>Pasi</forenames></author><author><keyname>Tolvanen</keyname><forenames>Ville</forenames></author><author><keyname>Vehtari</keyname><forenames>Aki</forenames></author></authors><title>Bayesian Modeling with Gaussian Processes using the GPstuff Toolbox</title><categories>stat.ML cs.AI cs.MS</categories><comments>- Updated according to GPstuff 4.6. Added, e.g., Pareto smoothed
  importance sampling</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian processes (GP) are powerful tools for probabilistic modeling
purposes. They can be used to define prior distributions over latent functions
in hierarchical Bayesian models. The prior over functions is defined implicitly
by the mean and covariance function, which determine the smoothness and
variability of the function. The inference can then be conducted directly in
the function space by evaluating or approximating the posterior process.
Despite their attractive theoretical properties GPs provide practical
challenges in their implementation. GPstuff is a versatile collection of
computational tools for GP models compatible with Linux and Windows MATLAB and
Octave. It includes, among others, various inference methods, sparse
approximations and tools for model assessment. In this work, we review these
tools and demonstrate the use of GPstuff in several models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5762</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5762</id><created>2012-05-07</created><authors><author><keyname>Haymaker</keyname><forenames>Kathryn</forenames></author><author><keyname>Kelley</keyname><forenames>Christine A.</forenames></author></authors><title>Geometric WOM codes and coding strategies for multilevel flash memories</title><categories>cs.IT math.CO math.IT</categories><comments>Preliminary version, 15 pages, 4 figures</comments><msc-class>94Bxx, 05B25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the design and application of write-once memory (WOM)
codes for flash memory storage. Using ideas from Merkx ('84), we present a
construction of WOM codes based on finite Euclidean geometries over
$\mathbb{F}_2$. This construction yields WOM codes with new parameters and
provides insight into the criterion that incidence structures should satisfy to
give rise to good codes. We also analyze methods of adapting binary WOM codes
for use on multilevel flash cells. In particular, we give two strategies based
on different rewrite objectives. A brief discussion of the average-write
performance of these strategies, as well as concatenation methods for WOM codes
is also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5766</identifier>
 <datestamp>2012-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5766</id><created>2012-06-25</created><updated>2012-10-28</updated><authors><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author></authors><title>Learning mixtures of spherical Gaussians: moment methods and spectral
  decompositions</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work provides a computationally efficient and statistically consistent
moment-based estimator for mixtures of spherical Gaussians. Under the condition
that component means are in general position, a simple spectral decomposition
technique yields consistent parameter estimates from low-order observable
moments, without additional minimum separation assumptions needed by previous
computationally efficient estimation procedures. Thus computational and
information-theoretic barriers to efficient estimation in mixture models are
precluded when the mixture components have means in general position and
spherical covariances. Some connections are made to estimation problems related
to independent component analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5771</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5771</id><created>2012-06-25</created><updated>2013-08-06</updated><authors><author><keyname>Marstaller</keyname><forenames>Lars</forenames></author><author><keyname>Hintze</keyname><forenames>Arend</forenames></author><author><keyname>Adami</keyname><forenames>Christoph</forenames></author></authors><title>The evolution of representation in simple cognitive networks</title><categories>q-bio.NC cs.NE q-bio.PE</categories><comments>36 pages, 10 figures, one Table</comments><journal-ref>Neural Computation 25 (2013) 2079-2107</journal-ref><doi>10.1162/NECO_a_00475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Representations are internal models of the environment that can provide
guidance to a behaving agent, even in the absence of sensory information. It is
not clear how representations are developed and whether or not they are
necessary or even essential for intelligent behavior. We argue here that the
ability to represent relevant features of the environment is the expected
consequence of an adaptive process, give a formal definition of representation
based on information theory, and quantify it with a measure R. To measure how R
changes over time, we evolve two types of networks---an artificial neural
network and a network of hidden Markov gates---to solve a categorization task
using a genetic algorithm. We find that the capacity to represent increases
during evolutionary adaptation, and that agents form representations of their
environment during their lifetime. This ability allows the agents to act on
sensorial inputs in the context of their acquired representations and enables
complex and context-dependent behavior. We examine which concepts (features of
the environment) our networks are representing, how the representations are
logically encoded in the networks, and how they form as an agent behaves to
solve a task. We conclude that R should be able to quantify the representations
within any cognitive system, and should be predictive of an agent's long-term
adaptive success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5780</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5780</id><created>2012-04-24</created><authors><author><keyname>Loshchilov</keyname><forenames>Ilya</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, MSR - INRIA</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author></authors><title>Black-box optimization benchmarking of IPOP-saACM-ES and BIPOP-saACM-ES
  on the BBOB-2012 noiseless testbed</title><categories>cs.NE</categories><comments>arXiv admin note: substantial text overlap with arXiv:1206.0974</comments><proxy>ccsd</proxy><journal-ref>Genetic and Evolutionary Computation Conference (GECCO 2012)
  (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the performance of IPOP-saACM-ES and BIPOP-saACM-ES,
recently proposed self-adaptive surrogate-assisted Covariance Matrix Adaptation
Evolution Strategies. Both algorithms were tested using restarts till a total
number of function evaluations of $10^6D$ was reached, where $D$ is the
dimension of the function search space. We compared surrogate-assisted
algorithms with their surrogate-less versions IPOP-saACM-ES and BIPOP-saACM-ES,
two algorithms with one of the best overall performance observed during the
BBOB-2009 and BBOB-2010. The comparison shows that the surrogate-assisted
versions outperform the original CMA-ES algorithms by a factor from 2 to 4 on 8
out of 24 noiseless benchmark problems, showing the best results among all
algorithms of the BBOB-2009 and BBOB-2010 on Ellipsoid, Discus, Bent Cigar,
Sharp Ridge and Sum of different powers functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5782</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5782</id><created>2012-06-25</created><updated>2012-10-03</updated><authors><author><keyname>Li</keyname><forenames>Yang</forenames></author><author><keyname>Nosratinia</keyname><forenames>Aria</forenames></author></authors><title>Spectrum Sharing with Distributed Relay Selection and Clustering</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Trans. Commun., 11 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a spectrum-sharing network where n secondary relays are used to
increase secondary rate and also mitigate interference on the primary by
reducing the required overall secondary emitted power. We propose a distributed
relay selection and clustering framework, obtain closed-form expressions for
the secondary rate, and show that secondary rate increases proportionally to
log n. Remarkably, this is on the same order as the growth rate obtained in the
absence of a primary system and its imposed constraints. Our results show that
to maximize the rate, the secondary relays must transmit with power
proportional to n^(-1) (thus the sum of relay powers is bounded) and also that
the secondary source may not operate at its maximum allowable power. The
tradeoff between the secondary rate and the interference on the primary is also
characterized, showing that the primary interference can be reduced
asymptotically to zero as n increases, while still maintaining a secondary rate
that grows proportionally to log n. Finally, to address the rate loss due to
half-duplex relaying in the secondary, we propose an alternating relay protocol
and investigate its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5790</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5790</id><created>2012-06-24</created><updated>2012-07-09</updated><authors><author><keyname>Huang</keyname><forenames>Shipei</forenames></author><author><keyname>Xiang</keyname><forenames>Zhengrong</forenames></author></authors><title>Stabilization of 2D discrete switched systems with state delays under
  asynchronous switching</title><categories>math.DS cs.SY math.OC</categories><comments>25 pages, 3figures. arXiv admin note: substantial text overlap with
  arXiv:1206.5508</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the problem of robust stabilization for a class
of uncertain 2D discrete switched systems with state delays represented by a
model of Roesser type, where the switching instants of the controller
experience delays with respect to those of the system, and the parameter
uncertainties are assumed to be norm-bounded. A state feedback controller is
proposed to guarantee exponential stability for such 2D discrete switched
systems, and the dwell time approach is utilized for the stability analysis and
controller design. A numerical example is given to illustrate the effectiveness
of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5795</identifier>
 <datestamp>2013-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5795</id><created>2012-06-25</created><updated>2013-10-24</updated><authors><author><keyname>Shad</keyname><forenames>Shafqat Ali</forenames></author><author><keyname>Chen</keyname><forenames>Enhong</forenames></author><author><keyname>Bao</keyname><forenames>Tengfei</forenames></author></authors><title>Cell Oscillation Resolution in Mobility Profile Building</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Science Issues, vol. 9, no. 3,
  pp. 205-213, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors. Mobility profile building
became extensively examined area in Location based services (LBS) through
extraction of significant locations. Mobility traces are recorded under three
reference positioning systems that are Satellite based i.e. GPS, Network based
i.e. GSM and Local positioning i.e. WLAN, RFID, IrDA. Satellite based and local
positioning due to of high power consumption, additional resource installation,
low accuracy and space limitation are less encouraging. So network based
positioning i.e. GSM is only viable solution for mobility tracing through Cell
global identity (CGI). CGI presents the Cell-ids to extract the significant
locations from mobility history. However CGI faces cell oscillation problem,
where user is assigned multiple Cell-Ids even at a stationary state for load
balancing and GSM cells overlapping. In this paper we proposed two
semi-supervised methodology for cell oscillation resolution i.e. semantic
tagging and overlapped area clustering, the proposed methodologies are equally
useful for the identification of significant places too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5829</identifier>
 <datestamp>2013-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5829</id><created>2012-05-22</created><updated>2013-03-20</updated><authors><author><keyname>Bartel</keyname><forenames>Alexandre</forenames><affiliation>SnT</affiliation></author><author><keyname>Klein</keyname><forenames>Jacques</forenames><affiliation>SnT</affiliation></author><author><keyname>Monperrus</keyname><forenames>Martin</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Traon</keyname><forenames>Yves Le</forenames><affiliation>SnT</affiliation></author></authors><title>Automatically Securing Permission-Based Software by Reducing the Attack
  Surface: An Application to Android</title><categories>cs.CR cs.SE</categories><proxy>ccsd</proxy><report-no>ISBN: 978-2-87971-107-2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common security architecture, called the permission-based security model
(used e.g. in Android and Blackberry), entails intrinsic risks. For instance,
applications can be granted more permissions than they actually need, what we
call a &quot;permission gap&quot;. Malware can leverage the unused permissions for
achieving their malicious goals, for instance using code injection. In this
paper, we present an approach to detecting permission gaps using static
analysis. Our prototype implementation in the context of Android shows that the
static analysis must take into account a significant amount of
platform-specific knowledge. Using our tool on two datasets of Android
applications, we found out that a non negligible part of applications suffers
from permission gaps, i.e. does not use all the permissions they declare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5833</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5833</id><created>2012-06-25</created><updated>2012-11-23</updated><authors><author><keyname>Governatori</keyname><forenames>Guido</forenames></author><author><keyname>Olivieri</keyname><forenames>Francesco</forenames></author><author><keyname>Scannapieco</keyname><forenames>Simone</forenames></author><author><keyname>Cristani</keyname><forenames>Matteo</forenames></author></authors><title>Revision of Defeasible Logic Preferences</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are several contexts of non-monotonic reasoning where a priority
between rules is established whose purpose is preventing conflicts.
  One formalism that has been widely employed for non-monotonic reasoning is
the sceptical one known as Defeasible Logic. In Defeasible Logic the tool used
for conflict resolution is a preference relation between rules, that
establishes the priority among them.
  In this paper we investigate how to modify such a preference relation in a
defeasible logic theory in order to change the conclusions of the theory
itself. We argue that the approach we adopt is applicable to legal reasoning
where users, in general, cannot change facts or rules, but can propose their
preferences about the relative strength of the rules.
  We provide a comprehensive study of the possible combinatorial cases and we
identify and analyse the cases where the revision process is successful.
  After this analysis, we identify three revision/update operators and study
them against the AGM postulates for belief revision operators, to discover that
only a part of these postulates are satisfied by the three operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5851</identifier>
 <datestamp>2013-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5851</id><created>2012-06-25</created><authors><author><keyname>Gayo-Avello</keyname><forenames>Daniel</forenames></author></authors><title>A meta-analysis of state-of-the-art electoral prediction from Twitter
  data</title><categories>cs.SI cs.CL cs.CY physics.soc-ph</categories><comments>19 pages, 3 tables</comments><acm-class>H.2.8; H.3.5; H.4.3; I.2.7; I.5.4; J.4; K.4.1</acm-class><journal-ref>Social Science Computer Review, August 23, 2013, 0894439313493979</journal-ref><doi>10.1177/0894439313493979</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electoral prediction from Twitter data is an appealing research topic. It
seems relatively straightforward and the prevailing view is overly optimistic.
This is problematic because while simple approaches are assumed to be good
enough, core problems are not addressed. Thus, this paper aims to (1) provide a
balanced and critical review of the state of the art; (2) cast light on the
presume predictive power of Twitter data; and (3) depict a roadmap to push
forward the field. Hence, a scheme to characterize Twitter prediction methods
is proposed. It covers every aspect from data collection to performance
evaluation, through data processing and vote inference. Using that scheme,
prior research is analyzed and organized to explain the main approaches taken
up to date but also their weaknesses. This is the first meta-analysis of the
whole body of research regarding electoral prediction from Twitter data. It
reveals that its presumed predictive power regarding electoral prediction has
been rather exaggerated: although social media may provide a glimpse on
electoral outcomes current research does not provide strong evidence to support
it can replace traditional polls. Finally, future lines of research along with
a set of requirements they must fulfill are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5856</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5856</id><created>2012-06-25</created><authors><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author><author><keyname>Mukerji</keyname><forenames>Pratik</forenames></author></authors><title>Crowd Disasters as Systemic Failures: Analysis of the Love Parade
  Disaster</title><categories>nlin.CD cs.SI physics.soc-ph</categories><comments>For a collection of links to complementary video materials see
  http://loveparadevideos.heroku.com/ For related work see
  http://www.soms.ethz.ch</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Each year, crowd disasters happen in different areas of the world. How and
why do such disasters happen? Are the fatalities caused by relentless behavior
of people or a psychological state of panic that makes the crowd 'go mad'? Or
are they a tragic consequence of a breakdown of coordination? These and other
questions are addressed, based on a qualitative analysis of publicly available
videos and materials, which document the planning and organization of the Love
Parade in Duisburg, Germany, and the crowd disaster on July 24, 2010. Our
analysis reveals a number of misunderstandings that have widely spread. We also
provide a new perspective on concepts such as 'intentional pushing', 'mass
panic', 'stampede', and 'crowd crushs'. The focus of our analysis is on the
contributing causal factors and their mutual interdependencies, not on legal
issues or the judgment of personal or institutional responsibilities. Video
recordings show that, in Duisburg, people stumbled and piled up due to a
'domino effect', resulting from a phenomenon called 'crowd turbulence' or
'crowd quake'. Crowd quakes are a typical reason for crowd disasters, to be
distinguished from crowd disasters resulting from 'panic stampedes' or 'crowd
crushes'. In Duisburg, crowd turbulence was the consequence of amplifying
feedback and cascading effects, which are typical for systemic instabilities.
Accordingly, things can go terribly wrong in spite of no bad intentions from
anyone. Comparing the incident in Duisburg with others, we give recommendations
to help prevent future crowd disasters. In particular, we introduce a new scale
to assess the criticality of conditions in the crowd. This may allow
preventative measures to be taken earlier on. Furthermore, we discuss the
merits and limitations of citizen science for public investigation, considering
that today, almost every event is recorded and reflected in the World Wide Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5863</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5863</id><created>2012-06-25</created><authors><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiande</forenames></author></authors><title>Improved Constructions of Frameproof Codes</title><categories>math.CO cs.IT math.IT</categories><comments>6 pages, to appear in Information Theory, IEEE Transactions on</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frameproof codes are used to preserve the security in the context of
coalition when fingerprinting digital data. Let $M_{c,l}(q)$ be the largest
cardinality of a $q$-ary $c$-frameproof code of length $l$ and
$R_{c,l}=\lim_{q\rightarrow \infty}M_{c,l}(q)/q^{\lceil l/c\rceil}$. It has
been determined by Blackburn that $R_{c,l}=1$ when $l\equiv 1\ (\bmod\ c)$,
$R_{c,l}=2$ when $c=2$ and $l$ is even, and $R_{3,5}=5/3$. In this paper, we
give a recursive construction for $c$-frameproof codes of length $l$ with
respect to the alphabet size $q$. As applications of this construction, we
establish the existence results for $q$-ary $c$-frameproof codes of length
$c+2$ and size $\frac{c+2}{c}(q-1)^2+1$ for all odd $q$ when $c=2$ and for all
$q\equiv 4\pmod{6}$ when $c=3$. Furthermore, we show that $R_{c,c+2}=(c+2)/c$
meeting the upper bound given by Blackburn, for all integers $c$ such that
$c+1$ is a prime power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5865</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5865</id><created>2012-06-25</created><authors><author><keyname>Jia</keyname><forenames>Qing-Shan</forenames></author></authors><title>Efficient Computing Budget Allocation for Simulation-based Optimization
  with Stochastic Simulation Time</title><categories>math.OC cs.SY</categories><comments>7 pages, 5 figures, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamics of many systems nowadays follow not only physical laws but also
man-made rules. These systems are known as discrete event dynamic systems and
their performances can be accurately evaluated only through simulations.
Existing studies on simulation-based optimization (SBO) usually assume
deterministic simulation time for each replication. However, in many
applications such as evacuation, smoke detection, and territory exploration,
the simulation time is stochastic due to the randomness in the system behavior.
We consider the computing budget allocation for SBO's with stochastic
simulation time in this paper, which has not been addressed in existing
literatures to the author's best knowledge. We make the following major
contribution. The relationship between simulation time and performance
estimation accuracy is quantified. It is shown that when the asymptotic
performance is of interest only the mean value of individual simulation time
matters. Then based on the existing optimal computing budget allocation (OCBA)
method for deterministic simulation time we develop OCBA for stochastic
simulation time (OCBAS), and show that OCBAS is asymptotically optimal.
Numerical experiments are used to discuss the impact of the variance of
simulation time, the impact of correlated simulation time and performance
estimation, and to demonstrate the performance of OCBAS on a smoke detection
problem in wireless sensor network. The numerical results also show that OCBA
for deterministic simulation time is robust even when the simulation time is
stochastic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5871</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5871</id><created>2012-06-25</created><updated>2013-12-15</updated><authors><author><keyname>Saleh</keyname><forenames>Moustafa</forenames></author></authors><title>Towards Metamorphic Virus Recognition Using Eigenviruses</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Metamorphic viruses are considered the most dangerous of all computer
viruses. Unlike other computer viruses that can be detected statically using
static signature technique or dynamically using emulators, metamorphic viruses
change their code to avoid such detection techniques. This makes metamorphic
viruses a real challenge for computer security researchers. In this thesis, we
investigate the techniques used by metamorphic viruses to alter their code,
such as trivial code insertion, instructions substitution, subroutines
permutation and register renaming. An in-depth survey of the current techniques
used for detection of this kind of viruses is presented. We discuss techniques
that are used by commercial antivirus products, and those introduced in
scientific researches. Moreover, a novel approach is then introduced for
metamorphic virus recognition based on unsupervised machine learning generally
and Eigenfaces technique specifically which is widely used for face
recognition. We analyze the performance of the proposed technique and show the
experimental results compared to results of well-known antivirus engines.
Finally, we discuss the future and potential enhancements of the proposed
approach to detect more and other target viruses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5882</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5882</id><created>2012-06-26</created><authors><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Wang</keyname><forenames>Huan</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>Exact Recovery of Sparsely-Used Dictionaries</title><categories>cs.LG cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning sparsely used dictionaries with an
arbitrary square dictionary and a random, sparse coefficient matrix. We prove
that $O (n \log n)$ samples are sufficient to uniquely determine the
coefficient matrix. Based on this proof, we design a polynomial-time algorithm,
called Exact Recovery of Sparsely-Used Dictionaries (ER-SpUD), and prove that
it probably recovers the dictionary and coefficient matrix when the coefficient
matrix is sufficiently sparse. Simulation results show that ER-SpUD reveals the
true dictionary as well as the coefficients with probability higher than many
state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5884</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5884</id><created>2012-06-26</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Deochake</keyname><forenames>Saurabh</forenames></author><author><keyname>Kanth</keyname><forenames>Shashank</forenames></author><author><keyname>Chakraborty</keyname><forenames>Subhadip</forenames></author><author><keyname>Sarode</keyname><forenames>Suresh</forenames></author></authors><title>MAINWAVE: Multi Agents and Issues Negotiation for Web using Alliance
  Virtual Engine</title><categories>cs.MA</categories><comments>12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper showcases an improved architecture for a complete negotiation
system that permits multi party multi issue negotiation. The concepts of
multithreading and concurrency has been utilized to perform parallel execution.
The negotiation history has been implemented that stores all the records of the
messages exchanged for every successful and rejected negotiation process and
implements the concepts of artificial intelligence in determination of proper
weights for a valid negotiation mechanism. The issues are arranged in a
hierarchical pattern so as to simplify the representation and priorities are
assigned to each issue, which amounts to its relative importance. There is
refinement of utilities by consideration of the non-functional attributes. So
as to avoid overloading of the system, a maximum number of parties are allowed
to participate in the entire mechanism and if more parties arrive, they're put
into a waiting queue in accordance to certain criteria such as the first come
first serve or the relative priorities. This helps in fault tolerance. It also
supports the formation of alliances among the various parties while carrying
out a negotiation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5901</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5901</id><created>2012-06-26</created><authors><author><keyname>Turner</keyname><forenames>Daniel Z.</forenames></author></authors><title>A nonlocal model for fluid-structure interaction with applications in
  hydraulic fracturing</title><categories>math.NA cs.CE physics.geo-ph</categories><comments>19 pages, 10 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modeling important engineering problems related to flow-induced damage (in
the context of hydraulic fracturing among others) depends critically on
characterizing the interaction of porous media and interstitial fluid flow.
This work presents a new formulation for incorporating the effects of pore
pressure in a nonlocal representation of solid mechanics. The result is a
framework for modeling fluid-structure interaction problems with the
discontinuity capturing advantages of an integral based formulation. A number
of numerical examples are used to show that the proposed formulation can be
applied to measure the effect of leak-off during hydraulic fracturing as well
as modeling consolidation of fluid saturated rock and surface subsidence caused
by fluid extraction from a geologic reservoir. The formulation incorporates the
effect of pore pressure in the constitutive description of the porous material
in a way that is appropriate for nonlinear materials, easily implemented in
existing codes, straightforward in its evaluation (no history dependence), and
justifiable from first principles. A mixture theory approach is used (deviating
only slightly where necessary) to motivate an alteration to the peridynamic
pressure term based on the fluid pore pressure. The resulting formulation has a
number of similarities to the effective stress principle developed by Terzaghi
and Biot and close correspondence is shown between the proposed method and the
classical effective stress principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5915</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5915</id><created>2012-06-26</created><authors><author><keyname>Sellamanickam</keyname><forenames>Sundararajan</forenames></author><author><keyname>Selvaraj</keyname><forenames>Sathiya Keerthi</forenames></author></authors><title>Graph Based Classification Methods Using Inaccurate External Classifier
  Information</title><categories>cs.LG</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of collectively classifying entities
where relational information is available across the entities. In practice
inaccurate class distribution for each entity is often available from another
(external) classifier. For example this distribution could come from a
classifier built using content features or a simple dictionary. Given the
relational and inaccurate external classifier information, we consider two
graph based settings in which the problem of collective classification can be
solved. In the first setting the class distribution is used to fix labels to a
subset of nodes and the labels for the remaining nodes are obtained like in a
transductive setting. In the other setting the class distributions of all nodes
are used to define the fitting function part of a graph regularized objective
function. We define a generalized objective function that handles both the
settings. Methods like harmonic Gaussian field and local-global consistency
(LGC) reported in the literature can be seen as special cases. We extend the
LGC and weighted vote relational neighbor classification (WvRN) methods to
support usage of external classifier information. We also propose an efficient
least squares regularization (LSR) based method and relate it to information
regularization methods. All the methods are evaluated on several benchmark and
real world datasets. Considering together speed, robustness and accuracy,
experimental results indicate that the LSR and WvRN-extension methods perform
better than other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5919</identifier>
 <datestamp>2014-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5919</id><created>2012-06-26</created><updated>2014-02-28</updated><authors><author><keyname>Takeuchi</keyname><forenames>Keigo</forenames></author><author><keyname>Tanaka</keyname><forenames>Toshiyuki</forenames></author><author><keyname>Kawabata</keyname><forenames>Tsutomu</forenames></author></authors><title>Performance Improvement of Iterative Multiuser Detection for Large
  Sparsely-Spread CDMA Systems by Spatial Coupling</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kudekar et al. proved that the belief-propagation (BP) performance for
low-density parity check (LDPC) codes can be boosted up to the
maximum-a-posteriori (MAP) performance by spatial coupling. In this paper,
spatial coupling is applied to sparsely-spread code-division multiple-access
(CDMA) systems to improve the performance of iterative multiuser detection
based on BP. Two iterative receivers based on BP are considered: One receiver
is based on exact BP and the other on an approximate BP with Gaussian
approximation. The performance of the two BP receivers is evaluated via density
evolution (DE) in the dense limit after taking the large-system limit, in which
the number of users and the spreading factor tend to infinity while their ratio
is kept constant. The two BP receivers are shown to achieve the same
performance as each other in these limits. Furthermore, taking a continuum
limit for the obtained DE equations implies that the performance of the two BP
receivers can be improved up to the performance achieved by the symbol-wise MAP
detection, called individually-optimal detection, via spatial coupling.
Numerical simulations show that spatial coupling can provide a significant
improvement in bit error rate for finite-sized systems especially in the region
of high system loads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5928</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5928</id><created>2012-06-26</created><authors><author><keyname>Nguyen</keyname><forenames>Truong-Huy Dinh</forenames></author><author><keyname>Hsu</keyname><forenames>David</forenames></author><author><keyname>Lee</keyname><forenames>Wee-Sun</forenames></author><author><keyname>Leong</keyname><forenames>Tze-Yun</forenames></author><author><keyname>Kaelbling</keyname><forenames>Leslie Pack</forenames></author><author><keyname>Lozano-Perez</keyname><forenames>Tomas</forenames></author><author><keyname>Grant</keyname><forenames>Andrew Haydn</forenames></author></authors><title>CAPIR: Collaborative Action Planning with Intention Recognition</title><categories>cs.AI</categories><comments>6 pages, accepted for presentation at AIIDE'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply decision theoretic techniques to construct non-player characters
that are able to assist a human player in collaborative games. The method is
based on solving Markov decision processes, which can be difficult when the
game state is described by many variables. To scale to more complex games, the
method allows decomposition of a game task into subtasks, each of which can be
modelled by a Markov decision process. Intention recognition is used to infer
the subtask that the human is currently performing, allowing the helper to
assist the human in performing the correct task. Experiments show that the
method can be effective, giving near-human level performance in helping a human
in a collaborative game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5930</identifier>
 <datestamp>2012-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5930</id><created>2012-06-26</created><updated>2012-12-07</updated><authors><author><keyname>Stokes</keyname><forenames>Klara</forenames></author><author><keyname>Farr&#xe0;s</keyname><forenames>Oriol</forenames></author></authors><title>Linear spaces and transversal designs: k-anonymous combinatorial
  configurations for anonymous database search</title><categories>cs.CR cs.DB math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anonymous database search protocols allow users to query a database
anonymously. This can be achieved by letting the users form a peer-to-peer
community and post queries on behalf of each other. In this article we discuss
an application of combinatorial configurations (also known as regular and
uniform partial linear spaces) to a protocol for anonymous database search, as
defining the key-distribution within the user community that implements the
protocol. The degree of anonymity that can be provided by the protocol is
determined by properties of the neighborhoods and the closed neighborhoods of
the points in the combinatorial configuration that is used. Combinatorial
configurations with unique neighborhoods or unique closed neighborhoods are
described and we show how to attack the protocol if such configurations are
used. We apply k-anonymity arguments and present the combinatorial
configurations with k-anonymous neighborhoods and with k-anonymous closed
neighborhoods. The transversal designs and the linear spaces are presented as
optimal configurations among the configurations with k-anonymous neighborhoods
and k-anonymous closed neighborhoods, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5937</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5937</id><created>2012-06-26</created><authors><author><keyname>Abouaissa</keyname><forenames>Hassane</forenames><affiliation>LGI2A</affiliation></author><author><keyname>Fliess</keyname><forenames>Michel</forenames><affiliation>LIX</affiliation></author><author><keyname>Iordanova</keyname><forenames>Violina</forenames><affiliation>DiRIF</affiliation></author><author><keyname>Join</keyname><forenames>C&#xe9;dric</forenames><affiliation>INRIA Saclay - Ile de France, CRAN</affiliation></author></authors><title>Freeway ramp metering control made easy and efficient</title><categories>math.OC cs.SY</categories><comments>13th IFAC Symposium on Control in Transportation Systems (CTS 2012),
  Sofia : Bulgaria (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Model-free&quot; control and the related &quot;intelligent&quot; proportional-integral (PI)
controllers are successfully applied to freeway ramp metering control.
Implementing moreover the corresponding control strategy is straightforward.
Numerical simulations on the other hand need the identification of quite
complex quantities like the free flow sp\^eed and the critical density. This is
achieved thanks to new estimation techniques where the differentiation of noisy
signals plays a key r\^ole. Several excellent computer simulations are provided
and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5938</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5938</id><created>2012-06-26</created><authors><author><keyname>Zungeru</keyname><forenames>Adamu Murtala</forenames></author><author><keyname>Ang</keyname><forenames>Li-Minn</forenames></author><author><keyname>Seng</keyname><forenames>Kah Phooi</forenames></author></authors><title>Performance Evaluation of Ant-Based Routing Protocols for Wireless
  Sensor Networks</title><categories>cs.DC</categories><comments>10 pages, 5 figures, Journal Publication</comments><journal-ref>International Journal of Computer Science Issues (IJCSI), volume
  9, Issue 3, No 2, May 2012, pp. 388-397</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High efficient routing is an important issue in the design of limited energy
resource Wireless Sensor Networks (WSNs). Due to the characteristic of the
environment at which the sensor node is to operate, coupled with severe
resources; on-board energy, transmission power, processing capability, and
storage limitations, prompt for careful resource management and new routing
protocol so as to counteract the differences and challenges. To this end, we
present an Improved Energy-Efficient Ant-Based Routing (IEEABR) Algorithm in
wireless sensor networks. Compared to the state-of-the-art Ant-Based routing
protocols; Basic Ant-Based Routing (BABR) Algorithm, Sensor-driven and
Cost-aware ant routing (SC), Flooded Forward ant routing (FF), Flooded
Piggybacked ant routing (FP), and Energy-Efficient Ant-Based Routing (EEABR),
the proposed IEEABR approach has advantages in terms of reduced energy usage
which can effectively balance the WSN node's power consumption, and high energy
efficiency. The performance evaluations for the algorithms on a real
application are conducted in a well known WSN MATLAB-based simulator (RMASE)
using both static and dynamic scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5940</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5940</id><created>2012-06-26</created><authors><author><keyname>Nguyen</keyname><forenames>Truong-Huy Dinh</forenames></author><author><keyname>Lee</keyname><forenames>Wee-Sun</forenames></author><author><keyname>Leong</keyname><forenames>Tze-Yun</forenames></author></authors><title>Bootstrapping Monte Carlo Tree Search with an Imperfect Heuristic</title><categories>cs.AI</categories><comments>16 pages, accepted for presentation at ECML'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of using a heuristic policy to improve the value
approximation by the Upper Confidence Bound applied in Trees (UCT) algorithm in
non-adversarial settings such as planning with large-state space Markov
Decision Processes. Current improvements to UCT focus on either changing the
action selection formula at the internal nodes or the rollout policy at the
leaf nodes of the search tree. In this work, we propose to add an auxiliary arm
to each of the internal nodes, and always use the heuristic policy to roll out
simulations at the auxiliary arms. The method aims to get fast convergence to
optimal values at states where the heuristic policy is optimal, while retaining
similar approximation as the original UCT in other states. We show that
bootstrapping with the proposed method in the new algorithm, UCT-Aux, performs
better compared to the original UCT algorithm and its variants in two benchmark
experiment settings. We also examine conditions under which UCT-Aux works well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5941</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5941</id><created>2012-06-26</created><authors><author><keyname>Bodlaender</keyname><forenames>Hans L.</forenames></author><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>Kernelization Lower Bounds By Cross-Composition</title><categories>cs.CC cs.DS</categories><comments>A preliminary version appeared in the proceedings of the 28th
  International Symposium on Theoretical Aspects of Computer Science (STACS
  2011) under the title &quot;Cross-Composition: A New Technique for Kernelization
  Lower Bounds&quot;. Several results have been strengthened compared to the
  preliminary version (http://arxiv.org/abs/1011.4224). 29 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the cross-composition framework for proving kernelization lower
bounds. A classical problem L AND/OR-cross-composes into a parameterized
problem Q if it is possible to efficiently construct an instance of Q with
polynomially bounded parameter value that expresses the logical AND or OR of a
sequence of instances of L. Building on work by Bodlaender et al. (ICALP 2008)
and using a result by Fortnow and Santhanam (STOC 2008) with a refinement by
Dell and van Melkebeek (STOC 2010), we show that if an NP-hard problem
OR-cross-composes into a parameterized problem Q then Q does not admit a
polynomial kernel unless NP \subseteq coNP/poly and the polynomial hierarchy
collapses. Similarly, an AND-cross-composition for Q rules out polynomial
kernels for Q under Bodlaender et al.'s AND-distillation conjecture.
  Our technique generalizes and strengthens the recent techniques of using
composition algorithms and of transferring the lower bounds via polynomial
parameter transformations. We show its applicability by proving kernelization
lower bounds for a number of important graphs problems with structural
(non-standard) parameterizations, e.g., Clique, Chromatic Number, Weighted
Feedback Vertex Set, and Weighted Odd Cycle Transversal do not admit polynomial
kernels with respect to the vertex cover number of the input graphs unless the
polynomial hierarchy collapses, contrasting the fact that these problems are
trivially fixed-parameter tractable for this parameter.
  After learning of our results, several teams of authors have successfully
applied the cross-composition framework to different parameterized problems.
For completeness, our presentation of the framework includes several extensions
based on this follow-up work. For example, we show how a relaxed version of
OR-cross-compositions may be used to give lower bounds on the degree of the
polynomial in the kernel size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5959</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5959</id><created>2012-06-26</created><authors><author><keyname>Adjiashvili</keyname><forenames>David</forenames></author><author><keyname>Senatore</keyname><forenames>Marco</forenames></author></authors><title>The Online Replacement Path Problem</title><categories>cs.DS</categories><comments>18 pages</comments><msc-class>68Q25</msc-class><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a natural online variant of the replacement path problem. The
\textit{replacement path problem} asks to find for a given graph $G = (V,E)$,
two designated vertices $s,t\in V$ and a shortest $s$-$t$ path $P$ in $G$, a
\textit{replacement path} $P_e$ for every edge $e$ on the path $P$. The
replacement path $P_e$ is simply a shortest $s$-$t$ path in the graph, which
avoids the \textit{failed} edge $e$. We adapt this problem to deal with the
natural scenario, that the edge which failed is not known at the time of
solution implementation. Instead, our problem assumes that the identity of the
failed edge only becomes available when the routing mechanism tries to cross
the edge. This situation is motivated by applications in distributed networks,
where information about recent changes in the network is only stored locally,
and fault-tolerant optimization, where an adversary tries to delay the
discovery of the materialized scenario as much as possible. Consequently, we
define the \textit{online replacement path problem}, which asks to find a
nominal $s$-$t$ path $Q$ and detours $Q_e$ for every edge on the path $Q$, such
that the worst-case arrival time at the destination is minimized. Our main
contribution is a label setting algorithm, which solves the problem in
undirected graphs in time $O(m \log n)$ and linear space for all sources and a
single destination. We also present algorithms for extensions of the model to
any bounded number of failed edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5980</identifier>
 <datestamp>2013-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5980</id><created>2012-06-25</created><updated>2013-03-05</updated><authors><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author></authors><title>Information Geometric Superactivation of Asymptotic Quantum Capacity and
  Classical Zero-Error Capacity of Zero-Capacity Quantum Channels</title><categories>quant-ph cs.IT math.IT</categories><comments>Ph.D. Thesis, Budapest University of Technology and Economics, 2013,
  392 pages, 4 tables, 128 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The superactivation of zero-capacity quantum channels makes it possible to
use two zero-capacity quantum channels with a positive joint capacity at the
output. Currently, we have no theoretical background for describing all
possible combinations of superactive zero-capacity channels; hence, there may
be many other possible combinations. In this PhD Thesis I provide an
algorithmic solution to the problem of superactivation and prove that
superactivation effect is rooted in information geometric issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5986</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5986</id><created>2012-06-26</created><updated>2013-06-04</updated><authors><author><keyname>Andersson</keyname><forenames>Joel</forenames></author><author><keyname>Str&#xf6;mberg</keyname><forenames>Jan-Olov</forenames></author></authors><title>On the Theorem of Uniform Recovery of Random Sampling Matrices</title><categories>cs.IT cs.NA math.IT</categories><msc-class>15A60, 15B52, 42A61, 60B20, 60G50, 94A12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two theorems from the theory of compressive sensing. Mainly a
theorem concerning uniform recovery of random sampling matrices, where the
number of samples needed in order to recover an $s$-sparse signal from linear
measurements (with high probability) is known to be $m\gtrsim s(\ln s)^3\ln N$.
We present new and improved constants together with what we consider to be a
more explicit proof. A proof that also allows for a slightly larger class of
$m\times N$-matrices, by considering what we call \emph{low entropy}. We also
present an improved condition on the so-called restricted isometry constants,
$\delta_s$, ensuring sparse recovery via $\ell^1$-minimization. We show that
$\delta_{2s}&lt;4/\sqrt{41}$ is sufficient and that this can be improved further
to almost allow for a sufficient condition of the type $\delta_{2s}&lt;2/3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.5996</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.5996</id><created>2012-06-26</created><authors><author><keyname>Imre</keyname><forenames>Sandor</forenames></author><author><keyname>Gyongyosi</keyname><forenames>Laszlo</forenames></author></authors><title>Quantum-assisted and Quantum-based Solutions in Wireless Systems</title><categories>quant-ph cs.IT math.IT</categories><comments>Review paper, published in the Special Centennial Celebration Issue
  of Proceedings of the IEEE, 10 pages, 2 figures</comments><journal-ref>Proceedings of the IEEE, Volume: 100, Issue: Special Centennial
  Issue, 2012, pp. 1853-1888</journal-ref><doi>10.1109/JPROC.2012.2189788</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless systems there is always a trade-off between reducing the transmit
power and mitigating the resultant signal-degradation imposed by the
transmit-power reduction with the aid of sophisticated receiver algorithms,
when considering the total energy consumption. Quantum-assisted wireless
communications exploits the extra computing power offered by quantum mechanics
based architectures. This paper summarizes some recent results in quantum
computing and the corresponding application areas in wireless communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6003</identifier>
 <datestamp>2013-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6003</id><created>2012-06-26</created><updated>2013-05-16</updated><authors><author><keyname>Jacques</keyname><forenames>L.</forenames></author><author><keyname>Hammond</keyname><forenames>D. K.</forenames></author><author><keyname>Fadili</keyname><forenames>M. J.</forenames></author></authors><title>Stabilizing Nonuniformly Quantized Compressed Sensing with Scalar
  Companders</title><categories>cs.IT math.IT</categories><comments>30 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of reconstructing sparse or compressible
signals from compressed sensing measurements that have undergone nonuniform
quantization. Previous approaches to this Quantized Compressed Sensing (QCS)
problem based on Gaussian models (bounded l2-norm) for the quantization
distortion yield results that, while often acceptable, may not be fully
consistent: re-measurement and quantization of the reconstructed signal do not
necessarily match the initial observations. Quantization distortion instead
more closely resembles heteroscedastic uniform noise, with variance depending
on the observed quantization bin. Generalizing our previous work on uniform
quantization, we show that for nonuniform quantizers described by the
&quot;compander&quot; formalism, quantization distortion may be better characterized as
having bounded weighted lp-norm (p &gt;= 2), for a particular weighting. We
develop a new reconstruction approach, termed Generalized Basis Pursuit DeNoise
(GBPDN), which minimizes the sparsity of the reconstructed signal under this
weighted lp-norm fidelity constraint. We prove that for B bits per measurement
and under the oversampled QCS scenario (when the number of measurements is
large compared to the signal sparsity) if the sensing matrix satisfies a
proposed generalized Restricted Isometry Property, then, GBPDN provides a
reconstruction error of sparse signals which decreases like
O(2^{-B}/\sqrt{p+1}): a reduction by a factor \sqrt{p+1} relative to that
produced by using the l2-norm. Besides the QCS scenario, we also show that
GBPDN applies straightforwardly to the related case of CS measurements
corrupted by heteroscedastic Generalized Gaussian noise with provable
reconstruction error reduction. Finally, we describe an efficient numerical
procedure for computing GBPDN via a primal-dual convex optimization scheme, and
demonstrate its effectiveness through simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6006</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6006</id><created>2012-06-26</created><updated>2012-12-27</updated><authors><author><keyname>Bellini</keyname><forenames>Emanuele</forenames></author><author><keyname>Guerrini</keyname><forenames>Eleonora</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author></authors><title>Some bounds on the size of codes</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>This paper had two old titles: &quot;A bound on the size of linear codes
  and systematic codes&quot;, &quot;A bound on the size of linear codes&quot;
  (arXiv:0902.1634)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present some upper bounds on the size of non-linear codes and their
restriction to systematic codes and linear codes. These bounds are independent
of other known theoretical bounds, e.g. the Griesmer bound, the Johnson bound
or the Plotkin bound, and one of these is actually an improvement of a bound by
Litsyn and Laihonen. Our experiments show that in some cases (the majority of
cases for some q) our bounds provide the best value, compared to all other
theoretical bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6015</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6015</id><created>2012-06-26</created><authors><author><keyname>Sellamanickam</keyname><forenames>Sundararajan</forenames></author><author><keyname>Selvaraj</keyname><forenames>Sathiya Keerthi</forenames></author></authors><title>Transductive Classification Methods for Mixed Graphs</title><categories>cs.LG stat.ML</categories><comments>8 Pages, 2 Tables, 2 Figures, KDD Workshop - MLG'11 San Diego, CA,
  USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide a principled approach to solve a transductive
classification problem involving a similar graph (edges tend to connect nodes
with same labels) and a dissimilar graph (edges tend to connect nodes with
opposing labels). Most of the existing methods, e.g., Information
Regularization (IR), Weighted vote Relational Neighbor classifier (WvRN) etc,
assume that the given graph is only a similar graph. We extend the IR and WvRN
methods to deal with mixed graphs. We evaluate the proposed extensions on
several benchmark datasets as well as two real world datasets and demonstrate
the usefulness of our ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6016</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6016</id><created>2012-05-30</created><authors><author><keyname>Innocent</keyname><forenames>A. Anasuya Threse</forenames></author></authors><title>Cloud Infrastructure Service Management - A Review</title><categories>cs.DC</categories><comments>6 pages</comments><journal-ref>International Journal of Computer Science Issues, Volume 9, Number
  2, March 2012, Pg. 287 - 292</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The new era of computing called Cloud Computing allows the user to access the
cloud services dynamically over the Internet wherever and whenever needed.
Cloud consists of data and resources; and the cloud services include the
delivery of software, infrastructure, applications, and storage over the
Internet based on user demand through Internet. In short, cloud computing is a
business and economic model allowing the users to utilize high-end computing
and storage virtually with minimal infrastructure on their end. Cloud has three
service models namely, Cloud Software-as-a-Service (SaaS), Cloud
Platform-as-a-Service (PaaS), and Cloud Infrastructure-as-a-Service (IaaS).
This paper talks in depth of cloud infrastructure service management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6030</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6030</id><created>2012-06-26</created><authors><author><keyname>Sellamanickam</keyname><forenames>Sundararajan</forenames></author><author><keyname>Shevade</keyname><forenames>Shirish</forenames></author></authors><title>An Additive Model View to Sparse Gaussian Process Classifier Design</title><categories>cs.LG stat.ML</categories><comments>14 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing a sparse Gaussian process classifier
(SGPC) that generalizes well. Viewing SGPC design as constructing an additive
model like in boosting, we present an efficient and effective SGPC design
method to perform a stage-wise optimization of a predictive loss function. We
introduce new methods for two key components viz., site parameter estimation
and basis vector selection in any SGPC design. The proposed adaptive sampling
based basis vector selection method aids in achieving improved generalization
performance at a reduced computational cost. This method can also be used in
conjunction with any other site parameter estimation methods. It has similar
computational and storage complexities as the well-known information vector
machine and is suitable for large datasets. The hyperparameters can be
determined by optimizing a predictive loss function. The experimental results
show better generalization performance of the proposed basis vector selection
method on several benchmark datasets, particularly for relatively smaller basis
vector set sizes or on difficult datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6036</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6036</id><created>2012-06-26</created><authors><author><keyname>Rocha</keyname><forenames>Luis Enrique Correa</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent D.</forenames></author></authors><title>Temporal Heterogeneities Increase the Prevalence of Epidemics on
  Evolving Networks</title><categories>physics.soc-ph cs.SI physics.med-ph q-bio.PE</categories><comments>5 figures + supplementary information</comments><journal-ref>PLoS Computational Biology 9(3): e1002974 (2013)</journal-ref><doi>10.1371/journal.pcbi.1002974</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical studies suggest that contact patterns follow heterogeneous
inter-event times, meaning that intervals of high activity are followed by
periods of inactivity. Combined with birth and death of individuals, these
temporal constraints affect the spread of infections in a non-trivial way and
are dependent on the particular contact dynamics. We propose a stochastic model
to generate temporal networks where vertices make instantaneous contacts
following heterogeneous inter-event times, and leave and enter the system at
fixed rates. We study how these temporal properties affect the prevalence of an
infection and estimate R0, the number of secondary infections, by modeling
simulated infections (SIR, SI and SIS) co-evolving with the network structure.
We find that heterogeneous contact patterns cause earlier and larger epidemics
on the SIR model in comparison to homogeneous scenarios. In case of SI and SIS,
the epidemics is faster in the early stages (up to 90% of prevalence) followed
by a slowdown in the asymptotic limit in case of heterogeneous patterns. In the
presence of birth and death, heterogeneous patterns always cause higher
prevalence in comparison to homogeneous scenarios with same average inter-event
times. Our results suggest that R0 may be underestimated if temporal
heterogeneities are not taken into account in the modeling of epidemics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6038</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6038</id><created>2012-06-26</created><authors><author><keyname>Sellamanickam</keyname><forenames>Sundararajan</forenames></author><author><keyname>Selvaraj</keyname><forenames>Sathiya Keerthi</forenames></author></authors><title>Predictive Approaches For Gaussian Process Classifier Model Selection</title><categories>cs.LG stat.ML</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of Gaussian process classifier (GPC)
model selection with different Leave-One-Out (LOO) Cross Validation (CV) based
optimization criteria and provide a practical algorithm using LOO predictive
distributions with such criteria to select hyperparameters. Apart from the
standard average negative logarithm of predictive probability (NLP), we also
consider smoothed versions of criteria such as F-measure and Weighted Error
Rate (WER), which are useful for handling imbalanced data. Unlike the
regression case, LOO predictive distributions for the classifier case are
intractable. We use approximate LOO predictive distributions arrived from
Expectation Propagation (EP) approximation. We conduct experiments on several
real world benchmark datasets. When the NLP criterion is used for optimizing
the hyperparameters, the predictive approaches show better or comparable NLP
generalization performance with existing GPC approaches. On the other hand,
when the F-measure criterion is used, the F-measure generalization performance
improves significantly on several datasets. Overall, the EP-based predictive
algorithm comes out as an excellent choice for GP classifier model selection
with different optimization criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6049</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6049</id><created>2012-06-25</created><updated>2015-11-28</updated><authors><author><keyname>Cover</keyname><forenames>Keith S.</forenames></author></authors><title>Improved visualisation of brain arteriovenous malformations using color
  intensity projections with hue cycling</title><categories>cs.GR cs.HC</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Color intensity projections (CIPs) have been shown to improve the
visualisation of greyscale angiography images by combining greyscale images
into a single color image. A key property of the combined CIPs image is the
encoding of the arrival time information from greyscale images into the hue of
the color in the CIPs image. A few minor improvements to the calculation of the
CIPs image are introduced that substantially improve the quality of the
visualisation. One improvement is interpolating of the greyscale images in time
before calculation of the CIPs image. A second is the use of hue cycling -
where the hue of the color is cycled through more than once in an image. The
hue cycling allows the variation of the hue to be concentrated in structures of
interest. An angiogram of a brain is used to demonstrate the substantial
improvements hue cycling brings to CIPs images. A third improvement is the use
of maximum intensity projection for 2D rendering of a 3D CIPs image volume. A
fourth improvement allows interpreters to interactively adjust the phase of the
hue via standard contrast-brightness controls using lookup tables. Other
potential applications of CIPs are also mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6068</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6068</id><created>2012-06-26</created><authors><author><keyname>Katz</keyname><forenames>Nets Hawk</forenames></author></authors><title>On the CNF-complexity of bipartite graphs containing no $K_{2,2}$'s</title><categories>cs.CC cs.DM math.CA math.CO</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By a probabilistic construction, we find a bipartite graph having average
degree $d$ which can be expressed as a conjunctive normal form using $C \log d$
clauses. This contradicts research problem 1.33 of Jukna.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6080</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6080</id><created>2012-06-26</created><authors><author><keyname>Schlicht</keyname><forenames>Erik J.</forenames></author><author><keyname>Lee</keyname><forenames>Ritchie</forenames></author><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Kochenderfer</keyname><forenames>Mykel J.</forenames></author><author><keyname>Tracey</keyname><forenames>Brendan</forenames></author></authors><title>Predicting the behavior of interacting humans by fusing data from
  multiple sources</title><categories>cs.AI cs.GT</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-fidelity methods combine inexpensive low-fidelity simulations with
costly but high-fidelity simulations to produce an accurate model of a system
of interest at minimal cost. They have proven useful in modeling physical
systems and have been applied to engineering problems such as wing-design
optimization. During human-in-the-loop experimentation, it has become
increasingly common to use online platforms, like Mechanical Turk, to run
low-fidelity experiments to gather human performance data in an efficient
manner. One concern with these experiments is that the results obtained from
the online environment generalize poorly to the actual domain of interest. To
address this limitation, we extend traditional multi-fidelity approaches to
allow us to combine fewer data points from high-fidelity human-in-the-loop
experiments with plentiful but less accurate data from low-fidelity experiments
to produce accurate models of how humans interact. We present both model-based
and model-free methods, and summarize the predictive performance of each method
under different conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6098</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6098</id><created>2012-06-26</created><updated>2012-11-18</updated><authors><author><keyname>Basso-Blandin</keyname><forenames>Adrien</forenames><affiliation>IBISC Lab</affiliation></author><author><keyname>Delaplace</keyname><forenames>Franck</forenames><affiliation>IBISC Lab</affiliation></author></authors><title>GUBS, a Behavior-based Language for Open System Dedicated to Synthetic
  Biology</title><categories>cs.PL cs.CE</categories><comments>In Proceedings MeCBIC 2012, arXiv:1211.3476</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 100, 2012, pp. 29-47</journal-ref><doi>10.4204/EPTCS.100.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose a domain specific language, GUBS (Genomic Unified
Behavior Specification), dedicated to the behavioral specification of synthetic
biological devices, viewed as discrete open dynamical systems. GUBS is a
rule-based declarative language. By contrast to a closed system, a program is
always a partial description of the behavior of the system. The semantics of
the language accounts the existence of some hidden non-specified actions
possibly altering the behavior of the programmed device. The compilation
framework follows a scheme similar to automatic theorem proving, aiming at
improving synthetic biological design safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6099</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6099</id><created>2012-06-25</created><updated>2012-09-20</updated><authors><author><keyname>Shad</keyname><forenames>Shafqat Ali</forenames></author><author><keyname>Chen</keyname><forenames>Enhong</forenames></author></authors><title>Precise Location Acquisition of Mobility Data Using Cell-id</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Science Issues, vol. 9, no. 3,
  pp. 222-231, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors. Cellular network data has
become a hot source of study for extraction of user-mobility and
spatio-temporal trends. Location binding in mobility data can be done through
different methods like GPS, service provider assisted faux-GPS and Cell Global
Identity (CGI). Among these Cell Global Identity is most inexpensive method and
readily available solution for mobility extraction; however exact spatial
extraction is somehow a problem in it. This paper presents the spatial
extraction technique of mobile phone user raw data which carries the
information like location information, proximity location and activity of
subjects. This work mainly focuses on the data pre-processing methodology and
technique to interpret the low level mobility data into high level mobility
information using the designed clustering methodology and publically available
Cell-IDs databases. Work proposed the semi- supervised strategy to derive the
missing locations thorough the usage of semantic tag information and removal of
spatial outliers for precise mobility profile building.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6135</identifier>
 <datestamp>2014-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6135</id><created>2012-06-26</created><updated>2014-12-22</updated><authors><author><keyname>Herrmann</keyname><forenames>Sven</forenames></author><author><keyname>Moulton</keyname><forenames>Vincent</forenames></author></authors><title>Computing the blocks of a quasi-median graph</title><categories>math.CO cs.DM q-bio.QM</categories><comments>17 pages, 2 figures</comments><msc-class>68R10, 92D20, 05C40</msc-class><journal-ref>Discrete Applied Mathematics, 179 (2014), 129-138</journal-ref><doi>10.1016/j.dam.2014.07.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quasi-median graphs are a tool commonly used by evolutionary biologists to
visualise the evolution of molecular sequences. As with any graph, a
quasi-median graph can contain cut vertices, that is, vertices whose removal
disconnect the graph. These vertices induce a decomposition of the graph into
blocks, that is, maximal subgraphs which do not contain any cut vertices. Here
we show that the special structure of quasi-median graphs can be used to
compute their blocks without having to compute the whole graph. In particular
we present an algorithm that, for a collection of $n$ aligned sequences of
length $m$, can compute the blocks of the associated quasi-median graph
together with the information required to correctly connect these blocks
together in run time $\mathcal O(n^2m^2)$, independent of the size of the
sequence alphabet. Our primary motivation for presenting this algorithm is the
fact that the quasi-median graph associated to a sequence alignment must
contain all most parsimonious trees for the alignment, and therefore
precomputing the blocks of the graph has the potential to help speed up any
method for computing such trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6141</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6141</id><created>2012-06-26</created><authors><author><keyname>Kao</keyname><forenames>Yi-Hao</forenames></author><author><keyname>Van Roy</keyname><forenames>Benjamin</forenames></author></authors><title>Directed Time Series Regression for Control</title><categories>cs.LG cs.SY stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose directed time series regression, a new approach to estimating
parameters of time-series models for use in certainty equivalent model
predictive control. The approach combines merits of least squares regression
and empirical optimization. Through a computational study involving a
stochastic version of a well known inverted pendulum balancing problem, we
demonstrate that directed time series regression can generate significant
improvements in controller performance over either of the aforementioned
alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6142</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6142</id><created>2012-06-26</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Planar Lombardi Drawings for Subcubic Graphs</title><categories>cs.CG</categories><comments>15 pages, 9 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that every planar graph with maximum degree three has a planar
drawing in which the edges are drawn as circular arcs that meet at equal angles
around every vertex. Our construction is based on the Koebe-Thurston-Andreev
circle packing theorem, and uses a novel type of Voronoi diagram for circle
packings that is invariant under Moebius transformations, defined using
three-dimensional hyperbolic geometry. We also use circle packing to construct
planar Lombardi drawings of a special class of 4-regular planar graphs, the
medial graphs of polyhedral graphs, and we show that not every 4-regular planar
graph has a Lombardi drawing. We have implemented our algorithm for 3-connected
planar cubic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6145</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6145</id><created>2012-06-26</created><updated>2013-08-06</updated><authors><author><keyname>Cheng</keyname><forenames>Zhiyu</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author></authors><title>Two-way Networks: when Adaptation is Useless</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Trans. on Information Theory, June 26, 2012.
  Portions have appeared in Allerton 2011, ISIT 2012, Allerton 2012. This new
  version was revised and the revision was re-submitted to IEEE Trans. on
  Information Theory on July 5, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In two-way networks, nodes act as both sources and destinations of messages.
This allows for &quot;adaptation&quot; at or &quot;interaction&quot; between the nodes - a node's
channel inputs may be functions of its message(s) and previously received
signals. How to best adapt is key to two-way communication, rendering it
challenging. However, examples exist of point-to-point channels where
adaptation is not beneficial from a capacity perspective. We ask whether
analogous examples exist for multi-user two-way networks.
  We first consider deterministic two-way channel models: the binary modulo-2
addition channel and a generalization thereof, and the linear deterministic
channel. For these deterministic models we obtain the capacity region for the
two-way multiple access/broadcast channel, the two-way Z channel and the
two-way interference channel (IC). In all cases we permit all nodes to adapt
channel inputs to past outputs (except for portions of the linear deterministic
two-way IC where we only permit 2 of the 4 nodes to fully adapt). However, we
show that this adaptation is useless from a capacity region perspective and
capacity is achieved by strategies where the channel inputs at each use do not
adapt to previous inputs. Finally, we consider the Gaussian two-way IC, and
show that partial adaptation is useless when the interference is very strong.
In the strong and weak interference regimes, we show that the non-adaptive Han
and Kobayashi scheme utilized in parallel in both directions achieves to within
a constant gap for the symmetric rate of the fully (some regimes) or partially
(remaining regimes) adaptive models.
  The central technical contribution is the derivation of new, computable outer
bounds which allow for adaptation. Inner bounds follow from non-adaptive
achievability schemes of the corresponding one-way channel models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6148</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6148</id><created>2012-06-26</created><authors><author><keyname>Gurvits</keyname><forenames>Leonid</forenames></author><author><keyname>Judd</keyname><forenames>J. Stephen</forenames></author></authors><title>The Social Will-Testing Game and its Solution</title><categories>cs.GT q-bio.PE</categories><comments>6 pages, 1 figure</comments><acm-class>J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine a two-person game we call Will-Testing in which the strategy space
for both players is a real number. It has no equilibrium. When an infinitely
large set of players plays this in all possible pairings, there is an
equilibrium for the distribution of strategies which requires all players to
use different strategies. We conjecture this solution could underlie some
phenomena (like pecking orders) observed in animals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6153</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6153</id><created>2012-06-26</created><authors><author><keyname>Shafie</keyname><forenames>Ahmed El</forenames></author></authors><title>To Sense or Not To Sense</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A longer sensing time improves the sensing performance; however, with a fixed
frame size, the longer sensing time will reduce the allowable data transmission
time of the secondary user (SU). In this paper, we try to address the tradeoff
between sensing the primary channel for $\tau$ seconds of the time slot
proceeded by randomly accessing it and randomly accessing primary channel
without sensing to avoid wasting $\tau$ seconds in sensing. The SU senses
primary channel to exploit the periods of silence, if the primary user (PU) is
declared to be idle the SU randomly accesses the channel with some access
probability $a_s$. In addition to randomly accesses the channel if the PU is
sensed to be idle, it possibly accesses it if the channel is declared to be
busy with some access probability $b_s$. This is because the probability of
false alarm and misdetection cause significant secondary throughput degradation
and affect the PU QoS. We propose variable sensing duration schemes where the
SU optimizes over the optimal sensing time to achieve the maximum stable
throughput for both primary and secondary queues. The results reveal the
performance gains of the proposed schemes over the conventional sensing scheme,
i.e., the SU senses the primary channel for $\tau$ seconds and accesses with
probability 1 if the PU is declared to be idle. Also, the proposed schemes
overcome random access without sensing scheme.
  The theoretical and numerical results show that pairs of misdetection and
false alarm probabilities may exist such that sensing the primary channel for
very small duration overcomes sensing it for large portion of the time slot. In
addition, for certain average arrival rate to the primary queue pairs of
misdetection and false alarm probabilities may exist such that the random
access without sensing overcomes the random access with long sensing duration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6161</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6161</id><created>2012-06-26</created><authors><author><keyname>Evans</keyname><forenames>Janet D.</forenames></author><author><keyname>Plante</keyname><forenames>Raymond L.</forenames></author><author><keyname>Bonaventura</keyname><forenames>Nina</forenames></author><author><keyname>Busko</keyname><forenames>Ivo</forenames></author><author><keyname>Cresitello-Dittmar</keyname><forenames>Mark</forenames></author><author><keyname>D'Abrusco</keyname><forenames>Raffaele</forenames></author><author><keyname>Doe</keyname><forenames>Stephen</forenames></author><author><keyname>Ebert</keyname><forenames>Rick</forenames></author><author><keyname>Laurino</keyname><forenames>Omar</forenames></author><author><keyname>Pevunova</keyname><forenames>Olga</forenames></author><author><keyname>Refsdal</keyname><forenames>Brian</forenames></author><author><keyname>Thomas</keyname><forenames>Brian</forenames></author></authors><title>Managing Distributed Software Development in the Virtual Astronomical
  Observatory</title><categories>astro-ph.IM cs.SE</categories><comments>7 pages, 2 figures, SPIE 2012 conference</comments><doi>10.1117/12.927371</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The U.S. Virtual Astronomical Observatory (VAO) is a product-driven
organization that provides new scientific research capabilities to the
astronomical community. Software development for the VAO follows a lightweight
framework that guides development of science applications and infrastructure.
Challenges to be overcome include distributed development teams, part-time
efforts, and highly constrained schedules. We describe the process we followed
to conquer these challenges while developing Iris, the VAO application for
analysis of 1-D astronomical spectral energy distributions (SEDs). Iris was
successfully built and released in less than a year with a team distributed
across four institutions. The project followed existing International Virtual
Observatory Alliance inter-operability standards for spectral data and
contributed a SED library as a by-product of the project. We emphasize lessons
learned that will be folded into future development efforts. In our experience,
a well-defined process that provides guidelines to ensure the project is
cohesive and stays on track is key to success. Internal product deliveries with
a planned test and feedback loop are critical. Release candidates are measured
against use cases established early in the process, and provide the opportunity
to assess priorities and make course corrections during development. Also key
is the participation of a stakeholder such as a lead scientist who manages the
technical questions, advises on priorities, and is actively involved as a lead
tester. Finally, frequent scheduled communications (for example a bi-weekly
tele-conference) assure issues are resolved quickly and the team is working
toward a common vision
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6170</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6170</id><created>2012-06-27</created><updated>2012-12-23</updated><authors><author><keyname>Modares</keyname><forenames>Hero</forenames><affiliation>corresponding author</affiliation></author><author><keyname>Salleh</keyname><forenames>Rosli</forenames></author><author><keyname>Moravejosharieh</keyname><forenames>Amirhosein</forenames></author><author><keyname>Malakootikhah</keyname><forenames>Hossein</forenames></author></authors><title>Securing Binding Update in Mobile IPv6 Using Private Key Base Binding
  Update Protocol</title><categories>cs.NI</categories><comments>This paper has been withdrawn by the author due to wrong update.
  please withdraw this article</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Mobile IPv6 control signalling messages generally act as informants to the
home agent (HA) and the correspondent node (CN) regarding a mobile node's
(MN's) new address when its network attachment point changes. Messages should
be protected to avoid different security attacks. In the existing standard,
control signalling messages between HA and MN are frequently authenticated with
IKEv2 and X.509 certificates via IPSec. These signalling messages between MN
and CN are so far protected by an effective but insecure protocol. A protocol
that uses Binding Update Route Optimisation has security vulnerabilities that
allow redirection of traffic by attackers. This traffic is intercepted and then
false binding updates is sent along with packet eavesdropping and Denial of
Service (DoS) that disrupts any communication. Due to lack of ineffective
authentication procedures to ascertain the validity of the users or hide the
location data of HoA and CoA, security issues mentioned above will occur. This
paper presents some of existing protecting control signalling message
protocols, as well as some proposed approaches for designing a secure
method-based private key IP address between an MN and a CN. Using Private Key
Based Binding Update (PKBU), care-of-address (CoA) can thus be protected
against False Binding Update (FBU), Man-in-the-Middle (MITM) and
Denial-of-Service (DoS) attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6172</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6172</id><created>2012-06-27</created><authors><author><keyname>Park</keyname><forenames>Juho</forenames></author><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Kim</keyname><forenames>Donggun</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Outage Probability and Outage-Based Robust Beamforming for MIMO
  Interference Channels with Imperfect Channel State Information</title><categories>cs.IT math.IT</categories><comments>41 pages, 14 figures. accepted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the outage probability and outage-based beam design for
multiple-input multiple-output (MIMO) interference channels are considered.
First, closed-form expressions for the outage probability in MIMO interference
channels are derived under the assumption of Gaussian-distributed channel state
information (CSI) error, and the asymptotic behavior of the outage probability
as a function of several system parameters is examined by using the Chernoff
bound. It is shown that the outage probability decreases exponentially with
respect to the quality of CSI measured by the inverse of the mean square error
of CSI. Second, based on the derived outage probability expressions, an
iterative beam design algorithm for maximizing the sum outage rate is proposed.
Numerical results show that the proposed beam design algorithm yields better
sum outage rate performance than conventional algorithms such as interference
alignment developed under the assumption of perfect CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6177</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6177</id><created>2012-06-27</created><authors><author><keyname>Qin</keyname><forenames>Xiaolin</forenames></author><author><keyname>Wu</keyname><forenames>Wenyuan</forenames></author><author><keyname>Feng</keyname><forenames>Yong</forenames></author><author><keyname>Reid</keyname><forenames>Greg</forenames></author></authors><title>Structural analysis of high-index DAE for process simulation</title><categories>cs.SY</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the structural analysis problem of dynamic lumped
process high-index DAE models. We consider two methods for index reduction of
such models by differentiation: Pryce's method and the symbolic differential
elimination algorithm rifsimp. Discussion and comparison of these methods are
given via a class of fundamental process simulation examples. In particular,
the efficiency of the Pryce method is illustrated as a function of the number
of tanks in process design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6185</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6185</id><created>2012-06-27</created><authors><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Dash</keyname><forenames>Shiba Prasad</forenames></author><author><keyname>Sharma</keyname><forenames>Burle</forenames></author><author><keyname>Patel</keyname><forenames>Sangita</forenames></author></authors><title>Performance Evaluation of A Proposed Variant of Frequency Count (VFC)
  List Accessing Algorithm</title><categories>cs.DS</categories><comments>4 pages, Proceedings of International Conference on Recent Advances
  in Engineering and Technology, Hyderabad, India, April, 2012</comments><report-no>Special Issue, May 2012</report-no><journal-ref>International Journal of Systems, Algorithms and Applications, may
  2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency Count (FC) algorithm is considered as the static optimal algorithm
for the list accessing problem. In this paper, we have made a study of FC
algorithm and explore its limitation. Using the concept of weak look ahead, we
have proposed a novel Variant of Frequency Count (VFC) list accessing
algorithm. We have evaluated the performance of FC and our proposed VFC
algorithm experimentally using input data set from Calgary Corpus. Our
experiments show that for all request sequences and list generated from the
above data set VFC performs better than FC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6187</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6187</id><created>2012-06-27</created><authors><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Patel</keyname><forenames>Sangita</forenames></author><author><keyname>Dash</keyname><forenames>Shiba Prasad</forenames></author><author><keyname>Sharma</keyname><forenames>Burle</forenames></author></authors><title>Some Novel Results From Analysis of Move To Front (MTF) List Accessing
  Algorithm</title><categories>cs.DS</categories><comments>5 pages, Proceedings of the International Conference on Recent
  Advances in Engineering and Technology, ICRAET, Hyderabad, India, April 2012</comments><report-no>Special Issue, May 15, 2012</report-no><journal-ref>International Journal of Systems, Algorithms and Applications, May
  2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  List accessing problem has been studied as a problem of significant
theoretical and practical interest in the context of linear search. Various
list accessing algorithms have been proposed in the literature and their
performances have been analyzed theoretically and experimentally.
Move-To-Front(MTF),Transpose (TRANS) and Frequency Count (FC) are the three
primitive and widely used list accessing algorithms. Most of the other list
accessing algorithms are the variants of these three algorithms. As mentioned
in the literature as an open problem, direct bounds on the behavior and
performance of these list accessing algorithms are needed to allow realistic
comparisons. MTF has been proved to be the best performing online algorithm
till date in the literature for real life inputs with locality of reference.
Motivated by the above challenging research issue, in this paper, we have
generated four types of input request sequences corresponding to real life
inputs without locality of reference. Using these types of request sequences,
we have made an analytical study for evaluating the performance of MTF list
accessing algorithm to obtain some novel and interesting theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6190</identifier>
 <datestamp>2013-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6190</id><created>2012-06-27</created><updated>2013-01-16</updated><authors><author><keyname>Rajashekar</keyname><forenames>Rakshith</forenames></author><author><keyname>Hari</keyname><forenames>K. V. S.</forenames></author></authors><title>Low Complexity Maximum Likelihood Detection in Spatial Modulation
  Systems</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatial Modulation (SM) is a recently developed low-complexity Multiple-Input
Multiple-Output scheme that uses antenna indices and a conventional signal set
to convey information. It has been shown that the Maximum-Likelihood (ML)
detection in an SM system involves joint detection of the transmit antenna
index and the transmitted symbol, and hence, the ML search complexity grows
linearly with the number of transmit antennas and the size of the signal set.
In this paper, we show that the ML search complexity in an SM system becomes
independent of the constellation size when the signal set employed is a square-
or a rectangular-QAM. Further, we show that Sphere Decoding (SD) algorithms
become essential in SM systems only when the number of transmit antennas is
large and not necessarily when the employed signal set is large. We propose a
novel {\em hard-limiting} enabled sphere decoding detector whose complexity is
lesser than that of the existing detector and a generalized detection scheme
for SM systems with {\em arbitrary} number of transmit antennas. We support our
claims with simulation results that the proposed detectors are ML-optimal and
offer a significantly reduced complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6193</identifier>
 <datestamp>2015-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6193</id><created>2012-06-27</created><updated>2013-09-29</updated><authors><author><keyname>Chazelle</keyname><forenames>Bernard</forenames></author><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author></authors><title>Data Structures on Event Graphs</title><categories>cs.DS</categories><comments>15 pages, 7 figures, a preliminary version appeared in Proc. 20th ESA</comments><journal-ref>Algorithmica, 71(4), 2015, pp. 1007-1020</journal-ref><doi>10.1007/s00453-013-9838-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the behavior of data structures when the input and operations
are generated by an event graph. This model is inspired by Markov chains. We
are given a fixed graph G, whose nodes are annotated with operations of the
type insert, delete and query. The algorithm responds to the requests as it
encounters them during a (random or adversarial) walk in G. We study the limit
behavior of such a walk and give an efficient algorithm for recognizing which
structures can be generated. We also give a near-optimal algorithm for
successor searching if the event graph is a cycle and the walk is adversarial.
For a random walk, the algorithm becomes optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6196</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6196</id><created>2012-06-27</created><authors><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>IRISA</affiliation></author><author><keyname>Bonnel</keyname><forenames>Nicolas</forenames><affiliation>IRISA</affiliation></author><author><keyname>M&#xe9;nier</keyname><forenames>Gilbas</forenames><affiliation>IRISA</affiliation></author></authors><title>Discrete Elastic Inner Vector Spaces with Application in Time Series and
  Sequence Mining</title><categories>cs.LG cs.DB</categories><comments>arXiv admin note: substantial text overlap with arXiv:1101.4318</comments><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Knowledge and Data Engineering (2012) pp 1-14</journal-ref><doi>10.1109/TKDE.2012.131</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a framework dedicated to the construction of what we call
discrete elastic inner product allowing one to embed sets of non-uniformly
sampled multivariate time series or sequences of varying lengths into inner
product space structures. This framework is based on a recursive definition
that covers the case of multiple embedded time elastic dimensions. We prove
that such inner products exist in our general framework and show how a simple
instance of this inner product class operates on some prospective applications,
while generalizing the Euclidean inner product. Classification experimentations
on time series and symbolic sequences datasets demonstrate the benefits that we
can expect by embedding time series or sequences into elastic inner spaces
rather than into classical Euclidean spaces. These experiments show good
accuracy when compared to the euclidean distance or even dynamic programming
algorithms while maintaining a linear algorithmic complexity at exploitation
stage, although a quadratic indexing phase beforehand is required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6201</identifier>
 <datestamp>2013-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6201</id><created>2012-06-27</created><updated>2013-01-24</updated><authors><author><keyname>Fukui</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Otachi</keyname><forenames>Yota</forenames></author><author><keyname>Uehara</keyname><forenames>Ryuhei</forenames></author><author><keyname>Uno</keyname><forenames>Takeaki</forenames></author><author><keyname>Uno</keyname><forenames>Yushi</forenames></author></authors><title>On Complexity of Flooding Games on Graphs with Interval Representations</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The flooding games, which are called Flood-It, Mad Virus, or HoneyBee, are a
kind of coloring games and they have been becoming popular online. In these
games, each player colors one specified cell in his/her turn, and all connected
neighbor cells of the same color are also colored by the color. This flooding
or coloring spreads on the same color cells. It is natural to consider these
new coloring games on more general boards, or general graphs. Recently,
computational complexities of the variants of the flooding games on several
graph classes have been studied. In this paper, we investigate the flooding
games on some graph classes characterized by interval representations. Our
results state that the number of colors is a key parameter to determine the
computational complexity of the flooding games. When the number of colors is a
fixed constant, these games can be solved in polynomial time on an interval
graph. On the other hand, if the number of colors is not bounded, the flooding
game is NP-complete on a proper interval graph. We also state similar results
for split graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6202</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6202</id><created>2012-06-27</created><authors><author><keyname>Uno</keyname><forenames>Takeaki</forenames></author><author><keyname>Uno</keyname><forenames>Yushi</forenames></author></authors><title>Mining Preserving Structures in a Graph Sequence</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent research of data mining, frequent structures in a sequence of
graphs have been studied intensively, and one of the main concern is changing
structures along a sequence of graphs that can capture dynamic properties of
data. On the contrary, we newly focus on &quot;preserving structures&quot; in a graph
sequence that satisfy a given property for a certain period, and mining such
structures is studied. As for an onset, we bring up two structures, a connected
vertex subset and a clique that exist for a certain period. We consider the
problem of enumerating these structures. and present polynomial delay
algorithms for the problems. Their running time may depend on the size of the
representation, however, if each edge has at most one time interval in the
representation, the running time is O(|V||E|^3) for connected vertex subsets
and O(min{\Delta^5, |E|^2\Delta}) for cliques, where the input graph is G =
(V,E) with maximum degree \Delta. To the best of our knowledge, this is the
first approach to the treatment of this notion, namely, preserving structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6207</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6207</id><created>2012-06-27</created><authors><author><keyname>Tziritas</keyname><forenames>Nikos</forenames></author><author><keyname>Khan</keyname><forenames>Samee Ullah</forenames></author><author><keyname>Xu</keyname><forenames>Cheng-Zhong</forenames></author><author><keyname>Hong</keyname><forenames>Jue</forenames></author></authors><title>An Optimal Fully Distributed Algorithm to Minimize the Resource
  Consumption of Cloud Applications</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to the pay-per-use model adopted in clouds, the more the resources
consumed by an application running in a cloud computing environment, the
greater the amount of money the owner of the corresponding application will be
charged. Therefore, applying intelligent solutions to minimize the resource
consumption is of great importance. Because centralized solutions are deemed
unsuitable for large-distributed systems or large-scale applications, we
propose a fully distributed algorithm (called DRA) to overcome the scalability
issues. Specifically, DRA migrates the inter-communicating components of an
application, such as processes or virtual machines, close to each other to
minimize the total resource consumption. The migration decisions are made in a
dynamic way and based only on local information. We prove that DRA achieves
convergence and results always in the optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6209</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6209</id><created>2012-06-27</created><authors><author><keyname>Abolfazli</keyname><forenames>Saeid</forenames></author><author><keyname>Sanaei</keyname><forenames>Zohreh</forenames></author><author><keyname>Gani</keyname><forenames>Abdullah</forenames></author><author><keyname>Shiraz</keyname><forenames>Muhammad</forenames></author></authors><title>MOMCC: Market-Oriented Architecture for Mobile Cloud Computing Based on
  Service Oriented Architecture</title><categories>cs.DC cs.NI cs.SE</categories><comments>6 full pages, accepted to be published in IEEE Mobicc'12; Saeid
  Abolfazli, Zohreh Sanaei, Muhammad Shiraz, Abdullah Gani, MOMCC:
  Market-Oriented Architecture for Mobile Cloud Computing Based on Service
  Oriented Architecture, MobiCC'12:2012 IEEE Workshop on Mobile Cloud
  Computing, Beijing, China</comments><journal-ref>2012 1st IEEE International Conference on Communications in China
  Workshops (2012), 8-13</journal-ref><doi>10.1109/ICCCW.2012.6316481</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vision of augmenting computing capabilities of mobile devices, especially
smartphones with least cost is likely transforming to reality leveraging cloud
computing. Cloud exploitation by mobile devices breeds a new research domain
called Mobile Cloud Computing (MCC). However, issues like portability and
interoperability should be addressed for mobile augmentation which is a
non-trivial task using component-based approaches. Service Oriented
Architecture (SOA) is a promising design philosophy embraced by mobile
computing and cloud computing communities to stimulate portable, complex
application using prefabricated building blocks called Services. Utilizing
distant cloud resources to host and run Services is hampered by long WAN
latency. Exploiting mobile devices in vicinity alleviates long WAN latency,
while creates new set of issues like Service publishing and discovery as well
as client-server security, reliability, and Service availability. In this
paper, we propose a market-oriented architecture based on SOA to stimulate
publishing, discovering, and hosting Services on nearby mobiles, which reduces
long WAN latency and creates a business opportunity that encourages mobile
owners to embrace Service hosting. Group of mobile phones simulate a nearby
cloud computing platform. We create new role of \textit{Service host} by
enabling unskilled mobile owners/users to host Services developed by skilled
developers. Evidently, Service availability, reliability, and Service-oriented
mobile application portability will increase towards green ubiquitous computing
in our mobile cloud infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6213</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6213</id><created>2012-06-27</created><authors><author><keyname>Merino</keyname><forenames>Javier</forenames></author><author><keyname>Puente</keyname><forenames>Valentin</forenames></author><author><keyname>Gregorio</keyname><forenames>Jos&#xe9; &#xc1;ngel</forenames></author></authors><title>The Necessity for Hardware QoS Support for Server Consolidation and
  Cloud Computing</title><categories>cs.AR cs.OS</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Chip multiprocessors (CMPs) are ubiquitous in most of today's computing
fields. Although they provide noticeable benefits in terms of performance, cost
and power efficiency, they also introduce some new issues. In this paper we
analyze how the interference from Virtual Private Servers running in other
cores is a significant component of performance unpredictability and can
threaten the attainment of cloud computing. Even if virtualization is used, the
sharing of the on-chip section of the memory hierarchy by different cores makes
performance isolation strongly dependent on what is running elsewhere in the
system. We will show in three actual computing systems, based on Sun UltraSparc
T1, Sun UltraSparc T2 and Intel Xeon processors, how state-of-the-art
virtualization techniques are unable to guarantee performance isolation in a
representative workload such as SPECweb2005. In an especially conceived near
worst-case scenario, it is possible to reduce the performance achieved by a
Solaris Zones consolidated server for this suite of benchmarks in a Sun Fire
T1000 and a Sun Enterprise T5120 by up to 80%. The performance drop observed by
a Xen consolidated server running in a HP Proliant DL160 G5 is almost 45%. For
all systems under study, off-chip bandwidth is shown to be the most critical
resource.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6214</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6214</id><created>2012-06-27</created><authors><author><keyname>Hennemann</keyname><forenames>Stefan</forenames></author><author><keyname>Derudder</keyname><forenames>Ben</forenames></author></authors><title>An Alternative Approach to the Calculation and Analysis of Connectivity
  in the World City Network</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages, 9 figures, 2 tables</comments><msc-class>05C82, 90B15, 62P25, 91D30</msc-class><journal-ref>Environment and Planning B: Planning and Design 41(3) 392-412</journal-ref><doi>10.1068/b39108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical research on world cities often draws on Taylor's (2001) notion of
an 'interlocking network model', in which office networks of globalized service
firms are assumed to shape the spatialities of urban networks. In spite of its
many merits, this approach is limited because the resultant adjacency matrices
are not really fit for network-analytic calculations. We therefore propose a
fresh analytical approach using a primary linkage algorithm that produces a
one-mode directed graph based on Taylor's two-mode city/firm network data. The
procedure has the advantage of creating less dense networks when compared to
the interlocking network model, while nonetheless retaining the network
structure apparent in the initial dataset. We randomize the empirical network
with a bootstrapping simulation approach, and compare the simulated parameters
of this null-model with our empirical network parameter (i.e. betweenness
centrality). We find that our approach produces results that are comparable to
those of the standard interlocking network model. However, because our approach
is based on an actual graph representation and network analysis, we are able to
assess cities' position in the network at large. For instance, we find that
cities such as Tokyo, Sydney, Melbourne, Almaty and Karachi hold more strategic
and valuable positions than suggested in the interlocking networks as they play
a bridging role in connecting cities across regions. In general, we argue that
our graph representation allows for further and deeper analysis of the original
data, further extending world city network research into a theory-based
empirical research approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6217</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6217</id><created>2012-06-27</created><authors><author><keyname>Huang</keyname><forenames>Shengchun</forenames></author><author><keyname>Yin</keyname><forenames>Hao</forenames></author><author><keyname>Wu</keyname><forenames>Jiangxing</forenames></author><author><keyname>Leung</keyname><forenames>Victor C. M.</forenames></author></authors><title>User Selection for Multi-user MIMO Downlink with Zero-Forcing
  Beamforming</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a greedy user selection with swap (GUSS) algorithm
based on zero-forcing beamforming (ZFBF) for the multi-user multiple-input
multiple-output (MIMO) downlink channels. Since existing user selection
algorithms, such as the zero-forcing with selection (ZFS), have `redundant
user' and `local optimum' flaws that compromise the achieved sum rate, GUSS
adds `delete' and `swap' operations to the user selection procedure of ZFS to
improve the performance by eliminating `redundant user' and escaping from
`local optimum', respectively. In addition, an effective channel vector based
effective-channel-gain updating scheme is presented to reduce the complexity of
GUSS. With the help of this updating scheme, GUSS has the same order of
complexity of ZFS with only a linear increment. Simulation results indicate
that on average GUSS achieves 99.3 percent of the sum rate upper bound that is
achieved by exhaustive search, over the range of transmit signal-to-noise
ratios considered with only three to six times the complexity of ZFS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6219</identifier>
 <datestamp>2013-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6219</id><created>2012-06-27</created><authors><author><keyname>Sanaei</keyname><forenames>Zohreh</forenames></author><author><keyname>Abolfazli</keyname><forenames>Saeid</forenames></author><author><keyname>Gani</keyname><forenames>Abdullah</forenames></author><author><keyname>Shiraz</keyname><forenames>Muhammad</forenames></author></authors><title>SAMI: Service-Based Arbitrated Multi-Tier Infrastructure for Mobile
  Cloud Computing</title><categories>cs.DC cs.NI</categories><comments>6 full pages, accepted for publication in IEEE MobiCC'12 conference,
  MobiCC 2012:IEEE Workshop on Mobile Cloud Computing, Beijing, China</comments><journal-ref>2012 1st IEEE International Conference on Communications in China
  Workshops, (2012) 14-19</journal-ref><doi>10.1109/ICCCW.2012.6316466</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Cloud Computing (MCC) is the state-ofthe- art mobile computing
technology aims to alleviate resource poverty of mobile devices. Recently,
several approaches and techniques have been proposed to augment mobile devices
by leveraging cloud computing. However, long-WAN latency and trust are still
two major issues in MCC that hinder its vision. In this paper, we analyze MCC
and discuss its issues. We leverage Service Oriented Architecture (SOA) to
propose an arbitrated multi-tier infrastructure model named SAMI for MCC. Our
architecture consists of three major layers, namely SOA, arbitrator, and
infrastructure. The main strength of this architecture is in its multi-tier
infrastructure layer which leverages infrastructures from three main sources of
Clouds, Mobile Network Operators (MNOs), and MNOs' authorized dealers. On top
of the infrastructure layer, an arbitrator layer is designed to classify
Services and allocate them the suitable resources based on several metrics such
as resource requirement, latency and security. Utilizing SAMI facilitate
development and deployment of service-based platform-neutral mobile
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6222</identifier>
 <datestamp>2012-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6222</id><created>2012-06-27</created><updated>2012-08-22</updated><authors><author><keyname>Abolfazli</keyname><forenames>Saeid</forenames></author><author><keyname>Sanaei</keyname><forenames>Zohre</forenames></author><author><keyname>Shiraz</keyname><forenames>Muhammad</forenames></author><author><keyname>Keshavarz</keyname><forenames>Hassan</forenames></author><author><keyname>Gani</keyname><forenames>Abdullah</forenames></author></authors><title>An Evolutionary Study of Rich Mobile Applications</title><categories>cs.HC</categories><comments>This paper has been withdrawn by the author due to some copyright
  issues</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Delivering Rich User eXperience (RUX) with the current explosion of
smartphone as real ubiquitous computing device requires adaptive application
architecture. Rich Mobile Application (RMA) is likely the candidate
architecture for future mobile applications to deliver rich, immersive
experience to the smartphone users. Research and development in domain of RMA
has started and results are appearing in literature which advocates its future
trend and encourages review of RMAs. This article aims to present overview of
RMA and states clear distinction between Rich Internet Applications (RIAs) -
that are desktop-like Web applications - and RMAs to facilitate and accelerate
development of smartphone-centric application development tools and
technologies. RMAs are defined, their comprehensive overview is presented, and
current trends are described. Our study shows that despite of literal
similarity of RMA and RIA, they have dissimilar inward architectures.
Implicitly, understanding the distinctions between richness delivery in PCs and
smartphones as well as knowledge of inward similarity and difference between
RIAs and RMAs contribute toward development of enhanced smartphone's
applications to deliver RUX to mobile clients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6225</identifier>
 <datestamp>2012-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6225</id><created>2012-06-27</created><updated>2012-11-29</updated><authors><author><keyname>Shiraz</keyname><forenames>Muhammad</forenames></author><author><keyname>Abolfazli</keyname><forenames>Saeid</forenames></author><author><keyname>Sanaei</keyname><forenames>Zohreh</forenames></author><author><keyname>Gani</keyname><forenames>Abdullah</forenames></author></authors><title>Virtual Machine Migration: A Resource Intensive Outsourcing Mechanism
  for Mobile Cloud Computing</title><categories>cs.DC</categories><comments>This article has been withdrawn by the author due to some copyright
  issues</comments><journal-ref>Muhammad Shiraz, Saeid Abolfazli, Zohreh Sanaei, Abdullah Gani,
  Virtual Machine Migration: A Resource Intensive Outsourcing Mechanism for
  Mobile Cloud Computing. Archives DesSciences Journal, Vol.65, No.6, 2012.
  ISSN: 1661-464X</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Mobile Cloud Computing (MCC), Virtual Machine (VM) migration based process
offloading is a dominant approach to enhance Smart Mobile Devices (SMDs). A
challenging aspect of VM deployment is the additional computing resources usage
in the deployment and management of VM which obliges computing resources for VM
creation and configuration. The management of VM comprises computing resources
exploitation in the monitoring of VM in entire lifecycle and physical resources
management for VM on SMDs. Therefore, VM migration based application offloading
requires additional computing resource. Consequently computing resources demand
and execution time of the application increases respectively. In this paper, we
empirically review the impact of VM deployment and management on the execution
time of application in diverse scenarios. We investigate VM deployment and
management for application processing in simulation environment by employing
CloudSim: a simulation toolkit that provides an extensible simulation framework
to model VM deployment and management for application processing in cloud
infrastructure. The significance of this work is to ensure that VM deployment
and management necessitates additional computing resources on SMD for
application offloading. We evaluate VM deployment and management in application
processing by analyzing Key Performance Parameters (KPPs) in different
scenarios; such as VM deployment, the execution time of applications, and total
execution time of the simulation. We use KPPs to assess deviations in the
results of diverse experimental scenarios. The empirical analysis concludes
that VM deployment and management oblige additional resources on computing host
which make it a heavyweight approach for process offloading on smart mobile
device.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6230</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6230</id><created>2012-06-27</created><updated>2012-06-28</updated><authors><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Tan</keyname><forenames>Colin Keng-Yan</forenames></author><author><keyname>Oran</keyname><forenames>Ali</forenames></author><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author><author><keyname>Dolan</keyname><forenames>John M.</forenames></author><author><keyname>Sukhatme</keyname><forenames>Gaurav S.</forenames></author></authors><title>Decentralized Data Fusion and Active Sensing with Mobile Sensors for
  Modeling and Predicting Spatiotemporal Traffic Phenomena</title><categories>cs.LG cs.AI cs.DC cs.MA cs.RO</categories><comments>28th Conference on Uncertainty in Artificial Intelligence (UAI 2012),
  Extended version with proofs, 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of modeling and predicting spatiotemporal traffic phenomena over
an urban road network is important to many traffic applications such as
detecting and forecasting congestion hotspots. This paper presents a
decentralized data fusion and active sensing (D2FAS) algorithm for mobile
sensors to actively explore the road network to gather and assimilate the most
informative data for predicting the traffic phenomenon. We analyze the time and
communication complexity of D2FAS and demonstrate that it can scale well with a
large number of observations and sensors. We provide a theoretical guarantee on
its predictive performance to be equivalent to that of a sophisticated
centralized sparse approximation for the Gaussian process (GP) model: The
computation of such a sparse approximate GP model can thus be parallelized and
distributed among the mobile sensors (in a Google-like MapReduce paradigm),
thereby achieving efficient and scalable prediction. We also theoretically
guarantee its active sensing performance that improves under various practical
environmental conditions. Empirical evaluation on real-world urban road network
data shows that our D2FAS algorithm is significantly more time-efficient and
scalable than state-of-the-art centralized algorithms while achieving
comparable predictive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6257</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6257</id><created>2012-06-27</created><authors><author><keyname>Buchin</keyname><forenames>Kevin</forenames></author><author><keyname>Buchin</keyname><forenames>Maike</forenames></author><author><keyname>Meulemans</keyname><forenames>Wouter</forenames></author><author><keyname>Speckmann</keyname><forenames>Bettina</forenames></author></authors><title>Locally Correct Frechet Matchings</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Frechet distance is a metric to compare two curves, which is based on
monotonous matchings between these curves. We call a matching that results in
the Frechet distance a Frechet matching. There are often many different Frechet
matchings and not all of these capture the similarity between the curves well.
We propose to restrict the set of Frechet matchings to &quot;natural&quot; matchings and
to this end introduce locally correct Frechet matchings. We prove that at least
one such matching exists for two polygonal curves and give an O(N^3 log N)
algorithm to compute it, where N is the total number of edges in both curves.
We also present an O(N^2) algorithm to compute a locally correct discrete
Frechet matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6262</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6262</id><created>2012-06-27</created><authors><author><keyname>White</keyname><forenames>Adam</forenames></author><author><keyname>Modayil</keyname><forenames>Joseph</forenames></author><author><keyname>Sutton</keyname><forenames>Richard S.</forenames></author></authors><title>Scaling Life-long Off-policy Learning</title><categories>cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We pursue a life-long learning approach to artificial intelligence that makes
extensive use of reinforcement learning algorithms. We build on our prior work
with general value functions (GVFs) and the Horde architecture. GVFs have been
shown able to represent a wide variety of facts about the world's dynamics that
may be useful to a long-lived agent (Sutton et al. 2011). We have also
previously shown scaling - that thousands of on-policy GVFs can be learned
accurately in real-time on a mobile robot (Modayil, White &amp; Sutton 2011). That
work was limited in that it learned about only one policy at a time, whereas
the greatest potential benefits of life-long learning come from learning about
many policies in parallel, as we explore in this paper. Many new challenges
arise in this off-policy learning setting. To deal with convergence and
efficiency challenges, we utilize the recently introduced GTD({\lambda})
algorithm. We show that GTD({\lambda}) with tile coding can simultaneously
learn hundreds of predictions for five simple target policies while following a
single random behavior policy, assessing accuracy with interspersed on-policy
tests. To escape the need for the tests, which preclude further scaling, we
introduce and empirically vali- date two online estimators of the off-policy
objective (MSPBE). Finally, we use the more efficient of the two estimators to
demonstrate off-policy learning at scale - the learning of value functions for
one thousand policies in real time on a physical robot. This ability
constitutes a significant step towards scaling life-long off-policy learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6266</identifier>
 <datestamp>2013-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6266</id><created>2012-06-27</created><updated>2013-04-08</updated><authors><author><keyname>Ramos</keyname><forenames>Marlon</forenames></author><author><keyname>Anteneodo</keyname><forenames>Celia</forenames></author></authors><title>Random degree-degree correlated networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>8 pages, 9 figures</comments><journal-ref>J. Stat. Mech. P06003 (2012)</journal-ref><doi>10.1088/1742-5468/2013/02/P02024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correlations may affect propagation processes on complex networks. To analyze
their effect, it is useful to build ensembles of networks constrained to have a
given value of a structural measure, such as the degree-degree correlation $r$,
being random in other aspects and preserving the degree distribution. This can
be done through Monte Carlo optimization procedures. Meanwhile, when tuning
$r$, other network properties may concomitantly change. Then, in this work we
analyze, for the $r$-ensembles, the impact of $r$ on properties such as
transitivity, branching and characteristic lengths, that are relevant when
investigating spreading phenomena on these networks. The present analysis is
performed for networks with degree distributions of two main types: either
localized around a typical degree (with exponentially bounded asymptotic decay)
or broadly distributed (with power-law decay). Correlation bounds and size
effects are also investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6273</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6273</id><created>2012-06-27</created><authors><author><keyname>Knapen</keyname><forenames>Johan H.</forenames></author><author><keyname>Prieto</keyname><forenames>Jorge A. P&#xe9;rez</forenames></author><author><keyname>Shahbaz</keyname><forenames>Tariq</forenames></author><author><keyname>Ferr&#xe9;-Mateu</keyname><forenames>Anna</forenames></author><author><keyname>Caon</keyname><forenames>Nicola</forenames></author><author><keyname>Almeida</keyname><forenames>Cristina Ramos</forenames></author><author><keyname>Tingley</keyname><forenames>Brandon</forenames></author><author><keyname>Luridiana</keyname><forenames>Valentina</forenames></author><author><keyname>Flores-Cacho</keyname><forenames>In&#xe9;s</forenames></author><author><keyname>Creevey</keyname><forenames>Orlagh</forenames></author><author><keyname>Torres</keyname><forenames>Arturo Manchado</forenames></author><author><keyname>Trujillo</keyname><forenames>Ignacio</forenames></author><author><keyname>Osorio</keyname><forenames>Maria Rosa Zapatero</forenames></author><author><keyname>Mart&#xed;nez</keyname><forenames>Francisco S&#xe1;nchez</forenames></author><author><keyname>Molina</keyname><forenames>Francisco L&#xf3;pez</forenames></author><author><keyname>D&#xed;az</keyname><forenames>Gabriel P&#xe9;rez</forenames></author><author><keyname>Briganti</keyname><forenames>Miguel</forenames></author><author><keyname>Bonet</keyname><forenames>In&#xe9;s</forenames></author></authors><title>IACTalks: an on-line archive of astronomy-related seminars</title><categories>astro-ph.IM cs.DL</categories><comments>2 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present IACTalks, a free and open access seminars archive
(http://iactalks.iac.es) aimed at promoting astronomy and the exchange of ideas
by providing high-quality scientific seminars to the astronomical community.
The archive of seminars and talks given at the Instituto de Astrofi\'isica de
Canarias goes back to 2008. Over 360 talks and seminars are now freely
available by streaming over the internet. We describe the user interface, which
includes two video streams, one showing the speaker, the other the
presentation. A search function is available, and seminars are indexed by
keywords and in some cases by series, such as special training courses or the
2011 Winter School of Astrophysics, on secular evolution of galaxies. The
archive is made available as an open resource, to be used by scientists and the
public.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6279</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6279</id><created>2012-06-26</created><authors><author><keyname>Ganesan</keyname><forenames>Ashwin</forenames></author></authors><title>Automorphism groups of graphs</title><categories>cs.DM math.CO</categories><comments>lecture notes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These lecture notes provide an introduction to automorphism groups of graphs.
Some special families of graphs are then discussed, especially the families of
Cayley graphs generated by transposition sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6281</identifier>
 <datestamp>2012-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6281</id><created>2012-06-27</created><updated>2012-08-19</updated><authors><author><keyname>Reddy</keyname><forenames>P. Radha Krishna</forenames></author><author><keyname>Joshna</keyname><forenames>P.</forenames></author><author><keyname>Sireesha</keyname><forenames>G.</forenames></author><author><keyname>Thirupathaiah</keyname><forenames>A.</forenames></author></authors><title>Data Collection through Vehicular Sensor Networks by using TCDGP</title><categories>cs.NI</categories><comments>Published</comments><journal-ref>CSCV01I1001, August 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now a days Many car manufacturers are planning to install wireless
connectivity equipment in their vehicles to enable communications with
&quot;roadside base station&quot; and also between vehicles, for the purposes of safety,
driving assistance, and entertainment. One distinct feature is that vehicles
are highly mobile, with speed up to 30 m/s, though their mobility patterns are
more predictable than those of nodes in Mobile Ad-hoc Networks (MANET) due to
the constraints imposed by road, speed limits, and commuting habits. Therefore,
these networks require specific solutions and identify a novel research area,
i.e., Vehicular Ad-hoc Networks (VANET). In this paper, we focus on a
particular VSN architecture, where the ad hoc network is operated by a
telecommunication/service provider to combine non-valuable individual sensed
data and extract from them effective feedbacks about the situation of the road
in a geographical area. In operated VSNs, providers tend to reduce the traffic
load on their network, using the free-frequency communication medium (IEEE
802.11p, for example). To do so, we propose TCDGP (Tree Clustered Data
Gathering Protocol), a cross layer protocol based on hierarchical and
geographical data collection, aggregation and dissemination mechanisms. We
analyze the performances of our solution using a simulation environment and
realistic mobility models. We demonstrate the feasibility of such solution and
show that TCDGP offers the operator precious information without overloading
his network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6285</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6285</id><created>2012-06-26</created><authors><author><keyname>Dutta</keyname><forenames>Ratna</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Collusion resistant self-healing key distribution in mobile wireless
  networks</title><categories>cs.NI</categories><comments>16 pages, 4 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental concern of any secure group communication system is key
management and wireless environments create new challenges. One core
requirement in these emerging networks is self-healing. In systems where users
can be offline and miss updates, self-healing allows a user to recover lost
session keys and get back into the secure communication without putting extra
burden on the group manager. Clearly, self-healing must only be available to
authorized users. This paper fixes the problem of collusion attack in an
existing self-healing key distribution scheme and provides a highly efficient
scheme as compared to the existing works. It is computationally secure, resists
collusion attacks made between newly joined users and revoked users and
achieves forward and backward secrecy. Our security analysis is in an
appropriate security model. Unlike the existing constructions, our scheme does
not forbid revoked users from rejoining in later sessions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6293</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6293</id><created>2012-06-27</created><authors><author><keyname>Przyjaciel-Zablocki</keyname><forenames>Martin</forenames></author><author><keyname>Sch&#xe4;tzle</keyname><forenames>Alexander</forenames></author><author><keyname>Hornung</keyname><forenames>Thomas</forenames></author><author><keyname>Dorner</keyname><forenames>Christopher</forenames></author><author><keyname>Lausen</keyname><forenames>Georg</forenames></author></authors><title>Cascading map-side joins over HBase for scalable join processing</title><categories>cs.DB cs.DC</categories><acm-class>C.2.4; H.2.3; H.2.4; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major challenges in large-scale data processing with MapReduce is
the smart computation of joins. Since Semantic Web datasets published in RDF
have increased rapidly over the last few years, scalable join techniques become
an important issue for SPARQL query processing as well. In this paper, we
introduce the Map-Side Index Nested Loop Join (MAPSIN join) which combines
scalable indexing capabilities of NoSQL storage systems like HBase, that suffer
from an insufficient distributed processing layer, with MapReduce, which in
turn does not provide appropriate storage structures for efficient large-scale
join processing. While retaining the flexibility of commonly used reduce-side
joins, we leverage the effectiveness of map-side joins without any changes to
the underlying framework. We demonstrate the significant benefits of MAPSIN
joins for the processing of SPARQL basic graph patterns on large RDF datasets
by an evaluation with the LUBM and SP2Bench benchmarks. For most queries,
MAPSIN join based query execution outperforms reduce-side join based execution
by an order of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6294</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6294</id><created>2012-06-27</created><authors><author><keyname>Lucas</keyname><forenames>Andrew</forenames></author></authors><title>Exact mean field dynamics for epidemic-like processes on heterogeneous
  networks</title><categories>physics.soc-ph cs.SI</categories><comments>20 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the mean field equations for the SIR epidemic can be exactly
solved for a network with arbitrary degree distribution. Our exact solution
consists of reducing the dynamics to a lone first order differential equation,
which has a solution in terms of an integral over functions dependent on the
degree distribution of the network, and reconstructing all mean field functions
of interest from this integral. Irreversibility of the SIR epidemic is crucial
for the solution. We also find exact solutions to the sexually transmitted
disease SI epidemic on bipartite graphs, to a simplified rumor spreading model,
and to a new model for recommendation spreading, via similar techniques.
Numerical simulations of these processes on scale free networks demonstrate the
qualitative validity of mean field theory in most regimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6295</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6295</id><created>2012-06-24</created><authors><author><keyname>Forejt</keyname><forenames>Vojtech</forenames></author><author><keyname>Kwiatkowska</keyname><forenames>Marta</forenames></author><author><keyname>Parker</keyname><forenames>David</forenames></author></authors><title>Pareto Curves for Probabilistic Model Checking</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-objective probabilistic model checking provides a way to verify
several, possibly conflicting, quantitative properties of a stochastic system.
It has useful applications in controller synthesis and compositional
probabilistic verification. However, existing methods are based on linear
programming, which limits the scale of systems that can be analysed and makes
verification of time-bounded properties very difficult. We present a novel
approach that addresses both of these shortcomings, based on the generation of
successive approximations of the Pareto curve for a multi-objective model
checking problem. We illustrate dramatic improvements in efficiency on a large
set of benchmarks and show how the ability to visualise Pareto curves
significantly enhances the quality of results obtained from current
probabilistic verification tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6302</identifier>
 <datestamp>2014-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6302</id><created>2012-06-27</created><updated>2014-06-09</updated><authors><author><keyname>Shafie</keyname><forenames>Ahmed El</forenames></author><author><keyname>Khattab</keyname><forenames>Tamer</forenames></author><author><keyname>El-Keyi</keyname><forenames>Amr</forenames></author><author><keyname>Nafie</keyname><forenames>Mohamed</forenames></author></authors><title>Maximum Secondary Stable Throughput of a Cooperative Secondary
  Transmitter-Receiver Pair: Protocol Design and Stability Analysis</title><categories>cs.IT cs.NI math.IT</categories><comments>Journal: Mobile Communications and Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the impact of cooperation between a secondary
transmitter-receiver pair and a primary transmitter (PT) on the maximum stable
throughput of the primary-secondary network. Each transmitter, primary or
secondary, has a buffer for storing its own traffic. In addition to its own
buffer, the secondary transmitter (ST) has a buffer for storing a fraction of
the undelivered primary packets due to channel impairments. Moreover, the
secondary destination has a relaying queue for storing a fraction of the
undelivered primary packets. In the proposed cooperative system, the ST and the
secondary destination increase the spectrum availability for the secondary
packets by relaying the unsuccessfully transmitted packets of the PT. We
consider two multiple access strategies to be used by the ST and the secondary
destination to utilize the silence sessions of the PT. Numerical results
demonstrate the gains of the proposed cooperative system over the
non-cooperation case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6318</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6318</id><created>2012-06-27</created><authors><author><keyname>Braun</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Pokutta</keyname><forenames>Sebastian</forenames></author></authors><title>An algebraic approach to symmetric extended formulations</title><categories>cs.CC math.CO</categories><comments>21 pages, presented at ISCO 2012</comments><msc-class>52B15, 52B05, 20B30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extended formulations are an important tool to obtain small (even compact)
formulations of polytopes by representing them as projections of higher
dimensional ones. It is an important question whether a polytope admits a small
extended formulation, i.e., one involving only a polynomial number of
inequalities in its dimension. For the case of symmetric extended formulations
(i.e., preserving the symmetries of the polytope) Yannakakis established a
powerful technique to derive lower bounds and rule out small formulations. We
rephrase the technique of Yannakakis in a group-theoretic framework. This
provides a different perspective on symmetric extensions and considerably
simplifies several lower bound constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6322</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6322</id><created>2012-06-27</created><authors><author><keyname>Sen</keyname><forenames>Soumya</forenames></author><author><keyname>Dutta</keyname><forenames>Anjan</forenames></author><author><keyname>Cortesi</keyname><forenames>Agostino</forenames></author><author><keyname>Chaki</keyname><forenames>Nabendu</forenames></author></authors><title>A New Scale for Attribute Dependency in Large Database Systems</title><categories>cs.IR cs.DB</categories><comments>12 pages - paper accepted for presentation and publication in CISIM
  2012 International Confrence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large, data centric applications are characterized by its different
attributes. In modern day, a huge majority of the large data centric
applications are based on relational model. The databases are collection of
tables and every table consists of numbers of attributes. The data is accessed
typically through SQL queries. The queries that are being executed could be
analyzed for different types of optimizations. Analysis based on different
attributes used in a set of query would guide the database administrators to
enhance the speed of query execution. A better model in this context would help
in predicting the nature of upcoming query set. An effective prediction model
would guide in different applications of database, data warehouse, data mining
etc. In this paper, a numeric scale has been proposed to enumerate the strength
of associations between independent data attributes. The proposed scale is
built based on some probabilistic analysis of the usage of the attributes in
different queries. Thus this methodology aims to predict future usage of
attributes based on the current usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6323</identifier>
 <datestamp>2015-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6323</id><created>2012-06-27</created><updated>2014-08-03</updated><authors><author><keyname>Saha</keyname><forenames>Debashis</forenames></author><author><keyname>Nandan</keyname><forenames>Sanket</forenames></author><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author></authors><title>Local implementations of non-local quantum gates in linear entangled
  channel</title><categories>quant-ph cs.IT math.IT</categories><comments>6 pages, 4 figures and 7 tables</comments><journal-ref>JQIS 4 (02), 97 (2014)</journal-ref><doi>10.4236/jqis.2014.42010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we demonstrate n-party controlled unitary gate implementations
locally on arbitrary remote state through linear entangled channel where
control parties share entanglement with the adjacent control parties and only
one of them shares entanglement with the target party. In such a network, we
describe the protocol of simultaneous implementation of controlled-Hermitian
gate starting from three party scenario. We also explicate the implementation
of three party controlled-Unitary gate, a generalized form of To?oli gate and
subsequently generalize the protocol for n-party using minimal cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6345</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6345</id><created>2012-06-27</created><authors><author><keyname>Aparicio</keyname><forenames>Ainhoa</forenames></author><author><keyname>Weil</keyname><forenames>Jacques-Arthur</forenames></author></authors><title>A Reduction Method for Higher Order Variational Equations of Hamiltonian
  Systems</title><categories>math.DS cs.SC math.CA</categories><comments>15 pages</comments><msc-class>34M03, 34M15, 34M25, 34Mxx, 20Gxx, 17B45, 17B80, 34A05, 34A26, 34A99</msc-class><journal-ref>In &quot;Symmetries and Related Topics in Differential and Difference
  Equations&quot;, Contemporary Mathematics 549 (Eds: David Blazquez-Sanz, Juan J.
  Morales-Ruiz and Jesus Rodriguez Lombardero), AMS 2011</journal-ref><doi>10.1090/conm/549</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbf{k}$ be a differential field and let $[A]\,:\,Y'=A\,Y$ be a
linear differential system where $A\in\mathrm{Mat}(n\,,\,\mathbf{k})$. We say
that $A$ is in a reduced form if $A\in\mathfrak{g}(\bar{\mathbf{k}})$ where
$\mathfrak{g}$ is the Lie algebra of $[A]$ and $\bar{\mathbf{k}}$ denotes the
algebraic closure of $\mathbf{k}$. We owe the existence of such reduced forms
to a result due to Kolchin and Kovacic \cite{Ko71a}. This paper is devoted to
the study of reduced forms, of (higher order) variational equations along a
particular solution of a complex analytical hamiltonian system $X$. Using a
previous result \cite{ApWea}, we will assume that the first order variational
equation has an abelian Lie algebra so that, at first order, there are no
Galoisian obstructions to Liouville integrability. We give a strategy to
(partially) reduce the variational equations at order $m+1$ if the variational
equations at order $m$ are already in a reduced form and their Lie algebra is
abelian. Our procedure stops when we meet obstructions to the meromorphic
integrability of $X$. We make strong use both of the lower block triangular
structure of the variational equations and of the notion of associated Lie
algebra of a linear differential system (based on the works of Wei and Norman
in \cite{WeNo63a}). Obstructions to integrability appear when at some step we
obtain a non-trivial commutator between a diagonal element and a nilpotent
(subdiagonal) element of the associated Lie algebra. We use our method coupled
with a reasoning on polylogarithms to give a new and systematic proof of the
non-integrability of the H\'enon-Heiles system. We conjecture that our method
is not only a partial reduction procedure but a complete reduction algorithm.
In the context of complex Hamiltonian systems, this would mean that our method
would be an effective version of the Morales-Ramis-Sim\'o theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6347</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6347</id><created>2012-06-27</created><authors><author><keyname>Scheider</keyname><forenames>Simon</forenames></author><author><keyname>Janowicz</keyname><forenames>Krzysztof</forenames></author><author><keyname>Adams</keyname><forenames>Benjamin</forenames></author></authors><title>The observational roots of reference of the semantic web</title><categories>cs.AI cs.DL</categories><comments>4 pages</comments><report-no>DPA-12221</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shared reference is an essential aspect of meaning. It is also indispensable
for the semantic web, since it enables to weave the global graph, i.e., it
allows different users to contribute to an identical referent. For example, an
essential kind of referent is a geographic place, to which users may contribute
observations. We argue for a human-centric, operational approach towards
reference, based on respective human competences. These competences encompass
perceptual, cognitive as well as technical ones, and together they allow humans
to inter-subjectively refer to a phenomenon in their environment. The
technology stack of the semantic web should be extended by such operations.
This would allow establishing new kinds of observation-based reference systems
that help constrain and integrate the semantic web bottom-up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6352</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6352</id><created>2012-06-27</created><updated>2012-07-30</updated><authors><author><keyname>Accomazzi</keyname><forenames>Alberto</forenames><affiliation>Smithsonian Astrophysical Observatory, Cambridge, MA, USA</affiliation></author><author><keyname>Henneken</keyname><forenames>Edwin</forenames><affiliation>Smithsonian Astrophysical Observatory, Cambridge, MA, USA</affiliation></author><author><keyname>Erdmann</keyname><forenames>Christopher</forenames><affiliation>Smithsonian Astrophysical Observatory, Cambridge, MA, USA</affiliation></author><author><keyname>Rots</keyname><forenames>Arnold</forenames><affiliation>Smithsonian Astrophysical Observatory, Cambridge, MA, USA</affiliation></author></authors><title>Telescope Bibliographies: an Essential Component of Archival Data
  Management and Operations</title><categories>astro-ph.IM cs.DL</categories><comments>10 pages, 3 figures, to appear in SPIE Astronomical Telescopes and
  Instrumentation, SPIE Conference Series 8448</comments><doi>10.1117/12.927262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Assessing the impact of astronomical facilities rests upon an evaluation of
the scientific discoveries which their data have enabled. Telescope
bibliographies, which link data products with the literature, provide a way to
use bibliometrics as an impact measure for the underlying data. In this paper
we argue that the creation and maintenance of telescope bibliographies should
be considered an integral part of an observatory's operations. We review the
existing tools, services, and workflows which support these curation
activities, giving an estimate of the effort and expertise required to maintain
an archive-based telescope bibliography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6356</identifier>
 <datestamp>2013-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6356</id><created>2012-06-27</created><updated>2013-08-01</updated><authors><author><keyname>Agaskar</keyname><forenames>Ameya</forenames></author><author><keyname>Lu</keyname><forenames>Yue M.</forenames></author></authors><title>A Spectral Graph Uncertainty Principle</title><categories>cs.IT math.IT</categories><comments>40 pages, 8 figures</comments><journal-ref>IEEE Trans. Info. Theory 59 (2013) 4338-4356</journal-ref><doi>10.1109/TIT.2013.2252233</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spectral theory of graphs provides a bridge between classical signal
processing and the nascent field of graph signal processing. In this paper, a
spectral graph analogy to Heisenberg's celebrated uncertainty principle is
developed. Just as the classical result provides a tradeoff between signal
localization in time and frequency, this result provides a fundamental tradeoff
between a signal's localization on a graph and in its spectral domain. Using
the eigenvectors of the graph Laplacian as a surrogate Fourier basis,
quantitative definitions of graph and spectral &quot;spreads&quot; are given, and a
complete characterization of the feasibility region of these two quantities is
developed. In particular, the lower boundary of the region, referred to as the
uncertainty curve, is shown to be achieved by eigenvectors associated with the
smallest eigenvalues of an affine family of matrices. The convexity of the
uncertainty curve allows it to be found to within $\varepsilon$ by a fast
approximation algorithm requiring $O(\varepsilon^{-1/2})$ typically sparse
eigenvalue evaluations. Closed-form expressions for the uncertainty curves for
some special classes of graphs are derived, and an accurate analytical
approximation for the expected uncertainty curve of Erd\H{o}s-R\'enyi random
graphs is developed. These theoretical results are validated by numerical
experiments, which also reveal an intriguing connection between diffusion
processes on graphs and the uncertainty bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6360</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6360</id><created>2012-06-27</created><authors><author><keyname>Miltzow</keyname><forenames>Tillmann</forenames></author></authors><title>Augmenting a Geometric Matching is $NP$-complete</title><categories>cs.CC cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given $2n$ points in the plane, it is well-known that there always exists a
perfect straight-line non-crossing matching. We show that it is $NP$-complete
to decide if a partial matching can be augmented to a perfect one, via a
reduction from 1-in-3-SAT. This result also holds for bichromatic matchings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6361</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6361</id><created>2012-06-27</created><authors><author><keyname>Khoshgnauz</keyname><forenames>Ehsan</forenames></author></authors><title>Learning Markov Network Structure using Brownian Distance Covariance</title><categories>stat.ML cs.LG</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a simple non-parametric method for learning the
structure of undirected graphs from data that drawn from an underlying unknown
distribution. We propose to use Brownian distance covariance to estimate the
conditional independences between the random variables and encodes pairwise
Markov graph. This framework can be applied in high-dimensional setting, where
the number of parameters much be larger than the sample size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6380</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6380</id><created>2012-06-27</created><authors><author><keyname>Ahn</keyname><forenames>Sungjin</forenames><affiliation>UC Irvine</affiliation></author><author><keyname>Korattikara</keyname><forenames>Anoop</forenames><affiliation>UC Irvine</affiliation></author><author><keyname>Welling</keyname><forenames>Max</forenames><affiliation>UC Irvine</affiliation></author></authors><title>Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring</title><categories>cs.LG stat.CO stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the following question: Can we approximately sample
from a Bayesian posterior distribution if we are only allowed to touch a small
mini-batch of data-items for every sample we generate?. An algorithm based on
the Langevin equation with stochastic gradients (SGLD) was previously proposed
to solve this, but its mixing rate was slow. By leveraging the Bayesian Central
Limit Theorem, we extend the SGLD algorithm so that at high mixing rates it
will sample from a normal approximation of the posterior, while for slow mixing
rates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a
bonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic
gradients) and as such an efficient optimizer during burn-in.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6381</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6381</id><created>2012-06-27</created><updated>2012-07-09</updated><authors><author><keyname>Alamgir</keyname><forenames>Morteza</forenames><affiliation>Max Planck Institute for Intelligent Systems</affiliation></author><author><keyname>von Luxburg</keyname><forenames>Ulrike</forenames><affiliation>Max Planck Institute for Intelligent Systems and University of Hamburg</affiliation></author></authors><title>Shortest path distance in random k-nearest neighbor graphs</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a weighted or unweighted k-nearest neighbor graph that has been
built on n data points drawn randomly according to some density p on R^d. We
study the convergence of the shortest path distance in such graphs as the
sample size tends to infinity. We prove that for unweighted kNN graphs, this
distance converges to an unpleasant distance function on the underlying space
whose properties are detrimental to machine learning. We also study the
behavior of the shortest path distance in weighted kNN graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6382</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6382</id><created>2012-06-27</created><authors><author><keyname>Janzamin</keyname><forenames>Majid</forenames><affiliation>UC Irvine</affiliation></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames><affiliation>UC Irvine</affiliation></author></authors><title>High-Dimensional Covariance Decomposition into Sparse Markov and
  Independence Domains</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel framework incorporating a combination of
sparse models in different domains. We posit the observed data as generated
from a linear combination of a sparse Gaussian Markov model (with a sparse
precision matrix) and a sparse Gaussian independence model (with a sparse
covariance matrix). We provide efficient methods for decomposition of the data
into two domains, \viz Markov and independence domains. We characterize a set
of sufficient conditions for identifiability and model consistency. Our
decomposition method is based on a simple modification of the popular
$\ell_1$-penalized maximum-likelihood estimator ($\ell_1$-MLE). We establish
that our estimator is consistent in both the domains, i.e., it successfully
recovers the supports of both Markov and independence models, when the number
of samples $n$ scales as $n = \Omega(d^2 \log p)$, where $p$ is the number of
variables and $d$ is the maximum node degree in the Markov model. Our
conditions for recovery are comparable to those of $\ell_1$-MLE for consistent
estimation of a sparse Markov model, and thus, we guarantee successful
high-dimensional estimation of a richer class of models under comparable
conditions. Our experiments validate these results and also demonstrate that
our models have better inference accuracy under simple algorithms such as loopy
belief propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6383</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6383</id><created>2012-06-27</created><authors><author><keyname>Danyluk</keyname><forenames>Andrea</forenames><affiliation>Williams College</affiliation></author><author><keyname>Arnosti</keyname><forenames>Nicholas</forenames><affiliation>Stanford University</affiliation></author></authors><title>Feature Selection via Probabilistic Outputs</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates two feature-scoring criteria that make use of
estimated class probabilities: one method proposed by \citet{shen} and a
complementary approach proposed below. We develop a theoretical framework to
analyze each criterion and show that both estimate the spread (across all
values of a given feature) of the probability that an example belongs to the
positive class. Based on our analysis, we predict when each scoring technique
will be advantageous over the other and give empirical results validating our
predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6384</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6384</id><created>2012-06-27</created><authors><author><keyname>Avron</keyname><forenames>Haim</forenames><affiliation>IBM T.J. Watson Research Center</affiliation></author><author><keyname>Kale</keyname><forenames>Satyen</forenames><affiliation>IBM T.J. Watson Research Center</affiliation></author><author><keyname>Kasiviswanathan</keyname><forenames>Shiva</forenames><affiliation>IBM T.J. Watson Research Center</affiliation></author><author><keyname>Sindhwani</keyname><forenames>Vikas</forenames><affiliation>IBM T.J. Watson Research Center</affiliation></author></authors><title>Efficient and Practical Stochastic Subgradient Descent for Nuclear Norm
  Regularization</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe novel subgradient methods for a broad class of matrix
optimization problems involving nuclear norm regularization. Unlike existing
approaches, our method executes very cheap iterations by combining low-rank
stochastic subgradients with efficient incremental SVD updates, made possible
by highly optimized and parallelizable dense linear algebra operations on small
matrices. Our practical algorithms always maintain a low-rank factorization of
iterates that can be conveniently held in memory and efficiently multiplied to
generate predictions in matrix completion settings. Empirical comparisons
confirm that our approach is highly competitive with several recently proposed
state-of-the-art solvers for such problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6385</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6385</id><created>2012-06-27</created><authors><author><keyname>Precup</keyname><forenames>Doina</forenames><affiliation>McGill University</affiliation></author><author><keyname>Bachman</keyname><forenames>Philip</forenames><affiliation>McGill University</affiliation></author></authors><title>Improved Estimation in Time Varying Models</title><categories>cs.LG stat.ME stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Locally adapted parameterizations of a model (such as locally weighted
regression) are expressive but often suffer from high variance. We describe an
approach for reducing the variance, based on the idea of estimating
simultaneously a transformed space for the model, as well as locally adapted
parameterizations in this new space. We present a new problem formulation that
captures this idea and illustrate it in the important context of time varying
models. We develop an algorithm for learning a set of bases for approximating a
time varying sparse network; each learned basis constitutes an archetypal
sparse network structure. We also provide an extension for learning task-driven
bases. We present empirical results on synthetic data sets, as well as on a BCI
EEG classification task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6386</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6386</id><created>2012-06-27</created><authors><author><keyname>Bachrach</keyname><forenames>Yoram</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Graepel</keyname><forenames>Thore</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Minka</keyname><forenames>Tom</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Guiver</keyname><forenames>John</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>How To Grade a Test Without Knowing the Answers --- A Bayesian Graphical
  Model for Adaptive Crowdsourcing and Aptitude Testing</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new probabilistic graphical model that jointly models the
difficulties of questions, the abilities of participants and the correct
answers to questions in aptitude testing and crowdsourcing settings. We devise
an active learning/adaptive testing scheme based on a greedy minimization of
expected model entropy, which allows a more efficient resource allocation by
dynamically choosing the next question to be asked based on the previous
responses. We present experimental results that confirm the ability of our
model to infer the required parameters and demonstrate that the adaptive
testing scheme requires fewer questions to obtain the same accuracy as a static
test scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6387</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6387</id><created>2012-06-27</created><authors><author><keyname>Benbouzid</keyname><forenames>Djalel</forenames><affiliation>University of Paris-Sud / CNRS / IN2P3</affiliation></author><author><keyname>Busa-Fekete</keyname><forenames>Robert</forenames><affiliation>LAL, CNRS</affiliation></author><author><keyname>Kegl</keyname><forenames>Balazs</forenames><affiliation>CNRS / University of Paris-Sud</affiliation></author></authors><title>Fast classification using sparse decision DAGs</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an algorithm that builds sparse decision DAGs
(directed acyclic graphs) from a list of base classifiers provided by an
external learning method such as AdaBoost. The basic idea is to cast the DAG
design task as a Markov decision process. Each instance can decide to use or to
skip each base classifier, based on the current state of the classifier being
built. The result is a sparse decision DAG where the base classifiers are
selected in a data-dependent way. The method has a single hyperparameter with a
clear semantics of controlling the accuracy/speed trade-off. The algorithm is
competitive with state-of-the-art cascade detectors on three object-detection
benchmarks, and it clearly outperforms them when there is a small number of
base classifiers. Unlike cascades, it is also readily applicable for
multi-class classification. Using the multi-class setup, we show on a benchmark
web page ranking data set that we can significantly improve the decision speed
without harming the performance of the ranker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6388</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6388</id><created>2012-06-27</created><authors><author><keyname>Biessmann</keyname><forenames>Felix</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Papaioannou</keyname><forenames>Jens-Michalis</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Braun</keyname><forenames>Mikio</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Harth</keyname><forenames>Andreas</forenames><affiliation>Karlsruhe Institue of Technology</affiliation></author></authors><title>Canonical Trends: Detecting Trend Setters in Web Data</title><categories>cs.LG cs.SI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much information available on the web is copied, reused or rephrased. The
phenomenon that multiple web sources pick up certain information is often
called trend. A central problem in the context of web data mining is to detect
those web sources that are first to publish information which will give rise to
a trend. We present a simple and efficient method for finding trends dominating
a pool of web sources and identifying those web sources that publish the
information relevant to a trend before others. We validate our approach on real
data collected from influential technology news feeds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6389</identifier>
 <datestamp>2013-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6389</id><created>2012-06-27</created><updated>2013-03-25</updated><authors><author><keyname>Biggio</keyname><forenames>Battista</forenames><affiliation>University of Cagliari</affiliation></author><author><keyname>Nelson</keyname><forenames>Blaine</forenames><affiliation>University of Tuebingen</affiliation></author><author><keyname>Laskov</keyname><forenames>Pavel</forenames><affiliation>University of Tuebingen</affiliation></author></authors><title>Poisoning Attacks against Support Vector Machines</title><categories>cs.LG cs.CR stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a family of poisoning attacks against Support Vector Machines
(SVM). Such attacks inject specially crafted training data that increases the
SVM's test error. Central to the motivation for these attacks is the fact that
most learning algorithms assume that their training data comes from a natural
or well-behaved distribution. However, this assumption does not generally hold
in security-sensitive settings. As we demonstrate, an intelligent adversary
can, to some extent, predict the change of the SVM's decision function due to
malicious input and use this ability to construct malicious data. The proposed
attack uses a gradient ascent strategy in which the gradient is computed based
on properties of the SVM's optimal solution. This method can be kernelized and
enables the attack to be constructed in the input space even for non-linear
kernels. We experimentally demonstrate that our gradient ascent procedure
reliably identifies good local maxima of the non-convex validation error
surface, which significantly increases the classifier's test error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6390</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6390</id><created>2012-06-27</created><authors><author><keyname>Borboudakis</keyname><forenames>Giorgos</forenames><affiliation>ICS FORTH</affiliation></author><author><keyname>Tsamardinos</keyname><forenames>Ioannis</forenames><affiliation>University of Crete</affiliation></author></authors><title>Incorporating Causal Prior Knowledge as Path-Constraints in Bayesian
  Networks and Maximal Ancestral Graphs</title><categories>cs.AI cs.CE cs.LG</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the incorporation of causal knowledge about the presence or
absence of (possibly indirect) causal relations into a causal model. Such
causal relations correspond to directed paths in a causal model. This type of
knowledge naturally arises from experimental data, among others. Specifically,
we consider the formalisms of Causal Bayesian Networks and Maximal Ancestral
Graphs and their Markov equivalence classes: Partially Directed Acyclic Graphs
and Partially Oriented Ancestral Graphs. We introduce sound and complete
procedures which are able to incorporate causal prior knowledge in such models.
In simulated experiments, we show that often considering even a few causal
facts leads to a significant number of new inferences. In a case study, we also
show how to use real experimental data to infer causal knowledge and
incorporate it into a real biological causal network. The code is available at
mensxmachina.org.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6391</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6391</id><created>2012-06-27</created><authors><author><keyname>Boukouvalas</keyname><forenames>Alexis</forenames><affiliation>Aston University</affiliation></author><author><keyname>Barillec</keyname><forenames>Remi</forenames><affiliation>Aston University</affiliation></author><author><keyname>Cornford</keyname><forenames>Dan</forenames><affiliation>Aston University</affiliation></author></authors><title>Gaussian Process Quantile Regression using Expectation Propagation</title><categories>stat.ME cs.LG stat.AP</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Direct quantile regression involves estimating a given quantile of a response
variable as a function of input variables. We present a new framework for
direct quantile regression where a Gaussian process model is learned,
minimising the expected tilted loss function. The integration required in
learning is not analytically tractable so to speed up the learning we employ
the Expectation Propagation algorithm. We describe how this work relates to
other quantile regression methods and apply the method on both synthetic and
real data sets. The method is shown to be competitive with state of the art
methods whilst allowing for the leverage of the full Gaussian process
probabilistic framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6392</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6392</id><created>2012-06-27</created><authors><author><keyname>Boulanger-Lewandowski</keyname><forenames>Nicolas</forenames><affiliation>Universite de Montreal</affiliation></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames><affiliation>Universite de Montreal</affiliation></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames><affiliation>Universite de Montreal</affiliation></author></authors><title>Modeling Temporal Dependencies in High-Dimensional Sequences:
  Application to Polyphonic Music Generation and Transcription</title><categories>cs.LG cs.SD stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of modeling symbolic sequences of polyphonic music
in a completely general piano-roll representation. We introduce a probabilistic
model based on distribution estimators conditioned on a recurrent neural
network that is able to discover temporal dependencies in high-dimensional
sequences. Our approach outperforms many traditional models of polyphonic music
on a variety of realistic datasets. We show how our musical language model can
serve as a symbolic prior to improve the accuracy of polyphonic transcription.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6393</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6393</id><created>2012-06-27</created><authors><author><keyname>Balle</keyname><forenames>Borja</forenames><affiliation>UPC</affiliation></author><author><keyname>Quattoni</keyname><forenames>Ariadna</forenames><affiliation>UPC</affiliation></author><author><keyname>Carreras</keyname><forenames>Xavier</forenames><affiliation>UPC</affiliation></author></authors><title>Local Loss Optimization in Operator Models: A New Insight into Spectral
  Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper re-visits the spectral method for learning latent variable models
defined in terms of observable operators. We give a new perspective on the
method, showing that operators can be recovered by minimizing a loss defined on
a finite subset of the domain. A non-convex optimization similar to the
spectral method is derived. We also propose a regularized convex relaxation of
this optimization. We show that in practice the availabilty of a continuous
regularization parameter (in contrast with the discrete number of states in the
original method) allows a better trade-off between accuracy and model
complexity. We also prove that in general, a randomized strategy for choosing
the local loss will succeed with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6394</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6394</id><created>2012-06-27</created><authors><author><keyname>Sarkar</keyname><forenames>Purnamrita</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Chakrabarti</keyname><forenames>Deepayan</forenames><affiliation>Facebook</affiliation></author><author><keyname>Jordan</keyname><forenames>Michael</forenames><affiliation>UC Berkeley</affiliation></author></authors><title>Nonparametric Link Prediction in Dynamic Networks</title><categories>cs.LG cs.SI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a non-parametric link prediction algorithm for a sequence of graph
snapshots over time. The model predicts links based on the features of its
endpoints, as well as those of the local neighborhood around the endpoints.
This allows for different types of neighborhoods in a graph, each with its own
dynamics (e.g, growing or shrinking communities). We prove the consistency of
our estimator, and give a fast implementation based on locality-sensitive
hashing. Experiments with simulated as well as five real-world dynamic graphs
show that we outperform the state of the art, especially when sharp
fluctuations or non-linearities are present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6395</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6395</id><created>2012-06-27</created><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames><affiliation>UCSD</affiliation></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>Convergence Rates for Differentially Private Statistical Estimation</title><categories>cs.LG cs.CR stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a cryptographically-motivated definition of privacy
which has gained significant attention over the past few years. Differentially
private solutions enforce privacy by adding random noise to a function computed
over the data, and the challenge in designing such algorithms is to control the
added noise in order to optimize the privacy-accuracy-sample size tradeoff.
  This work studies differentially-private statistical estimation, and shows
upper and lower bounds on the convergence rates of differentially private
approximations to statistical estimators. Our results reveal a formal
connection between differential privacy and the notion of Gross Error
Sensitivity (GES) in robust statistics, by showing that the convergence rate of
any differentially private approximation to an estimator that is accurate over
a large class of distributions has to grow with the GES of the estimator. We
then provide an upper bound on the convergence rate of a differentially private
approximation to an estimator with bounded range and bounded GES. We show that
the bounded range condition is necessary if we wish to ensure a strict form of
differential privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6396</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6396</id><created>2012-06-27</created><authors><author><keyname>Chen</keyname><forenames>Bo</forenames><affiliation>Caltech</affiliation></author><author><keyname>Castro</keyname><forenames>Rui</forenames><affiliation>Eindhoven University of Technology</affiliation></author><author><keyname>Krause</keyname><forenames>Andreas</forenames><affiliation>ETH Zurich</affiliation></author></authors><title>Joint Optimization and Variable Selection of High-dimensional Gaussian
  Processes</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximizing high-dimensional, non-convex functions through noisy observations
is a notoriously hard problem, but one that arises in many applications. In
this paper, we tackle this challenge by modeling the unknown function as a
sample from a high-dimensional Gaussian process (GP) distribution. Assuming
that the unknown function only depends on few relevant variables, we show that
it is possible to perform joint variable selection and GP optimization. We
provide strong performance guarantees for our algorithm, bounding the sample
complexity of variable selection, and as well as providing cumulative regret
bounds. We further provide empirical evidence on the effectiveness of our
algorithm on several benchmark optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6397</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6397</id><created>2012-06-27</created><authors><author><keyname>Chen</keyname><forenames>Minhua</forenames><affiliation>Duke University</affiliation></author><author><keyname>Carson</keyname><forenames>William</forenames><affiliation>PA Consulting Group, Cambridge Technology Centre</affiliation></author><author><keyname>Rodrigues</keyname><forenames>Miguel</forenames><affiliation>University College London</affiliation></author><author><keyname>Calderbank</keyname><forenames>Robert</forenames><affiliation>Duke University</affiliation></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames><affiliation>Duke University</affiliation></author></authors><title>Communications Inspired Linear Discriminant Analysis</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of supervised linear dimensionality reduction, taking an
information-theoretic viewpoint. The linear projection matrix is designed by
maximizing the mutual information between the projected signal and the class
label (based on a Shannon entropy measure). By harnessing a recent theoretical
result on the gradient of mutual information, the above optimization problem
can be solved directly using gradient descent, without requiring simplification
of the objective function. Theoretical analysis and empirical comparison are
made between the proposed method and two closely related methods (Linear
Discriminant Analysis and Information Discriminant Analysis), and comparisons
are also made with a method in which Renyi entropy is used to define the mutual
information (in this case the gradient may be computed simply, under a special
parameter setting). Relative to these alternative approaches, the proposed
method achieves promising results on real datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6398</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6398</id><created>2012-06-27</created><updated>2012-09-03</updated><authors><author><keyname>Da Silva</keyname><forenames>Bruno</forenames><affiliation>UMass Amherst</affiliation></author><author><keyname>Konidaris</keyname><forenames>George</forenames><affiliation>MIT</affiliation></author><author><keyname>Barto</keyname><forenames>Andrew</forenames><affiliation>UMass Amherst</affiliation></author></authors><title>Learning Parameterized Skills</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a method for constructing skills capable of solving tasks drawn
from a distribution of parameterized reinforcement learning problems. The
method draws example tasks from a distribution of interest and uses the
corresponding learned policies to estimate the topology of the
lower-dimensional piecewise-smooth manifold on which the skill policies lie.
This manifold models how policy parameters change as task parameters vary. The
method identifies the number of charts that compose the manifold and then
applies non-linear regression in each chart to construct a parameterized skill
by predicting policy parameters from task parameters. We evaluate our method on
an underactuated simulated robotic arm tasked with learning to accurately throw
darts at a parameterized target location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6399</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6399</id><created>2012-06-27</created><authors><author><keyname>Davis</keyname><forenames>Jesse</forenames><affiliation>KU Leuven</affiliation></author><author><keyname>Costa</keyname><forenames>Vitor Santos</forenames><affiliation>University of Porto</affiliation></author><author><keyname>Peissig</keyname><forenames>Peggy</forenames><affiliation>Marshfield Clinic</affiliation></author><author><keyname>Caldwell</keyname><forenames>Michael</forenames><affiliation>Marshfield Clinic</affiliation></author><author><keyname>Berg</keyname><forenames>Elizabeth</forenames><affiliation>University of Wisconsin - Madison</affiliation></author><author><keyname>Page</keyname><forenames>David</forenames><affiliation>University of Wisconsin - Madison</affiliation></author></authors><title>Demand-Driven Clustering in Relational Domains for Predicting Adverse
  Drug Events</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning from electronic medical records (EMR) is challenging due to their
relational nature and the uncertain dependence between a patient's past and
future health status. Statistical relational learning is a natural fit for
analyzing EMRs but is less adept at handling their inherent latent structure,
such as connections between related medications or diseases. One way to capture
the latent structure is via a relational clustering of objects. We propose a
novel approach that, instead of pre-clustering the objects, performs a
demand-driven clustering during learning. We evaluate our algorithm on three
real-world tasks where the goal is to use EMRs to predict whether a patient
will have an adverse reaction to a medication. We find that our approach is
more accurate than performing no clustering, pre-clustering, and using
expert-constructed medical heterarchies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6400</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6400</id><created>2012-06-27</created><authors><author><keyname>Arora</keyname><forenames>Raman</forenames><affiliation>TTIC</affiliation></author><author><keyname>Dekel</keyname><forenames>Ofer</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames><affiliation>University of Texas</affiliation></author></authors><title>Online Bandit Learning against an Adaptive Adversary: from Regret to
  Policy Regret</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online learning algorithms are designed to learn even when their input is
generated by an adversary. The widely-accepted formal definition of an online
algorithm's ability to learn is the game-theoretic notion of regret. We argue
that the standard definition of regret becomes inadequate if the adversary is
allowed to adapt to the online algorithm's actions. We define the alternative
notion of policy regret, which attempts to provide a more meaningful way to
measure an online algorithm's performance against adaptive adversaries.
Focusing on the online bandit setting, we show that no bandit algorithm can
guarantee a sublinear policy regret against an adaptive adversary with
unbounded memory. On the other hand, if the adversary's memory is bounded, we
present a general technique that converts any bandit algorithm with a sublinear
regret bound into an algorithm with a sublinear policy regret bound. We extend
this result to other variants of regret, such as switching regret, internal
regret, and swap regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6401</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6401</id><created>2012-06-27</created><authors><author><keyname>Dembczynski</keyname><forenames>Krzysztof</forenames><affiliation>Poznan University of Technology</affiliation></author><author><keyname>Kotlowski</keyname><forenames>Wojciech</forenames><affiliation>Poznan University of Technology</affiliation></author><author><keyname>Huellermeier</keyname><forenames>Eyke</forenames><affiliation>Marburg University</affiliation></author></authors><title>Consistent Multilabel Ranking through Univariate Losses</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of rank loss minimization in the setting of
multilabel classification, which is usually tackled by means of convex
surrogate losses defined on pairs of labels. Very recently, this approach was
put into question by a negative result showing that commonly used pairwise
surrogate losses, such as exponential and logistic losses, are inconsistent. In
this paper, we show a positive result which is arguably surprising in light of
the previous one: the simpler univariate variants of exponential and logistic
surrogates (i.e., defined on single labels) are consistent for rank loss
minimization. Instead of directly proving convergence, we give a much stronger
result by deriving regret bounds and convergence rates. The proposed losses
suggest efficient and scalable algorithms, which are tested experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6402</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6402</id><created>2012-06-27</created><authors><author><keyname>Desautels</keyname><forenames>Thomas</forenames><affiliation>California Inst. of Technology</affiliation></author><author><keyname>Krause</keyname><forenames>Andreas</forenames><affiliation>ETH Zurich</affiliation></author><author><keyname>Burdick</keyname><forenames>Joel</forenames><affiliation>California Inst. of Technology</affiliation></author></authors><title>Parallelizing Exploration-Exploitation Tradeoffs with Gaussian Process
  Bandit Optimization</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Can one parallelize complex exploration exploitation tradeoffs? As an
example, consider the problem of optimal high-throughput experimental design,
where we wish to sequentially design batches of experiments in order to
simultaneously learn a surrogate function mapping stimulus to response and
identify the maximum of the function. We formalize the task as a multi-armed
bandit problem, where the unknown payoff function is sampled from a Gaussian
process (GP), and instead of a single arm, in each round we pull a batch of
several arms in parallel. We develop GP-BUCB, a principled algorithm for
choosing batches, based on the GP-UCB algorithm for sequential GP optimization.
We prove a surprising result; as compared to the sequential approach, the
cumulative regret of the parallel algorithm only increases by a constant factor
independent of the batch size B. Our results provide rigorous theoretical
support for exploiting parallelism in Bayesian global optimization. We
demonstrate the effectiveness of our approach on two real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6403</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6403</id><created>2012-06-27</created><authors><author><keyname>Dhillon</keyname><forenames>Paramveer</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Rodu</keyname><forenames>Jordan</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Foster</keyname><forenames>Dean</forenames><affiliation>University of Pennsylvania</affiliation></author><author><keyname>Ungar</keyname><forenames>Lyle</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Two Step CCA: A new spectral method for estimating vector models of
  words</title><categories>cs.CL cs.LG</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlabeled data is often used to learn representations which can be used to
supplement baseline features in a supervised learner. For example, for text
applications where the words lie in a very high dimensional space (the size of
the vocabulary), one can learn a low rank &quot;dictionary&quot; by an
eigen-decomposition of the word co-occurrence matrix (e.g. using PCA or CCA).
In this paper, we present a new spectral method based on CCA to learn an
eigenword dictionary. Our improved procedure computes two set of CCAs, the
first one between the left and right contexts of the given word and the second
one between the projections resulting from this CCA and the word itself. We
prove theoretically that this two-step procedure has lower sample complexity
than the simple single step procedure and also illustrate the empirical
efficacy of our approach and the richness of representations learned by our Two
Step CCA (TSCCA) procedure on the tasks of POS tagging and sentiment
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6404</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6404</id><created>2012-06-27</created><authors><author><keyname>Di Castro</keyname><forenames>Dotan</forenames><affiliation>Technion</affiliation></author><author><keyname>Tamar</keyname><forenames>Aviv</forenames><affiliation>Technion</affiliation></author><author><keyname>Mannor</keyname><forenames>Shie</forenames><affiliation>Technion</affiliation></author></authors><title>Policy Gradients with Variance Related Risk Criteria</title><categories>cs.LG cs.CY math.OC stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Managing risk in dynamic decision problems is of cardinal importance in many
fields such as finance and process control. The most common approach to
defining risk is through various variance related criteria such as the Sharpe
Ratio or the standard deviation adjusted reward. It is known that optimizing
many of the variance related risk criteria is NP-hard. In this paper we devise
a framework for local policy gradient style algorithms for reinforcement
learning for variance related criteria. Our starting point is a new formula for
the variance of the cost-to-go in episodic tasks. Using this formula we develop
policy gradient algorithms for criteria that involve both the expected cost and
the variance of the cost. We prove the convergence of these algorithms to local
minima and demonstrate their applicability in a portfolio planning problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6405</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6405</id><created>2012-06-27</created><authors><author><keyname>Fox</keyname><forenames>Roy</forenames><affiliation>Hebrew University</affiliation></author><author><keyname>Tishby</keyname><forenames>Naftali</forenames><affiliation>Hebrew University</affiliation></author></authors><title>Bounded Planning in Passive POMDPs</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Passive POMDPs actions do not affect the world state, but still incur
costs. When the agent is bounded by information-processing constraints, it can
only keep an approximation of the belief. We present a variational principle
for the problem of maintaining the information which is most useful for
minimizing the cost, and introduce an efficient and simple algorithm for
finding an optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6406</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6406</id><created>2012-06-27</created><authors><author><keyname>Garnett</keyname><forenames>Roman</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Krishnamurthy</keyname><forenames>Yamuna</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Xiong</keyname><forenames>Xuehan</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Schneider</keyname><forenames>Jeff</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Mann</keyname><forenames>Richard</forenames><affiliation>Uppsala Universitet</affiliation></author></authors><title>Bayesian Optimal Active Search and Surveying</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two active binary-classification problems with atypical
objectives. In the first, active search, our goal is to actively uncover as
many members of a given class as possible. In the second, active surveying, our
goal is to actively query points to ultimately predict the proportion of a
given class. Numerous real-world problems can be framed in these terms, and in
either case typical model-based concerns such as generalization error are only
of secondary importance.
  We approach these problems via Bayesian decision theory; after choosing
natural utility functions, we derive the optimal policies. We provide three
contributions. In addition to introducing the active surveying problem, we
extend previous work on active search in two ways. First, we prove a novel
theoretical result, that less-myopic approximations to the optimal policy can
outperform more-myopic approximations by any arbitrary degree. We then derive
bounds that for certain models allow us to reduce (in practice dramatically)
the exponential search space required by a na?ve implementation of the optimal
policy, enabling further lookahead while still ensuring that optimal decisions
are always made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6407</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6407</id><created>2012-06-27</created><authors><author><keyname>Goodfellow</keyname><forenames>Ian</forenames><affiliation>Universite de Montreal</affiliation></author><author><keyname>Courville</keyname><forenames>Aaron</forenames><affiliation>Universite de Montreal</affiliation></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames><affiliation>Universite de Montreal</affiliation></author></authors><title>Large-Scale Feature Learning With Spike-and-Slab Sparse Coding</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012). arXiv admin note: substantial text overlap with
  arXiv:1201.3382</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of object recognition with a large number of classes.
In order to overcome the low amount of labeled examples available in this
setting, we introduce a new feature learning and extraction procedure based on
a factor model we call spike-and-slab sparse coding (S3C). Prior work on S3C
has not prioritized the ability to exploit parallel architectures and scale S3C
to the enormous problem sizes needed for object recognition. We present a novel
inference procedure for appropriate for use with GPUs which allows us to
dramatically increase both the training set size and the amount of latent
factors that S3C may be trained with. We demonstrate that this approach
improves upon the supervised learning capabilities of both sparse coding and
the spike-and-slab Restricted Boltzmann Machine (ssRBM) on the CIFAR-10
dataset. We use the CIFAR-100 dataset to demonstrate that our method scales to
large numbers of classes better than previous methods. Finally, we use our
method to win the NIPS 2011 Workshop on Challenges In Learning Hierarchical
Models? Transfer Learning Challenge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6408</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6408</id><created>2012-06-27</created><authors><author><keyname>Gu</keyname><forenames>Haijie</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Lafferty</keyname><forenames>John</forenames><affiliation>University of Chicago</affiliation></author></authors><title>Sequential Nonparametric Regression</title><categories>stat.ME astro-ph.IM cs.LG</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms for nonparametric regression in settings where the data
are obtained sequentially. While traditional estimators select bandwidths that
depend upon the sample size, for sequential data the effective sample size is
dynamically changing. We propose a linear time algorithm that adjusts the
bandwidth for each new data point, and show that the estimator achieves the
optimal minimax rate of convergence. We also propose the use of online expert
mixing algorithms to adapt to unknown smoothness of the regression function. We
provide simulations that confirm the theoretical results, and demonstrate the
effectiveness of the methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6409</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6409</id><created>2012-06-27</created><authors><author><keyname>Scherrer</keyname><forenames>Chad</forenames><affiliation>Pacific Northwest National Lab</affiliation></author><author><keyname>Halappanavar</keyname><forenames>Mahantesh</forenames><affiliation>Pacific Northwest National Lab</affiliation></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames><affiliation>University of Texas</affiliation></author><author><keyname>Haglin</keyname><forenames>David</forenames><affiliation>Pacific Northwest National Lab</affiliation></author></authors><title>Scaling Up Coordinate Descent Algorithms for Large $\ell_1$
  Regularization Problems</title><categories>cs.LG cs.DC stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a generic framework for parallel coordinate descent (CD)
algorithms that includes, as special cases, the original sequential algorithms
Cyclic CD and Stochastic CD, as well as the recent parallel Shotgun algorithm.
We introduce two novel parallel algorithms that are also special
cases---Thread-Greedy CD and Coloring-Based CD---and give performance
measurements for an OpenMP implementation of these.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6410</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6410</id><created>2012-06-27</created><authors><author><keyname>Hazan</keyname><forenames>Tamir</forenames><affiliation>TTIC</affiliation></author><author><keyname>Jaakkola</keyname><forenames>Tommi</forenames><affiliation>MIT</affiliation></author></authors><title>On the Partition Function and Random Maximum A-Posteriori Perturbations</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we relate the partition function to the max-statistics of
random variables. In particular, we provide a novel framework for approximating
and bounding the partition function using MAP inference on randomly perturbed
models. As a result, we can use efficient MAP solvers such as graph-cuts to
evaluate the corresponding partition function. We show that our method excels
in the typical &quot;high signal - high coupling&quot; regime that results in ragged
energy landscapes difficult for alternative approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6411</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6411</id><created>2012-06-27</created><authors><author><keyname>He</keyname><forenames>Junfeng</forenames><affiliation>Columbia University</affiliation></author><author><keyname>Kumar</keyname><forenames>Sanjiv</forenames><affiliation>Google Research</affiliation></author><author><keyname>Chang</keyname><forenames>Shih-Fu</forenames><affiliation>Columbia University</affiliation></author></authors><title>On the Difficulty of Nearest Neighbor Search</title><categories>cs.LG cs.DB cs.IR stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast approximate nearest neighbor (NN) search in large databases is becoming
popular. Several powerful learning-based formulations have been proposed
recently. However, not much attention has been paid to a more fundamental
question: how difficult is (approximate) nearest neighbor search in a given
data set? And which data properties affect the difficulty of nearest neighbor
search and how? This paper introduces the first concrete measure called
Relative Contrast that can be used to evaluate the influence of several crucial
data characteristics such as dimensionality, sparsity, and database size
simultaneously in arbitrary normed metric spaces. Moreover, we present a
theoretical analysis to prove how the difficulty measure (relative contrast)
determines/affects the complexity of Local Sensitive Hashing, a popular
approximate NN search method. Relative contrast also provides an explanation
for a family of heuristic hashing algorithms with good practical performance
based on PCA. Finally, we show that most of the previous works in measuring NN
search meaningfulness/difficulty can be derived as special asymptotic cases for
dense vectors of the proposed measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6412</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6412</id><created>2012-06-27</created><authors><author><keyname>Ji</keyname><forenames>Ming</forenames><affiliation>UIUC</affiliation></author><author><keyname>Yang</keyname><forenames>Tianbao</forenames><affiliation>Michigan State University</affiliation></author><author><keyname>Lin</keyname><forenames>Binbin</forenames><affiliation>Zhejiang University</affiliation></author><author><keyname>Jin</keyname><forenames>Rong</forenames><affiliation>Michigan State University</affiliation></author><author><keyname>Han</keyname><forenames>Jiawei</forenames><affiliation>UIUC</affiliation></author></authors><title>A Simple Algorithm for Semi-supervised Learning with Improved
  Generalization Error Bound</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we develop a simple algorithm for semi-supervised regression.
The key idea is to use the top eigenfunctions of integral operator derived from
both labeled and unlabeled examples as the basis functions and learn the
prediction function by a simple linear regression. We show that under
appropriate assumptions about the integral operator, this approach is able to
achieve an improved regression error bound better than existing bounds of
supervised learning. We also verify the effectiveness of the proposed algorithm
by an empirical study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6413</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6413</id><created>2012-06-27</created><authors><author><keyname>Joulin</keyname><forenames>Armand</forenames><affiliation>INRIA - Ecole Normale Superieure</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>INRIA - Ecole Normale Superieure</affiliation></author></authors><title>A Convex Relaxation for Weakly Supervised Classifiers</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a general multi-class approach to weakly supervised
classification. Inferring the labels and learning the parameters of the model
is usually done jointly through a block-coordinate descent algorithm such as
expectation-maximization (EM), which may lead to local minima. To avoid this
problem, we propose a cost function based on a convex relaxation of the
soft-max loss. We then propose an algorithm specifically designed to
efficiently solve the corresponding semidefinite program (SDP). Empirically,
our method compares favorably to standard ones on different datasets for
multiple instance learning and semi-supervised learning as well as on
clustering tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6414</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6414</id><created>2012-06-27</created><authors><author><keyname>Kim</keyname><forenames>Dae Il</forenames><affiliation>Brown University</affiliation></author><author><keyname>Hughes</keyname><forenames>Michael</forenames><affiliation>Brown University</affiliation></author><author><keyname>Sudderth</keyname><forenames>Erik</forenames><affiliation>Brown University</affiliation></author></authors><title>The Nonparametric Metadata Dependent Relational Model</title><categories>cs.LG cs.SI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the nonparametric metadata dependent relational (NMDR) model, a
Bayesian nonparametric stochastic block model for network data. The NMDR allows
the entities associated with each node to have mixed membership in an unbounded
collection of latent communities. Learned regression models allow these
memberships to depend on, and be predicted from, arbitrary node metadata. We
develop efficient MCMC algorithms for learning NMDR models from partially
observed node relationships. Retrospective MCMC methods allow our sampler to
work directly with the infinite stick-breaking representation of the NMDR,
avoiding the need for finite truncations. Our results demonstrate recovery of
useful latent communities from real-world social and ecological networks, and
the usefulness of metadata in link prediction tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6415</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6415</id><created>2012-06-27</created><authors><author><keyname>Kleiner</keyname><forenames>Ariel</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Talwalkar</keyname><forenames>Ameet</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Sarkar</keyname><forenames>Purnamrita</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Jordan</keyname><forenames>Michael</forenames><affiliation>UC Berkeley</affiliation></author></authors><title>The Big Data Bootstrap</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012). arXiv admin note: text overlap with
  arXiv:1112.5016</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bootstrap provides a simple and powerful means of assessing the quality
of estimators. However, in settings involving large datasets, the computation
of bootstrap-based quantities can be prohibitively demanding. As an
alternative, we present the Bag of Little Bootstraps (BLB), a new procedure
which incorporates features of both the bootstrap and subsampling to obtain a
robust, computationally efficient means of assessing estimator quality. BLB is
well suited to modern parallel and distributed computing architectures and
retains the generic applicability, statistical efficiency, and favorable
theoretical properties of the bootstrap. We provide the results of an extensive
empirical and theoretical investigation of BLB's behavior, including a study of
its statistical correctness, its large-scale implementation and performance,
selection of hyperparameters, and performance on real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6416</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6416</id><created>2012-06-27</created><authors><author><keyname>Palla</keyname><forenames>Konstantina</forenames><affiliation>University of Cambridge</affiliation></author><author><keyname>Knowles</keyname><forenames>David</forenames><affiliation>University of Cambridge</affiliation></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames><affiliation>University of Cambridge</affiliation></author></authors><title>An Infinite Latent Attribute Model for Network Data</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latent variable models for network data extract a summary of the relational
structure underlying an observed network. The simplest possible models
subdivide nodes of the network into clusters; the probability of a link between
any two nodes then depends only on their cluster assignment. Currently
available models can be classified by whether clusters are disjoint or are
allowed to overlap. These models can explain a &quot;flat&quot; clustering structure.
Hierarchical Bayesian models provide a natural approach to capture more complex
dependencies. We propose a model in which objects are characterised by a latent
feature vector. Each feature is itself partitioned into disjoint groups
(subclusters), corresponding to a second layer of hierarchy. In experimental
comparisons, the model achieves significantly improved predictive performance
on social and biological link prediction tasks. The results indicate that
models with a single layer hierarchy over-simplify real networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6417</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6417</id><created>2012-06-27</created><authors><author><keyname>Kumar</keyname><forenames>Abhishek</forenames><affiliation>University of Maryland</affiliation></author><author><keyname>Daume</keyname><forenames>Hal</forenames><suffix>III</suffix><affiliation>University of Maryland</affiliation></author></authors><title>Learning Task Grouping and Overlap in Multi-task Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paradigm of multi-task learning, mul- tiple related prediction tasks
are learned jointly, sharing information across the tasks. We propose a
framework for multi-task learn- ing that enables one to selectively share the
information across the tasks. We assume that each task parameter vector is a
linear combi- nation of a finite number of underlying basis tasks. The
coefficients of the linear combina- tion are sparse in nature and the overlap
in the sparsity patterns of two tasks controls the amount of sharing across
these. Our model is based on on the assumption that task pa- rameters within a
group lie in a low dimen- sional subspace but allows the tasks in differ- ent
groups to overlap with each other in one or more bases. Experimental results on
four datasets show that our approach outperforms competing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6418</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6418</id><created>2012-06-27</created><authors><author><keyname>Sohn</keyname><forenames>Kihyuk</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Lee</keyname><forenames>Honglak</forenames><affiliation>University of Michigan</affiliation></author></authors><title>Learning Invariant Representations with Local Transformations</title><categories>cs.LG cs.CV stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning invariant representations is an important problem in machine
learning and pattern recognition. In this paper, we present a novel framework
of transformation-invariant feature learning by incorporating linear
transformations into the feature learning algorithms. For example, we present
the transformation-invariant restricted Boltzmann machine that compactly
represents data by its weights and their transformations, which achieves
invariance of the feature representation via probabilistic max pooling. In
addition, we show that our transformation-invariant feature learning framework
can also be extended to other unsupervised learning methods, such as
autoencoders or sparse coding. We evaluate our method on several image
classification benchmark datasets, such as MNIST variations, CIFAR-10, and
STL-10, and show competitive or superior classification performance when
compared to the state-of-the-art. Furthermore, our method achieves
state-of-the-art performance on phone classification tasks with the TIMIT
dataset, which demonstrates wide applicability of our proposed algorithms to
other domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6419</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6419</id><created>2012-06-27</created><authors><author><keyname>Han</keyname><forenames>Shaobo</forenames><affiliation>Duke University</affiliation></author><author><keyname>Liao</keyname><forenames>Xuejun</forenames><affiliation>Duke University</affiliation></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames><affiliation>Duke University</affiliation></author></authors><title>Cross-Domain Multitask Learning with Latent Probit Models</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning multiple tasks across heterogeneous domains is a challenging problem
since the feature space may not be the same for different tasks. We assume the
data in multiple tasks are generated from a latent common domain via sparse
domain transforms and propose a latent probit model (LPM) to jointly learn the
domain transforms, and the shared probit classifier in the common domain. To
learn meaningful task relatedness and avoid over-fitting in classification, we
introduce sparsity in the domain transforms matrices, as well as in the common
classifier. We derive theoretical bounds for the estimation error of the
classifier in terms of the sparsity of domain transforms. An
expectation-maximization algorithm is derived for learning the LPM. The
effectiveness of the approach is demonstrated on several real datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6420</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6420</id><created>2012-06-27</created><authors><author><keyname>Liu</keyname><forenames>Qiang</forenames><affiliation>UC Irvine</affiliation></author><author><keyname>Ihler</keyname><forenames>Alexander</forenames><affiliation>UC Irvine</affiliation></author></authors><title>Distributed Parameter Estimation via Pseudo-likelihood</title><categories>cs.LG cs.DC stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating statistical models within sensor networks requires distributed
algorithms, in which both data and computation are distributed across the nodes
of the network. We propose a general approach for distributed learning based on
combining local estimators defined by pseudo-likelihood components,
encompassing a number of combination methods, and provide both theoretical and
experimental analysis. We show that simple linear combination or max-voting
methods, when combined with second-order information, are statistically
competitive with more advanced and costly joint optimization. Our algorithms
have many attractive properties including low communication and computational
cost and &quot;any-time&quot; behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6421</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6421</id><created>2012-06-27</created><authors><author><keyname>Lou</keyname><forenames>Xinghua</forenames><affiliation>University of Heidelberg</affiliation></author><author><keyname>Hamprecht</keyname><forenames>Fred</forenames><affiliation>University of Heidelberg</affiliation></author></authors><title>Structured Learning from Partial Annotations</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured learning is appropriate when predicting structured outputs such as
trees, graphs, or sequences. Most prior work requires the training set to
consist of complete trees, graphs or sequences. Specifying such detailed ground
truth can be tedious or infeasible for large outputs. Our main contribution is
a large margin formulation that makes structured learning from only partially
annotated data possible. The resulting optimization problem is non-convex, yet
can be efficiently solve by concave-convex procedure (CCCP) with novel speedup
strategies. We apply our method to a challenging tracking-by-assignment problem
of a variable number of divisible objects. On this benchmark, using only 25% of
a full annotation we achieve a performance comparable to a model learned with a
full annotation. Finally, we offer a unifying perspective of previous work
using the hinge, ramp, or max loss for structured learning, followed by an
empirical comparison on their practical performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6422</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6422</id><created>2012-06-27</created><authors><author><keyname>Chen</keyname><forenames>Shang-Tse</forenames><affiliation>Academia Sinica</affiliation></author><author><keyname>Lin</keyname><forenames>Hsuan-Tien</forenames><affiliation>National Taiwan University</affiliation></author><author><keyname>Lu</keyname><forenames>Chi-Jen</forenames><affiliation>Academia Sinica</affiliation></author></authors><title>An Online Boosting Algorithm with Theoretical Justifications</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the task of online boosting--combining online weak learners into an
online strong learner. While batch boosting has a sound theoretical foundation,
online boosting deserves more study from the theoretical perspective. In this
paper, we carefully compare the differences between online and batch boosting,
and propose a novel and reasonable assumption for the online weak learner.
Based on the assumption, we design an online boosting algorithm with a strong
theoretical guarantee by adapting from the offline SmoothBoost algorithm that
matches the assumption closely. We further tackle the task of deciding the
number of weak learners using established theoretical results for online convex
programming and predicting with expert advice. Experiments on real-world data
sets demonstrate that the proposed algorithm compares favorably with existing
online boosting algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6423</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6423</id><created>2012-06-27</created><authors><author><keyname>Matuszek</keyname><forenames>Cynthia</forenames><affiliation>University of Washington</affiliation></author><author><keyname>FitzGerald</keyname><forenames>Nicholas</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Zettlemoyer</keyname><forenames>Luke</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Bo</keyname><forenames>Liefeng</forenames><affiliation>University of Washington</affiliation></author><author><keyname>Fox</keyname><forenames>Dieter</forenames><affiliation>University of Washington</affiliation></author></authors><title>A Joint Model of Language and Perception for Grounded Attribute Learning</title><categories>cs.CL cs.LG cs.RO</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As robots become more ubiquitous and capable, it becomes ever more important
to enable untrained users to easily interact with them. Recently, this has led
to study of the language grounding problem, where the goal is to extract
representations of the meanings of natural language tied to perception and
actuation in the physical world. In this paper, we present an approach for
joint learning of language and perception models for grounded attribute
induction. Our perception model includes attribute classifiers, for example to
detect object color and shape, and the language model is based on a
probabilistic categorial grammar that enables the construction of rich,
compositional meaning representations. The approach is evaluated on the task of
interpreting sentences that describe sets of objects in a physical workspace.
We demonstrate accurate task performance and effective latent-variable concept
induction in physical grounded scenes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6424</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6424</id><created>2012-06-27</created><authors><author><keyname>Maua</keyname><forenames>Denis</forenames><affiliation>IDSIA</affiliation></author><author><keyname>De Campos</keyname><forenames>Cassio</forenames><affiliation>IDSIA</affiliation></author></authors><title>Anytime Marginal MAP Inference</title><categories>cs.AI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new anytime algorithm for the marginal MAP problem in
graphical models. The algorithm is described in detail, its complexity and
convergence rate are studied, and relations to previous theoretical results for
the problem are discussed. It is shown that the algorithm runs in
polynomial-time if the underlying graph of the model has bounded tree-width,
and that it provides guarantees to the lower and upper bounds obtained within a
fixed amount of computational resources. Experiments with both real and
synthetic generated models highlight its main characteristics and show that it
compares favorably against Park and Darwiche's systematic search, particularly
in the case of problems with many MAP variables and moderate tree-width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6425</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6425</id><created>2012-06-27</created><authors><author><keyname>Mimno</keyname><forenames>David</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Hoffman</keyname><forenames>Matt</forenames><affiliation>Columbia University</affiliation></author><author><keyname>Blei</keyname><forenames>David</forenames><affiliation>Princeton University</affiliation></author></authors><title>Sparse Stochastic Inference for Latent Dirichlet allocation</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a hybrid algorithm for Bayesian topic models that combines the
efficiency of sparse Gibbs sampling with the scalability of online stochastic
inference. We used our algorithm to analyze a corpus of 1.2 million books (33
billion words) with thousands of topics. Our approach reduces the bias of
variational inference and generalizes to many Bayesian hidden-variable models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6426</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6426</id><created>2012-06-27</created><authors><author><keyname>Mnih</keyname><forenames>Andriy</forenames><affiliation>University College London</affiliation></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames><affiliation>University College London</affiliation></author></authors><title>A Fast and Simple Algorithm for Training Neural Probabilistic Language
  Models</title><categories>cs.CL cs.LG</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spite of their superior performance, neural probabilistic language models
(NPLMs) remain far less widely used than n-gram models due to their notoriously
long training times, which are measured in weeks even for moderately-sized
datasets. Training NPLMs is computationally expensive because they are
explicitly normalized, which leads to having to consider all words in the
vocabulary when computing the log-likelihood gradients.
  We propose a fast and simple algorithm for training NPLMs based on
noise-contrastive estimation, a newly introduced procedure for estimating
unnormalized continuous distributions. We investigate the behaviour of the
algorithm on the Penn Treebank corpus and show that it reduces the training
times by more than an order of magnitude without affecting the quality of the
resulting models. The algorithm is also more efficient and much more stable
than importance sampling because it requires far fewer noise samples to perform
well.
  We demonstrate the scalability of the proposed approach by training several
neural language models on a 47M-word corpus with a 80K-word vocabulary,
obtaining state-of-the-art results on the Microsoft Research Sentence
Completion Challenge dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6427</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6427</id><created>2012-06-27</created><authors><author><keyname>Naim</keyname><forenames>Iftekhar</forenames><affiliation>University of Rochester</affiliation></author><author><keyname>Gildea</keyname><forenames>Daniel</forenames><affiliation>University of Rochester</affiliation></author></authors><title>Convergence of the EM Algorithm for Gaussian Mixtures with Unbalanced
  Mixing Coefficients</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The speed of convergence of the Expectation Maximization (EM) algorithm for
Gaussian mixture model fitting is known to be dependent on the amount of
overlap among the mixture components. In this paper, we study the impact of
mixing coefficients on the convergence of EM. We show that when the mixture
components exhibit some overlap, the convergence of EM becomes slower as the
dynamic range among the mixing coefficients increases. We propose a
deterministic anti-annealing algorithm, that significantly improves the speed
of convergence of EM for such mixtures with unbalanced mixing coefficients. The
proposed algorithm is compared against other standard optimization techniques
like BFGS, Conjugate Gradient, and the traditional EM algorithm. Finally, we
propose a similar deterministic anti-annealing based algorithm for the
Dirichlet process mixture model and demonstrate its advantages over the
conventional variational Bayesian approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6428</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6428</id><created>2012-06-27</created><authors><author><keyname>Kumar</keyname><forenames>Abhishek</forenames><affiliation>University of Maryland</affiliation></author><author><keyname>Niculescu-Mizil</keyname><forenames>Alexandru</forenames><affiliation>NEC Laboratories America</affiliation></author><author><keyname>Kavukcuoglu</keyname><forenames>Koray</forenames><affiliation>NEC Laboratories America</affiliation></author><author><keyname>Daume</keyname><forenames>Hal</forenames><suffix>III</suffix><affiliation>University of Maryland</affiliation></author></authors><title>A Binary Classification Framework for Two-Stage Multiple Kernel Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advent of kernel methods, automating the task of specifying a
suitable kernel has become increasingly important. In this context, the
Multiple Kernel Learning (MKL) problem of finding a combination of
pre-specified base kernels that is suitable for the task at hand has received
significant attention from researchers. In this paper we show that Multiple
Kernel Learning can be framed as a standard binary classification problem with
additional constraints that ensure the positive definiteness of the learned
kernel. Framing MKL in this way has the distinct advantage that it makes it
easy to leverage the extensive research in binary classification to develop
better performing and more scalable MKL algorithms that are conceptually
simpler, and, arguably, more accessible to practitioners. Experiments on nine
data sets from different domains show that, despite its simplicity, the
proposed technique compares favorably with current leading MKL approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6429</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6429</id><created>2012-06-27</created><authors><author><keyname>Pachauri</keyname><forenames>Deepti</forenames><affiliation>University of Wisconsin Madison</affiliation></author><author><keyname>Collins</keyname><forenames>Maxwell</forenames><affiliation>University of Wisconsin Madison</affiliation></author><author><keyname>SIngh</keyname><forenames>Vikas</forenames><affiliation>University of Wisconsin Madison</affiliation></author><author><keyname>Kondor</keyname><forenames>Risi</forenames><affiliation>University of Chicago</affiliation></author></authors><title>Incorporating Domain Knowledge in Matching Problems via Harmonic
  Analysis</title><categories>cs.LG cs.CV stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching one set of objects to another is a ubiquitous task in machine
learning and computer vision that often reduces to some form of the quadratic
assignment problem (QAP). The QAP is known to be notoriously hard, both in
theory and in practice. Here, we investigate if this difficulty can be
mitigated when some additional piece of information is available: (a) that all
QAP instances of interest come from the same application, and (b) the correct
solution for a set of such QAP instances is given. We propose a new approach to
accelerate the solution of QAPs based on learning parameters for a modified
objective function from prior QAP instances. A key feature of our approach is
that it takes advantage of the algebraic structure of permutations, in
conjunction with special methods for optimizing functions over the symmetric
group Sn in Fourier space. Experiments show that in practical domains the new
method can outperform existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6430</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6430</id><created>2012-06-27</created><authors><author><keyname>Paisley</keyname><forenames>John</forenames><affiliation>UC Berkeley</affiliation></author><author><keyname>Blei</keyname><forenames>David</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Jordan</keyname><forenames>Michael</forenames><affiliation>UC Berkeley</affiliation></author></authors><title>Variational Bayesian Inference with Stochastic Search</title><categories>cs.LG stat.CO stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean-field variational inference is a method for approximate Bayesian
posterior inference. It approximates a full posterior distribution with a
factorized set of distributions by maximizing a lower bound on the marginal
likelihood. This requires the ability to integrate a sum of terms in the log
joint likelihood using this factorized distribution. Often not all integrals
are in closed form, which is typically handled by using a lower bound. We
present an alternative algorithm based on stochastic optimization that allows
for direct optimization of the variational lower bound. This method uses
control variates to reduce the variance of the stochastic search gradient, in
which existing lower bounds can play an important role. We demonstrate the
approach on two non-conjugate models: logistic regression and an approximation
to the HDP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6431</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6431</id><created>2012-06-27</created><authors><author><keyname>Peharz</keyname><forenames>Robert</forenames><affiliation>Graz University of Technology</affiliation></author><author><keyname>Pernkopf</keyname><forenames>Franz</forenames><affiliation>Graz University of Technology</affiliation></author></authors><title>Exact Maximum Margin Structure Learning of Bayesian Networks</title><categories>cs.LG stat.ML</categories><comments>ICML</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, there has been much interest in finding globally optimal Bayesian
network structures. These techniques were developed for generative scores and
can not be directly extended to discriminative scores, as desired for
classification. In this paper, we propose an exact method for finding network
structures maximizing the probabilistic soft margin, a successfully applied
discriminative score. Our method is based on branch-and-bound techniques within
a linear programming framework and maintains an any-time solution, together
with worst-case sub-optimality bounds. We apply a set of order constraints for
enforcing the network structure to be acyclic, which allows a compact problem
representation and the use of general-purpose optimization techniques. In
classification experiments, our methods clearly outperform generatively trained
network structures and compete with support vector machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6432</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6432</id><created>2012-06-27</created><authors><author><keyname>Rakotomamonjy</keyname><forenames>Alain</forenames><affiliation>Universite de Rouen</affiliation></author></authors><title>Sparse Support Vector Infinite Push</title><categories>cs.LG cs.CE stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of embedded feature selection for
ranking on top of the list problems. We pose this problem as a regularized
empirical risk minimization with $p$-norm push loss function ($p=\infty$) and
sparsity inducing regularizers. We leverage the issues related to this
challenging optimization problem by considering an alternating direction method
of multipliers algorithm which is built upon proximal operators of the loss
function and the regularizer. Our main technical contribution is thus to
provide a numerical scheme for computing the infinite push loss function
proximal operator. Experimental results on toy, DNA microarray and BCI problems
show how our novel algorithm compares favorably to competitors for ranking on
top while using fewer variables in the scoring function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6433</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6433</id><created>2012-06-27</created><authors><author><keyname>Rey</keyname><forenames>Melanie</forenames><affiliation>University of Basel</affiliation></author><author><keyname>Roth</keyname><forenames>Volker</forenames><affiliation>University of Basel</affiliation></author></authors><title>Copula Mixture Model for Dependency-seeking Clustering</title><categories>stat.ME cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a copula mixture model to perform dependency-seeking clustering
when co-occurring samples from different data sources are available. The model
takes advantage of the great flexibility offered by the copulas framework to
extend mixtures of Canonical Correlation Analysis to multivariate data with
arbitrary continuous marginal densities. We formulate our model as a
non-parametric Bayesian mixture, while providing efficient MCMC inference.
Experiments on synthetic and real data demonstrate that the increased
flexibility of the copula mixture significantly improves the clustering and the
interpretability of the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6434</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6434</id><created>2012-06-27</created><authors><author><keyname>Rifai</keyname><forenames>Salah</forenames><affiliation>Universite de Montreal</affiliation></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames><affiliation>Universite de Montreal</affiliation></author><author><keyname>Dauphin</keyname><forenames>Yann</forenames><affiliation>Universite de Montreal</affiliation></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames><affiliation>Universite de Montreal</affiliation></author></authors><title>A Generative Process for Sampling Contractive Auto-Encoders</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The contractive auto-encoder learns a representation of the input data that
captures the local manifold structure around each data point, through the
leading singular vectors of the Jacobian of the transformation from input to
representation. The corresponding singular values specify how much local
variation is plausible in directions associated with the corresponding singular
vectors, while remaining in a high-density region of the input space. This
paper proposes a procedure for generating samples that are consistent with the
local structure captured by a contractive auto-encoder. The associated
stochastic process defines a distribution from which one can sample, and which
experimentally appears to converge quickly and mix well between modes, compared
to Restricted Boltzmann Machines and Deep Belief Networks. The intuitions
behind this procedure can also be used to train the second layer of contraction
that pools lower-level features and learns to be invariant to the local
directions of variation discovered in the first layer. We show that this can
help learn and represent invariances present in the data and improve
classification error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6435</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6435</id><created>2012-06-27</created><authors><author><keyname>Sato</keyname><forenames>Issei</forenames><affiliation>The University of Tokyo</affiliation></author><author><keyname>Nakagawa</keyname><forenames>Hiroshi</forenames><affiliation>The University of Tokyo</affiliation></author></authors><title>Rethinking Collapsed Variational Bayes Inference for LDA</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel interpretation of the collapsed variational Bayes
inference with a zero-order Taylor expansion approximation, called CVB0
inference, for latent Dirichlet allocation (LDA). We clarify the properties of
the CVB0 inference by using the alpha-divergence. We show that the CVB0
inference is composed of two different divergence projections: alpha=1 and -1.
This interpretation will help shed light on CVB0 works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6436</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6436</id><created>2012-06-27</created><authors><author><keyname>Schwing</keyname><forenames>Alexander</forenames><affiliation>ETH Zurich</affiliation></author><author><keyname>Hazan</keyname><forenames>Tamir</forenames><affiliation>TTIC</affiliation></author><author><keyname>Pollefeys</keyname><forenames>Marc</forenames><affiliation>ETH Zurich</affiliation></author><author><keyname>Urtasun</keyname><forenames>Raquel</forenames><affiliation>TTIC</affiliation></author></authors><title>Efficient Structured Prediction with Latent Variables for General
  Graphical Models</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a unified framework for structured prediction with
latent variables which includes hidden conditional random fields and latent
structured support vector machines as special cases. We describe a local
entropy approximation for this general formulation using duality, and derive an
efficient message passing algorithm that is guaranteed to converge. We
demonstrate its effectiveness in the tasks of image segmentation as well as 3D
indoor scene understanding from single images, showing that our approach is
superior to latent structured support vector machines and hidden conditional
random fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6437</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6437</id><created>2012-06-27</created><authors><author><keyname>Ko</keyname><forenames>Young Jun</forenames><affiliation>Ecole Polytechnique Federale de Lausanne</affiliation></author><author><keyname>Seeger</keyname><forenames>Matthias</forenames><affiliation>Ecole Polytechnique Federale de Lausanne</affiliation></author></authors><title>Large Scale Variational Bayesian Inference for Structured Scale Mixture
  Models</title><categories>cs.CV cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural image statistics exhibit hierarchical dependencies across multiple
scales. Representing such prior knowledge in non-factorial latent tree models
can boost performance of image denoising, inpainting, deconvolution or
reconstruction substantially, beyond standard factorial &quot;sparse&quot; methodology.
We derive a large scale approximate Bayesian inference algorithm for linear
models with non-factorial (latent tree-structured) scale mixture priors.
Experimental results on a range of denoising and inpainting problems
demonstrate substantially improved performance compared to MAP estimation or to
inference with factorial priors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6438</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6438</id><created>2012-06-27</created><authors><author><keyname>Shi</keyname><forenames>Yuan</forenames><affiliation>University of Southern California</affiliation></author><author><keyname>Sha</keyname><forenames>Fei</forenames><affiliation>University of Southern California</affiliation></author></authors><title>Information-Theoretical Learning of Discriminative Clusters for
  Unsupervised Domain Adaptation</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of unsupervised domain adaptation, which aims to adapt
classifiers trained on a labeled source domain to an unlabeled target domain.
Many existing approaches first learn domain-invariant features and then
construct classifiers with them. We propose a novel approach that jointly learn
the both. Specifically, while the method identifies a feature space where data
in the source and the target domains are similarly distributed, it also learns
the feature space discriminatively, optimizing an information-theoretic metric
as an proxy to the expected misclassification error on the target domain. We
show how this optimization can be effectively carried out with simple
gradient-based methods and how hyperparameters can be cross-validated without
demanding any labeled data from the target domain. Empirical studies on
benchmark tasks of object recognition and sentiment analysis validated our
modeling assumptions and demonstrated significant improvement of our method
over competing ones in classification accuracies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6439</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6439</id><created>2012-06-27</created><authors><author><keyname>Shan</keyname><forenames>Hanhuai</forenames><affiliation>University of Minnesota</affiliation></author><author><keyname>Kattge</keyname><forenames>Jens</forenames><affiliation>Max Planck Institute for Biogeochemistry</affiliation></author><author><keyname>Reich</keyname><forenames>Peter</forenames><affiliation>University of Minnesota</affiliation></author><author><keyname>Banerjee</keyname><forenames>Arindam</forenames><affiliation>University of Minnesota</affiliation></author><author><keyname>Schrodt</keyname><forenames>Franziska</forenames><affiliation>University of Minnesota</affiliation></author><author><keyname>Reichstein</keyname><forenames>Markus</forenames><affiliation>Max Planck Institute for Biogeochemistry</affiliation></author></authors><title>Gap Filling in the Plant Kingdom---Trait Prediction Using Hierarchical
  Probabilistic Matrix Factorization</title><categories>cs.CE cs.LG stat.AP</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plant traits are a key to understanding and predicting the adaptation of
ecosystems to environmental changes, which motivates the TRY project aiming at
constructing a global database for plant traits and becoming a standard
resource for the ecological community. Despite its unprecedented coverage, a
large percentage of missing data substantially constrains joint trait analysis.
Meanwhile, the trait data is characterized by the hierarchical phylogenetic
structure of the plant kingdom. While factorization based matrix completion
techniques have been widely used to address the missing data problem,
traditional matrix factorization methods are unable to leverage the
phylogenetic structure. We propose hierarchical probabilistic matrix
factorization (HPMF), which effectively uses hierarchical phylogenetic
information for trait prediction. We demonstrate HPMF's high accuracy,
effectiveness of incorporating hierarchical structure and ability to capture
trait correlation through experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6440</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6440</id><created>2012-06-27</created><authors><author><keyname>Sheffet</keyname><forenames>Or</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Mishra</keyname><forenames>Nina</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Ieong</keyname><forenames>Samuel</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>Predicting Preference Flips in Commerce Search</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional approaches to ranking in web search follow the paradigm of
rank-by-score: a learned function gives each query-URL combination an absolute
score and URLs are ranked according to this score. This paradigm ensures that
if the score of one URL is better than another then one will always be ranked
higher than the other. Scoring contradicts prior work in behavioral economics
that showed that users' preferences between two items depend not only on the
items but also on the presented alternatives. Thus, for the same query, users'
preference between items A and B depends on the presence/absence of item C. We
propose a new model of ranking, the Random Shopper Model, that allows and
explains such behavior. In this model, each feature is viewed as a Markov chain
over the items to be ranked, and the goal is to find a weighting of the
features that best reflects their importance. We show that our model can be
learned under the empirical risk minimization framework, and give an efficient
learning algorithm. Experiments on commerce search logs demonstrate that our
algorithm outperforms scoring-based approaches including regression and
listwise ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6441</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6441</id><created>2012-06-27</created><authors><author><keyname>Spiliopoulou</keyname><forenames>Athina</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Storkey</keyname><forenames>Amos</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>A Topic Model for Melodic Sequences</title><categories>cs.LG cs.IR stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the problem of learning a probabilistic model for melody directly
from musical sequences belonging to the same genre. This is a challenging task
as one needs to capture not only the rich temporal structure evident in music,
but also the complex statistical dependencies among different music components.
To address this problem we introduce the Variable-gram Topic Model, which
couples the latent topic formalism with a systematic model for contextual
information. We evaluate the model on next-step prediction. Additionally, we
present a novel way of model evaluation, where we directly compare model
samples with data sequences using the Maximum Mean Discrepancy of string
kernels, to assess how close is the model distribution to the data
distribution. We show that the model has the highest performance under both
evaluation measures when compared to LDA, the Topic Bigram and related
non-topic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6442</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6442</id><created>2012-06-27</created><authors><author><keyname>Ben-David</keyname><forenames>Shai</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Loker</keyname><forenames>David</forenames><affiliation>University of Waterloo</affiliation></author><author><keyname>Srebro</keyname><forenames>Nathan</forenames><affiliation>TTIC</affiliation></author><author><keyname>Sridharan</keyname><forenames>Karthik</forenames><affiliation>University of Pennsylvania</affiliation></author></authors><title>Minimizing The Misclassification Error Rate Using a Surrogate Convex
  Loss</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We carefully study how well minimizing convex surrogate loss functions,
corresponds to minimizing the misclassification error rate for the problem of
binary classification with linear predictors. In particular, we show that
amongst all convex surrogate losses, the hinge loss gives essentially the best
possible bound, of all convex loss functions, for the misclassification error
rate of the resulting linear predictor in terms of the best possible margin
error rate. We also provide lower bounds for specific convex surrogates that
show how different commonly used losses qualitatively differ from each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6443</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6443</id><created>2012-06-27</created><updated>2012-09-04</updated><authors><author><keyname>Storkey</keyname><forenames>Amos</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Millin</keyname><forenames>Jono</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Geras</keyname><forenames>Krzysztof</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>Isoelastic Agents and Wealth Updates in Machine Learning Markets</title><categories>cs.LG cs.GT stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>Amir Globerson</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, prediction markets have shown considerable promise for developing
flexible mechanisms for machine learning. In this paper, agents with isoelastic
utilities are considered. It is shown that the costs associated with
homogeneous markets of agents with isoelastic utilities produce equilibrium
prices corresponding to alpha-mixtures, with a particular form of mixing
component relating to each agent's wealth. We also demonstrate that wealth
accumulation for logarithmic and other isoelastic agents (through payoffs on
prediction of training targets) can implement both Bayesian model updates and
mixture weight updates by imposing different market payoff structures. An
iterative algorithm is given for market equilibrium computation. We demonstrate
that inhomogeneous markets of agents with isoelastic utilities outperform state
of the art aggregate classifiers such as random forests, as well as single
classifiers (neural networks, decision trees) on a number of machine learning
benchmarks, and show that isoelastic combination methods are generally better
than their logarithmic counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6444</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6444</id><created>2012-06-27</created><authors><author><keyname>Pires</keyname><forenames>Bernardo Avila</forenames><affiliation>University of Alberta</affiliation></author><author><keyname>Szepesvari</keyname><forenames>Csaba</forenames><affiliation>University of Alberta</affiliation></author></authors><title>Statistical Linear Estimation with Penalized Estimators: an Application
  to Reinforcement Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by value function estimation in reinforcement learning, we study
statistical linear inverse problems, i.e., problems where the coefficients of a
linear system to be solved are observed in noise. We consider penalized
estimators, where performance is evaluated using a matrix-weighted two-norm of
the defect of the estimator measured with respect to the true, unknown
coefficients. Two objective functions are considered depending whether the
error of the defect measured with respect to the noisy coefficients is squared
or unsquared. We propose simple, yet novel and theoretically well-founded
data-dependent choices for the regularization parameters for both cases that
avoid data-splitting. A distinguishing feature of our analysis is that we
derive deterministic error bounds in terms of the error of the coefficients,
thus allowing the complete separation of the analysis of the stochastic
properties of these errors. We show that our results lead to new insights and
bounds for linear value function estimation in reinforcement learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6445</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6445</id><created>2012-06-27</created><authors><author><keyname>Tang</keyname><forenames>Yichuan</forenames><affiliation>University of Toronto</affiliation></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan</forenames><affiliation>University of Toronto</affiliation></author><author><keyname>Hinton</keyname><forenames>Geoffrey</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Deep Lambertian Networks</title><categories>cs.CV cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual perception is a challenging problem in part due to illumination
variations. A possible solution is to first estimate an illumination invariant
representation before using it for recognition. The object albedo and surface
normals are examples of such representations. In this paper, we introduce a
multilayer generative model where the latent variables include the albedo,
surface normals, and the light source. Combining Deep Belief Nets with the
Lambertian reflectance assumption, our model can learn good priors over the
albedo from 2D images. Illumination variations can be explained by changing
only the lighting latent variable in our model. By transferring learned
knowledge from similar objects, albedo and surface normals estimation from a
single image is possible in our model. Experiments demonstrate that our model
is able to generalize as well as improve over standard baselines in one-shot
face recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6446</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6446</id><created>2012-06-27</created><authors><author><keyname>Telgarsky</keyname><forenames>Matus</forenames><affiliation>UCSD</affiliation></author><author><keyname>Dasgupta</keyname><forenames>Sanjoy</forenames><affiliation>UCSD</affiliation></author></authors><title>Agglomerative Bregman Clustering</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript develops the theory of agglomerative clustering with Bregman
divergences. Geometric smoothing techniques are developed to deal with
degenerate clusters. To allow for cluster models based on exponential families
with overcomplete representations, Bregman divergences are developed for
nondifferentiable convex functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6447</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6447</id><created>2012-06-27</created><authors><author><keyname>Varoquaux</keyname><forenames>Gael</forenames><affiliation>INRIA</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>INRIA</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>INRIA</affiliation></author></authors><title>Small-sample Brain Mapping: Sparse Recovery on Spatially Correlated
  Designs with Randomization and Clustering</title><categories>cs.LG cs.CV stat.AP stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional neuroimaging can measure the brain?s response to an external
stimulus. It is used to perform brain mapping: identifying from these
observations the brain regions involved. This problem can be cast into a linear
supervised learning task where the neuroimaging data are used as predictors for
the stimulus. Brain mapping is then seen as a support recovery problem. On
functional MRI (fMRI) data, this problem is particularly challenging as i) the
number of samples is small due to limited acquisition time and ii) the
variables are strongly correlated. We propose to overcome these difficulties
using sparse regression models over new variables obtained by clustering of the
original variables. The use of randomization techniques, e.g. bootstrap
samples, and clustering of the variables improves the recovery properties of
sparse methods. We demonstrate the benefit of our approach on an extensive
simulation study as well as two fMRI datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6448</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6448</id><created>2012-06-27</created><authors><author><keyname>Wang</keyname><forenames>Huahua</forenames><affiliation>University of Minnesota</affiliation></author><author><keyname>Banerjee</keyname><forenames>Arindam</forenames><affiliation>University of Minnesota</affiliation></author></authors><title>Online Alternating Direction Method</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online optimization has emerged as powerful tool in large scale optimization.
In this paper, we introduce efficient online algorithms based on the
alternating directions method (ADM). We introduce a new proof technique for ADM
in the batch setting, which yields the O(1/T) convergence rate of ADM and forms
the basis of regret analysis in the online setting. We consider two scenarios
in the online setting, based on whether the solution needs to lie in the
feasible set or not. In both settings, we establish regret bounds for both the
objective function as well as constraint violation for general and strongly
convex functions. Preliminary results are presented to illustrate the
performance of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6449</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6449</id><created>2012-06-27</created><authors><author><keyname>Wang</keyname><forenames>Yi</forenames><affiliation>NUS</affiliation></author><author><keyname>Won</keyname><forenames>Kok Sung</forenames><affiliation>NUS</affiliation></author><author><keyname>Hsu</keyname><forenames>David</forenames><affiliation>NUS</affiliation></author><author><keyname>Lee</keyname><forenames>Wee Sun</forenames><affiliation>NUS</affiliation></author></authors><title>Monte Carlo Bayesian Reinforcement Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian reinforcement learning (BRL) encodes prior knowledge of the world in
a model and represents uncertainty in model parameters by maintaining a
probability distribution over them. This paper presents Monte Carlo BRL
(MC-BRL), a simple and general approach to BRL. MC-BRL samples a priori a
finite set of hypotheses for the model parameter values and forms a discrete
partially observable Markov decision process (POMDP) whose state space is a
cross product of the state space for the reinforcement learning task and the
sampled model parameter space. The POMDP does not require conjugate
distributions for belief representation, as earlier works do, and can be solved
relatively easily with point-based approximation algorithms. MC-BRL naturally
handles both fully and partially observable worlds. Theoretical and
experimental results show that the discrete POMDP approximates the underlying
BRL task well with guaranteed performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6450</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6450</id><created>2012-06-27</created><authors><author><keyname>Xu</keyname><forenames>Min</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Lafferty</keyname><forenames>John</forenames><affiliation>University of Chicago</affiliation></author></authors><title>Conditional Sparse Coding and Grouped Multivariate Regression</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of multivariate regression where the data are naturally
grouped, and a regression matrix is to be estimated for each group. We propose
an approach in which a dictionary of low rank parameter matrices is estimated
across groups, and a sparse linear combination of the dictionary elements is
estimated to form a model within each group. We refer to the method as
conditional sparse coding since it is a coding procedure for the response
vectors Y conditioned on the covariate vectors X. This approach captures the
shared information across the groups while adapting to the structure within
each group. It exploits the same intuition behind sparse coding that has been
successfully developed in computer vision and computational neuroscience. We
propose an algorithm for conditional sparse coding, analyze its theoretical
properties in terms of predictive accuracy, and present the results of
simulation and brain imaging experiments that compare the new technique to
reduced rank regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6451</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6451</id><created>2012-06-27</created><authors><author><keyname>Xu</keyname><forenames>Zhixiang</forenames><affiliation>Washington University, St. Louis</affiliation></author><author><keyname>Weinberger</keyname><forenames>Kilian</forenames><affiliation>Washington University, St. Louis</affiliation></author><author><keyname>Chapelle</keyname><forenames>Olivier</forenames><affiliation>Criteo</affiliation></author></authors><title>The Greedy Miser: Learning under Test-time Budgets</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As machine learning algorithms enter applications in industrial settings,
there is increased interest in controlling their cpu-time during testing. The
cpu-time consists of the running time of the algorithm and the extraction time
of the features. The latter can vary drastically when the feature set is
diverse. In this paper, we propose an algorithm, the Greedy Miser, that
incorporates the feature extraction cost during training to explicitly minimize
the cpu-time during testing. The algorithm is a straightforward extension of
stage-wise regression and is equally suitable for regression or multi-class
classification. Compared to prior work, it is significantly more cost-effective
and scales to larger data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6452</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6452</id><created>2012-06-27</created><authors><author><keyname>Yackley</keyname><forenames>Benjamin</forenames><affiliation>University of New Mexico</affiliation></author><author><keyname>Lane</keyname><forenames>Terran</forenames><affiliation>University of New Mexico</affiliation></author></authors><title>Smoothness and Structure Learning by Proxy</title><categories>cs.LG math.OC stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As data sets grow in size, the ability of learning methods to find structure
in them is increasingly hampered by the time needed to search the large spaces
of possibilities and generate a score for each that takes all of the observed
data into account. For instance, Bayesian networks, the model chosen in this
paper, have a super-exponentially large search space for a fixed number of
variables. One possible method to alleviate this problem is to use a proxy,
such as a Gaussian Process regressor, in place of the true scoring function,
training it on a selection of sampled networks. We prove here that the use of
such a proxy is well-founded, as we can bound the smoothness of a commonly-used
scoring function for Bayesian network structure learning. We show here that,
compared to an identical search strategy using the network?s exact scores, our
proxy-based search is able to get equivalent or better scores on a number of
data sets in a fraction of the time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6453</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6453</id><created>2012-06-27</created><authors><author><keyname>Yger</keyname><forenames>Florian</forenames><affiliation>LITIS</affiliation></author><author><keyname>Berar</keyname><forenames>Maxime</forenames><affiliation>LITIS</affiliation></author><author><keyname>Gasso</keyname><forenames>Gilles</forenames><affiliation>INSA de Rouen</affiliation></author><author><keyname>Rakotomamonjy</keyname><forenames>Alain</forenames><affiliation>INSA de Rouen</affiliation></author></authors><title>Adaptive Canonical Correlation Analysis Based On Matrix Manifolds</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formulate the Canonical Correlation Analysis (CCA) problem
on matrix manifolds. This framework provides a natural way for dealing with
matrix constraints and tools for building efficient algorithms even in an
adaptive setting. Finally, an adaptive CCA algorithm is proposed and applied to
a change detection problem in EEG signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6454</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6454</id><created>2012-06-27</created><authors><author><keyname>Yue</keyname><forenames>Yisong</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Hong</keyname><forenames>Sue Ann</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Guestrin</keyname><forenames>Carlos</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>Hierarchical Exploration for Accelerating Contextual Bandits</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contextual bandit learning is an increasingly popular approach to optimizing
recommender systems via user feedback, but can be slow to converge in practice
due to the need for exploring a large feature space. In this paper, we propose
a coarse-to-fine hierarchical approach for encoding prior knowledge that
drastically reduces the amount of exploration required. Intuitively, user
preferences can be reasonably embedded in a coarse low-dimensional feature
space that can be explored efficiently, requiring exploration in the
high-dimensional space only as necessary. We introduce a bandit algorithm that
explores within this coarse-to-fine spectrum, and prove performance guarantees
that depend on how well the coarse space captures the user's preferences. We
demonstrate substantial improvement over conventional bandit algorithms through
extensive simulation as well as a live user study in the setting of
personalized news recommendation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6455</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6455</id><created>2012-06-27</created><authors><author><keyname>Yu</keyname><forenames>Yaoliang</forenames><affiliation>University of Alberta</affiliation></author><author><keyname>Neufeld</keyname><forenames>James</forenames><affiliation>University of Alberta</affiliation></author><author><keyname>Kiros</keyname><forenames>Ryan</forenames><affiliation>University of Alberta</affiliation></author><author><keyname>Zhang</keyname><forenames>Xinhua</forenames><affiliation>University of Alberta</affiliation></author><author><keyname>Schuurmans</keyname><forenames>Dale</forenames><affiliation>University of Alberta</affiliation></author></authors><title>Regularizers versus Losses for Nonlinear Dimensionality Reduction: A
  Factored View with New Convex Relaxations</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that almost all non-parametric dimensionality reduction
methods can be expressed by a simple procedure: regularized loss minimization
plus singular value truncation. By distinguishing the role of the loss and
regularizer in such a process, we recover a factored perspective that reveals
some gaps in the current literature. Beyond identifying a useful new loss for
manifold unfolding, a key contribution is to derive new convex regularizers
that combine distance maximization with rank reduction. These regularizers can
be applied to any loss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6456</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6456</id><created>2012-06-27</created><authors><author><keyname>Zhou</keyname><forenames>Mingyuan</forenames><affiliation>Duke University</affiliation></author><author><keyname>Li</keyname><forenames>Lingbo</forenames><affiliation>Duke University</affiliation></author><author><keyname>Dunson</keyname><forenames>David</forenames><affiliation>Duke University</affiliation></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames><affiliation>Duke University</affiliation></author></authors><title>Lognormal and Gamma Mixed Negative Binomial Regression</title><categories>stat.AP cs.LG stat.ME</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In regression analysis of counts, a lack of simple and efficient algorithms
for posterior computation has made Bayesian approaches appear unattractive and
thus underdeveloped. We propose a lognormal and gamma mixed negative binomial
(NB) regression model for counts, and present efficient closed-form Bayesian
inference; unlike conventional Poisson models, the proposed approach has two
free parameters to include two different kinds of random effects, and allows
the incorporation of prior information, such as sparsity in the regression
coefficients. By placing a gamma distribution prior on the NB dispersion
parameter r, and connecting a lognormal distribution prior with the logit of
the NB probability parameter p, efficient Gibbs sampling and variational Bayes
inference are both developed. The closed-form updates are obtained by
exploiting conditional conjugacy via both a compound Poisson representation and
a Polya-Gamma distribution based data augmentation approach. The proposed
Bayesian inference can be implemented routinely, while being easily
generalizable to more complex settings involving multivariate dependence
structures. The algorithms are illustrated using real examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6457</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6457</id><created>2012-06-27</created><authors><author><keyname>de Freitas</keyname><forenames>Nando</forenames><affiliation>University of British Columbia</affiliation></author><author><keyname>Smola</keyname><forenames>Alex</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Zoghi</keyname><forenames>Masrour</forenames><affiliation>University of British Columbia</affiliation></author></authors><title>Exponential Regret Bounds for Gaussian Process Bandits with
  Deterministic Observations</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012). arXiv admin note: substantial text overlap with
  arXiv:1203.2177</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the problem of Gaussian process (GP) bandits with
deterministic observations. The analysis uses a branch and bound algorithm that
is related to the UCB algorithm of (Srinivas et al, 2010). For GPs with
Gaussian observation noise, with variance strictly greater than zero, Srinivas
et al proved that the regret vanishes at the approximate rate of
$O(1/\sqrt{t})$, where t is the number of observations. To complement their
result, we attack the deterministic case and attain a much faster exponential
convergence rate. Under some regularity assumptions, we show that the regret
decreases asymptotically according to $O(e^{-\frac{\tau t}{(\ln t)^{d/4}}})$
with high probability. Here, d is the dimension of the search space and tau is
a constant that depends on the behaviour of the objective function near its
global maximum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6458</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6458</id><created>2012-06-27</created><authors><author><keyname>Azimi</keyname><forenames>Javad</forenames><affiliation>Oregon State University</affiliation></author><author><keyname>Fern</keyname><forenames>Alan</forenames><affiliation>Oregon State University</affiliation></author><author><keyname>Zhang-Fern</keyname><forenames>Xiaoli</forenames><affiliation>Oregon State University</affiliation></author><author><keyname>Borradaile</keyname><forenames>Glencora</forenames><affiliation>Oregon State University</affiliation></author><author><keyname>Heeringa</keyname><forenames>Brent</forenames><affiliation>Williams College</affiliation></author></authors><title>Batch Active Learning via Coordinated Matching</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most prior work on active learning of classifiers has focused on sequentially
selecting one unlabeled example at a time to be labeled in order to reduce the
overall labeling effort. In many scenarios, however, it is desirable to label
an entire batch of examples at once, for example, when labels can be acquired
in parallel. This motivates us to study batch active learning, which
iteratively selects batches of $k&gt;1$ examples to be labeled. We propose a novel
batch active learning method that leverages the availability of high-quality
and efficient sequential active-learning policies by attempting to approximate
their behavior when applied for $k$ steps. Specifically, our algorithm first
uses Monte-Carlo simulation to estimate the distribution of unlabeled examples
selected by a sequential policy over $k$ step executions. The algorithm then
attempts to select a set of $k$ examples that best matches this distribution,
leading to a combinatorial optimization problem that we term &quot;bounded
coordinated matching&quot;. While we show this problem is NP-hard in general, we
give an efficient greedy solution, which inherits approximation bounds from
supermodular minimization theory. Our experimental results on eight benchmark
datasets show that the proposed approach is highly effective
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6459</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6459</id><created>2012-06-27</created><authors><author><keyname>Bracegirdle</keyname><forenames>Chris</forenames><affiliation>University College London</affiliation></author><author><keyname>Barber</keyname><forenames>David</forenames><affiliation>University College London</affiliation></author></authors><title>Bayesian Conditional Cointegration</title><categories>cs.CE cs.LG stat.ME</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cointegration is an important topic for time-series, and describes a
relationship between two series in which a linear combination is stationary.
Classically, the test for cointegration is based on a two stage process in
which first the linear relation between the series is estimated by Ordinary
Least Squares. Subsequently a unit root test is performed on the residuals. A
well-known deficiency of this classical approach is that it can lead to
erroneous conclusions about the presence of cointegration. As an alternative,
we present a framework for estimating whether cointegration exists using
Bayesian inference which is empirically superior to the classical approach.
Finally, we apply our technique to model segmented cointegration in which
cointegration may exist only for limited time. In contrast to previous
approaches our model makes no restriction on the number of possible
cointegration segments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6460</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6460</id><created>2012-06-27</created><authors><author><keyname>Doppa</keyname><forenames>Janardhan Rao</forenames><affiliation>Oregon State University</affiliation></author><author><keyname>Fern</keyname><forenames>Alan</forenames><affiliation>Oregon State University</affiliation></author><author><keyname>Tadepalli</keyname><forenames>Prasad</forenames><affiliation>Oregon State University</affiliation></author></authors><title>Output Space Search for Structured Prediction</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a framework for structured prediction based on search in the
space of complete structured outputs. Given a structured input, an output is
produced by running a time-bounded search procedure guided by a learned cost
function, and then returning the least cost output uncovered during the search.
This framework can be instantiated for a wide range of search spaces and search
procedures, and easily incorporates arbitrary structured-prediction loss
functions. In this paper, we make two main technical contributions. First, we
define the limited-discrepancy search space over structured outputs, which is
able to leverage powerful classification learning algorithms to improve the
search space quality. Second, we give a generic cost function learning
approach, where the key idea is to learn a cost function that attempts to mimic
the behavior of conducting searches guided by the true loss function. Our
experiments on six benchmark domains demonstrate that using our framework with
only a small amount of search is sufficient for significantly improving on
state-of-the-art structured-prediction performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6461</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6461</id><created>2012-06-27</created><authors><author><keyname>Azar</keyname><forenames>Mohammad Gheshlaghi</forenames><affiliation>Radboud University</affiliation></author><author><keyname>Munos</keyname><forenames>Remi</forenames><affiliation>INRIA Lille</affiliation></author><author><keyname>Kappen</keyname><forenames>Bert</forenames><affiliation>Radboud University</affiliation></author></authors><title>On the Sample Complexity of Reinforcement Learning with a Generative
  Model</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning the optimal action-value function in the
discounted-reward Markov decision processes (MDPs). We prove a new PAC bound on
the sample-complexity of model-based value iteration algorithm in the presence
of the generative model, which indicates that for an MDP with N state-action
pairs and the discount factor \gamma\in[0,1) only
O(N\log(N/\delta)/((1-\gamma)^3\epsilon^2)) samples are required to find an
\epsilon-optimal estimation of the action-value function with the probability
1-\delta. We also prove a matching lower bound of \Theta
(N\log(N/\delta)/((1-\gamma)^3\epsilon^2)) on the sample complexity of
estimating the optimal action-value function by every RL algorithm. To the best
of our knowledge, this is the first matching result on the sample complexity of
estimating the optimal (action-) value function in which the upper bound
matches the lower bound of RL in terms of N, \epsilon, \delta and 1/(1-\gamma).
Also, both our lower bound and our upper bound significantly improve on the
state-of-the-art in terms of 1/(1-\gamma).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6462</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6462</id><created>2012-06-27</created><authors><author><keyname>Jiang</keyname><forenames>Yun</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Lim</keyname><forenames>Marcus</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames><affiliation>Cornell University</affiliation></author></authors><title>Learning Object Arrangements in 3D Scenes using Human Context</title><categories>cs.LG cs.CV cs.RO stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning object arrangements in a 3D scene. The
key idea here is to learn how objects relate to human poses based on their
affordances, ease of use and reachability. In contrast to modeling
object-object relationships, modeling human-object relationships scales
linearly in the number of objects. We design appropriate density functions
based on 3D spatial features to capture this. We learn the distribution of
human poses in a scene using a variant of the Dirichlet process mixture model
that allows sharing of the density function parameters across the same object
types. Then we can reason about arrangements of the objects in the room based
on these meaningful human poses. In our extensive experiments on 20 different
rooms with a total of 47 objects, our algorithm predicted correct placements
with an average error of 1.6 meters from ground truth. In arranging five real
scenes, it received a score of 4.3/5 compared to 3.7 for the best baseline
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6463</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6463</id><created>2012-06-27</created><authors><author><keyname>Kong</keyname><forenames>Deguang</forenames><affiliation>The University of Texas at Arlington</affiliation></author><author><keyname>Ding</keyname><forenames>Chris H. Q.</forenames><affiliation>The University of Texas at Arlington</affiliation></author><author><keyname>Huang</keyname><forenames>Heng</forenames><affiliation>The University of Texas at Arlington</affiliation></author><author><keyname>Nie</keyname><forenames>Feiping</forenames><affiliation>The University of Texas at Arlington</affiliation></author></authors><title>An Iterative Locally Linear Embedding Algorithm</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Local Linear embedding (LLE) is a popular dimension reduction method. In this
paper, we first show LLE with nonnegative constraint is equivalent to the
widely used Laplacian embedding. We further propose to iterate the two steps in
LLE repeatedly to improve the results. Thirdly, we relax the kNN constraint of
LLE and present a sparse similarity learning algorithm. The final Iterative LLE
combines these three improvements. Extensive experiment results show that
iterative LLE algorithm significantly improve both classification and
clustering results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6464</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6464</id><created>2012-06-27</created><updated>2012-09-04</updated><authors><author><keyname>Martens</keyname><forenames>James</forenames><affiliation>University of Toronto</affiliation></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames><affiliation>University of Toronto</affiliation></author><author><keyname>Swersky</keyname><forenames>Kevin</forenames><affiliation>University of Toronto</affiliation></author></authors><title>Estimating the Hessian by Back-propagating Curvature</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>Amir Globerson</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we develop Curvature Propagation (CP), a general technique for
efficiently computing unbiased approximations of the Hessian of any function
that is computed using a computational graph. At the cost of roughly two
gradient evaluations, CP can give a rank-1 approximation of the whole Hessian,
and can be repeatedly applied to give increasingly precise unbiased estimates
of any or all of the entries of the Hessian. Of particular interest is the
diagonal of the Hessian, for which no general approach is known to exist that
is both efficient and accurate. We show in experiments that CP turns out to
work well in practice, giving very accurate estimates of the Hessian of neural
networks, for example, with a relatively small amount of work. We also apply CP
to Score Matching, where a diagonal of a Hessian plays an integral role in the
Score Matching objective, and where it is usually computed exactly using
inefficient algorithms which do not scale to larger and more complex models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6465</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6465</id><created>2012-06-27</created><authors><author><keyname>Gonen</keyname><forenames>Mehmet</forenames><affiliation>Aalto University</affiliation></author></authors><title>Bayesian Efficient Multiple Kernel Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple kernel learning algorithms are proposed to combine kernels in order
to obtain a better similarity measure or to integrate feature representations
coming from different data sources. Most of the previous research on such
methods is focused on the computational efficiency issue. However, it is still
not feasible to combine many kernels using existing Bayesian approaches due to
their high time complexity. We propose a fully conjugate Bayesian formulation
and derive a deterministic variational approximation, which allows us to
combine hundreds or thousands of kernels very efficiently. We briefly explain
how the proposed method can be extended for multiclass learning and
semi-supervised learning. Experiments with large numbers of kernels on
benchmark data sets show that our inference method is quite fast, requiring
less than a minute. On one bioinformatics and three image recognition data
sets, our method outperforms previously reported results with better
generalization performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6466</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6466</id><created>2012-06-27</created><authors><author><keyname>McAfee</keyname><forenames>Lawrence</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Olukotun</keyname><forenames>Kunle</forenames><affiliation>Stanford University</affiliation></author></authors><title>Utilizing Static Analysis and Code Generation to Accelerate Neural
  Networks</title><categories>cs.NE cs.MS cs.PL</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As datasets continue to grow, neural network (NN) applications are becoming
increasingly limited by both the amount of available computational power and
the ease of developing high-performance applications. Researchers often must
have expert systems knowledge to make their algorithms run efficiently.
Although available computing power increases rapidly each year, algorithm
efficiency is not able to keep pace due to the use of general purpose
compilers, which are not able to fully optimize specialized application
domains. Within the domain of NNs, we have the added knowledge that network
architecture remains constant during training, meaning the architecture's data
structure can be statically optimized by a compiler. In this paper, we present
SONNC, a compiler for NNs that utilizes static analysis to generate optimized
parallel code. We show that SONNC's use of static optimizations make it able to
outperform hand-optimized C++ code by up to 7.8X, and MATLAB code by up to 24X.
Additionally, we show that use of SONNC significantly reduces code complexity
when using structurally sparse networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6467</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6467</id><created>2012-06-27</created><authors><author><keyname>McDowell</keyname><forenames>Luke</forenames><affiliation>U.S. Naval Academy</affiliation></author><author><keyname>Aha</keyname><forenames>David</forenames><affiliation>U.S. Naval Research Laboratory</affiliation></author></authors><title>Semi-Supervised Collective Classification via Hybrid Label
  Regularization</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many classification problems involve data instances that are interlinked with
each other, such as webpages connected by hyperlinks. Techniques for
&quot;collective classification&quot; (CC) often increase accuracy for such data graphs,
but usually require a fully-labeled training graph. In contrast, we examine how
to improve the semi-supervised learning of CC models when given only a
sparsely-labeled graph, a common situation. We first describe how to use novel
combinations of classifiers to exploit the different characteristics of the
relational features vs. the non-relational features. We also extend the ideas
of &quot;label regularization&quot; to such hybrid classifiers, enabling them to leverage
the unlabeled data to bias the learning process. We find that these techniques,
which are efficient and easy to implement, significantly increase accuracy on
three real datasets. In addition, our results explain conflicting findings from
prior related studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6468</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6468</id><created>2012-06-27</created><authors><author><keyname>Mysore</keyname><forenames>Gautham</forenames><affiliation>Adobe Systems</affiliation></author><author><keyname>Sahani</keyname><forenames>Maneesh</forenames><affiliation>University College London</affiliation></author></authors><title>Variational Inference in Non-negative Factorial Hidden Markov Models for
  Efficient Audio Source Separation</title><categories>cs.LG cs.SD stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The past decade has seen substantial work on the use of non-negative matrix
factorization and its probabilistic counterparts for audio source separation.
Although able to capture audio spectral structure well, these models neglect
the non-stationarity and temporal dynamics that are important properties of
audio. The recently proposed non-negative factorial hidden Markov model
(N-FHMM) introduces a temporal dimension and improves source separation
performance. However, the factorial nature of this model makes the complexity
of inference exponential in the number of sound sources. Here, we present a
Bayesian variant of the N-FHMM suited to an efficient variational inference
algorithm, whose complexity is linear in the number of sound sources. Our
algorithm performs comparably to exact inference in the original N-FHMM but is
significantly faster. In typical configurations of the N-FHMM, our method
achieves around a 30x increase in speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6469</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6469</id><created>2012-06-27</created><authors><author><keyname>Salazar</keyname><forenames>Esther</forenames><affiliation>Duke University</affiliation></author><author><keyname>Cain</keyname><forenames>Matthew</forenames><affiliation>Duke University</affiliation></author><author><keyname>Darling</keyname><forenames>Elise</forenames><affiliation>Duke University</affiliation></author><author><keyname>Mitroff</keyname><forenames>Stephen</forenames><affiliation>Duke University</affiliation></author><author><keyname>Carin</keyname><forenames>Lawrence</forenames><affiliation>Duke University</affiliation></author></authors><title>Inferring Latent Structure From Mixed Real and Categorical Relational
  Data</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider analysis of relational data (a matrix), in which the rows
correspond to subjects (e.g., people) and the columns correspond to attributes.
The elements of the matrix may be a mix of real and categorical. Each subject
and attribute is characterized by a latent binary feature vector, and an
inferred matrix maps each row-column pair of binary feature vectors to an
observed matrix element. The latent binary features of the rows are modeled via
a multivariate Gaussian distribution with low-rank covariance matrix, and the
Gaussian random variables are mapped to latent binary features via a probit
link. The same type construction is applied jointly to the columns. The model
infers latent, low-dimensional binary features associated with each row and
each column, as well correlation structure between all rows and between all
columns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6470</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6470</id><created>2012-06-27</created><authors><author><keyname>Kiraly</keyname><forenames>Franz</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Tomioka</keyname><forenames>Ryota</forenames><affiliation>University of Tokyo</affiliation></author></authors><title>A Combinatorial Algebraic Approach for the Identifiability of Low-Rank
  Matrix Completion</title><categories>cs.LG cs.DM cs.NA stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we review the problem of matrix completion and expose its
intimate relations with algebraic geometry, combinatorics and graph theory. We
present the first necessary and sufficient combinatorial conditions for
matrices of arbitrary rank to be identifiable from a set of matrix entries,
yielding theoretical constraints and new algorithms for the problem of matrix
completion. We conclude by algorithmically evaluating the tightness of the
given conditions and algorithms for practically relevant matrix sizes, showing
that the algebraic-combinatoric approach can lead to improvements over
state-of-the-art matrix completion methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6471</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6471</id><created>2012-06-27</created><authors><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames><affiliation>Max Planck Institute for Intelligent Systems</affiliation></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames><affiliation>Max Planck Institute for Intelligent Systems</affiliation></author><author><keyname>Peters</keyname><forenames>Jonas</forenames><affiliation>Max Planck Institute for Intelligent Systems</affiliation></author><author><keyname>Sgouritsa</keyname><forenames>Eleni</forenames><affiliation>Max Planck Institute for Intelligent Systems</affiliation></author><author><keyname>Zhang</keyname><forenames>Kun</forenames><affiliation>Max Planck Institute for Intelligent Systems</affiliation></author><author><keyname>Mooij</keyname><forenames>Joris</forenames><affiliation>Radboud University</affiliation></author></authors><title>On Causal and Anticausal Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012). arXiv admin note: substantial text overlap with
  arXiv:1112.2738</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of function estimation in the case where an
underlying causal model can be inferred. This has implications for popular
scenarios such as covariate shift, concept drift, transfer learning and
semi-supervised learning. We argue that causal knowledge may facilitate some
approaches for a given problem, and rule out others. In particular, we
formulate a hypothesis for when semi-supervised learning can help, and
corroborate it with empirical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6472</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6472</id><created>2012-06-27</created><authors><author><keyname>Merchante</keyname><forenames>Luis Francisco Sanchez</forenames><affiliation>UTC/CNRS</affiliation></author><author><keyname>Grandvalet</keyname><forenames>Yves</forenames><affiliation>UTC/CNRS</affiliation></author><author><keyname>Govaert</keyname><forenames>Gerrad</forenames><affiliation>UTC/CNRS</affiliation></author></authors><title>An Efficient Approach to Sparse Linear Discriminant Analysis</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to the formulation and the resolution of sparse
Linear Discriminant Analysis (LDA). Our proposal, is based on penalized Optimal
Scoring. It has an exact equivalence with penalized LDA, contrary to the
multi-class approaches based on the regression of class indicator that have
been proposed so far. Sparsity is obtained thanks to a group-Lasso penalty that
selects the same features in all discriminant directions. Our experiments
demonstrate that this approach generates extremely parsimonious models without
compromising prediction performances. Besides prediction, the resulting sparse
discriminant directions are also amenable to low-dimensional representations of
data. Our algorithm is highly efficient for medium to large number of
variables, and is thus particularly well suited to the analysis of gene
expression data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6473</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6473</id><created>2012-06-27</created><authors><author><keyname>Silver</keyname><forenames>David</forenames><affiliation>University College London</affiliation></author><author><keyname>Ciosek</keyname><forenames>Kamil</forenames><affiliation>University College London</affiliation></author></authors><title>Compositional Planning Using Optimal Option Models</title><categories>cs.AI cs.LG</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a framework for option model composition. Option
models are temporal abstractions that, like macro-operators in classical
planning, jump directly from a start state to an end state. Prior work has
focused on constructing option models from primitive actions, by intra-option
model learning; or on using option models to construct a value function, by
inter-option planning. We present a unified view of intra- and inter-option
model learning, based on a major generalisation of the Bellman equation. Our
fundamental operation is the recursive composition of option models into other
option models. This key idea enables compositional planning over many levels of
abstraction. We illustrate our framework using a dynamic programming algorithm
that simultaneously constructs optimal option models for multiple subgoals, and
also searches over those option models to provide rapid progress towards other
subgoals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6474</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6474</id><created>2012-06-27</created><authors><author><keyname>Richard</keyname><forenames>Emile</forenames><affiliation>ENS Cachan</affiliation></author><author><keyname>Savalle</keyname><forenames>Pierre-Andre</forenames><affiliation>Ecole Centrale de Paris</affiliation></author><author><keyname>Vayatis</keyname><forenames>Nicolas</forenames><affiliation>ENS Cachan</affiliation></author></authors><title>Estimation of Simultaneously Sparse and Low Rank Matrices</title><categories>cs.DS cs.LG cs.NA stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper introduces a penalized matrix estimation procedure aiming at
solutions which are sparse and low-rank at the same time. Such structures arise
in the context of social networks or protein interactions where underlying
graphs have adjacency matrices which are block-diagonal in the appropriate
basis. We introduce a convex mixed penalty which involves $\ell_1$-norm and
trace norm simultaneously. We obtain an oracle inequality which indicates how
the two effects interact according to the nature of the target matrix. We bound
generalization error in the link prediction problem. We also develop proximal
descent strategies to solve the optimization problem efficiently and evaluate
performance on synthetic and real data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6475</identifier>
 <datestamp>2012-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6475</id><created>2012-06-27</created><updated>2012-09-04</updated><authors><author><keyname>Xiang</keyname><forenames>Qiaoliang</forenames><affiliation>Nanyang Technological University</affiliation></author><author><keyname>Mao</keyname><forenames>Qi</forenames><affiliation>Nanyang Technological University</affiliation></author><author><keyname>Chai</keyname><forenames>Kian Ming</forenames><affiliation>DSO National Laboratories</affiliation></author><author><keyname>Chieu</keyname><forenames>Hai Leong</forenames><affiliation>DSO National Laboratories</affiliation></author><author><keyname>Tsang</keyname><forenames>Ivor</forenames><affiliation>Nanyang Technological University</affiliation></author><author><keyname>Zhao</keyname><forenames>Zhendong</forenames><affiliation>Macquarie University</affiliation></author></authors><title>A Split-Merge Framework for Comparing Clusterings</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>Amir Globerson</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering evaluation measures are frequently used to evaluate the
performance of algorithms. However, most measures are not properly normalized
and ignore some information in the inherent structure of clusterings. We model
the relation between two clusterings as a bipartite graph and propose a general
component-based decomposition formula based on the components of the graph.
Most existing measures are examples of this formula. In order to satisfy
consistency in the component, we further propose a split-merge framework for
comparing clusterings of different data sets. Our framework gives measures that
are conditionally normalized, and it can make use of data point information,
such as feature vectors and pairwise distances. We use an entropy-based
instance of the framework and a coreference resolution data set to demonstrate
empirically the utility of our framework over other measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6476</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6476</id><created>2012-06-27</created><authors><author><keyname>Bellet</keyname><forenames>Aurelien</forenames><affiliation>University of Saint-Etienne</affiliation></author><author><keyname>Habrard</keyname><forenames>Amaury</forenames><affiliation>University of Saint-Etienne</affiliation></author><author><keyname>Sebban</keyname><forenames>Marc</forenames><affiliation>University of Saint-Etienne</affiliation></author></authors><title>Similarity Learning for Provably Accurate Sparse Linear Classification</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the crucial importance of metrics in machine learning
algorithms has led to an increasing interest for optimizing distance and
similarity functions. Most of the state of the art focus on learning
Mahalanobis distances (requiring to fulfill a constraint of positive
semi-definiteness) for use in a local k-NN algorithm. However, no theoretical
link is established between the learned metrics and their performance in
classification. In this paper, we make use of the formal framework of good
similarities introduced by Balcan et al. to design an algorithm for learning a
non PSD linear similarity optimized in a nonlinear feature space, which is then
used to build a global linear classifier. We show that our approach has uniform
stability and derive a generalization bound on the classification error.
Experiments performed on various datasets confirm the effectiveness of our
approach compared to state-of-the-art methods and provide evidence that (i) it
is fast, (ii) robust to overfitting and (iii) produces very sparse classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6477</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6477</id><created>2012-06-27</created><authors><author><keyname>Zhai</keyname><forenames>Yiteng</forenames><affiliation>Nanyang Technological University</affiliation></author><author><keyname>Tan</keyname><forenames>Mingkui</forenames><affiliation>Nanyang Technological University</affiliation></author><author><keyname>Tsang</keyname><forenames>Ivor</forenames><affiliation>Nanyang Technological University</affiliation></author><author><keyname>Ong</keyname><forenames>Yew Soon</forenames><affiliation>Nanyang Technological University</affiliation></author></authors><title>Discovering Support and Affiliated Features from Very High Dimensions</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel learning paradigm is presented to automatically
identify groups of informative and correlated features from very high
dimensions. Specifically, we explicitly incorporate correlation measures as
constraints and then propose an efficient embedded feature selection method
using recently developed cutting plane strategy. The benefits of the proposed
algorithm are two-folds. First, it can identify the optimal discriminative and
uncorrelated feature subset to the output labels, denoted here as Support
Features, which brings about significant improvements in prediction performance
over other state of the art feature selection methods considered in the paper.
Second, during the learning process, the underlying group structures of
correlated features associated with each support feature, denoted as Affiliated
Features, can also be discovered without any additional cost. These affiliated
features serve to improve the interpretations on the learning tasks. Extensive
empirical studies on both synthetic and very high dimensional real-world
datasets verify the validity and efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6478</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6478</id><created>2012-06-27</created><authors><author><keyname>Zhang</keyname><forenames>Yi</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Schneider</keyname><forenames>Jeff</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>Maximum Margin Output Coding</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study output coding for multi-label prediction. For a
multi-label output coding to be discriminative, it is important that codewords
for different label vectors are significantly different from each other. In the
meantime, unlike in traditional coding theory, codewords in output coding are
to be predicted from the input, so it is also critical to have a predictable
label encoding.
  To find output codes that are both discriminative and predictable, we first
propose a max-margin formulation that naturally captures these two properties.
We then convert it to a metric learning formulation, but with an exponentially
large number of constraints as commonly encountered in structured prediction
problems. Without a label structure for tractable inference, we use
overgenerating (i.e., relaxation) techniques combined with the cutting plane
method for optimization.
  In our empirical study, the proposed output coding scheme outperforms a
variety of existing multi-label prediction methods for image, text and music
classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6479</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6479</id><created>2012-06-27</created><authors><author><keyname>Balasubramanian</keyname><forenames>Krishnakumar</forenames><affiliation>Georgia Institute of Technology</affiliation></author><author><keyname>Lebanon</keyname><forenames>Guy</forenames><affiliation>Georgia Institute of Technology</affiliation></author></authors><title>The Landmark Selection Method for Multiple Output Prediction</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional modeling x \to y is a central problem in machine learning. A
substantial research effort is devoted to such modeling when x is high
dimensional. We consider, instead, the case of a high dimensional y, where x is
either low dimensional or high dimensional. Our approach is based on selecting
a small subset y_L of the dimensions of y, and proceed by modeling (i) x \to
y_L and (ii) y_L \to y. Composing these two models, we obtain a conditional
model x \to y that possesses convenient statistical properties. Multi-label
classification and multivariate regression experiments on several datasets show
that this model outperforms the one vs. all approach as well as several
sophisticated multiple output prediction methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6480</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6480</id><created>2012-06-27</created><authors><author><keyname>Geist</keyname><forenames>Matthieu</forenames><affiliation>Supelec</affiliation></author><author><keyname>Scherrer</keyname><forenames>Bruno</forenames><affiliation>INRIA Nancy</affiliation></author><author><keyname>Lazaric</keyname><forenames>Alessandro</forenames><affiliation>INRIA Lille</affiliation></author><author><keyname>Ghavamzadeh</keyname><forenames>Mohammad</forenames><affiliation>INRIA Lille</affiliation></author></authors><title>A Dantzig Selector Approach to Temporal Difference Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LSTD is a popular algorithm for value function approximation. Whenever the
number of features is larger than the number of samples, it must be paired with
some form of regularization. In particular, L1-regularization methods tend to
perform feature selection by promoting sparsity, and thus, are well-suited for
high-dimensional problems. However, since LSTD is not a simple regression
algorithm, but it solves a fixed--point problem, its integration with
L1-regularization is not straightforward and might come with some drawbacks
(e.g., the P-matrix assumption for LASSO-TD). In this paper, we introduce a
novel algorithm obtained by integrating LSTD with the Dantzig Selector. We
investigate the performance of the proposed algorithm and its relationship with
the existing regularized approaches, and show how it addresses some of their
drawbacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6481</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6481</id><created>2012-06-27</created><authors><author><keyname>Guo</keyname><forenames>Yuhong</forenames><affiliation>Temple University</affiliation></author><author><keyname>Xiao</keyname><forenames>Min</forenames><affiliation>Temple University</affiliation></author></authors><title>Cross Language Text Classification via Subspace Co-Regularized
  Multi-View Learning</title><categories>cs.CL cs.IR cs.LG</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many multilingual text classification problems, the documents in different
languages often share the same set of categories. To reduce the labeling cost
of training a classification model for each individual language, it is
important to transfer the label knowledge gained from one language to another
language by conducting cross language classification. In this paper we develop
a novel subspace co-regularized multi-view learning method for cross language
text classification. This method is built on parallel corpora produced by
machine translation. It jointly minimizes the training error of each classifier
in each language while penalizing the distance between the subspace
representations of parallel documents. Our empirical study on a large set of
cross language text classification tasks shows the proposed method consistently
outperforms a number of inductive methods, domain adaptation methods, and
multi-view learning methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6482</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6482</id><created>2012-06-27</created><authors><author><keyname>Zhai</keyname><forenames>Ke</forenames><affiliation>University of Maryland</affiliation></author><author><keyname>Hu</keyname><forenames>Yuening</forenames><affiliation>University of Maryland</affiliation></author><author><keyname>Williamson</keyname><forenames>Sinead</forenames><affiliation>Carnegie Mellon University</affiliation></author><author><keyname>Boyd-Graber</keyname><forenames>Jordan</forenames><affiliation>University of Maryland</affiliation></author></authors><title>Modeling Images using Transformed Indian Buffet Processes</title><categories>cs.CV cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latent feature models are attractive for image modeling, since images
generally contain multiple objects. However, many latent feature models ignore
that objects can appear at different locations or require pre-segmentation of
images. While the transformed Indian buffet process (tIBP) provides a method
for modeling transformation-invariant features in unsegmented binary images,
its current form is inappropriate for real images because of its computational
cost and modeling assumptions. We combine the tIBP with likelihoods appropriate
for real images and develop an efficient inference, using the cross-correlation
between images and features, that is theoretically and empirically faster than
existing inference techniques. Our method discovers reasonable components and
achieve effective image reconstruction in natural images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6483</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6483</id><created>2012-06-27</created><authors><author><keyname>Kriege</keyname><forenames>Nils</forenames><affiliation>TU Dortmund</affiliation></author><author><keyname>Mutzel</keyname><forenames>Petra</forenames><affiliation>TU Dortmund</affiliation></author></authors><title>Subgraph Matching Kernels for Attributed Graphs</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose graph kernels based on subgraph matchings, i.e.
structure-preserving bijections between subgraphs. While recently proposed
kernels based on common subgraphs (Wale et al., 2008; Shervashidze et al.,
2009) in general can not be applied to attributed graphs, our approach allows
to rate mappings of subgraphs by a flexible scoring scheme comparing vertex and
edge attributes by kernels. We show that subgraph matching kernels generalize
several known kernels. To compute the kernel we propose a graph-theoretical
algorithm inspired by a classical relation between common subgraphs of two
graphs and cliques in their product graph observed by Levi (1973). Encouraging
experimental results on a classification task of real-world graphs are
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6484</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6484</id><created>2012-06-27</created><authors><author><keyname>Makino</keyname><forenames>Takaki</forenames><affiliation>University of Tokyo</affiliation></author><author><keyname>Takeuchi</keyname><forenames>Johane</forenames><affiliation>Honda Research Institute Japan</affiliation></author></authors><title>Apprenticeship Learning for Model Parameters of Partially Observable
  Environments</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider apprenticeship learning, i.e., having an agent learn a task by
observing an expert demonstrating the task in a partially observable
environment when the model of the environment is uncertain. This setting is
useful in applications where the explicit modeling of the environment is
difficult, such as a dialogue system. We show that we can extract information
about the environment model by inferring action selection process behind the
demonstration, under the assumption that the expert is choosing optimal actions
based on knowledge of the true model of the target environment. Proposed
algorithms can achieve more accurate estimates of POMDP parameters and better
policies from a short demonstration, compared to methods that learns only from
the reaction from the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6485</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6485</id><created>2012-06-27</created><authors><author><keyname>Painter-Wakefield</keyname><forenames>Christopher</forenames><affiliation>Duke University</affiliation></author><author><keyname>Parr</keyname><forenames>Ronald</forenames><affiliation>Duke University</affiliation></author></authors><title>Greedy Algorithms for Sparse Reinforcement Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection and regularization are becoming increasingly prominent
tools in the efforts of the reinforcement learning (RL) community to expand the
reach and applicability of RL. One approach to the problem of feature selection
is to impose a sparsity-inducing form of regularization on the learning method.
Recent work on $L_1$ regularization has adapted techniques from the supervised
learning literature for use with RL. Another approach that has received renewed
attention in the supervised learning community is that of using a simple
algorithm that greedily adds new features. Such algorithms have many of the
good properties of the $L_1$ regularization methods, while also being extremely
efficient and, in some cases, allowing theoretical guarantees on recovery of
the true form of a sparse target function from sampled data. This paper
considers variants of orthogonal matching pursuit (OMP) applied to
reinforcement learning. The resulting algorithms are analyzed and compared
experimentally with existing $L_1$ regularized approaches. We demonstrate that
perhaps the most natural scenario in which one might hope to achieve sparse
recovery fails; however, one variant, OMP-BRM, provides promising theoretical
guarantees under certain assumptions on the feature dictionary. Another
variant, OMP-TD, empirically outperforms prior methods both in approximation
accuracy and efficiency on several benchmark problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6486</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6486</id><created>2012-06-27</created><authors><author><keyname>Passos</keyname><forenames>Alexandre</forenames><affiliation>UMass Amherst</affiliation></author><author><keyname>Rai</keyname><forenames>Piyush</forenames><affiliation>University of Utah</affiliation></author><author><keyname>Wainer</keyname><forenames>Jacques</forenames><affiliation>University of Campinas</affiliation></author><author><keyname>Daume</keyname><forenames>Hal</forenames><suffix>III</suffix><affiliation>University of Maryland</affiliation></author></authors><title>Flexible Modeling of Latent Task Structures in Multitask Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multitask learning algorithms are typically designed assuming some fixed, a
priori known latent structure shared by all the tasks. However, it is usually
unclear what type of latent task structure is the most appropriate for a given
multitask learning problem. Ideally, the &quot;right&quot; latent task structure should
be learned in a data-driven manner. We present a flexible, nonparametric
Bayesian model that posits a mixture of factor analyzers structure on the
tasks. The nonparametric aspect makes the model expressive enough to subsume
many existing models of latent task structures (e.g, mean-regularized tasks,
clustered tasks, low-rank or linear/non-linear subspace assumption on tasks,
etc.). Moreover, it can also learn more general task structures, addressing the
shortcomings of such models. We present a variational inference algorithm for
our model. Experimental results on synthetic and real-world datasets, on both
regression and classification problems, demonstrate the effectiveness of the
proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6487</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6487</id><created>2012-06-27</created><authors><author><keyname>Bartok</keyname><forenames>Gabor</forenames><affiliation>University of Alberta</affiliation></author><author><keyname>Zolghadr</keyname><forenames>Navid</forenames><affiliation>University of Alberta</affiliation></author><author><keyname>Szepesvari</keyname><forenames>Csaba</forenames><affiliation>University of Alberta</affiliation></author></authors><title>An Adaptive Algorithm for Finite Stochastic Partial Monitoring</title><categories>cs.LG cs.GT stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new anytime algorithm that achieves near-optimal regret for any
instance of finite stochastic partial monitoring. In particular, the new
algorithm achieves the minimax regret, within logarithmic factors, for both
&quot;easy&quot; and &quot;hard&quot; problems. For easy problems, it additionally achieves
logarithmic individual regret. Most importantly, the algorithm is adaptive in
the sense that if the opponent strategy is in an &quot;easy region&quot; of the strategy
space then the regret grows as if the problem was easy. As an implication, we
show that under some reasonable additional assumptions, the algorithm enjoys an
O(\sqrt{T}) regret in Dynamic Pricing, proven to be hard by Bartok et al.
(2011).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6488</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6488</id><created>2012-06-27</created><authors><author><keyname>Liu</keyname><forenames>Han</forenames><affiliation>Johns Hopkins University</affiliation></author><author><keyname>Han</keyname><forenames>Fang</forenames><affiliation>Johns Hopkins University</affiliation></author><author><keyname>Yuan</keyname><forenames>Ming</forenames><affiliation>Georgia Institute of Technology</affiliation></author><author><keyname>Lafferty</keyname><forenames>John</forenames><affiliation>University of Chicago</affiliation></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames><affiliation>Carnegie Mellon University</affiliation></author></authors><title>The Nonparanormal SKEPTIC</title><categories>stat.ME cs.LG stat.ML</categories><comments>Appears in Proceedings of the 29th International Conference on
  Machine Learning (ICML 2012)</comments><proxy>icml2012</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a semiparametric approach, named nonparanormal skeptic, for
estimating high dimensional undirected graphical models. In terms of modeling,
we consider the nonparanormal family proposed by Liu et al (2009). In terms of
estimation, we exploit nonparametric rank-based correlation coefficient
estimators including the Spearman's rho and Kendall's tau. In high dimensional
settings, we prove that the nonparanormal skeptic achieves the optimal
parametric rate of convergence in both graph and parameter estimation. This
result suggests that the nonparanormal graphical models are a safe replacement
of the Gaussian graphical models, even when the data are Gaussian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6504</identifier>
 <datestamp>2015-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6504</id><created>2012-06-27</created><updated>2013-02-14</updated><authors><author><keyname>Boudes</keyname><forenames>Pierre</forenames></author><author><keyname>Mazza</keyname><forenames>Damiano</forenames></author><author><keyname>de Falco</keyname><forenames>Lorenzo Tortora</forenames></author></authors><title>An Abstract Approach to Stratification in Linear Logic</title><categories>cs.LO</categories><msc-class>03F52</msc-class><journal-ref>Information and Computation, 241:32-61, 2015</journal-ref><doi>10.1016/j.ic.2014.10.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the notion of stratification, as used in subsystems of linear logic
with low complexity bounds on the cut-elimination procedure (the so-called
light logics), from an abstract point of view, introducing a logical system in
which stratification is handled by a separate modality. This modality, which is
a generalization of the paragraph modality of Girard's light linear logic,
arises from a general categorical construction applicable to all models of
linear logic. We thus learn that stratification may be formulated independently
of exponential modalities; when it is forced to be connected to exponential
modalities, it yields interesting complexity properties. In particular, from
our analysis stem three alternative reformulations of Baillot and Mazza's
linear logic by levels: one geometric, one interactive, and one semantic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6514</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6514</id><created>2012-06-27</created><authors><author><keyname>Bejuri</keyname><forenames>Wan Mohd Yaakob Wan</forenames></author><author><keyname>Mohamad</keyname><forenames>Mohd Murtadha</forenames></author><author><keyname>Sapri</keyname><forenames>Maimunah</forenames></author><author><keyname>Rosly</keyname><forenames>Mohd Adly</forenames></author></authors><title>Investigation of Color Constancy for Ubiquitous Wireless LAN/Camera
  Positioning: An Initial Outcome</title><categories>cs.CV cs.HC</categories><comments>International Journal of Advancements in Computing Technology (IJACT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper present our color constancy investigation in the hybridization of
Wireless LAN and Camera positioning in the mobile phone. Five typical color
constancy schemes are analyzed in different location environment. The results
can be used to combine with RF signals from Wireless LAN positioning by using
model fitting approach in order to establish absolute positioning output. There
is no conventional searching algorithm required, thus it is expected to reduce
the complexity of computation. Finally we present our preliminary results to
illustrate the indoor positioning algorithm performance evaluation for an
indoor environment set-up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6528</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6528</id><created>2012-06-27</created><updated>2012-08-09</updated><authors><author><keyname>Belovs</keyname><forenames>Aleksandrs</forenames></author><author><keyname>Spalek</keyname><forenames>Robert</forenames></author></authors><title>Adversary Lower Bound for the k-sum Problem</title><categories>quant-ph cs.CC</categories><comments>10 pages, minor changes in v2. Extended and simplified version of an
  earlier preprint of one of the authors arXiv:1204.5074</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a tight quantum query lower bound $\Omega(n^{k/(k+1)})$ for the
problem of deciding whether there exist $k$ numbers among $n$ that sum up to a
prescribed number, provided that the alphabet size is sufficiently large.
  This is an extended and simplified version of an earlier preprint of one of
the authors arXiv:1204.5074.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6541</identifier>
 <datestamp>2013-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6541</id><created>2012-06-27</created><updated>2013-06-14</updated><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author></authors><title>A Low-Depth Monotone Function that is not an Approximate Junta</title><categories>cs.DM</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We provide an example of a monotone Boolean function on the hypercube given
by a low depth decision tree that is not well approximated by any k-junta for
small k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6544</identifier>
 <datestamp>2014-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6544</id><created>2012-06-27</created><updated>2014-02-20</updated><authors><author><keyname>Berend</keyname><forenames>Daniel</forenames></author><author><keyname>Harremo&#xeb;s</keyname><forenames>Peter</forenames></author><author><keyname>Kontorovich</keyname><forenames>Aryeh</forenames></author></authors><title>Minimum KL-divergence on complements of $L_1$ balls</title><categories>cs.IT math.IT</categories><comments>A previous version had the title &quot;A Reverse Pinsker Inequality&quot;</comments><msc-class>60F10, 94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pinsker's widely used inequality upper-bounds the total variation distance
$||P-Q||_1$ in terms of the Kullback-Leibler divergence $D(P||Q)$. Although in
general a bound in the reverse direction is impossible, in many applications
the quantity of interest is actually $D^*(P,\eps)$ --- defined, for an
arbitrary fixed $P$, as the infimum of $D(P||Q)$ over all distributions $Q$
that are $\eps$-far away from $P$ in total variation. We show that
$D^*(P,\eps)\le C\eps^2 + O(\eps^3)$, where $C=C(P)=1/2$ for &quot;balanced&quot;
distributions, thereby providing a kind of reverse Pinsker inequality. An
application to large deviations is given, and some of the structural results
may be of independent interest. Keywords: Pinsker inequality, Sanov's theorem,
large deviations
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6557</identifier>
 <datestamp>2012-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6557</id><created>2012-06-27</created><authors><author><keyname>Liu</keyname><forenames>Tingyu</forenames></author><author><keyname>Cheng</keyname><forenames>Yalong</forenames></author><author><keyname>Ni</keyname><forenames>Zhonghua</forenames></author></authors><title>Mining Event Logs to Support Workflow Resource Allocation</title><categories>cs.SE cs.DB</categories><comments>T. Liu et al., Mining event logs to support workflow resource
  allocation, Knowl. Based Syst. (2012), http://dx.doi.org/
  10.1016/j.knosys.2012.05.010</comments><acm-class>H.4.1; H.4.2; I.2; H.2.8; J.1</acm-class><journal-ref>Knowledge-based Systems 35(2012) 320-331</journal-ref><doi>10.1016/j.knosys.2012.05.010</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Workflow technology is widely used to facilitate the business process in
enterprise information systems (EIS), and it has the potential to reduce design
time, enhance product quality and decrease product cost. However, significant
limitations still exist: as an important task in the context of workflow, many
present resource allocation operations are still performed manually, which are
time-consuming. This paper presents a data mining approach to address the
resource allocation problem (RAP) and improve the productivity of workflow
resource management. Specifically, an Apriori-like algorithm is used to find
the frequent patterns from the event log, and association rules are generated
according to predefined resource allocation constraints. Subsequently, a
correlation measure named lift is utilized to annotate the negatively
correlated resource allocation rules for resource reservation. Finally, the
rules are ranked using the confidence measures as resource allocation rules.
Comparative experiments are performed using C4.5, SVM, ID3, Na\&quot;ive Bayes and
the presented approach, and the results show that the presented approach is
effective in both accuracy and candidate resource recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6561</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6561</id><created>2012-06-28</created><authors><author><keyname>Hassan</keyname><forenames>Ahmed Hassan M.</forenames></author><author><keyname>Dai</keyname><forenames>Bin</forenames></author><author><keyname>Huang</keyname><forenames>Benxiong</forenames></author></authors><title>Regenerative and Adaptive schemes Based on Network Coding for Wireless
  Relay Network</title><categories>cs.IT math.IT</categories><comments>11 pages, 8 figures, International Journal of Computer Networks &amp;
  Communications (IJCNC), Vol.4, No.3, May 2012</comments><doi>10.5121/ijcnc.2012.4305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent technological advances in wireless communications offer new
opportunities and challenges for relay network.To enhance system performance,
Demodulate-Network Coding (Dm-NC) scheme has been examined at relay node; it
works directly to De-map the received signals and after that forward the
mixture to the destination. Simulation analysis has been proven that the
performance of Dm-NC has superiority over analog-NC. In addition, the
Quantize-Decode-NC scheme (QDF-NC) has been introduced. The presented
simulation results clearly provide that the QDF-NC perform better than
analog-NC. The toggle between analogNC and QDF-NC is simulated in order to
investigate delay and power consumption reduction at relay node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6565</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6565</id><created>2012-06-28</created><authors><author><keyname>Guha</keyname><forenames>Shibashis</forenames></author><author><keyname>Krishna</keyname><forenames>Shankara Narayanan</forenames></author></authors><title>Game Characterizations of Timed Relations for Timed Automata Processes</title><categories>cs.FL cs.LO</categories><comments>20 pages</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we design the game semantics for timed equivalences and
preorders of timed processes. The timed games corresponding to the various
timed relations form a hierarchy. These games are similar to Stirling's
bisimulation games. If it is the case that the existence of a winning strategy
for the defender in a game ${\cal G}_1$ implies that there exists a winning
strategy for the defender in another game ${\cal G}_2$, then the relation that
corresponds to ${\cal G}_1$ is stronger than the relation corresponding to
${\cal G}_2$. The game hierarchy also throws light into several timed relations
that are not considered in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6570</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6570</id><created>2012-06-28</created><updated>2012-06-29</updated><authors><author><keyname>Liu</keyname><forenames>Jingwei</forenames></author></authors><title>Extension of Three-Variable Counterfactual Casual Graphic Model: from
  Two-Value to Three-Value Random Variable</title><categories>stat.ME cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The extension of counterfactual causal graphic model with three variables of
vertex set in directed acyclic graph (DAG) is discussed in this paper by
extending two- value distribution to three-value distribution of the variables
involved in DAG. Using the conditional independence as ancillary information, 6
kinds of extension counterfactual causal graphic models with some variables are
extended from two-value distribution to three-value distribution and the
sufficient conditions of identifiability are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6573</identifier>
 <datestamp>2014-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6573</id><created>2012-06-28</created><updated>2014-03-14</updated><authors><author><keyname>Galliani</keyname><forenames>Pietro</forenames></author></authors><title>Dialetheism, Game Theoretic Semantics, and Paraconsistent Team Semantics</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a variant of Dependence Logic in which truth is defined not in
terms of existence of winning strategies for the Proponent (Eloise) in a
semantic game, but in terms of lack of winning strategies for the Opponent
(Abelard). We show that this language is a conservative but paraconsistent
extension of First Order Logic, that its validity problem can be reduced to
that of First Order Logic, that it capable of expressing its own truth and
validity predicates, and that it is expressively equivalent to Universal Second
Order Logic. Furthermore, we prove that a Paraconsistent Non-dependence Logic
formula is consistent if and only if it is equivalent to some First Order Logic
sentence; and we show that, on the other hand, all Paraconsistent Dependence
Logic sentences are equivalent to some First Order sentence with respect to
truth (but not necessarily with respect to falsity).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6584</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6584</id><created>2012-06-28</created><authors><author><keyname>Akhtman</keyname><forenames>Yosef</forenames></author><author><keyname>Maunder</keyname><forenames>Robert G.</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>An Approximate Coding-Rate Versus Minimum Distance Formula for Binary
  Codes</title><categories>cs.IT math.IT</categories><comments>4 pages, 4 figures. Earlier version was presented at IEEE VTC'09
  Fall, Anchorage, Alaska, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We devise an analytically simple as well as invertible approximate
expression, which describes the relation between the minimum distance of a
binary code and the corresponding maximum attainable code-rate. For example,
for a rate-(1/4), length-256 binary code the best known bounds limit the
attainable minimum distance to 65&lt;d(n=256,k=64)&lt;90, while our solution yields
d(n=256,k=64)=74.4. The proposed formula attains the approximation accuracy
within the rounding error for ~97% of (n,k) scenarios, where the exact value of
the minimum distance is known. The results provided may be utilized for the
analysis and design of efficient communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6588</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6588</id><created>2012-06-28</created><authors><author><keyname>Suvakov</keyname><forenames>Milovan</forenames></author><author><keyname>Mitrovic</keyname><forenames>Marija</forenames></author><author><keyname>Gligorijevic</keyname><forenames>Vladimir</forenames></author><author><keyname>Tadic</keyname><forenames>Bosiljka</forenames></author></authors><title>How the online social networks are used: Dialogs-based structure of
  MySpace</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages, 12 figures (resized to 50KB)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative study of collective dynamics in online social networks is a new
challenge based on the abundance of empirical data. Conclusions, however, may
depend on factors as user's psychology profiles and their reasons to use the
online contacts. In this paper we have compiled and analyzed two datasets from
\texttt{MySpace}. The data contain networked dialogs occurring within a
specified time depth, high temporal resolution, and texts of messages, in which
the emotion valence is assessed by using SentiStrength classifier. Performing a
comprehensive analysis we obtain three groups of results: Dynamic topology of
the dialogs-based networks have characteristic structure with Zipf's
distribution of communities, low link reciprocity, and disassortative
correlations. Overlaps supporting &quot;weak-ties&quot; hypothesis are found to follow
the laws recently conjectured for online games. Long-range temporal
correlations and persistent fluctuations occur in the time series of messages
carrying positive (negative) emotion. Patterns of user communications have
dominant positive emotion (attractiveness) and strong impact of circadian
cycles and nteractivity times longer than one day. Taken together, these
results give a new insight into functioning of the online social networks and
unveil importance of the amount of information and emotion that is communicated
along the social links. (All data used in this study are fully anonymized.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6605</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6605</id><created>2012-06-28</created><authors><author><keyname>Georgakopoulos</keyname><forenames>Agelos</forenames></author></authors><title>A Tractable Variant of Cover Time</title><categories>math.CO cs.DM</categories><msc-class>05C81</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a variant of the cover time of a graph, called cover cost, in
which the cost of a step is proportional to the number of yet uncovered
vertices. It turns out that cover cost is more tractable than cover time; we
provide an $O(n^4)$ algorithm for its computation, as well as some explicit
formulae. The two values are not very far from each other, and so cover cost
might be a useful tool in the study of cover time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6606</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6606</id><created>2012-06-28</created><authors><author><keyname>Kakkonen</keyname><forenames>T.</forenames></author><author><keyname>Myller</keyname><forenames>N.</forenames></author></authors><title>A Sampling-based Tool for Plagiarism Detection in Student Texts</title><categories>cs.CY</categories><comments>Proceedings of the 8th European Conference on e-Learning, Bari,
  Italy, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces AntiPlag, an advanced plagiarism detection tool
intended for use on student texts. It is capable of both hermetic detection
that scrutinizes only local collections of documents (other students' texts and
lecture materials, for example) and web plagiarism detection, in which the aim
is at identifying instances of plagiarism that have been sourced from the
Internet. The main feature of the system is the sampling-based web plagiarism
detection, a novel approach to plagiarism detection that is based on combining
web and hermetic search technologies. The system uses standard web search
engines to locate documents on the Internet that might have been used as
sources of plagiarism by the writer of a text. During this sampling phase, the
suspected sources are downloaded, converted to ASCII text and saved to the
local database so that they can be later processed by using the hermetic
detection methods. We evaluated the system by using a test set that contained
instances of verbatim copying as well as texts in which plagiarism was
concealed by minor editing, replacing words with synonyms and by paraphrasing.
We compared the results achieved by AntiPlag to an earlier evaluation study of
four web plagiarism detection systems, SafeAssignment, TurnitIn, EVE2 and
Plagiarism-Finder. AntiPlag performed better than any of these systems,
achieving the accuracy 95.8% over all the test items.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6612</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6612</id><created>2012-06-28</created><authors><author><keyname>Kakkonen</keyname><forenames>T.</forenames></author></authors><title>TexComp - A Text Complexity Analyzer for Student Texts</title><categories>cs.CY</categories><comments>Proceedings of the 12th International Conference on Interactive
  Computer-aided Learning, Villach, Austria, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a method for providing feedback about the degree of
complexity that is present in particular texts. Both the method and the
software tool called TexComp are designed for use during the assessment of
student compositions (such as essays and theses). The method is based on a
cautious approach to the application of readability and lexical diversity
formulas for reasons that are analyzed in detail in this paper. We evaluated
the tool by using USE and BAWE, two corpora of texts that originate from
students who use English as a medium of instruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6613</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6613</id><created>2012-06-28</created><authors><author><keyname>Kakkonen</keyname><forenames>T.</forenames></author><author><keyname>Sutinen</keyname><forenames>E.</forenames></author></authors><title>Semi-automatic Assessment Model of Student Texts - Pedagogical
  Foundations</title><categories>cs.CY</categories><comments>Proceedings of the 12th International Conference on Interactive
  Computer-aided Learning, Villach, Austria, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the concept of the semi-automatic assessment of student
texts that aims at offering the twin benefits of fully automatic grading and
feedback together with the advantages that can be provided by human assessors.
This paper concentrates on the pedagogical foundations of the model by
demonstrating how the relevant findings in research into written composition
and writing education have been taken into account in the model design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6646</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6646</id><created>2012-06-28</created><authors><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author><author><keyname>Teja</keyname><forenames>B. Palvali</forenames></author></authors><title>Aggregate Skyline Join Queries: Skylines with Aggregate Operations over
  Multiple Relations</title><categories>cs.DB</categories><comments>Best student paper award; COMAD 2010 (International Conference on
  Management of Data)</comments><acm-class>H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multi-criteria decision making, which is possible with the advent of
skyline queries, has been applied in many areas. Though most of the existing
research is concerned with only a single relation, several real world
applications require finding the skyline set of records over multiple
relations. Consequently, the join operation over skylines where the preferences
are local to each relation, has been proposed. In many of those cases, however,
the join often involves performing aggregate operations among some of the
attributes from the different relations. In this paper, we introduce such
queries as &quot;aggregate skyline join queries&quot;. Since the naive algorithm is
impractical, we propose three algorithms to efficiently process such queries.
The algorithms utilize certain properties of skyline sets, and processes the
skylines as much as possible locally before computing the join. Experiments
with real and synthetic datasets exhibit the practicality and scalability of
the algorithms with respect to the cardinality and dimensionality of the
relations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6648</identifier>
 <datestamp>2013-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6648</id><created>2012-06-28</created><updated>2013-05-17</updated><authors><author><keyname>Mazo</keyname><forenames>Manuel</forenames><suffix>Jr</suffix></author><author><keyname>Cao</keyname><forenames>Ming</forenames></author></authors><title>Asynchronous Decentralized Event-triggered Control</title><categories>math.OC cs.SY</categories><comments>17 pages, 2 figures</comments><msc-class>93C10, 93C30, 93C57, 93C95</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an approach to the implementation of controllers
with decentralized strategies triggering controller updates. We consider
set-ups with a central node in charge of the computation of the control
commands, and a set of not co-located sensors providing measurements to the
controller node. The solution we propose does not require measurements from the
sensors to be synchronized in time. The sensors in our proposal provide
measurements in an aperiodic way triggered by local conditions. Furthermore, in
the proposed implementation (most of) the communication between nodes requires
only the exchange of one bit of information (per controller update), which
could aid in reducing transmission delays and as a secondary effect result in
fewer transmissions being triggered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6651</identifier>
 <datestamp>2012-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6651</id><created>2012-06-28</created><authors><author><keyname>Lee</keyname><forenames>Sang Hoon</forenames></author><author><keyname>Holme</keyname><forenames>Petter</forenames></author></authors><title>Geometric properties of graph layouts optimized for greedy navigation</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Phys. Rev. E 86, 067103 (2012)</journal-ref><doi>10.1103/PhysRevE.86.067103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The graph layouts used for complex network studies have been mainly been
developed to improve visualization. If we interpret the layouts in metric
spaces such as Euclidean ones, however, the embedded spatial information can be
a valuable cue for various purposes. In this work, we focus on the navigational
properties of spatial graphs. We use an recently user-centric navigation
protocol to explore spatial layouts of complex networks that are optimal for
navigation. These layouts are generated with a simple simulated annealing
optimization technique. We compared these layouts to others targeted at better
visualization. We discuss the spatial statistical properties of the optimized
layouts for better navigability and its implication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6661</identifier>
 <datestamp>2012-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6661</id><created>2012-06-28</created><updated>2012-10-21</updated><authors><author><keyname>Aparicio-Monforte</keyname><forenames>Ainhoa</forenames></author><author><keyname>Compoint</keyname><forenames>Elie</forenames></author><author><keyname>Weil</keyname><forenames>Jacques-Arthur</forenames></author></authors><title>A Characterization of Reduced Forms of Linear Differential Systems</title><categories>math.CA cs.SC math.RT</categories><comments>To appear in : Journal of Pure and Applied Algebra</comments><msc-class>34M03, 34M15, 34M25, 34Mxx, 20Gxx, 17B45, 17B80, 34A05, 34A26, 34A99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A differential system $[A] : \; Y'=AY$, with $A\in \mathrm{Mat}(n, \bar{k})$
is said to be in reduced form if $A\in \mathfrak{g}(\bar{k})$ where
$\mathfrak{g}$ is the Lie algebra of the differential Galois group $G$ of
$[A]$. In this article, we give a constructive criterion for a system to be in
reduced form. When $G$ is reductive and unimodular, the system $[A]$ is in
reduced form if and only if all of its invariants (rational solutions of
appropriate symmetric powers) have constant coefficients (instead of rational
functions). When $G$ is non-reductive, we give a similar characterization via
the semi-invariants of $G$. In the reductive case, we propose a decision
procedure for putting the system into reduced form which, in turn, gives a
constructive proof of the classical Kolchin-Kovacic reduction theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6679</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6679</id><created>2012-06-28</created><updated>2014-07-28</updated><authors><author><keyname>Salimans</keyname><forenames>Tim</forenames></author><author><keyname>Knowles</keyname><forenames>David A.</forenames></author></authors><title>Fixed-Form Variational Posterior Approximation through Stochastic Linear
  Regression</title><categories>stat.CO cs.CV stat.ML</categories><msc-class>62F15</msc-class><journal-ref>Bayesian Analysis, Volume 8, Number 4 (2013), 837-882</journal-ref><doi>10.1214/13-BA858</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a general algorithm for approximating nonstandard Bayesian
posterior distributions. The algorithm minimizes the Kullback-Leibler
divergence of an approximating distribution to the intractable posterior
distribution. Our method can be used to approximate any posterior distribution,
provided that it is given in closed form up to the proportionality constant.
The approximation can be any distribution in the exponential family or any
mixture of such distributions, which means that it can be made arbitrarily
precise. Several examples illustrate the speed and accuracy of our
approximation method in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6682</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6682</id><created>2012-06-28</created><updated>2012-07-11</updated><authors><author><keyname>Xu</keyname><forenames>Weiqiang</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Pricing-based Distributed Downlink Beamforming in Multi-Cell OFDMA
  Networks</title><categories>cs.IT cs.NI math.IT</categories><journal-ref>IEEE Journal on Selected Areas in Communications, Oct., 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of downlink beamforming for mitigating the co-channel
interference in multi-cell OFDMA networks. Based on the network utility
maximization framework, we formulate the problem as a non-convex optimization
problem subject to the per-cell power constraints, in which a general utility
function of SINR is used to characterize the network performance. Some
classical utility functions, such as the proportional fairness utility, the
weighted sum-rate utility and the {$\alpha$}-fairness utility, are subsumed as
special cases of our formulation. To solve the problem in a distributed
fashion, we devise an algorithm based on the non-cooperative game with pricing
mechanism. We give a sufficient condition for the convergence of the algorithm
to the Nash equilibrium (NE), and analyze the information exchange overhead
among the base stations. Moreover, to speed up the optimization of the
beam-vectors at each cell, we derive an efficient algorithm to solve for the
KKT conditions at each cell. We provide extensive simulation results to
demonstrate that the proposed distributed multi-cell beamforming algorithm
converges to an NE point in just a few iterations with low information exchange
overhead. Moreover, it provides significant performance gains, especially under
the strong interference scenario, in comparison with several existing
multi-cell interference mitigation schemes, such as the distributed
interference alignment method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6690</identifier>
 <datestamp>2013-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6690</id><created>2012-06-28</created><updated>2013-06-28</updated><authors><author><keyname>Brinkmann</keyname><forenames>Gunnar</forenames></author><author><keyname>Goedgebeur</keyname><forenames>Jan</forenames></author><author><keyname>H&#xe4;gglund</keyname><forenames>Jonas</forenames></author><author><keyname>Markstr&#xf6;m</keyname><forenames>Klas</forenames></author></authors><title>Generation and Properties of Snarks</title><categories>math.CO cs.DM</categories><comments>Submitted for publication V2: various corrections V3: Figures updated
  and typos corrected. This version differs from the published one in that the
  Arxiv-version has data about the automorphisms of snarks; Journal of
  Combinatorial Theory. Series B. 2013</comments><doi>10.1016/j.jctb.2013.05.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many of the unsolved problems concerning cycles and matchings in graphs
it is known that it is sufficient to prove them for \emph{snarks}, the class of
nontrivial 3-regular graphs which cannot be 3-edge coloured. In the first part
of this paper we present a new algorithm for generating all non-isomorphic
snarks of a given order. Our implementation of the new algorithm is 14 times
faster than previous programs for generating snarks, and 29 times faster for
generating weak snarks. Using this program we have generated all non-isomorphic
snarks on $n\leq 36$ vertices. Previously lists up to $n=28$ vertices have been
published. In the second part of the paper we analyze the sets of generated
snarks with respect to a number of properties and conjectures. We find that
some of the strongest versions of the cycle double cover conjecture hold for
all snarks of these orders, as does Jaeger's Petersen colouring conjecture,
which in turn implies that Fulkerson's conjecture has no small counterexamples.
In contrast to these positive results we also find counterexamples to eight
previously published conjectures concerning cycle coverings and the general
cycle structure of cubic graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6720</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6720</id><created>2012-06-28</created><updated>2012-09-26</updated><authors><author><keyname>Laarhoven</keyname><forenames>Thijs</forenames></author><author><keyname>Oosterwijk</keyname><forenames>Jan-Jaap</forenames></author><author><keyname>Doumen</keyname><forenames>Jeroen</forenames></author></authors><title>Dynamic Traitor Tracing for Arbitrary Alphabets: Divide and Conquer</title><categories>cs.CR</categories><comments>6 pages, 1 figure</comments><journal-ref>IEEE International Workshop on Information Forensics and Security
  (WIFS), pp. 240-245, 2012</journal-ref><doi>10.1109/WIFS.2012.6412656</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a generic divide-and-conquer approach for constructing
collusion-resistant probabilistic dynamic traitor tracing schemes with larger
alphabets from schemes with smaller alphabets. This construction offers a
linear tradeoff between the alphabet size and the codelength. In particular, we
show that applying our results to the binary dynamic Tardos scheme of Laarhoven
et al. leads to schemes that are shorter by a factor equal to half the alphabet
size. Asymptotically, these codelengths correspond, up to a constant factor, to
the fingerprinting capacity for static probabilistic schemes. This gives a
hierarchy of probabilistic dynamic traitor tracing schemes, and bridges the gap
between the low bandwidth, high codelength scheme of Laarhoven et al. and the
high bandwidth, low codelength scheme of Fiat and Tassa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6722</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6722</id><created>2012-06-28</created><authors><author><keyname>Clark</keyname><forenames>Andrew</forenames></author></authors><title>Piecewise Linear Topology, Evolutionary Algorithms, and Optimization
  Problems</title><categories>cs.NE math.GN math.OC</categories><comments>PDF from Word docx, 11 pages, no figures</comments><acm-class>I.6.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schemata theory, Markov chains, and statistical mechanics have been used to
explain how evolutionary algorithms (EAs) work. Incremental success has been
achieved with all of these methods, but each has been stymied by limitations
related to its less-than-global view. We show that moving the investigation
into topological space improves our understanding of why EAs work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6728</identifier>
 <datestamp>2012-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6728</id><created>2012-06-28</created><updated>2012-10-16</updated><authors><author><keyname>Ferreira</keyname><forenames>Silvio C.</forenames></author><author><keyname>Castellano</keyname><forenames>Claudio</forenames></author><author><keyname>Pastor-Satorras</keyname><forenames>Romualdo</forenames></author></authors><title>Epidemic thresholds of the Susceptible-Infected-Susceptible model on
  networks: A comparison of numerical and theoretical results</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>9 pages, 8 figures, final version as in PRE</comments><journal-ref>Phys. Rev. E 86, 041125 (2012)</journal-ref><doi>10.1103/PhysRevE.86.041125</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has shown that different theoretical approaches to the dynamics
of the Susceptible-Infected-Susceptible (SIS) model for epidemics lead to
qualitatively different estimates for the position of the epidemic threshold in
networks. Here we present large-scale numerical simulations of the SIS dynamics
on various types of networks, allowing the precise determination of the
effective threshold for systems of finite size N. We compare quantitatively the
numerical thresholds with theoretical predictions of the heterogeneous
mean-field theory and of the quenched mean-field theory. We show that the
latter is in general more accurate, scaling with N with the correct exponent,
but often failing to capture the correct prefactor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6735</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6735</id><created>2012-06-28</created><authors><author><keyname>Cohen</keyname><forenames>Shay B.</forenames></author><author><keyname>G&#xf3;mez-Rodr&#xed;guez</keyname><forenames>Carlos</forenames></author><author><keyname>Satta</keyname><forenames>Giorgio</forenames></author></authors><title>Elimination of Spurious Ambiguity in Transition-Based Dependency Parsing</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel technique to remove spurious ambiguity from transition
systems for dependency parsing. Our technique chooses a canonical sequence of
transition operations (computation) for a given dependency tree. Our technique
can be applied to a large class of bottom-up transition systems, including for
instance Nivre (2004) and Attardi (2006).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6741</identifier>
 <datestamp>2012-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6741</id><created>2012-06-28</created><authors><author><keyname>Guillaume</keyname><forenames>Sylvie</forenames></author><author><keyname>Grissa</keyname><forenames>Dhouha</forenames></author><author><keyname>Nguifo</keyname><forenames>Engelbert Mephu</forenames></author></authors><title>Categorization of interestingness measures for knowledge extraction</title><categories>cs.IT math.IT</categories><comments>34 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding interesting association rules is an important and active research
field in data mining. The algorithms of the Apriori family are based on two
rule extraction measures, support and confidence. Although these two measures
have the virtue of being algorithmically fast, they generate a prohibitive
number of rules most of which are redundant and irrelevant. It is therefore
necessary to use further measures which filter uninteresting rules. Many
synthesis studies were then realized on the interestingness measures according
to several points of view. Different reported studies have been carried out to
identify &quot;good&quot; properties of rule extraction measures and these properties
have been assessed on 61 measures. The purpose of this paper is twofold. First
to extend the number of the measures and properties to be studied, in addition
to the formalization of the properties proposed in the literature. Second, in
the light of this formal study, to categorize the studied measures. This paper
leads then to identify categories of measures in order to help the users to
efficiently select an appropriate measure by choosing one or more measure(s)
during the knowledge extraction process. The properties evaluation on the 61
measures has enabled us to identify 7 classes of measures, classes that we
obtained using two different clustering techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6757</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6757</id><created>2012-06-28</created><updated>2012-07-12</updated><authors><author><keyname>Casalino</keyname><forenames>Matteo Maria</forenames></author><author><keyname>Mangili</keyname><forenames>Michele</forenames></author><author><keyname>Plate</keyname><forenames>Henrik</forenames></author><author><keyname>Ponta</keyname><forenames>Serena Elisa</forenames></author></authors><title>Detection of Configuration Vulnerabilities in Distributed (Web)
  Environments</title><categories>cs.CR cs.SE</categories><comments>18 pages. To appear in Proc. of Security and Privacy in Communication
  Networks - 8th Iternational ICST Conference, SecureComm, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many tools and libraries are readily available to build and operate
distributed Web applications. While the setup of operational environments is
comparatively easy, practice shows that their continuous secure operation is
more difficult to achieve, many times resulting in vulnerable systems exposed
to the Internet. Authenticated vulnerability scanners and validation tools
represent a means to detect security vulnerabilities caused by missing patches
or misconfiguration, but current approaches center much around the concepts of
hosts and operating systems. This paper presents a language and an approach for
the declarative specification and execution of machine-readable security checks
for sets of more fine-granular system components depending on each other in a
distributed environment. Such a language, building on existing standards,
fosters the creation and sharing of security content among security
stakeholders. Our approach is exemplified by vulnerabilities of and
corresponding checks for Open Source Software commonly used in today's Internet
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6778</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6778</id><created>2012-06-28</created><updated>2013-10-11</updated><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author><author><keyname>Chen</keyname><forenames>Yuhua</forenames></author><author><keyname>Verma</keyname><forenames>Pramode</forenames></author></authors><title>iAQC: The Intensity-Aware Quantum Cryptography Protocol</title><categories>quant-ph cs.CR</categories><comments>8 pages, 2 figures, corrected typographical errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports a variant of the three-stage quantum cryptography protocol
which can be used in low intensity laser output regimes. The variant, which
tracks the intensity of the laser beam at the intermediate stages, makes the
task of the eavesdropper harder than the standard K06 protocol. The constraints
on the iAQC protocol are much less than those on BB84 and in principle it can
not only be used for key distribution but also for direct bitwise encryption of
data. The iAQC protocol is an improvement on the K06 protocol in that it makes
it harder for the eavesdropper to monitor the channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6808</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6808</id><created>2012-06-28</created><authors><author><keyname>Li</keyname><forenames>Yan-Fu</forenames><affiliation>SSEC, LGI</affiliation></author><author><keyname>Zio</keyname><forenames>Enrico</forenames><affiliation>SSEC, LGI</affiliation></author></authors><title>A Multi-State Power Model for Adequacy Assessment of Distributed
  Generation via Universal Generating Function</title><categories>cs.OH cs.PF cs.SY</categories><comments>Reliability Engineering &amp; System Safety (2012) 1-20</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current and future developments of electric power systems are pushing the
boundaries of reliability assessment to consider distribution networks with
renewable generators. Given the stochastic features of these elements, most
modeling approaches rely on Monte Carlo simulation. The computational costs
associated to the simulation approach force to treating mostly small-sized
systems, i.e. with a limited number of lumped components of a given renewable
technology (e.g. wind or solar, etc.) whose behavior is described by a binary
state, working or failed. In this paper, we propose an analytical multi-state
modeling approach for the reliability assessment of distributed generation
(DG). The approach allows looking to a number of diverse energy generation
technologies distributed on the system. Multiple states are used to describe
the randomness in the generation units, due to the stochastic nature of the
generation sources and of the mechanical degradation/failure behavior of the
generation systems. The universal generating function (UGF) technique is used
for the individual component multi-state modeling. A multiplication-type
composition operator is introduced to combine the UGFs for the mechanical
degradation and renewable generation source states into the UGF of the
renewable generator power output. The overall multi-state DG system UGF is then
constructed and classical reliability indices (e.g. loss of load expectation
(LOLE), expected energy not supplied (EENS)) are computed from the DG system
generation and load UGFs. An application of the model is shown on a DG system
adapted from the IEEE 34 nodes distribution test feeder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6811</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6811</id><created>2012-06-28</created><updated>2013-04-28</updated><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>An Information-Theoretic Perspective of the Poisson Approximation via
  the Chen-Stein Method</title><categories>cs.IT math.IT math.PR</categories><comments>This paper was withdrawn from the IEEE Transactions on Information
  Theory after its conditional acceptance (subject to revision) because
  stronger and more general results for the entropy bounds appear in a
  follow-up paper [arXiv:1209.5259]. The lower bounds on the TV distance here
  are re-submitted to Statistics and Probability Letters [arXiv:1301.7504]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The first part of this work considers the entropy of the sum of (possibly
dependent and non-identically distributed) Bernoulli random variables. Upper
bounds on the error that follows from an approximation of this entropy by the
entropy of a Poisson random variable with the same mean are derived via the
Chen-Stein method. The second part of this work derives new lower bounds on the
total variation (TV) distance and relative entropy between the distribution of
the sum of independent Bernoulli random variables and the Poisson distribution.
The starting point of the derivation of the new bounds in the second part of
this work is an introduction of a new lower bound on the total variation
distance, whose derivation generalizes and refines the analysis by Barbour and
Hall (1984), based on the Chen-Stein method for the Poisson approximation. A
new lower bound on the relative entropy between these two distributions is
introduced, and this lower bound is compared to a previously reported upper
bound on the relative entropy by Kontoyiannis et al. (2005). The derivation of
the new lower bound on the relative entropy follows from the new lower bound on
the total variation distance, combined with a distribution-dependent refinement
of Pinsker's inequality by Ordentlich and Weinberger (2005). Upper and lower
bounds on the Bhattacharyya parameter, Chernoff information and Hellinger
distance between the distribution of the sum of independent Bernoulli random
variables and the Poisson distribution with the same mean are derived as well
via some relations between these quantities with the total variation distance
and the relative entropy. The analysis in this work combines elements of
information theory with the Chen-Stein method for the Poisson approximation.
The resulting bounds are easy to compute, and their applicability is
exemplified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6813</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6813</id><created>2012-06-27</created><authors><author><keyname>Dasgupta</keyname><forenames>Sanjoy</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Verma</keyname><forenames>Nakul</forenames></author></authors><title>A concentration theorem for projections</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-114-121</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  X in R^D has mean zero and finite second moments. We show that there is a
precise sense in which almost all linear projections of X into R^d (for d &lt; D)
look like a scale-mixture of spherical Gaussians -- specifically, a mixture of
distributions N(0, sigma^2 I_d) where the weight of the particular sigma
component is P (| X |^2 = sigma^2 D). The extent of this effect depends upon
the ratio of d to D, and upon a particular coefficient of eccentricity of X's
distribution. We explore this result in a variety of experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6814</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6814</id><created>2012-06-27</created><authors><author><keyname>Dani</keyname><forenames>Varsha</forenames></author><author><keyname>Madani</keyname><forenames>Omid</forenames></author><author><keyname>Pennock</keyname><forenames>David M</forenames></author><author><keyname>Sanghai</keyname><forenames>Sumit</forenames></author><author><keyname>Galebach</keyname><forenames>Brian</forenames></author></authors><title>An Empirical Comparison of Algorithms for Aggregating Expert Predictions</title><categories>cs.AI cs.LG</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-106-113</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting the outcomes of future events is a challenging problem for which a
variety of solution methods have been explored and attempted. We present an
empirical comparison of a variety of online and offline adaptive algorithms for
aggregating experts' predictions of the outcomes of five years of US National
Football League games (1319 games) using expert probability elicitations
obtained from an Internet contest called ProbabilitySports. We find that it is
difficult to improve over simple averaging of the predictions in terms of
prediction accuracy, but that there is room for improvement in quadratic loss.
Somewhat surprisingly, a Bayesian estimation algorithm which estimates the
variance of each expert's prediction exhibits the most consistent superior
performance over simple averaging among our collection of algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6815</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6815</id><created>2012-06-27</created><authors><author><keyname>Crammer</keyname><forenames>Koby</forenames></author><author><keyname>Globerson</keyname><forenames>Amir</forenames></author></authors><title>Discriminative Learning via Semidefinite Probabilistic Models</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-98-105</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discriminative linear models are a popular tool in machine learning. These
can be generally divided into two types: The first is linear classifiers, such
as support vector machines, which are well studied and provide state-of-the-art
results. One shortcoming of these models is that their output (known as the
'margin') is not calibrated, and cannot be translated naturally into a
distribution over the labels. Thus, it is difficult to incorporate such models
as components of larger systems, unlike probabilistic based approaches. The
second type of approach constructs class conditional distributions using a
nonlinearity (e.g. log-linear models), but is occasionally worse in terms of
classification error. We propose a supervised learning method which combines
the best of both approaches. Specifically, our method provides a distribution
over the labels, which is a linear function of the model parameters. As a
consequence, differences between probabilities are linear functions, a property
which most probabilistic models (e.g. log-linear) do not have.
  Our model assumes that classes correspond to linear subspaces (rather than to
half spaces). Using a relaxed projection operator, we construct a measure which
evaluates the degree to which a given vector 'belongs' to a subspace, resulting
in a distribution over labels. Interestingly, this view is closely related to
similar concepts in quantum detection theory. The resulting models can be
trained either to maximize the margin or to optimize average likelihood
measures. The corresponding optimization problems are semidefinite programs
which can be solved efficiently. We illustrate the performance of our algorithm
on real world datasets, and show that it outperforms 2nd order kernel methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6816</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6816</id><created>2012-06-27</created><authors><author><keyname>Cowell</keyname><forenames>Robert G.</forenames></author><author><keyname>Lauritzen</keyname><forenames>Steffen L.</forenames></author><author><keyname>Mortera</keyname><forenames>Julia</forenames></author></authors><title>MAIES: A Tool for DNA Mixture Analysis</title><categories>cs.AI cs.CE stat.AP</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-90-97</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an expert system, MAIES, developed for analysing forensic
identification problems involving DNA mixture traces using quantitative peak
area information. Peak area information is represented by conditional Gaussian
distributions, and inference based on exact junction tree propagation
ascertains whether individuals, whose profiles have been measured, have
contributed to the mixture. The system can also be used to predict DNA profiles
of unknown contributors by separating the mixture into its individual
components. The use of the system is illustrated with an application to a real
world example. The system implements a novel MAP (maximum a posteriori) search
algorithm that is described in an appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6817</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6817</id><created>2012-06-27</created><authors><author><keyname>Choi</keyname><forenames>Arthur</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>A Variational Approach for Approximating Bayesian Networks by Edge
  Deletion</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-80-89</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider in this paper the formulation of approximate inference in
Bayesian networks as a problem of exact inference on an approximate network
that results from deleting edges (to reduce treewidth). We have shown in
earlier work that deleting edges calls for introducing auxiliary network
parameters to compensate for lost dependencies, and proposed intuitive
conditions for determining these parameters. We have also shown that our method
corresponds to IBP when enough edges are deleted to yield a polytree, and
corresponds to some generalizations of IBP when fewer edges are deleted. In
this paper, we propose a different criteria for determining auxiliary
parameters based on optimizing the KL-divergence between the original and
approximate networks. We discuss the relationship between the two methods for
selecting parameters, shedding new light on IBP and its generalizations. We
also discuss the application of our new method to approximating inference
problems which are exponential in constrained treewidth, including MAP and
nonmyopic value of information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6818</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6818</id><created>2012-06-27</created><authors><author><keyname>Charitos</keyname><forenames>Theodore</forenames></author><author><keyname>van der Gaag</keyname><forenames>Linda C.</forenames></author></authors><title>Sensitivity Analysis for Threshold Decision Making with Dynamic Networks</title><categories>cs.AI cs.CE</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-72-79</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effect of inaccuracies in the parameters of a dynamic Bayesian network
can be investigated by subjecting the network to a sensitivity analysis. Having
detailed the resulting sensitivity functions in our previous work, we now study
the effect of parameter inaccuracies on a recommended decision in view of a
threshold decision-making model. We detail the effect of varying a single and
multiple parameters from a conditional probability table and present a
computational procedure for establishing bounds between which assessments for
these parameters can be varied without inducing a change in the recommended
decision. We illustrate the various concepts involved by means of a real-life
dynamic network in the field of infectious disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6819</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6819</id><created>2012-06-27</created><authors><author><keyname>Chan</keyname><forenames>Hei</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>On the Robustness of Most Probable Explanations</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-63-71</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Bayesian networks, a Most Probable Explanation (MPE) is a complete
variable instantiation with a highest probability given the current evidence.
In this paper, we discuss the problem of finding robustness conditions of the
MPE under single parameter changes. Specifically, we ask the question: How much
change in a single network parameter can we afford to apply while keeping the
MPE unchanged? We will describe a procedure, which is the first of its kind,
that computes this answer for each parameter in the Bayesian network variable
in time O(n exp(w)), where n is the number of network variables and w is its
treewidth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6820</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6820</id><created>2012-06-27</created><authors><author><keyname>Cavallo</keyname><forenames>Ruggiero</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author><author><keyname>Singh</keyname><forenames>Satinder</forenames></author></authors><title>Optimal Coordinated Planning Amongst Self-Interested Agents with Private
  State</title><categories>cs.GT cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-55-62</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a multi-agent system in a dynamic and uncertain environment. Each
agent's local decision problem is modeled as a Markov decision process (MDP)
and agents must coordinate on a joint action in each period, which provides a
reward to each agent and causes local state transitions. A social planner knows
the model of every agent's MDP and wants to implement the optimal joint policy,
but agents are self-interested and have private local state. We provide an
incentive-compatible mechanism for eliciting state information that achieves
the optimal joint plan in a Markov perfect equilibrium of the induced
stochastic game. In the special case in which local problems are Markov chains
and agents compete to take a single action in each period, we leverage Gittins
allocation indices to provide an efficient factored algorithm and distribute
computation of the optimal policy among the agents. Distributed, optimal
coordinated learning in a multi-agent variant of the multi-armed bandit problem
is obtained as a special case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6821</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6821</id><created>2012-06-27</created><authors><author><keyname>Brito</keyname><forenames>Carlos</forenames></author><author><keyname>Pearl</keyname><forenames>Judea</forenames></author></authors><title>Graphical Condition for Identification in recursive SEM</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-47-54</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper concerns the problem of predicting the effect of actions or
interventions on a system from a combination of (i) statistical data on a set
of observed variables, and (ii) qualitative causal knowledge encoded in the
form of a directed acyclic graph (DAG). The DAG represents a set of linear
equations called Structural Equations Model (SEM), whose coefficients are
parameters representing direct causal effects. Reliable quantitative
conclusions can only be obtained from the model if the causal effects are
uniquely determined by the data. That is, if there exists a unique
parametrization for the model that makes it compatible with the data. If this
is the case, the model is called identified. The main result of the paper is a
general sufficient condition for identification of recursive SEM models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6822</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6822</id><created>2012-06-27</created><authors><author><keyname>Bidyuk</keyname><forenames>Bozhena</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>Cutset Sampling with Likelihood Weighting</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-39-46</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper analyzes theoretically and empirically the performance of
likelihood weighting (LW) on a subset of nodes in Bayesian networks. The
proposed scheme requires fewer samples to converge due to reduction in sampling
variance. The method exploits the structure of the network to bound the
complexity of exact inference used to compute sampling distributions, similar
to Gibbs cutset sampling. Yet, the extension of the previosly proposed cutset
sampling principles to likelihood weighting is non-trivial due to differences
in the sampling processes of Gibbs sampler and LW. We demonstrate empirically
that likelihood weighting on a cutset (LWLC) is effective time-wise and has a
lower rejection rate than LW when applied to networks with many deterministic
probabilities. Finally, we show that the performance of likelihood weighting on
a cutset can be improved further by caching computed sampling distributions
and, consequently, learning 'zeros' of the target distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6823</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6823</id><created>2012-06-27</created><authors><author><keyname>Bi</keyname><forenames>Yaxin</forenames></author><author><keyname>Guan</keyname><forenames>Jiwen W.</forenames></author></authors><title>An Efficient Triplet-based Algorithm for Evidential Reasoning</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-31-38</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear-time computational techniques have been developed for combining
evidence which is available on a number of contending hypotheses. They offer a
means of making the computation-intensive calculations involved more efficient
in certain circumstances. Unfortunately, they restrict the orthogonal sum of
evidential functions to the dichotomous structure applies only to elements and
their complements. In this paper, we present a novel evidence structure in
terms of a triplet and a set of algorithms for evidential reasoning. The merit
of this structure is that it divides a set of evidence into three subsets,
distinguishing trivial evidential elements from important ones focusing some
particular elements. It avoids the deficits of the dichotomous structure in
representing the preference of evidence and estimating the basic probability
assignment of evidence. We have established a formalism for this structure and
the general formulae for combining pieces of evidence in the form of the
triplet, which have been theoretically justified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6824</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6824</id><created>2012-06-27</created><authors><author><keyname>Beal</keyname><forenames>Matthew</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Praveen</forenames></author></authors><title>Gene Expression Time Course Clustering with Countably Infinite Hidden
  Markov Models</title><categories>cs.LG cs.CE stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-23-30</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most existing approaches to clustering gene expression time course data treat
the different time points as independent dimensions and are invariant to
permutations, such as reversal, of the experimental time course. Approaches
utilizing HMMs have been shown to be helpful in this regard, but are hampered
by having to choose model architectures with appropriate complexities. Here we
propose for a clustering application an HMM with a countably infinite state
space; inference in this model is possible by recasting it in the hierarchical
Dirichlet process (HDP) framework (Teh et al. 2006), and hence we call it the
HDP-HMM. We show that the infinite model outperforms model selection methods
over finite models, and traditional time-independent methods, as measured by a
variety of external and internal indices for clustering on two large publicly
available data sets. Moreover, we show that the infinite models utilize more
hidden states and employ richer architectures (e.g. state-to-state transitions)
without the damaging effects of overfitting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6825</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6825</id><created>2012-06-27</created><authors><author><keyname>Bartels</keyname><forenames>Chris</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author></authors><title>Non-Minimal Triangulations for Mixed Stochastic/Deterministic Graphical
  Models</title><categories>cs.AI cs.DS</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-15-22</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We observe that certain large-clique graph triangulations can be useful to
reduce both computational and space requirements when making queries on mixed
stochastic/deterministic graphical models. We demonstrate that many of these
large-clique triangulations are non-minimal and are thus unattainable via the
variable elimination algorithm. We introduce ancestral pairs as the basis for
novel triangulation heuristics and prove that no more than the addition of
edges between ancestral pairs need be considered when searching for state space
optimal triangulations in such graphs. Empirical results on random and real
world graphs show that the resulting triangulations that yield significant
speedups are almost always non-minimal. We also give an algorithm and
correctness proof for determining if a triangulation can be obtained via
elimination, and we show that the decision problem associated with finding
optimal state space triangulations in this mixed stochastic/deterministic
setting is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6826</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6826</id><created>2012-06-27</created><authors><author><keyname>Ashlagi</keyname><forenames>Itai</forenames></author><author><keyname>Monderer</keyname><forenames>Dov</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Robust Learning Equilibrium</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-7-14</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce robust learning equilibrium. The idea of learning equilibrium is
that learning algorithms in multi-agent systems should themselves be in
equilibrium rather than only lead to equilibrium. That is, learning equilibrium
is immune to strategic deviations: Every agent is better off using its
prescribed learning algorithm, if all other agents follow their algorithms,
regardless of the unknown state of the environment. However, a learning
equilibrium may not be immune to non strategic mistakes. For example, if for a
certain period of time there is a failure in the monitoring devices (e.g., the
correct input does not reach the agents), then it may not be in equilibrium to
follow the algorithm after the devices are corrected. A robust learning
equilibrium is immune also to such non-strategic mistakes. The existence of
(robust) learning equilibrium is especially challenging when the monitoring
devices are 'weak'. That is, the information available to each agent at each
stage is limited. We initiate a study of robust learning equilibrium with
general monitoring structure and apply it to the context of auctions. We prove
the existence of robust learning equilibrium in repeated first-price auctions,
and discuss its properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6827</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6827</id><created>2012-06-27</created><authors><author><keyname>Asavathiratham</keyname><forenames>Chalee</forenames></author></authors><title>Linear Algebra Approach to Separable Bayesian Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-1-6</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separable Bayesian Networks, or the Influence Model, are dynamic Bayesian
Networks in which the conditional probability distribution can be separated
into a function of only the marginal distribution of a node's neighbors,
instead of the joint distributions. In terms of modeling, separable networks
has rendered possible siginificant reduction in complexity, as the state space
is only linear in the number of variables on the network, in contrast to a
typical state space which is exponential. In this work, We describe the
connection between an arbitrary Conditional Probability Table (CPT) and
separable systems using linear algebra. We give an alternate proof on the
equivalence of sufficiency and separability. We present a computational method
for testing whether a given CPT is separable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6828</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6828</id><created>2012-06-27</created><authors><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>Advances in exact Bayesian structure discovery in Bayesian networks</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-241-248</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a Bayesian method for learning the Bayesian network structure
from complete data. Recently, Koivisto and Sood (2004) presented an algorithm
that for any single edge computes its marginal posterior probability in O(n
2^n) time, where n is the number of attributes; the number of parents per
attribute is bounded by a constant. In this paper we show that the posterior
probabilities for all the n (n - 1) potential edges can be computed in O(n 2^n)
total time. This result is achieved by a forward-backward technique and fast
Moebius transform algorithms, which are of independent interest. The resulting
speedup by a factor of about n^2 allows us to experimentally study the
statistical power of learning moderate-size networks. We report results from a
simulation study that covers data sets with 20 to 10,000 records over 5 to 25
discrete attributes
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6829</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6829</id><created>2012-06-27</created><authors><author><keyname>Kang</keyname><forenames>Changsung</forenames></author><author><keyname>Tian</keyname><forenames>Jin</forenames></author></authors><title>Inequality Constraints in Causal Models with Hidden Variables</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-233-240</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a class of inequality constraints on the set of distributions
induced by local interventions on variables governed by a causal Bayesian
network, in which some of the variables remain unmeasured. We derive bounds on
causal effects that are not directly measured in randomized experiments. We
derive instrumental inequality type of constraints on nonexperimental
distributions. The results have applications in testing causal models with
observational or experimental data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6830</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6830</id><created>2012-06-27</created><authors><author><keyname>Jaeger</keyname><forenames>Manfred</forenames></author></authors><title>The AI&amp;M Procedure for Learning from Incomplete Data</title><categories>stat.ME cs.AI cs.LG</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-225-232</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate methods for parameter learning from incomplete data that is
not missing at random. Likelihood-based methods then require the optimization
of a profile likelihood that takes all possible missingness mechanisms into
account. Optimzing this profile likelihood poses two main difficulties:
multiple (local) maxima, and its very high-dimensional parameter space. In this
paper a new method is presented for optimizing the profile likelihood that
addresses the second difficulty: in the proposed AI&amp;M (adjusting imputation and
mazimization) procedure the optimization is performed by operations in the
space of data completions, rather than directly in the parameter space of the
profile likelihood. We apply the AI&amp;M method to learning parameters for
Bayesian networks. The method is compared against conservative inference, which
takes into account each possible data completion, and against EM. The results
indicate that likelihood-based inference is still feasible in the case of
unknown missingness mechanisms, and that conservative inference is
unnecessarily weak. On the other hand, our results also provide evidence that
the EM algorithm is still quite effective when the data is not missing at
random.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6831</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6831</id><created>2012-06-27</created><authors><author><keyname>Huang</keyname><forenames>Yimin</forenames></author><author><keyname>Valtorta</keyname><forenames>Marco</forenames></author></authors><title>Pearl's Calculus of Intervention Is Complete</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-217-224</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with graphical criteria that can be used to solve the
problem of identifying casual effects from nonexperimental data in a causal
Bayesian network structure, i.e., a directed acyclic graph that represents
causal relationships. We first review Pearl's work on this topic [Pearl, 1995],
in which several useful graphical criteria are presented. Then we present a
complete algorithm [Huang and Valtorta, 2006b] for the identifiability problem.
By exploiting the completeness of this algorithm, we prove that the three basic
do-calculus rules that Pearl presents are complete, in the sense that, if a
causal effect is identifiable, there exists a sequence of applications of the
rules of the do-calculus that transforms the causal effect formula into a
formula that only includes observational quantities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6832</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6832</id><created>2012-06-27</created><authors><author><keyname>Guo</keyname><forenames>Yuhong</forenames></author><author><keyname>Schuurmans</keyname><forenames>Dale</forenames></author></authors><title>Convex Structure Learning for Bayesian Networks: Polynomial Feature
  Selection and Approximate Ordering</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-208-216</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to learning the structure and parameters of a
Bayesian network based on regularized estimation in an exponential family
representation. Here we show that, given a fixed variable order, the optimal
structure and parameters can be learned efficiently, even without restricting
the size of the parent sets. We then consider the problem of optimizing the
variable order for a given set of features. This is still a computationally
hard problem, but we present a convex relaxation that yields an optimal 'soft'
ordering in polynomial time. One novel aspect of the approach is that we do not
perform a discrete search over DAG structures, nor over variable orders, but
instead solve a continuous relaxation that can then be rounded to obtain a
valid network structure. We conduct an experimental comparison against standard
structure search procedures over standard objectives, which cope with local
minima, and evaluate the advantages of using convex relaxations that reduce the
effects of local minima.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6833</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6833</id><created>2012-06-27</created><authors><author><keyname>Givoni</keyname><forenames>Inmar</forenames></author><author><keyname>Cheung</keyname><forenames>Vincent</forenames></author><author><keyname>Frey</keyname><forenames>Brendan J.</forenames></author></authors><title>Matrix Tile Analysis</title><categories>cs.LG cs.CE cs.NA stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-200-207</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many tasks require finding groups of elements in a matrix of numbers, symbols
or class likelihoods. One approach is to use efficient bi- or tri-linear
factorization techniques including PCA, ICA, sparse matrix factorization and
plaid analysis. These techniques are not appropriate when addition and
multiplication of matrix elements are not sensibly defined. More directly,
methods like bi-clustering can be used to classify matrix elements, but these
methods make the overly-restrictive assumption that the class of each element
is a function of a row class and a column class. We introduce a general
computational problem, `matrix tile analysis' (MTA), which consists of
decomposing a matrix into a set of non-overlapping tiles, each of which is
defined by a subset of usually nonadjacent rows and columns. MTA does not
require an algebra for combining tiles, but must search over discrete
combinations of tile assignments. Exact MTA is a computationally intractable
integer programming problem, but we describe an approximate iterative technique
and a computationally efficient sum-product relaxation of the integer program.
We compare the effectiveness of these methods to PCA and plaid on hundreds of
randomly generated tasks. Using double-gene-knockout data, we show that MTA
finds groups of interacting yeast genes that have biologically-related
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6834</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6834</id><created>2012-06-27</created><authors><author><keyname>Giang</keyname><forenames>Phan H.</forenames></author></authors><title>A new axiomatization for likelihood gambles</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-192-199</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a new and more general axiomatization than one presented
previously for preference on likelihood gambles. Likelihood gambles describe
actions in a situation where a decision maker knows multiple probabilistic
models and a random sample generated from one of those models but does not know
prior probability of models. This new axiom system is inspired by Jensen's
axiomatization of probabilistic gambles. Our approach provides a new
perspective to the role of data in decision making under ambiguity. It avoids
one of the most controversial issue of Bayesian methodology namely the
assumption of prior probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6835</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6835</id><created>2012-06-27</created><authors><author><keyname>Friedman</keyname><forenames>Nir</forenames></author><author><keyname>Kupferman</keyname><forenames>Raz</forenames></author></authors><title>Dimension Reduction in Singularly Perturbed Continuous-Time Bayesian
  Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-182-191</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous-time Bayesian networks (CTBNs) are graphical representations of
multi-component continuous-time Markov processes as directed graphs. The edges
in the network represent direct influences among components. The joint rate
matrix of the multi-component process is specified by means of conditional rate
matrices for each component separately. This paper addresses the situation
where some of the components evolve on a time scale that is much shorter
compared to the time scale of the other components. In this paper, we prove
that in the limit where the separation of scales is infinite, the Markov
process converges (in distribution, or weakly) to a reduced, or effective
Markov process that only involves the slow components. We also demonstrate that
for reasonable separation of scale (an order of magnitude) the reduced process
is a good approximation of the marginal process over the slow components. We
provide a simple procedure for building a reduced CTBN for this effective
process, with conditional rate matrices that can be directly calculated from
the original CTBN, and discuss the implications for approximate reasoning in
large systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6836</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6836</id><created>2012-06-27</created><authors><author><keyname>Ferns</keyname><forenames>Norman</forenames></author><author><keyname>Castro</keyname><forenames>Pablo Samuel</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author><author><keyname>Panangaden</keyname><forenames>Prakash</forenames></author></authors><title>Methods for computing state similarity in Markov Decision Processes</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-174-181</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A popular approach to solving large probabilistic systems relies on
aggregating states based on a measure of similarity. Many approaches in the
literature are heuristic. A number of recent methods rely instead on metrics
based on the notion of bisimulation, or behavioral equivalence between states
(Givan et al, 2001, 2003; Ferns et al, 2004). An integral component of such
metrics is the Kantorovich metric between probability distributions. However,
while this metric enables many satisfying theoretical properties, it is costly
to compute in practice. In this paper, we use techniques from network
optimization and statistical sampling to overcome this problem. We obtain in
this manner a variety of distance functions for MDP state aggregation, which
differ in the tradeoff between time and space complexity, as well as the
quality of the aggregation. We provide an empirical evaluation of these
trade-offs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6837</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6837</id><created>2012-06-27</created><authors><author><keyname>Elidan</keyname><forenames>Gal</forenames></author><author><keyname>McGraw</keyname><forenames>Ian</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author></authors><title>Residual Belief Propagation: Informed Scheduling for Asynchronous
  Message Passing</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-165-173</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference for probabilistic graphical models is still very much a practical
challenge in large domains. The commonly used and effective belief propagation
(BP) algorithm and its generalizations often do not converge when applied to
hard, real-life inference tasks. While it is widely recognized that the
scheduling of messages in these algorithms may have significant consequences,
this issue remains largely unexplored. In this work, we address the question of
how to schedule messages for asynchronous propagation so that a fixed point is
reached faster and more often. We first show that any reasonable asynchronous
BP converges to a unique fixed point under conditions similar to those that
guarantee convergence of synchronous BP. In addition, we show that the
convergence rate of a simple round-robin schedule is at least as good as that
of synchronous propagation. We then propose residual belief propagation (RBP),
a novel, easy-to-implement, asynchronous propagation algorithm that schedules
messages in an informed way, that pushes down a bound on the distance from the
fixed point. Finally, we demonstrate the superiority of RBP over
state-of-the-art methods for a variety of challenging synthetic and real-life
problems: RBP converges significantly more often than other methods; and it
significantly reduces running time until convergence, even when other methods
converge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6838</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6838</id><created>2012-06-27</created><authors><author><keyname>El-Hay</keyname><forenames>Tal</forenames></author><author><keyname>Friedman</keyname><forenames>Nir</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author><author><keyname>Kupferman</keyname><forenames>Raz</forenames></author></authors><title>Continuous Time Markov Networks</title><categories>cs.AI cs.LG</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-155-164</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A central task in many applications is reasoning about processes that change
in a continuous time. The mathematical framework of Continuous Time Markov
Processes provides the basic foundations for modeling such systems. Recently,
Nodelman et al introduced continuous time Bayesian networks (CTBNs), which
allow a compact representation of continuous-time processes over a factored
state space. In this paper, we introduce continuous time Markov networks
(CTMNs), an alternative representation language that represents a different
type of continuous-time dynamics. In many real life processes, such as
biological and chemical systems, the dynamics of the process can be naturally
described as an interplay between two forces - the tendency of each entity to
change its state, and the overall fitness or energy function of the entire
system. In our model, the first force is described by a continuous-time
proposal process that suggests possible local changes to the state of the
system at different rates. The second force is represented by a Markov network
that encodes the fitness, or desirability, of different states; a proposed
local change is then accepted with a probability that is a function of the
change in the fitness distribution. We show that the fitness distribution is
also the stationary distribution of the Markov process, so that this
representation provides a characterization of a temporal process whose
stationary distribution has a compact graphical representation. This allows us
to naturally capture a different type of structure in complex dynamical
processes, such as evolving biological sequences. We describe the semantics of
the representation, its basic properties, and how it compares to CTBNs. We also
provide algorithms for learning such models from data, and discuss its
applicability to biological sequence evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6841</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6841</id><created>2012-06-27</created><authors><author><keyname>Didelez</keyname><forenames>Vanessa</forenames></author></authors><title>Asymmetric separation for local independence graphs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-130-137</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Directed possibly cyclic graphs have been proposed by Didelez (2000) and
Nodelmann et al. (2002) in order to represent the dynamic dependencies among
stochastic processes. These dependencies are based on a generalization of
Granger-causality to continuous time, first developed by Schweder (1970) for
Markov processes, who called them local dependencies. They deserve special
attention as they are asymmetric unlike stochastic (in)dependence. In this
paper we focus on their graphical representation and develop a suitable, i.e.
asymmetric notion of separation, called delta-separation. The properties of
this graph separation as well as of local independence are investigated in
detail within a framework of asymmetric (semi)graphoids allowing a deeper
insight into what information can be read off these graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6842</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6842</id><created>2012-06-27</created><authors><author><keyname>Degris</keyname><forenames>Thomas</forenames></author><author><keyname>Sigaud</keyname><forenames>Olivier</forenames></author><author><keyname>Wuillemin</keyname><forenames>Pierre-Henri</forenames></author></authors><title>Chi-square Tests Driven Method for Learning the Structure of Factored
  MDPs</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-122-129</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SDYNA is a general framework designed to address large stochastic
reinforcement learning problems. Unlike previous model based methods in FMDPs,
it incrementally learns the structure and the parameters of a RL problem using
supervised learning techniques. Then, it integrates decision-theoric planning
algorithms based on FMDPs to compute its policy. SPITI is an instanciation of
SDYNA that exploits ITI, an incremental decision tree algorithm, to learn the
reward function and the Dynamic Bayesian Networks with local structures
representing the transition function of the problem. These representations are
used by an incremental version of the Structured Value Iteration algorithm. In
order to learn the structure, SPITI uses Chi-Square tests to detect the
independence between two probability distributions. Thus, we study the relation
between the threshold used in the Chi-Square test, the size of the model built
and the relative error of the value function of the induced policy with respect
to the optimal value. We show that, on stochastic problems, one can tune the
threshold so as to generate both a compact model and an efficient policy. Then,
we show that SPITI, while keeping its model compact, uses the generalization
property of its learning method to perform better than a stochastic classical
tabular algorithm in large RL problem with an unknown structure. We also
introduce a new measure based on Chi-Square to qualify the accuracy of the
model learned by SPITI. We qualitatively show that the generalization property
in SPITI within the FMDP framework may prevent an exponential growth of the
time required to learn the structure of large stochastic RL problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6843</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6843</id><created>2012-06-27</created><authors><author><keyname>Ramsey</keyname><forenames>Joseph</forenames></author><author><keyname>Zhang</keyname><forenames>Jiji</forenames></author><author><keyname>Spirtes</keyname><forenames>Peter L.</forenames></author></authors><title>Adjacency-Faithfulness and Conservative Causal Inference</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-401-408</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most causal inference algorithms in the literature (e.g., Pearl (2000),
Spirtes et al. (2000), Heckerman et al. (1999)) exploit an assumption usually
referred to as the causal Faithfulness or Stability condition. In this paper,
we highlight two components of the condition used in constraint-based
algorithms, which we call &quot;Adjacency-Faithfulness&quot; and
&quot;Orientation-Faithfulness&quot;. We point out that assuming Adjacency-Faithfulness
is true, it is in principle possible to test the validity of
Orientation-Faithfulness. Based on this observation, we explore the consequence
of making only the Adjacency-Faithfulness assumption. We show that the familiar
PC algorithm has to be modified to be (asymptotically) correct under the
weaker, Adjacency-Faithfulness assumption. Roughly the modified algorithm,
called Conservative PC (CPC), checks whether Orientation-Faithfulness holds in
the orientation phase, and if not, avoids drawing certain causal conclusions
the PC algorithm would draw. However, if the stronger, standard causal
Faithfulness condition actually obtains, the CPC algorithm is shown to output
the same pattern as the PC algorithm does in the large sample limit. We also
present a simulation study showing that the CPC algorithm runs almost as fast
as the PC algorithm, and outputs significantly fewer false causal arrowheads
than the PC algorithm does on realistic sample sizes. We end our paper by
discussing how score-based algorithms such as GES perform when the
Adjacency-Faithfulness but not the standard causal Faithfulness condition
holds, and how to extend our work to the FCI algorithm, which allows for the
possibility of latent variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6844</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6844</id><created>2012-06-27</created><authors><author><keyname>Pralet</keyname><forenames>Cedric</forenames></author><author><keyname>Schiex</keyname><forenames>Thomas</forenames></author><author><keyname>Verfaillie</keyname><forenames>Gerard</forenames></author></authors><title>From influence diagrams to multi-operator cluster DAGs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-393-400</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There exist several architectures to solve influence diagrams using local
computations, such as the Shenoy-Shafer, the HUGIN, or the Lazy Propagation
architectures. They all extend usual variable elimination algorithms thanks to
the use of so-called 'potentials'. In this paper, we introduce a new
architecture, called the Multi-operator Cluster DAG architecture, which can
produce decompositions with an improved constrained induced-width, and
therefore induce potentially exponential gains. Its principle is to benefit
from the composite nature of influence diagrams, instead of using uniform
potentials, in order to better analyze the problem structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6845</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6845</id><created>2012-06-27</created><authors><author><keyname>Porteous</keyname><forenames>Ian</forenames></author><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author><author><keyname>Smyth</keyname><forenames>Padhraic</forenames></author><author><keyname>Welling</keyname><forenames>Max</forenames></author></authors><title>Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick
  Breaking Representation</title><categories>stat.ME cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-385-392</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonparametric Bayesian approaches to clustering, information retrieval,
language modeling and object recognition have recently shown great promise as a
new paradigm for unsupervised data analysis. Most contributions have focused on
the Dirichlet process mixture models or extensions thereof for which efficient
Gibbs samplers exist. In this paper we explore Gibbs samplers for infinite
complexity mixture models in the stick breaking representation. The advantage
of this representation is improved modeling flexibility. For instance, one can
design the prior distribution over cluster sizes or couple multiple infinite
mixture models (e.g. over time) at the level of their parameters (i.e. the
dependent Dirichlet process model). However, Gibbs samplers for infinite
mixture models (as recently introduced in the statistics literature) seem to
mix poorly over cluster labels. Among others issues, this can have the adverse
effect that labels for the same cluster in coupled mixture models are mixed up.
We introduce additional moves in these samplers to improve mixing over cluster
labels and to bring clusters into correspondence. An application to modeling of
storm trajectories is used to illustrate these ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6846</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6846</id><created>2012-06-27</created><authors><author><keyname>Pfeffer</keyname><forenames>Avi</forenames></author></authors><title>Approximate Separability for Weak Interaction in Dynamic Systems</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-375-384</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One approach to monitoring a dynamic system relies on decomposition of the
system into weakly interacting subsystems. An earlier paper introduced a notion
of weak interaction called separability, and showed that it leads to exact
propagation of marginals for prediction. This paper addresses two questions
left open by the earlier paper: can we define a notion of approximate
separability that occurs naturally in practice, and do separability and
approximate separability lead to accurate monitoring? The answer to both
questions is afirmative. The paper also analyzes the structure of approximately
separable decompositions, and provides some explanation as to why these models
perform well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6847</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6847</id><created>2012-06-27</created><authors><author><keyname>Pena</keyname><forenames>Jose M.</forenames></author><author><keyname>Nilsson</keyname><forenames>Roland</forenames></author><author><keyname>Bj&#xf6;rkegren</keyname><forenames>Johan</forenames></author><author><keyname>Tegn&#xe9;r</keyname><forenames>Jesper</forenames></author></authors><title>Identifying the Relevant Nodes Without Learning the Model</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-367-374</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method to identify all the nodes that are relevant to compute
all the conditional probability distributions for a given set of nodes. Our
method is simple, effcient, consistent, and does not require learning a
Bayesian network first. Therefore, our method can be applied to
high-dimensional databases, e.g. gene expression databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6849</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6849</id><created>2012-06-27</created><authors><author><keyname>Milch</keyname><forenames>Brian</forenames></author><author><keyname>Russell</keyname><forenames>Stuart</forenames></author></authors><title>General-Purpose MCMC Inference over Relational Structures</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-349-358</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tasks such as record linkage and multi-target tracking, which involve
reconstructing the set of objects that underlie some observed data, are
particularly challenging for probabilistic inference. Recent work has achieved
efficient and accurate inference on such problems using Markov chain Monte
Carlo (MCMC) techniques with customized proposal distributions. Currently,
implementing such a system requires coding MCMC state representations and
acceptance probability calculations that are specific to a particular
application. An alternative approach, which we pursue in this paper, is to use
a general-purpose probabilistic modeling language (such as BLOG) and a generic
Metropolis-Hastings MCMC algorithm that supports user-supplied proposal
distributions. Our algorithm gains flexibility by using MCMC states that are
only partial descriptions of possible worlds; we provide conditions under which
MCMC over partial worlds yields correct answers to queries. We also show how to
use a context-specific Bayes net to identify the factors in the acceptance
probability that need to be computed for a given proposed move. Experimental
results on a citation matching task show that our general-purpose MCMC engine
compares favorably with an application-specific system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6850</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6850</id><created>2012-06-27</created><authors><author><keyname>Mei</keyname><forenames>Guobiao</forenames></author><author><keyname>Shelton</keyname><forenames>Christian R.</forenames></author></authors><title>Visualization of Collaborative Data</title><categories>cs.GR cs.AI cs.HC</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-341-348</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative data consist of ratings relating two distinct sets of objects:
users and items. Much of the work with such data focuses on filtering:
predicting unknown ratings for pairs of users and items. In this paper we focus
on the problem of visualizing the information. Given all of the ratings, our
task is to embed all of the users and items as points in the same Euclidean
space. We would like to place users near items that they have rated (or would
rate) high, and far away from those they would give a low rating. We pose this
problem as a real-valued non-linear Bayesian network and employ Markov chain
Monte Carlo and expectation maximization to find an embedding. We present a
metric by which to judge the quality of a visualization and compare our results
to local linear embedding and Eigentaste on three real-world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6851</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6851</id><created>2012-06-27</created><authors><author><keyname>Marthi</keyname><forenames>Bhaskara</forenames></author><author><keyname>Russell</keyname><forenames>Stuart</forenames></author><author><keyname>Andre</keyname><forenames>David</forenames></author></authors><title>A compact, hierarchical Q-function decomposition</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-332-340</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous work in hierarchical reinforcement learning has faced a dilemma:
either ignore the values of different possible exit states from a subroutine,
thereby risking suboptimal behavior, or represent those values explicitly
thereby incurring a possibly large representation cost because exit values
refer to nonlocal aspects of the world (i.e., all subsequent rewards). This
paper shows that, in many cases, one can avoid both of these problems. The
solution is based on recursively decomposing the exit value function in terms
of Q-functions at higher levels of the hierarchy. This leads to an intuitively
appealing runtime architecture in which a parent subroutine passes to its child
a value function on the exit states and the child reasons about how its choices
affect the exit value. We also identify structural conditions on the value
function and transition distributions that allow much more concise
representations of exit state distributions, leading to further state
abstraction. In essence, the only variables whose exit values need be
considered are those that the parent cares about and the child affects. We
demonstrate the utility of our algorithms on a series of increasingly complex
environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6852</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6852</id><created>2012-06-27</created><authors><author><keyname>Mansinghka</keyname><forenames>Vikash</forenames></author><author><keyname>Kemp</keyname><forenames>Charles</forenames></author><author><keyname>Griffiths</keyname><forenames>Thomas</forenames></author><author><keyname>Tenenbaum</keyname><forenames>Joshua</forenames></author></authors><title>Structured Priors for Structure Learning</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-324-331</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional approaches to Bayes net structure learning typically assume
little regularity in graph structure other than sparseness. However, in many
cases, we expect more systematicity: variables in real-world systems often
group into classes that predict the kinds of probabilistic dependencies they
participate in. Here we capture this form of prior knowledge in a hierarchical
Bayesian framework, and exploit it to enable structure learning and type
discovery from small datasets. Specifically, we present a nonparametric
generative model for directed acyclic graphs as a prior for Bayes net structure
learning. Our model assumes that variables come in one or more classes and that
the prior probability of an edge existing between two variables is a function
only of their classes. We derive an MCMC algorithm for simultaneous inference
of the number of classes, the class assignments of variables, and the Bayes net
structure over variables. For several realistic, sparse datasets, we show that
the bias towards systematicity of connections provided by our model yields more
accurate learned networks than a traditional, uniform prior approach, and that
the classes found by our model are appropriate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6853</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6853</id><created>2012-06-27</created><authors><author><keyname>Mani</keyname><forenames>Subramani</forenames></author><author><keyname>Spirtes</keyname><forenames>Peter L.</forenames></author><author><keyname>Cooper</keyname><forenames>Gregory F.</forenames></author></authors><title>A theoretical study of Y structures for causal discovery</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-314-323</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are several existing algorithms that under appropriate assumptions can
reliably identify a subset of the underlying causal relationships from
observational data. This paper introduces the first computationally feasible
score-based algorithm that can reliably identify causal relationships in the
large sample limit for discrete models, while allowing for the possibility that
there are unobserved common causes. In doing so, the algorithm does not ever
need to assign scores to causal structures with unobserved common causes. The
algorithm is based on the identification of so called Y substructures within
Bayesian network structures that can be learned from observational data. An
example of a Y substructure is A -&gt; C, B -&gt; C, C -&gt; D. After providing
background on causal discovery, the paper proves the conditions under which the
algorithm is reliable in the large sample limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6854</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6854</id><created>2012-06-27</created><authors><author><keyname>Madsen</keyname><forenames>Anders L.</forenames></author></authors><title>Belief Update in CLG Bayesian Networks With Lazy Propagation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-306-313</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years Bayesian networks (BNs) with a mixture of continuous and
discrete variables have received an increasing level of attention. We present
an architecture for exact belief update in Conditional Linear Gaussian BNs (CLG
BNs). The architecture is an extension of lazy propagation using operations of
Lauritzen &amp; Jensen [6] and Cowell [2]. By decomposing clique and separator
potentials into sets of factors, the proposed architecture takes advantage of
independence and irrelevance properties induced by the structure of the graph
and the evidence. The resulting benefits are illustrated by examples. Results
of a preliminary empirical performance evaluation indicate a significant
potential of the proposed architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6855</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6855</id><created>2012-06-27</created><authors><author><keyname>Littman</keyname><forenames>Michael L.</forenames></author><author><keyname>Ravi</keyname><forenames>Nishkam</forenames></author><author><keyname>Talwar</keyname><forenames>Arjun</forenames></author><author><keyname>Zinkevich</keyname><forenames>Martin</forenames></author></authors><title>An Efficient Optimal-Equilibrium Algorithm for Two-player Game Trees</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-298-305</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two-player complete-information game trees are perhaps the simplest possible
setting for studying general-sum games and the computational problem of finding
equilibria. These games admit a simple bottom-up algorithm for finding subgame
perfect Nash equilibria efficiently. However, such an algorithm can fail to
identify optimal equilibria, such as those that maximize social welfare. The
reason is that, counterintuitively, probabilistic action choices are sometimes
needed to achieve maximum payoffs. We provide a novel polynomial-time algorithm
for this problem that explicitly reasons about stochastic decisions and
demonstrate its use in an example card game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6856</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6856</id><created>2012-06-27</created><authors><author><keyname>Lee</keyname><forenames>Seunghwan</forenames></author></authors><title>Reasoning about Uncertainty in Metric Spaces</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-289-297</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We set up a model for reasoning about metric spaces with belief theoretic
measures. The uncertainty in these spaces stems from both probability and
metric. To represent both aspect of uncertainty, we choose an expected distance
function as a measure of uncertainty. A formal logical system is constructed
for the reasoning about expected distance. Soundness and completeness are shown
for this logic. For reasoning on product metric space with uncertainty, a new
metric is defined and shown to have good properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6857</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6857</id><created>2012-06-27</created><authors><author><keyname>Lee</keyname><forenames>Dongryeol</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author></authors><title>Faster Gaussian Summation: Theory and Experiment</title><categories>cs.LG cs.NA stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-281-288</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide faster algorithms for the problem of Gaussian summation, which
occurs in many machine learning methods. We develop two new extensions - an
O(Dp) Taylor expansion for the Gaussian kernel with rigorous error bounds and a
new error control scheme integrating any arbitrary approximation method -
within the best discretealgorithmic framework using adaptive hierarchical data
structures. We rigorously evaluate these techniques empirically in the context
of optimal bandwidth selection in kernel density estimation, revealing the
strengths and weaknesses of current state-of-the-art approaches for the first
time. Our results demonstrate that the new error control scheme yields improved
performance, whereas the series expansion approach is only effective in low
dimensions (five or less).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6858</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6858</id><created>2012-06-27</created><authors><author><keyname>Lebanon</keyname><forenames>Guy</forenames></author></authors><title>Sequential Document Representations and Simplicial Curves</title><categories>cs.IR cs.LG</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-273-280</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The popular bag of words assumption represents a document as a histogram of
word occurrences. While computationally efficient, such a representation is
unable to maintain any sequential information. We present a continuous and
differentiable sequential document representation that goes beyond the bag of
words assumption, and yet is efficient and effective. This representation
employs smooth curves in the multinomial simplex to account for sequential
information. We discuss the representation and its geometric properties and
demonstrate its applicability for the task of text classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6859</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6859</id><created>2012-06-27</created><authors><author><keyname>Laskey</keyname><forenames>Kathryn Blackmond</forenames></author><author><keyname>Xu</keyname><forenames>Ning</forenames></author><author><keyname>Chen</keyname><forenames>Chun-Hung</forenames></author></authors><title>Propagation of Delays in the National Airspace System</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-265-272</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The National Airspace System (NAS) is a large and complex system with
thousands of interrelated components: administration, control centers,
airports, airlines, aircraft, passengers, etc. The complexity of the NAS
creates many difficulties in management and control. One of the most pressing
problems is flight delay. Delay creates high cost to airlines, complaints from
passengers, and difficulties for airport operations. As demand on the system
increases, the delay problem becomes more and more prominent. For this reason,
it is essential for the Federal Aviation Administration to understand the
causes of delay and to find ways to reduce delay. Major contributing factors to
delay are congestion at the origin airport, weather, increasing demand, and air
traffic management (ATM) decisions such as the Ground Delay Programs (GDP).
Delay is an inherently stochastic phenomenon. Even if all known causal factors
could be accounted for, macro-level national airspace system (NAS) delays could
not be predicted with certainty from micro-level aircraft information. This
paper presents a stochastic model that uses Bayesian Networks (BNs) to model
the relationships among different components of aircraft delay and the causal
factors that affect delays. A case study on delays of departure flights from
Chicago O'Hare international airport (ORD) to Hartsfield-Jackson Atlanta
International Airport (ATL) reveals how local and system level environmental
and human-caused factors combine to affect components of delay, and how these
components contribute to the final arrival delay at the destination airport.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6860</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6860</id><created>2012-06-27</created><authors><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Oliveira</keyname><forenames>Roberto</forenames></author><author><keyname>Zadrozny</keyname><forenames>Bianca</forenames></author></authors><title>Predicting Conditional Quantiles via Reduction to Classification</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-257-264</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to reduce the process of predicting general order statistics (and
the median in particular) to solving classification. The accompanying
theoretical statement shows that the regret of the classifier bounds the regret
of the quantile regression under a quantile loss. We also test this reduction
empirically against existing quantile regression methods on large real-world
datasets and discover that it provides state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6861</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6861</id><created>2012-06-27</created><authors><author><keyname>Kuroki</keyname><forenames>Manabu</forenames></author><author><keyname>Cai</keyname><forenames>Zhihong</forenames></author></authors><title>Stratified Analysis of `Probabilities of Causation'</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-249-256</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes new formulas for the probabilities of causation difined
by Pearl (2000). Tian and Pearl (2000a, 2000b) showed how to bound the
quantities of the probabilities of causation from experimental and
observational data, under the minimal assumptions about the data-generating
process. We derive narrower bounds than Tian-Pearl bounds by making use of the
covariate information measured in experimental and observational studies. In
addition, we provide identifiable case under no-prevention assumption and
discuss the covariate selection problem from the viewpoint of estimation
accuracy. These results are helpful in providing more evidence for public
policy assessment and dicision making problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6862</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6862</id><created>2012-06-27</created><authors><author><keyname>Zuk</keyname><forenames>Or</forenames></author><author><keyname>Margel</keyname><forenames>Shiri</forenames></author><author><keyname>Domany</keyname><forenames>Eytan</forenames></author></authors><title>On the Number of Samples Needed to Learn the Correct Structure of a
  Bayesian Network</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-560-567</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian Networks (BNs) are useful tools giving a natural and compact
representation of joint probability distributions. In many applications one
needs to learn a Bayesian Network (BN) from data. In this context, it is
important to understand the number of samples needed in order to guarantee a
successful learning. Previous work have studied BNs sample complexity, yet it
mainly focused on the requirement that the learned distribution will be close
to the original distribution which generated the data. In this work, we study a
different aspect of the learning, namely the number of samples needed in order
to learn the correct structure of the network. We give both asymptotic results,
valid in the large sample limit, and experimental results, demonstrating the
learning behavior for feasible sample sizes. We show that structure learning is
a more difficult task, compared to approximating the correct distribution, in
the sense that it requires a much larger number of samples, regardless of the
computational power available for the learner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6863</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6863</id><created>2012-06-27</created><authors><author><keyname>Zhang</keyname><forenames>Zhihua</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>Bayesian Multicategory Support Vector Machines</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-552-559</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the multi-class support vector machine (MSVM) proposed by Lee
et. al. (2004), can be viewed as a MAP estimation procedure under an
appropriate probabilistic interpretation of the classifier. We also show that
this interpretation can be extended to a hierarchical Bayesian architecture and
to a fully-Bayesian inference procedure for multi-class classification based on
data augmentation. We present empirical results that show that the advantages
of the Bayesian formalism are obtained without a loss in classification
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6864</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6864</id><created>2012-06-27</created><authors><author><keyname>Xu</keyname><forenames>Zhao</forenames></author><author><keyname>Tresp</keyname><forenames>Volker</forenames></author><author><keyname>Yu</keyname><forenames>Kai</forenames></author><author><keyname>Kriegel</keyname><forenames>Hans-Peter</forenames></author></authors><title>Infinite Hidden Relational Models</title><categories>cs.AI cs.DB cs.LG</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-544-551</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many cases it makes sense to model a relationship symmetrically, not
implying any particular directionality. Consider the classical example of a
recommendation system where the rating of an item by a user should
symmetrically be dependent on the attributes of both the user and the item. The
attributes of the (known) relationships are also relevant for predicting
attributes of entities and for predicting attributes of new relations. In
recommendation systems, the exploitation of relational attributes is often
referred to as collaborative filtering. Again, in many applications one might
prefer to model the collaborative effect in a symmetrical way. In this paper we
present a relational model, which is completely symmetrical. The key innovation
is that we introduce for each entity (or object) an infinite-dimensional latent
variable as part of a Dirichlet process (DP) model. We discuss inference in the
model, which is based on a DP Gibbs sampler, i.e., the Chinese restaurant
process. We extend the Chinese restaurant process to be applicable to
relational modeling. Our approach is evaluated in three applications. One is a
recommendation system based on the MovieLens data set. The second application
concerns the prediction of the function of yeast genes/proteins on the data set
of KDD Cup 2001 using a multi-relational model. The third application involves
a relational medical domain. The experimental results show that our model gives
significantly improved estimates of attributes describing relationships or
entities in complex relational models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6865</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6865</id><created>2012-06-27</created><authors><author><keyname>Wood</keyname><forenames>Frank</forenames></author><author><keyname>Griffiths</keyname><forenames>Thomas</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>A Non-Parametric Bayesian Method for Inferring Hidden Causes</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-536-543</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a non-parametric Bayesian approach to structure learning with
hidden causes. Previous Bayesian treatments of this problem define a prior over
the number of hidden causes and use algorithms such as reversible jump Markov
chain Monte Carlo to move between solutions. In contrast, we assume that the
number of hidden causes is unbounded, but only a finite number influence
observable variables. This makes it possible to use a Gibbs sampler to
approximate the distribution over causal structures. We evaluate the
performance of both approaches in discovering hidden causes in simulated data,
and use our non-parametric approach to discover hidden causes in a real medical
dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6866</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6866</id><created>2012-06-27</created><authors><author><keyname>Wiegerinck</keyname><forenames>Wim</forenames></author><author><keyname>Broek</keyname><forenames>Bart van den</forenames></author><author><keyname>Kappen</keyname><forenames>Hilbert</forenames></author></authors><title>Stochastic Optimal Control in Continuous Space-Time Multi-Agent Systems</title><categories>cs.MA cs.SY math.OC</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-528-535</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a theory for stochastic optimal control in non-linear dynamical
systems in continuous space-time has been developed (Kappen, 2005). We apply
this theory to collaborative multi-agent systems. The agents evolve according
to a given non-linear dynamics with additive Wiener noise. Each agent can
control its own dynamics. The goal is to minimize the accumulated joint cost,
which consists of a state dependent term and a term that is quadratic in the
control. We focus on systems of non-interacting agents that have to distribute
themselves optimally over a number of targets, given a set of end-costs for the
different possible agent-target combinations. We show that optimal control is
the combinatorial sum of independent single-agent single-target optimal
controls weighted by a factor proportional to the end-costs of the different
combinations. Thus, multi-agent control is related to a standard graphical
model inference problem. The additional computational cost compared to
single-agent control is exponential in the tree-width of the graph specifying
the combinatorial sum times the number of targets. We illustrate the result by
simulations of systems with up to 42 agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6867</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6867</id><created>2012-06-27</created><authors><author><keyname>Weng</keyname><forenames>Paul</forenames></author></authors><title>Axiomatic Foundations for a Class of Generalized Expected Utility:
  Algebraic Expected Utility</title><categories>cs.AI cs.GT</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-520-527</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Expected Utility: Algebraic Expected Utility In this paper, we provide two
axiomatizations of algebraic expected utility, which is a particular
generalized expected utility, in a von Neumann-Morgenstern setting, i.e.
uncertainty representation is supposed to be given and here to be described by
a plausibility measure valued on a semiring, which could be partially ordered.
We show that axioms identical to those for expected utility entail that
preferences are represented by an algebraic expected utility. This algebraic
approach allows many previous propositions (expected utility, binary
possibilistic utility,...) to be unified in a same general framework and proves
that the obtained utility enjoys the same nice features as expected utility:
linearity, dynamic consistency, autoduality of the underlying uncertainty
measure, autoduality of the decision criterion and possibility of modeling
decision maker's attitude toward uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6868</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6868</id><created>2012-06-27</created><authors><author><keyname>Welling</keyname><forenames>Max</forenames></author><author><keyname>Parise</keyname><forenames>Sridevi</forenames></author></authors><title>Bayesian Random Fields: The Bethe-Laplace Approximation</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-512-519</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While learning the maximum likelihood value of parameters of an undirected
graphical model is hard, modelling the posterior distribution over parameters
given data is harder. Yet, undirected models are ubiquitous in computer vision
and text modelling (e.g. conditional random fields). But where Bayesian
approaches for directed models have been very successful, a proper Bayesian
treatment of undirected models in still in its infant stages. We propose a new
method for approximating the posterior of the parameters given data based on
the Laplace approximation. This approximation requires the computation of the
covariance matrix over features which we compute using the linear response
approximation based in turn on loopy belief propagation. We develop the theory
for conditional and 'unconditional' random fields with or without hidden
variables. In the conditional setting we introduce a new variant of bagging
suitable for structured domains. Here we run the loopy max-product algorithm on
a 'super-graph' composed of graphs for individual models sampled from the
posterior and connected by constraints. Experiments on real world data validate
the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6869</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6869</id><created>2012-06-27</created><authors><author><keyname>Subramanya</keyname><forenames>Amarnag</forenames></author><author><keyname>Raj</keyname><forenames>Alvin</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author><author><keyname>Fox</keyname><forenames>Dieter</forenames></author></authors><title>Recognizing Activities and Spatial Context Using Wearable Sensors</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-494-502</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new dynamic model with the capability of recognizing both
activities that an individual is performing as well as where that ndividual is
located. Our model is novel in that it utilizes a dynamic graphical model to
jointly estimate both activity and spatial context over time based on the
simultaneous use of asynchronous observations consisting of GPS measurements,
and measurements from a small mountable sensor board. Joint inference is quite
desirable as it has the ability to improve accuracy of the model. A key goal,
however, in designing our overall system is to be able to perform accurate
inference decisions while minimizing the amount of hardware an individual must
wear. This minimization leads to greater comfort and flexibility, decreased
power requirements and therefore increased battery life, and reduced cost. We
show results indicating that our joint measurement model outperforms
measurements from either the sensor board or GPS alone, using two types of
probabilistic inference procedures, namely particle filtering and pruned exact
inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6870</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6870</id><created>2012-06-27</created><authors><author><keyname>Strehl</keyname><forenames>Alexander L.</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author><author><keyname>Littman</keyname><forenames>Michael L.</forenames></author></authors><title>Incremental Model-based Learners With Formal Learning-Time Guarantees</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-485-493</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-based learning algorithms have been shown to use experience efficiently
when learning to solve Markov Decision Processes (MDPs) with finite state and
action spaces. However, their high computational cost due to repeatedly solving
an internal model inhibits their use in large-scale problems. We propose a
method based on real-time dynamic programming (RTDP) to speed up two
model-based algorithms, RMAX and MBIE (model-based interval estimation),
resulting in computationally much faster algorithms with little loss compared
to existing bounds. Specifically, our two new learning algorithms, RTDP-RMAX
and RTDP-IE, have considerably smaller computational demands than RMAX and
MBIE. We develop a general theoretical framework that allows us to prove that
both are efficient learners in a PAC (probably approximately correct) sense. We
also present an experimental evaluation of these new algorithms that helps
quantify the tradeoff between computational and experience demands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6871</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6871</id><created>2012-06-27</created><authors><author><keyname>Steck</keyname><forenames>Harald</forenames></author></authors><title>Ranking by Dependence - A Fair Criteria</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-477-484</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the dependences between random variables, and ranking them
accordingly, is a prevalent problem in machine learning. Pursuing frequentist
and information-theoretic approaches, we first show that the p-value and the
mutual information can fail even in simplistic situations. We then propose two
conditions for regularizing an estimator of dependence, which leads to a simple
yet effective new measure. We discuss its advantages and compare it to
well-established model-selection criteria. Apart from that, we derive a simple
constraint for regularizing parameter estimates in a graphical model. This
results in an analytical approximation for the optimal value of the equivalent
sample size, which agrees very well with the more involved Bayesian approach in
our experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6872</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6872</id><created>2012-06-27</created><authors><author><keyname>Stavens</keyname><forenames>David</forenames></author><author><keyname>Thrun</keyname><forenames>Sebastian</forenames></author></authors><title>A Self-Supervised Terrain Roughness Estimator for Off-Road Autonomous
  Driving</title><categories>cs.CV cs.LG cs.RO</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-469-476</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a machine learning approach for estimating the second derivative
of a drivable surface, its roughness. Robot perception generally focuses on the
first derivative, obstacle detection. However, the second derivative is also
important due to its direct relation (with speed) to the shock the vehicle
experiences. Knowing the second derivative allows a vehicle to slow down in
advance of rough terrain. Estimating the second derivative is challenging due
to uncertainty. For example, at range, laser readings may be so sparse that
significant information about the surface is missing. Also, a high degree of
precision is required in projecting laser readings. This precision may be
unavailable due to latency or error in the pose estimation. We model these
sources of error as a multivariate polynomial. Its coefficients are learned
using the shock data as ground truth -- the accelerometers are used to train
the lasers. The resulting classifier operates on individual laser readings from
a road surface described by a 3D point cloud. The classifier identifies
sections of road where the second derivative is likely to be large. Thus, the
vehicle can slow down in advance, reducing the shock it experiences. The
algorithm is an evolution of one we used in the 2005 DARPA Grand Challenge. We
analyze it using data from that route.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6873</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6873</id><created>2012-06-27</created><authors><author><keyname>Snelson</keyname><forenames>Edward</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Variable noise and dimensionality reduction for sparse Gaussian
  processes</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-461-468</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sparse pseudo-input Gaussian process (SPGP) is a new approximation method
for speeding up GP regression in the case of a large number of data points N.
The approximation is controlled by the gradient optimization of a small set of
M `pseudo-inputs', thereby reducing complexity from N^3 to NM^2. One limitation
of the SPGP is that this optimization space becomes impractically big for high
dimensional data sets. This paper addresses this limitation by performing
automatic dimensionality reduction. A projection of the input space to a low
dimensional space is learned in a supervised manner, alongside the
pseudo-inputs, which now live in this reduced space. The paper also
investigates the suitability of the SPGP for modeling data with input-dependent
noise. A further extension of the model is made to make it even more powerful
in this regard - we learn an uncertainty parameter for each pseudo-input. The
combination of sparsity, reduced dimension, and input-dependent noise makes it
possible to apply GPs to much larger and more complex data sets than was
previously practical. We demonstrate the benefits of these methods on several
synthetic and real world problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6874</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6874</id><created>2012-06-27</created><authors><author><keyname>Silva</keyname><forenames>Ricardo</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Bayesian Inference for Gaussian Mixed Graph Models</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-453-460</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce priors and algorithms to perform Bayesian inference in Gaussian
models defined by acyclic directed mixed graphs. Such a class of graphs,
composed of directed and bi-directed edges, is a representation of conditional
independencies that is closed under marginalization and arises naturally from
causal models which allow for unmeasured confounding. Monte Carlo methods and a
variational approximation for such models are presented. Our algorithms for
Bayesian inference allow the evaluation of posterior distributions for several
quantities of interest, including causal effects that are not identifiable from
data alone but could otherwise be inferred where informative prior knowledge
about confounding is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6875</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6875</id><created>2012-06-27</created><authors><author><keyname>Silander</keyname><forenames>Tomi</forenames></author><author><keyname>Myllymaki</keyname><forenames>Petri</forenames></author></authors><title>A simple approach for finding the globally optimal Bayesian network
  structure</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-445-452</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of learning the best Bayesian network structure with
respect to a decomposable score such as BDe, BIC or AIC. This problem is known
to be NP-hard, which means that solving it becomes quickly infeasible as the
number of variables increases. Nevertheless, in this paper we show that it is
possible to learn the best Bayesian network structure with over 30 variables,
which covers many practically interesting cases. Our algorithm is less
complicated and more efficient than the techniques presented earlier. It can be
easily parallelized, and offers a possibility for efficient exploration of the
best networks consistent with different variable orderings. In the experimental
part of the paper we compare the performance of the algorithm to the previous
state-of-the-art algorithm. Free source-code and an online-demo can be found at
http://b-course.hiit.fi/bene.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6876</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6876</id><created>2012-06-27</created><authors><author><keyname>Shpitser</keyname><forenames>Ilya</forenames></author><author><keyname>Pearl</keyname><forenames>Judea</forenames></author></authors><title>Identification of Conditional Interventional Distributions</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-437-444</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subject of this paper is the elucidation of effects of actions from
causal assumptions represented as a directed graph, and statistical knowledge
given as a probability distribution. In particular, we are interested in
predicting conditional distributions resulting from performing an action on a
set of variables and, subsequently, taking measurements of another set. We
provide a necessary and sufficient graphical condition for the cases where such
distributions can be uniquely computed from the available information, as well
as an algorithm which performs this computation whenever the condition holds.
Furthermore, we use our results to prove completeness of do-calculus [Pearl,
1995] for the same identification problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6877</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6877</id><created>2012-06-27</created><authors><author><keyname>Shenoy</keyname><forenames>Prakash P.</forenames></author></authors><title>Inference in Hybrid Bayesian Networks Using Mixtures of Gaussians</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-428-436</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main goal of this paper is to describe a method for exact inference in
general hybrid Bayesian networks (BNs) (with a mixture of discrete and
continuous chance variables). Our method consists of approximating general
hybrid Bayesian networks by a mixture of Gaussians (MoG) BNs. There exists a
fast algorithm by Lauritzen-Jensen (LJ) for making exact inferences in MoG
Bayesian networks, and there exists a commercial implementation of this
algorithm. However, this algorithm can only be used for MoG BNs. Some
limitations of such networks are as follows. All continuous chance variables
must have conditional linear Gaussian distributions, and discrete chance nodes
cannot have continuous parents. The methods described in this paper will enable
us to use the LJ algorithm for a bigger class of hybrid Bayesian networks. This
includes networks with continuous chance nodes with non-Gaussian distributions,
networks with no restrictions on the topology of discrete and continuous
variables, networks with conditionally deterministic variables that are a
nonlinear function of their continuous parents, and networks with continuous
chance variables whose variances are functions of their parents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6878</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6878</id><created>2012-06-27</created><authors><author><keyname>Schaeffer</keyname><forenames>Monika</forenames></author><author><keyname>Parr</keyname><forenames>Ron</forenames></author></authors><title>Efficient Selection of Disambiguating Actions for Stereo Vision</title><categories>cs.CV</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-418-427</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many domains that involve the use of sensors, such as robotics or sensor
networks, there are opportunities to use some form of active sensing to
disambiguate data from noisy or unreliable sensors. These disambiguating
actions typically take time and expend energy. One way to choose the next
disambiguating action is to select the action with the greatest expected
entropy reduction, or information gain. In this work, we consider active
sensing in aid of stereo vision for robotics. Stereo vision is a powerful
sensing technique for mobile robots, but it can fail in scenes that lack strong
texture. In such cases, a structured light source, such as vertical laser line
can be used for disambiguation. By treating the stereo matching problem as a
specially structured HMM-like graphical model, we demonstrate that for a scan
line with n columns and maximum stereo disparity d, the entropy minimizing aim
point for the laser can be selected in O(nd) time - cost no greater than the
stereo algorithm itself. In contrast, a typical HMM formulation would suggest
at least O(nd^2) time for the entropy calculation alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6879</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6879</id><created>2012-06-27</created><authors><author><keyname>Sanner</keyname><forenames>Scott</forenames></author><author><keyname>Boutilier</keyname><forenames>Craig</forenames></author></authors><title>Practical Linear Value-approximation Techniques for First-order MDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-409-417</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work on approximate linear programming (ALP) techniques for
first-order Markov Decision Processes (FOMDPs) represents the value function
linearly w.r.t. a set of first-order basis functions and uses linear
programming techniques to determine suitable weights. This approach offers the
advantage that it does not require simplification of the first-order value
function, and allows one to solve FOMDPs independent of a specific domain
instantiation. In this paper, we address several questions to enhance the
applicability of this work: (1) Can we extend the first-order ALP framework to
approximate policy iteration to address performance deficiencies of previous
approaches? (2) Can we automatically generate basis functions and evaluate
their impact on value function quality? (3) How can we decompose intractable
problems with universally quantified rewards into tractable subproblems? We
propose answers to these questions along with a number of novel optimizations
and provide a comparative empirical evaluation on logistics problems from the
ICAPS 2004 Probabilistic Planning Competition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6883</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6883</id><created>2012-06-28</created><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Woznica</keyname><forenames>Adam</forenames></author><author><keyname>Kalousis</keyname><forenames>Alexandros</forenames></author></authors><title>Learning Neighborhoods for Metric Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Metric learning methods have been shown to perform well on different learning
tasks. Many of them rely on target neighborhood relationships that are computed
in the original feature space and remain fixed throughout learning. As a
result, the learned metric reflects the original neighborhood relations. We
propose a novel formulation of the metric learning problem in which, in
addition to the metric, the target neighborhood relations are also learned in a
two-step iterative approach. The new formulation can be seen as a
generalization of many existing metric learning methods. The formulation
includes a target neighbor assignment rule that assigns different numbers of
neighbors to instances according to their quality; `high quality' instances get
more neighbors. We experiment with two of its instantiations that correspond to
the metric learning algorithms LMNN and MCML and compare it to other metric
learning methods on a number of datasets. The experimental results show
state-of-the-art performance and provide evidence that learning the
neighborhood relations does improve predictive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6899</identifier>
 <datestamp>2012-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6899</id><created>2012-06-28</created><updated>2012-07-16</updated><authors><author><keyname>Thomas</keyname><forenames>Antoine</forenames></author><author><keyname>Ouangraoua</keyname><forenames>A&#xef;da</forenames></author><author><keyname>Varr&#xe9;</keyname><forenames>Jean-St&#xe9;phane</forenames></author></authors><title>Tandem halving problems by DCJ</title><categories>cs.DS q-bio.GN</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6918</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6918</id><created>2012-06-28</created><authors><author><keyname>Murin</keyname><forenames>Yonathan</forenames></author><author><keyname>Dabora</keyname><forenames>Ron</forenames></author><author><keyname>G&#xfc;nd&#xfc;z</keyname><forenames>Deniz</forenames></author></authors><title>Source-Channel Coding for the Multiple-Access Relay Channel</title><categories>cs.IT math.IT</categories><comments>Presented in ISWCS 2011, Aachen, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers reliable transmission of general correlated sources over
the multiple-access relay channel (MARC) and the multiple-access broadcast
relay channel (MABRC). In MARCs only the destination is interested in a
reconstruction of the sources, while in MABRCs both the relay and the
destination want to reconstruct the sources. We assume that both the relay and
the destination have correlated side information. We find sufficient conditions
for reliable communication based on operational separation, as well as
necessary conditions on the achievable source-channel rate. For correlated
sources transmitted over fading Gaussian MARCs and MABRCs we find conditions
under which informational separation is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6921</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6921</id><created>2012-06-28</created><authors><author><keyname>Baek</keyname><forenames>Seung Ki</forenames></author><author><keyname>Choi</keyname><forenames>Jung-Kyoo</forenames></author><author><keyname>Kim</keyname><forenames>Beom Jun</forenames></author></authors><title>Dworkin's Paradox</title><categories>physics.soc-ph cs.SI</categories><comments>15 pages, 4 figures</comments><journal-ref>PLoS One 7, e38529 (2012)</journal-ref><doi>10.1371/journal.pone.0038529</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How to distribute welfare in a society is a key issue in the subject of
distributional justice, which is deeply involved with notions of fairness.
Following a thought experiment by Dworkin, this work considers a society of
individuals with different preferences on the welfare distribution and an
official to mediate the coordination among them. Based on a simple assumption
that an individual's welfare is proportional to how her preference is fulfilled
by the actual distribution, we show that an egalitarian preference is a strict
Nash equilibrium and can be favorable even in certain inhomogeneous situations.
These suggest how communication can encourage and secure a notion of fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6938</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6938</id><created>2012-06-29</created><authors><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Nie</keyname><forenames>Canping</forenames></author><author><keyname>Lu</keyname><forenames>Liya</forenames></author><author><keyname>Qian</keyname><forenames>Gongbin</forenames></author></authors><title>MIMO Physical Layer Network Coding Based on VBLAST Detection</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For MIMO two-way relay channel, this paper proposes a novel scheme,
VBLAST-PNC, to transform the two superimposed packets received by the relay to
their network coding form. Different from traditional schemes, which tries to
detect each packet before network coding them, VBLAST-PNC detects the summation
of the two packets before network coding. In particular, after firstly
detecting the second layer signal in 2-by-2 MIMO system with VBLAST, we only
cancel part of the detected signal, rather than canceling all the components,
from the first layer. Then we directly map the obtained signal, summation of
the first layer and the second layer, to their network coding form. With such
partial interference cancellation, the error propagation effect is mitigated
and the performance is thus improved as shown in simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6940</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6940</id><created>2012-06-29</created><authors><author><keyname>Roune</keyname><forenames>Bjarke Hammersholt</forenames></author><author><keyname>Stillman</keyname><forenames>Michael</forenames></author></authors><title>Practical Groebner Basis Computation</title><categories>cs.SC cs.DS math.AC</categories><comments>Full online version including appendices, 17 pages; Proceedings of
  the International Symposium on Symbolic and Algebraic Computation (ISSAC)
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on our experiences exploring state of the art Groebner basis
computation. We investigate signature based algorithms in detail. We also
introduce new practical data structures and computational techniques for use in
both signature based Groebner basis algorithms and more traditional variations
of the classic Buchberger algorithm. Our conclusions are based on experiments
using our new freely available open source standalone C++ library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6943</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6943</id><created>2012-06-29</created><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Lee</keyname><forenames>Changryeol</forenames></author></authors><title>Single-Source Dilation-Bounded Minimum Spanning Trees</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set $S$ of points in the plane, a geometric network for $S$ is a
graph $G$ with vertex set $S$ and straight edges. We consider a broadcasting
situation, where one point $r \in S$ is a designated source. Given a dilation
factor $\delta$, we ask for a geometric network $G$ such that for every point
$v \in S$ there is a path from $r$ to $v$ in $G$ of length at most
$\delta|rv|$, and such that the total edge length is minimized. We show that
finding such a network of minimum total edge length is NP-hard, and give an
approximation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.6982</identifier>
 <datestamp>2013-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.6982</id><created>2012-06-29</created><updated>2013-02-01</updated><authors><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Optimal Dynamic Sequence Representations</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a data structure that supports access, rank and select queries,
as well as symbol insertions and deletions, on a string $S[1,n]$ over alphabet
$[1..\sigma]$ in time $O(\lg n/\lg\lg n)$, which is optimal even on binary
sequences and in the amortized sense. Our time is worst-case for the queries
and amortized for the updates. This complexity is better than the best previous
ones by a $\Theta(1+\lg\sigma/\lg\lg n)$ factor. We also design a variant where
times are worst-case, yet rank and updates take $O(\lg n)$ time. Our structure
uses $nH_0(S)+o(n\lg\sigma) + O(\sigma\lg n)$ bits, where $H_0(S)$ is the
zero-order entropy of $S$. Finally, we pursue various extensions and
applications of the result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7038</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7038</id><created>2012-06-25</created><updated>2012-07-05</updated><authors><author><keyname>Aroudi</keyname><forenames>El</forenames></author></authors><title>Comments on &quot;Comments on &quot;Prediction of Subharmonic Oscillation in
  Switching Converters Under Different Control Strategies&quot;&quot;</title><categories>cs.SY math.DS nlin.CD</categories><comments>arXiv admin note: This submission has been removed by arXiv
  administrators due to unprofessional personal attack</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  arXiv admin note: This submission has been removed by arXiv administrators
due to unprofessional personal attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7050</identifier>
 <datestamp>2014-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7050</id><created>2012-06-29</created><updated>2014-01-27</updated><authors><author><keyname>O'Callaghan</keyname><forenames>Derek</forenames></author><author><keyname>Greene</keyname><forenames>Derek</forenames></author><author><keyname>Conway</keyname><forenames>Maura</forenames></author><author><keyname>Carthy</keyname><forenames>Joe</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>An Analysis of Interactions Within and Between Extreme Right Communities
  in Social Media</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>20 pages, 6 figures. Additional topic analysis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many extreme right groups have had an online presence for some time through
the use of dedicated websites. This has been accompanied by increased activity
in social media platforms in recent years, enabling the dissemination of
extreme right content to a wider audience. In this paper, we present an
analysis of the activity of a selection of such groups on Twitter, using
network representations based on reciprocal follower and interaction
relationships, while also analyzing topics found in their corresponding tweets.
International relationships between certain extreme right groups across
geopolitical boundaries are initially identified. Furthermore, we also discover
stable communities of accounts within local interaction networks, in addition
to associated topics, where the underlying extreme right ideology of these
communities is often identifiable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7051</identifier>
 <datestamp>2013-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7051</id><created>2012-06-29</created><updated>2013-04-22</updated><authors><author><keyname>Hoffman</keyname><forenames>Matt</forenames></author><author><keyname>Blei</keyname><forenames>David M.</forenames></author><author><keyname>Wang</keyname><forenames>Chong</forenames></author><author><keyname>Paisley</keyname><forenames>John</forenames></author></authors><title>Stochastic Variational Inference</title><categories>stat.ML cs.AI stat.CO stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop stochastic variational inference, a scalable algorithm for
approximating posterior distributions. We develop this technique for a large
class of probabilistic models and we demonstrate it with two probabilistic
topic models, latent Dirichlet allocation and the hierarchical Dirichlet
process topic model. Using stochastic variational inference, we analyze several
large collections of documents: 300K articles from Nature, 1.8M articles from
The New York Times, and 3.8M articles from Wikipedia. Stochastic inference can
easily handle data sets of this size and outperforms traditional variational
inference, which can only handle a smaller subset. (We also show that the
Bayesian nonparametric topic model outperforms its parametric counterpart.)
Stochastic variational inference lets us apply complex Bayesian models to
massive data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7064</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7064</id><created>2012-06-29</created><authors><author><keyname>Vujosevic-Janicic</keyname><forenames>Milena</forenames></author><author><keyname>Nikolic</keyname><forenames>Mladen</forenames></author><author><keyname>Tosic</keyname><forenames>Dusan</forenames></author><author><keyname>Kuncak</keyname><forenames>Viktor</forenames></author></authors><title>Software Verification and Graph Similarity for Automated Evaluation of
  Students' Assignments</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we promote introducing software verification and control flow
graph similarity measurement in automated evaluation of students' programs. We
present a new grading framework that merges results obtained by combination of
these two approaches with results obtained by automated testing, leading to
improved quality and precision of automated grading. These two approaches are
also useful in providing a comprehensible feedback that can help students to
improve the quality of their programs We also present our corresponding tools
that are publicly available and open source. The tools are based on LLVM
low-level intermediate code representation, so they could be applied to a
number of programming languages. Experimental evaluation of the proposed
grading framework is performed on a corpus of university students' programs
written in programming language C. Results of the experiments show that
automatically generated grades are highly correlated with manually determined
grades suggesting that the presented tools can find real-world applications in
studying and grading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7067</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7067</id><created>2012-06-29</created><updated>2016-01-12</updated><authors><author><keyname>Fisikopoulos</keyname><forenames>Vissarion</forenames></author><author><keyname>Pe&#xf1;aranda</keyname><forenames>Luis</forenames></author></authors><title>Faster Geometric Algorithms via Dynamic Determinant Computation</title><categories>cs.CG</categories><comments>29 pages, 8 figures, 3 tables</comments><journal-ref>Computational Geometry: Theory and Applications, 54:1--16, 2016</journal-ref><doi>10.1016/j.comgeo.2015.12.001</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The computation of determinants or their signs is the core procedure in many
important geometric algorithms, such as convex hull, volume and point location.
As the dimension of the computation space grows, a higher percentage of the
total computation time is consumed by these computations. In this paper we
study the sequences of determinants that appear in geometric algorithms. The
computation of a single determinant is accelerated by using the information
from the previous computations in that sequence.
  We propose two dynamic determinant algorithms with quadratic arithmetic
complexity when employed in convex hull and volume computations, and with
linear arithmetic complexity when used in point location problems. We implement
the proposed algorithms and perform an extensive experimental analysis. On one
hand, our analysis serves as a performance study of state-of-the-art
determinant algorithms and implementations. On the other hand, we demonstrate
the supremacy of our methods over state-of-the-art implementations of
determinant and geometric algorithms. Our experimental results include a 20 and
78 times speed-up in volume and point location computations in dimension 6 and
11 respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7105</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7105</id><created>2012-06-29</created><updated>2014-02-10</updated><authors><author><keyname>Hermelin</keyname><forenames>Danny</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Erik Jan</forenames></author></authors><title>Parameterized Complexity of Induced Graph Matching on Claw-Free Graphs</title><categories>cs.DM cs.CC cs.DS</categories><comments>Conference version appeared in ESA 2012. This version is a
  substantial revision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Induced Graph Matching problem asks to find k disjoint induced subgraphs
isomorphic to a given graph H in a given graph G such that there are no edges
between vertices of different subgraphs. This problem generalizes the classical
Independent Set and Induced Matching problems, among several other problems. We
show that Induced Graph Matching is fixed-parameter tractable in k on claw-free
graphs when H is a fixed connected graph, and even admits a polynomial kernel
when H is a complete graph. Both results rely on a new, strong, and generic
algorithmic structure theorem for claw-free graphs.
  Complementing the above positive results, we prove W[1]-hardness of Induced
Graph Matching on graphs excluding K_1,4 as an induced subgraph, for any fixed
complete graph H. In particular, we show that Independent Set is W[1]-hard on
K_1,4-free graphs.
  Finally, we consider the complexity of Induced Graph Matching on a large
subclass of claw-free graphs, namely on proper circular-arc graphs. We show
that the problem is either polynomial-time solvable or NP-complete, depending
on the connectivity of H and the structure of G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7111</identifier>
 <datestamp>2014-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7111</id><created>2012-06-15</created><updated>2014-01-13</updated><authors><author><keyname>Veeningen</keyname><forenames>Meilof</forenames></author><author><keyname>de Weger</keyname><forenames>Benne</forenames></author><author><keyname>Zannone</keyname><forenames>Nicola</forenames></author></authors><title>Data Minimisation in Communication Protocols: A Formal Analysis
  Framework and Application to Identity Management</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing amount of personal information exchanged over the Internet,
privacy is becoming more and more a concern for users. One of the key
principles in protecting privacy is data minimisation. This principle requires
that only the minimum amount of information necessary to accomplish a certain
goal is collected and processed. &quot;Privacy-enhancing&quot; communication protocols
have been proposed to guarantee data minimisation in a wide range of
applications. However, currently there is no satisfactory way to assess and
compare the privacy they offer in a precise way: existing analyses are either
too informal and high-level, or specific for one particular system. In this
work, we propose a general formal framework to analyse and compare
communication protocols with respect to privacy by data minimisation. Privacy
requirements are formalised independent of a particular protocol in terms of
the knowledge of (coalitions of) actors in a three-layer model of personal
information. These requirements are then verified automatically for particular
protocols by computing this knowledge from a description of their
communication. We validate our framework in an identity management (IdM) case
study. As IdM systems are used more and more to satisfy the increasing need for
reliable on-line identification and authentication, privacy is becoming an
increasingly critical issue. We use our framework to analyse and compare four
identity management systems. Finally, we discuss the completeness and
(re)usability of the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1206.7112</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1206.7112</id><created>2012-06-29</created><authors><author><keyname>Kao</keyname><forenames>Yi-Hao</forenames></author><author><keyname>Van Roy</keyname><forenames>Benjamin</forenames></author><author><keyname>Rubin</keyname><forenames>Daniel</forenames></author><author><keyname>Xu</keyname><forenames>Jiajing</forenames></author><author><keyname>Faruque</keyname><forenames>Jessica</forenames></author><author><keyname>Napel</keyname><forenames>Sandy</forenames></author></authors><title>A Hybrid Method for Distance Metric Learning</title><categories>cs.LG cs.IR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning a measure of distance among vectors in a
feature space and propose a hybrid method that simultaneously learns from
similarity ratings assigned to pairs of vectors and class labels assigned to
individual vectors. Our method is based on a generative model in which class
labels can provide information that is not encoded in feature vectors but yet
relates to perceived similarity between objects. Experiments with synthetic
data as well as a real medical image retrieval problem demonstrate that
leveraging class labels through use of our method improves retrieval
performance significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0016</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0016</id><created>2012-06-29</created><updated>2012-07-08</updated><authors><author><keyname>Liang</keyname><forenames>Ruchen Duan Yingbin</forenames></author></authors><title>Bounds and Capacity Theorems for Cognitive Interference Channels with
  State</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of cognitive interference channel with state is investigated, in
which two transmitters (transmitters 1 and 2) communicate with two receivers
(receivers 1 and 2) over an interference channel. The two transmitters jointly
transmit a common message to the two receivers, and transmitter 2 also sends a
separate message to receiver 2. The channel is corrupted by an independent and
identically distributed (i.i.d.) state sequence. The scenario in which the
state sequence is noncausally known only at transmitter 2 is first studied. For
the discrete memoryless channel and its degraded version, inner and outer
bounds on the capacity region are obtained. The capacity region is
characterized for the degraded semideterministic channel and channels that
satisfy a less noisy condition. The Gaussian channels are further studied,
which are partitioned into two cases based on how the interference compares
with the signal at receiver 1. For each case, inner and outer bounds on the
capacity region are derived, and partial boundary of the capacity region is
characterized. The full capacity region is characterized for channels that
satisfy certain conditions. The second scenario in which the state sequence is
noncausally known at both transmitter 2 and receiver 2 is further studied. The
capacity region is obtained for both the discrete memoryless and Gaussian
channels. It is also shown that this capacity is achieved by certain Gaussian
channels with state noncausally known only at transmitter 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0017</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0017</id><created>2012-06-29</created><authors><author><keyname>Greene</keyname><forenames>Derek</forenames></author><author><keyname>O'Callaghan</keyname><forenames>Derek</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>Identifying Topical Twitter Communities via User List Aggregation</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A particular challenge in the area of social media analysis is how to find
communities within a larger network of social interactions. Here a community
may be a group of microblogging users who post content on a coherent topic, or
who are associated with a specific event or news story. Twitter provides the
ability to curate users into lists, corresponding to meaningful topics or
themes. Here we describe an approach for crowdsourcing the list building
efforts of many different Twitter users, in order to identify topical
communities. This approach involves the use of ensemble community finding to
produce stable groupings of user lists, and by extension, individual Twitter
users. We examine this approach in the context of a case study surrounding the
detection of communities on Twitter relating to the London 2012 Olympics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0018</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0018</id><created>2012-06-12</created><authors><author><keyname>Elias</keyname><forenames>J. Robinson Ebi</forenames></author><author><keyname>Rajesh</keyname><forenames>R.</forenames></author></authors><title>Quasi-Orthogonal Space-Time-Frequency Trellis Codes for MIMO-OFDM
  Systems</title><categories>cs.IT math.IT</categories><doi>10.5121/ijsea.2012.3303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main objective of this project is to design the full-rate
Space-Time-Frequency Trellis code (STFTC), which is based on Quasi-Orthogonal
designs for Multiple-Input Multiple-Output (MIMO) Orthogonal Frequency Division
Multiplexing (OFDM) systems. The proposed Quasi-Orthogonal Space-Time-Frequency
Trellis code combines set partitioning and the structure of quasi-orthogonal
space-frequency designs in a systematic way. In addition to multipath diversity
and transmit diversity, the proposed code provides receive diversity, array
gain, and achieve high-coding gain over a frequency selective fading channel.
As simulation results demonstrate, the code outperforms the existing
Quasi-Orthogonal Space-Time-Frequency Trellis codes in terms of frame error
rate performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0023</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0023</id><created>2012-06-29</created><authors><author><keyname>Hansson</keyname><forenames>Anders</forenames></author><author><keyname>Liu</keyname><forenames>Zhang</forenames></author><author><keyname>Vandenberghe</keyname><forenames>Lieven</forenames></author></authors><title>Subspace System Identification via Weighted Nuclear Norm Optimization</title><categories>cs.SY</categories><comments>Submitted to IEEE Conference on Decision and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a subspace system identification method based on weighted nuclear
norm approximation. The weight matrices used in the nuclear norm minimization
are the same weights as used in standard subspace identification methods. We
show that the inclusion of the weights improves the performance in terms of fit
on validation data. As a second benefit, the weights reduce the size of the
optimization problems that need to be solved. Experimental results from
randomly generated examples as well as from the Daisy benchmark collection are
reported. The key to an efficient implementation is the use of the alternating
direction method of multipliers to solve the optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0032</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0032</id><created>2012-06-29</created><authors><author><keyname>Kar</keyname><forenames>Swarnendu</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Linear Coherent Estimation with Spatial Collaboration</title><categories>cs.IT math.IT</categories><comments>22 pages, 9 figures, submitted to IEEE Transactions on Information
  Theory, an earlier conference version can be found here:
  http://arxiv.org/abs/1205.3286</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A power constrained sensor network that consists of multiple sensor nodes and
a fusion center (FC) is considered, where the goal is to estimate a random
parameter of interest. In contrast to the distributed framework, the sensor
nodes may be partially connected, where individual nodes can update their
observations by (linearly) combining observations from other adjacent nodes.
The updated observations are communicated to the FC by transmitting through a
coherent multiple access channel. The optimal collaborative strategy is
obtained by minimizing the expected mean-square-error subject to power
constraints at the sensor nodes. Each sensor can utilize its available power
for both collaboration with other nodes and transmission to the FC. Two kinds
of constraints, namely the cumulative and individual power constraints are
considered. The effects due to imperfect information about observation and
channel gains are also investigated. The resulting performance improvement is
illustrated analytically through the example of a homogeneous network with
equicorrelated parameters. Assuming random geometric graph topology for
collaboration, numerical results demonstrate a significant reduction in
distortion even for a moderately connected network, particularly in the low
local-SNR regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0034</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0034</id><created>2012-06-29</created><authors><author><keyname>Bar-Yam</keyname><forenames>Yaneer Bar-Yam with Shlomiya</forenames></author><author><keyname>Bertrand</keyname><forenames>Karla Z.</forenames></author><author><keyname>Cohen</keyname><forenames>Nancy</forenames></author><author><keyname>Gard-Murray</keyname><forenames>Alexander S.</forenames></author><author><keyname>Harte</keyname><forenames>Helen P.</forenames></author><author><keyname>Leykum</keyname><forenames>Luci</forenames></author></authors><title>A Complex Systems Science Approach to Healthcare Costs and Quality</title><categories>physics.soc-ph cs.CY</categories><comments>27 pages + 19 page bibliography, 7 figures</comments><report-no>NECSI Report 2012-06-02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a mounting crisis in delivering affordable healthcare in the US. For
decades, key decision makers in the public and private sectors have considered
cost-effectiveness in healthcare a top priority. Their actions have focused on
putting a limit on fees, services, or care options. However, they have met with
limited success as costs have increased rapidly while the quality isn't
commensurate with the high costs. A new approach is needed. Here we provide
eight scientifically-based steps for improving the healthcare system. The core
of the approach is promoting the best use of resources by matching the people
and organization to the tasks they are good at, and providing the right
incentive structure. Harnessing costs need not mean sacrificing quality.
Quality service and low costs can be achieved by making sure the right people
and the right organizations deliver services. As an example, the frequent use
of emergency rooms for non-emergency care demonstrates the waste of resources
of highly capable individuals and facilities resulting in high costs and
ineffective care. Neither free markets nor managed care guarantees the best use
of resources. A different oversight system is needed to promote the right
incentives. Unlike managed care, effective oversight must not interfere with
the performance of care. Otherwise, cost control only makes care more
cumbersome. The eight steps we propose are designed to dramatically improve the
effectiveness of the healthcare system, both for those who receive services and
those who provide them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0036</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0036</id><created>2012-06-29</created><updated>2014-08-21</updated><authors><author><keyname>Fryer</keyname><forenames>Dashiell E. A.</forenames></author></authors><title>The Kullback-Leibler Divergence as a Lyapunov Function for Incentive
  Based Game Dynamics</title><categories>math.DS cs.GT cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown that the Kullback-Leibler divergence is a Lyapunov function
for the replicator equations at evolutionary stable states, or ESS. In this
paper we extend the result to a more general class of game dynamics. As a
result, sufficient conditions can be given for the asymptotic stability of rest
points for the entire class of incentive dynamics. The previous known results
will be can be shown as corollaries to the main theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0037</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0037</id><created>2012-06-29</created><authors><author><keyname>Fryer</keyname><forenames>Dashiell E. A.</forenames></author></authors><title>The Uniform Distribution in Incentive Dynamics</title><categories>cs.GT cs.IT math.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The uniform distribution is an important counterexample in game theory as
many of the canonical game dynamics have been shown not to converge to the
equilibrium in certain cases. In particular none of the canonical game dynamics
converge to the uniform distribution in a form of rock-paper-scissors where the
amount an agent can lose is more than the agent can win, despite this fact, it
is the unique Nash equilibrium. I will show that certain incentive dynamics are
asymptotically stable at the uniform distribution when it is an incentive
equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0043</identifier>
 <datestamp>2013-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0043</id><created>2012-06-30</created><updated>2013-01-15</updated><authors><author><keyname>Laekhanukit</keyname><forenames>Bundit</forenames></author><author><keyname>Vetta</keyname><forenames>Adrian</forenames></author><author><keyname>Wilfong</keyname><forenames>Gordon</forenames></author></authors><title>Routing Regardless of Network Stability</title><categories>cs.DS</categories><comments>ESA 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the effectiveness of packet routing in this model for the broad
class next-hop preferences with filtering. Here each node v has a filtering
list D(v) consisting of nodes it does not want its packets to route through.
Acceptable paths (those that avoid nodes in the filtering list) are ranked
according to the next-hop, that is, the neighbour of v that the path begins
with. On the negative side, we present a strong inapproximability result. For
filtering lists of cardinality at most one, given a network in which an
equilibrium is guaranteed to exist, it is NP-hard to approximate the maximum
number of packets that can be routed to within a factor of O(n^{1-\epsilon}),
for any constant \epsilon &gt;0. On the positive side, we give algorithms to show
that in two fundamental cases every packet will eventually route with
probability one. The first case is when each node's filtering list contains
only itself, that is, D(v)={v}. Moreover, with positive probability every
packet will be routed before the control plane reaches an equilibrium. The
second case is when all the filtering lists are empty, that is,
$\mathcal{D}(v)=\emptyset$. Thus, with probability one packets will route even
when the nodes don't care if their packets cycle! Furthermore, with probability
one every packet will route even when the control plane has em no equilibrium
at all.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0051</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0051</id><created>2012-06-30</created><authors><author><keyname>Ramezanian</keyname><forenames>Rasoul</forenames></author></authors><title>Computation Environments (2) Persistently Evolutionary Semantics</title><categories>cs.LO</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the manuscript titled &quot;Computation environment (1)&quot;, we introduced a
notion called computation environment as an interactive model for computation
and complexity theory. In this model, Turing machines are not autonomous
entities and find their meanings through the interaction between a computist
and a universal processor, and thus due to evolution of the universal
processor, the meanings of Turing machines could change. In this manuscript, we
discuss persistently evolutionary intensions. We introduce a new semantics,
called persistently evolutionary semantics, for predicate logic that the
meaning of function and predicate symbols are not already predetermined, and
predicate and function symbols find their meaning through the interaction of
the subject with the language. In (classic) model theory, the mathematician who
studies a structure is assumed as a god who lives out of the structure, and the
study of the mathematician does not effect the structure. The meaning of
predicate and function symbols are assumed to be independent of the
mathematician who does math. The persistently evolutionary semantics could be
regarded as a start of &quot;Interactive Model Theory&quot; as a new paradigm in model
theory (similar to the paradigm of interactive computation). In interactive
model theory, we suppose that a mathematical structure should consist of two
parts: 1) an intelligent agent (a subject), and 2) an environment (language),
and every things should find its meaning through the interaction of these two
parts. We introduce persistently evolutionary Kripke structure for
propositional and predicate logic. Also, we propose a persistently evolutionary
Kripke semantics for the notion of computation, where the intension of a code
of a Turing machine persistently evolve. We show that in this Kripke model the
subject can never know P = NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0052</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0052</id><created>2012-06-30</created><updated>2012-07-06</updated><authors><author><keyname>Andreas</keyname><forenames>Jacob</forenames></author></authors><title>The Complexity of Learning Principles and Parameters Grammars</title><categories>cs.FL cs.CL</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We investigate models for learning the class of context-free and
context-sensitive languages (CFLs and CSLs). We begin with a brief discussion
of some early hardness results which show that unrestricted language learning
is impossible, and unrestricted CFL learning is computationally infeasible; we
then briefly survey the literature on algorithms for learning restricted
subclasses of the CFLs. Finally, we introduce a new family of subclasses, the
principled parametric context-free grammars (and a corresponding family of
principled parametric context-sensitive grammars), which roughly model the
&quot;Principles and Parameters&quot; framework in psycholinguistics. We present three
hardness results: first, that the PPCFGs are not efficiently learnable given
equivalence and membership oracles, second, that the PPCFGs are not efficiently
learnable from positive presentations unless P = NP, and third, that the PPCSGs
are not efficiently learnable from positive presentations unless integer
factorization is in P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0057</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0057</id><created>2012-06-30</created><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Alain</keyname><forenames>Guillaume</forenames></author><author><keyname>Rifai</keyname><forenames>Salah</forenames></author></authors><title>Implicit Density Estimation by Local Moment Matching to Sample from
  Auto-Encoders</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work suggests that some auto-encoder variants do a good job of
capturing the local manifold structure of the unknown data generating density.
This paper contributes to the mathematical understanding of this phenomenon and
helps define better justified sampling algorithms for deep learning based on
auto-encoder variants. We consider an MCMC where each step samples from a
Gaussian whose mean and covariance matrix depend on the previous state, defines
through its asymptotic distribution a target density. First, we show that good
choices (in the sense of consistency) for these mean and covariance functions
are the local expected value and local covariance under that target density.
Then we show that an auto-encoder with a contractive penalty captures
estimators of these local moments in its reconstruction function and its
Jacobian. A contribution of this work is thus a novel alternative to
maximum-likelihood density estimation, which we call local moment matching. It
also justifies a recently proposed sampling algorithm for the Contractive
Auto-Encoder and extends it to the Denoising Auto-Encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0080</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0080</id><created>2012-06-30</created><authors><author><keyname>Ackerman</keyname><forenames>Eyal</forenames></author><author><keyname>Pinchasi</keyname><forenames>Rom</forenames></author></authors><title>A note on coloring line arrangements</title><categories>cs.CG math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the lines of every arrangement of $n$ lines in the plane can be
colored with $O(\sqrt{n/ \log n})$ colors such that no face of the arrangement
is monochromatic. This improves a bound of Bose et al. \cite{BCC12} by a
$\Theta(\sqrt{\log n})$ factor. Any further improvement on this bound will
improve the best known lower bound on the following problem of Erd\H{o}s:
Estimate the maximum number of points in general position within a set of $n$
points containing no four collinear points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0097</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0097</id><created>2012-06-30</created><authors><author><keyname>Guo</keyname><forenames>Ge</forenames></author><author><keyname>Wong</keyname><forenames>Wing Shing</forenames></author><author><keyname>Liu</keyname><forenames>Zhongchang</forenames></author></authors><title>Cooperative Target Realization in Multi-Agent Systems Allowing
  Choice-Based Actions</title><categories>cs.SY</categories><comments>31 pages, 5 figures</comments><report-no>FP-12-073</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study cooperative multi-agent systems in which the target
objective and the controls exercised by the agents are dependent on the choices
they made at initial system time. Such systems have been investigated in
several recently published papers, mainly from the perspective of system
analysis on issues such as control communication complexity, control energy
cost and the feasibility of realization of target functions. This paper
continues this line of research by developing optimal control design
methodology for linear systems that are collaboratively manipulated by multiple
agents based on their distributed choices. For target matrices that satisfy
particular structural constraints, we derive control algorithms that can
achieve the specified targets with minimum control cost. We compare
state-feedback as well as open-loop control strategies for target realization
and extend the optimality result to an arbitrary target matrix. The optimal
control solutions are obtained by minimizing the average control cost subject
to the set of specified target-state constraints by means of modern variation
theory and the Lagrange multiplier method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0099</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0099</id><created>2012-06-30</created><authors><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author><author><keyname>Kanamori</keyname><forenames>Takafumi</forenames></author><author><keyname>Suzuki</keyname><forenames>Taiji</forenames></author><author><keyname>Plessis</keyname><forenames>Marthinus Christoffel du</forenames></author><author><keyname>Liu</keyname><forenames>Song</forenames></author><author><keyname>Takeuchi</keyname><forenames>Ichiro</forenames></author></authors><title>Density-Difference Estimation</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of estimating the difference between two probability
densities. A naive approach is a two-step procedure of first estimating two
densities separately and then computing their difference. However, such a
two-step procedure does not necessarily work well because the first step is
performed without regard to the second step and thus a small error incurred in
the first stage can cause a big error in the second stage. In this paper, we
propose a single-shot procedure for directly estimating the density difference
without separately estimating two densities. We derive a non-parametric
finite-sample error bound for the proposed single-shot density-difference
estimator and show that it achieves the optimal convergence rate. The
usefulness of the proposed method is also demonstrated experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0117</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0117</id><created>2012-06-30</created><authors><author><keyname>Borgohain</keyname><forenames>Rajdeep</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Rule Based Expert System for Cerebral Palsy Diagnosis</title><categories>cs.AI</categories><comments>4 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of Artificial Intelligence is finding prominence not only in core
computer areas, but also in cross disciplinary areas including medical
diagnosis. In this paper, we present a rule based Expert System used in
diagnosis of Cerebral Palsy. The expert system takes user input and depending
on the symptoms of the patient, diagnoses if the patient is suffering from
Cerebral Palsy. The Expert System also classifies the Cerebral Palsy as mild,
moderate or severe based on the presented symptoms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0120</identifier>
 <datestamp>2014-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0120</id><created>2012-06-30</created><updated>2014-10-22</updated><authors><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Distributed Secret Dissemination Across a Network</title><categories>cs.CR cs.IT math.IT</categories><comments>Extended version of a paper presented at the International Symposium
  on Information Theory (ISIT) 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shamir's (n, k) threshold secret sharing is an important component of several
cryptographic protocols, such as those for secure multiparty-computation and
key management. These protocols typically assume the presence of direct
communication links from the dealer to all participants, in which case the
dealer can directly pass the shares of the secret to each participant. In this
paper, we consider the problem of secret sharing when the dealer does not have
direct communication links to all the participants, and instead, the dealer and
the participants form a general network. Existing methods are based on secure
message transmissions from the dealer to each participant requiring
considerable coordination in the network. In this paper, we present a
distributed algorithm for disseminating shares over a network, which we call
the SNEAK algorithm, requiring each node to know only the identities of its
one-hop neighbours. While SNEAK imposes a stronger condition on the network by
requiring the dealer to be what we call k-propagating rather than k-connected
as required by the existing solutions, we show that in addition to being
distributed, SNEAK achieves significant reduction in the communication cost and
the amount of randomness required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0122</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0122</id><created>2012-06-30</created><authors><author><keyname>Thakur</keyname><forenames>Manoj Rameshchandra</forenames></author></authors><title>A Distributed and Cooperative Approach to Botnet Detection Using Gossip
  Protocol</title><categories>cs.CR</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bots, in recent times, have posed a major threat to enterprise networks. With
the distributed nature of the way in which botnets operate, the problems faced
by enterprises have become acute. A bot is a program that operates as an agent
for a user and runs automated tasks over the internet, at a much higher rate
than would be possible for a human alone. A collection of bots in a network,
used for malicious purposes, is referred to as a botnet. In this paper we
suggested a distributed, co-operative approach towards detecting botnets is a
given network which is inspired by the gossip protocol. Each node in a given
network runs a standalone agent that computes a suspicion value for that node
after regular intervals. Each node in the network exchanges its suspicion
values with every other node in the network at regular intervals. The use of
gossip protocol ensures that if a node in the network is compromised, all other
nodes in the network are informed about it as soon as possible. Each node also
ensures that at any instance, by means of the gossip protocol, it maintains the
latest suspicion values of all the other nodes in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0132</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0132</id><created>2012-06-30</created><authors><author><keyname>Pimplikar</keyname><forenames>Rakesh</forenames></author><author><keyname>Sarawagi</keyname><forenames>Sunita</forenames></author></authors><title>Answering Table Queries on the Web using Column Keywords</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  908-919 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the design of a structured search engine which returns a
multi-column table in response to a query consisting of keywords describing
each of its columns. We answer such queries by exploiting the millions of
tables on the Web because these are much richer sources of structured knowledge
than free-format text. However, a corpus of tables harvested from arbitrary
HTML web pages presents huge challenges of diversity and redundancy not seen in
centrally edited knowledge bases. We concentrate on one concrete task in this
paper. Given a set of Web tables T1, . . ., Tn, and a query Q with q sets of
keywords Q1, . . ., Qq, decide for each Ti if it is relevant to Q and if so,
identify the mapping between the columns of Ti and query columns. We represent
this task as a graphical model that jointly maps all tables by incorporating
diverse sources of clues spanning matches in different parts of the table,
corpus-wide co-occurrence statistics, and content overlap across table columns.
We define a novel query segmentation model for matching keywords to table
columns, and a robust mechanism of exploiting content overlap across table
columns. We design efficient inference algorithms based on bipartite matching
and constrained graph cuts to solve the joint labeling task. Experiments on a
workload of 59 queries over a 25 million web table corpus shows significant
boost in accuracy over baseline IR methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0133</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0133</id><created>2012-06-30</created><authors><author><keyname>Leyffer</keyname><forenames>Sven</forenames></author><author><keyname>Safro</keyname><forenames>Ilya</forenames></author></authors><title>Fast Response to Infection Spread and Cyber Attacks on Large-Scale
  Networks</title><categories>cs.SI cs.CR physics.soc-ph q-bio.QM</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We present a strategy for designing fast methods of response to cyber attacks
and infection spread on complex weighted networks. In these networks, nodes can
be interpreted as primitive elements of the system, and weighted edges reflect
the strength of interaction among these elements. The proposed strategy belongs
to the family of multiscale methods whose goal is to approximate the system at
multiple scales of coarseness and to obtain a solution of microscopic scale by
combining the information from coarse scales. In recent years these methods
have demonstrated their potential for solving optimization and analysis
problems on large-scale networks. We consider an optimization problem that is
based on the SIS epidemiological model. The objective is to detect the network
nodes that have to be immunized in order to keep a low level of infection in
the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0134</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0134</id><created>2012-06-30</created><authors><author><keyname>Blunschi</keyname><forenames>Lukas</forenames></author><author><keyname>Jossen</keyname><forenames>Claudio</forenames></author><author><keyname>Kossman</keyname><forenames>Donald</forenames></author><author><keyname>Mori</keyname><forenames>Magdalini</forenames></author><author><keyname>Stockinger</keyname><forenames>Kurt</forenames></author></authors><title>SODA: Generating SQL for Business Users</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  932-943 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of data warehouses is to enable business analysts to make better
decisions. Over the years the technology has matured and data warehouses have
become extremely successful. As a consequence, more and more data has been
added to the data warehouses and their schemas have become increasingly
complex. These systems still work great in order to generate pre-canned
reports. However, with their current complexity, they tend to be a poor match
for non tech-savvy business analysts who need answers to ad-hoc queries that
were not anticipated. This paper describes the design, implementation, and
experience of the SODA system (Search over DAta Warehouse). SODA bridges the
gap between the business needs of analysts and the technical complexity of
current data warehouses. SODA enables a Google-like search experience for data
warehouses by taking keyword queries of business users and automatically
generating executable SQL. The key idea is to use a graph pattern matching
algorithm that uses the metadata model of the data warehouse. Our results with
real data from a global player in the financial services industry show that
SODA produces queries with high precision and recall, and makes it much easier
for business users to interactively explore highly-complex data warehouses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0135</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0135</id><created>2012-06-30</created><authors><author><keyname>Terrovitis</keyname><forenames>Manolis</forenames></author><author><keyname>Liagouris</keyname><forenames>John</forenames></author><author><keyname>Mamoulis</keyname><forenames>Nikos</forenames></author><author><keyname>Skiadopoulos</keyname><forenames>Spiros</forenames></author></authors><title>Privacy Preservation by Disassociation</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  944-955 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we focus on protection against identity disclosure in the
publication of sparse multidimensional data. Existing multidimensional
anonymization techniquesa) protect the privacy of users either by altering the
set of quasi-identifiers of the original data (e.g., by generalization or
suppression) or by adding noise (e.g., using differential privacy) and/or (b)
assume a clear distinction between sensitive and non-sensitive information and
sever the possible linkage. In many real world applications the above
techniques are not applicable. For instance, consider web search query logs.
Suppressing or generalizing anonymization methods would remove the most
valuable information in the dataset: the original query terms. Additionally,
web search query logs contain millions of query terms which cannot be
categorized as sensitive or non-sensitive since a term may be sensitive for a
user and non-sensitive for another. Motivated by this observation, we propose
an anonymization technique termed disassociation that preserves the original
terms but hides the fact that two or more different terms appear in the same
record. We protect the users' privacy by disassociating record terms that
participate in identifying combinations. This way the adversary cannot
associate with high probability a record with a rare combination of terms. To
the best of our knowledge, our proposal is the first to employ such a technique
to provide protection against identity disclosure. We propose an anonymization
algorithm based on our approach and evaluate its performance on real and
synthetic datasets, comparing it against other state-of-the-art methods based
on generalization and differential privacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0136</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0136</id><created>2012-06-30</created><authors><author><keyname>Kanagal</keyname><forenames>Bhargav</forenames></author><author><keyname>Ahmed</keyname><forenames>Amr</forenames></author><author><keyname>Pandey</keyname><forenames>Sandeep</forenames></author><author><keyname>Josifovski</keyname><forenames>Vanja</forenames></author><author><keyname>Yuan</keyname><forenames>Jeff</forenames></author><author><keyname>Garcia-Pueyo</keyname><forenames>Lluis</forenames></author></authors><title>Supercharging Recommender Systems using Taxonomies for Learning User
  Purchase Behavior</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  956-967 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems based on latent factor models have been effectively used
for understanding user interests and predicting future actions. Such models
work by projecting the users and items into a smaller dimensional space,
thereby clustering similar users and items together and subsequently compute
similarity between unknown user-item pairs. When user-item interactions are
sparse (sparsity problem) or when new items continuously appear (cold start
problem), these models perform poorly. In this paper, we exploit the
combination of taxonomies and latent factor models to mitigate these issues and
improve recommendation accuracy. We observe that taxonomies provide structure
similar to that of a latent factor model: namely, it imposes human-labeled
categories (clusters) over items. This leads to our proposed taxonomy-aware
latent factor model (TF) which combines taxonomies and latent factors using
additive models. We develop efficient algorithms to train the TF models, which
scales to large number of users/items and develop scalable
inference/recommendation algorithms by exploiting the structure of the
taxonomy. In addition, we extend the TF model to account for the temporal
dynamics of user interests using high-order Markov chains. To deal with
large-scale data, we develop a parallel multi-core implementation of our TF
model. We empirically evaluate the TF model for the task of predicting user
purchases using a real-world shopping dataset spanning more than a million
users and products. Our experiments demonstrate the benefits of using our TF
models over existing approaches, in terms of both prediction accuracy and
running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0137</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0137</id><created>2012-06-30</created><authors><author><keyname>Ahmad</keyname><forenames>Yanif</forenames></author><author><keyname>Kennedy</keyname><forenames>Oliver</forenames></author><author><keyname>Koch</keyname><forenames>Christoph</forenames></author><author><keyname>Nikolic</keyname><forenames>Milos</forenames></author></authors><title>DBToaster: Higher-order Delta Processing for Dynamic, Frequently Fresh
  Views</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  968-979 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications ranging from algorithmic trading to scientific data analysis
require realtime analytics based on views over databases that change at very
high rates. Such views have to be kept fresh at low maintenance cost and
latencies. At the same time, these views have to support classical SQL, rather
than window semantics, to enable applications that combine current with aged or
historical data. In this paper, we present viewlet transforms, a recursive
finite differencing technique applied to queries. The viewlet transform
materializes a query and a set of its higher-order deltas as views. These views
support each other's incremental maintenance, leading to a reduced overall view
maintenance cost. The viewlet transform of a query admits efficient evaluation,
the elimination of certain expensive query operations, and aggressive
parallelization. We develop viewlet transforms into a workable query execution
technique, present a heuristic and cost-based optimization framework, and
report on experiments with a prototype dynamic data management system that
combines viewlet transforms with an optimizing compilation technique. The
system supports tens of thousands of complete view refreshes a second for a
wide range of queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0138</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0138</id><created>2012-06-30</created><authors><author><keyname>Agarwal</keyname><forenames>Manoj K</forenames></author><author><keyname>Ramamritham</keyname><forenames>Krithi</forenames></author><author><keyname>Bhide</keyname><forenames>Manish</forenames></author></authors><title>Real Time Discovery of Dense Clusters in Highly Dynamic Graphs:
  Identifying Real World Events in Highly Dynamic Environments</title><categories>cs.DB cs.SI physics.soc-ph</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  980-991 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to their real time nature, microblog streams are a rich source of dynamic
information, for example, about emerging events. Existing techniques for
discovering such events from a microblog stream in real time (such as Twitter
trending topics), have several lacunae when used for discovering emerging
events; extant graph based event detection techniques are not practical in
microblog settings due to their complexity; and conventional techniques, which
have been developed for blogs, web-pages, etc., involving the use of keyword
search, are only useful for finding information about known events. Hence, in
this paper, we present techniques to discover events that are unraveling in
microblog message streams in real time so that such events can be reported as
soon as they occur. We model the problem as discovering dense clusters in
highly dynamic graphs. Despite many recent advances in graph analysis, ours is
the first technique to identify dense clusters in massive and highly dynamic
graphs in real time. Given the characteristics of microblog streams, in order
to find clusters without missing any events, we propose and exploit a novel
graph property which we call short-cycle property. Our algorithms find these
clusters efficiently in spite of rapid changes to the microblog streams.
Further we present a novel ranking function to identify the important events.
Besides proving the correctness of our algorithms we show their practical
utility by evaluating them using real world microblog data. These demonstrate
our technique's ability to discover, with high precision and recall, emerging
events in high intensity data streams in real time. Many recent web
applications create data which can be represented as massive dynamic graphs.
Our technique can be easily extended to discover, in real time, interesting
patterns in such graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0139</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0139</id><created>2012-06-30</created><authors><author><keyname>Papapetrou</keyname><forenames>Odysseas</forenames></author><author><keyname>Garofalakis</keyname><forenames>Minos</forenames></author><author><keyname>Deligiannakis</keyname><forenames>Antonios</forenames></author></authors><title>Sketch-based Querying of Distributed Sliding-Window Data Streams</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  992-1003 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While traditional data-management systems focus on evaluating single, ad-hoc
queries over static data sets in a centralized setting, several emerging
applications require (possibly, continuous) answers to queries on dynamic data
that is widely distributed and constantly updated. Furthermore, such query
answers often need to discount data that is &quot;stale&quot;, and operate solely on a
sliding window of recent data arrivals (e.g., data updates occurring over the
last 24 hours). Such distributed data streaming applications mandate novel
algorithmic solutions that are both time- and space-efficient (to manage
high-speed data streams), and also communication-efficient (to deal with
physical data distribution). In this paper, we consider the problem of complex
query answering over distributed, high-dimensional data streams in the
sliding-window model. We introduce a novel sketching technique (termed
ECM-sketch) that allows effective summarization of streaming data over both
time-based and count-based sliding windows with probabilistic accuracy
guarantees. Our sketch structure enables point as well as inner-product
queries, and can be employed to address a broad range of problems, such as
maintaining frequency statistics, finding heavy hitters, and computing
quantiles in the sliding-window model. Focusing on distributed environments, we
demonstrate how ECM-sketches of individual, local streams can be composed to
generate a (low-error) ECM-sketch summary of the order-preserving aggregation
of all streams; furthermore, we show how ECM-sketches can be exploited for
continuous monitoring of sliding-window queries over distributed streams. Our
extensive experimental study with two real-life data sets validates our
theoretical claims and verifies the effectiveness of our techniques. To the
best of our knowledge, ours is the first work to address efficient,
guaranteed-error complex query answ...[truncated].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0140</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0140</id><created>2012-06-30</created><authors><author><keyname>Vo</keyname><forenames>Hoang Tam</forenames></author><author><keyname>Wang</keyname><forenames>Sheng</forenames></author><author><keyname>Agrawal</keyname><forenames>Divyakant</forenames></author><author><keyname>Chen</keyname><forenames>Gang</forenames></author><author><keyname>Ooi</keyname><forenames>Beng Chin</forenames></author></authors><title>LogBase: A Scalable Log-structured Database System in the Cloud</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  1004-1015 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous applications such as financial transactions (e.g., stock trading)
are write-heavy in nature. The shift from reads to writes in web applications
has also been accelerating in recent years. Write-ahead-logging is a common
approach for providing recovery capability while improving performance in most
storage systems. However, the separation of log and application data incurs
write overheads observed in write-heavy environments and hence adversely
affects the write throughput and recovery time in the system. In this paper, we
introduce LogBase - a scalable log-structured database system that adopts
log-only storage for removing the write bottleneck and supporting fast system
recovery. LogBase is designed to be dynamically deployed on commodity clusters
to take advantage of elastic scaling property of cloud environments. LogBase
provides in-memory multiversion indexes for supporting efficient access to data
maintained in the log. LogBase also supports transactions that bundle read and
write operations spanning across multiple records. We implemented the proposed
system and compared it with HBase and a disk-based log-structured
record-oriented system modeled after RAMCloud. The experimental results show
that LogBase is able to provide sustained write throughput, efficient data
access out of the cache, and effective system recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0141</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0141</id><created>2012-06-30</created><authors><author><keyname>Lu</keyname><forenames>Wei</forenames></author><author><keyname>Shen</keyname><forenames>Yanyan</forenames></author><author><keyname>Chen</keyname><forenames>Su</forenames></author><author><keyname>Ooi</keyname><forenames>Beng Chin</forenames></author></authors><title>Efficient Processing of k Nearest Neighbor Joins using MapReduce</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  1016-1027 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  k nearest neighbor join (kNN join), designed to find k nearest neighbors from
a dataset S for every object in another dataset R, is a primitive operation
widely adopted by many data mining applications. As a combination of the k
nearest neighbor query and the join operation, kNN join is an expensive
operation. Given the increasing volume of data, it is difficult to perform a
kNN join on a centralized machine efficiently. In this paper, we investigate
how to perform kNN join using MapReduce which is a well-accepted framework for
data-intensive applications over clusters of computers. In brief, the mappers
cluster objects into groups; the reducers perform the kNN join on each group of
objects separately. We design an effective mapping mechanism that exploits
pruning rules for distance filtering, and hence reduces both the shuffling and
computational costs. To reduce the shuffling cost, we propose two approximate
algorithms to minimize the number of replicas. Extensive experiments on our
in-house cluster demonstrate that our proposed methods are efficient, robust
and scalable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0142</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0142</id><created>2012-06-30</created><authors><author><keyname>Laptev</keyname><forenames>Nikolay</forenames></author><author><keyname>Zeng</keyname><forenames>Kai</forenames></author><author><keyname>Zaniolo</keyname><forenames>Carlo</forenames></author></authors><title>Early Accurate Results for Advanced Analytics on MapReduce</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  1028-1039 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximate results based on samples often provide the only way in which
advanced analytical applications on very massive data sets can satisfy their
time and resource constraints. Unfortunately, methods and tools for the
computation of accurate early results are currently not supported in
MapReduce-oriented systems although these are intended for `big data'.
Therefore, we proposed and implemented a non-parametric extension of Hadoop
which allows the incremental computation of early results for arbitrary
work-flows, along with reliable on-line estimates of the degree of accuracy
achieved so far in the computation. These estimates are based on a technique
called bootstrapping that has been widely employed in statistics and can be
applied to arbitrary functions and data distributions. In this paper, we
describe our Early Accurate Result Library (EARL) for Hadoop that was designed
to minimize the changes required to the MapReduce framework. Various tests of
EARL of Hadoop are presented to characterize the frequent situations where EARL
can provide major speed-ups over the current version of Hadoop.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0143</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0143</id><created>2012-06-30</created><authors><author><keyname>Liu</keyname><forenames>Xuan</forenames></author><author><keyname>Lu</keyname><forenames>Meiyu</forenames></author><author><keyname>Ooi</keyname><forenames>Beng Chin</forenames></author><author><keyname>Shen</keyname><forenames>Yanyan</forenames></author><author><keyname>Wu</keyname><forenames>Sai</forenames></author><author><keyname>Zhang</keyname><forenames>Meihui</forenames></author></authors><title>CDAS: A Crowdsourcing Data Analytics System</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  1040-1051 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some complex problems, such as image tagging and natural language processing,
are very challenging for computers, where even state-of-the-art technology is
yet able to provide satisfactory accuracy. Therefore, rather than relying
solely on developing new and better algorithms to handle such tasks, we look to
the crowdsourcing solution -- employing human participation -- to make good the
shortfall in current technology. Crowdsourcing is a good supplement to many
computer tasks. A complex job may be divided into computer-oriented tasks and
human-oriented tasks, which are then assigned to machines and humans
respectively. To leverage the power of crowdsourcing, we design and implement a
Crowdsourcing Data Analytics System, CDAS. CDAS is a framework designed to
support the deployment of various crowdsourcing applications. The core part of
CDAS is a quality-sensitive answering model, which guides the crowdsourcing
engine to process and monitor the human tasks. In this paper, we introduce the
principles of our quality-sensitive model. To satisfy user required accuracy,
the model guides the crowdsourcing query engine for the design and processing
of the corresponding crowdsourcing jobs. It provides an estimated accuracy for
each generated result based on the human workers' historical performances. When
verifying the quality of the result, the model employs an online strategy to
reduce waiting time. To show the effectiveness of the model, we implement and
deploy two analytics jobs on CDAS, a twitter sentiment analytics job and an
image tagging job. We use real Twitter and Flickr data as our queries
respectively. We compare our approaches with state-of-the-art classification
and image annotation techniques. The results show that the human-assisted
methods can indeed achieve a much higher accuracy. By embedding the
quality-sensitive model into crowdsourcing query engine, we
effectiv...[truncated].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0144</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0144</id><created>2012-06-30</created><authors><author><keyname>Sachan</keyname><forenames>Mayank</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author></authors><title>Mining Statistically Significant Substrings using the Chi-Square
  Statistic</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  1052-1063 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of identification of statistically significant patterns in a
sequence of data has been applied to many domains such as intrusion detection
systems, financial models, web-click records, automated monitoring systems,
computational biology, cryptology, and text analysis. An observed pattern of
events is deemed to be statistically significant if it is unlikely to have
occurred due to randomness or chance alone. We use the chi-square statistic as
a quantitative measure of statistical significance. Given a string of
characters generated from a memoryless Bernoulli model, the problem is to
identify the substring for which the empirical distribution of single letters
deviates the most from the distribution expected from the generative Bernoulli
model. This deviation is captured using the chi-square measure. The most
significant substring (MSS) of a string is thus defined as the substring having
the highest chi-square value. Till date, to the best of our knowledge, there
does not exist any algorithm to find the MSS in better than O(n^2) time, where
n denotes the length of the string. In this paper, we propose an algorithm to
find the most significant substring, whose running time is O(n^{3/2}) with high
probability. We also study some variants of this problem such as finding the
top-t set, finding all substrings having chi-square greater than a fixed
threshold and finding the MSS among substrings greater than a given length. We
experimentally demonstrate the asymptotic behavior of the MSS on varying the
string size and alphabet size. We also describe some applications of our
algorithm on cryptology and real world data from finance and sports. Finally,
we compare our technique with the existing heuristics for finding the MSS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0145</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0145</id><created>2012-06-30</created><authors><author><keyname>Albutiu</keyname><forenames>Martina-Cezara</forenames></author><author><keyname>Kemper</keyname><forenames>Alfons</forenames></author><author><keyname>Neumann</keyname><forenames>Thomas</forenames></author></authors><title>Massively Parallel Sort-Merge Joins in Main Memory Multi-Core Database
  Systems</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  1064-1075 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two emerging hardware trends will dominate the database system technology in
the near future: increasing main memory capacities of several TB per server and
massively parallel multi-core processing. Many algorithmic and control
techniques in current database technology were devised for disk-based systems
where I/O dominated the performance. In this work we take a new look at the
well-known sort-merge join which, so far, has not been in the focus of research
in scalable massively parallel multi-core data processing as it was deemed
inferior to hash joins. We devise a suite of new massively parallel sort-merge
(MPSM) join algorithms that are based on partial partition-based sorting.
Contrary to classical sort-merge joins, our MPSM algorithms do not rely on a
hard to parallelize final merge step to create one complete sort order. Rather
they work on the independently created runs in parallel. This way our MPSM
algorithms are NUMA-affine as all the sorting is carried out on local memory
partitions. An extensive experimental evaluation on a modern 32-core machine
with one TB of main memory proves the competitive performance of MPSM on large
main memory databases with billions of objects. It scales (almost) linearly in
the number of employed cores and clearly outperforms competing hash join
proposals - in particular it outperforms the &quot;cutting-edge&quot; Vectorwise parallel
query engine by a factor of four.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0147</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0147</id><created>2012-06-30</created><authors><author><keyname>Luo</keyname><forenames>Tian</forenames></author><author><keyname>Lee</keyname><forenames>Rubao</forenames></author><author><keyname>Mesnier</keyname><forenames>Michael</forenames></author><author><keyname>Chen</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Xiaodong</forenames></author></authors><title>hStorage-DB: Heterogeneity-aware Data Management to Exploit the Full
  Capability of Hybrid Storage Systems</title><categories>cs.DB</categories><comments>VLDB2012</comments><proxy>Ahmet Sacan</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 10, pp.
  1076-1087 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As storage systems become increasingly heterogeneous and complex, it adds
burdens on DBAs, causing suboptimal performance even after a lot of human
efforts have been made. In addition, existing monitoring-based storage
management by access pattern detections has difficulties to handle workloads
that are highly dynamic and concurrent. To achieve high performance by best
utilizing heterogeneous storage devices, we have designed and implemented a
heterogeneity-aware software framework for DBMS storage management called
hStorage-DB, where semantic information that is critical for storage I/O is
identified and passed to the storage manager. According to the collected
semantic information, requests are classified into different types. Each type
is assigned a proper QoS policy supported by the underlying storage system, so
that every request will be served with a suitable storage device. With
hStorage-DB, we can well utilize semantic information that cannot be detected
through data access monitoring but is particularly important for a hybrid
storage system. To show the effectiveness of hStorage-DB, we have implemented a
system prototype that consists of an I/O request classification enabled DBMS,
and a hybrid storage system that is organized into a two-level caching
hierarchy. Our performance evaluation shows that hStorage-DB can automatically
make proper decisions for data allocation in different storage devices and make
substantial performance improvements in a cost-efficient way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0151</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0151</id><created>2012-06-30</created><authors><author><keyname>Zeiler</keyname><forenames>Matthew D.</forenames></author><author><keyname>Fergus</keyname><forenames>Rob</forenames></author></authors><title>Differentiable Pooling for Hierarchical Feature Learning</title><categories>cs.CV cs.LG</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a parametric form of pooling, based on a Gaussian, which can be
optimized alongside the features in a single global objective function. By
contrast, existing pooling schemes are based on heuristics (e.g. local maximum)
and have no clear link to the cost function of the model. Furthermore, the
variables of the Gaussian explicitly store location information, distinct from
the appearance captured by the features, thus providing a what/where
decomposition of the input signal. Although the differentiable pooling scheme
can be incorporated in a wide range of hierarchical models, we demonstrate it
in the context of a Deconvolutional Network model (Zeiler et al. ICCV 2011). We
also explore a number of secondary issues within this model and present
detailed experiments on MNIST digits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0157</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0157</id><created>2012-06-30</created><authors><author><keyname>Athanasiou</keyname><forenames>George</forenames></author></authors><title>Green Traffic Engineering for Future Core Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important goal towards the design of Future Networks is to achieve the
best ratio of performance to energy consumption and at the same time assure
manageability. This paper presents a general problem formulation for
Energy-Aware Traffic Engineering and proposes a distributed, heuristic
Energy-Aware Traffic Engineering scheme (ETE) that provides load balancing and
energy-awareness in accordance with the operator's needs. Simulation results of
ETE compared to the optimal network performance confirm the capability of ETE
to meeting the needs of Future Networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0158</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0158</id><created>2012-06-30</created><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author><author><keyname>Bakhshi</keyname><forenames>Rena</forenames></author></authors><title>On the Complexity of Equivalence of Specifications of Infinite Objects</title><categories>cs.LO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of deciding the equality of infinite objects
specified by systems of equations, and of infinite objects specified by
lambda-terms. For equational specifications there are several natural notions
of equality: equality in all models, equality of the sets of solutions, and
equality of normal forms for productive specifications. For lambda-terms we
investigate Boehm-tree equality and various notions of observational equality.
We pinpoint the complexity of each of these notions in the arithmetical or
analytical hierarchy. We show that the complexity of deciding equality in all
models subsumes the entire analytical hierarchy. This holds already for the
most simple infinite objects, viz. streams over {0,1}, and stands in sharp
contrast to the low arithmetical Pi^0_2-completeness of equality of
equationally specified streams derived in [Rosu 2006] employing a different
notion of equality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0159</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0159</id><created>2012-06-30</created><authors><author><keyname>Athanasiou</keyname><forenames>George</forenames></author></authors><title>Energy-efficient traffic engineering for future core networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general problem formulation for energy-efficient traffic engineering for
future core networks is presented. Moreover, a distributed heuristic algorithm
that provides jointly load balancing and energy efficiency is proposed,
approaching in this way the optimal network operation in terms of throughput
and energy consumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0160</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0160</id><created>2012-06-30</created><authors><author><keyname>Athanasiou</keyname><forenames>George</forenames></author><author><keyname>Tassiulas</keyname><forenames>Leandros</forenames></author></authors><title>Design and Implementation of Distributed Resource Management Mechanisms
  for Wireless Mesh Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we design and implement a resource management scheme based on
cooperative association, where the STAs can share useful information in order
to improve the performance of the association/handoff procedures. The
cooperative association mechanism is inspired by the rapidly designed
cooperative protocols in the field of wireless networks. Furthermore, we
introduce a load balancing mechanism that operates in a cross-layer manner
taking into account uplink and downlink channel conditions, routing performance
and congestion control. The iterative heuristic algorithms that we propose,
control the communication load of each mesh AP in a distributed manner. We
evaluate the performance of our mechanisms through OPNET simulations and
testbed experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0162</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0162</id><created>2012-06-30</created><authors><author><keyname>Logothetis</keyname><forenames>Marios</forenames></author><author><keyname>Athanasiou</keyname><forenames>George</forenames></author><author><keyname>Tsagkaris</keyname><forenames>Kostas</forenames></author><author><keyname>Demestichas</keyname><forenames>Panagiotis</forenames></author></authors><title>Green Footprint by Cognitive Management of Opportunistic Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existing characteristics of the wireless networks nowadays, urgently
impose the exploitation of flexible networking solutions that will offer
increased efficiency in resource utilization and application Quality of Service
(QoS) provisioning and at the same time will reduce the energy consumption and
achieve green targets. In this respect, Operator-governed Opportunistic
Networks (ONs), which are dynamically created, temporary, coordinated
extensions of the infrastructure, are the basic constituents in the proposed
approach. In addition, Cognitive Management Systems (CMSs), which comprise
self-management and learning capabilities, can be exploited for ensuring fast
and reliable establishment of ONs, achieving efficiently the desired goals.
This paper presents the concept of ONs and their representative scenarios, as
well as an evaluation of indicative test cases as a proof of concept of the
aforementioned approach. Indicative simulation results are presented, which
yield the conditions in which the adoption of such a solution can lead to lower
costs and management decisions with a &quot;greener&quot; footprint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0163</identifier>
 <datestamp>2013-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0163</id><created>2012-06-30</created><updated>2013-04-03</updated><authors><author><keyname>Giustiniano</keyname><forenames>Domenico</forenames></author><author><keyname>Goma</keyname><forenames>Eduard</forenames></author><author><keyname>Toledo</keyname><forenames>Alberto Lopez</forenames></author><author><keyname>Athanasiou</keyname><forenames>George</forenames></author></authors><title>Optimizing TCP Performance in Multi-AP Residential Broadband Connections
  via Mini-Slot Access</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The high bandwidth demand of Internet applications has recently driven the
need of increasing the residential download speed. A practical solution to the
problem has been proposed aggregating the bandwidth of 802.11 Access Points
(APs) backhauls in range via 802.11 connections. Since 802.11 devices are
usually single-radio, the communication to multiple APs on different
radio-channels requires the introduction of a time-division multiple access
(TDMA) policy at the client station. Current investigation in this area
supposes that there is a sufficient number of TCP flows to saturate the
Asymmetric Digital Subscriber Line (ADSL) behind the APs. However, this may be
not guaranteed according to the user traffic pattern. As a consequence, a TDMA
policy introduces additional delays in the end-to-end transmissions that will
cause degradation of the TCP throughput and an under-utilization of the AP
backhauls. In this paper, we first perform an in-depth experimental analysis
with a customized 802.11 driver of how the usage of multi-AP TDMA affects the
observed Round-Trip-Time (RTT) of TCP flows. Then, we introduce a simple
analytical model that accurately predicts the TCP RTT when accessing the
wireless medium with a Multi-AP TDMA policy. Based on this model, we propose a
resource allocation algorithm that runs locally at the station and it greatly
reduces the observed TCP RTT with a very low computational cost. Our proposed
scheme can improve up to 1:5 times the aggregate throughput observed by the
station compared to state-of-the-art multi-AP TDMA allocations. We also show
that the throughput performance of the algorithm is very close to the
theoretical upper-bound in key simulation scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0166</identifier>
 <datestamp>2013-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0166</id><created>2012-06-30</created><updated>2013-01-16</updated><authors><author><keyname>Gentile</keyname><forenames>Claudio</forenames></author><author><keyname>Orabona</keyname><forenames>Francesco</forenames></author></authors><title>On Multilabel Classification and Ranking with Partial Feedback</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel multilabel/ranking algorithm working in partial
information settings. The algorithm is based on 2nd-order descent methods, and
relies on upper-confidence bounds to trade-off exploration and exploitation. We
analyze this algorithm in a partial adversarial setting, where covariates can
be adversarial, but multilabel probabilities are ruled by (generalized) linear
models. We show O(T^{1/2} log T) regret bounds, which improve in several ways
on the existing results. We test the effectiveness of our upper-confidence
scheme by contrasting against full-information baselines on real-world
multilabel datasets, often obtaining comparable performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0170</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0170</id><created>2012-06-30</created><authors><author><keyname>Taghizadeh-Popp</keyname><forenames>M.</forenames></author><author><keyname>Heinis</keyname><forenames>S.</forenames></author><author><keyname>Szalay</keyname><forenames>A. S.</forenames></author></authors><title>Single parameter galaxy classification: The Principal Curve through the
  multi-dimensional space of galaxy properties</title><categories>astro-ph.CO cs.CV stat.ML</categories><comments>Full abstract in downloadable version</comments><doi>10.1088/0004-637X/755/2/143</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to describe the variety of galaxies from SDSS by using only one
affine parameter. To this aim, we build the Principal Curve (P-curve) passing
through the spine of the data point cloud, considering the eigenspace derived
from Principal Component Analysis of morphological, physical and photometric
galaxy properties. Thus, galaxies can be labeled, ranked and classified by a
single arc length value of the curve, measured at the unique closest projection
of the data points on the P-curve. We find that the P-curve has a &quot;W&quot; letter
shape with 3 turning points, defining 4 branches that represent distinct galaxy
populations. This behavior is controlled mainly by 2 properties, namely u-r and
SFR. We further present the variations of several galaxy properties as a
function of arc length. Luminosity functions variate from steep Schechter fits
at low arc length, to double power law and ending in Log-normal fits at high
arc length. Galaxy clustering shows increasing autocorrelation power at large
scales as arc length increases. PCA analysis allowed to find peculiar galaxy
populations located apart from the main cloud of data points, such as small red
galaxies dominated by a disk, of relatively high stellar mass-to-light ratio
and surface mass density. The P-curve allows not only dimensionality reduction,
but also provides supporting evidence for relevant physical models and
scenarios in extragalactic astronomy: 1) Evidence for the hierarchical merging
scenario in the formation of a selected group of red massive galaxies. These
galaxies present a log-normal r-band luminosity function, which might arise
from multiplicative processes involved in this scenario. 2) Connection between
the onset of AGN activity and star formation quenching, which appears in green
galaxies when transitioning from blue to red populations. (Full abstract in
downloadable version)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0180</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0180</id><created>2012-07-01</created><updated>2012-07-21</updated><authors><author><keyname>Sivasankar</keyname><forenames>M.</forenames></author></authors><title>Generation of Efficient Key Bit-Streams</title><categories>cs.CR</categories><comments>another version is updated so this is withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stream ciphers play important role in cryptography. In this paper we do a
survey on stream ciphers.Various possible attacks are analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0188</identifier>
 <datestamp>2013-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0188</id><created>2012-07-01</created><updated>2013-12-10</updated><authors><author><keyname>Vu</keyname><forenames>Duy Q.</forenames></author><author><keyname>Hunter</keyname><forenames>David R.</forenames></author><author><keyname>Schweinberger</keyname><forenames>Michael</forenames></author></authors><title>Model-based clustering of large networks</title><categories>stat.CO cs.SI physics.soc-ph stat.AP</categories><comments>Published in at http://dx.doi.org/10.1214/12-AOAS617 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS617</report-no><journal-ref>Annals of Applied Statistics 2013, Vol. 7, No. 2, 1010-1039</journal-ref><doi>10.1214/12-AOAS617</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a network clustering framework, based on finite mixture models,
that can be applied to discrete-valued networks with hundreds of thousands of
nodes and billions of edge variables. Relative to other recent model-based
clustering work for networks, we introduce a more flexible modeling framework,
improve the variational-approximation estimation algorithm, discuss and
implement standard error estimation via a parametric bootstrap approach, and
apply these methods to much larger data sets than those seen elsewhere in the
literature. The more flexible framework is achieved through introducing novel
parameterizations of the model, giving varying degrees of parsimony, using
exponential family models whose structure may be exploited in various
theoretical and algorithmic ways. The algorithms are based on variational
generalized EM algorithms, where the E-steps are augmented by a
minorization-maximization (MM) idea. The bootstrapped standard error estimates
are based on an efficient Monte Carlo network simulation idea. Last, we
demonstrate the usefulness of the model-based clustering framework by applying
it to a discrete-valued network with more than 131,000 nodes and 17 billion
edge variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0203</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0203</id><created>2012-07-01</created><authors><author><keyname>Gubbi</keyname><forenames>Jayavardhana</forenames></author><author><keyname>Buyya</keyname><forenames>Rajkumar</forenames></author><author><keyname>Marusic</keyname><forenames>Slaven</forenames></author><author><keyname>Palaniswami</keyname><forenames>Marimuthu</forenames></author></authors><title>Internet of Things (IoT): A Vision, Architectural Elements, and Future
  Directions</title><categories>cs.DC</categories><comments>19 pages, 8 figures</comments><report-no>Technical Report CLOUDS-TR-2012-2, Cloud Computing and Distributed
  Systems Laboratory, The University of Melbourne, June 29, 2012</report-no><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ubiquitous sensing enabled by Wireless Sensor Network (WSN) technologies cuts
across many areas of modern day living. This offers the ability to measure,
infer and understand environmental indicators, from delicate ecologies and
natural resources to urban environments. The proliferation of these devices in
a communicating-actuating network creates the Internet of Things (IoT),
wherein, sensors and actuators blend seamlessly with the environment around us,
and the information is shared across platforms in order to develop a common
operating picture (COP). Fuelled by the recent adaptation of a variety of
enabling device technologies such as RFID tags and readers, near field
communication (NFC) devices and embedded sensor and actuator nodes, the IoT has
stepped out of its infancy and is the the next revolutionary technology in
transforming the Internet into a fully integrated Future Internet. As we move
from www (static pages web) to web2 (social networking web) to web3 (ubiquitous
computing web), the need for data-on-demand using sophisticated intuitive
queries increases significantly. This paper presents a cloud centric vision for
worldwide implementation of Internet of Things. The key enabling technologies
and application domains that are likely to drive IoT research in the near
future are discussed. A cloud implementation using Aneka, which is based on
interaction of private and public clouds is presented. We conclude our IoT
vision by expanding on the need for convergence of WSN, the Internet and
distributed computing directed at technological research community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0206</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0206</id><created>2012-07-01</created><authors><author><keyname>Loshchilov</keyname><forenames>Ilya</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Saclay - Ile de France, MSR - INRIA</affiliation></author><author><keyname>Sebag</keyname><forenames>Mich&#xe8;le</forenames><affiliation>INRIA Saclay - Ile de France, LRI</affiliation></author></authors><title>Alternative Restart Strategies for CMA-ES</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>Parallel Problem Solving From Nature (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the restart strategy of CMA-ES on multi-modal
functions. A first alternative strategy proceeds by decreasing the initial
step-size of the mutation while doubling the population size at each restart. A
second strategy adaptively allocates the computational budget among the restart
settings in the BIPOP scheme. Both restart strategies are validated on the BBOB
benchmark; their generality is also demonstrated on an independent real-world
problem suite related to spacecraft trajectory optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0216</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0216</id><created>2012-07-01</created><authors><author><keyname>Barth</keyname><forenames>Dominique</forenames></author><author><keyname>Boudaoud</keyname><forenames>Boubkeur</forenames></author><author><keyname>Mautor</keyname><forenames>Thierry</forenames></author></authors><title>La th\'eorie des jeux pour l'\'etablissement des contrats dans les
  r\'eseaux interdomaines</title><categories>cs.GT cs.NI</categories><comments>2 pages, conf\'erence ROADEF'2012</comments><journal-ref>ROADEF 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dans ce travail, nous montrons comment mettre en oeuvre la gestion des
ressources et la garantie de QoS (Quality of Service) dans l'interdomaine en
utilisant le mod\`ele en stock. Nous avons d\'ej\`a appliqu\'e un mod\`ele
distribu\'e pour l'\'etablissement des SLAs (Service Level Agreement) entre les
op\'erateurs pour l'achat des routes avec une garantie de QoS et des
r\'esultats significatifs ont \'et\'e obtenus sur des topologies simples. Dans
ce travail, nous appliquons un mod\`ele de jeu pour l'\'etablissement des SLAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0226</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0226</id><created>2012-07-01</created><authors><author><keyname>Bouzid</keyname><forenames>Zohir</forenames></author><author><keyname>Das</keyname><forenames>Shantanu</forenames></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>Wait-Free Gathering of Mobile Robots</title><categories>cs.DC cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of gathering multiple mobile robots to a single location, is one
of the fundamental problems in distributed coordination between autonomous
robots. The problem has been studied and solved even for robots that are
anonymous, disoriented, memoryless and operate in the semi-synchronous (ATOM)
model. However all known solutions require the robots to be faulty-free except
for the results of [Agmon and Peleg 2006] who solve the gathering problem in
presence of one crash fault. This leaves open the question of whether gathering
of correct robots can be achieved in the presence of multiple crash failures.
We resolve the question in this paper and show how to solve gathering, when any
number of robots may crash at any time during the algorithm, assuming strong
multiplicity detection and chirality. In contrast it is known that for the more
stronger byzantine faults, it is impossible to gather even in a 3-robot system
if one robot is faulty. Our algorithm solves the gathering of correct robots in
the semi-synchronous model where an adversary may stop any robot before
reaching its desired destination. Further the algorithm is self-stabilizing as
it achieves gathering starting from any configuration (except the bivalent
configuration where deterministic gathering is impossible).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0229</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0229</id><created>2012-07-01</created><authors><author><keyname>Szczecinski</keyname><forenames>Leszek</forenames></author><author><keyname>Correa</keyname><forenames>Ciro</forenames></author><author><keyname>Ahumada</keyname><forenames>Luciano</forenames></author></authors><title>Variable-rate Retransmissions for Incremental Redundancy Hybrid ARQ</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The throughput achievable in truncated Hybrid ARQ protocol (HARQ) using
incremental redundancy (IR) in analyzed when transmitting over a block-fading
channel whose state is unknown at the transmitter. We allow the transmission
lengths to vary, optimize them efficiently via dynamic programming, and show
that such a variable-rate HARQ-IR provides gains with respect to a fixed-rate
transmission in terms of increased throughput and decreased average number of
transmissions, reducing at the same time the outage probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0235</identifier>
 <datestamp>2013-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0235</id><created>2012-07-01</created><updated>2013-09-19</updated><authors><author><keyname>Krahmer</keyname><forenames>Felix</forenames></author><author><keyname>Mendelson</keyname><forenames>Shahar</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Suprema of Chaos Processes and the Restricted Isometry Property</title><categories>math.PR cs.IT math.IT</categories><comments>revised version, accepted for publication in Communications on Pure
  and Applied Mathematics, a number of typos removed</comments><msc-class>60B20, 60G70, 94A12, 94A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new bound for suprema of a special type of chaos processes
indexed by a set of matrices, which is based on a chaining method. As
applications we show significantly improved estimates for the restricted
isometry constants of partial random circulant matrices and time-frequency
structured random matrices. In both cases the required condition on the number
$m$ of rows in terms of the sparsity $s$ and the vector length $n$ is $m
\gtrsim s \log^2 s \log^2 n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0240</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0240</id><created>2012-07-01</created><authors><author><keyname>Georges</keyname><forenames>Robert</forenames><affiliation>Freie Universit&#xe4;t Berlin, Germany</affiliation></author><author><keyname>Hoffmann</keyname><forenames>Frank</forenames><affiliation>Freie Universit&#xe4;t Berlin, Germany</affiliation></author><author><keyname>Kriegel</keyname><forenames>Klaus</forenames><affiliation>Freie Universit&#xe4;t Berlin, Germany</affiliation></author></authors><title>Online Exploration of Polygons with Holes</title><categories>cs.CG cs.DS cs.RO</categories><comments>16 pages, 9 figures, submitted to WAOA 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study online strategies for autonomous mobile robots with vision to
explore unknown polygons with at most h holes. Our main contribution is an
(h+c_0)!-competitive strategy for such polygons under the assumption that each
hole is marked with a special color, where c_0 is a universal constant. The
strategy is based on a new hybrid approach. Furthermore, we give a new lower
bound construction for small h.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0245</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0245</id><created>2012-07-01</created><updated>2012-07-15</updated><authors><author><keyname>Smith</keyname><forenames>Noah A.</forenames></author></authors><title>Adversarial Evaluation for Models of Natural Language</title><categories>cs.CL</categories><comments>12 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We now have a rich and growing set of modeling tools and algorithms for
inducing linguistic structure from text that is less than fully annotated. In
this paper, we discuss some of the weaknesses of our current methodology. We
present a new abstract framework for evaluating natural language processing
(NLP) models in general and unsupervised NLP models in particular. The central
idea is to make explicit certain adversarial roles among researchers, so that
the different roles in an evaluation are more clearly defined and performers of
all roles are offered ways to make measurable contributions to the larger goal.
Adopting this approach may help to characterize model successes and failures by
encouraging earlier consideration of error analysis. The framework can be
instantiated in a variety of ways, simulating some familiar intrinsic and
extrinsic evaluations as well as some new evaluations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0246</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0246</id><created>2012-07-01</created><updated>2014-06-09</updated><authors><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>De Meo</keyname><forenames>Pasquale</forenames></author><author><keyname>Fiumara</keyname><forenames>Giacomo</forenames></author><author><keyname>Baumgartner</keyname><forenames>Robert</forenames></author></authors><title>Web Data Extraction, Applications and Techniques: A Survey</title><categories>cs.IR</categories><comments>Knowledge-based Systems</comments><doi>10.1016/j.knosys.2014.07.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web Data Extraction is an important problem that has been studied by means of
different scientific tools and in a broad range of applications. Many
approaches to extracting data from the Web have been designed to solve specific
problems and operate in ad-hoc domains. Other approaches, instead, heavily
reuse techniques and algorithms developed in the field of Information
Extraction.
  This survey aims at providing a structured and comprehensive overview of the
literature in the field of Web Data Extraction. We provided a simple
classification framework in which existing Web Data Extraction applications are
grouped into two main classes, namely applications at the Enterprise level and
at the Social Web level. At the Enterprise level, Web Data Extraction
techniques emerge as a key tool to perform data analysis in Business and
Competitive Intelligence systems as well as for business process
re-engineering. At the Social Web level, Web Data Extraction techniques allow
to gather a large amount of structured data continuously generated and
disseminated by Web 2.0, Social Media and Online Social Network users and this
offers unprecedented opportunities to analyze human behavior at a very large
scale. We discuss also the potential of cross-fertilization, i.e., on the
possibility of re-using Web Data Extraction techniques originally designed to
work in a given domain, in other domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0252</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0252</id><created>2012-07-01</created><authors><author><keyname>Fraigniaud</keyname><forenames>Pierre</forenames></author><author><keyname>Korman</keyname><forenames>Amos</forenames></author><author><keyname>Parter</keyname><forenames>Merav</forenames></author><author><keyname>Peleg</keyname><forenames>David</forenames></author></authors><title>Randomized Distributed Decision</title><categories>cs.DC cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper tackles the power of randomization in the context of locality by
analyzing the ability to`boost' the success probability of deciding a
distributed language. The main outcome of this analysis is that the distributed
computing setting contrasts significantly with the sequential one as far as
randomization is concerned. Indeed, we prove that in some cases, the ability to
increase the success probability for deciding distributed languages is rather
limited. Informally, a (p,q)-decider for a language L is a distributed
randomized algorithm which accepts instances in L with probability at least p
and rejects instances outside of L with probability at least q. It is known
that every hereditary language that can be decided in t rounds by a
(p,q)-decider, where p^2+q&gt;1, can actually be decided deterministically in O(t)
rounds. In one of our results we give evidence supporting the conjecture that
the above statement holds for all distributed languages. This is achieved by
considering the restricted case of path topologies. We then turn our attention
to the range below the aforementioned threshold, namely, the case where
p^2+q\leq1. We define B_k(t) to be the set of all languages decidable in at
most t rounds by a (p,q)-decider, where p^{1+1/k}+q&gt;1. It is easy to see that
every language is decidable (in zero rounds) by a (p,q)-decider satisfying
p+q=1. Hence, the hierarchy B_k provides a spectrum of complexity classes
between determinism and complete randomization. We prove that all these classes
are separated: for every integer k\geq 1, there exists a language L satisfying
L\in B_{k+1}(0) but L\notin B_k(t) for any t=o(n). In addition, we show that
B_\infty(t) does not contain all languages, for any t=o(n). Finally, we show
that if the inputs can be restricted in certain ways, then the ability to boost
the success probability becomes almost null.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0255</identifier>
 <datestamp>2013-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0255</id><created>2012-07-01</created><updated>2013-05-20</updated><authors><author><keyname>Klavik</keyname><forenames>Pavel</forenames></author><author><keyname>Kratochvil</keyname><forenames>Jan</forenames></author><author><keyname>Otachi</keyname><forenames>Yota</forenames></author><author><keyname>Saitoh</keyname><forenames>Toshiki</forenames></author></authors><title>Extending Partial Representations of Subclasses of Chordal Graphs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chordal graphs are intersection graphs of subtrees of a tree T. We
investigate the complexity of the partial representation extension problem for
chordal graphs. A partial representation specifies a tree T' and some pre-drawn
subtrees of T'. It asks whether it is possible to construct a representation
inside a modified tree T which extends the partial representation (i.e, keeps
the pre-drawn subtrees unchanged).
  We consider four modifications of T' and get vastly different problems. In
some cases, it is interesting to consider the complexity even if just T' is
given and no subtree is pre-drawn. Also, we consider three well-known
subclasses of chordal graphs: Proper interval graphs, interval graphs and path
graphs. We give an almost complete complexity characterization.
  We further study the parametrized complexity of the problems when
parametrized by the number of pre-drawn subtrees, the number of components and
the size of the tree T'. We describe an interesting relation with integer
partition problems. The problem Partition is used for all NP-completeness
reductions. The extension of interval graphs when the space in T' is limited is
&quot;equivalent&quot; to the BinPacking problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0261</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0261</id><created>2012-07-01</created><updated>2012-12-27</updated><authors><author><keyname>Hori</keyname><forenames>Yutaka</forenames></author><author><keyname>Hara</keyname><forenames>Shinji</forenames></author></authors><title>Biochemical Oscillations in Delayed Negative Cyclic Feedback: Harmonic
  Balance Analysis with Applications</title><categories>cs.SY math.OC q-bio.QM</categories><comments>Appendix A and some references have been added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Oscillatory chemical reactions often serve as a timing clock of cellular
processes in living cells. The temporal dynamics of protein concentration
levels is thus of great interest in biology. Here we propose a theoretical
framework to analyze the frequency, phase and amplitude of oscillatory protein
concentrations in gene regulatory networks with negative cyclic feedback. We
first formulate the analysis framework of oscillation profiles based on
multivariable harmonic balance. With this framework, the frequency, phase and
amplitude are obtained analytically in terms of kinetic constants of the
reactions despite the nonlinearity of the dynamics. These results are
demonstrated with the Pentilator and Hes7 self-repression network, and it is
shown that the developed analysis method indeed predicts the profiles of the
oscillations. A distinctive feature of the presented result is that the
waveform of oscillations is analytically obtained for a broad class of
biochemical systems. Thus, it is easy to see how the waveform is determined
from the system's parameters and structures. We present general biological
insights that are applicable for any gene regulatory networks with negative
cyclic feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0262</identifier>
 <datestamp>2013-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0262</id><created>2012-07-01</created><updated>2013-03-03</updated><authors><author><keyname>Wang</keyname><forenames>Shiping</forenames></author><author><keyname>Zhu</keyname><forenames>Qingxin</forenames></author><author><keyname>Zhu</keyname><forenames>William</forenames></author><author><keyname>Min</keyname><forenames>Fan</forenames></author></authors><title>Characteristic matrix of covering and its application to boolean matrix
  decomposition and axiomatization</title><categories>cs.AI</categories><comments>18-page original paper</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Covering is an important type of data structure while covering-based rough
sets provide an efficient and systematic theory to deal with covering data. In
this paper, we use boolean matrices to represent and axiomatize three types of
covering approximation operators. First, we define two types of characteristic
matrices of a covering which are essentially square boolean ones, and their
properties are studied. Through the characteristic matrices, three important
types of covering approximation operators are concisely equivalently
represented. Second, matrix representations of covering approximation operators
are used in boolean matrix decomposition. We provide a sufficient and necessary
condition for a square boolean matrix to decompose into the boolean product of
another one and its transpose. And we develop an algorithm for this boolean
matrix decomposition. Finally, based on the above results, these three types of
covering approximation operators are axiomatized using boolean matrices. In a
word, this work borrows extensively from boolean matrices and present a new
view to study covering-based rough sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0268</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0268</id><created>2012-07-01</created><authors><author><keyname>Agarwal</keyname><forenames>Shivani</forenames></author></authors><title>Surrogate Regret Bounds for Bipartite Ranking via Strongly Proper Losses</title><categories>cs.LG stat.ML</categories><comments>20 pages</comments><acm-class>I.2.6</acm-class><journal-ref>Journal of Machine Learning Research, 15:1653-1674, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of bipartite ranking, where instances are labeled positive or
negative and the goal is to learn a scoring function that minimizes the
probability of mis-ranking a pair of positive and negative instances (or
equivalently, that maximizes the area under the ROC curve), has been widely
studied in recent years. A dominant theoretical and algorithmic framework for
the problem has been to reduce bipartite ranking to pairwise classification; in
particular, it is well known that the bipartite ranking regret can be
formulated as a pairwise classification regret, which in turn can be upper
bounded using usual regret bounds for classification problems. Recently,
Kotlowski et al. (2011) showed regret bounds for bipartite ranking in terms of
the regret associated with balanced versions of the standard (non-pairwise)
logistic and exponential losses. In this paper, we show that such
(non-pairwise) surrogate regret bounds for bipartite ranking can be obtained in
terms of a broad class of proper (composite) losses that we term as strongly
proper. Our proof technique is much simpler than that of Kotlowski et al.
(2011), and relies on properties of proper (composite) losses as elucidated
recently by Reid and Williamson (2010, 2011) and others. Our result yields
explicit surrogate bounds (with no hidden balancing terms) in terms of a
variety of strongly proper losses, including for example logistic, exponential,
squared and squared hinge losses as special cases. We also obtain tighter
surrogate bounds under certain low-noise conditions via a recent result of
Clemencon and Robbiano (2011).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0269</identifier>
 <datestamp>2012-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0269</id><created>2012-07-01</created><updated>2012-10-22</updated><authors><author><keyname>Khoo</keyname><forenames>Khoongming</forenames></author><author><keyname>Tan</keyname><forenames>Chik How</forenames></author></authors><title>Breaking the Estream Finalists and AES Modes of Operation Faster than
  Exhaustive Search</title><categories>cs.CR</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the time-memory-data trade-off attack on stream and block
ciphers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0271</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0271</id><created>2012-07-01</created><updated>2013-05-10</updated><authors><author><keyname>Cai</keyname><forenames>Shuxin</forenames></author><author><keyname>Yang</keyname><forenames>Wenguo</forenames></author><author><keyname>Tang</keyname><forenames>Yaohua</forenames></author></authors><title>Approximating Soft-Capacitated Facility Location Problem With
  Uncertainty</title><categories>cs.DS</categories><comments>This preliminary version has been withdrawn by the author due to a
  crucial error in Lemma 1; a series of modification has been made afterward.
  The final version has been published by Journal of Combinatorial Optimization</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We first show that a better analysis of the algorithm for The Two-Sage
Stochastic Facility Location Problem from Srinivasan \cite{sri07} and the
algorithm for The Robust Fault Tolerant Facility Location Problem from Byrka et
al \cite{bgs10} can render improved approximation factors of 2.206 and \alpha+4
where \alpha is the maximum number an adversary can close, respectively, and
which are the best ratios so far.
  We then present new models for the soft-capacitated facility location problem
with uncertainty and design constant factor approximation algorithms to solve
them. We devise the stochastic and robust approaches to handle the uncertainty
incorporated into the original model. Explicitly, in this paper we propose two
new problem, named The 2-Stage Soft-Capacitated Facility Location Problem and
The Robust Soft-Capacitated Facility Location Problem respectively, and present
constant factor approximation algorithms for them both. Our method uses
reductions between facility location problems and linear-cost models, the
randomized thresholding technique of Srinivasan \cite{sri07} and the filtering
and clustering technique of Byrka et al \cite{bgs10}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0273</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0273</id><created>2012-07-01</created><authors><author><keyname>Ding</keyname><forenames>Haichuan</forenames></author><author><keyname>Ma</keyname><forenames>Shaodan</forenames></author><author><keyname>Xing</keyname><forenames>Chengwen</forenames></author><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Performance Analysis for Heterogeneous Cellular Systems with Range
  Expansion</title><categories>cs.IT math.IT</categories><comments>six pages, five figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently heterogeneous base station structure has been adopted in cellular
systems to enhance system throughput and coverage. In this paper, the uplink
coverage probability for the heterogeneous cellular systems is analyzed and
derived in closed-form. The randomness on the locations and number of mobile
users is taken into account in the analysis. Based on the analytical results,
the impacts of various system parameters on the uplink performance are
investigated in detail. The correctness of the analytical results is also
verified by simulation results. These analytical results can thus serve as a
guidance for system design without the need of time consuming simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0288</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0288</id><created>2012-07-02</created><authors><author><keyname>Tapie</keyname><forenames>Laurent</forenames><affiliation>LURPA</affiliation></author><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author><author><keyname>Bernard</keyname><forenames>Alain</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Topological model for machining of parts with complex shapes</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>Computers in Industry 63, Issue 5 (2012) Pages 528-541</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex shapes are widely used to design products in several industries such
as aeronautics, automotive and domestic appliances. Several variations of their
curvatures and orientations generate difficulties during their manufacturing or
the machining of dies used in moulding, injection and forging. Analysis of
several parts highlights two levels of difficulties between three types of
shapes: prismatic parts with simple geometrical shapes, aeronautic structure
parts composed of several shallow pockets and forging dies composed of several
deep cavities which often contain protrusions. This paper mainly concerns High
Speed Machining (HSM) of these dies which represent the highest complexity
level because of the shapes' geometry and their topology. Five axes HSM is
generally required for such complex shaped parts but 3 axes machining can be
sufficient for dies. Evolutions in HSM CAM software and machine tools lead to
an important increase in time for machining preparation. Analysis stages of the
CAD model particularly induce this time increase which is required for a wise
choice of cutting tools and machining strategies. Assistance modules for
prismatic parts machining features identification in CAD models are widely
implemented in CAM software. In spite of the last CAM evolutions, these kinds
of CAM modules are undeveloped for aeronautical structure parts and forging
dies. Development of new CAM modules for the extraction of relevant machining
areas as well as the definition of the topological relations between these
areas must make it possible for the machining assistant to reduce the machining
preparation time. In this paper, a model developed for the description of
complex shape parts topology is presented. It is based on machining areas
extracted for the construction of geometrical features starting from CAD models
of the parts. As topology is described in order to assist machining assistant
during machining process generation, the difficulties associated with tasks he
carried out are analyzed at first. The topological model presented after is
based on the basic geometrical features extracted. Topological relations which
represent the framework of the model are defined between the basic geometrical
features which are gathered afterwards in macro-features. Approach used for the
identification of these macro-features is also presented in this paper.
Detailed application on the construction of the topological model of forging
dies is presented in the last part of the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0290</identifier>
 <datestamp>2013-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0290</id><created>2012-07-02</created><updated>2013-08-21</updated><authors><author><keyname>Yazdi</keyname><forenames>S. M. Sadegh Tabatabaei</forenames></author><author><keyname>Dolecek</keyname><forenames>Lara</forenames></author></authors><title>A Deterministic Polynomial-Time Protocol for Synchronizing from
  Deletions</title><categories>cs.IT math.IT</categories><comments>Accepted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a synchronization problem between nodes $A$ and
$B$ that are connected through a two--way communication channel. {Node $A$}
contains a binary file $X$ of length $n$ and {node $B$} contains a binary file
$Y$ that is generated by randomly deleting bits from $X$, by a small deletion
rate $\beta$. The location of deleted bits is not known to either node $A$ or
node $B$. We offer a deterministic synchronization scheme between nodes $A$ and
$B$ that needs a total of $O(n\beta\log \frac{1}{\beta})$ transmitted bits and
reconstructs $X$ at node $B$ with probability of error that is exponentially
low in the size of $X$. Orderwise, the rate of our scheme matches the optimal
rate for this channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0297</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0297</id><created>2012-07-02</created><updated>2012-12-20</updated><authors><author><keyname>Meron</keyname><forenames>Eado</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author><author><keyname>Shtaif</keyname><forenames>Mark</forenames></author></authors><title>On the Achievable Communication Rates of Generalized Soliton
  Transmission Systems</title><categories>cs.IT math.IT</categories><comments>Work in progress as part of Eado Meron's PHD</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the achievable communication rates of a generalized soliton-based
transmission system for the optical fiber channel. This method is based on
modulation of parameters of the scattering domain, via the inverse scattering
transform, by the information bits. The decoder uses the direct spectral
transform to estimate these parameters and decode the information message.
Unlike ordinary On-Off Keying (OOK) soliton systems, the solitons' amplitude
may take values in a continuous interval. A considerable rate gain is shown in
the case where the waveforms are 2-bound soliton states. Using traditional
information theory and inverse scattering perturbation theory, we analyze the
influence of the amplitude fluctuations as well as soliton arrival time jitter,
on the achievable rates. Using this approach we show that the time of arrival
jitter (Gordon-Haus) limits the information rate in a continuous manner, as
opposed to a strict threshold in OOK systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0302</identifier>
 <datestamp>2012-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0302</id><created>2012-07-02</created><updated>2012-09-18</updated><authors><author><keyname>Leckey</keyname><forenames>Kevin</forenames></author><author><keyname>Neininger</keyname><forenames>Ralph</forenames></author><author><keyname>Szpankowski</keyname><forenames>Wojciech</forenames></author></authors><title>Towards More Realistic Probabilistic Models for Data Structures: The
  External Path Length in Tries under the Markov Model</title><categories>math.PR cs.DS</categories><comments>minor revision; to appear in Proceedings of ACM-SIAM Symposium on
  Discrete Algorithms (SODA) (2013)</comments><msc-class>60F05, 68P05, 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tries are among the most versatile and widely used data structures on words.
They are pertinent to the (internal) structure of (stored) words and several
splitting procedures used in diverse contexts ranging from document taxonomy to
IP addresses lookup, from data compression (i.e., Lempel-Ziv'77 scheme) to
dynamic hashing, from partial-match queries to speech recognition, from leader
election algorithms to distributed hashing tables and graph compression. While
the performance of tries under a realistic probabilistic model is of
significant importance, its analysis, even for simplest memoryless sources, has
proved difficult. Rigorous findings about inherently complex parameters were
rarely analyzed (with a few notable exceptions) under more realistic models of
string generations. In this paper we meet these challenges: By a novel use of
the contraction method combined with analytic techniques we prove a central
limit theorem for the external path length of a trie under a general Markov
source. In particular, our results apply to the Lempel-Ziv'77 code. We envision
that the methods described here will have further applications to other trie
parameters and data structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0313</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0313</id><created>2012-07-02</created><authors><author><keyname>Ostapov</keyname><forenames>Yuriy</forenames></author></authors><title>Intellectual Management of Enterprise</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new technology (in addition to ERP) is proposed to provide an increase of
profit and normal cash flow. This technology involves the next functions:
forming of intellectual interface on a natural language to communicate with a
control system; joint planning of production and sales to get the maximal
profit; an adaptation of control system to internal and external events. The
use of the natural language permits to overcome a barrier between the control
system and upper managers. To solve posed actual problems of management the
selection of information from a database and call to mathematical methods are
executed automatically. Optimal planning provides the maximal use of available
resources and opportunities of market. Adaptive control implements the
efficient reaction to critical events that lead up to a decrease of profit and
increase of accounts receivable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0315</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0315</id><created>2012-07-02</created><updated>2012-07-03</updated><authors><author><keyname>Bui</keyname><forenames>Huyen Chi</forenames></author><author><keyname>Lacan</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Boucheret</keyname><forenames>Marie-Laure</forenames></author></authors><title>Multi-slot Coded ALOHA with Irregular Degree Distribution</title><categories>cs.IT math.IT</categories><comments>6 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an improvement of the random multiple access scheme for
satellite communication named Multislot coded ALOHA (MuSCA). MuSCA is a
generalization of Contention Resolution Diversity Slotted ALOHA (CRDSA). In
this scheme, each user transmits several parts of a single codeword of an error
correcting code instead of sending replicas. At the receiver level, the decoder
collects all these parts and includes them in the decoding process even if they
are interfered. In this paper, we show that a high throughput can be obtained
by selecting variable code rates and user degrees according to a probability
distribution. With an optimal irregular degree distribution, our system
achieves a normalized throughput up to 1.43, resulting in a significant gain
compared to CRDSA and MuSCA. The spectral efficiency and the implementation
issues of the scheme are also analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0316</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0316</id><created>2012-07-02</created><authors><author><keyname>Li</keyname><forenames>Angsheng</forenames></author><author><keyname>Zhang</keyname><forenames>Peng</forenames></author></authors><title>Algorithmic Aspects of Homophyly of Networks</title><categories>cs.DS</categories><comments>23 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the algorithmic problems of the {\it homophyly phenomenon} in
networks. Given an undirected graph $G = (V, E)$ and a vertex coloring $c
\colon V \rightarrow {1, 2, ..., k}$ of $G$, we say that a vertex $v\in V$ is
{\it happy} if $v$ shares the same color with all its neighbors, and {\it
unhappy}, otherwise, and that an edge $e\in E$ is {\it happy}, if its two
endpoints have the same color, and {\it unhappy}, otherwise. Supposing $c$ is a
{\it partial vertex coloring} of $G$, we define the Maximum Happy Vertices
problem (MHV, for short) as to color all the remaining vertices such that the
number of happy vertices is maximized, and the Maximum Happy Edges problem
(MHE, for short) as to color all the remaining vertices such that the number of
happy edges is maximized.
  Let $k$ be the number of colors allowed in the problems. We show that both
MHV and MHE can be solved in polynomial time if $k = 2$, and that both MHV and
MHE are NP-hard if $k \geq 3$. We devise a $\max {1/k,
\Omega(\Delta^{-3})}$-approximation algorithm for the MHV problem, where
$\Delta$ is the maximum degree of vertices in the input graph, and a
1/2-approximation algorithm for the MHE problem. This is the first theoretical
progress of these two natural and fundamental new problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0332</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0332</id><created>2012-07-02</created><authors><author><keyname>Buliga</keyname><forenames>Marius</forenames></author></authors><title>Local and global moves on locally planar trivalent graphs, lambda
  calculus and $\lambda$-Scale</title><categories>cs.LO math.GT math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a description of local and global moves on a class of locally planar
trivalent graphs and we show that it contains $\lambda$-Scale calculus,
therefore in particular untyped lambda calculus. Surprisingly, the beta
reduction rule comes from a local &quot;sewing&quot; transformation of trivalent locally
planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0334</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0334</id><created>2012-07-02</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Signal Space Alignment for the Gaussian Y-Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multi-way communication network with three nodes and a relay is considered.
The three nodes in this so-called Y-channel, communicate with each other in a
bi-directional manner via the relay. Studying this setup is important due to
its being an important milestone for characterizing the capacity of larger
networks. A transmit strategy for the Gaussian Y-channel is proposed, which
mimics a previously considered scheme for the deterministic approximation of
the Y-channel. Namely, a scheme which uses nested-lattice codes and lattice
alignment is used, to perform network coding. A new mode of operation is
introduced, named `cyclic communication', which interestingly turns out to be
an important component for achieving the capacity region of the Gaussian
Y-channel within a constant gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0335</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0335</id><created>2012-07-02</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Lattice Coding and the Generalized Degrees of Freedom of the
  Interference Channel with Relay</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized degrees of freedom (GDoF) of the symmetric two-user Gaussian
interference relay channel (IRC) is studied. While it is known that the relay
does not increase the DoF of the IC, this is not known for the more general
GDoF. For the characterization of the GDoF, new sum-capacity upper bounds and
lower bounds are derived. The lower bounds are obtained by a new scheme, which
is based on functional decode-and-forward (FDF). The GDoF is characterized for
the regime in which the source-relay link is weaker than the interference link,
which constitutes half the overall space of channel parameters. It is shown
that the relay can indeed increase the GDoF of the IRC and that it is achieved
by FDF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0337</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0337</id><created>2012-07-02</created><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>The DoF of the K-user Interference Channel with a Cognitive Relay</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, ISIT 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was shown recently that the 2-user interference channel with a cognitive
relay (IC-CR) has full degrees of freedom (DoF) almost surely, that is, 2 DoF.
The purpose of this work is to check whether the DoF of the $K$-user IC-CR,
consisting of $K$ user pairs and a cognitive relay, follow as a straight
forward extension of the 2-user case. As it turns out, this is not the case.
The $K$-user IC-CR is shown to have $2K/3$ DoF if $K&gt;2$ for the when the
channel is time varying, achievable using interference alignment. Thus, while
the basic $K$-user IC with time varying channel coefficients has 1/2 DoF per
user for all $K$, the $K$-user IC-CR with varying channels has 1 DoF per user
if K=2 and 2/3 DoF per user if $K&gt;2$. Furthermore, the DoF region of the 3-user
IC-CR with constant channels is characterized using interference
neutralization, and a new upper bound on the sum-capacity of the 2-user IC-CR
is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0349</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0349</id><created>2012-07-02</created><updated>2012-09-11</updated><authors><author><keyname>Baek</keyname><forenames>Yongjoo</forenames></author><author><keyname>Kim</keyname><forenames>Daniel</forenames></author><author><keyname>Ha</keyname><forenames>Meesoon</forenames></author><author><keyname>Jeong</keyname><forenames>Hawoong</forenames></author></authors><title>Fundamental Structural Constraint of Random Scale-Free Networks</title><categories>cond-mat.stat-mech cs.CR physics.soc-ph</categories><comments>5 pages, 4 figures (7 eps files), 2 tables; published version</comments><journal-ref>Phys. Rev. Lett. 109, 118701 (2012)</journal-ref><doi>10.1103/PhysRevLett.109.118701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the structural constraint of random scale-free networks that
determines possible combinations of the degree exponent $\gamma$ and the upper
cutoff $k_c$ in the thermodynamic limit. We employ the framework of
graphicality transitions proposed by [Del Genio and co-workers, Phys. Rev.
Lett. {\bf 107}, 178701 (2011)], while making it more rigorous and applicable
to general values of kc. Using the graphicality criterion, we show that the
upper cutoff must be lower than $k_c N^{1/\gamma}$ for $\gamma &lt; 2$, whereas
any upper cutoff is allowed for $\gamma &gt; 2$. This result is also numerically
verified by both the random and deterministic sampling of degree sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0350</identifier>
 <datestamp>2012-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0350</id><created>2012-07-02</created><updated>2012-12-12</updated><authors><author><keyname>Raja</keyname><forenames>Humza Qadir</forenames></author><author><keyname>Scholz</keyname><forenames>Oliver</forenames></author></authors><title>Dynamic Power Distribution and Energy Management in a Reconfigurable
  Multi-Robotic Organism</title><categories>cs.SY</categories><comments>This paper has been withdrawn by the author for further improvements</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several design parameters in collective robotic systems have been
investigated and developed in order to explore the cooperation among the
autonomous robotic individuals in a variety of robotic swarms in the presence
of different internal and external system constraints. In particular, the
dynamic power management and distribution in a multi-robotic organism is of
very high importance that depends not only on the electronic design but also on
the mechanical structure of the robots. It further defines the true nature of
the collaboration among the modules of a self-reconfigurable multi-robotic
organism. This article describes the essential features and design of a dynamic
power distribution and management system for a dynamically reconfigurable
multi-robotic system. It further presents the empirical results of the proposed
dynamic power management system collected with the real robotic platform. In
the later half of the article, it presents a simulation framework that was
especially developed to explore the collective system behavior and complexities
involved in the operations of a multi-robotic organism. At the end, summary and
conclusion follows the detailed discussion on the obtained simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0361</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0361</id><created>2012-07-02</created><updated>2012-07-03</updated><authors><author><keyname>Dutta</keyname><forenames>Sourav</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author></authors><title>INSTRUCT: Space-Efficient Structure for Indexing and Complete Query
  Management of String Databases</title><categories>cs.DB cs.DS</categories><comments>International Conference on Management of Data (COMAD), 2010</comments><acm-class>H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The tremendous expanse of search engines, dictionary and thesaurus storage,
and other text mining applications, combined with the popularity of readily
available scanning devices and optical character recognition tools, has
necessitated efficient storage, retrieval and management of massive text
databases for various modern applications. For such applications, we propose a
novel data structure, INSTRUCT, for efficient storage and management of
sequence databases. Our structure uses bit vectors for reusing the storage
space for common triplets, and hence, has a very low memory requirement.
INSTRUCT efficiently handles prefix and suffix search queries in addition to
the exact string search operation by iteratively checking the presence of
triplets. We also propose an extension of the structure to handle substring
search efficiently, albeit with an increase in the space requirements. This
extension is important in the context of trie-based solutions which are unable
to handle such queries efficiently. We perform several experiments portraying
that INSTRUCT outperforms the existing structures by nearly a factor of two in
terms of space requirements, while the query times are better. The ability to
handle insertion and deletion of strings in addition to supporting all kinds of
queries including exact search, prefix/suffix search and substring search makes
INSTRUCT a complete data structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0362</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0362</id><created>2012-07-02</created><authors><author><keyname>Pratas</keyname><forenames>Nuno K.</forenames></author><author><keyname>Thomsen</keyname><forenames>Henning</forenames></author><author><keyname>Stefanovic</keyname><forenames>Cedomir</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author></authors><title>Code-Expanded Random Access for Machine-Type Communications</title><categories>cs.IT math.IT</categories><comments>6 Pages, 7 figures, This paper has been submitted to GC'12 Workshop:
  Second International Workshop on Machine-to-Machine Communications 'Key' to
  the Future Internet of Things</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random access methods used for support of machine-type communications
(MTC) in current cellular standards are derivatives of traditional framed
slotted ALOHA and therefore do not support high user loads efficiently.
Motivated by the random access method employed in LTE, we propose a novel
approach that is able to sustain a wide random access load range, while
preserving the physical layer unchanged and incurring minor changes in the
medium access control layer. The proposed scheme increases the amount of
available contention resources, without resorting to the increase of system
resources, such as contention sub-frames and preambles. This increase is
accomplished by expanding the contention space to the code domain, through the
creation of random access codewords. Specifically, in the proposed scheme,
users perform random access by transmitting one or none of the available LTE
orthogonal preambles in multiple random access sub-frames, thus creating access
codewords that are used for contention. In this way, for the same number of
random access sub-frames and orthogonal preambles, the amount of available
contention resources is drastically increased, enabling the support of an
increased number of MTC users. We present the framework and analysis of the
proposed code-expanded random access method and show that our approach supports
load regions that are beyond the reach of current systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0369</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0369</id><created>2012-07-02</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Johannsen</keyname><forenames>Daniel</forenames></author><author><keyname>K&#xf6;tzing</keyname><forenames>Timo</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author><author><keyname>Theile</keyname><forenames>Madeleine</forenames></author></authors><title>More Effective Crossover Operators for the All-Pairs Shortest Path
  Problem</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The all-pairs shortest path problem is the first non-artificial problem for
which it was shown that adding crossover can significantly speed up a
mutation-only evolutionary algorithm. Recently, the analysis of this algorithm
was refined and it was shown to have an expected optimization time (w.r.t. the
number of fitness evaluations) of $\Theta(n^{3.25}(\log n)^{0.25})$.
  In contrast to this simple algorithm, evolutionary algorithms used in
practice usually employ refined recombination strategies in order to avoid the
creation of infeasible offspring. We study extensions of the basic algorithm by
two such concepts which are central in recombination, namely \emph{repair
mechanisms} and \emph{parent selection}. We show that repairing infeasible
offspring leads to an improved expected optimization time of
$\mathord{O}(n^{3.2}(\log n)^{0.2})$. As a second part of our study we prove
that choosing parents that guarantee feasible offspring results in an even
better optimization time of $\mathord{O}(n^{3}\log n)$.
  Both results show that already simple adjustments of the recombination
operator can asymptotically improve the runtime of evolutionary algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0370</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0370</id><created>2012-07-02</created><authors><author><keyname>Euldji</keyname><forenames>Abderrahmane</forenames></author><author><keyname>Tienti</keyname><forenames>Abderrahim</forenames></author><author><keyname>Stambouli</keyname><forenames>Amine Boudghene</forenames></author></authors><title>A new path algorithm for the weighted multi-graphs WMGPA: application to
  the Direct Topological Method</title><categories>cs.DS</categories><comments>7 pages, 1 figure, 4 tables</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 1, No 2, January 2012, pp. 248-254</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to present an algorithm which gives all the possible
paths that start from a specific node to another of a weighted multi-graph.
This algorithm is intended to be applied for the direct topological method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0393</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0393</id><created>2012-07-02</created><updated>2012-08-10</updated><authors><author><keyname>Kraj&#xed;&#x10d;ek</keyname><forenames>Jan</forenames></author></authors><title>Pseudo-finite hard instances for a student-teacher game with a
  Nisan-Wigderson generator</title><categories>cs.CC math.LO</categories><proxy>Logical Methods In Computer Science</proxy><acm-class>F.2.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (August 13,
  2012) lmcs:788</journal-ref><doi>10.2168/LMCS-8(3:9)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an NP intersect coNP function g of the Nisan-Wigderson type and a string
b outside its range we consider a two player game on a common input a to the
function. One player, a computationally limited Student, tries to find a bit of
g(a) that differs from the corresponding bit of b. He can query a
computationally unlimited Teacher for the witnesses of the values of constantly
many bits of g(a). The Student computes the queries from a and from Teacher's
answers to his previous queries. It was proved by Krajicek (2011) that if g is
based on a hard bit of a one-way permutation then no Student computed by a
polynomial size circuit can succeed on all a. In this paper we give a lower
bound on the number of inputs a any such Student must fail on. Using that we
show that there is a pseudo-finite set of hard instances on which all uniform
students must fail. The hard-core set is defined in a non-standard model of
true arithmetic and has applications in a forcing construction relevant to
proof complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0396</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0396</id><created>2012-07-02</created><authors><author><keyname>Wiriyathammabhum</keyname><forenames>Peratham</forenames></author><author><keyname>Kijsirikul</keyname><forenames>Boonserm</forenames></author><author><keyname>Takamura</keyname><forenames>Hiroya</forenames></author><author><keyname>Okumura</keyname><forenames>Manabu</forenames></author></authors><title>Applying Deep Belief Networks to Word Sense Disambiguation</title><categories>cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we applied a novel learning algorithm, namely, Deep Belief
Networks (DBN) to word sense disambiguation (WSD). DBN is a probabilistic
generative model composed of multiple layers of hidden units. DBN uses
Restricted Boltzmann Machine (RBM) to greedily train layer by layer as a
pretraining. Then, a separate fine tuning step is employed to improve the
discriminative power. We compared DBN with various state-of-the-art supervised
learning algorithms in WSD such as Support Vector Machine (SVM), Maximum
Entropy model (MaxEnt), Naive Bayes classifier (NB) and Kernel Principal
Component Analysis (KPCA). We used all words in the given paragraph,
surrounding context words and part-of-speech of surrounding words as our
knowledge sources. We conducted our experiment on the SENSEVAL-2 data set. We
observed that DBN outperformed all other learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0398</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0398</id><created>2012-07-02</created><authors><author><keyname>Pons</keyname><forenames>Viviane</forenames></author></authors><title>Multivariate Polynomials in Sage</title><categories>math.CO cs.MS math.AC</categories><comments>18 pages</comments><journal-ref>Seminaire Lotharingien de Combinatoire 66 (2011), Article B66z, 18
  pp</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have developed a patch implementing multivariate polynomials seen as a
multi-base algebra. The patch is to be released into the software Sage and can
already be found within the Sage-Combinat distribution. One can use our patch
to define a polynomial in a set of indexed variables and expand it into a
linear basis of the multivariate polynomials. So far, we have the Schubert
polynomials, the Key polynomials of types A, B, C, or D, the Grothendieck
polynomials and the non-symmetric Macdonald polynomials. One can also use a
double set of variables and work with specific double-linear bases like the
double Schubert polynomials or double Grothendieck polynomials. Our
implementation is based on a definition of the basis using divided difference
operators and one can also define new bases using these operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0403</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0403</id><created>2012-07-02</created><authors><author><keyname>Wiriyathammabhum</keyname><forenames>Peratham</forenames></author><author><keyname>Kijsirikul</keyname><forenames>Boonserm</forenames></author></authors><title>Robust Principal Component Analysis Using Statistical Estimators</title><categories>cs.AI</categories><comments>In Proc. of the International Joint Conference on Computer Science
  and Software Engineering (JCSSE) 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principal Component Analysis (PCA) finds a linear mapping and maximizes the
variance of the data which makes PCA sensitive to outliers and may cause wrong
eigendirection. In this paper, we propose techniques to solve this problem; we
use the data-centering method and reestimate the covariance matrix using robust
statistic techniques such as median, robust scaling which is a booster to
data-centering and Huber M-estimator which measures the presentation of
outliers and reweight them with small values. The results on several real world
data sets show that our proposed method handles outliers and gains better
results than the original PCA and provides the same accuracy with lower
computation cost than the Kernel PCA using the polynomial kernel in
classification tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0405</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0405</id><created>2012-07-02</created><authors><author><keyname>Staab</keyname><forenames>Eugen</forenames></author><author><keyname>Muller</keyname><forenames>Guillaume</forenames></author></authors><title>MITRA: A Meta-Model for Information Flow in Trust and Reputation
  Architectures</title><categories>cs.MA</categories><comments>19 pages, 2 figures, 2 tables. Keywords: Computational Trust,
  Reputation Systems, Meta Model</comments><msc-class>68T42</msc-class><acm-class>I.2.11</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose MITRA, a meta-model for the information flow in (computational)
trust and reputation architectures. On an abstract level, MITRA describes the
information flow as it is inherent in prominent trust and reputation models
from the literature. We use MITRA to provide a structured comparison of these
models. This makes it possible to get a clear overview of the complex research
area. Furthermore, by doing so, we identify interesting new approaches for
trust and reputation modeling that so far have not been investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0418</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0418</id><created>2012-07-02</created><authors><author><keyname>Ramsdell</keyname><forenames>John D.</forenames></author><author><keyname>Guttman</keyname><forenames>Joshua D.</forenames></author><author><keyname>Millen</keyname><forenames>Jonathan K.</forenames></author><author><keyname>O'Hanlon</keyname><forenames>Brian</forenames></author></authors><title>An Analysis of the CAVES Attestation Protocol using CPSA</title><categories>cs.CR</categories><report-no>MITRE Technical Report MTR090213</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the CAVES attestation protocol and presents a
tool-supported analysis showing that the runs of the protocol achieve stated
goals. The goals are stated formally by annotating the protocol with logical
formulas using the rely-guarantee method. The protocol analysis tool used is
the Cryptographic Protocol Shape Analyzer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0421</identifier>
 <datestamp>2012-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0421</id><created>2012-07-02</created><updated>2012-11-01</updated><authors><author><keyname>Choure</keyname><forenames>Ayush</forenames></author><author><keyname>Vishwanathan</keyname><forenames>Sundar</forenames></author></authors><title>On graph parameters guaranteeing fast Sandpile diffusion</title><categories>cs.DM math-ph math.MP</categories><comments>26 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Abelian Sandpile Model is a discrete diffusion process defined on graphs
(Dhar \cite{DD90}, Dhar et al. \cite{DD95}) which serves as the standard model
of self-organized criticality. The transience class of a sandpile is defined as
the maximum number of particles that can be added without making the system
recurrent (\cite{BT05}). We demonstrate a class of sandpile which have
polynomially bound transience classes by identifying key graph properties that
play a role in the rapid diffusion process. These are the volume growth
parameters, boundary regularity type properties and non-empty interior type
constraints. This generalizes a previous result by Babai and Gorodezky (SODA
2007,\cite{LB07}), in which they establish polynomial bounds on $n \times n$
grid. Indeed the properties we show are based on ideas extracted from their
proof as well as the continuous analogs in complex analysis. We conclude with a
discussion on the notion of degeneracy and dimensions in graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0425</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0425</id><created>2012-07-02</created><authors><author><keyname>Amphawan</keyname><forenames>Angela</forenames></author><author><keyname>Khair</keyname><forenames>Mohd Amirol Md</forenames></author><author><keyname>Hasan</keyname><forenames>Hassanuddin</forenames></author></authors><title>Multimedia Traffic Routing in Multilayer WDM Networks</title><categories>cs.NI physics.optics</categories><comments>10 pages, 8 figures</comments><journal-ref>Multimedia Traffic Routing in Multilayer WDM Networks&quot;, Network
  and Complex Systems, Vol. 2, No. 3, pp. 1 - 9, 2012, ISSN 2224-610X (Paper)
  ISSN 2225-0603 (Online)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of real-time multimedia services over the Internet has stimulated
new technologies for expanding the information carrying capacity of optical
network backbones. Multilayer wavelength division multiplexing (WDM) packet
switching is an emerging technology for increasing the bandwidth of optical
networks. Two algorithms for the routing of the multimedia traffic flows were
applied: (i) Capacitated Shortest Path First (CSPF) routing, which minimizes
the distance of each flow linking the given source and destination nodes and
satisfying capacity constraints; and (ii) Flow Deviation Algorithm (FDA)
routing, which minimizes the network?wide average packet delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0436</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0436</id><created>2012-07-02</created><updated>2012-09-21</updated><authors><author><keyname>Sason</keyname><forenames>Igal</forenames></author></authors><title>On the Entropy of Sums of Bernoulli Random Variables via the Chen-Stein
  Method</title><categories>cs.IT math.IT math.PR</categories><comments>A conference paper of 5 pages that appears in the Proceedings of the
  2012 IEEE International Workshop on Information Theory (ITW 2012), pp.
  542--546, Lausanne, Switzerland, September 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the entropy of the sum of (possibly dependent and
non-identically distributed) Bernoulli random variables. Upper bounds on the
error that follows from an approximation of this entropy by the entropy of a
Poisson random variable with the same mean are derived. The derivation of these
bounds combines elements of information theory with the Chen-Stein method for
Poisson approximation. The resulting bounds are easy to compute, and their
applicability is exemplified. This conference paper presents in part the first
half of the paper entitled &quot;An information-theoretic perspective of the Poisson
approximation via the Chen-Stein method&quot; (see:arxiv:1206.6811). A
generalization of the bounds that considers the accuracy of the Poisson
approximation for the entropy of a sum of non-negative, integer-valued and
bounded random variables is introduced in the full paper. It also derives lower
bounds on the total variation distance, relative entropy and other measures
that are not considered in this conference paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0437</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0437</id><created>2012-07-02</created><updated>2012-08-09</updated><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Dendrogram/Regionalization of U. S. Counties Based upon Migration Flows</title><categories>physics.soc-ph cs.SI stat.AP</categories><comments>44 pages, certain passages extracted from arXiv:0809.2768, technical
  problem addressed in more faithfully including the multi-page dendrogram (by
  slightly scaling the individual pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have obtained a &quot;hierarchical regionalization&quot; of 3,107 county-level units
of the United States based upon 1995-2000 intercounty migration flows. The
methodology employed was the two-stage (double-standardization and strong
component directed graph] hierarchical clustering) algorithm described in the
2009 PNAS letter arXiv:0904.4863. Various features (e. g., cosmopolitan vs.
provincial aspects) of the regionalization have been discussed in
arXiv:0907.2393, arXiv:0903.3623 and arXiv:0809.2768. However, due to the
cumbersome (38-page) nature of the dendrogram, this interesting tree structure
was not readily available for inspection (but see
http://www.spatial.ucsb.edu/events/brownbags/docs/2009-2010/Slater-Ordinal-Hierarchy.pdf).
Here, we do directly present this (searchable) dendrogram. An ordinal
scale--rather than the originally-derived cardinal scale of the
doubly-standardized values--in which groupings/features are more immediately
apparent, is employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0439</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0439</id><created>2012-07-02</created><authors><author><keyname>Kinne</keyname><forenames>Richard C. S.</forenames></author></authors><title>An Overview of the AAVSO's Information Technology Infrastructure From
  1967 to 1997</title><categories>cs.CY</categories><comments>14 pages, 5 figures, 1 table. Based on a poster presented at the
  100th Spring Meeting of the AAVSO, May 22, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer technology and data processing swept both society and the sciences
like a wave in the latter half of the 20th century. We trace the AAVSO's usage
of computational and data processing technology from its beginnings in 1967,
through 1997. We focus on equipment, people, and the purpose such computational
power was put to, and compare and contrast the organization's use of hardware
and software with that of the wider industry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0443</identifier>
 <datestamp>2014-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0443</id><created>2012-07-02</created><updated>2014-02-13</updated><authors><author><keyname>Medeiros</keyname><forenames>S&#xe9;rgio</forenames></author><author><keyname>Mascarenhas</keyname><forenames>Fabio</forenames></author><author><keyname>Ierusalimschy</keyname><forenames>Roberto</forenames></author></authors><title>Left Recursion in Parsing Expression Grammars</title><categories>cs.FL</categories><comments>Extended version of the paper &quot;Left Recursion in Parsing Expression
  Grammars&quot;, that was published on 2012 Brazilian Symposium on Programming
  Languages</comments><doi>10.1016/j.scico.2014.01.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parsing Expression Grammars (PEGs) are a formalism that can describe all
deterministic context-free languages through a set of rules that specify a
top-down parser for some language. PEGs are easy to use, and there are
efficient implementations of PEG libraries in several programming languages.
  A frequently missed feature of PEGs is left recursion, which is commonly used
in Context-Free Grammars (CFGs) to encode left-associative operations. We
present a simple conservative extension to the semantics of PEGs that gives
useful meaning to direct and indirect left-recursive rules, and show that our
extensions make it easy to express left-recursive idioms from CFGs in PEGs,
with similar results. We prove the conservativeness of these extensions, and
also prove that they work with any left-recursive PEG.
  PEGs can also be compiled to programs in a low-level parsing machine. We
present an extension to the semantics of the operations of this parsing machine
that let it interpret left-recursive PEGs, and prove that this extension is
correct with regards to our semantics for left-recursive PEGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0446</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0446</id><created>2012-07-02</created><authors><author><keyname>Elberrichi</keyname><forenames>Zakaria</forenames></author><author><keyname>Amel</keyname><forenames>Belaggoun</forenames></author><author><keyname>Malika</keyname><forenames>Taibi</forenames></author></authors><title>Medical Documents Classification Based on the Domain Ontology MeSH</title><categories>cs.IR</categories><journal-ref>The International Arab Journal of e-Technology, Vol. 2, No. 4,
  June 2012, page 210-215</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of classifying web documents using domain
ontology. Our goal is to provide a method for improving the classification of
medical documents by exploiting the MeSH thesaurus (Medical Subject Headings)
which will allow us to generate a new representation based on concepts. This
approach was tested with two well-known data mining algorithms C4.5 and KNN,
and a comparison was made with the usual representation using stems. The
enrichment of vectors using the concepts and the hyperonyms drawn from the
domain ontology has significantly boosted their representation, something
essential for good classification. The results of our experiments on the
benchmark biomedical collection Ohsumed confirm the importance of the approach
by a very significant improvement in the performance of the ontology-based
classification compared to the classical representation (Stems) by 30%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0484</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0484</id><created>2012-07-02</created><authors><author><keyname>Ekin</keyname><forenames>Sabit</forenames></author><author><keyname>Abdallah</keyname><forenames>Mohamed M.</forenames></author><author><keyname>Qaraqe</keyname><forenames>Khalid A.</forenames></author><author><keyname>Serpedin</keyname><forenames>Erchin</forenames></author></authors><title>Random Subcarrier Allocation in OFDM-Based Cognitive Radio Networks</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>To appear in IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2012.2203126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the performance of an orthogonal frequency-division
multiplexing (OFDM)-based cognitive radio (CR) spectrum sharing communication
system that assumes random allocation and absence of the primary user's (PU)
channel occupation information, i.e., no spectrum sensing is employed to
acquire information about the availability of unused subcarriers. In case of a
single secondary user (SU) in the secondary network, due to the lack of
information of PUs' activities, the SU randomly allocates the subcarriers of
the primary network and collide with the PUs' subcarriers with a certain
probability. To maintain the quality of service (QoS) requirement of PUs, the
interference that SU causes onto PUs is controlled by adjusting SU's transmit
power below a predefined threshold, referred to as interference temperature. In
this work, the average capacity of SU with subcarrier collisions is employed as
performance measure to investigate the proposed random allocation scheme for
both general and Rayleigh channel fading models. Bounds and scaling laws of
average capacity with respect to the number of SU's, PUs' and available
subcarriers are derived. In addition, in the presence of multiple SUs, the
multiuser diversity gain of SUs assuming an opportunistic scheduling is also
investigated. To avoid the interference at the SUs that might be caused by the
random allocation scheme and obtain the maximum sum rate for SUs based on the
available subcarriers, an efficient centralized sequential algorithm based on
the opportunistic scheduling and random allocation (utilization) methods is
proposed to ensure the orthogonality of assigned subcarriers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0535</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0535</id><created>2012-07-02</created><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Liu</keyname><forenames>David</forenames></author></authors><title>Universal Witnesses for State Complexity of Basic Operations Combined
  with Reversal</title><categories>cs.FL</categories><comments>18 pages, 8 figures. LNCS format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the state complexity of boolean operations, concatenation and star
with one or two of the argument languages reversed. We derive tight upper
bounds for the symmetric differences and differences of such languages. We
prove that the previously discovered bounds for union, intersection,
concatenation and star of such languages can all be met by the recently
introduced universal witnesses and their variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0543</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0543</id><created>2012-07-02</created><authors><author><keyname>Fawzi</keyname><forenames>Omar</forenames></author><author><keyname>Savov</keyname><forenames>Ivan</forenames></author></authors><title>Rate-splitting in the presence of multiple receivers</title><categories>cs.IT math.IT</categories><comments>3 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the presence of multiple senders, one of the simplest decoding strategies
that can be employed by a receiver is successive decoding. In a successive
decoding strategy, the receiver decodes the messages one at a time using the
knowledge of the previously decoded messages as side information. Recently,
there have been two separate attempts to construct codes for the interference
channel using successive decoding based on the idea of rate-splitting.
  In this note, we highlight a difficulty that arises when a rate-splitting
codebook is to be decoded by multiple receivers. The main issue is that the
rates of the split codebook are tightly coupled to the properties of the
channel to the receiver, thus, rates chosen for one of the receivers may not be
decodable for the other. We illustrate this issue by scrutinizing two recent
arguments claiming to achieve the Han-Kobayashi rate region for the
interference channel using rate-splitting and successive decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0546</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0546</id><created>2012-07-02</created><authors><author><keyname>Karimi</keyname><forenames>Kamran</forenames></author></authors><title>Challenges of Upgrading a Virtual Appliance</title><categories>cs.SE</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A virtual appliance contains a target application, and the running
environment necessary for running that application. Users run an appliance
using a virtualization engine, freeing them from the need to make sure that the
target application has access to all its dependencies. However, creating and
managing a virtual appliance, versus a stand-alone application, requires
special considerations. Upgrading a software system is a common requirement,
and is more complicated when dealing with an appliance. This is because both
the target application and the running environment must be upgraded, and there
are often dependencies between these two components. In this paper we briefly
discuss some important points to consider when upgrading an appliance. We then
present a list of items that can help developers prevent problems during an
upgrade effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0550</identifier>
 <datestamp>2012-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0550</id><created>2012-07-02</created><updated>2012-09-26</updated><authors><author><keyname>Ito</keyname><forenames>Tsuyoshi</forenames></author><author><keyname>Vidick</keyname><forenames>Thomas</forenames></author></authors><title>A multi-prover interactive proof for NEXP sound against entangled
  provers</title><categories>quant-ph cs.CC</categories><comments>47 pages. Minor improvements; reduced number of provers from 4 to 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a strong limitation on the ability of entangled provers to collude
in a multiplayer game. Our main result is the first nontrivial lower bound on
the class MIP* of languages having multi-prover interactive proofs with
entangled provers; namely MIP* contains NEXP, the class of languages decidable
in non-deterministic exponential time. While Babai, Fortnow, and Lund
(Computational Complexity 1991) proved the celebrated equality MIP = NEXP in
the absence of entanglement, ever since the introduction of the class MIP* it
was open whether shared entanglement between the provers could weaken or
strengthen the computational power of multi-prover interactive proofs. Our
result shows that it does not weaken their computational power: MIP* contains
MIP.
  At the heart of our result is a proof that Babai, Fortnow, and Lund's
multilinearity test is sound even in the presence of entanglement between the
provers, and our analysis of this test could be of independent interest. As a
byproduct we show that the correlations produced by any entangled strategy
which succeeds in the multilinearity test with high probability can always be
closely approximated using shared randomness alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0552</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0552</id><created>2012-07-02</created><authors><author><keyname>Mertzios</keyname><forenames>George B.</forenames></author><author><keyname>Zaks</keyname><forenames>Shmuel</forenames></author></authors><title>On the Intersection of Tolerance and Cocomparability Graphs</title><categories>cs.DM math.CO</categories><comments>58 pages, 9 figures. A preliminary conference version appeared in the
  Proceedings of the 21st International Symposium on Algorithms and Computation
  (ISAAC), Jeju Island, Korea, December 2010, Volume 1, pages 230-240</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been conjectured by Golumbic and Monma in 1984 that the intersection
of tolerance and cocomparability graphs coincides with bounded tolerance
graphs. The conjecture has been proved under some - rather strong -
\emph{structural} assumptions on the input graph; in particular, it has been
proved for complements of trees, and later extended to complements of bipartite
graphs, and these are the only known results so far. Our main result in this
article is that the above conjecture is true for every graph $G$ that admits a
tolerance representation with exactly one unbounded vertex; note here that this
assumption concerns only the given tolerance \emph{representation} $R$ of $G$,
rather than any structural property of $G$. Moreover, our results imply as a
corollary that the conjecture of Golumbic, Monma, and Trotter is true for every
graph $G=(V,E)$ that has no three independent vertices $a,b,c\in V$ such that
$N(a) \subset N(b) \subset N(c)$; this is satisfied in particular when $G$ is
the complement of a triangle-free graph (which also implies the above-mentioned
correctness for complements of bipartite graphs). Our proofs are constructive,
in the sense that, given a tolerance representation $R$ of a graph $G$, we
transform $R$ into a bounded tolerance representation $R^{\ast}$ of $G$.
Furthermore, we conjecture that any \emph{minimal} tolerance graph $G$ that is
not a bounded tolerance graph, has a tolerance representation with exactly one
unbounded vertex. Our results imply the non-trivial result that, in order to
prove the conjecture of Golumbic, Monma, and Trotter, it suffices to prove our
conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0554</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0554</id><created>2012-07-02</created><authors><author><keyname>Peled</keyname><forenames>Doron</forenames><affiliation>Bar Ilan University</affiliation></author><author><keyname>Schewe</keyname><forenames>Sven</forenames><affiliation>University of Liverpool</affiliation></author></authors><title>Proceedings First Workshop on Synthesis</title><categories>cs.LO cs.FL cs.SE cs.SY</categories><proxy>EPTCS</proxy><acm-class>I.2.2</acm-class><journal-ref>EPTCS 84, 2012</journal-ref><doi>10.4204/EPTCS.84</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the First Workshop on Synthesis (SYNT
2012). The workshop is held is held in Berkeley, California, on June 6th and
7th, as a satellite event to the 24th International Conference on Computer
Aided Verification (CAV 2012). SYNT aims at bringing together and providing an
open platform for researchers interested in synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0557</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0557</id><created>2012-07-02</created><authors><author><keyname>Yang</keyname><forenames>C.</forenames></author><author><keyname>Jiang</keyname><forenames>C.</forenames></author><author><keyname>Wang</keyname><forenames>M.</forenames></author></authors><title>Distributed Dynamic Inter-Cell Interference Management for Femtocell
  Networks Using Over-the-Air Single-Tone Signaling</title><categories>cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1112.1989,
  arXiv:1103.2503</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Femtocell networks are promising for not only improving the coverage but also
increasing the capacity of current cellular networks. The interference-limited
reality in femtocell networks makes interference management (IM) the key to
maintaining the quality of service and fairness in femtocell networks.
Over-the-air signaling is one of the most effective means for fast distributed
dynamic IM. However, the design of this type of signal is challenging. In this
paper, we address the challenges and propose an effective solution, referred to
as single-tone signaling (STS). The proposed STS scheme possesses many highly
desirable properties, such as no dedicated resource requirement (no system
overhead), no near-far effect, no inter-signal interference, and immunity to
synchronization error. In addition, the proposed STS signal provides a means
for high quality wideband channel estimation for the use of coordinated
techniques, such as coordinated beamforming. Based on the proposed STS, two
distributed dynamic IM schemes, ON/OFF power control and SLNR
(signal-to-leakage-plus-noise-ratio)-based transmitter beam coordination, are
proposed. Simulation results show significant performance improvement as a
result of the use of STS-based IM schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0559</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0559</id><created>2012-07-02</created><authors><author><keyname>Wiklicky</keyname><forenames>Herbert</forenames></author><author><keyname>Massink</keyname><forenames>Mieke</forenames></author></authors><title>Proceedings 10th Workshop on Quantitative Aspects of Programming
  Languages and Systems</title><categories>cs.PL cs.LO cs.PF</categories><comments>EPTCS 85, 2012</comments><proxy>EPTCS</proxy><doi>10.4204/EPTCS.85</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Tenth Workshop on Quantitative
Aspects of Programming Languages (QAPL 2012), held in Tallin, Estonia, on March
31 and April 1, 2012. QAPL 2012 is a satellite event of the European Joint
Conferences on Theory and Practice of Software (ETAPS 2012). The workshop theme
is on quantitative aspects of computation. These aspects are related to the use
of physical quantities (storage space, time, bandwidth, etc.) as well as
mathematical quantities (e.g. probability and measures for reliability,
security and trust), and play an important (sometimes essential) role in
characterising the behavior and determining the properties of systems. Such
quantities are central to the definition of both the model of systems
(architecture, language design, semantics) and the methodologies and tools for
the analysis and verification of the systems properties. The aim of this
workshop is to discuss the explicit use of quantitative information such as
time and probabilities either directly in the model or as a tool for the
analysis of systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0560</identifier>
 <datestamp>2013-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0560</id><created>2012-07-02</created><updated>2013-08-24</updated><authors><author><keyname>Iyer</keyname><forenames>Rishabh</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff</forenames></author></authors><title>Algorithms for Approximate Minimization of the Difference Between
  Submodular Functions, with Applications</title><categories>cs.DS cs.LG</categories><comments>17 pages, 8 figures. A shorter version of this appeared in Proc.
  Uncertainty in Artificial Intelligence (UAI), Catalina Islands, 2012</comments><journal-ref>UAI-2012</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We extend the work of Narasimhan and Bilmes [30] for minimizing set functions
representable as a difference between submodular functions. Similar to [30],
our new algorithms are guaranteed to monotonically reduce the objective
function at every step. We empirically and theoretically show that the
per-iteration cost of our algorithms is much less than [30], and our algorithms
can be used to efficiently minimize a difference between submodular functions
under various combinatorial constraints, a problem not previously addressed. We
provide computational bounds and a hardness result on the mul- tiplicative
inapproximability of minimizing the difference between submodular functions. We
show, however, that it is possible to give worst-case additive bounds by
providing a polynomial time computable lower-bound on the minima. Finally we
show how a number of machine learning problems can be modeled as minimizing the
difference between submodular functions. We experimentally show the validity of
our algorithms by testing them on the problem of feature selection with
submodular cost features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0561</identifier>
 <datestamp>2014-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0561</id><created>2012-07-02</created><updated>2013-12-31</updated><authors><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author><author><keyname>Kurahashi</keyname><forenames>Issei</forenames></author><author><keyname>Onari</keyname><forenames>Hiroko</forenames></author></authors><title>Suicide ideation of individuals in online social networks</title><categories>cs.SI physics.soc-ph</categories><comments>4 figures, 9 tables</comments><journal-ref>PLOS ONE, 8 (4), e62262 (2013)</journal-ref><doi>10.1371/journal.pone.0062262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suicide explains the largest number of death tolls among Japanese adolescents
in their twenties and thirties. Suicide is also a major cause of death for
adolescents in many other countries. Although social isolation has been
implicated to influence the tendency to suicidal behavior, the impact of social
isolation on suicide in the context of explicit social networks of individuals
is scarcely explored. To address this question, we examined a large data set
obtained from a social networking service dominant in Japan. The social network
is composed of a set of friendship ties between pairs of users created by
mutual endorsement. We carried out the logistic regression to identify users'
characteristics, both related and unrelated to social networks, which
contribute to suicide ideation. We defined suicide ideation of a user as the
membership to at least one active user-defined community related to suicide. We
found that the number of communities to which a user belongs to, the
intransitivity (i.e., paucity of triangles including the user), and the
fraction of suicidal neighbors in the social network, contributed the most to
suicide ideation in this order. Other characteristics including the age and
gender contributed little to suicide ideation. We also found qualitatively the
same results for depressive symptoms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0563</identifier>
 <datestamp>2013-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0563</id><created>2012-07-02</created><updated>2013-04-01</updated><authors><author><keyname>Caliskan</keyname><forenames>Sina Y.</forenames></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>Kron Reduction of Generalized Electrical Networks</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kron reduction is used to simplify the analysis of multi-machine power
systems under certain steady state assumptions that underly the usage of
phasors. In this paper we show how to perform Kron reduction for a class of
electrical networks without steady state assumptions. The reduced models can
thus be used to analyze the transient as well as the steady state behavior of
these electrical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0577</identifier>
 <datestamp>2013-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0577</id><created>2012-07-03</created><updated>2013-10-10</updated><authors><author><keyname>Liu</keyname><forenames>Ji</forenames></author><author><keyname>Wright</keyname><forenames>Stephen J.</forenames></author></authors><title>Robust Dequantized Compressive Sensing</title><categories>stat.ML cs.LG</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider the reconstruction problem in compressed sensing in which the
observations are recorded in a finite number of bits. They may thus contain
quantization errors (from being rounded to the nearest representable value) and
saturation errors (from being outside the range of representable values). Our
formulation has an objective of weighted $\ell_2$-$\ell_1$ type, along with
constraints that account explicitly for quantization and saturation errors, and
is solved with an augmented Lagrangian method. We prove a consistency result
for the recovered solution, stronger than those that have appeared to date in
the literature, showing in particular that asymptotic consistency can be
obtained without oversampling. We present extensive computational comparisons
with formulations proposed previously, and variants thereof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0578</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0578</id><created>2012-07-03</created><updated>2012-10-09</updated><authors><author><keyname>Sutton</keyname><forenames>Andrew M.</forenames></author><author><keyname>Neumann</keyname><forenames>Frank</forenames></author></authors><title>Parameterized Runtime Analyses of Evolutionary Algorithms for the
  Euclidean Traveling Salesperson Problem</title><categories>cs.NE cs.DS</categories><comments>A conference version has been accepted for AAAI 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parameterized runtime analysis seeks to understand the influence of problem
structure on algorithmic runtime. In this paper, we contribute to the
theoretical understanding of evolutionary algorithms and carry out a
parameterized analysis of evolutionary algorithms for the Euclidean traveling
salesperson problem (Euclidean TSP).
  We investigate the structural properties in TSP instances that influence the
optimization process of evolutionary algorithms and use this information to
bound the runtime of simple evolutionary algorithms. Our analysis studies the
runtime in dependence of the number of inner points $k$ and shows that $(\mu +
\lambda)$ evolutionary algorithms solve the Euclidean TSP in expected time
$O((\mu/\lambda) \cdot n^3\gamma(\epsilon) + n\gamma(\epsilon) + (\mu/\lambda)
\cdot n^{4k}(2k-1)!)$ where $\gamma$ is a function of the minimum angle
$\epsilon$ between any three points.
  Finally, our analysis provides insights into designing a mutation operator
that improves the upper bound on expected runtime. We show that a mixed
mutation strategy that incorporates both 2-opt moves and permutation jumps
results in an upper bound of $O((\mu/\lambda) \cdot n^3\gamma(\epsilon) +
n\gamma(\epsilon) + (\mu/\lambda) \cdot n^{2k}(k-1)!)$ for the $(\mu+\lambda)$
EA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0580</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0580</id><created>2012-07-03</created><authors><author><keyname>Hinton</keyname><forenames>Geoffrey E.</forenames></author><author><keyname>Srivastava</keyname><forenames>Nitish</forenames></author><author><keyname>Krizhevsky</keyname><forenames>Alex</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan R.</forenames></author></authors><title>Improving neural networks by preventing co-adaptation of feature
  detectors</title><categories>cs.NE cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a large feedforward neural network is trained on a small training set,
it typically performs poorly on held-out test data. This &quot;overfitting&quot; is
greatly reduced by randomly omitting half of the feature detectors on each
training case. This prevents complex co-adaptations in which a feature detector
is only helpful in the context of several other specific feature detectors.
Instead, each neuron learns to detect a feature that is generally helpful for
producing the correct answer given the combinatorially large variety of
internal contexts in which it must operate. Random &quot;dropout&quot; gives big
improvements on many benchmark tasks and sets new records for speech and object
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0592</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0592</id><created>2012-07-03</created><authors><author><keyname>Poornima</keyname><forenames>U. S.</forenames></author><author><keyname>Suma</keyname><forenames>V.</forenames></author></authors><title>Significance of Quality Metrics in Software Development Process</title><categories>cs.SE</categories><comments>5 pages,International Conference on Innovative Computing and
  Information Processing (ICCIP - 2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, Software has become an indispensable part of every segment
from simple Office Automation to Space Technology and E-mail to E-commerce. The
evolution in Software architecture is always an open issue for researchers to
address complex systems with numerous domain-specific requirements. Success of
a system is based on quality outcome of every stage of development with proper
measuring techniques. Metrics are measures of Process, Product and People (P3)
who are involved in the development process, acts as quality indicators
reflecting the maturity level of the company. Several process metrics has been
defined and practiced to measure the software deliverables comprising of
requirement analysis through maintenance. Metrics at each stage has its own
significance to increase the quality of the milestones and hence the quality of
end product. This paper highlights the significance of software quality metrics
followed at major phases of software development namely requirement, design and
implementation. This paper thereby aims to bring awareness towards existing
metrics and leads towards enhancement of them in order to reflect continuous
process improvement in the company for their sustainability in the market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0602</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0602</id><created>2012-07-03</created><updated>2012-07-16</updated><authors><author><keyname>Jurdzinski</keyname><forenames>Tomasz</forenames></author><author><keyname>Kowalski</keyname><forenames>Dariusz R.</forenames></author></authors><title>Distributed backbone structure for deterministic algorithms in the SINR
  model of wireless networks</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Signal-to-Interference-and-Noise-Ratio (SINR) physical model is one of
the legitimate models of wireless networks. Despite of the vast amount of study
done in design and analysis of centralized algorithms supporting wireless
communication under the SINR physical model, little is known about distributed
algorithms in this model, especially deterministic ones. In this work we
construct, in a deterministic distributed way, a backbone structure on the top
of a given wireless network, which can be used for transforming many algorithms
designed in a simpler model of ad hoc broadcast networks without interference
into the SINR physical model with uniform power of stations, without increasing
their asymptotic time complexity. The time cost of the backbone data structure
construction is only O(Delta polylog n) rounds, where Delta is roughly the
inverse of network density and n is the number of nodes in the whole network.
The core of the construction is a novel combinatorial structure called
SINR-selector, which is introduced and constructed in this paper. We
demonstrate the power of the backbone data structure by using it for obtaining
efficient O(D+Delta polylog n)-round and O(D+k+Delta polylog n)-round
deterministic distributed solutions for leader election and multi-broadcast,
respectively, where D is the network diameter and k is the number of messages
to be disseminated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0630</identifier>
 <datestamp>2012-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0630</id><created>2012-07-03</created><updated>2012-08-28</updated><authors><author><keyname>Terui</keyname><forenames>Akira</forenames></author></authors><title>GPGCD: An iterative method for calculating approximate GCD of univariate
  polynomials</title><categories>math.AC cs.SC</categories><comments>37 pages. To appear in Theoretical Computer Science, Special Issue on
  Symbolic Numeric Computation SNC 2011. Preliminary versions have been
  presented as doi:10.1145/1576702.1576750 and arXiv:1007.1834</comments><msc-class>13P99, 68W30</msc-class><acm-class>I.1.2; F.2.1; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an iterative algorithm for calculating approximate greatest common
divisor (GCD) of univariate polynomials with the real or the complex
coefficients. For a given pair of polynomials and a degree, our algorithm finds
a pair of polynomials which has a GCD of the given degree and whose
coefficients are perturbed from those in the original inputs, making the
perturbations as small as possible, along with the GCD. The problem of
approximate GCD is transfered to a constrained minimization problem, then
solved with the so-called modified Newton method, which is a generalization of
the gradient-projection method, by searching the solution iteratively. We
demonstrate that, in some test cases, our algorithm calculates approximate GCD
with perturbations as small as those calculated by a method based on the
structured total least norm (STLN) method and the UVGCD method, while our
method runs significantly faster than theirs by approximately up to 30 or 10
times, respectively, compared with their implementation. We also show that our
algorithm properly handles some ill-conditioned polynomials which have a GCD
with small or large leading coefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0634</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0634</id><created>2012-07-03</created><authors><author><keyname>Murthy</keyname><forenames>Garimella Rama</forenames><affiliation>International Institute of Information Technology, Gachibowli, Hyderabad, India</affiliation></author></authors><title>Optimization of Quadratic Forms: NP Hard Problems : Neural Networks</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research paper, the problem of optimization of a quadratic form over
the convex hull generated by the corners of hypercube is attempted and solved.
Some results related to stable states/vectors, anti-stable states/vectors (over
the hypercube) are discussed. Some results related to the computation of global
optimum stable state (an NP hard problem) are discussed. It is hoped that the
results shed light on resolving the P \neq NP problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0639</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0639</id><created>2012-07-03</created><authors><author><keyname>Murin</keyname><forenames>Yonathan</forenames></author><author><keyname>Dabora</keyname><forenames>Ron</forenames></author><author><keyname>G&#xfc;nd&#xfc;z</keyname><forenames>Deniz</forenames></author></authors><title>Joint Source-Channel Coding for the Multiple-Access Relay Channel</title><categories>cs.IT math.IT</categories><comments>To be presented in ISIT 2012, 5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable transmission of arbitrarily correlated sources over multiple-access
relay channels (MARCs) and multiple-access broadcast relay channels (MABRCs) is
considered. In MARCs, only the destination is interested in a reconstruction of
the sources, while in MABRCs, both the relay and the destination want to
reconstruct the sources. We allow an arbitrary correlation among the sources at
the transmitters, and let both the relay and the destination have side
information that are correlated with the sources.
  Two joint source-channel coding schemes are presented and the corresponding
sets of sufficient conditions for reliable communication are derived. The
proposed schemes use a combination of the correlation preserving mapping (CPM)
technique with Slepian-Wolf (SW) source coding: the first scheme uses CPM for
encoding information to the relay and SW source coding for encoding information
to the destination; while the second scheme uses SW source coding for encoding
information to the relay and CPM for encoding information to the destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0654</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0654</id><created>2012-07-03</created><authors><author><keyname>Perrot</keyname><forenames>Kevin</forenames></author><author><keyname>Phan</keyname><forenames>Thi Ha Duong</forenames></author><author><keyname>Van Pham</keyname><forenames>Trung</forenames></author></authors><title>On the set of Fixed Points of the Parallel Symmetric Sand Pile Model</title><categories>cs.DM</categories><comments>13 pages</comments><journal-ref>Automata 2011, DMTCS : Automata 2011 - 17th International Workshop
  on Cellular Automata and Discrete Complex Systems, pages 17-28</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sand Pile Models are discrete dynamical systems emphasizing the phenomenon of
Self-Organized Criticality. From a configuration composed of a finite number of
stacked grains, we apply on every possible positions (in parallel) two grain
moving transition rules. The transition rules permit one grain to fall to its
right or left (symmetric) neighboring column if the difference of height
between those columns is larger than 2. The model is nondeterministic and
grains always fall downward. We propose a study of the set of fixed points
reachable in the Parallel Symmetric Sand Pile Model (PSSPM). Using a comparison
with the Symmetric Sand Pile Model (SSPM) on which rules are applied once at
each iteration, we get a continuity property. This property states that within
PSSPM we can't reach every fixed points of SSPM, but a continuous subset
according to the lexicographic order. Moreover we define a successor relation
to browse exhaustively the sets of fixed points of those models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0657</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0657</id><created>2012-07-03</created><authors><author><keyname>Yordzhev</keyname><forenames>Krasimir</forenames></author><author><keyname>Peneva</keyname><forenames>Ivelina</forenames></author></authors><title>Computer Administering of the Psychological Investigations:
  Set-relational Representation</title><categories>cs.HC cs.CY</categories><msc-class>91E45, 68P15</msc-class><journal-ref>Open Journal of Applied Sciences, 2012, 2, 110-114</journal-ref><doi>10.4236/ojapps.2012.22015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer administering of a psychological investigation is the computer
representation of the entire procedure of psychological assessments - test
construction, test implementation, results evaluation, storage and maintenance
of the developed database, its statistical processing, analysis and
interpretation. A mathematical description of psychological assessment with the
aid of personality tests is discussed in this article. The set theory and the
relational algebra are used in this description. A relational model of data,
needed to design a computer system for automation of certain psychological
assessments is given. Some finite sets and relation on them, which are
necessary for creating a personality psychological test, are described. The
described model could be used to develop real software for computer
administering of any psychological test and there is full automation of the
whole process: test construction, test implementation, result evaluation,
storage of the developed database, statistical implementation, analysis and
interpretation. A software project for computer administering personality
psychological tests is suggested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0658</identifier>
 <datestamp>2013-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0658</id><created>2012-07-03</created><authors><author><keyname>Altmann</keyname><forenames>Eduardo G.</forenames></author><author><keyname>Cristadoro</keyname><forenames>Giampaolo</forenames></author><author><keyname>Esposti</keyname><forenames>Mirko Degli</forenames></author></authors><title>On the origin of long-range correlations in texts</title><categories>physics.data-an cs.CL physics.soc-ph</categories><comments>Full paper (8 pages) and Supporting Information (19 pages)</comments><journal-ref>Proc. Natl. Acad. Sci. USA 109, 11582 (2012)</journal-ref><doi>10.1073/pnas.1117723109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of human interactions with social and natural phenomena is
mirrored in the way we describe our experiences through natural language. In
order to retain and convey such a high dimensional information, the statistical
properties of our linguistic output has to be highly correlated in time. An
example are the robust observations, still largely not understood, of
correlations on arbitrary long scales in literary texts. In this paper we
explain how long-range correlations flow from highly structured linguistic
levels down to the building blocks of a text (words, letters, etc..). By
combining calculations and data analysis we show that correlations take form of
a bursty sequence of events once we approach the semantically relevant topics
of the text. The mechanisms we identify are fairly general and can be equally
applied to other hierarchical settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0660</identifier>
 <datestamp>2013-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0660</id><created>2012-07-03</created><updated>2012-09-07</updated><authors><author><keyname>Viossat</keyname><forenames>Yannick</forenames><affiliation>CEREMADE</affiliation></author><author><keyname>Zapechelnyuk</keyname><forenames>Andriy</forenames><affiliation>QMUL</affiliation></author></authors><title>No-regret Dynamics and Fictitious Play</title><categories>math.DS cs.GT</categories><proxy>ccsd</proxy><journal-ref>Journal of Economic Theory 148, 2 (2013) 825-842</journal-ref><doi>10.1016/j.jet.2012.07.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Potential based no-regret dynamics are shown to be related to fictitious
play. Roughly, these are epsilon-best reply dynamics where epsilon is the
maximal regret, which vanishes with time. This allows for alternative and
sometimes much shorter proofs of known results on convergence of no-regret
dynamics to the set of Nash equilibria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0663</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0663</id><created>2012-07-03</created><updated>2014-06-23</updated><authors><author><keyname>Fijalkow</keyname><forenames>Nathana&#xeb;l</forenames><affiliation>LIAFA, Universit&#xe9; Paris 7 and Institute of Informatics, University of Warsaw</affiliation></author><author><keyname>Zimmermann</keyname><forenames>Martin</forenames><affiliation>Saarland University</affiliation></author></authors><title>Parity and Streett Games with Costs</title><categories>cs.LO cs.CC cs.GT</categories><comments>A preliminary version of this work appeared in FSTTCS 2012 under the
  name &quot;Cost-parity and Cost-Streett Games&quot;. The research leading to these
  results has received funding from the European Union's Seventh Framework
  Programme (FP7/2007-2013) under grant agreements 259454 (GALE) and 239850
  (SOSNA)</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 2 (June 26,
  2014) lmcs:794</journal-ref><doi>10.2168/LMCS-10(2:14)2014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider two-player games played on finite graphs equipped with costs on
edges and introduce two winning conditions, cost-parity and cost-Streett, which
require bounds on the cost between requests and their responses. Both
conditions generalize the corresponding classical omega-regular conditions and
the corresponding finitary conditions. For parity games with costs we show that
the first player has positional winning strategies and that determining the
winner lies in NP and coNP. For Streett games with costs we show that the first
player has finite-state winning strategies and that determining the winner is
EXPTIME-complete. The second player might need infinite memory in both games.
Both types of games with costs can be solved by solving linearly many instances
of their classical variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0665</identifier>
 <datestamp>2012-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0665</id><created>2012-07-03</created><updated>2012-08-19</updated><authors><author><keyname>Huque</keyname><forenames>M. D. Sirajul</forenames></author><author><keyname>Surekha</keyname><forenames>C.</forenames></author><author><keyname>Reddy</keyname><forenames>S. Pavan Kumar</forenames></author><author><keyname>Yadav</keyname><forenames>Vidhisha</forenames></author></authors><title>The Common Difference Between MIMO With Other Antennas</title><categories>cs.NI</categories><comments>Published in Computer Science Chronicle</comments><journal-ref>CSCV01I1, August 2012</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In past 802.11 systems there is a single Radio Frequency (RF) chain on the
Wi-Fi device. Multiple antennas use the same hardware to process the radio
signal. So only one antenna can transmit or receive at a time as all radio
signals need to go through the single RF chain. In MIMO there can be a separate
RF chain for each antenna allowing multiple RF chains to coexist. MIMO
technology has attracted attention in wireless communications, because it
offers significant increases in data throughput and link range without
additional bandwidth or increased transmit power. It achieves this goal by
spreading the same total transmit power over the antennas to achieve an array
gain that improves the spectral efficiency (more bits per second per hertz of
bandwidth) or to achieve a diversity gain that improves the link reliability.
Multiple Input/Multiple Output (MIMO) is an area of intense development in the
wireless industry because it delivers profound gains in range, throughput and
reliability. As a result, manufacturers of wireless local area network (WLAN),
wireless metropolitan area network (WMAN), and mobile phone equipment are
embracing MIMO technology. In this paper we are interested to compare the MIMO
Antenna functions with traditional Antenna functions. And we take an example of
IRT for illustration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0672</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0672</id><created>2012-07-03</created><authors><author><keyname>Keszegh</keyname><forenames>Bal&#xe1;zs</forenames></author><author><keyname>P&#xe1;lv&#xf6;lgyi</keyname><forenames>D&#xf6;m&#xf6;t&#xf6;r</forenames></author></authors><title>Octants are Cover-Decomposable into Many Coverings</title><categories>math.CO cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:1101.3773</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that octants are cover-decomposable into multiple coverings, i.e.,
for any k there is an m(k) such that any m(k)-fold covering of any subset of
the space with a finite number of translates of a given octant can be
decomposed into k coverings. As a corollary, we obtain that any m(k)-fold
covering of any subset of the plane with a finite number of homothetic copies
of a given triangle can be decomposed into k coverings. Previously only some
weaker bounds were known for related problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0677</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0677</id><created>2012-07-03</created><authors><author><keyname>Giot</keyname><forenames>Romain</forenames><affiliation>GREYC</affiliation></author><author><keyname>Charrier</keyname><forenames>Christophe</forenames><affiliation>GREYC</affiliation></author><author><keyname>Descoteaux</keyname><forenames>Maxime</forenames><affiliation>SCIL</affiliation></author></authors><title>Local Water Diffusion Phenomenon Clustering From High Angular Resolution
  Diffusion Imaging (HARDI)</title><categories>cs.LG cs.CV</categories><comments>IAPR International Conference on Pattern Recognition (ICPR), Tsukuba,
  Japan : France (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The understanding of neurodegenerative diseases undoubtedly passes through
the study of human brain white matter fiber tracts. To date, diffusion magnetic
resonance imaging (dMRI) is the unique technique to obtain information about
the neural architecture of the human brain, thus permitting the study of white
matter connections and their integrity. However, a remaining challenge of the
dMRI community is to better characterize complex fiber crossing configurations,
where diffusion tensor imaging (DTI) is limited but high angular resolution
diffusion imaging (HARDI) now brings solutions. This paper investigates the
development of both identification and classification process of the local
water diffusion phenomenon based on HARDI data to automatically detect imaging
voxels where there are single and crossing fiber bundle populations. The
technique is based on knowledge extraction processes and is validated on a dMRI
phantom dataset with ground truth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0689</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0689</id><created>2012-07-03</created><updated>2012-09-29</updated><authors><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author><author><keyname>Forns</keyname><forenames>N&#xfa;ria</forenames></author><author><keyname>Hern&#xe1;ndez-Fern&#xe1;ndez</keyname><forenames>Antoni</forenames></author><author><keyname>Bel-Enguix</keyname><forenames>Gemma</forenames></author><author><keyname>Baixeries</keyname><forenames>Jaume</forenames></author></authors><title>The challenges of statistical patterns of language: the case of
  Menzerath's law in genomes</title><categories>q-bio.GN cs.CE physics.data-an</categories><comments>Title changed, abstract and introduction improved and little
  corrections on the statistical arguments</comments><doi>10.1002/cplx.21429</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of statistical patterns of language has been debated over
decades. Although Zipf's law is perhaps the most popular case, recently,
Menzerath's law has begun to be involved. Menzerath's law manifests in
language, music and genomes as a tendency of the mean size of the parts to
decrease as the number of parts increases in many situations. This statistical
regularity emerges also in the context of genomes, for instance, as a tendency
of species with more chromosomes to have a smaller mean chromosome size. It has
been argued that the instantiation of this law in genomes is not indicative of
any parallel between language and genomes because (a) the law is inevitable and
(b) non-coding DNA dominates genomes. Here mathematical, statistical and
conceptual challenges of these criticisms are discussed. Two major conclusions
are drawn: the law is not inevitable and languages also have a correlate of
non-coding DNA. However, the wide range of manifestations of the law in and
outside genomes suggests that the striking similarities between non-coding DNA
and certain linguistics units could be anecdotal for understanding the
recurrence of that statistical law.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0702</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0702</id><created>2012-07-03</created><authors><author><keyname>Feng</keyname><forenames>Liang</forenames></author><author><keyname>Ong</keyname><forenames>Yew Soon</forenames></author><author><keyname>Tan</keyname><forenames>Ah Hwee</forenames></author><author><keyname>Tsang</keyname><forenames>Ivor Wai-Hung</forenames></author></authors><title>Meme as Building Block for Evolutionary Optimization of Problem
  Instances</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significantly under-explored area of evolutionary optimization in the
literature is the study of optimization methodologies that can evolve along
with the problems solved. Particularly, present evolutionary optimization
approaches generally start their search from scratch or the ground-zero state
of knowledge, independent of how similar the given new problem of interest is
to those optimized previously. There has thus been the apparent lack of
automated knowledge transfers and reuse across problems. Taking the cue, this
paper introduces a novel Memetic Computational Paradigm for search, one that
models after how human solves problems, and embarks on a study towards
intelligent evolutionary optimization of problems through the transfers of
structured knowledge in the form of memes learned from previous problem-solving
experiences, to enhance future evolutionary searches. In particular, the
proposed memetic search paradigm is composed of four culture-inspired
operators, namely, Meme Learning, Meme Selection, Meme Variation and Meme
Imitation. The learning operator mines for memes in the form of latent
structures derived from past experiences of problem-solving. The selection
operator identifies the fit memes that replicate and transmit across problems,
while the variation operator introduces innovations into the memes. The
imitation operator, on the other hand, defines how fit memes assimilate into
the search process of newly encountered problems, thus gearing towards
efficient and effective evolutionary optimization. Finally, comprehensive
studies on two widely studied challenging well established NP-hard routing
problem domains, particularly, the capacitated vehicle routing (CVR) and
capacitated arc routing (CAR), confirm the high efficacy of the proposed
memetic computational search paradigm for intelligent evolutionary optimization
of problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0704</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0704</id><created>2012-07-03</created><authors><author><keyname>Torres</keyname><forenames>Leonardo</forenames></author><author><keyname>Cavalcante</keyname><forenames>Tamer</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>Speckle Reduction using Stochastic Distances</title><categories>cs.IT cs.CV cs.GR math.IT stat.AP stat.ML</categories><comments>Accepted for publication on the proceedings of the 17th Iberoamerican
  Congress on Patter Recognition (CIARP), to be published in the Lecture Notes
  in Computer Science series</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach for filter design based on stochastic
distances and tests between distributions. A window is defined around each
pixel, samples are compared and only those which pass a goodness-of-fit test
are used to compute the filtered value. The technique is applied to intensity
Synthetic Aperture Radar (SAR) data, using the Gamma model with varying number
of looks allowing, thus, changes in heterogeneity. Modified Nagao-Matsuyama
windows are used to define the samples. The proposal is compared with the Lee's
filter which is considered a standard, using a protocol based on simulation.
Among the criteria used to quantify the quality of filters, we employ the
equivalent number of looks (related to the signal-to-noise ratio), line
contrast, and edge preservation. Moreover, we also assessed the filters by the
Universal Image Quality Index and the Pearson's correlation between edges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0739</identifier>
 <datestamp>2012-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0739</id><created>2012-06-21</created><authors><author><keyname>Braha</keyname><forenames>Dan</forenames></author></authors><title>A Universal Model of Global Civil Unrest</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>8 pages, 3 figures</comments><journal-ref>PLoS ONE 7(10): e48596 (2012)</journal-ref><doi>10.1371/journal.pone.0048596</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Civil unrest is a powerful form of collective human dynamics, which has led
to major transitions of societies in modern history. The study of collective
human dynamics, including collective aggression, has been the focus of much
discussion in the context of modeling and identification of universal patterns
of behavior. In contrast, the possibility that civil unrest activities, across
countries and over long time periods, are governed by universal mechanisms has
not been explored. Here, we analyze records of civil unrest of 170 countries
during the period 1919-2008. We demonstrate that the distributions of the
number of unrest events per year are robustly reproduced by a nonlinear,
spatially extended dynamical model, which reflects the spread of civil disorder
between geographic regions connected through social and communication networks.
The results also expose the similarity between global social instability and
the dynamics of natural hazards and epidemics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0742</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0742</id><created>2012-07-03</created><authors><author><keyname>Dymetman</keyname><forenames>Marc</forenames></author><author><keyname>Bouchard</keyname><forenames>Guillaume</forenames></author><author><keyname>Carter</keyname><forenames>Simon</forenames></author></authors><title>The OS* Algorithm: a Joint Approach to Exact Optimization and Sampling</title><categories>cs.AI cs.CL cs.LG</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most current sampling algorithms for high-dimensional distributions are based
on MCMC techniques and are approximate in the sense that they are valid only
asymptotically. Rejection sampling, on the other hand, produces valid samples,
but is unrealistically slow in high-dimension spaces. The OS* algorithm that we
propose is a unified approach to exact optimization and sampling, based on
incremental refinements of a functional upper bound, which combines ideas of
adaptive rejection sampling and of A* optimization search. We show that the
choice of the refinement can be done in a way that ensures tractability in
high-dimension spaces, and we present first experiments in two different
settings: inference in high-order HMMs and in large discrete graphical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0745</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0745</id><created>2012-07-03</created><authors><author><keyname>Dritsoula</keyname><forenames>Lemonia</forenames></author><author><keyname>Loiseau</keyname><forenames>Patrick</forenames></author><author><keyname>Musacchio</keyname><forenames>John</forenames></author></authors><title>A Game-Theoretical Approach for Finding Optimal Strategies in an
  Intruder Classification Game</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a game in which a strategic defender classifies an intruder as
spy or spammer. The classification is based on the number of file server and
mail server attacks observed during a fixed window. The spammer naively attacks
(with a known distribution) his main target: the mail server. The spy
strategically selects the number of attacks on his main target: the file
server. The defender strategically selects his classification policy: a
threshold on the number of file server attacks. We model the interaction of the
two players (spy and defender) as a nonzero-sum game: The defender needs to
balance missed detections and false alarms in his objective function, while the
spy has a tradeoff between attacking the file server more aggressively and
increasing the chances of getting caught. We give a characterization of the
Nash equilibria in mixed strategies, and demonstrate how the Nash equilibria
can be computed in polynomial time. Our characterization gives interesting and
non-intuitive insights on the players' strategies at equilibrium: The defender
uniformly randomizes between a set of thresholds that includes very large
values. The strategy of the spy is a truncated version of the spammer's
distribution. We present numerical simulations that validate and illustrate our
theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0753</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0753</id><created>2012-07-03</created><authors><author><keyname>Liu</keyname><forenames>Jiaqi</forenames></author><author><keyname>Ren</keyname><forenames>Zhong</forenames></author><author><keyname>Li</keyname><forenames>Deng</forenames></author></authors><title>MPO: An Efficient and Low-cost Peer-to-Peer Overlay for Autonomic
  Communications</title><categories>cs.DC cs.NI</categories><comments>37 pages,9 figures,37 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The term Autonomic Communication (AC) refers to self-managing systems which
are capable of supporting self-configuration, self-healing and
self-optimization. However, information reflection and collection, lack of
centralized control, non-cooperation and so on are just some of the challenges
within AC systems. We have considered these problems in theory and practice and
reached the following conclusion; in order to build an ideal system for
autonomic communication, there are three key problems to be solved. Motivated
by the need for AC, we have designed an efficient and low-cost Peer-to-Peer
(P2P) overlay called Maya-Pyramid overlay (MPO) and combined merits of
unstructured P2P with those of structured P2P overlays. Differing from the
traditional hierarchical P2P (i.e. tree-like structure) overlay, (1) MPO is
composed of levels and layers, which uses small world characteristic to improve
efficiency, and the maintenance cost is decreased because update and backup
only take place in two neighboring levels or layers instead of recursively
perform in higher levels. (2) Unlike normal redundant mechanisms for solving
the single fault problem: Tri-Information Center (Tri-IC) mechanism is
presented in order to improve robustness by alleviating the load of cluster
heads in a hierarchical P2P overlay. (3) A source ranking mechanism is proposed
in order to discourage free riding and whitewashing and to encourage frequent
information exchanges between peers. (4) Inspired by Pastry's ID structure for
a structured DHT algorithm, a 3D unique ID structure is presented in the
unstructured P2P overlay. This will guarantee anonymity in routing, and will
be, not only more efficient because it applies the DHT-like routing algorithm
in the unstructured P2P overlay, but also more adaptive to suit AC. Evaluation
proved that MPO is robust, highly efficient and of a low-cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0757</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0757</id><created>2012-07-03</created><authors><author><keyname>de Almeida</keyname><forenames>Eliana S.</forenames></author><author><keyname>de Medeiros</keyname><forenames>Antonio Carlos</forenames></author><author><keyname>Rosso</keyname><forenames>Osvaldo A.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>Generalized Statistical Complexity of SAR Imagery</title><categories>cs.IT cs.GR math.IT stat.AP stat.ML</categories><comments>Article accepted for publication in the proceedings of the 17
  Iberoamerican Conference on Pattern Recognition (CIARP), to be published in
  the Lecture Notes in Computer Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new generalized Statistical Complexity Measure (SCM) was proposed by Rosso
et al in 2010. It is a functional that captures the notions of order/disorder
and of distance to an equilibrium distribution. The former is computed by a
measure of entropy, while the latter depends on the definition of a stochastic
divergence. When the scene is illuminated by coherent radiation, image data is
corrupted by speckle noise, as is the case of ultrasound-B, sonar, laser and
Synthetic Aperture Radar (SAR) sensors. In the amplitude and intensity formats,
this noise is multiplicative and non-Gaussian requiring, thus, specialized
techniques for image processing and understanding. One of the most successful
family of models for describing these images is the Multiplicative Model which
leads, among other probability distributions, to the G0 law. This distribution
has been validated in the literature as an expressive and tractable model,
deserving the &quot;universal&quot; denomination for its ability to describe most types
of targets. In order to compute the statistical complexity of a site in an
image corrupted by speckle noise, we assume that the equilibrium distribution
is that of fully developed speckle, namely the Gamma law in intensity format,
which appears in areas with little or no texture. We use the Shannon entropy
along with the Hellinger distance to measure the statistical complexity of
intensity SAR images, and we show that it is an expressive feature capable of
identifying many types of targets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0758</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0758</id><created>2012-07-03</created><updated>2012-07-11</updated><authors><author><keyname>Balachandran</keyname><forenames>Nitish</forenames></author></authors><title>Surveying Solutions to Securing On-Demand Routing Protocols in MANETs</title><categories>cs.NI</categories><comments>7 pages, 1 table, updated refernces</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Mobile ad hoc Network or MANET is a wireless network of mobile devices that
has the ability to self-configure and self-organise and is characterised by an
absence of centralised administration and network infrastructure. An
appreciable number of routing protocols used in a typical MANET have left the
critical aspect of security out of consideration by assuming that all of its
constituent nodes are trustworthy and non-malicious. In this paper, we discuss
some of the major threats that such networks are vulnerable to, because of
these inherently insecure protocols. The focus is specifically on the
source-initiated and on-demand routing protocols. Further, solutions and
modifications to these protocols that have been proposed over time, enabling
them to mitigate the aforementioned threats to some extent, are also analysed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0771</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0771</id><created>2012-07-03</created><authors><author><keyname>Torres</keyname><forenames>Leonardo</forenames></author><author><keyname>Medeiros</keyname><forenames>Antonio C.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>Polarimetric SAR Image Smoothing with Stochastic Distances</title><categories>cs.IT cs.CV cs.GR math.IT stat.AP stat.ML</categories><comments>Accepted for publication in the proceedings of the 17th Iberoamerican
  Conference on Pattern Recognition, to be published in the Lecture Notes in
  Computer Science series</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polarimetric Synthetic Aperture Radar (PolSAR) images are establishing as an
important source of information in remote sensing applications. The most
complete format this type of imaging produces consists of complex-valued
Hermitian matrices in every image coordinate and, as such, their visualization
is challenging. They also suffer from speckle noise which reduces the
signal-to-noise ratio. Smoothing techniques have been proposed in the
literature aiming at preserving different features and, analogously,
projections from the cone of Hermitian positive matrices to different color
representation spaces are used for enhancing certain characteristics. In this
work we propose the use of stochastic distances between models that describe
this type of data in a Nagao-Matsuyama-type of smoothing technique. The
resulting images are shown to present good visualization properties (noise
reduction with preservation of fine details) in all the considered
visualization spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0773</identifier>
 <datestamp>2013-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0773</id><created>2012-07-03</created><updated>2013-01-17</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Doerr</keyname><forenames>Carola</forenames></author><author><keyname>Sp&#xf6;hel</keyname><forenames>Reto</forenames></author><author><keyname>Thomas</keyname><forenames>Henning</forenames></author></authors><title>Playing Mastermind with Many Colors</title><categories>cs.DS cs.DM</categories><comments>Extended abstract appeared in SODA 2013. This full version has 22
  pages and 1 picture</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the general version of the classic guessing game Mastermind with
$n$ positions and $k$ colors. Since the case $k \le n^{1-\varepsilon}$,
$\varepsilon&gt;0$ a constant, is well understood, we concentrate on larger
numbers of colors. For the most prominent case $k = n$, our results imply that
Codebreaker can find the secret code with $O(n \log \log n)$ guesses. This
bound is valid also when only black answer-pegs are used. It improves the $O(n
\log n)$ bound first proven by Chv\'atal (Combinatorica 3 (1983), 325--329). We
also show that if both black and white answer-pegs are used, then the $O(n
\log\log n)$ bound holds for up to $n^2 \log\log n$ colors. These bounds are
almost tight as the known lower bound of $\Omega(n)$ shows. Unlike for $k \le
n^{1-\varepsilon}$, simply guessing at random until the secret code is
determined is not sufficient. In fact, we show that an optimal non-adaptive
strategy (deterministic or randomized) needs $\Theta(n \log n)$ guesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0780</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0780</id><created>2012-07-03</created><authors><author><keyname>Rao</keyname><forenames>B. Thirumala</forenames></author><author><keyname>Reddy</keyname><forenames>L. S. S.</forenames></author></authors><title>Survey on Improved Scheduling in Hadoop MapReduce in Cloud Environments</title><categories>cs.DC</categories><comments>5 Pages, 2 figures; International Journal of Computer Applications,
  November 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Cloud Computing is emerging as a new computational paradigm shift.
Hadoop-MapReduce has become a powerful Computation Model for processing large
data on distributed commodity hardware clusters such as Clouds. In all Hadoop
implementations, the default FIFO scheduler is available where jobs are
scheduled in FIFO order with support for other priority based schedulers also.
In this paper we study various scheduler improvements possible with Hadoop and
also provided some guidelines on how to improve the scheduling in Hadoop in
Cloud Environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0782</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0782</id><created>2012-07-03</created><updated>2012-10-07</updated><authors><author><keyname>Burshtein</keyname><forenames>David</forenames></author><author><keyname>Strugatski</keyname><forenames>Alona</forenames></author></authors><title>Polar write once memory codes</title><categories>cs.IT math.IT</categories><comments>submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coding scheme for write once memory (WOM) using polar codes is presented.
It is shown that the scheme achieves the capacity region of noiseless WOMs when
an arbitrary number of multiple writes is permitted. The encoding and decoding
complexities scale as O(N log N) where N is the blocklength. For N sufficiently
large, the error probability decreases sub-exponentially in N. The results can
be generalized from binary to generalized WOMs, described by an arbitrary
directed acyclic graph, using nonbinary polar codes. In the derivation we also
obtain results on the typical distortion of polar codes for lossy source
coding. Some simulation results with finite length codes are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0783</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0783</id><created>2012-07-03</created><authors><author><keyname>Giot</keyname><forenames>Romain</forenames><affiliation>GREYC</affiliation></author><author><keyname>Rosenberger</keyname><forenames>Christophe</forenames><affiliation>GREYC</affiliation></author><author><keyname>Dorizzi</keyname><forenames>Bernadette</forenames><affiliation>EPH, SAMOVAR</affiliation></author></authors><title>Hybrid Template Update System for Unimodal Biometric Systems</title><categories>cs.LG</categories><comments>IEEE International Conference on Biometrics: Theory, Applications and
  Systems (BTAS 2012), Washington, District of Columbia, USA : France (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-supervised template update systems allow to automatically take into
account the intra-class variability of the biometric data over time. Such
systems can be inefficient by including too many impostor's samples or skipping
too many genuine's samples. In the first case, the biometric reference drifts
from the real biometric data and attracts more often impostors. In the second
case, the biometric reference does not evolve quickly enough and also
progressively drifts from the real biometric data. We propose a hybrid system
using several biometric sub-references in order to increase per- formance of
self-update systems by reducing the previously cited errors. The proposition is
validated for a keystroke- dynamics authentication system (this modality
suffers of high variability over time) on two consequent datasets from the
state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0784</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0784</id><created>2012-07-03</created><authors><author><keyname>Giot</keyname><forenames>Romain</forenames><affiliation>GREYC</affiliation></author><author><keyname>El-Abed</keyname><forenames>Mohamad</forenames><affiliation>GREYC</affiliation></author><author><keyname>Rosenberger</keyname><forenames>Christophe</forenames><affiliation>GREYC</affiliation></author></authors><title>Web-Based Benchmark for Keystroke Dynamics Biometric Systems: A
  Statistical Analysis</title><categories>cs.LG</categories><comments>The Eighth International Conference on Intelligent Information Hiding
  and Multimedia Signal Processing (IIHMSP 2012), Piraeus : Greece (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most keystroke dynamics studies have been evaluated using a specific kind of
dataset in which users type an imposed login and password. Moreover, these
studies are optimistics since most of them use different acquisition protocols,
private datasets, controlled environment, etc. In order to enhance the accuracy
of keystroke dynamics' performance, the main contribution of this paper is
twofold. First, we provide a new kind of dataset in which users have typed both
an imposed and a chosen pairs of logins and passwords. In addition, the
keystroke dynamics samples are collected in a web-based uncontrolled
environment (OS, keyboards, browser, etc.). Such kind of dataset is important
since it provides us more realistic results of keystroke dynamics' performance
in comparison to the literature (controlled environment, etc.). Second, we
present a statistical analysis of well known assertions such as the
relationship between performance and password size, impact of fusion schemes on
system overall performance, and others such as the relationship between
performance and entropy. We put into obviousness in this paper some new results
on keystroke dynamics in realistic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0788</identifier>
 <datestamp>2013-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0788</id><created>2012-07-03</created><updated>2013-07-12</updated><authors><author><keyname>Fagiano</keyname><forenames>Lorenzo</forenames></author><author><keyname>Teel</keyname><forenames>Andrew R.</forenames></author></authors><title>On generalized terminal state constraints for model predictive control</title><categories>cs.SY math.OC</categories><comments>Part of the material in this manuscript is contained in a paper
  accepted for publication on Automatica and it is subject to Elsevier
  copyright. The copy of record is available on http://www.sciencedirect.com/</comments><doi>10.1016/j.automatica.2013.05.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript contains technical results related to a particular approach
for the design of Model Predictive Control (MPC) laws. The approach, named
&quot;generalized&quot; terminal state constraint, induces the recursive feasibility of
the underlying optimization problem and recursive satisfaction of state and
input constraints, and it can be used for both tracking MPC (i.e. when the
objective is to track a given steady state) and economic MPC (i.e. when the
objective is to minimize a cost function which does not necessarily attains its
minimum at a steady state). It is shown that the proposed technique provides,
in general, a larger feasibility set with respect to existing approaches, given
the same computational complexity. Moreover, a new receding horizon strategy is
introduced, exploiting the generalized terminal state constraint. Under mild
assumptions, the new strategy is guaranteed to converge in finite time, with
arbitrarily good accuracy, to an MPC law with an optimally-chosen terminal
state constraint, while still enjoying a larger feasibility set. The features
of the new technique are illustrated by three examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0790</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0790</id><created>2012-07-03</created><updated>2012-07-07</updated><authors><author><keyname>Bandara</keyname><forenames>H. M. N. Dilum</forenames></author><author><keyname>Jayasumana</keyname><forenames>Anura P.</forenames></author></authors><title>Collaborative Applications over Peer-to-Peer Systems - Challenges and
  Solutions</title><categories>cs.DC cs.CR cs.NI</categories><comments>Keywords - Collaborative applications, multi-attribute resources,
  peer-to-peer, resource discovery; H. M. N. D. Bandara and A. P. Jayasumana,
  &quot;Collaborative applications over peer-to-peer systems - Challenges and
  solutions,&quot; Peer-to-Peer Networking and Applications, Springer, 2012</comments><doi>10.1007/s12083-012-0157-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emerging collaborative Peer-to-Peer (P2P) systems require discovery and
utilization of diverse, multi-attribute, distributed, and dynamic groups of
resources to achieve greater tasks beyond conventional file and processor cycle
sharing. Collaborations involving application specific resources and dynamic
quality of service goals are stressing current P2P architectures. Salient
features and desirable characteristics of collaborative P2P systems are
highlighted. Resource advertising, selecting, matching, and binding, the
critical phases in these systems, and their associated challenges are reviewed
using examples from distributed collaborative adaptive sensing systems, cloud
computing, and mobile social networks. State-of-the-art resource
discovery/aggregation solutions are compared with respect to their
architecture, lookup overhead, load balancing, etc., to determine their ability
to meet the goals and challenges of each critical phase. Incentives, trust,
privacy, and security issues are also discussed, as they will ultimately
determine the success of a collaborative P2P system. Open issues and research
opportunities that are essential to achieve the true potential of collaborative
P2P systems are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0805</identifier>
 <datestamp>2013-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0805</id><created>2012-07-03</created><updated>2013-03-30</updated><authors><author><keyname>Lakshmi</keyname><forenames>G. Geethu</forenames></author></authors><title>Anatomical Structure Segmentation in Liver MRI Images</title><categories>cs.CV</categories><comments>Withdrawn by author for final modification</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Segmentation of medical images is a challenging task owing to their
complexity. A standard segmentation problem within Magnetic Resonance Imaging
(MRI) is the task of labeling voxels according to their tissue type. Image
segmentation provides volumetric quantification of liver area and thus helps in
the diagnosis of disorders, such as Hepatitis, Cirrhosis, Jaundice,
Hemochromatosis etc.This work deals with comparison of segmentation by applying
Level Set Method,Fuzzy Level Information C-Means Clustering Algorithm and
Gradient Vector Flow Snake Algorithm.The results are compared using the
parameters such as Number of pixels correctly classified, and percentage of
area segmented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0806</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0806</id><created>2012-07-03</created><updated>2012-07-21</updated><authors><author><keyname>Sivasankar</keyname><forenames>M.</forenames></author><author><keyname>Padmanabhan</keyname><forenames>T. R.</forenames></author></authors><title>Generation of Efficient Key Bit-Streams Using Sparse Matrix-Vector
  Multiplication</title><categories>cs.CR</categories><comments>another version is updated so this is withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The contribution of Stream ciphers to cryptography is immense. For fast
encryption, stream ciphers are preferred to block ciphers due to their XORing
operation, which is easier and faster to implement. In this paper we present a
matrix based stream cipher, in which a m x n binary matrix single handedly
performs the work of m parallel LFSRs. The resistivity of the proposed stream
cipher to various possible attacks are analyzed. Interestingly the output of
the matrix multiplication can otherwise be used as a parallel bit/byte
generator, useful for encrypting video streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0833</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0833</id><created>2012-07-03</created><authors><author><keyname>Blanchard</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Herbin</keyname><forenames>Michel</forenames></author></authors><title>Relational Data Mining Through Extraction of Representative Exemplars</title><categories>cs.AI cs.IR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the growing interest on Network Analysis, Relational Data Mining is
becoming an emphasized domain of Data Mining. This paper addresses the problem
of extracting representative elements from a relational dataset. After defining
the notion of degree of representativeness, computed using the Borda
aggregation procedure, we present the extraction of exemplars which are the
representative elements of the dataset. We use these concepts to build a
network on the dataset. We expose the main properties of these notions and we
propose two typical applications of our framework. The first application
consists in resuming and structuring a set of binary images and the second in
mining co-authoring relation in a research team.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0835</identifier>
 <datestamp>2012-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0835</id><created>2012-07-03</created><updated>2012-07-31</updated><authors><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Langer</keyname><forenames>Alexander</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Reidl</keyname><forenames>Felix</forenames></author><author><keyname>Rossmanith</keyname><forenames>Peter</forenames></author><author><keyname>Sau</keyname><forenames>Ignasi</forenames></author><author><keyname>Sikdar</keyname><forenames>Somnath</forenames></author></authors><title>Linear kernels and single-exponential algorithms via protrusion
  decompositions</title><categories>cs.DS cs.DM math.CO</categories><comments>We would like to point out that this article replaces and extends the
  results of [CoRR, abs/1201.2780, 2012]</comments><msc-class>05C85</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A \emph{$t$-treewidth-modulator} of a graph $G$ is a set $X \subseteq V(G)$
such that the treewidth of $G-X$ is at most some constant $t-1$. In this paper,
we present a novel algorithm to compute a decomposition scheme for graphs $G$
that come equipped with a $t$-treewidth-modulator. This decomposition, called a
\emph{protrusion decomposition}, is the cornerstone in obtaining the following
two main results.
  We first show that any parameterized graph problem (with parameter $k$) that
has \emph{finite integer index} and is \emph{treewidth-bounding} admits a
linear kernel on $H$-topological-minor-free graphs, where $H$ is some arbitrary
but fixed graph. A parameterized graph problem is called treewidth-bounding if
all positive instances have a $t$-treewidth-modulator of size $O(k)$, for some
constant $t$. This result partially extends previous meta-theorems on the
existence of linear kernels on graphs of bounded genus [Bodlaender et al., FOCS
2009] and $H$-minor-free graphs [Fomin et al., SODA 2010].
  Our second application concerns the Planar-$\mathcal{F}$-Deletion problem.
Let $\mathcal{F}$ be a fixed finite family of graphs containing at least one
planar graph. Given an $n$-vertex graph $G$ and a non-negative integer $k$,
Planar-$\mathcal{F}$-Deletion asks whether $G$ has a set $X\subseteq V(G)$ such
that $|X|\leq k$ and $G-X$ is $H$-minor-free for every $H\in \mathcal{F}$. Very
recently, an algorithm for Planar-$\mathcal{F}$-Deletion with running time
$2^{O(k)} n \log^2 n$ (such an algorithm is called \emph{single-exponential})
has been presented in [Fomin et al., FOCS 2012] under the condition that every
graph in $\mathcal{F}$ is connected. Using our algorithm to construct
protrusion decompositions as a building block, we get rid of this connectivity
constraint and present an algorithm for the general
Planar-$\mathcal{F}$-Deletion problem running in time $2^{O(k)} n^2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0840</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0840</id><created>2012-07-03</created><authors><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author><author><keyname>Mousset</keyname><forenames>Frank</forenames></author></authors><title>On Rainbow Cycles and Paths</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a properly edge colored graph, a subgraph using every color at most once
is called rainbow. In this thesis, we study rainbow cycles and paths in proper
edge colorings of complete graphs, and we prove that in every proper edge
coloring of K_n, there is a rainbow path on (3/4-o(1))n vertices, improving on
the previously best bound of (2n+1)/3 from Gyarfas and Mhalla. Similarly, a
k-rainbow path in a proper edge coloring of K_n is a path using no color more
than k times. We prove that in every proper edge coloring of K_n, there is a
k-rainbow path on (1-2/(k+1)!)n vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0847</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0847</id><created>2012-07-03</created><authors><author><keyname>Bahgat</keyname><forenames>A. T.</forenames></author><author><keyname>Salama</keyname><forenames>K. N.</forenames></author></authors><title>Memristor-based mono-stable oscillator</title><categories>cs.ET</categories><comments>This paper was submitted to Electronics Letters on the 28th of March
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, a reactance-less mono-stable oscillator is introduced for the
first time using memristors. By replacing bulky inductors and capacitors with
memristors, the novel mono-stable oscillator can be an area-efficient solution
for on-chip fully integrated systems. The proposed circuit is described,
mathematically analysed and verified by circuit simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0852</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0852</id><created>2012-07-03</created><authors><author><keyname>Lee</keyname><forenames>Ritchie</forenames></author><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Bono</keyname><forenames>James</forenames></author><author><keyname>Backhaus</keyname><forenames>Scott</forenames></author><author><keyname>Bent</keyname><forenames>Russell</forenames></author><author><keyname>Tracey</keyname><forenames>Brendan</forenames></author></authors><title>Counter-Factual Reinforcement Learning: How to Model Decision-Makers
  That Anticipate The Future</title><categories>cs.MA cs.GT</categories><comments>Decision Making with Multiple Imperfect Decision Makers; Springer. 29
  Pages, 6 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel framework for modeling interacting humans in a
multi-stage game. This &quot;iterated semi network-form game&quot; framework has the
following desirable characteristics: (1) Bounded rational players, (2)
strategic players (i.e., players account for one another's reward functions
when predicting one another's behavior), and (3) computational tractability
even on real-world systems. We achieve these benefits by combining concepts
from game theory and reinforcement learning. To be precise, we extend the
bounded rational &quot;level-K reasoning&quot; model to apply to games over multiple
stages. Our extension allows the decomposition of the overall modeling problem
into a series of smaller ones, each of which can be solved by standard
reinforcement learning algorithms. We call this hybrid approach &quot;level-K
reinforcement learning&quot;. We investigate these ideas in a cyber battle scenario
over a smart power grid and discuss the relationship between the behavior
predicted by our model and what one might expect of real human defenders and
attackers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0854</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0854</id><created>2012-07-03</created><authors><author><keyname>Jiekak</keyname><forenames>Steve</forenames></author><author><keyname>Scouarnec</keyname><forenames>Nicolas Le</forenames></author></authors><title>CROSS-MBCR: Exact Minimum Bandwith Coordinated Regenerating Codes</title><categories>cs.IT math.IT</categories><comments>ISIT 2012 - Recent Results Poster Session</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the exact and optimal repair of multiple failures in codes for
distributed storage. More particularly, we provide an explicit construction of
exact minimum bandwidth coordinated regenerating codes (MBCR) for n=d+t,k,d &gt;=
k,t &gt;= 1. Our construction differs from existing constructions by allowing both
t&gt;1 (i.e., repair of multiple failures) and d&gt;k (i.e., contacting more than k
devices during repair).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0855</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0855</id><created>2012-07-03</created><authors><author><keyname>Kuhn</keyname><forenames>Adrian</forenames></author><author><keyname>Murphy</keyname><forenames>Gail C.</forenames></author><author><keyname>Thompson</keyname><forenames>C. Albert</forenames></author></authors><title>An Exploratory Study of Forces and Frictions affecting Large-Scale
  Model-Driven Development</title><categories>cs.SE</categories><comments>To appear in proceedings of MODELS 2012, LNCS Springer</comments><doi>10.1007/978-3-642-33666-9_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate model-driven engineering, reporting on an
exploratory case-study conducted at a large automotive company. The study
consisted of interviews with 20 engineers and managers working in different
roles. We found that, in the context of a large organization, contextual forces
dominate the cognitive issues of using model-driven technology. The four forces
we identified that are likely independent of the particular abstractions chosen
as the basis of software development are the need for diffing in software
product lines, the needs for problem-specific languages and types, the need for
live modeling in exploratory activities, and the need for point-to-point
traceability between artifacts. We also identified triggers of accidental
complexity, which we refer to as points of friction introduced by languages and
tools. Examples of the friction points identified are insufficient support for
model diffing, point-to-point traceability, and model changes at runtime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0865</identifier>
 <datestamp>2013-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0865</id><created>2012-07-03</created><updated>2013-10-29</updated><authors><author><keyname>Bickel</keyname><forenames>Peter</forenames></author><author><keyname>Choi</keyname><forenames>David</forenames></author><author><keyname>Chang</keyname><forenames>Xiangyu</forenames></author><author><keyname>Zhang</keyname><forenames>Hai</forenames></author></authors><title>Asymptotic normality of maximum likelihood and its variational
  approximation for stochastic blockmodels</title><categories>math.ST cs.SI stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/13-AOS1124 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS1124</report-no><journal-ref>Annals of Statistics 2013, Vol. 41, No. 4, 1922-1943</journal-ref><doi>10.1214/13-AOS1124</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variational methods for parameter estimation are an active research area,
potentially offering computationally tractable heuristics with theoretical
performance bounds. We build on recent work that applies such methods to
network data, and establish asymptotic normality rates for parameter estimates
of stochastic blockmodel data, by either maximum likelihood or variational
estimation. The result also applies to various sub-models of the stochastic
blockmodel found in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0867</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0867</id><created>2012-07-03</created><authors><author><keyname>Ehlers</keyname><forenames>R&#xfc;diger</forenames><affiliation>Saarland University</affiliation></author><author><keyname>Moldovan</keyname><forenames>Daniela</forenames><affiliation>Saarland University</affiliation></author></authors><title>Sparse Positional Strategies for Safety Games</title><categories>cs.LO cs.FL</categories><comments>In Proceedings SYNT 2012, arXiv:1207.0554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 84, 2012, pp. 1-16</journal-ref><doi>10.4204/EPTCS.84.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of obtaining sparse positional strategies for safety
games. Such games are a commonly used model in many formal methods, as they
make the interaction of a system with its environment explicit. Often, a
winning strategy for one of the players is used as a certificate or as an
artefact for further processing in the application. Small such certificates,
i.e., strategies that can be written down very compactly, are typically
preferred. For safety games, we only need to consider positional strategies.
These map game positions of a player onto a move that is to be taken by the
player whenever the play enters that position. For representing positional
strategies compactly, a common goal is to minimize the number of positions for
which a winning player's move needs to be defined such that the game is still
won by the same player, without visiting a position with an undefined next
move. We call winning strategies in which the next move is defined for few of
the player's positions sparse.
  Unfortunately, even roughly approximating the density of the sparsest
strategy for a safety game has been shown to be NP-hard. Thus, to obtain sparse
strategies in practice, one either has to apply some heuristics, or use some
exhaustive search technique, like ILP (integer linear programming) solving. In
this paper, we perform a comparative study of currently available methods to
obtain sparse winning strategies for the safety player in safety games. We
consider techniques from common knowledge, such as using ILP or SAT
(satisfiability) solving, and a novel technique based on iterative linear
programming. The results of this paper tell us if current techniques are
already scalable enough for practical use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0868</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0868</id><created>2012-07-03</created><authors><author><keyname>Samanta</keyname><forenames>Roopsha</forenames><affiliation>UT, Austin</affiliation></author></authors><title>Towards Algorithmic Synthesis of Synchronization for Shared-Memory
  Concurrent Programs</title><categories>cs.LO cs.PL</categories><comments>In Proceedings SYNT 2012, arXiv:1207.0554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 84, 2012, pp. 17-32</journal-ref><doi>10.4204/EPTCS.84.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework that takes a concurrent program composed of
unsynchronized processes, along with a temporal specification of their global
concurrent behaviour, and automatically generates a concurrent program with
synchronization ensuring correct global behaviour. Our methodology supports
finite-state concurrent programs composed of processes that may have local and
shared variables, may be straight-line or branching programs, may be ongoing or
terminating, and may have program-initialized or user-initialized variables.
The specification language is an extension of propositional Computation Tree
Logic (CTL) that enables easy specification of safety and liveness properties
over control and data variables. The framework also supports synthesis of
synchronization at different levels of abstraction and granularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0869</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0869</id><created>2012-07-03</created><authors><author><keyname>Nedunuri</keyname><forenames>Srinivas</forenames><affiliation>The University of Texas at Austin</affiliation></author><author><keyname>Cook</keyname><forenames>William R.</forenames><affiliation>The University of Texas at Austin</affiliation></author><author><keyname>Smith</keyname><forenames>Douglas R.</forenames><affiliation>Kestrel Institute</affiliation></author></authors><title>Theory and Techniques for Synthesizing a Family of Graph Algorithms</title><categories>cs.SE cs.AI cs.DS cs.PL</categories><comments>In Proceedings SYNT 2012, arXiv:1207.0554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 84, 2012, pp. 33-46</journal-ref><doi>10.4204/EPTCS.84.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although Breadth-First Search (BFS) has several advantages over Depth-First
Search (DFS) its prohibitive space requirements have meant that algorithm
designers often pass it over in favor of DFS. To address this shortcoming, we
introduce a theory of Efficient BFS (EBFS) along with a simple recursive
program schema for carrying out the search. The theory is based on dominance
relations, a long standing technique from the field of search algorithms. We
show how the theory can be used to systematically derive solutions to two graph
algorithms, namely the Single Source Shortest Path problem and the Minimum
Spanning Tree problem. The solutions are found by making small systematic
changes to the derivation, revealing the connections between the two problems
which are often obscured in textbook presentations of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0870</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0870</id><created>2012-07-03</created><authors><author><keyname>Cormie-Bowins</keyname><forenames>Elise</forenames></author><author><keyname>van Breugel</keyname><forenames>Franck</forenames></author></authors><title>Measuring Progress of Probabilistic LTL Model Checking</title><categories>cs.LO cs.SE</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><acm-class>D.2.4</acm-class><journal-ref>EPTCS 85, 2012, pp. 33-47</journal-ref><doi>10.4204/EPTCS.85.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Zhang and Van Breugel introduced the notion of a progress measure
for a probabilistic model checker. Given a linear-time property P and a
description of the part of the system that has already been checked, the
progress measure returns a real number in the unit interval. The real number
captures how much progress the model checker has made towards verifying P. If
the progress is zero, no progress has been made. If it is one, the model
checker is done. They showed that the progress measure provides a lower bound
for the measure of the set of execution paths that satisfy P. They also
presented an algorithm to compute the progress measure when P is an invariant.
  In this paper, we present an algorithm to compute the progress measure when P
is a formula of a positive fragment of linear temporal logic. In this fragment,
we can express invariants but also many other interesting properties. The
algorithm is exponential in the size of P and polynomial in the size of that
part of the system that has already been checked. We also present an algorithm
to compute a lower bound for the progress measure in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0871</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0871</id><created>2012-07-03</created><authors><author><keyname>Yasuoka</keyname><forenames>Hirotoshi</forenames><affiliation>Tohoku University</affiliation></author><author><keyname>Terauchi</keyname><forenames>Tachio</forenames><affiliation>Nagoya University</affiliation></author></authors><title>Quantitative Information Flow as Safety and Liveness Hyperproperties</title><categories>cs.CR cs.LO</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 85, 2012, pp. 77-91</journal-ref><doi>10.4204/EPTCS.85.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We employ Clarkson and Schneider's &quot;hyperproperties&quot; to classify various
verification problems of quantitative information flow. The results of this
paper unify and extend the previous results on the hardness of checking and
inferring quantitative information flow. In particular, we identify a subclass
of liveness hyperproperties, which we call &quot;k-observable hyperproperties&quot;, that
can be checked relative to a reachability oracle via self composition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0872</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0872</id><created>2012-07-03</created><authors><author><keyname>Palamidessi</keyname><forenames>Catuscia</forenames><affiliation>INRIA and LIX, Ecole Polytechnique, France</affiliation></author><author><keyname>Stronati</keyname><forenames>Marco</forenames><affiliation>Universit&#xe0; di Pisa, Italy</affiliation></author></authors><title>Differential Privacy for Relational Algebra: Improving the Sensitivity
  Bounds via Constraint Systems</title><categories>cs.CR cs.DB</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><acm-class>H.2.3;K.6.5</acm-class><journal-ref>EPTCS 85, 2012, pp. 92-105</journal-ref><doi>10.4204/EPTCS.85.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy is a modern approach in privacy-preserving data analysis
to control the amount of information that can be inferred about an individual
by querying a database. The most common techniques are based on the
introduction of probabilistic noise, often defined as a Laplacian parametric on
the sensitivity of the query. In order to maximize the utility of the query, it
is crucial to estimate the sensitivity as precisely as possible.
  In this paper we consider relational algebra, the classical language for
queries in relational databases, and we propose a method for computing a bound
on the sensitivity of queries in an intuitive and compositional way. We use
constraint-based techniques to accumulate the information on the possible
values for attributes provided by the various components of the query, thus
making it possible to compute tight bounds on the sensitivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0873</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0873</id><created>2012-07-03</created><authors><author><keyname>Bortolussi</keyname><forenames>Luca</forenames><affiliation>University of Trieste</affiliation></author><author><keyname>Galpin</keyname><forenames>Vashti</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Hillston</keyname><forenames>Jane</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>Hybrid performance modelling of opportunistic networks</title><categories>cs.SY cs.LO cs.NI cs.PF</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 85, 2012, pp. 106-121</journal-ref><doi>10.4204/EPTCS.85.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate the modelling of opportunistic networks using the process
algebra stochastic HYPE. Network traffic is modelled as continuous flows,
contact between nodes in the network is modelled stochastically, and
instantaneous decisions are modelled as discrete events. Our model describes a
network of stationary video sensors with a mobile ferry which collects data
from the sensors and delivers it to the base station. We consider different
mobility models and different buffer sizes for the ferries. This case study
illustrates the flexibility and expressive power of stochastic HYPE. We also
discuss the software that enables us to describe stochastic HYPE models and
simulate them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0874</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0874</id><created>2012-07-03</created><authors><author><keyname>Bernardo</keyname><forenames>Marco</forenames><affiliation>University of Urbino</affiliation></author></authors><title>Weak Markovian Bisimulation Congruences and Exact CTMC-Level
  Aggregations for Concurrent Processes</title><categories>cs.LO</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 85, 2012, pp. 122-136</journal-ref><doi>10.4204/EPTCS.85.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have recently defined a weak Markovian bisimulation equivalence in an
integrated-time setting, which reduces sequences of exponentially timed
internal actions to individual exponentially timed internal actions having the
same average duration and execution probability as the corresponding sequences.
This weak Markovian bisimulation equivalence is a congruence for sequential
processes with abstraction and turns out to induce an exact CTMC-level
aggregation at steady state for all the considered processes. However, it is
not a congruence with respect to parallel composition. In this paper, we show
how to generalize the equivalence in a way that a reasonable tradeoff among
abstraction, compositionality, and exactness is achieved for concurrent
processes. We will see that, by enhancing the abstraction capability in the
presence of concurrent computations, it is possible to retrieve the congruence
property with respect to parallel composition, with the resulting CTMC-level
aggregation being exact at steady state only for a certain subset of the
considered processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0877</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0877</id><created>2012-07-03</created><updated>2012-07-11</updated><authors><author><keyname>Wang</keyname><forenames>Xiumin</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Song</keyname><forenames>Wentu</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Yuen</keyname><forenames>Chau</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname><forenames>Jing</forenames><affiliation>Tiffany</affiliation></author></authors><title>Exchanging Third-Party Information with Minimum Transmission Cost</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages, Globecom'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of minimizing the total transmission
cost for exchanging channel state information. We proposed a network coded
cooperative data exchange scheme, such that the total transmission cost is
minimized while each client can decode all the channel information held by all
other clients. In this paper, we first derive a necessary and sufficient
condition for a feasible transmission. Based on the derived condition, there
exists a feasible code design to guarantee that each client can decode the
complete information. We further formulate the problem of minimizing the total
transmission cost as an integer linear programming. Finally, we discuss the
probability that each client can decode the complete information with
distributed random linear network coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0879</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0879</id><created>2012-07-03</created><authors><author><keyname>Wang</keyname><forenames>Anyu</forenames></author><author><keyname>Zhang</keyname><forenames>Zhifang</forenames></author></authors><title>Exact Cooperative Regenerating Codes with Minimum-Repair-Bandwidth for
  Distributed Storage</title><categories>cs.IT math.IT</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an explicit construction of exact cooperative regenerating codes at
the MBCR (minimum bandwidth cooperative regeneration) point. Before the paper,
the only known explicit MBCR code is given with parameters $n=d+r$ and $d=k$,
while our construction applies to all possible values of $n,k,d,r$. The code
has a brief expression in the polynomial form and the data reconstruction is
accomplished by bivariate polynomial interpolation. It is a scalar code and
operates over a finite field of size $q\geq n$. Besides, we establish several
subspace properties for linear exact MBCR codes. Based on these properties we
prove that linear exact MBCR codes cannot achieve repair-by-transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0892</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0892</id><created>2012-07-03</created><authors><author><keyname>Chan</keyname><forenames>T-H. Hubert</forenames></author><author><keyname>Li</keyname><forenames>Mingfei</forenames></author><author><keyname>Ning</keyname><forenames>Li</forenames></author></authors><title>Incubators vs Zombies: Fault-Tolerant, Short, Thin and Lanky Spanners
  for Doubling Metrics</title><categories>cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently Elkin and Solomon gave a construction of spanners for doubling
metrics that has constant maximum degree, hop-diameter O(log n) and lightness
O(log n) (i.e., weight O(log n)w(MST). This resolves a long standing conjecture
proposed by Arya et al. in a seminal STOC 1995 paper.
  However, Elkin and Solomon's spanner construction is extremely complicated;
we offer a simple alternative construction that is very intuitive and is based
on the standard technique of net tree with cross edges. Indeed, our approach
can be readily applied to our previous construction of k-fault tolerant
spanners (ICALP 2012) to achieve k-fault tolerance, maximum degree O(k^2),
hop-diameter O(log n) and lightness O(k^3 log n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0893</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0893</id><created>2012-07-04</created><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Neeman</keyname><forenames>Joe</forenames></author><author><keyname>Tamuz</keyname><forenames>Omer</forenames></author></authors><title>Majority Dynamics and Aggregation of Information in Social Networks</title><categories>math.ST cs.SI physics.soc-ph stat.TH</categories><comments>22 pages</comments><journal-ref>Autonomous Agents and Multi-Agent Systems (2014) 28:408-429</journal-ref><doi>10.1007/s10458-013-9230-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider n individuals who, by popular vote, choose among q &gt;= 2
alternatives, one of which is &quot;better&quot; than the others. Assume that each
individual votes independently at random, and that the probability of voting
for the better alternative is larger than the probability of voting for any
other. It follows from the law of large numbers that a plurality vote among the
n individuals would result in the correct outcome, with probability approaching
one exponentially quickly as n tends to infinity. Our interest in this paper is
in a variant of the process above where, after forming their initial opinions,
the voters update their decisions based on some interaction with their
neighbors in a social network. Our main example is &quot;majority dynamics&quot;, in
which each voter adopts the most popular opinion among its friends. The
interaction repeats for some number of rounds and is then followed by a
population-wide plurality vote.
  The question we tackle is that of &quot;efficient aggregation of information&quot;: in
which cases is the better alternative chosen with probability approaching one
as n tends to infinity? Conversely, for which sequences of growing graphs does
aggregation fail, so that the wrong alternative gets chosen with probability
bounded away from zero? We construct a family of examples in which interaction
prevents efficient aggregation of information, and give a condition on the
social network which ensures that aggregation occurs. For the case of majority
dynamics we also investigate the question of unanimity in the limit. In
particular, if the voters' social network is an expander graph, we show that if
the initial population is sufficiently biased towards a particular alternative
then that alternative will eventually become the unanimous preference of the
entire population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0894</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0894</id><created>2012-07-04</created><authors><author><keyname>Rao</keyname><forenames>B. Thirumala</forenames></author><author><keyname>Sridevi</keyname><forenames>N. V.</forenames></author><author><keyname>Reddy</keyname><forenames>V. Krishna</forenames></author><author><keyname>Reddy</keyname><forenames>L. S. S.</forenames></author></authors><title>Performance Issues of Heterogeneous Hadoop Clusters in Cloud Computing</title><categories>cs.DC</categories><comments>6 Pages</comments><journal-ref>Global Journal of Computer Science and Technology, Volume XI Issue
  VIII May 2011</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Nowadays most of the cloud applications process large amount of data to
provide the desired results. Data volumes to be processed by cloud applications
are growing much faster than computing power. This growth demands new
strategies for processing and analyzing information. Dealing with large data
volumes requires two things: 1) Inexpensive, reliable storage 2) New tools for
analyzing unstructured and structured data. Hadoop is a powerful open source
software platform that addresses both of these problems. The current Hadoop
implementation assumes that computing nodes in a cluster are homogeneous in
nature. Hadoop lacks performance in heterogeneous clusters where the nodes have
different computing capacity. In this paper we address the issues that affect
the performance of hadoop in heterogeneous clusters and also provided some
guidelines on how to overcome these bottlenecks
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0904</identifier>
 <datestamp>2013-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0904</id><created>2012-07-04</created><updated>2012-10-03</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author><author><keyname>Spreer</keyname><forenames>Jonathan</forenames></author></authors><title>The complexity of detecting taut angle structures on triangulations</title><categories>math.GT cs.CG math.CO</categories><comments>22 pages, 10 figures, 3 tables; v2: minor updates. To appear in SODA
  2013: Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete
  Algorithms</comments><journal-ref>SODA '13: Proceedings of the Twenty-Fourth Annual ACM-SIAM
  Symposium on Discrete Algorithms, SIAM, 2013, pp. 168-183</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many fundamental algorithmic problems on triangulated 3-manifolds
whose complexities are unknown. Here we study the problem of finding a taut
angle structure on a 3-manifold triangulation, whose existence has implications
for both the geometry and combinatorics of the triangulation. We prove that
detecting taut angle structures is NP-complete, but also fixed-parameter
tractable in the treewidth of the face pairing graph of the triangulation.
These results have deeper implications: the core techniques can serve as a
launching point for approaching decision problems such as unknot recognition
and prime decomposition of 3-manifolds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0911</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0911</id><created>2012-07-04</created><authors><author><keyname>Colla</keyname><forenames>Valentina</forenames></author><author><keyname>Matarese</keyname><forenames>Nicola</forenames></author><author><keyname>Nastasi</keyname><forenames>Gianluca</forenames></author></authors><title>Prediction of under pickling defects on steel strip surface</title><categories>cs.OH</categories><comments>9 Page</comments><journal-ref>International Journal of Soft Computing and Software Engineering
  [JSCSE], Vol. 1, No. 1, pp. 1-9, 2011</journal-ref><doi>10.7321/jscse.v1.n1.2</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  An extremely important part of the finishing line is the pickling process, in
which oxides formed during the hot rolling stage are removed from the surface
of the steel sheets. The efficiency of the pickling process is mainly dependent
on the nature of the oxide present at the surface of the steel, but, also, on
process parameters such as bath composition and time duration are relevant.
When acid concentration, solution temperatures and line speed are not properly
balanced, in fact, sheet defects like under pickling or over pickling may
happen and their occurrence does have a very serious effect on cold-reduction
performance and surface appearance of the finished product. Furthermore,
product damage from handling or improper equipment adjustment can render the
steel unsuitable for further processing. This is the reason why it is important
that process significant parameters are controlled and maintained as accurately
as possible in order to avoid these undesired phenomena. In the present work, a
control algorithm, composed by two different modules, i.e. decision tree and
rectangular Basis Function Network, has been implemented to aim of predicting
pickling defects and suggesting the optimal speed or the admissible speed range
of the steel strip in the process line. In this way the most suitable line
speed value can be set in an automatic way or by the technical personnel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0913</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0913</id><created>2012-07-04</created><authors><author><keyname>Li</keyname><forenames>Rong-Hua</forenames></author><author><keyname>Yu</keyname><forenames>Jeffrey Xu</forenames></author><author><keyname>Shang</keyname><forenames>Zechao</forenames></author></authors><title>Estimating Node Influenceability in Social Networks</title><categories>cs.SI cs.DB physics.soc-ph</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Influence analysis is a fundamental problem in social network analysis and
mining. The important applications of the influence analysis in social network
include influence maximization for viral marketing, finding the most
influential nodes, online advertising, etc. For many of these applications, it
is crucial to evaluate the influenceability of a node. In this paper, we study
the problem of evaluating influenceability of nodes in social network based on
the widely used influence spread model, namely, the independent cascade model.
Since this problem is #P-complete, most existing work is based on Naive
Monte-Carlo (\nmc) sampling. However, the \nmc estimator typically results in a
large variance, which significantly reduces its effectiveness. To overcome this
problem, we propose two families of new estimators based on the idea of
stratified sampling. We first present two basic stratified sampling (\bss)
estimators, namely \bssi estimator and \bssii estimator, which partition the
entire population into $2^r$ and $r+1$ strata by choosing $r$ edges
respectively. Second, to further reduce the variance, we find that both \bssi
and \bssii estimators can be recursively performed on each stratum, thus we
propose two recursive stratified sampling (\rss) estimators, namely \rssi
estimator and \rssii estimator. Theoretically, all of our estimators are shown
to be unbiased and their variances are significantly smaller than the variance
of the \nmc estimator. Finally, our extensive experimental results on both
synthetic and real datasets demonstrate the efficiency and accuracy of our new
estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0917</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0917</id><created>2012-07-04</created><authors><author><keyname>Lubacz</keyname><forenames>Jozef</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Principles and Overview of Network Steganography</title><categories>cs.CR</categories><comments>7 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents basic principles of network steganography, which is a
comparatively new research subject in the area of information hiding, followed
by a concise overview and classification of network steganographic methods and
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0922</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0922</id><created>2012-07-04</created><authors><author><keyname>Wang</keyname><forenames>Zheng</forenames></author><author><keyname>Pu</keyname><forenames>Geguang</forenames></author><author><keyname>Qin</keyname><forenames>Shenchao</forenames></author><author><keyname>Li</keyname><forenames>Jianwen</forenames></author><author><keyname>Larsen</keyname><forenames>Kim G.</forenames></author><author><keyname>Madsen</keyname><forenames>Jan</forenames></author><author><keyname>Gu</keyname><forenames>Bin</forenames></author><author><keyname>He</keyname><forenames>Jifeng</forenames></author></authors><title>MDM: A Mode Diagram Modeling Framework for Periodic Control Systems</title><categories>cs.SY cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Periodic control systems used in spacecrafts and automotives are usually
period-driven and can be decomposed into different modes with each mode
representing a system state observed from outside. Such systems may also
involve intensive computing in their modes. Despite the fact that such control
systems are widely used in the above-mentioned safety-critical embedded
domains, there is lack of domain-specific formal modelling languages for such
systems in the relevant industry. To address this problem, we propose a formal
visual modeling framework called MDM as a concise and precise way to specify
and analyze such systems. To capture the temporal properties of periodic
control systems, we provide, along with MDM, a property specification language
based on interval logic for the description of concrete temporal requirements
the engineers are concerned with. The statistical model checking technique can
then be used to verify the MDM models against desired properties. To
demonstrate the viability of our approach, we have applied our modelling
framework to some real life case studies from industry and helped detect two
design defects for some spacecraft control systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0931</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0931</id><created>2012-07-04</created><authors><author><keyname>Shu</keyname><forenames>Panpan</forenames></author><author><keyname>Tang</keyname><forenames>Ming</forenames></author><author><keyname>Gong</keyname><forenames>Kai</forenames></author><author><keyname>Liu</keyname><forenames>Ying</forenames></author></authors><title>Effects of Weak Ties on Epidemic Predictability in Community Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>8 pages, 6 figures</comments><msc-class>65Zxx, 82Dxx</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weak ties play a significant role in the structures and the dynamics of
community networks. Based on the susceptible-infected model in contact process,
we study numerically how weak ties influence the predictability of epidemic
dynamics. We first investigate the effects of different kinds of weak ties on
the variabilities of both the arrival time and the prevalence of disease, and
find that the bridgeness with small degree can enhance the predictability of
epidemic spreading. Once weak ties are settled, compared with the variability
of arrival time, the variability of prevalence displays a diametrically opposed
changing trend with both the distance of the initial seed to the bridgeness and
the degree of the initial seed. More specifically, the further distance and the
larger degree of the initial seed can induce the better predictability of
arrival time and the worse predictability of prevalence. Moreover, we discuss
the effects of weak tie number on the epidemic variability. As community
strength becomes very strong, which is caused by the decrease of weak tie
number, the epidemic variability will change dramatically. Compared with the
case of hub seed and random seed, the bridgenss seed can result in the worst
predictability of arrival time and the best predictability of prevalence. These
results show that the variability of arrival time always marks a complete
reversal trend of that of prevalence, which implies it is impossible to predict
epidemic spreading in the early stage of outbreaks accurately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0932</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0932</id><created>2012-07-04</created><updated>2012-07-09</updated><authors><author><keyname>Kloks</keyname><forenames>Ton</forenames></author><author><keyname>Wang</keyname><forenames>Yue-Li</forenames></author></authors><title>Folding graphs</title><categories>cs.DM</categories><comments>This paper has been withdrawn. At the moment we are uncertain of the
  fixed-parameter tractability of max-fold coloring</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be a graph. Consider two nonadjacent vertices x and y that have a
common neighbor. Folding G with respect to x and y is the operation which
identifies x and y. After a maximal series of foldings the graph is a disjoint
union of cliques. The minimal clique number that can appear after a maximal
series of foldings is equal to the chromatic number of G. In this paper we
consider the problem to determine the maximal clique number which can appear
after a maximal series of foldings. We denote this number as Sigma(G) and we
call it the max-folding number. We show that the problem is NP-complete, even
when restricted to classes such as trivially perfect graphs, cobipartite graphs
and planar graphs. We show that the max-folding number of trees is two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0933</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0933</id><created>2012-07-04</created><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Lingas</keyname><forenames>Andrzej</forenames></author><author><keyname>Sledneu</keyname><forenames>Dzmitry</forenames></author></authors><title>Optimal Cuts and Bisections on the Real Line in Polynomial Time</title><categories>cs.DS cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exact complexity of geometric cuts and bisections is the longstanding
open problem including even the dimension one. In this paper, we resolve this
problem for dimension one (the real line) by designing an exact polynomial time
algorithm. Our results depend on a new technique of dealing with metric
equalities and their connection to dynamic programming. The method of our
solution could be also of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0935</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0935</id><created>2012-07-04</created><authors><author><keyname>Fotakis</keyname><forenames>Dimitris</forenames></author><author><keyname>Tzamos</keyname><forenames>Christos</forenames></author></authors><title>On the Power of Deterministic Mechanisms for Facility Location Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider K-Facility Location games, where n strategic agents report their
locations in a metric space, and a mechanism maps them to K facilities. Our
main result is an elegant characterization of deterministic strategyproof
mechanisms with a bounded approximation ratio for 2-Facility Location on the
line. In particular, we show that for instances with n \geq 5 agents, any such
mechanism either admits a unique dictator, or always places the facilities at
the leftmost and the rightmost location of the instance. As a corollary, we
obtain that the best approximation ratio achievable by deterministic
strategyproof mechanisms for the problem of locating 2 facilities on the line
to minimize the total connection cost is precisely n-2. Another rather
surprising consequence is that the Two-Extremes mechanism of (Procaccia and
Tennenholtz, EC 2009) is the only deterministic anonymous strategyproof
mechanism with a bounded approximation ratio for 2-Facility Location on the
line.
  The proof of the characterization employs several new ideas and technical
tools, which provide new insights into the behavior of deterministic
strategyproof mechanisms for K-Facility Location games, and may be of
independent interest. Employing one of these tools, we show that for every K
\geq 3, there do not exist any deterministic anonymous strategyproof mechanisms
with a bounded approximation ratio for K-Facility Location on the line, even
for simple instances with K+1 agents. Moreover, building on the
characterization for the line, we show that there do not exist any
deterministic strategyproof mechanisms with a bounded approximation ratio for
2-Facility Location on more general metric spaces, which is true even for
simple instances with 3 agents located in a star.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0938</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0938</id><created>2012-07-04</created><authors><author><keyname>Yang</keyname><forenames>Ang</forenames></author><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Yang</keyname><forenames>Nan</forenames></author><author><keyname>Xing</keyname><forenames>Chengwen</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Symbol Error Rate of Space-Time Network Coding in Nakagami-m Fading</title><categories>cs.IT math.IT</categories><comments>23 pages, 9 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we analyze the symbol error rate (SER) of space-time network
coding (STNC) in a distributed cooperative network over independent but not
necessarily identically distributed (i.n.i.d.) Nakagami-$m$ fading channels. In
this network, multiple sources communicate with a single destination with the
assistance of multiple decode-and-forward (DF) relays. We first derive new
exact closed-form expressions for the SER with $M$-ary phase shift-keying
modulation ($M$-PSK) and $M$-ary quadrature amplitude modulation ($M$-QAM). We
then derive new compact expressions for the asymptotic SER to offer valuable
insights into the network behavior in the high signal-to-noise ratio (SNR)
regime. Importantly, we demonstrate that STNC guarantees full diversity order,
which is determined by the Nakagami-$m$ fading parameters of all the channels
but independent of the number of sources. Based on the new expressions, we
examine the impact of the number of relays, relay location, Nakagami-$m$ fading
parameters, power allocation, and nonorthogonal codes on the SER.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0953</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0953</id><created>2012-07-04</created><updated>2012-07-06</updated><authors><author><keyname>Brandst&#xe4;dt</keyname><forenames>Andreas</forenames></author><author><keyname>Leitert</keyname><forenames>Arne</forenames></author><author><keyname>Rautenbach</keyname><forenames>Dieter</forenames></author></authors><title>Efficient Dominating and Edge Dominating Sets for Graphs and Hypergraphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E) be a graph. A vertex dominates itself and all its neighbors,
i.e., every vertex v in V dominates its closed neighborhood N[v]. A vertex set
D in G is an efficient dominating (e.d.) set for G if for every vertex v in V,
there is exactly one d in D dominating v. An edge set M is an efficient edge
dominating (e.e.d.) set for G if it is an efficient dominating set in the line
graph L(G) of G. The ED problem (EED problem, respectively) asks for the
existence of an e.d. set (e.e.d. set, respectively) in the given graph.
  We give a unified framework for investigating the complexity of these
problems on various classes of graphs. In particular, we solve some open
problems and give linear time algorithms for ED and EED on dually chordal
graphs.
  We extend the two problems to hypergraphs and show that ED remains
NP-complete on alpha-acyclic hypergraphs, and is solvable in polynomial time on
hypertrees, while EED is polynomial on alpha-acyclic hypergraphs and
NP-complete on hypertrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0967</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0967</id><created>2012-07-04</created><authors><author><keyname>Samara</keyname><forenames>Ghassan</forenames></author></authors><title>A New Security Mechanism for Vehicular Communication Networks</title><categories>cs.CR</categories><comments>5 Pages</comments><journal-ref>International Conference on Cyber Security, CyberWarfare and
  Digital Forensic (CyberSec2012), Kuala Lumpur, Malaysia. P. 18 - 22</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular communication networks is a promising and emerging technology to
facilitat road safety, Safety of life, traffic management, and infotainment
dissemination for drivers and passengers. One of the ultimate goals in the
design of such networking is to resist various malicious abuses and security
attacks. In this research new security mechanisms are proposed to achieve
secure certificate revocation, which is considered among the most challenging
design objective in vehicular ad hoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0979</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0979</id><created>2012-07-04</created><authors><author><keyname>Eisenbrand</keyname><forenames>Friedrich</forenames></author><author><keyname>H&#xe4;hnle</keyname><forenames>Nicolai</forenames></author></authors><title>Minimizing the number of lattice points in a translated polygon</title><categories>cs.CC math.NT</categories><msc-class>11H06, 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The parametric lattice-point counting problem is as follows: Given an integer
matrix $A \in Z^{m \times n}$, compute an explicit formula parameterized by $b
\in R^m$ that determines the number of integer points in the polyhedron $\{x
\in R^n : Ax \leq b\}$. In the last decade, this counting problem has received
considerable attention in the literature. Several variants of Barvinok's
algorithm have been shown to solve this problem in polynomial time if the
number $n$ of columns of $A$ is fixed.
  Central to our investigation is the following question: Can one also
efficiently determine a parameter $b$ such that the number of integer points in
$\{x \in R^n : Ax \leq b\}$ is minimized? Here, the parameter $b$ can be chosen
from a given polyhedron $Q \subseteq R^m$.
  Our main result is a proof that finding such a minimizing parameter is
$NP$-hard, even in dimension 2 and even if the parametrization reflects a
translation of a 2-dimensional convex polygon. This result is established via a
relationship of this problem to arithmetic progressions and simultaneous
Diophantine approximation.
  On the positive side we show that in dimension 2 there exists a polynomial
time algorithm for each fixed $k$ that either determines a minimizing
translation or asserts that any translation contains at most $1 + 1/k$ times
the minimal number of lattice points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0988</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0988</id><created>2012-07-04</created><updated>2012-09-08</updated><authors><author><keyname>Laitinen</keyname><forenames>Tero</forenames></author><author><keyname>Junttila</keyname><forenames>Tommi</forenames></author><author><keyname>Niemel&#xe4;</keyname><forenames>Ilkka</forenames></author></authors><title>Extending Clause Learning SAT Solvers with Complete Parity Reasoning
  (extended version)</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instances of logical cryptanalysis, circuit verification, and bounded model
checking can often be succinctly represented as a combined satisfiability (SAT)
problem where an instance is a combination of traditional clauses and parity
constraints. This paper studies how such combined problems can be efficiently
solved by augmenting a modern SAT solver with an xor-reasoning module in the
DPLL(XOR) framework. A new xor-reasoning module that deduces all possible
implied literals using incremental Gauss-Jordan elimination is presented. A
decomposition technique that can greatly reduce the size of parity constraint
matrices while allowing still to deduce all implied literals is presented. It
is shown how to eliminate variables occuring only in parity constraints while
preserving the decomposition. The proposed techniques are evaluated
experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.0996</identifier>
 <datestamp>2015-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.0996</id><created>2012-07-04</created><updated>2015-02-10</updated><authors><author><keyname>G&#xfc;nther</keyname><forenames>Felix</forenames></author></authors><title>The maximum number of intersections of two polygons</title><categories>math.CO cs.DM</categories><comments>This paper has been withdrawn by the author due to an unrecoverable
  error in the proof of Lemma 2. In fact, a counterexample to an even weaker
  version of Lemma 2 has been found by the author</comments><msc-class>52C45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the maximum number of intersections between two polygons with
p and q vertices, respectively, in the plane. The cases where p or q is even or
the polygons do not have to be simple are quite easy and already known, but
when p and q are both odd and both polygons are simple, the problem is more
difficult. The conjectured maximum is (p-1)(q-1)+2 for all odd p and q.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1016</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1016</id><created>2012-07-04</created><authors><author><keyname>Kurdej</keyname><forenames>Marek</forenames><affiliation>HEUDIASYC</affiliation></author><author><keyname>Moras</keyname><forenames>Julien</forenames><affiliation>HEUDIASYC</affiliation></author><author><keyname>Cherfaoui</keyname><forenames>V&#xe9;ronique</forenames><affiliation>HEUDIASYC</affiliation></author><author><keyname>Bonnifait</keyname><forenames>Philippe</forenames><affiliation>HEUDIASYC</affiliation></author></authors><title>Map-aided Fusion Using Evidential Grids for Mobile Perception in Urban
  Environment</title><categories>cs.RO cs.AI</categories><proxy>ccsd</proxy><journal-ref>The 2nd International Conference on Belief Functions, Compi\`egne
  : France (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evidential grids have been recently used for mobile object perception. The
novelty of this article is to propose a perception scheme using prior map
knowledge. A geographic map is considered an additional source of information
fused with a grid representing sensor data. Yager's rule is adapted to exploit
the Dempster-Shafer conflict information at large. In order to distinguish
stationary and mobile objects, a counter is introduced and used as a factor for
mass function specialisation. Contextual discounting is used, since we assume
that different pieces of information become obsolete at different rates. Tests
on real-world data are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1019</identifier>
 <datestamp>2015-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1019</id><created>2012-07-04</created><authors><author><keyname>Morvant</keyname><forenames>Emilie</forenames><affiliation>LIF</affiliation></author><author><keyname>Habrard</keyname><forenames>Amaury</forenames><affiliation>LAHC</affiliation></author><author><keyname>Ayache</keyname><forenames>St&#xe9;phane</forenames><affiliation>LIF</affiliation></author></authors><title>PAC-Bayesian Majority Vote for Late Classifier Fusion</title><categories>stat.ML cs.CV cs.LG cs.MM</categories><comments>7 pages, Research report</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lot of attention has been devoted to multimedia indexing over the past few
years. In the literature, we often consider two kinds of fusion schemes: The
early fusion and the late fusion. In this paper we focus on late classifier
fusion, where one combines the scores of each modality at the decision level.
To tackle this problem, we investigate a recent and elegant well-founded
quadratic program named MinCq coming from the Machine Learning PAC-Bayes
theory. MinCq looks for the weighted combination, over a set of real-valued
functions seen as voters, leading to the lowest misclassification rate, while
making use of the voters' diversity. We provide evidence that this method is
naturally adapted to late fusion procedure. We propose an extension of MinCq by
adding an order- preserving pairwise loss for ranking, helping to improve Mean
Averaged Precision measure. We confirm the good behavior of the MinCq-based
fusion approaches with experiments on a real image benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1031</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1031</id><created>2012-07-03</created><authors><author><keyname>Barcelo</keyname><forenames>Jaume</forenames></author><author><keyname>Bellalta</keyname><forenames>Boris</forenames></author><author><keyname>Baig</keyname><forenames>Roger</forenames></author><author><keyname>Roca</keyname><forenames>Ramon</forenames></author><author><keyname>Domingo</keyname><forenames>Albert</forenames></author><author><keyname>Sanabria</keyname><forenames>Luis</forenames></author><author><keyname>Cano</keyname><forenames>Cristina</forenames></author><author><keyname>Oliver</keyname><forenames>Miquel</forenames></author></authors><title>Bottom-up Broadband Initiatives in the Commons for Europe Project</title><categories>cs.CY cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper offers an overview of the Commons for Europe (C4EU) project and
the role of Bottom-up Broadband (BuB) in developing the information society.
BuB is characterized by the fact that the beneficiaries of the networks
actively participate in the planning, deployment and maintenance tasks. For the
beneficiaries, this represent a paradigm shift from a consumer-only position to
an active-participant position. We summarize a representative set of the BuB
pilot proposals that have been considered in the context of the C4EU project. A
selection of these proposals will be executed and carefully documented to
define good practices in BuB deployments. The documentation will include
project templates, work plans, case studies, replicable success models and
regulatory guidelines. The overall goal of the project is to assess the
validity of the BuB model to effectively and efficiently complement exiting
traditional deployments in satisfying the networking and technological needs of
the European citizens and organizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1032</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1032</id><created>2012-07-03</created><authors><author><keyname>Dodig-Crnkovic</keyname><forenames>Gordana</forenames></author></authors><title>Info-Computationalism and Philosophical Aspects of Research in
  Information Sciences</title><categories>cs.GL</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The historical development has lead to the decay of Natural Philosophy which
until 19th century included all of our knowledge about the physical world into
the growing multitude of specialized sciences. The focus on the in-depth
enquiry disentangled from its broad context lead to the problem of loss of
common world-view and impossibility of communication between specialist
research fields because of different languages they developed in isolation. The
need for a new unifying framework is becoming increasingly apparent with the
information technology enabling and intensifying the communication between
different research fields and knowledge communities. This time, not only
natural sciences, but also all of human knowledge is being integrated in a
global network such as Internet with its diverse knowledge and language
communities. Info-computationalism (ICON) as a synthesis of pancomputationalism
and paninformationalism presents a unifying framework for understanding of
natural phenomena including living beings and their cognition, their ways of
processing information and producing knowledge. Within ICON physical universe
is understood as a network of computational processes on an informational
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1033</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1033</id><created>2012-07-03</created><authors><author><keyname>Dodig-Crnkovic</keyname><forenames>Gordana</forenames></author></authors><title>Alan Turing's Legacy: Info-Computational Philosophy of Nature</title><categories>cs.GL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alan Turing's pioneering work on computability, and his ideas on
morphological computing support Andrew Hodges' view of Turing as a natural
philosopher. Turing's natural philosophy differs importantly from Galileo's
view that the book of nature is written in the language of mathematics (The
Assayer, 1623). Computing is more than a language of nature as computation
produces real time physical behaviors. This article presents the framework of
Natural Info-computationalism as a contemporary natural philosophy that builds
on the legacy of Turing's computationalism. Info-computationalism is a
synthesis of Informational Structural Realism (the view that nature is a web of
informational structures) and Natural Computationalism (the view that nature
physically computes its own time development). It presents a framework for the
development of a unified approach to nature, with common interpretation of
inanimate nature as well as living organisms and their social networks.
Computing is understood as information processing that drives all the changes
on different levels of organization of information and can be modeled as
morphological computing on data sets pertinent to informational structures. The
use of infocomputational conceptualizations, models and tools makes possible
for the first time in history the study of complex selforganizing adaptive
systems, including basic characteristics and functions of living systems,
intelligence, and cognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1034</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1034</id><created>2012-07-03</created><authors><author><keyname>Dodig-Crnkovic</keyname><forenames>Gordana</forenames></author><author><keyname>Burgin</keyname><forenames>Mark</forenames></author></authors><title>Axiomatic Tools versus Constructive approach to Unconventional
  Algorithms</title><categories>cs.GL cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze axiomatic issues of unconventional computations
from a methodological and philosophical point of view. We explain how the new
models of algorithms changed the algorithmic universe, making it open and
allowing increased flexibility and creativity. However, the greater power of
new types of algorithms also brought the greater complexity of the algorithmic
universe, demanding new tools for its study. That is why we analyze new
powerful tools brought forth by the axiomatic theory of algorithms, automata
and computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1035</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1035</id><created>2012-07-04</created><authors><author><keyname>Dall'Anese</keyname><forenames>Emiliano</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Statistical Routing for Multihop Wireless Cognitive Networks</title><categories>math.OC cs.NI</categories><comments>Accepted for publication on the IEEE Journal on Selected Areas in
  Communications - Cognitive Radio Series (Nov 2012 Issue)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To account for the randomness of propagation channels and interference levels
in hierarchical spectrum sharing, a novel approach to multihop routing is
introduced for cognitive random access networks, whereby packets are randomly
routed according to outage probabilities. Leveraging channel and interference
level statistics, the resultant cross-layer optimization framework provides
optimal routes, transmission probabilities, and transmit-powers, thus enabling
cognizant adaptation of routing, medium access, and physical layer parameters
to the propagation environment. The associated optimization problem is
non-convex, and hence hard to solve in general. Nevertheless, a successive
convex approximation approach is adopted to efficiently find a
Karush-Kuhn-Tucker solution. Augmented Lagrangian and primal decomposition
methods are employed to develop a distributed algorithm, which also lends
itself to online implementation. Enticingly, the fresh look advocated here
permeates benefits also to conventional multihop wireless networks in the
presence of channel uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1061</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1061</id><created>2012-07-04</created><authors><author><keyname>Ahmed-Ali</keyname><forenames>Tarek</forenames></author><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Lamnabhi-Lagarrigue</keyname><forenames>Francoise</forenames></author></authors><title>Global Exponential Sampled-Data Observers for Nonlinear Systems with
  Delayed Measurements</title><categories>math.OC cs.SY</categories><comments>17 pages, submitted for possible publication to Systems and Control
  Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new results concerning the observer design for wide
classes of nonlinear systems with both sampled and delayed measurements. By
using a small gain approach we provide sufficient conditions, which involve
both the delay and the sampling period, ensuring exponential convergence of the
observer system error. The proposed observer is robust with respect to
measurement errors and perturbations of the sampling schedule. Moreover, new
results on the robust global exponential state predictor design problem are
provided, for wide classes of nonlinear systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1067</identifier>
 <datestamp>2013-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1067</id><created>2012-07-04</created><updated>2013-01-28</updated><authors><author><keyname>Bourla</keyname><forenames>Avraham</forenames></author></authors><title>Bounding differences in Jager Pairs</title><categories>math.NT cs.IT math.DS math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetrical subdivisions in the space of Jager Pairs for continued
fractions-like expansions will provide us with bounds on their difference.
Results will also apply to the classical regular and backwards continued
fractions expansions, which are realized as special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1098</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1098</id><created>2012-07-04</created><authors><author><keyname>Bassil</keyname><forenames>Youssef</forenames></author></authors><title>TCP Congestion Control Scheme for Wireless Networks based on TCP
  Reserved Field and SNR Ratio</title><categories>cs.NI</categories><comments>LACSC - Lebanese Association for Computational Sciences,
  International Journal of Research and Reviews in Information Sciences
  (IJRRIS), Vol. 2, No. 2, June 2012, http://www.lacsc.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, TCP is the most popular and widely used network transmission
protocol. In actual fact, about 90% of connections on the internet use TCP to
communicate. Through several upgrades and improvements, TCP became well
optimized for the very reliable wired networks. As a result, TCP considers all
packet timeouts in wired networks as due to network congestion and not to bit
errors. However, with networking becoming more heterogeneous, providing wired
as well as wireless topologies, TCP suffers from performance degradation over
error-prone wireless links as it has no mechanism to differentiate error losses
from congestion losses. It therefore considers all packet losses as due to
congestion and consequently reduces the burst of packet, diminishing at the
same time the network throughput. This paper proposes a new TCP congestion
control scheme appropriate for wireless as well as wired networks and is
capable of distinguishing congestion losses from error losses. The proposed
scheme is based on using the reserved field of the TCP header to indicate
whether the established connection is over a wired or a wireless link.
Additionally, the proposed scheme leverages the SNR ratio to detect the
reliability of the link and decide whether to reduce packet burst or retransmit
a timed-out packet. Experiments conducted, revealed that the proposed scheme
proved to behave correctly in situations where timeouts were due to error and
not to congestion. Future work can improve upon the proposed scheme so much so
that it can leverage CRC and HEC errors so as to better determine the cause of
transmission timeouts in wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1114</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1114</id><created>2012-07-03</created><updated>2012-08-10</updated><authors><author><keyname>Lu</keyname><forenames>Yao</forenames></author><author><keyname>Huang</keyname><forenames>Kaizhu</forenames></author><author><keyname>Liu</keyname><forenames>Cheng-Lin</forenames></author></authors><title>A Fast Projected Fixed-Point Algorithm for Large Graph Matching</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a fast approximate algorithm for large graph matching. A new
projected fixed-point method is defined and a new doubly stochastic projection
is adopted to derive the algorithm. Previous graph matching algorithms suffer
from high computational complexity and therefore do not have good scalability
with respect to graph size. For matching two weighted graphs of $n$ nodes, our
algorithm has time complexity only $O(n^3)$ per iteration and space complexity
$O(n^2)$. In addition to its scalability, our algorithm is easy to implement,
robust, and able to match undirected weighted attributed graphs of different
sizes. While the convergence rate of previous iterative graph matching
algorithms is unknown, our algorithm is theoretically guaranteed to converge at
a linear rate. Extensive experiments on large synthetic and real graphs (more
than 1,000 nodes) were conducted to evaluate the performance of various
algorithms. Results show that in most cases our proposed algorithm achieves
better performance than previous state-of-the-art algorithms in terms of both
speed and accuracy in large graph matching. In particular, with high accuracy,
our algorithm takes only a few seconds (in a PC) to match two graphs of 1,000
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1115</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1115</id><created>2012-07-03</created><authors><author><keyname>Toole</keyname><forenames>Jameson L.</forenames></author><author><keyname>Ulm</keyname><forenames>Michael</forenames></author><author><keyname>Bauer</keyname><forenames>Dietmar</forenames></author><author><keyname>Gonzalez</keyname><forenames>Marta C.</forenames></author></authors><title>Inferring land use from mobile phone activity</title><categories>stat.ML cs.LG physics.data-an physics.soc-ph</categories><comments>To be presented at ACM UrbComp2012</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the spatiotemporal distribution of people within a city is
crucial to many planning applications. Obtaining data to create required
knowledge, currently involves costly survey methods. At the same time
ubiquitous mobile sensors from personal GPS devices to mobile phones are
collecting massive amounts of data on urban systems. The locations,
communications, and activities of millions of people are recorded and stored by
new information technologies. This work utilizes novel dynamic data, generated
by mobile phone users, to measure spatiotemporal changes in population. In the
process, we identify the relationship between land use and dynamic population
over the course of a typical week. A machine learning classification algorithm
is used to identify clusters of locations with similar zoned uses and mobile
phone activity patterns. It is shown that the mobile phone data is capable of
delivering useful information on actual land use that supplements zoning
regulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1119</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1119</id><created>2012-07-04</created><authors><author><keyname>Juditsky</keyname><forenames>Anatoli</forenames></author><author><keyname>Karzan</keyname><forenames>Fatma Kilinc</forenames></author><author><keyname>Nemirovski</keyname><forenames>Arkadi</forenames></author></authors><title>On unified view of nullspace-type conditions for recoveries associated
  with general sparsity structures</title><categories>math.OC cs.IT math.IT stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a general notion of &quot;sparsity structure&quot; and associated recoveries
of a sparse signal from its linear image of reduced dimension possibly
corrupted with noise. Our approach allows for uni?ed treatment of (a) the
&quot;usual sparsity&quot; and &quot;usual $\ell_1$ recovery,&quot; (b) block-sparsity with
possibly overlapping blocks and associated block-$\ell_1$ recovery, and (c)
low-rank-oriented recovery by nuclear norm minimization. The proposed recovery
routines are natural extensions of the usual $\ell_1$ minimization used in
Compressed Sensing. Specifically we present nullspace-type sufficient
conditions for the recovery to be precise on sparse signals in the noiseless
case. Then we derive error bounds for imperfect (nearly sparse signal, presence
of observation noise, etc.) recovery under these conditions. In all of these
cases, we present efficiently verifiable sufficient conditions for the validity
of the associated nullspace properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1134</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1134</id><created>2012-07-04</created><authors><author><keyname>Balan</keyname><forenames>Radu</forenames></author></authors><title>Reconstruction of Signals from Magnitudes of Redundant Representations</title><categories>math.FA cs.IT math.IT stat.AP</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the question of reconstructing a vector in a
finite-dimensional real or complex Hilbert space when only the magnitudes of
the coefficients of the vector under a redundant linear map are known. We
present new invertibility results as well an iterative algorithm that finds the
least-square solution and is robust in the presence of noise. We analyze its
numerical performance by comparing it to two versions of the Cramer-Rao lower
bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1135</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1135</id><created>2012-07-04</created><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>G&#xf8;rtz</keyname><forenames>Inge Li</forenames></author><author><keyname>Kopelowitz</keyname><forenames>Tsvi</forenames></author><author><keyname>Sach</keyname><forenames>Benjamin</forenames></author><author><keyname>Vildh&#xf8;j</keyname><forenames>Hjalte Wedel</forenames></author></authors><title>Sparse Suffix Tree Construction with Small Space</title><categories>cs.DS</categories><comments>7 pages, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of constructing a sparse suffix tree (or suffix
array) for $b$ suffixes of a given text $T$ of size $n$, using only $O(b)$
words of space during construction time. Breaking the naive bound of
$\Omega(nb)$ time for this problem has occupied many algorithmic researchers
since a different structure, the (evenly spaced) sparse suffix tree, was
introduced by K{\&quot;a}rkk{\&quot;a}inen and Ukkonen in 1996. While in the evenly
spaced sparse suffix tree the suffixes considered must be evenly spaced in $T$,
here there is no constraint on the locations of the suffixes.
  We show that the sparse suffix tree can be constructed in $O(n\log^2b)$ time.
To achieve this we develop a technique, which may be of independent interest,
that allows to efficiently answer $b$ longest common prefix queries on suffixes
of $T$, using only $O(b)$ space. We expect that this technique will prove
useful in many other applications in which space usage is a concern.
Furthermore, additional tradeoffs between the space usage and the construction
time are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1137</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1137</id><created>2012-07-04</created><authors><author><keyname>Edelstein</keyname><forenames>Andrea</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author></authors><title>Background Subtraction for Online Calibration of Baseline RSS in RF
  Sensing Networks</title><categories>cs.NI</categories><comments>24 pages, 11 figures, 7 tables, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio frequency (RF) sensing networks are a class of wireless sensor networks
(WSNs) which use RF signals to accomplish tasks such as passive device-free
localization and tracking. The algorithms used for these tasks usually require
access to measurements of baseline received signal strength (RSS) on each link.
However, it is often impossible to collect this calibration data (measurements
collected during an offline calibration period when the region of interest is
empty of targets). We propose adapting background subtraction methods from the
field of computer vision to estimate baseline RSS values from measurements
taken while the system is online and obstructions may be present. This is done
by forming an analogy between the intensity of a background pixel in an image
and the baseline RSS value of a WSN link and then translating the concepts of
temporal similarity, spatial similarity and spatial ergodicity which underlie
specific background subtraction algorithms to WSNs. Using experimental data, we
show that these techniques are capable of estimating baseline RSS values with
enough accuracy that RF tomographic tracking can be carried out in a variety of
different environments without the need for a calibration period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1138</identifier>
 <datestamp>2013-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1138</id><created>2012-07-04</created><updated>2013-07-02</updated><authors><author><keyname>Fujiwara</keyname><forenames>Yuichiro</forenames></author></authors><title>Parsing a sequence of qubits</title><categories>quant-ph cs.IT math.CO math.IT</categories><comments>11 pages, 2 figures, 1 table. Final accepted version for publication
  in the IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory 59 (2013) 6796-6806</journal-ref><doi>10.1109/TIT.2013.2272695</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a theoretical framework for frame synchronization, also known as
block synchronization, in the quantum domain which makes it possible to attach
classical and quantum metadata to quantum information over a noisy channel even
when the information source and sink are frame-wise asynchronous. This
eliminates the need of frame synchronization at the hardware level and allows
for parsing qubit sequences during quantum information processing. Our
framework exploits binary constant-weight codes that are self-synchronizing.
Possible applications may include asynchronous quantum communication such as a
self-synchronizing quantum network where one can hop into the channel at any
time, catch the next coming quantum information with a label indicating the
sender, and reply by routing her quantum information with control qubits for
quantum switches all without assuming prior frame synchronization between
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1140</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1140</id><created>2012-07-04</created><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author><author><keyname>Velingker</keyname><forenames>Ameya</forenames></author></authors><title>Restricted Isometry of Fourier Matrices and List Decodability of Random
  Linear Codes</title><categories>cs.IT math.CO math.IT math.PR</categories><comments>Preliminary full version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that a random linear code over F_q, with probability arbitrarily
close to 1, is list decodable at radius (1-1/q-\epsilon) with list size
L=O(1/\epsilon^2) and rate R=\Omega_q(\epsilon^2/(log^3(1/\epsilon))). Up to
the polylogarithmic factor in (1/\epsilon) and constant factors depending on q,
this matches the lower bound L=\Omega_q(1/\epsilon^2) for the list size and
upper bound R=O_q(\epsilon^2) for the rate. Previously only existence (and not
abundance) of such codes was known for the special case q=2 (Guruswami,
H{\aa}stad, Sudan and Zuckerman, 2002).
  In order to obtain our result, we employ a relaxed version of the well known
Johnson bound on list decoding that translates the average Hamming distance
between codewords to list decoding guarantees. We furthermore prove that the
desired average-distance guarantees hold for a code provided that a natural
complex matrix encoding the codewords satisfies the Restricted Isometry
Property with respect to the Euclidean norm (RIP-2). For the case of random
binary linear codes, this matrix coincides with a random submatrix of the
Hadamard-Walsh transform matrix that is well studied in the compressed sensing
literature.
  Finally, we improve the analysis of Rudelson and Vershynin (2008) on the
number of random frequency samples required for exact reconstruction of
k-sparse signals of length N. Specifically, we improve the number of samples
from O(k log(N) log^2(k) (log k + loglog N)) to O(k log(N) log^3(k)). The proof
involves bounding the expected supremum of a related Gaussian process by using
an improved analysis of the metric defined by the process. This improvement is
crucial for our application in list decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1141</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1141</id><created>2012-07-04</created><updated>2012-07-08</updated><authors><author><keyname>Matsakis</keyname><forenames>Nicolaos</forenames></author></authors><title>The Longest Queue Drop Policy for Shared-Memory Switches is
  1.5-competitive</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Longest Queue Drop memory management policy in shared-memory
switches consisting of $N$ output ports. The shared memory of size $M\geq N$
may have an arbitrary number of input ports. Each packet may be admitted by any
incoming port, but must be destined to a specific output port and each output
port may be used by only one queue. The Longest Queue Drop policy is a natural
online strategy used in directing the packet flow in buffering problems.
According to this policy and assuming unit packet values and cost of
transmission, every incoming packet is accepted, whereas if the shared memory
becomes full, one or more packets belonging to the longest queue are preempted,
in order to make space for the newly arrived packets. It was proved in 2001
[Hahne et al., SPAA '01] that the Longest Queue Drop policy is 2-competitive
and at least $\sqrt{2}$-competitive. It remained an open question whether a
(2-\epsilon) upper bound for the competitive ratio of this policy could be
shown, for any positive constant \epsilon. We show that the Longest Queue Drop
online policy is 1.5-competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1157</identifier>
 <datestamp>2012-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1157</id><created>2012-07-04</created><updated>2012-11-13</updated><authors><author><keyname>Ariffin</keyname><forenames>M. R. K.</forenames></author><author><keyname>Asbullah</keyname><forenames>M. A.</forenames></author><author><keyname>Abu</keyname><forenames>N. A.</forenames></author></authors><title>A New Efficient Asymmetric Cryptosystem Based on the Square Root Problem</title><categories>cs.IT cs.CR math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1209.3458</comments><msc-class>94A60, 68P25, 11D45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The square root modulo problem is a known primitive in designing an
asymmetric cryptosystem. It was first attempted by Rabin. Decryption failure of
the Rabin cryptosystem caused by the 4-to-1 decryption output is overcome
efficiently in this work. The proposed scheme (known as the AA_\beta-
cryptosystem) has its encryption speed having a complexity order faster than
the Diffie-Hellman Key Exchange, El-Gammal, RSA and ECC. It can also transmit a
larger data set securely when compared to existing asymmetric schemes. It has a
simple mathematical structure. Thus, it would have low computational
requirements and would enable communication devices with low computing power to
deploy secure communication procedures efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1161</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1161</id><created>2012-07-05</created><authors><author><keyname>Chhajer</keyname><forenames>Abhishek</forenames></author><author><keyname>Gupta</keyname><forenames>Manish K.</forenames></author><author><keyname>Vasani</keyname><forenames>Sandeep</forenames></author><author><keyname>Dholakiya</keyname><forenames>Jaley</forenames></author></authors><title>Modular Arithmetic Expressions and Primality Testing via DNA
  Self-Assembly</title><categories>cs.ET cs.DS cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-assembly is a fundamental process by which supramolecular species form
spontaneously from their components. This process is ubiquitous throughout the
life chemistry and is central to biological information processing. Algorithms
for solving many mathematical and computational problems via tile self assembly
have been proposed by many researchers in the last decade. In particular tile
set for doing basic arithmetic of two inputs have been given. In this work we
give tile set for doing basic arithmetic (addition, subtraction,
multiplication) of n inputs and subsequently computing its modulo. We also
present a tile set for primality testing. Finally we present a software
'xtilemod' for doing modular arithmetic. This simplifies the task of creating
the input files to xgrow simulator for doing basic (addition, subtraction,
multiplication and division) as well as modular arithmetic of n inputs. Similar
software for creating tile set for primality testing is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1166</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1166</id><created>2012-07-05</created><authors><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author></authors><title>On the Fundamental Relationship Determining the Capacity of Static and
  Mobile Wireless Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>submitted to IEEE Communication Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studying the capacity of wireless multi-hop networks is an important problem
and extensive research has been done in the area. In this letter, we sift
through various capacity-impacting parameters and show that the capacity of
both static and mobile networks is fundamentally determined by the average
number of simultaneous transmissions, the link capacity and the average number
of transmissions required to deliver a packet to its destination. We then use
this result to explain and help to better understand existing results on the
capacities of static networks, mobile networks and hybrid networks and the
multicast capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1173</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1173</id><created>2012-07-05</created><authors><author><keyname>G.</keyname><forenames>Shanmugasundaram</forenames></author><author><keyname>Venkatesan</keyname><forenames>V. Prasanna</forenames></author><author><keyname>Devi</keyname><forenames>C. Punitha</forenames></author></authors><title>A Comprehensive Model to achieve Service Reusability for Multi level
  stakeholders using Non-Functional attributes of Service Oriented Architecture</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SOA is a prominent paradigm for accomplishing reuse of services. Service
reusability is one dominant factor which has a greater influence on achieving
quality in SOA systems. There exists sufficient research in this area and
researchers have contributed many works towards achieving quality in SOA
systems but much emphasis was not provided on service reusability [1] [2] [3].
Few authors have addressed reusability factor with limited non-functional
attributes. Our study focuses on identifying the non-functional attributes
which have major or greater influence towards obtaining reusability in SOA
systems. The objective of this study goes into the next level, to categorize
the non-functional attributes on multi stakeholder's perspective i.e. Service
Consumer, Service Provider and Service Developer which paves the way to build a
comprehensive quality model for achieving Service Reusability
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1187</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1187</id><created>2012-07-05</created><authors><author><keyname>Shah</keyname><forenames>Hardik</forenames></author><author><keyname>Raabe</keyname><forenames>Andreas</forenames></author><author><keyname>Knoll</keyname><forenames>Alois</forenames></author></authors><title>Dynamic Priority Queue: An SDRAM Arbiter With Bounded Access Latencies
  for Tight WCET Calculation</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This report introduces a shared resource arbitration scheme &quot;DPQ - Dynamic
Priority Queue&quot; which provides bandwidth guarantees and low worst case latency
to each master in an MPSoC. Being a non-trivial candidate for timing analysis,
SDRAM has been chosen as a showcase, but the approach is valid for any shared
resource arbitration.
  Due to its significant cost, data rate and physical size advantages, SDRAM is
a potential candidate for cost sensitive, safety critical and space conserving
systems. The variable access latency is a major drawback of SDRAM that induces
largely over estimated Worst Case Execution Time (WCET) bounds of applications.
In this report we present the DPQ together with an algorithm to predict the
shared SDRAM's worst case latencies. We use the approach to calculate WCET
bounds of six hardware tasks executing on an Altera Cyclone III FPGA with
shared DDR2 memory. The results show that the DPQ is a fair arbitration scheme
and produces low WCET bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1188</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1188</id><created>2012-07-05</created><authors><author><keyname>Qu</keyname><forenames>Meixia</forenames></author><author><keyname>Luan</keyname><forenames>Junfeng</forenames></author><author><keyname>Zhu</keyname><forenames>Daming</forenames></author></authors><title>On the toggling-branching recurrence of Computability Logic</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new, substantially simplified version of the
toggling-branching recurrence operation of Computability Logic, prove its
equivalence to Japaridze's old, &quot;canonical&quot; version, and also prove that both
versions preserve the static property of their arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1206</identifier>
 <datestamp>2014-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1206</id><created>2012-07-05</created><updated>2012-09-07</updated><authors><author><keyname>Karimi</keyname><forenames>Fariba</forenames></author><author><keyname>Holme</keyname><forenames>Petter</forenames></author></authors><title>Threshold model of cascades in temporal networks</title><categories>physics.soc-ph cs.SI</categories><comments>7 pages, 5 figures, 2 tables</comments><journal-ref>Physica A: Statistical Mechanics and its Applications.392.16
  (2013): 3476-3483</journal-ref><doi>10.1016/j.physa.2013.03.050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Threshold models try to explain the consequences of social influence like the
spread of fads and opinions. Along with models of epidemics, they constitute a
major theoretical framework of social spreading processes. In threshold models
on static networks, an individual changes her state if a certain fraction of
her neighbors has done the same. When there are strong correlations in the
temporal aspects of contact patterns, it is useful to represent the system as a
temporal network. In such a system, not only contacts but also the time of the
contacts are represented explicitly. There is a consensus that bursty temporal
patterns slow down disease spreading. However, as we will see, this is not a
universal truth for threshold models. In this work, we propose an extension of
Watts' classic threshold model to temporal networks. We do this by assuming
that an agent is influenced by contacts which lie a certain time into the past.
I.e., the individuals are affected by contacts within a time window. In
addition to thresholds as the fraction of contacts, we also investigate the
number of contacts within the time window as a basis for influence. To
elucidate the model's behavior, we run the model on real and randomized
empirical contact datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1223</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1223</id><created>2012-07-05</created><authors><author><keyname>Gamarnik</keyname><forenames>David</forenames></author><author><keyname>Katz</keyname><forenames>Dmitry</forenames></author><author><keyname>Misra</keyname><forenames>Sidhant</forenames></author></authors><title>Strong spatial mixing for list coloring of graphs</title><categories>math.PR cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The property of spatial mixing and strong spatial mixing in spin systems has
been of interest because of its implications on uniqueness of Gibbs measures on
infinite graphs and efficient approximation of counting problems that are
otherwise known to be #P hard. In the context of coloring, strong spatial
mixing has been established for regular trees when $q \geq \alpha^{*} \Delta +
1$ where $q$ the number of colors, $\Delta$ is the degree and $\alpha^* =
1.763..$ is the unique solution to $xe^{-1/x} = 1$. It has also been
established for bounded degree lattice graphs whenever $q \geq \alpha^* \Delta
- \beta$ for some constant $\beta$, where $\Delta$ is the maximum vertex degree
of the graph. The latter uses a technique based on recursively constructed
coupling of Markov chains whereas the former is based on establishing decay of
correlations on the tree. We establish strong spatial mixing of list colorings
on arbitrary bounded degree triangle-free graphs whenever the size of the list
of each vertex $v$ is at least $\alpha \Delta(v) + \beta$ where $\Delta(v)$ is
the degree of vertex $v$ and $\alpha &gt; \alpha ^*$ and $\beta$ is a constant
that only depends on $\alpha$. We do this by proving the decay of correlations
via recursive contraction of the distance between the marginals measured with
respect to a suitably chosen error function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1230</identifier>
 <datestamp>2014-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1230</id><created>2012-07-05</created><authors><author><keyname>Zhao</keyname><forenames>Qibin</forenames></author><author><keyname>Caiafa</keyname><forenames>Cesar F.</forenames></author><author><keyname>Mandic</keyname><forenames>Danilo P.</forenames></author><author><keyname>Chao</keyname><forenames>Zenas C.</forenames></author><author><keyname>Nagasaka</keyname><forenames>Yasuo</forenames></author><author><keyname>Fujii</keyname><forenames>Naotaka</forenames></author><author><keyname>Zhang</keyname><forenames>Liqing</forenames></author><author><keyname>Cichocki</keyname><forenames>Andrzej</forenames></author></authors><title>Higher-Order Partial Least Squares (HOPLS): A Generalized Multi-Linear
  Regression Method</title><categories>cs.AI</categories><journal-ref>Pattern Analysis and Machine Intelligence, IEEE Transactions on,
  vol. 35, no.7, July, 2013</journal-ref><doi>10.1109/TPAMI.2012.254.</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new generalized multilinear regression model, termed the Higher-Order
Partial Least Squares (HOPLS), is introduced with the aim to predict a tensor
(multiway array) $\tensor{Y}$ from a tensor $\tensor{X}$ through projecting the
data onto the latent space and performing regression on the corresponding
latent variables. HOPLS differs substantially from other regression models in
that it explains the data by a sum of orthogonal Tucker tensors, while the
number of orthogonal loadings serves as a parameter to control model complexity
and prevent overfitting. The low dimensional latent space is optimized
sequentially via a deflation operation, yielding the best joint subspace
approximation for both $\tensor{X}$ and $\tensor{Y}$. Instead of decomposing
$\tensor{X}$ and $\tensor{Y}$ individually, higher order singular value
decomposition on a newly defined generalized cross-covariance tensor is
employed to optimize the orthogonal loadings. A systematic comparison on both
synthetic data and real-world decoding of 3D movement trajectories from
electrocorticogram (ECoG) signals demonstrate the advantages of HOPLS over the
existing methods in terms of better predictive ability, suitability to handle
small sample sizes, and robustness to noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1238</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1238</id><created>2012-07-05</created><authors><author><keyname>Kova&#x10d;evi&#x107;</keyname><forenames>Mladen</forenames></author><author><keyname>Stanojevi&#x107;</keyname><forenames>Ivan</forenames></author><author><keyname>&#x160;enk</keyname><forenames>Vojin</forenames></author></authors><title>On the Hardness of Entropy Minimization and Related Problems</title><categories>cs.IT cs.CC math.IT</categories><comments>IEEE Information Theory Workshop (ITW) 2012</comments><msc-class>94A17, 68Q17</msc-class><doi>10.1109/ITW.2012.6404727</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate certain optimization problems for Shannon information
measures, namely, minimization of joint and conditional entropies $H(X,Y)$,
$H(X|Y)$, $H(Y|X)$, and maximization of mutual information $I(X;Y)$, over
convex regions. When restricted to the so-called transportation polytopes (sets
of distributions with fixed marginals), very simple proofs of NP-hardness are
obtained for these problems because in that case they are all equivalent, and
their connection to the well-known \textsc{Subset sum} and \textsc{Partition}
problems is revealed. The computational intractability of the more general
problems over arbitrary polytopes is then a simple consequence. Further, a
simple class of polytopes is shown over which the above problems are not
equivalent and their complexity differs sharply, namely, minimization of
$H(X,Y)$ and $H(Y|X)$ is trivial, while minimization of $H(X|Y)$ and
maximization of $I(X;Y)$ are strongly NP-hard problems. Finally, two new
(pseudo)metrics on the space of discrete probability distributions are
introduced, based on the so-called variation of information quantity, and
NP-hardness of their computation is shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1253</identifier>
 <datestamp>2012-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1253</id><created>2012-07-05</created><updated>2012-10-19</updated><authors><author><keyname>Bavaud</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Guex</keyname><forenames>Guillaume</forenames></author></authors><title>Interpolating between Random Walks and Shortest Paths: a Path Functional
  Approach</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General models of network navigation must contain a deterministic or drift
component, encouraging the agent to follow routes of least cost, as well as a
random or diffusive component, enabling free wandering. This paper proposes a
thermodynamic formalism involving two path functionals, namely an energy
functional governing the drift and an entropy functional governing the
diffusion. A freely adjustable parameter, the temperature, arbitrates between
the conflicting objectives of minimising travel costs and maximising spatial
exploration. The theory is illustrated on various graphs and various
temperatures. The resulting optimal paths, together with presumably new
associated edges and nodes centrality indices, are analytically and numerically
investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1255</identifier>
 <datestamp>2012-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1255</id><created>2012-07-05</created><updated>2012-10-27</updated><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LJK</affiliation></author><author><keyname>Fousse</keyname><forenames>Laurent</forenames><affiliation>LJK</affiliation></author><author><keyname>Reynaud</keyname><forenames>Jean-Claude</forenames><affiliation>RC</affiliation></author></authors><title>Adjunctions for exceptions</title><categories>cs.LO math.CT</categories><comments>In this Version 2, minor improvements are made to Version 1</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algebraic method is used to study the semantics of exceptions in computer
languages. The exceptions form a computational effect, in the sense that there
is an apparent mismatch between the syntax of exceptions and their intended
semantics. We solve this apparent contradiction by efining a logic for
exceptions with a proof system which is close to their syntax and where their
intended semantics can be seen as a model. This requires a robust framework for
logics and their morphisms, which is provided by categorical tools relying on
adjunctions, fractions and limit sketches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1257</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1257</id><created>2012-07-05</created><updated>2012-07-09</updated><authors><author><keyname>Belov</keyname><forenames>Anton</forenames></author><author><keyname>Marques-Silva</keyname><forenames>Joao</forenames></author></authors><title>Generalizing Redundancy in Propositional Logic: Foundations and Hitting
  Sets Duality</title><categories>cs.LO cs.AI</categories><comments>13 pages; first part of series on labelled CNF formulas; fixed some
  references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection and elimination of redundant clauses from propositional formulas in
Conjunctive Normal Form (CNF) is a fundamental problem with numerous
application domains, including AI, and has been the subject of extensive
research. Moreover, a number of recent applications motivated various
extensions of this problem. For example, unsatisfiable formulas partitioned
into disjoint subsets of clauses (so-called groups) often need to be simplified
by removing redundant groups, or may contain redundant variables, rather than
clauses. In this report we present a generalized theoretical framework of
labelled CNF formulas that unifies various extensions of the redundancy
detection and removal problem and allows to derive a number of results that
subsume and extend previous work. The follow-up reports contain a number of
additional theoretical results and algorithms for various computational
problems in the context of the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1264</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1264</id><created>2012-07-03</created><authors><author><keyname>Giro</keyname><forenames>Sergio</forenames><affiliation>Department of Computer Science, University of Oxford, UK</affiliation></author></authors><title>Efficient computation of exact solutions for quantitative model checking</title><categories>cs.LO</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 85, 2012, pp. 17-32</journal-ref><doi>10.4204/EPTCS.85.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative model checkers for Markov Decision Processes typically use
finite-precision arithmetic. If all the coefficients in the process are
rational numbers, then the model checking results are rational, and so they can
be computed exactly. However, exact techniques are generally too expensive or
limited in scalability. In this paper we propose a method for obtaining exact
results starting from an approximated solution in finite-precision arithmetic.
The input of the method is a description of a scheduler, which can be obtained
by a model checker using finite precision. Given a scheduler, we show how to
obtain a corresponding basis in a linear-programming problem, in such a way
that the basis is optimal whenever the scheduler attains the worst-case
probability. This correspondence is already known for discounted MDPs, we show
how to apply it in the undiscounted case provided that some preprocessing is
done. Using the correspondence, the linear-programming problem can be solved in
exact arithmetic starting from the basis obtained. As a consequence, the method
finds the worst-case probability even if the scheduler provided by the model
checker was not optimal. In our experiments, the calculation of exact solutions
from a candidate scheduler is significantly faster than the calculation using
the simplex method under exact arithmetic starting from a default basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1265</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1265</id><created>2012-07-05</created><updated>2012-07-06</updated><authors><author><keyname>Hoefer</keyname><forenames>Martin</forenames></author><author><keyname>Wagner</keyname><forenames>Lisa</forenames></author></authors><title>Locally Stable Matching with General Preferences</title><categories>cs.DS cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study stable matching problems with locality of information and control.
In our model, each player is a node in a fixed network and strives to be
matched to another player. A player has a complete preference list over all
other players it can be matched with. Players can match arbitrarily, and they
learn about possible partners dynamically based on their current neighborhood.
We consider convergence of dynamics to locally stable matchings -- states that
are stable with respect to their imposed information structure in the network.
In the two-sided case of stable marriage in which existence is guaranteed, we
show that reachability becomes NP-hard to decide. This holds even when the
network exists only among one partition of players. In contrast, if one
partition has no network and players remember a previous match every round,
reachability is guaranteed and random dynamics converge with probability 1. We
characterize this positive result in various ways. For instance, it holds for
random memory and for cache memory with the most recent partner, but not for
cache memory with the best partner. Also, it is crucial which partition of the
players has memory. Finally, we present a variety of results for centralized
computation of locally stable matchings, e.g., computing maximum locally stable
matchings in the two-sided case and deciding and characterizing existence in
the general roommates case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1266</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1266</id><created>2012-07-05</created><updated>2013-03-22</updated><authors><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author><author><keyname>Pach</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Pinchasi</keyname><forenames>Rom</forenames></author><author><keyname>Zerbib</keyname><forenames>Shira</forenames></author></authors><title>The number of distinct distances from a vertex of a convex polygon</title><categories>cs.CG cs.DM</categories><comments>11 pages, 4 figures</comments><msc-class>68U05, 52C10</msc-class><journal-ref>Journal of Computational Geometry, 4:1-12, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erd\H{o}s conjectured in 1946 that every n-point set P in convex position in
the plane contains a point that determines at least floor(n/2) distinct
distances to the other points of P. The best known lower bound due to
Dumitrescu (2006) is 13n/36 - O(1). In the present note, we slightly improve on
this result to (13/36 + eps)n - O(1) for eps ~= 1/23000. Our main ingredient is
an improved bound on the maximum number of isosceles triangles determined by P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1268</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1268</id><created>2012-07-03</created><authors><author><keyname>Bloem</keyname><forenames>Roderick</forenames><affiliation>IAIK, TU-Graz</affiliation></author><author><keyname>Gamauf</keyname><forenames>Hans-J&#xfc;rgen</forenames><affiliation>IAIK, TU-Graz</affiliation></author><author><keyname>Hofferek</keyname><forenames>Georg</forenames><affiliation>IAIK, TU-Graz</affiliation></author><author><keyname>K&#xf6;nighofer</keyname><forenames>Bettina</forenames><affiliation>IAIK, TU-Graz</affiliation></author><author><keyname>K&#xf6;nighofer</keyname><forenames>Robert</forenames><affiliation>IAIK, TU-Graz</affiliation></author></authors><title>Synthesizing Robust Systems with RATSY</title><categories>cs.LO cs.GT</categories><comments>In Proceedings SYNT 2012, arXiv:1207.0554</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 84, 2012, pp. 47-53</journal-ref><doi>10.4204/EPTCS.84.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Specifications for reactive systems often consist of environment assumptions
and system guarantees. An implementation should not only be correct, but also
robust in the sense that it behaves reasonably even when the assumptions are
(temporarily) violated. We present an extension of the requirements analysis
and synthesis tool RATSY that is able to synthesize robust systems from GR(1)
specifications, i.e., system in which a finite number of safety assumption
violations is guaranteed to induce only a finite number of safety guarantee
violations. We show how the specification can be turned into a two-pair Streett
game, and how a winning strategy corresponding to a correct and robust
implementation can be computed. Finally, we provide some experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1271</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1271</id><created>2012-07-03</created><authors><author><keyname>Belardinelli</keyname><forenames>F.</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Gonzalez</keyname><forenames>P.</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Lomuscio</keyname><forenames>A.</forenames><affiliation>Imperial College London</affiliation></author></authors><title>Automated Verification of Quantum Protocols using MCMAS</title><categories>cs.LO cs.CR cs.MA quant-ph</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 85, 2012, pp. 48-62</journal-ref><doi>10.4204/EPTCS.85.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a methodology for the automated verification of quantum protocols
using MCMAS, a symbolic model checker for multi-agent systems The method is
based on the logical framework developed by D'Hondt and Panangaden for
investigating epistemic and temporal properties, built on the model for
Distributed Measurement-based Quantum Computation (DMC), an extension of the
Measurement Calculus to distributed quantum systems. We describe the
translation map from DMC to interpreted systems, the typical formalism for
reasoning about time and knowledge in multi-agent systems. Then, we introduce
dmc2ispl, a compiler into the input language of the MCMAS model checker. We
demonstrate the technique by verifying the Quantum Teleportation Protocol, and
discuss the performance of the tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1272</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1272</id><created>2012-07-03</created><authors><author><keyname>Bulychev</keyname><forenames>Peter</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>David</keyname><forenames>Alexandre</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>Larsen</keyname><forenames>Kim Gulstrand</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>Miku&#x10d;ionis</keyname><forenames>Marius</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>Poulsen</keyname><forenames>Danny B&#xf8;gsted</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>Legay</keyname><forenames>Axel</forenames><affiliation>INRIA rennes, France and Aalborg University, Denmark</affiliation></author><author><keyname>Wang</keyname><forenames>Zheng</forenames><affiliation>East China Normal University, China</affiliation></author></authors><title>UPPAAL-SMC: Statistical Model Checking for Priced Timed Automata</title><categories>cs.LO cs.FL</categories><comments>In Proceedings QAPL 2012, arXiv:1207.0559</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 85, 2012, pp. 1-16</journal-ref><doi>10.4204/EPTCS.85.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper offers a survey of uppaalsmc, a major extension of the real-time
verification tool uppaal. uppaalsmc allows for the efficient analysis of
performance properties of networks of priced timed automata under a natural
stochastic semantics. In particular, uppaalsmc relies on a series of extensions
of the statistical model checking approach generalized to handle real-time
systems and estimate undecidable problems. uppaalsmc comes together with a
friendly user interface that allows a user to specify complex problems in an
efficient manner as well as to get feedback in the form of probability
distributions and compare probabilities to analyze performance aspects of
systems. The focus of the survey is on the evolution of the tool - including
modeling and specification formalisms as well as techniques applied - together
with applications of the tool to case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1276</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1276</id><created>2012-07-02</created><authors><author><keyname>Bulychev</keyname><forenames>Peter</forenames></author><author><keyname>Cassez</keyname><forenames>Franck</forenames></author><author><keyname>David</keyname><forenames>Alexandre</forenames></author><author><keyname>Larsen</keyname><forenames>Kim G.</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Francois</forenames></author><author><keyname>Reynier</keyname><forenames>Pierre-Alain</forenames></author></authors><title>Controllers with Minimal Observation Power (Application to Timed
  Systems)</title><categories>cs.SY cs.GT cs.LO</categories><comments>This is the full version of the ATVA'12 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of controller synthesis under imperfect information
in a setting where there is a set of available observable predicates equipped
with a cost function. The problem that we address is the computation of a
subset of predicates sufficient for control and whose cost is minimal. Our
solution avoids a full exploration of all possible subsets of predicates and
reuses some information between different iterations. We apply our approach to
timed systems. We have developed a tool prototype and analyze the performance
of our optimization algorithm on two case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1277</identifier>
 <datestamp>2013-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1277</id><created>2012-07-05</created><updated>2013-02-18</updated><authors><author><keyname>Neiman</keyname><forenames>Ofer</forenames></author><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>Simple Deterministic Algorithms for Fully Dynamic Maximal Matching</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A maximal matching can be maintained in fully dynamic (supporting both
addition and deletion of edges) $n$-vertex graphs using a trivial deterministic
algorithm with a worst-case update time of O(n). No deterministic algorithm
that outperforms the na\&quot;{\i}ve O(n) one was reported up to this date. The only
progress in this direction is due to Ivkovi\'{c} and Lloyd \cite{IL93}, who in
1993 devised a deterministic algorithm with an \emph{amortized} update time of
$O((n+m)^{\sqrt{2}/2})$, where $m$ is the number of edges.
  In this paper we show the first deterministic fully dynamic algorithm that
outperforms the trivial one. Specifically, we provide a deterministic
\emph{worst-case} update time of $O(\sqrt{m})$. Moreover, our algorithm
maintains a matching which is in fact a 3/2-approximate maximum cardinality
matching (MCM). We remark that no fully dynamic algorithm for maintaining
$(2-\eps)$-approximate MCM improving upon the na\&quot;{\i}ve O(n) was known prior
to this work, even allowing amortized time bounds and \emph{randomization}.
  For low arboricity graphs (e.g., planar graphs and graphs excluding fixed
minors), we devise another simple deterministic algorithm with
\emph{sub-logarithmic update time}. Specifically, it maintains a fully dynamic
maximal matching with amortized update time of $O(\log n/\log \log n)$. This
result addresses an open question of Onak and Rubinfeld \cite{OR10}.
  We also show a deterministic algorithm with optimal space usage, that for
arbitrary graphs maintains a maximal matching in amortized $O(\sqrt{m})$ time,
and uses only $O(n+m)$ space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1280</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1280</id><created>2012-07-05</created><authors><author><keyname>Cizelj</keyname><forenames>Igor</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author></authors><title>Probabilistically Safe Control of Noisy Dubins Vehicles</title><categories>cs.RO cs.SY</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of controlling a stochastic version of a Dubins
vehicle such that the probability of satisfying a temporal logic specification
over a set of properties at the regions in a partitioned environment is
maximized. We assume that the vehicle can determine its precise initial
position in a known map of the environment. However, inspired by practical
limitations, we assume that the vehicle is equipped with noisy actuators and,
during its motion in the environment, it can only measure its angular velocity
using a limited accuracy gyroscope. Through quantization and discretization, we
construct a finite approximation for the motion of the vehicle in the form of a
Markov Decision Process (MDP). We allow for task specifications given as
temporal logic statements over the environmental properties, and use tools in
Probabilistic Computation Tree Logic (PCTL) to generate an MDP control policy
that maximizes the probability of satisfaction. We translate this policy to a
vehicle feedback control strategy and show that the probability that the
vehicle satisfies the specification in the original environment is bounded from
below by the maximum probability of satisfying the specification on the MDP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1291</identifier>
 <datestamp>2015-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1291</id><created>2012-07-05</created><updated>2015-03-24</updated><authors><author><keyname>Louzada</keyname><forenames>Vitor H. P.</forenames></author><author><keyname>Daolio</keyname><forenames>Fabio</forenames></author><author><keyname>Herrmann</keyname><forenames>Hans J.</forenames></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames></author></authors><title>Generating Robust and Efficient Networks Under Targeted Attacks</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Propagation Phenomena in Real World Networks, volume 85 of
  Intelligent Systems Reference Library, pages 215-224. Springer, 2015</journal-ref><doi>10.1007/978-3-319-15916-4_9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Much of our commerce and traveling depend on the efficient operation of large
scale networks. Some of those, such as electric power grids, transportation
systems, communication networks, and others, must maintain their efficiency
even after several failures, or malicious attacks. We outline a procedure that
modifies any given network to enhance its robustness, defined as the size of
its largest connected component after a succession of attacks, whilst keeping a
high efficiency, described in terms of the shortest paths among nodes. We also
show that this generated set of networks is very similar to networks optimized
for robustness in several aspects such as high assortativity and the presence
of an onion-like structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1307</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1307</id><created>2012-07-05</created><authors><author><keyname>Christou</keyname><forenames>Michalis</forenames></author><author><keyname>Crochemore</keyname><forenames>Maxime</forenames></author><author><keyname>Iliopoulos</keyname><forenames>Costas S.</forenames></author></authors><title>Identifying all abelian periods of a string in quadratic time and
  relevant problems</title><categories>cs.DS</categories><comments>Accepted in the &quot;International Journal of foundations of Computer
  Science&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abelian periodicity of strings has been studied extensively over the last
years. In 2006 Constantinescu and Ilie defined the abelian period of a string
and several algorithms for the computation of all abelian periods of a string
were given. In contrast to the classical period of a word, its abelian version
is more flexible, factors of the word are considered the same under any
internal permutation of their letters. We show two O(|y|^2) algorithms for the
computation of all abelian periods of a string y. The first one maps each
letter to a suitable number such that each factor of the string can be
identified by the unique sum of the numbers corresponding to its letters and
hence abelian periods can be identified easily. The other one maps each letter
to a prime number such that each factor of the string can be identified by the
unique product of the numbers corresponding to its letters and so abelian
periods can be identified easily. We also define weak abelian periods on
strings and give an O(|y|log(|y|)) algorithm for their computation, together
with some other algorithms for more basic problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1315</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1315</id><created>2012-07-05</created><authors><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author><author><keyname>Mora</keyname><forenames>Antonio M.</forenames></author><author><keyname>Cotta</keyname><forenames>Carlos</forenames></author><author><keyname>Runarsson</keyname><forenames>Thomas P.</forenames></author></authors><title>An experimental study of exhaustive solutions for the Mastermind puzzle</title><categories>cs.NE math.OC</categories><comments>41 pages, to be submitted to Computers and Operations Research</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Mastermind is in essence a search problem in which a string of symbols that
is kept secret must be found by sequentially playing strings that use the same
alphabet, and using the responses that indicate how close are those other
strings to the secret one as hints. Although it is commercialized as a game, it
is a combinatorial problem of high complexity, with applications on fields that
range from computer security to genomics. As such a kind of problem, there are
no exact solutions; even exhaustive search methods rely on heuristics to
choose, at every step, strings to get the best possible hint. These methods
mostly try to play the move that offers the best reduction in search space size
in the next step; this move is chosen according to an empirical score. However,
in this paper we will examine several state of the art exhaustive search
methods and show that another factor, the presence of the actual solution among
the candidate moves, or, in other words, the fact that the actual solution has
the highest score, plays also a very important role. Using that, we will
propose new exhaustive search approaches that obtain results which are
comparable to the classic ones, and besides, are better suited as a basis for
non-exhaustive search strategies such as evolutionary algorithms, since their
behavior in a series of key indicators is better than the classical algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1333</identifier>
 <datestamp>2014-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1333</id><created>2012-07-05</created><updated>2014-06-23</updated><authors><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author><author><keyname>Soto</keyname><forenames>Jos&#xe9; A.</forenames></author><author><keyname>Zenklusen</keyname><forenames>Rico</forenames></author></authors><title>Advances on Matroid Secretary Problems: Free Order Model and Laminar
  Case</title><categories>cs.DS cs.DM cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most well-known conjecture in the context of matroid secretary problems
claims the existence of a constant-factor approximation applicable to any
matroid. Whereas this conjecture remains open, modified forms of it were shown
to be true, when assuming that the assignment of weights to the secretaries is
not adversarial but uniformly random (Soto [SODA 2011], Oveis Gharan and
Vondr\'ak [ESA 2011]). However, so far, there was no variant of the matroid
secretary problem with adversarial weight assignment for which a
constant-factor approximation was found. We address this point by presenting a
9-approximation for the \emph{free order model}, a model suggested shortly
after the introduction of the matroid secretary problem, and for which no
constant-factor approximation was known so far. The free order model is a
relaxed version of the original matroid secretary problem, with the only
difference that one can choose the order in which secretaries are interviewed.
  Furthermore, we consider the classical matroid secretary problem for the
special case of laminar matroids. Only recently, a constant-factor
approximation has been found for this case, using a clever but rather involved
method and analysis (Im and Wang, [SODA 2011]) that leads to a
16000/3-approximation. This is arguably the most involved special case of the
matroid secretary problem for which a constant-factor approximation is known.
We present a considerably simpler and stronger $3\sqrt{3}e\approx
14.12$-approximation, based on reducing the problem to a matroid secretary
problem on a partition matroid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1336</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1336</id><created>2012-07-05</created><authors><author><keyname>Swanson</keyname><forenames>Colleen M.</forenames></author><author><keyname>Stinson</keyname><forenames>Douglas R.</forenames></author></authors><title>Combinatorial Solutions Providing Improved Security for the Generalized
  Russian Cards Problem</title><categories>math.CO cs.CR cs.DM</categories><msc-class>05B05, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first formal mathematical presentation of the generalized
Russian cards problem, and provide rigorous security definitions that capture
both basic and extended versions of weak and perfect security notions. In the
generalized Russian cards problem, three players, Alice, Bob, and Cathy, are
dealt a deck of $n$ cards, each given $a$, $b$, and $c$ cards, respectively.
The goal is for Alice and Bob to learn each other's hands via public
communication, without Cathy learning the fate of any particular card. The
basic idea is that Alice announces a set of possible hands she might hold, and
Bob, using knowledge of his own hand, should be able to learn Alice's cards
from this announcement, but Cathy should not. Using a combinatorial approach,
we are able to give a nice characterization of informative strategies (i.e.,
strategies allowing Bob to learn Alice's hand), having optimal communication
complexity, namely the set of possible hands Alice announces must be equivalent
to a large set of $t-(n, a, 1)$-designs, where $t=a-c$. We also provide some
interesting necessary conditions for certain types of deals to be
simultaneously informative and secure. That is, for deals satisfying $c = a-d$
for some $d \geq 2$, where $b \geq d-1$ and the strategy is assumed to satisfy
a strong version of security (namely perfect $(d-1)$-security), we show that $a
= d+1$ and hence $c=1$. We also give a precise characterization of informative
and perfectly $(d-1)$-secure deals of the form $(d+1, b, 1)$ satisfying $b \geq
d-1$ involving $d-(n, d+1, 1)$-designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1337</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1337</id><created>2012-07-05</created><authors><author><keyname>Caron</keyname><forenames>Eddy</forenames><affiliation>LIP</affiliation></author><author><keyname>Chuffart</keyname><forenames>Florent</forenames><affiliation>LIP</affiliation></author><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>MIS</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6</affiliation></author></authors><title>Optimization in a Self-Stabilizing Service Discovery Framework for Large
  Scale Systems</title><categories>cs.DC</categories><comments>(2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ability to find and get services is a key requirement in the development of
large-scale distributed sys- tems. We consider dynamic and unstable
environments, namely Peer-to-Peer (P2P) systems. In previous work, we designed
a service discovery solution called Distributed Lexicographic Placement Table
(DLPT), based on a hierar- chical overlay structure. A self-stabilizing version
was given using the Propagation of Information with Feedback (PIF) paradigm. In
this paper, we introduce the self-stabilizing COPIF (for Collaborative PIF)
scheme. An algo- rithm is provided with its correctness proof. We use this
approach to improve a distributed P2P framework designed for the services
discovery. Significantly efficient experimental results are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1345</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1345</id><created>2012-07-05</created><authors><author><keyname>Haim</keyname><forenames>Eli</forenames></author><author><keyname>Kochman</keyname><forenames>Yuval</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>Distributed Structure: Joint Expurgation for the Multiple-Access Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. Info. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we show how an improved lower bound to the error exponent of the
memoryless multiple-access (MAC) channel is attained via the use of linear
codes, thus demonstrating that structure can be beneficial even in cases where
there is no capacity gain. We show that if the MAC channel is modulo-additive,
then any error probability, and hence any error exponent, achievable by a
linear code for the corresponding single-user channel, is also achievable for
the MAC channel. Specifically, for an alphabet of prime cardinality, where
linear codes achieve the best known exponents in the single-user setting and
the optimal exponent above the critical rate, this performance carries over to
the MAC setting. At least at low rates, where expurgation is needed, our
approach strictly improves performance over previous results, where expurgation
was used at most for one of the users. Even when the MAC channel is not
additive, it may be transformed into such a channel. While the transformation
is lossy, we show that the distributed structure gain in some &quot;nearly additive&quot;
cases outweighs the loss, and thus the error exponent can improve upon the best
known error exponent for these cases as well. Finally we apply a similar
approach to the Gaussian MAC channel. We obtain an improvement over the best
known achievable exponent, given by Gallager, for certain rate pairs, using
lattice codes which satisfy a nesting condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1350</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1350</id><created>2012-07-04</created><authors><author><keyname>Bryce</keyname><forenames>Daniel</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author></authors><title>Cost Sensitive Reachability Heuristics for Handling State Uncertainty</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-60-68</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While POMDPs provide a general platform for non-deterministic conditional
planning under a variety of quality metrics they have limited scalability. On
the other hand, non-deterministic conditional planners scale very well, but
many lack the ability to optimize plan quality metrics. We present a novel
generalization of planning graph based heuristics that helps conditional
planners both scale and generate high quality plans when using actions with
nonuniform costs. We make empirical comparisons with two state of the art
planners to show the benefit of our techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1351</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1351</id><created>2012-07-04</created><authors><author><keyname>de Waal</keyname><forenames>Peter</forenames></author><author><keyname>van der Gaag</keyname><forenames>Linda C.</forenames></author></authors><title>Stable Independence in Perfect Maps</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-161-168</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the aid of the concept of stable independence we can construct, in an
efficient way, a compact representation of a semi-graphoid independence
relation. We show that this representation provides a new necessary condition
for the existence of a directed perfect map for the relation. The test for this
condition is based to a large extent on the transitivity property of a special
form of d-separation. The complexity of the test is linear in the size of the
representation. The test, moreover, brings the additional benefit that it can
be used to guide the early stages of network construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1352</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1352</id><created>2012-07-04</created><authors><author><keyname>Horvitz</keyname><forenames>Eric J.</forenames></author><author><keyname>Apacible</keyname><forenames>Johnson</forenames></author><author><keyname>Sarin</keyname><forenames>Raman</forenames></author><author><keyname>Liao</keyname><forenames>Lin</forenames></author></authors><title>Prediction, Expectation, and Surprise: Methods, Designs, and Study of a
  Deployed Traffic Forecasting Service</title><categories>cs.AI physics.soc-ph</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-275-283</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present research on developing models that forecast traffic flow and
congestion in the Greater Seattle area. The research has led to the deployment
of a service named JamBayes, that is being actively used by over 2,500 users
via smartphones and desktop versions of the system. We review the modeling
effort and describe experiments probing the predictive accuracy of the models.
Finally, we present research on building models that can identify current and
future surprises, via efforts on modeling and forecasting unexpected
situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1353</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1353</id><created>2012-07-04</created><authors><author><keyname>Kersting</keyname><forenames>Kristian</forenames></author><author><keyname>Raiko</keyname><forenames>Tapani</forenames></author></authors><title>'Say EM' for Selecting Probabilistic Models for Logical Sequences</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-300-307</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real world sequences such as protein secondary structures or shell logs
exhibit a rich internal structures. Traditional probabilistic models of
sequences, however, consider sequences of flat symbols only. Logical hidden
Markov models have been proposed as one solution. They deal with logical
sequences, i.e., sequences over an alphabet of logical atoms. This comes at the
expense of a more complex model selection problem. Indeed, different
abstraction levels have to be explored. In this paper, we propose a novel
method for selecting logical hidden Markov models from data called SAGEM. SAGEM
combines generalized expectation maximization, which optimizes parameters, with
structure search for model selection using inductive logic programming
refinement operators. We provide convergence and experimental results that show
SAGEM's effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1354</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1354</id><created>2012-07-04</created><authors><author><keyname>Laskey</keyname><forenames>Kathryn Blackmond</forenames></author><author><keyname>da Costa</keyname><forenames>Paulo</forenames></author></authors><title>Of Starships and Klingons: Bayesian Logic for the 23rd Century</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-346-353</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent systems in an open world must reason about many interacting
entities related to each other in diverse ways and having uncertain features
and relationships. Traditional probabilistic languages lack the expressive
power to handle relational domains. Classical first-order logic is sufficiently
expressive, but lacks a coherent plausible reasoning capability. Recent years
have seen the emergence of a variety of approaches to integrating first-order
logic, probability, and machine learning. This paper presents Multi-entity
Bayesian networks (MEBN), a formal system that integrates First Order Logic
(FOL) with Bayesian probability theory. MEBN extends ordinary Bayesian networks
to allow representation of graphical models with repeated sub-structures, and
can express a probability distribution over models of any consistent, finitely
axiomatizable first-order theory. We present the logic using an example
inspired by the Paramount Series StarTrek.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1355</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1355</id><created>2012-07-04</created><authors><author><keyname>Madsen</keyname><forenames>Anders L.</forenames></author></authors><title>A Differential Semantics of Lazy AR Propagation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-364-371</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a differential semantics of Lazy AR Propagation
(LARP) in discrete Bayesian networks. We describe how both single and multi
dimensional partial derivatives of the evidence may easily be calculated from a
junction tree in LARP equilibrium. We show that the simplicity of the
calculations stems from the nature of LARP. Based on the differential semantics
we describe how variable propagation in the LARP architecture may give access
to additional partial derivatives. The cautious LARP (cLARP) scheme is derived
to produce a flexible cLARP equilibrium that offers additional opportunities
for calculating single and multidimensional partial derivatives of the evidence
and subsets of the evidence from a single propagation. The results of an
empirical evaluation illustrates how the access to a largely increased number
of partial derivatives comes at a low computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1356</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1356</id><created>2012-07-04</created><authors><author><keyname>Peng</keyname><forenames>Yun</forenames></author><author><keyname>Ding</keyname><forenames>Zhongli</forenames></author></authors><title>Modifying Bayesian Networks by Probability Constraints</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-459-466</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the following problem: modify a Bayesian network to
satisfy a given set of probability constraints by only change its conditional
probability tables, and the probability distribution of the resulting network
should be as close as possible to that of the original network. We propose to
solve this problem by extending IPFP (iterative proportional fitting procedure)
to probability distributions represented by Bayesian networks. The resulting
algorithm E-IPFP is further developed to D-IPFP, which reduces the
computational cost by decomposing a global EIPFP into a set of smaller local
E-IPFP problems. Limited analysis is provided, including the convergence proofs
of the two algorithms. Computer experiments were conducted to validate the
algorithms. The results are consistent with the theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1357</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1357</id><created>2012-07-04</created><authors><author><keyname>Renooij</keyname><forenames>Silja</forenames></author><author><keyname>van der Gaag</keyname><forenames>Linda C.</forenames></author></authors><title>Exploiting Evidence-dependent Sensitivity Bounds</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-485-492</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studying the effects of one-way variation of any number of parameters on any
number of output probabilities quickly becomes infeasible in practice,
especially if various evidence profiles are to be taken into consideration. To
provide for identifying the parameters that have a potentially large effect
prior to actually performing the analysis, we need properties of sensitivity
functions that are independent of the network under study, of the available
evidence, or of both. In this paper, we study properties that depend upon just
the probability of the entered evidence. We demonstrate that these properties
provide for establishing an upper bound on the sensitivity value for a
parameter; they further provide for establishing the region in which the vertex
of the sensitivity function resides, thereby serving to identify parameters
with a low sensitivity value that may still have a large impact on the
probability of interest for relatively small parameter variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1358</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1358</id><created>2012-07-04</created><authors><author><keyname>Shortreed</keyname><forenames>Susan</forenames></author><author><keyname>Meila</keyname><forenames>Marina</forenames></author></authors><title>Unsupervised spectral learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-534-541</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In spectral clustering and spectral image segmentation, the data is partioned
starting from a given matrix of pairwise similarities S. the matrix S is
constructed by hand, or learned on a separate training set. In this paper we
show how to achieve spectral clustering in unsupervised mode. Our algorithm
starts with a set of observed pairwise features, which are possible components
of an unknown, parametric similarity function. This function is learned
iteratively, at the same time as the clustering of the data. The algorithm
shows promosing results on synthetic and real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1359</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1359</id><created>2012-07-04</created><authors><author><keyname>Szer</keyname><forenames>Daniel</forenames></author><author><keyname>Charpillet</keyname><forenames>Francois</forenames></author><author><keyname>Zilberstein</keyname><forenames>Shlomo</forenames></author></authors><title>MAA*: A Heuristic Search Algorithm for Solving Decentralized POMDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-576-583</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present multi-agent A* (MAA*), the first complete and optimal heuristic
search algorithm for solving decentralized partially-observable Markov decision
problems (DEC-POMDPs) with finite horizon. The algorithm is suitable for
computing optimal plans for a cooperative group of agents that operate in a
stochastic environment such as multirobot coordination, network traffic
control, `or distributed resource allocation. Solving such problems efiectively
is a major challenge in the area of planning under uncertainty. Our solution is
based on a synthesis of classical heuristic search and decentralized control
theory. Experimental results show that MAA* has significant advantages. We
introduce an anytime variant of MAA* and conclude with a discussion of
promising extensions such as an approach to solving infinite horizon problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1360</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1360</id><created>2012-07-04</created><authors><author><keyname>Bredin</keyname><forenames>Jonathan</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author></authors><title>Models for Truthful Online Double Auctions</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-50-59</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online double auctions (DAs) model a dynamic two-sided matching problem with
private information and self-interest, and are relevant for dynamic resource
and task allocation problems. We present a general method to design truthful
DAs, such that no agent can benefit from misreporting its arrival time,
duration, or value. The family of DAs is parameterized by a pricing rule, and
includes a generalization of McAfee's truthful DA to this dynamic setting. We
present an empirical study, in which we study the allocative-surplus and agent
surplus for a number of different DAs. Our results illustrate that dynamic
pricing rules are important to provide good market efficiency for markets with
high volatility or low volume.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1361</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1361</id><created>2012-07-04</created><authors><author><keyname>Braziunas</keyname><forenames>Darius</forenames></author><author><keyname>Boutilier</keyname><forenames>Craig</forenames></author></authors><title>Local Utility Elicitation in GAI Models</title><categories>cs.GT cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-42-49</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structured utility models are essential for the effective representation and
elicitation of complex multiattribute utility functions. Generalized additive
independence (GAI) models provide an attractive structural model of user
preferences, offering a balanced tradeoff between simplicity and applicability.
While representation and inference with such models is reasonably well
understood, elicitation of the parameters of such models has been studied less
from a practical perspective. We propose a procedure to elicit GAI model
parameters using only &quot;local&quot; utility queries rather than &quot;global&quot; queries over
full outcomes. Our local queries take full advantage of GAI structure and
provide a sound framework for extending the elicitation procedure to settings
where the uncertainty over utility parameters is represented probabilistically.
We describe experiments using a myopic value-of-information approach to
elicitation in a large GAI model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1362</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1362</id><created>2012-07-04</created><authors><author><keyname>Ashlagi</keyname><forenames>Itai</forenames></author><author><keyname>Monderer</keyname><forenames>Dov</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>On the Value of Correlation</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-34-41</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correlated equilibrium (Aumann, 1974) generalizes Nash equilibrium to allow
correlation devices. Aumann showed an example of a game, and of a correlated
equilibrium in this game, in which the agents' surplus (expected sum of payo s)
is greater than their surplus in all mixed-strategy equilibria. Following the
idea initiated by the price of anarchy literature (Koutsoupias &amp; Papadimitriou,
1999;Papadimitriou, 2001) this suggests the study of two major measures for the
value of correlation in a game with non-negative payoffs: 1. The ratio between
the maximal surplus obtained in a correlated equilibrium to the maximal surplus
obtained in a mixed-strategy equilibrium. We refer to this ratio as the
mediation value. 2. The ratio between the maximal surplus to the maximal
surplus obtained in a correlated equilibrium. We refer to this ratio as the
enforcement value. In this work we initiate the study of the mediation and
enforcement values, providing several general results on the value of
correlation as captured by these concepts. We also present a set of results for
the more specialized case of congestion games (Rosenthal,1973), a class of
games that received a lot of attention in the recent literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1363</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1363</id><created>2012-07-04</created><authors><author><keyname>Amgoud</keyname><forenames>Leila</forenames></author></authors><title>A unified setting for inference and decision: An argumentation-based
  approach</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-26-33</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring from inconsistency and making decisions are two problems which have
always been treated separately by researchers in Artificial Intelligence.
Consequently, different models have been proposed for each category. Different
argumentation systems [2, 7, 10, 11] have been developed for handling
inconsistency in knowledge bases. Recently, other argumentation systems [3, 4,
8] have been defined for making decisions under uncertainty. The aim of this
paper is to present a general argumentation framework in which both inferring
from inconsistency and decision making are captured. The proposed framework can
be used for decision under uncertainty, multiple criteria decision, rule-based
decision and finally case-based decision. Moreover, works on classical decision
suppose that the information about environment is coherent, and this no longer
required by this general framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1364</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1364</id><created>2012-07-04</created><authors><author><keyname>Altendorf</keyname><forenames>Eric E.</forenames></author><author><keyname>Restificar</keyname><forenames>Angelo C.</forenames></author><author><keyname>Dietterich</keyname><forenames>Thomas G.</forenames></author></authors><title>Learning from Sparse Data by Exploiting Monotonicity Constraints</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-18-26</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When training data is sparse, more domain knowledge must be incorporated into
the learning algorithm in order to reduce the effective size of the hypothesis
space. This paper builds on previous work in which knowledge about qualitative
monotonicities was formally represented and incorporated into learning
algorithms (e.g., Clark &amp; Matwin's work with the CN2 rule learning algorithm).
We show how to interpret knowledge of qualitative influences, and in particular
of monotonicities, as constraints on probability distributions, and to
incorporate this knowledge into Bayesian network learning algorithms. We show
that this yields improved accuracy, particularly with very small training sets
(e.g. less than 10 examples).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1365</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1365</id><created>2012-07-04</created><authors><author><keyname>Ali</keyname><forenames>Ayesha R.</forenames></author><author><keyname>Richardson</keyname><forenames>Thomas S.</forenames></author><author><keyname>Spirtes</keyname><forenames>Peter L.</forenames></author><author><keyname>Zhang</keyname><forenames>Jiji</forenames></author></authors><title>Towards Characterizing Markov Equivalence Classes for Directed Acyclic
  Graphs with Latent Variables</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-10-17</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that there may be many causal explanations that are
consistent with a given set of data. Recent work has been done to represent the
common aspects of these explanations into one representation. In this paper, we
address what is less well known: how do the relationships common to every
causal explanation among the observed variables of some DAG process change in
the presence of latent variables? Ancestral graphs provide a class of graphs
that can encode conditional independence relations that arise in DAG models
with latent and selection variables. In this paper we present a set of
orientation rules that construct the Markov equivalence class representative
for ancestral graphs, given a member of the equivalence class. These rules are
sound and complete. We also show that when the equivalence class includes a
DAG, the equivalence class representative is the essential graph for the said
DAG
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1366</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1366</id><created>2012-07-04</created><authors><author><keyname>Abbeel</keyname><forenames>Pieter</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author><author><keyname>Ng</keyname><forenames>Andrew Y.</forenames></author></authors><title>Learning Factor Graphs in Polynomial Time &amp; Sample Complexity</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-1-9</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study computational and sample complexity of parameter and structure
learning in graphical models. Our main result shows that the class of factor
graphs with bounded factor size and bounded connectivity can be learned in
polynomial time and polynomial number of samples, assuming that the data is
generated by a network in this class. This result covers both parameter
estimation for a known network structure and structure learning. It implies as
a corollary that we can learn factor graphs for both Bayesian networks and
Markov networks of bounded degree, in polynomial time and sample complexity.
Unlike maximum likelihood estimation, our method does not require inference in
the underlying network, and so applies to networks where inference is
intractable. We also show that the error of our learned model degrades
gracefully when the generating distribution is not a member of the target class
of networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1367</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1367</id><created>2012-07-04</created><authors><author><keyname>de Campos</keyname><forenames>Cassio Polpo</forenames></author><author><keyname>Cozman</keyname><forenames>Fabio Gagliardi</forenames></author></authors><title>Belief Updating and Learning in Semi-Qualitative Probabilistic Networks</title><categories>cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-153-160</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores semi-qualitative probabilistic networks (SQPNs) that
combine numeric and qualitative information. We first show that exact
inferences with SQPNs are NPPP-Complete. We then show that existing qualitative
relations in SQPNs (plus probabilistic logic and imprecise assessments) can be
dealt effectively through multilinear programming. We then discuss learning: we
consider a maximum likelihood method that generates point estimates given a
SQPN and empirical data, and we describe a Bayesian-minded method that employs
the Imprecise Dirichlet Model to generate set-valued estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1368</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1368</id><created>2012-07-04</created><authors><author><keyname>Conitzer</keyname><forenames>Vincent</forenames></author><author><keyname>Sandholm</keyname><forenames>Tuomas</forenames></author></authors><title>Common Voting Rules as Maximum Likelihood Estimators</title><categories>cs.GT cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-145-152</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voting is a very general method of preference aggregation. A voting rule
takes as input every voter's vote (typically, a ranking of the alternatives),
and produces as output either just the winning alternative or a ranking of the
alternatives. One potential view of voting is the following. There exists a
'correct' outcome (winner/ranking), and each voter's vote corresponds to a
noisy perception of this correct outcome. If we are given the noise model, then
for any vector of votes, we can
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1369</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1369</id><created>2012-07-04</created><authors><author><keyname>Cobb</keyname><forenames>Barry</forenames></author><author><keyname>Shenoy</keyname><forenames>Prakash P.</forenames></author></authors><title>Hybrid Bayesian Networks with Linear Deterministic Variables</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-136-144</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a hybrid Bayesian network has conditionally deterministic variables with
continuous parents, the joint density function for the continuous variables
does not exist. Conditional linear Gaussian distributions can handle such cases
when the continuous variables have a multi-variate normal distribution and the
discrete variables do not have continuous parents. In this paper, operations
required for performing inference with conditionally deterministic variables in
hybrid Bayesian networks are developed. These methods allow inference in
networks with deterministic variables where continuous variables may be
non-Gaussian, and their density functions can be approximated by mixtures of
truncated exponentials. There are no constraints on the placement of continuous
and discrete nodes in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1370</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1370</id><created>2012-07-04</created><authors><author><keyname>Choi</keyname><forenames>Arthur</forenames></author><author><keyname>Chan</keyname><forenames>Hei</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>On Bayesian Network Approximation by Edge Deletion</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-128-135</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of deleting edges from a Bayesian network for the
purpose of simplifying models in probabilistic inference. In particular, we
propose a new method for deleting network edges, which is based on the evidence
at hand. We provide some interesting bounds on the KL-divergence between
original and approximate networks, which highlight the impact of given evidence
on the quality of approximation and shed some light on good and bad candidates
for edge deletion. We finally demonstrate empirically the promise of the
proposed edge deletion technique as a basis for approximate inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1371</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1371</id><created>2012-07-04</created><authors><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Dwork</keyname><forenames>Cynthia</forenames></author><author><keyname>McSherry</keyname><forenames>Frank</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author></authors><title>On Privacy-Preserving Histograms</title><categories>cs.DS</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-120-127</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We advance the approach initiated by Chawla et al. for sanitizing (census)
data so as to preserve the privacy of respondents while simultaneously
extracting &quot;useful&quot; statistical information. First, we extend the scope of
their techniques to a broad and rich class of distributions, specifically,
mixtures of highdimensional balls, spheres, Gaussians, and other &quot;nice&quot;
distributions. Second, we randomize the histogram constructions to preserve
spatial characteristics of the data, allowing us to approximate various
quantities of interest, e.g., cost of the minimum spanning tree on the data, in
a privacy-preserving fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1372</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1372</id><created>2012-07-04</created><authors><author><keyname>Chavira</keyname><forenames>Mark</forenames></author><author><keyname>Allen</keyname><forenames>David</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>Exploiting Evidence in Probabilistic Inference</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-112-119</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the notion of compiling a Bayesian network with evidence and
provide a specific approach for evidence-based compilation, which makes use of
logical processing. The approach is practical and advantageous in a number of
application areas-including maximum likelihood estimation, sensitivity
analysis, and MAP computations-and we provide specific empirical results in the
domain of genetic linkage analysis. We also show that the approach is
applicable for networks that do not contain determinism, and show that it
empirically subsumes the performance of the quickscore algorithm when applied
to noisy-or networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1373</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1373</id><created>2012-07-04</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Jhala</keyname><forenames>Ranjit</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author></authors><title>Counterexample-guided Planning</title><categories>cs.AI cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-104-111</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planning in adversarial and uncertain environments can be modeled as the
problem of devising strategies in stochastic perfect information games. These
games are generalizations of Markov decision processes (MDPs): there are two
(adversarial) players, and a source of randomness. The main practical obstacle
to computing winning strategies in such games is the size of the state space.
In practice therefore, one typically works with abstractions of the model. The
diffculty is to come up with an abstraction that is neither too coarse to
remove all winning strategies (plans), nor too fine to be intractable. In
verification, the paradigm of counterexample-guided abstraction refinement has
been successful to construct useful but parsimonious abstractions
automatically. We extend this paradigm to probabilistic models (namely, perfect
information games and, as a special case, MDPs). This allows us to apply the
counterexample-guided abstraction paradigm to the AI planning problem. As
special cases, we get planning algorithms for MDPs and deterministic systems
that automatically construct system abstractions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1374</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1374</id><created>2012-07-04</created><authors><author><keyname>Carlson</keyname><forenames>Jennifer</forenames></author><author><keyname>Murphy</keyname><forenames>Robin R.</forenames></author></authors><title>Use of Dempster-Shafer Conflict Metric to Detect Interpretation
  Inconsistency</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-94-104</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model of the world built from sensor data may be incorrect even if the
sensors are functioning correctly. Possible causes include the use of
inappropriate sensors (e.g. a laser looking through glass walls), sensor
inaccuracies accumulate (e.g. localization errors), the a priori models are
wrong, or the internal representation does not match the world (e.g. a static
occupancy grid used with dynamically moving objects). We are interested in the
case where the constructed model of the world is flawed, but there is no access
to the ground truth that would allow the system to see the discrepancy, such as
a robot entering an unknown environment. This paper considers the problem of
determining when something is wrong using only the sensor data used to
construct the world model. It proposes 11 interpretation inconsistency
indicators based on the Dempster-Shafer conflict metric, Con, and evaluates
these indicators according to three criteria: ability to distinguish true
inconsistency from sensor noise (classification), estimate the magnitude of
discrepancies (estimation), and determine the source(s) (if any) of sensing
problems in the environment (isolation). The evaluation is conducted using data
from a mobile robot with sonar and laser range sensors navigating indoor
environments under controlled conditions. The evaluation shows that the Gambino
indicator performed best in terms of estimation (at best 0.77 correlation),
isolation, and classification of the sensing situation as degraded (7% false
negative rate) or normal (0% false positive rate).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1375</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1375</id><created>2012-07-04</created><authors><author><keyname>Carbonetto</keyname><forenames>Peter</forenames></author><author><keyname>Kisynski</keyname><forenames>Jacek</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author><author><keyname>Poole</keyname><forenames>David L</forenames></author></authors><title>Nonparametric Bayesian Logic</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-85-93</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Bayesian Logic (BLOG) language was recently developed for defining
first-order probability models over worlds with unknown numbers of objects. It
handles important problems in AI, including data association and population
estimation. This paper extends BLOG by adopting generative processes over
function spaces - known as nonparametrics in the Bayesian literature. We
introduce syntax for reasoning about arbitrary collections of objects, and
their properties, in an intuitive manner. By exploiting exchangeability,
distributions over unknown objects and their attributes are cast as Dirichlet
processes, which resolve difficulties in model selection and inference caused
by varying numbers of objects. We demonstrate these concepts with application
to citation matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1376</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1376</id><created>2012-07-04</created><authors><author><keyname>Cai</keyname><forenames>Zhihong</forenames></author><author><keyname>Kuroki</keyname><forenames>Manabu</forenames></author></authors><title>Counterfactual Reasoning in Linear Structural Equation Models</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-77-84</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the case where causal relations among variables can be described as
a Gaussian linear structural equation model. This paper deals with the problem
of clarifying how the variance of a response variable would have changed if a
treatment variable were assigned to some value (counterfactually), given that a
set of variables is observed (actually). In order to achieve this aim, we
reformulate the formulas of the counterfactual distribution proposed by Balke
and Pearl (1995) through both the total effects and a covariance matrix of
observed variables. We further extend the framework of Balke and Pearl (1995)
from point observations to interval observations, and from an unconditional
plan to a conditional plan. The results of this paper enable us to clarify the
properties of counterfactual distribution and establish an optimal plan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1377</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1377</id><created>2012-07-04</created><authors><author><keyname>Brzostowski</keyname><forenames>Jakub</forenames></author><author><keyname>Kowalczyk</keyname><forenames>Ryszard</forenames></author></authors><title>Efficient algorithm for estimation of qualitative expected utility in
  possibilistic case-based reasoning</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-69-76</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient algorithm for estimation of possibility based
qualitative expected utility. It is useful for decision making mechanisms where
each possible decision is assigned a multi-attribute possibility distribution.
The computational complexity of ordinary methods calculating the expected
utility based on discretization is growing exponentially with the number of
attributes, and may become infeasible with a high number of these attributes.
We present series of theorems and lemmas proving the correctness of our
algorithm that exibits a linear computational complexity. Our algorithm has
been applied in the context of selecting the most prospective partners in
multi-party multi-attribute negotiation, and can also be used in making
decisions about potential offers during the negotiation as other similar
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1378</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1378</id><created>2012-07-04</created><authors><author><keyname>Kang</keyname><forenames>Changsung</forenames></author><author><keyname>Tian</keyname><forenames>Jin</forenames></author></authors><title>Local Markov Property for Models Satisfying Composition Axiom</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-284-291</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The local Markov condition for a DAG to be an independence map of a
probability distribution is well known. For DAGs with latent variables,
represented as bi-directed edges in the graph, the local Markov property may
invoke exponential number of conditional independencies. This paper shows that
the number of conditional independence relations required may be reduced if the
probability distributions satisfy the composition axiom. In certain types of
graphs, only linear number of conditional independencies are required. The
result has applications in testing linear structural equation models with
correlated errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1379</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1379</id><created>2012-07-04</created><authors><author><keyname>Ho</keyname><forenames>Shen-Shyang</forenames></author><author><keyname>Wechsler</keyname><forenames>Harry</forenames></author></authors><title>On the Detection of Concept Changes in Time-Varying Data Stream by
  Testing Exchangeability</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-267-274</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A martingale framework for concept change detection based on testing data
exchangeability was recently proposed (Ho, 2005). In this paper, we describe
the proposed change-detection test based on the Doob's Maximal Inequality and
show that it is an approximation of the sequential probability ratio test
(SPRT). The relationship between the threshold value used in the proposed test
and its size and power is deduced from the approximation. The mean delay time
before a change is detected is estimated using the average sample number of a
SPRT. The performance of the test using various threshold values is examined on
five different data stream scenarios simulated using two synthetic data sets.
Finally, experimental results show that the test is effective in detecting
changes in time-varying data streams simulated using three benchmark data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1380</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1380</id><created>2012-07-04</created><authors><author><keyname>Harva</keyname><forenames>Markus</forenames></author><author><keyname>Raiko</keyname><forenames>Tapani</forenames></author><author><keyname>Honkela</keyname><forenames>Antti</forenames></author><author><keyname>Valpola</keyname><forenames>Harri</forenames></author><author><keyname>Karhunen</keyname><forenames>Juha</forenames></author></authors><title>Bayes Blocks: An Implementation of the Variational Bayesian Building
  Blocks Framework</title><categories>cs.MS cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-259-266</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A software library for constructing and learning probabilistic models is
presented. The library offers a set of building blocks from which a large
variety of static and dynamic models can be built. These include hierarchical
models for variances of other variables and many nonlinear models. The
underlying variational Bayesian machinery, providing for fast and robust
estimation but being mathematically rather involved, is almost completely
hidden from the user thus making it very easy to use the library. The building
blocks include Gaussian, rectified Gaussian and mixture-of-Gaussians variables
and computational nodes which can be combined rather freely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1381</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1381</id><created>2012-07-04</created><authors><author><keyname>Hammid</keyname><forenames>Rafay</forenames></author><author><keyname>Maddi</keyname><forenames>Siddhartha</forenames></author><author><keyname>Johnson</keyname><forenames>Amos</forenames></author><author><keyname>Bobick</keyname><forenames>Aaron</forenames></author><author><keyname>Essa</keyname><forenames>Irfan</forenames></author><author><keyname>Isbell</keyname><forenames>Charles Lee</forenames></author></authors><title>Unsupervised Activity Discovery and Characterization From Event-Streams</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-251-258</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework to discover and characterize different classes of
everyday activities from event-streams. We begin by representing activities as
bags of event n-grams. This allows us to analyze the global structural
information of activities, using their local event statistics. We demonstrate
how maximal cliques in an undirected edge-weighted graph of activities, can be
used for activity-class discovery in an unsupervised manner. We show how
modeling an activity as a variable length Markov process, can be used to
discover recurrent event-motifs to characterize the discovered
activity-classes. We present results over extensive data-sets, collected from
multiple active environments, to show the competence and generalizability of
our proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1382</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1382</id><created>2012-07-04</created><authors><author><keyname>Guo</keyname><forenames>Yuhong</forenames></author><author><keyname>Wilkinson</keyname><forenames>Dana</forenames></author><author><keyname>Schuurmans</keyname><forenames>Dale</forenames></author></authors><title>Maximum Margin Bayesian Networks</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-233-242</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning Bayesian network classifiers that
maximize the marginover a set of classification variables. We find that this
problem is harder for Bayesian networks than for undirected graphical models
like maximum margin Markov networks. The main difficulty is that the parameters
in a Bayesian network must satisfy additional normalization constraints that an
undirected graphical model need not respect. These additional constraints
complicate the optimization task. Nevertheless, we derive an effective training
algorithm that solves the maximum margin training problem for a range of
Bayesian network topologies, and converges to an approximate solution for
arbitrary network topologies. Experimental results show that the method can
demonstrate improved generalization performance over Markov networks when the
directed graphical structure encodes relevant knowledge. In practice, the
training technique allows one to combine prior knowledge expressed as a
directed (causal) model with state of the art discriminative learning methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1383</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1383</id><created>2012-07-04</created><authors><author><keyname>Greco</keyname><forenames>Gianluigi</forenames></author><author><keyname>Scarcello</keyname><forenames>Francesco</forenames></author></authors><title>Bounding the Uncertainty of Graphical Games: The Complexity of Simple
  Requirements, Pareto and Strong Nash Equilibria</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-225-232</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the complexity of bounding the uncertainty of graphical games,
and we provide new insight into the intrinsic difficulty of computing Nash
equilibria. In particular, we show that, if one adds very simple and natural
additional requirements to a graphical game, the existence of Nash equilibria
is no longer guaranteed, and computing an equilibrium is an intractable
problem. Moreover, if stronger equilibrium conditions are required for the
game, we get hardness results for the second level of the polynomial hierarchy.
Our results offer a clear picture of the complexity of mixed Nash equilibria in
graphical games, and answer some open research questions posed by Conitzer and
Sandholm (2003).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1384</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1384</id><created>2012-07-04</created><authors><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author><author><keyname>Bidyuk</keyname><forenames>Bozhena</forenames></author><author><keyname>Rindt</keyname><forenames>Craig</forenames></author><author><keyname>Marca</keyname><forenames>James</forenames></author></authors><title>Modeling Transportation Routines using Hybrid Dynamic Mixed Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-217-224</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a general framework called Hybrid Dynamic Mixed Networks
(HDMNs) which are Hybrid Dynamic Bayesian Networks that allow representation of
discrete deterministic information in the form of constraints. We propose
approximate inference algorithms that integrate and adjust well known
algorithmic principles such as Generalized Belief Propagation,
Rao-Blackwellised Particle Filtering and Constraint Propagation to address the
complexity of modeling and reasoning in HDMNs. We use this framework to model a
person's travel activity over time and to predict destination and routes given
the current location. We present a preliminary empirical evaluation
demonstrating the effectiveness of our modeling framework and algorithms using
several variants of the activity model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1385</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1385</id><created>2012-07-04</created><authors><author><keyname>Gogate</keyname><forenames>Vibhav</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>Approximate Inference Algorithms for Hybrid Bayesian Networks with
  Discrete Constraints</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-209-216</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider Hybrid Mixed Networks (HMN) which are Hybrid
Bayesian Networks that allow discrete deterministic information to be modeled
explicitly in the form of constraints. We present two approximate inference
algorithms for HMNs that integrate and adjust well known algorithmic principles
such as Generalized Belief Propagation, Rao-Blackwellised Importance Sampling
and Constraint Propagation to address the complexity of modeling and reasoning
in HMNs. We demonstrate the performance of our approximate inference algorithms
on randomly generated HMNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1386</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1386</id><created>2012-07-04</created><authors><author><keyname>Ferns</keyname><forenames>Norman</forenames></author><author><keyname>Panangaden</keyname><forenames>Prakash</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>Metrics for Markov Decision Processes with Infinite State Spaces</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-201-208</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present metrics for measuring state similarity in Markov decision
processes (MDPs) with infinitely many states, including MDPs with continuous
state spaces. Such metrics provide a stable quantitative analogue of the notion
of bisimulation for MDPs, and are suitable for use in MDP approximation. We
show that the optimal value function associated with a discounted infinite
horizon planning task varies continuously with respect to our metric distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1387</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1387</id><created>2012-07-04</created><authors><author><keyname>Feelders</keyname><forenames>Ad</forenames></author><author><keyname>van der Gaag</keyname><forenames>Linda C.</forenames></author></authors><title>Learning Bayesian Network Parameters with Prior Knowledge about
  Context-Specific Qualitative Influences</title><categories>cs.AI cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-193-200</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for learning the parameters of a Bayesian network with
prior knowledge about the signs of influences between variables. Our method
accommodates not just the standard signs, but provides for context-specific
signs as well. We show how the various signs translate into order constraints
on the network parameters and how isotonic regression can be used to compute
order-constrained estimates from the available data. Our experimental results
show that taking prior knowledge about the signs of influences into account
leads to an improved fit of the true distribution, especially when only a small
sample of data is available. Moreover, the computed estimates are guaranteed to
be consistent with the specified signs, thereby resulting in a network that is
more likely to be accepted by experts in its domain of application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1388</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1388</id><created>2012-07-04</created><authors><author><keyname>Even-Dar</keyname><forenames>Eyal</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Mansour</keyname><forenames>Yishay</forenames></author></authors><title>Planning in POMDPs Using Multiplicity Automata</title><categories>cs.AI cs.FL</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-185-192</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planning and learning in Partially Observable MDPs (POMDPs) are among the
most challenging tasks in both the AI and Operation Research communities.
Although solutions to these problems are intractable in general, there might be
special cases, such as structured POMDPs, which can be solved efficiently. A
natural and possibly efficient way to represent a POMDP is through the
predictive state representation (PSR) - a representation which recently has
been receiving increasing attention. In this work, we relate POMDPs to
multiplicity automata- showing that POMDPs can be represented by multiplicity
automata with no increase in the representation size. Furthermore, we show that
the size of the multiplicity automaton is equal to the rank of the predictive
state representation. Therefore, we relate both the predictive state
representation and POMDPs to the well-founded multiplicity automata literature.
Based on the multiplicity automata representation, we provide a planning
algorithm which is exponential only in the multiplicity automata rank rather
than the number of states of the POMDP. As a result, whenever the predictive
state representation is logarithmic in the standard POMDP representation, our
planning algorithm is efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1389</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1389</id><created>2012-07-04</created><authors><author><keyname>Eberhardt</keyname><forenames>Frederick</forenames></author><author><keyname>Glymour</keyname><forenames>Clark</forenames></author><author><keyname>Scheines</keyname><forenames>Richard</forenames></author></authors><title>On the Number of Experiments Sufficient and in the Worst Case Necessary
  to Identify All Causal Relations Among N Variables</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-178-184</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that if any number of variables are allowed to be simultaneously and
independently randomized in any one experiment, log2(N) + 1 experiments are
sufficient and in the worst case necessary to determine the causal relations
among N &gt;= 2 variables when no latent variables, no sample selection bias and
no feedback cycles are present. For all K, 0 &lt; K &lt; 1/(2N) we provide an upper
bound on the number experiments required to determine causal structure when
each experiment simultaneously randomizes K variables. For large N, these
bounds are significantly lower than the N - 1 bound required when each
experiment randomizes at most one variable. For kmax &lt; N/2, we show that
(N/kmax-1)+N/(2kmax)log2(kmax) experiments aresufficient and in the worst case
necessary. We over a conjecture as to the minimal number of experiments that
are in the worst case sufficient to identify all causal relations among N
observed variables that are a subset of the vertices of a DAG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1390</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1390</id><created>2012-07-04</created><authors><author><keyname>Domshlak</keyname><forenames>Carmel</forenames></author><author><keyname>Joachims</keyname><forenames>Thorsten</forenames></author></authors><title>Unstructuring User Preferences: Efficient Non-Parametric Utility
  Revelation</title><categories>cs.AI cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-169-177</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tackling the problem of ordinal preference revelation and reasoning, we
propose a novel methodology for generating an ordinal utility function from a
set of qualitative preference statements. To the best of our knowledge, our
proposal constitutes the first nonparametric solution for this problem that is
both efficient and semantically sound. Our initial experiments provide strong
evidence for practical effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1391</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1391</id><created>2012-07-04</created><authors><author><keyname>Liu</keyname><forenames>Yaxin</forenames></author><author><keyname>Koenig</keyname><forenames>Sven</forenames></author></authors><title>Existence and Finiteness Conditions for Risk-Sensitive Planning: Results
  and Conjectures</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-354-363</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decision-theoretic planning with risk-sensitive planning objectives is
important for building autonomous agents or decision-support systems for
real-world applications. However, this line of research has been largely
ignored in the artificial intelligence and operations research communities
since planning with risk-sensitive planning objectives is more complicated than
planning with risk-neutral planning objectives. To remedy this situation, we
derive conditions that guarantee that the optimal expected utilities of the
total plan-execution reward exist and are finite for fully observable Markov
decision process models with non-linear utility functions. In case of Markov
decision process models with both positive and negative rewards, most of our
results hold for stationary policies only, but we conjecture that they can be
generalized to non stationary policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1392</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1392</id><created>2012-07-04</created><authors><author><keyname>Kuroki</keyname><forenames>Manabu</forenames></author><author><keyname>Cai</keyname><forenames>Zhihong</forenames></author><author><keyname>Motogaito</keyname><forenames>Hiroki</forenames></author></authors><title>The Graphical Identification for Total Effects by using Surrogate
  Variables</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-340-345</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the case where cause-effect relationships between variables can be
described as a directed acyclic graph and the corresponding linear structural
equation model. This paper provides graphical identifiability criteria for
total effects by using surrogate variables in the case where it is difficult to
observe a treatment/response variable. The results enable us to judge from
graph structure whether a total effect can be identified through the
observation of surrogate variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1393</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1393</id><created>2012-07-04</created><authors><author><keyname>Kuck</keyname><forenames>Hendrik</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Learning about individuals from group statistics</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-332-339</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new problem formulation which is similar to, but more
informative than, the binary multiple-instance learning problem. In this
setting, we are given groups of instances (described by feature vectors) along
with estimates of the fraction of positively-labeled instances per group. The
task is to learn an instance level classifier from this information. That is,
we are trying to estimate the unknown binary labels of individuals from
knowledge of group statistics. We propose a principled probabilistic model to
solve this problem that accounts for uncertainty in the parameters and in the
unknown individual labels. This model is trained with an efficient MCMC
algorithm. Its performance is demonstrated on both synthetic and real-world
data arising in general object recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1394</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1394</id><created>2012-07-04</created><authors><author><keyname>Krause</keyname><forenames>Andreas</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos E.</forenames></author></authors><title>Near-optimal Nonmyopic Value of Information in Graphical Models</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-324-331</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental issue in real-world systems, such as sensor networks, is the
selection of observations which most effectively reduce uncertainty. More
specifically, we address the long standing problem of nonmyopically selecting
the most informative subset of variables in a graphical model. We present the
first efficient randomized algorithm providing a constant factor
(1-1/e-epsilon) approximation guarantee for any epsilon &gt; 0 with high
confidence. The algorithm leverages the theory of submodular functions, in
combination with a polynomial bound on sample complexity. We furthermore prove
that no polynomial time algorithm can provide a constant factor approximation
better than (1 - 1/e) unless P = NP. Finally, we provide extensive evidence of
the effectiveness of our method on two complex real-world datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1395</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1395</id><created>2012-07-04</created><authors><author><keyname>Kolmogorov</keyname><forenames>Vladimir</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin</forenames></author></authors><title>On the optimality of tree-reweighted max-product message-passing</title><categories>cs.AI cs.DS</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-316-323</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tree-reweighted max-product (TRW) message passing is a modified form of the
ordinary max-product algorithm for attempting to find minimal energy
configurations in Markov random field with cycles. For a TRW fixed point
satisfying the strong tree agreement condition, the algorithm outputs a
configuration that is provably optimal. In this paper, we focus on the case of
binary variables with pairwise couplings, and establish stronger properties of
TRW fixed points that satisfy only the milder condition of weak tree agreement
(WTA). First, we demonstrate how it is possible to identify part of the optimal
solution|i.e., a provably optimal solution for a subset of nodes| without
knowing a complete solution. Second, we show that for submodular functions, a
WTA fixed point always yields a globally optimal solution. We establish that
for binary variables, any WTA fixed point always achieves the global maximum of
the linear programming relaxation underlying the TRW method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1396</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1396</id><created>2012-07-04</created><authors><author><keyname>Klaas</keyname><forenames>Mike</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author><author><keyname>Doucet</keyname><forenames>Arnaud</forenames></author></authors><title>Toward Practical N2 Monte Carlo: the Marginal Particle Filter</title><categories>stat.CO cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-308-315</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential Monte Carlo techniques are useful for state estimation in
non-linear, non-Gaussian dynamic models. These methods allow us to approximate
the joint posterior distribution using sequential importance sampling. In this
framework, the dimension of the target distribution grows with each time step,
thus it is necessary to introduce some resampling steps to ensure that the
estimates provided by the algorithm have a reasonable variance. In many
applications, we are only interested in the marginal filtering distribution
which is defined on a space of fixed dimension. We present a Sequential Monte
Carlo algorithm called the Marginal Particle Filter which operates directly on
the marginal distribution, hence avoiding having to perform importance sampling
on a space of growing dimension. Using this idea, we also derive an improved
version of the auxiliary particle filter. We show theoretic and empirical
results which demonstrate a reduction in variance over conventional particle
filtering, and present techniques for reducing the cost of the marginal
particle filter with N particles from O(N2) to O(N logN).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1397</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1397</id><created>2012-07-04</created><authors><author><keyname>Qi</keyname><forenames>Guilin</forenames></author><author><keyname>Liu</keyname><forenames>Weiru</forenames></author><author><keyname>Bell</keyname><forenames>David A.</forenames></author></authors><title>A Revision-Based Approach to Resolving Conflicting Information</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-477-484</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a revision-based approach for conflict resolution
by generalizing the Disjunctive Maxi-Adjustment (DMA) approach (Benferhat et
al. 2004). Revision operators can be classified into two different families:
the model-based ones and the formula-based ones. So the revision-based approach
has two different versions according to which family of revision operators is
chosen. Two particular revision operators are considered, one is the Dalal's
revision operator, which is a model-based revision operator, and the other is
the cardinality-maximal based revision operator, which is a formulabased
revision operator. When the Dalal's revision operator is chosen, the
revision-based approach is independent of the syntactic form in each stratum
and it captures some notion of minimal change. When the cardinalitymaximal
based revision operator is chosen, the revision-based approach is equivalent to
the DMA approach. We also show that both approaches are computationally easier
than the DMA approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1398</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1398</id><created>2012-07-04</created><authors><author><keyname>Pfeffer</keyname><forenames>Avi</forenames></author><author><keyname>Tai</keyname><forenames>Terry</forenames></author></authors><title>Asynchronous Dynamic Bayesian Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-467-476</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Systems such as sensor networks and teams of autonomous robots consist of
multiple autonomous entities that interact with each other in a distributed,
asynchronous manner. These entities need to keep track of the state of the
system as it evolves. Asynchronous systems lead to special challenges for
monitoring, as nodes must update their beliefs independently of each other and
no central coordination is possible. Furthermore, the state of the system
continues to change as beliefs are being updated. Previous approaches to
developing distributed asynchronous probabilistic reasoning systems have used
static models. We present an approach using dynamic models, that take into
account the way the system changes state over time. Our approach, which is
based on belief propagation, is fully distributed and asynchronous, and allows
the world to keep on changing as messages are being sent around. Experimental
results show that our approach compares favorably to the factored frontier
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1399</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1399</id><created>2012-07-04</created><authors><author><keyname>Paskin</keyname><forenames>Mark</forenames></author><author><keyname>Thrun</keyname><forenames>Sebastian</forenames></author></authors><title>Robotic Mapping with Polygonal Random Fields</title><categories>cs.RO cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-450-458</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two types of probabilistic maps are popular in the mobile robotics
literature: occupancy grids and geometric maps. Occupancy grids have the
advantages of simplicity and speed, but they represent only a restricted class
of maps and they make incorrect independence assumptions. On the other hand,
current geometric approaches, which characterize the environment by features
such as line segments, can represent complex environments compactly. However,
they do not reason explicitly about occupancy, a necessity for motion planning;
and, they lack a complete probability model over environmental structures. In
this paper we present a probabilistic mapping technique based on polygonal
random fields (PRF), which combines the advantages of both approaches. Our
approach explicitly represents occupancy using a geometric representation, and
it is based upon a consistent probability distribution over environments which
avoids the incorrect independence assumptions made by occupancy grids. We show
how sampling techniques for PRFs can be applied to localized laser and sonar
data, and we demonstrate significant improvements in mapping performance over
occupancy grids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1400</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1400</id><created>2012-07-04</created><authors><author><keyname>Osepayshvili</keyname><forenames>Anna</forenames></author><author><keyname>Wellman</keyname><forenames>Michael P.</forenames></author><author><keyname>Reeves</keyname><forenames>Daniel</forenames></author><author><keyname>MacKie-Mason</keyname><forenames>Jeffrey K.</forenames></author></authors><title>Self-Confirming Price Prediction for Bidding in Simultaneous Ascending
  Auctions</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-441-449</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simultaneous ascending auctions present agents with the exposure problem:
bidding to acquire a bundle risks the possibility of obtaining an undesired
subset of the goods. Auction theory provides little guidance for dealing with
this problem. We present a new family of decisiontheoretic bidding strategies
that use probabilistic predictions of final prices. We focus on selfconfirming
price distribution predictions, which by definition turn out to be correct when
all agents bid decision-theoretically based on them. Bidding based on these is
provably not optimal in general, but our experimental evidence indicates the
strategy can be quite effective compared to other known methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1401</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1401</id><created>2012-07-04</created><authors><author><keyname>Nodelman</keyname><forenames>Uri</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author><author><keyname>Shelton</keyname><forenames>Christian R.</forenames></author></authors><title>Expectation Propagation for Continuous Time Bayesian Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-431-440</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous time Bayesian networks (CTBNs) describe structured stochastic
processes with finitely many states that evolve over continuous time. A CTBN is
a directed (possibly cyclic) dependency graph over a set of variables, each of
which represents a finite state continuous time Markov process whose transition
model is a function of its parents. As shown previously, exact inference in
CTBNs is intractable. We address the problem of approximate inference, allowing
for general queries conditioned on evidence over continuous time intervals and
at discrete time points. We show how CTBNs can be parameterized within the
exponential family, and use that insight to develop a message passing scheme in
cluster graphs and allows us to apply expectation propagation to CTBNs. The
clusters in our cluster graph do not contain distributions over the cluster
variables at individual time points, but distributions over trajectories of the
variables throughout a duration. Thus, unlike discrete time temporal models
such as dynamic Bayesian networks, we can adapt the time granularity at which
we reason for different variables and in different conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1402</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1402</id><created>2012-07-04</created><authors><author><keyname>Nodelman</keyname><forenames>Uri</forenames></author><author><keyname>Shelton</keyname><forenames>Christian R.</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author></authors><title>Expectation Maximization and Complex Duration Distributions for
  Continuous Time Bayesian Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-421-430</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous time Bayesian networks (CTBNs) describe structured stochastic
processes with finitely many states that evolve over continuous time. A CTBN is
a directed (possibly cyclic) dependency graph over a set of variables, each of
which represents a finite state continuous time Markov process whose transition
model is a function of its parents. We address the problem of learning the
parameters and structure of a CTBN from partially observed data. We show how to
apply expectation maximization (EM) and structural expectation maximization
(SEM) to CTBNs. The availability of the EM algorithm allows us to extend the
representation of CTBNs to allow a much richer class of transition durations
distributions, known as phase distributions. This class is a highly expressive
semi-parametric representation, which can approximate any duration distribution
arbitrarily closely. This extension to the CTBN framework addresses one of the
main limitations of both CTBNs and DBNs - the restriction to exponentially /
geometrically distributed duration. We present experimental results on a real
data set of people's life spans, showing that our algorithm learns reasonable
models - structure and parameters - from partially observed data, and, with the
use of phase distributions, achieves better performance than DBNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1403</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1403</id><created>2012-07-04</created><authors><author><keyname>Niculescu-Mizil</keyname><forenames>Alexandru</forenames></author><author><keyname>Caruana</keyname><forenames>Richard A.</forenames></author></authors><title>Obtaining Calibrated Probabilities from Boosting</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-413-420</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosted decision trees typically yield good accuracy, precision, and ROC
area. However, because the outputs from boosting are not well calibrated
posterior probabilities, boosting yields poor squared error and cross-entropy.
We empirically demonstrate why AdaBoost predicts distorted probabilities and
examine three calibration methods for correcting this distortion: Platt
Scaling, Isotonic Regression, and Logistic Correction. We also experiment with
boosting using log-loss instead of the usual exponential loss. Experiments show
that Logistic Correction and boosting with log-loss work well when boosting
weak models such as decision stumps, but yield poor performance when boosting
more complex models such as full decision trees. Platt Scaling and Isotonic
Regression, however, significantly improve the probabilities predicted by
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1404</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1404</id><created>2012-07-04</created><authors><author><keyname>Narasimhan</keyname><forenames>Mukund</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author></authors><title>A submodular-supermodular procedure with applications to discriminative
  structure learning</title><categories>cs.LG cs.DS stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-404-412</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an algorithm for minimizing the difference between
two submodular functions using a variational framework which is based on (an
extension of) the concave-convex procedure [17]. Because several commonly used
metrics in machine learning, like mutual information and conditional mutual
information, are submodular, the problem of minimizing the difference of two
submodular problems arises naturally in many machine learning applications. Two
such applications are learning discriminatively structured graphical models and
feature selection under computational complexity constraints. A commonly used
metric for measuring discriminative capacity is the EAR measure which is the
difference between two conditional mutual information terms. Feature selection
taking complexity considerations into account also fall into this framework
because both the information that a set of features provide and the cost of
computing and using the features can be modeled as submodular functions. This
problem is NP-hard, and we give a polynomial time heuristic for it. We also
present results on synthetic data to show that classifiers based on
discriminative graphical models using this algorithm can significantly
outperform classifiers based on generative graphical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1405</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1405</id><created>2012-07-04</created><authors><author><keyname>Mooij</keyname><forenames>Joris</forenames></author><author><keyname>Kappen</keyname><forenames>Hilbert</forenames></author></authors><title>Sufficient conditions for convergence of Loopy Belief Propagation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-396-403</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive novel sufficient conditions for convergence of Loopy Belief
Propagation (also known as the Sum-Product algorithm) to a unique fixed point.
Our results improve upon previously known conditions. For binary variables with
(anti-)ferromagnetic interactions, our conditions seem to be sharp.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1406</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1406</id><created>2012-07-04</created><authors><author><keyname>McCallum</keyname><forenames>Andrew</forenames></author><author><keyname>Bellare</keyname><forenames>Kedar</forenames></author><author><keyname>Pereira</keyname><forenames>Fernando</forenames></author></authors><title>A Conditional Random Field for Discriminatively-trained Finite-state
  String Edit Distance</title><categories>cs.LG cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-388-395</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The need to measure sequence similarity arises in information extraction,
object identity, data mining, biological sequence analysis, and other domains.
This paper presents discriminative string-edit CRFs, a finitestate conditional
random field model for edit sequences between strings. Conditional random
fields have advantages over generative approaches to this problem, such as pair
HMMs or the work of Ristad and Yianilos, because as conditionally-trained
methods, they enable the use of complex, arbitrary actions and features of the
input strings. As in generative models, the training data does not have to
specify the edit sequences between the given string pairs. Unlike generative
models, however, our model is trained on both positive and negative instances
of string pairs. We present positive experimental results on several data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1407</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1407</id><created>2012-07-04</created><authors><author><keyname>Mateescu</keyname><forenames>Robert</forenames></author><author><keyname>Dechter</keyname><forenames>Rina</forenames></author></authors><title>The Relationship Between AND/OR Search and Variable Elimination</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-380-387</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we compare search and inference in graphical models through the
new framework of AND/OR search. Specifically, we compare Variable Elimination
(VE) and memoryintensive AND/OR Search (AO) and place algorithms such as
graph-based backjumping and no-good and good learning, as well as Recursive
Conditioning [7] and Value Elimination [2] within the AND/OR search framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1408</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1408</id><created>2012-07-04</created><authors><author><keyname>Mahadevan</keyname><forenames>Sridhar</forenames></author></authors><title>Representation Policy Iteration</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-372-379</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses a fundamental issue central to approximation methods for
solving large Markov decision processes (MDPs): how to automatically learn the
underlying representation for value function approximation? A novel
theoretically rigorous framework is proposed that automatically generates
geometrically customized orthonormal sets of basis functions, which can be used
with any approximate MDP solver like least squares policy iteration (LSPI). The
key innovation is a coordinate-free representation of value functions, using
the theory of smooth functions on a Riemannian manifold. Hodge theory yields a
constructive method for generating basis functions for approximating value
functions based on the eigenfunctions of the self-adjoint (Laplace-Beltrami)
operator on manifolds. In effect, this approach performs a global Fourier
analysis on the state space graph to approximate value functions, where the
basis functions reflect the largescale topology of the underlying state space.
A new class of algorithms called Representation Policy Iteration (RPI) are
presented that automatically learn both basis functions and approximately
optimal policies. Illustrative experiments compare the performance of RPI with
that of LSPI using two handcoded basis functions (RBF and polynomial state
encodings).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1409</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1409</id><created>2012-07-04</created><authors><author><keyname>Sutton</keyname><forenames>Charles</forenames></author><author><keyname>McCallum</keyname><forenames>Andrew</forenames></author></authors><title>Piecewise Training for Undirected Models</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-568-575</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For many large undirected models that arise in real-world applications, exact
maximumlikelihood training is intractable, because it requires computing
marginal distributions of the model. Conditional training is even more
difficult, because the partition function depends not only on the parameters,
but also on the observed input, requiring repeated inference over each training
example. An appealing idea for such models is to independently train a local
undirected classifier over each clique, afterwards combining the learned
weights into a single global model. In this paper, we show that this piecewise
method can be justified as minimizing a new family of upper bounds on the log
partition function. On three natural-language data sets, piecewise training is
more accurate than pseudolikelihood, and often performs comparably to global
training using belief propagation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1410</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1410</id><created>2012-07-04</created><authors><author><keyname>Straccia</keyname><forenames>Umberto</forenames></author></authors><title>Description Logics with Fuzzy Concrete Domains</title><categories>cs.AI cs.LO</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-559-567</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fuzzy version of description logics with concrete domains. Main
features are: (i) concept constructors are based on t-norm, t-conorm, negation
and implication; (ii) concrete domains are fuzzy sets; (iii) fuzzy modifiers
are allowed; and (iv) the reasoning algorithm is based on a mixture of
completion rules and bounded mixed integer programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1411</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1411</id><created>2012-07-04</created><authors><author><keyname>Southey</keyname><forenames>Finnegan</forenames></author><author><keyname>Bowling</keyname><forenames>Michael P.</forenames></author><author><keyname>Larson</keyname><forenames>Bryce</forenames></author><author><keyname>Piccione</keyname><forenames>Carmelo</forenames></author><author><keyname>Burch</keyname><forenames>Neil</forenames></author><author><keyname>Billings</keyname><forenames>Darse</forenames></author><author><keyname>Rayner</keyname><forenames>Chris</forenames></author></authors><title>Bayes' Bluff: Opponent Modelling in Poker</title><categories>cs.GT cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-550-558</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Poker is a challenging problem for artificial intelligence, with
non-deterministic dynamics, partial observability, and the added difficulty of
unknown adversaries. Modelling all of the uncertainties in this domain is not
an easy task. In this paper we present a Bayesian probabilistic model for a
broad class of poker games, separating the uncertainty in the game dynamics
from the uncertainty of the opponent's strategy. We then describe approaches to
two key subproblems: (i) inferring a posterior over opponent strategies given a
prior distribution and observations of their play, and (ii) playing an
appropriate response to that distribution. We demonstrate the overall approach
on a reduced version of poker using Dirichlet priors and then on the full game
of Texas hold'em using a more informed prior. We demonstrate methods for
playing effective responses to the opponent, based on the posterior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1412</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1412</id><created>2012-07-04</created><authors><author><keyname>Smith</keyname><forenames>Trey</forenames></author><author><keyname>Simmons</keyname><forenames>Reid</forenames></author></authors><title>Point-Based POMDP Algorithms: Improved Analysis and Implementation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-542-549</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing complexity bounds for point-based POMDP value iteration algorithms
focus either on the curse of dimensionality or the curse of history. We derive
a new bound that relies on both and uses the concept of discounted
reachability; our conclusions may help guide future algorithm design. We also
discuss recent improvements to our (point-based) heuristic search value
iteration algorithm. Our new implementation calculates tighter initial bounds,
avoids solving linear programs, and makes more effective use of sparsity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1413</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1413</id><created>2012-07-04</created><authors><author><keyname>Shimizu</keyname><forenames>Shohei</forenames></author><author><keyname>Hyvarinen</keyname><forenames>Aapo</forenames></author><author><keyname>Kano</keyname><forenames>Yutaka</forenames></author><author><keyname>Hoyer</keyname><forenames>Patrik O.</forenames></author></authors><title>Discovery of non-gaussian linear causal models using ICA</title><categories>cs.LG cs.MS stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-525-533</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, several methods have been proposed for the discovery of
causal structure from non-experimental data (Spirtes et al. 2000; Pearl 2000).
Such methods make various assumptions on the data generating process to
facilitate its identification from purely observational data. Continuing this
line of research, we show how to discover the complete causal structure of
continuous-valued data, under the assumptions that (a) the data generating
process is linear, (b) there are no unobserved confounders, and (c) disturbance
variables have non-gaussian distributions of non-zero variances. The solution
relies on the use of the statistical method known as independent component
analysis (ICA), and does not require any pre-specified time-ordering of the
variables. We provide a complete Matlab package for performing this LiNGAM
analysis (short for Linear Non-Gaussian Acyclic Model), and demonstrate the
effectiveness of the method using artificially generated data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1414</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1414</id><created>2012-07-04</created><authors><author><keyname>Savia</keyname><forenames>Eerika</forenames></author><author><keyname>Puolamaki</keyname><forenames>Kai</forenames></author><author><keyname>Sinkkonen</keyname><forenames>Janne</forenames></author><author><keyname>Kaski</keyname><forenames>Samuel</forenames></author></authors><title>Two-Way Latent Grouping Model for User Preference Prediction</title><categories>cs.IR cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-518-524</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel latent grouping model for predicting the relevance of a
new document to a user. The model assumes a latent group structure for both
users and documents. We compared the model against a state-of-the-art method,
the User Rating Profile model, where only users have a latent group structure.
We estimate both models by Gibbs sampling. The new method predicts relevance
more accurately for new documents that have few known ratings. The reason is
that generalization over documents then becomes necessary and hence the twoway
grouping is profitable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1415</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1415</id><created>2012-07-04</created><authors><author><keyname>Sanner</keyname><forenames>Scott</forenames></author><author><keyname>Boutilier</keyname><forenames>Craig</forenames></author></authors><title>Approximate Linear Programming for First-order MDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-509-517</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new approximate solution technique for first-order Markov
decision processes (FOMDPs). Representing the value function linearly w.r.t. a
set of first-order basis functions, we compute suitable weights by casting the
corresponding optimization as a first-order linear program and show how
off-the-shelf theorem prover and LP software can be effectively used. This
technique allows one to solve FOMDPs independent of a specific domain
instantiation; furthermore, it allows one to determine bounds on approximation
error that apply equally to all domain instantiations. We apply this solution
technique to the task of elevator scheduling with a rich feature space and
multi-criteria additive reward, and demonstrate that it outperforms a number of
intuitive, heuristicallyguided policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1416</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1416</id><created>2012-07-04</created><authors><author><keyname>Rudary</keyname><forenames>Matthew</forenames></author><author><keyname>Singh</keyname><forenames>Satinder</forenames></author><author><keyname>Wingate</keyname><forenames>David</forenames></author></authors><title>Predictive Linear-Gaussian Models of Stochastic Dynamical Systems</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-501-508</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models of dynamical systems based on predictive state representations (PSRs)
are defined strictly in terms of observable quantities, in contrast with
traditional models (such as Hidden Markov Models) that use latent variables or
statespace representations. In addition, PSRs have an effectively infinite
memory, allowing them to model some systems that finite memory-based models
cannot. Thus far, PSR models have primarily been developed for domains with
discrete observations. Here, we develop the Predictive Linear-Gaussian (PLG)
model, a class of PSR models for domains with continuous observations. We show
that PLG models subsume Linear Dynamical System models (also called Kalman
filter models or state-space models) while using fewer parameters. We also
introduce an algorithm to estimate PLG parameters from data, and contrast it
with standard Expectation Maximization (EM) algorithms used to estimate Kalman
filter parameters. We show that our algorithm is a consistent estimation
procedure and present preliminary empirical results suggesting that our
algorithm outperforms EM, particularly as the model dimension increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1417</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1417</id><created>2012-07-04</created><authors><author><keyname>Rosen-Zvi</keyname><forenames>Michal</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author></authors><title>The DLR Hierarchy of Approximate Inference</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-493-500</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a hierarchy for approximate inference based on the Dobrushin,
Lanford, Ruelle (DLR) equations. This hierarchy includes existing algorithms,
such as belief propagation, and also motivates novel algorithms such as
factorized neighbors (FN) algorithms and variants of mean field (MF)
algorithms. In particular, we show that extrema of the Bethe free energy
correspond to approximate solutions of the DLR equations. In addition, we
demonstrate a close connection between these approximate algorithms and Gibbs
sampling. Finally, we compare and contrast various of the algorithms in the DLR
hierarchy on spin-glass problems. The experiments show that algorithms higher
up in the hierarchy give more accurate results when they converge but tend to
be less stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1418</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1418</id><created>2012-07-04</created><authors><author><keyname>Zheng</keyname><forenames>Alice X.</forenames></author><author><keyname>Rish</keyname><forenames>Irina</forenames></author><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author></authors><title>Efficient Test Selection in Active Diagnosis via Entropy Approximation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-675-682</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of diagnosing faults in a system represented by a
Bayesian network, where diagnosis corresponds to recovering the most likely
state of unobserved nodes given the outcomes of tests (observed nodes). Finding
an optimal subset of tests in this setting is intractable in general. We show
that it is difficult even to compute the next most-informative test using
greedy test selection, as it involves several entropy terms whose exact
computation is intractable. We propose an approximate approach that utilizes
the loopy belief propagation infrastructure to simultaneously compute
approximations of marginal and conditional entropies on multiple subsets of
nodes. We apply our method to fault diagnosis in computer networks, and show
the algorithm to be very effective on realistic Internet-like topologies. We
also provide theoretical justification for the greedy test selection approach,
along with some performance guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1419</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1419</id><created>2012-07-04</created><authors><author><keyname>Zhang</keyname><forenames>Jiji</forenames></author><author><keyname>Spirtes</keyname><forenames>Peter L.</forenames></author></authors><title>A Transformational Characterization of Markov Equivalence for Directed
  Acyclic Graphs with Latent Variables</title><categories>cs.AI stat.ME</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-667-674</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different directed acyclic graphs (DAGs) may be Markov equivalent in the
sense that they entail the same conditional independence relations among the
observed variables. Chickering (1995) provided a transformational
characterization of Markov equivalence for DAGs (with no latent variables),
which is useful in deriving properties shared by Markov equivalent DAGs, and,
with certain generalization, is needed to prove the asymptotic correctness of a
search procedure over Markov equivalence classes, known as the GES algorithm.
For DAG models with latent variables, maximal ancestral graphs (MAGs) provide a
neat representation that facilitates model search. However, no transformational
characterization -- analogous to Chickering's -- of Markov equivalent MAGs is
yet available. This paper establishes such a characterization for directed
MAGs, which we expect will have similar uses as it does for DAGs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1420</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1420</id><created>2012-07-04</created><authors><author><keyname>Zettlemoyer</keyname><forenames>Luke S.</forenames></author><author><keyname>Collins</keyname><forenames>Michael</forenames></author></authors><title>Learning to Map Sentences to Logical Form: Structured Classification
  with Probabilistic Categorial Grammars</title><categories>cs.CL</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-658-666</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of mapping natural language sentences to
lambda-calculus encodings of their meaning. We describe a learning algorithm
that takes as input a training set of sentences labeled with expressions in the
lambda calculus. The algorithm induces a grammar for the problem, along with a
log-linear model that represents a distribution over syntactic and semantic
analyses conditioned on the input sentence. We apply the method to the task of
learning natural language interfaces to databases and show that the learned
parsers outperform previous methods in two benchmark database domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1421</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1421</id><created>2012-07-04</created><authors><author><keyname>Yu</keyname><forenames>Huizhen</forenames></author></authors><title>A Function Approximation Approach to Estimation of Policy Gradient for
  POMDP with Structured Policies</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-642-649</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the estimation of the policy gradient in partially observable
Markov decision processes (POMDP) with a special class of structured policies
that are finite-state controllers. We show that the gradient estimation can be
done in the Actor-Critic framework, by making the critic compute a &quot;value&quot;
function that does not depend on the states of POMDP. This function is the
conditional mean of the true value function that depends on the states. We show
that the critic can be implemented using temporal difference (TD) methods with
linear function approximations, and the analytical results on TD and
Actor-Critic can be transfered to this case. Although Actor-Critic algorithms
have been used extensively in Markov decision processes (MDP), up to now they
have not been proposed for POMDP as an alternative to the earlier proposal
GPOMDP algorithm, an actor-only method. Furthermore, we show that the same idea
applies to semi-Markov problems with a subset of finite-state controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1422</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1422</id><created>2012-07-04</created><authors><author><keyname>Yuan</keyname><forenames>Changhe</forenames></author><author><keyname>Druzdzel</keyname><forenames>Marek J.</forenames></author></authors><title>Importance Sampling in Bayesian Networks: An Influence-Based
  Approximation Strategy for Importance Functions</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-650-657</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main problems of importance sampling in Bayesian networks is
representation of the importance function, which should ideally be as close as
possible to the posterior joint distribution. Typically, we represent an
importance function as a factorization, i.e., product of conditional
probability tables (CPTs). Given diagnostic evidence, we do not have explicit
forms for the CPTs in the networks. We first derive the exact form for the CPTs
of the optimal importance function. Since the calculation is hard, we usually
only use their approximations. We review several popular strategies and point
out their limitations. Based on an analysis of the influence of evidence, we
propose a method for approximating the exact form of importance function by
explicitly modeling the most important additional dependence relations
introduced by evidence. Our experimental results show that the new
approximation strategy offers an immediate improvement in the quality of the
importance function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1423</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1423</id><created>2012-07-04</created><authors><author><keyname>Xing</keyname><forenames>Eric P.</forenames></author><author><keyname>Yan</keyname><forenames>Rong</forenames></author><author><keyname>Hauptmann</keyname><forenames>Alexander G.</forenames></author></authors><title>Mining Associated Text and Images with Dual-Wing Harmoniums</title><categories>cs.LG cs.DB stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-633-641</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a multi-wing harmonium model for mining multimedia data that
extends and improves on earlier models based on two-layer random fields, which
capture bidirectional dependencies between hidden topic aspects and observed
inputs. This model can be viewed as an undirected counterpart of the two-layer
directed models such as LDA for similar tasks, but bears significant difference
in inference/learning cost tradeoffs, latent topic representations, and topic
mixing mechanisms. In particular, our model facilitates efficient inference and
robust topic mixing, and potentially provides high flexibilities in modeling
the latent topic spaces. A contrastive divergence and a variational algorithm
are derived for learning. We specialized our model to a dual-wing harmonium for
captioned images, incorporating a multivariate Poisson for word-counts and a
multivariate Gaussian for color histogram. We present empirical results on the
applications of this model to classification, retrieval and image annotation on
news video collections, and we report an extensive comparison with various
extant models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1424</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1424</id><created>2012-07-04</created><authors><author><keyname>Wicks</keyname><forenames>John</forenames></author><author><keyname>Greenwald</keyname><forenames>Amy</forenames></author></authors><title>An Algorithm for Computing Stochastically Stable Distributions with
  Applications to Multiagent Learning in Repeated Games</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-623-632</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the proposed solutions to the equilibrium selection problem for agents
learning in repeated games is obtained via the notion of stochastic stability.
Learning algorithms are perturbed so that the Markov chain underlying the
learning dynamics is necessarily irreducible and yields a unique stable
distribution. The stochastically stable distribution is the limit of these
stable distributions as the perturbation rate tends to zero. We present the
first exact algorithm for computing the stochastically stable distribution of a
Markov chain. We use our algorithm to predict the long-term dynamics of simple
learning algorithms in sample repeated games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1425</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1425</id><created>2012-07-04</created><authors><author><keyname>Weng</keyname><forenames>Paul</forenames></author></authors><title>Qualitative Decision Making Under Possibilistic Uncertainty: Toward more
  discriminating criteria</title><categories>cs.AI cs.GT</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-615-622</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to propose a generalization of previous approaches
in qualitative decision making. Our work is based on the binary possibilistic
utility (PU), which is a possibilistic counterpart of Expected Utility (EU).We
first provide a new axiomatization of PU and study its relation with the
lexicographic aggregation of pessimistic and optimistic utilities. Then we
explain the reasons of the coarseness of qualitative decision criteria.
Finally, thanks to a redefinition of possibilistic lotteries and mixtures, we
present the refined binary possibilistic utility, which is more discriminating
than previously proposed criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1426</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1426</id><created>2012-07-04</created><authors><author><keyname>Welling</keyname><forenames>Max</forenames></author><author><keyname>Minka</keyname><forenames>Thomas P.</forenames></author><author><keyname>Teh</keyname><forenames>Yee Whye</forenames></author></authors><title>Structured Region Graphs: Morphing EP into GBP</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-609-614</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  GBP and EP are two successful algorithms for approximate probabilistic
inference, which are based on different approximation strategies. An open
problem in both algorithms has been how to choose an appropriate approximation
structure. We introduce 'structured region graphs', a formalism which marries
these two strategies, reveals a deep connection between them, and suggests how
to choose good approximation structures. In this formalism, each region has an
internal structure which defines an exponential family, whose sufficient
statistics must be matched by the parent region. Reduction operators on these
structures allow conversion between EP and GBP free energies. Thus it is
revealed that all EP approximations on discrete variables are special cases of
GBP, and conversely that some wellknown GBP approximations, such as overlapping
squares, are special cases of EP. Furthermore, region graphs derived from EP
have a number of good structural properties, including maxent-normality and
overall counting number of one. The result is a convenient framework for
producing high-quality approximations with a user-adjustable level of
complexity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1427</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1427</id><created>2012-07-04</created><authors><author><keyname>Wasserkrug</keyname><forenames>Segev</forenames></author><author><keyname>Gal</keyname><forenames>Avigdor</forenames></author><author><keyname>Etzion</keyname><forenames>Opher</forenames></author></authors><title>A Model for Reasoning with Uncertain Rules in Event Composition Systems</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-599-608</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there has been an increased need for the use of active
systems - systems required to act automatically based on events, or changes in
the environment. Such systems span many areas, from active databases to
applications that drive the core business processes of today's enterprises.
However, in many cases, the events to which the system must respond are not
generated by monitoring tools, but must be inferred from other events based on
complex temporal predicates. In addition, in many applications, such inference
is inherently uncertain. In this paper, we introduce a formal framework for
knowledge representation and reasoning enabling such event inference. Based on
probability theory, we define the representation of the associated uncertainty.
In addition, we formally define the probability space, and show how the
relevant probabilities can be calculated by dynamically constructing a Bayesian
network. To the best of our knowledge, this is the first work that enables
taking such uncertainty into account in the context of active systems.
herefore, our contribution is twofold: We formally define the representation
and semantics of event composition for probabilistic settings, and show how to
apply these extensions to the quantification of the occurrence probability of
events. These results enable any active system to handle such uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1428</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1428</id><created>2012-07-04</created><authors><author><keyname>Tian</keyname><forenames>Jin</forenames></author></authors><title>Generating Markov Equivalent Maximal Ancestral Graphs by Single Edge
  Replacement</title><categories>stat.ME cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-591-598</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximal ancestral graphs (MAGs) are used to encode conditional independence
relations in DAG models with hidden variables. Different MAGs may represent the
same set of conditional independences and are called Markov equivalent. This
paper considers MAGs without undirected edges and shows conditions under which
an arrow in a MAG can be reversed or interchanged with a bi-directed edge so as
to yield a Markov equivalent MAG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1429</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1429</id><created>2012-07-04</created><authors><author><keyname>Teyssier</keyname><forenames>Marc</forenames></author><author><keyname>Koller</keyname><forenames>Daphne</forenames></author></authors><title>Ordering-Based Search: A Simple and Effective Algorithm for Learning
  Bayesian Networks</title><categories>cs.LG cs.AI stat.ML</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-584-590</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the basic tasks for Bayesian networks (BNs) is that of learning a
network structure from data. The BN-learning problem is NP-hard, so the
standard solution is heuristic search. Many approaches have been proposed for
this task, but only a very small number outperform the baseline of greedy
hill-climbing with tabu lists; moreover, many of the proposed algorithms are
quite complex and hard to implement. In this paper, we propose a very simple
and easy-to-implement method for addressing this task. Our approach is based on
the well-known fact that the best network (of bounded in-degree) consistent
with a given node ordering can be found very efficiently. We therefore propose
a search not over the space of structures, but over the space of orderings,
selecting for each ordering the best network consistent with it. This search
space is much smaller, makes more global search steps, has a lower branching
factor, and avoids costly acyclicity checks. We present results for this
algorithm on both synthetic and real data sets, evaluating both the score of
the network found and in the running time. We show that ordering-based search
outperforms the standard baseline, and is competitive with recent algorithms
that are much harder to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1457</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1457</id><created>2012-07-05</created><authors><author><keyname>Stefan</keyname><forenames>Deian</forenames></author><author><keyname>Russo</keyname><forenames>Alejandro</forenames></author><author><keyname>Mitchell</keyname><forenames>John C.</forenames></author><author><keyname>Mazi&#xe8;res</keyname><forenames>David</forenames></author></authors><title>Flexible Dynamic Information Flow Control in the Presence of Exceptions</title><categories>cs.CR cs.PL</categories><acm-class>D.4.6; D.1.1; D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new, dynamic, floating-label approach to language-based
information flow control. A labeled IO monad, LIO, keeps track of a current
label and permits restricted access to IO functionality. The current label
floats to exceed the labels of all data observed and restricts what can be
modified. Unlike other language-based work, LIO also bounds the current label
with a current clearance that provides a form of discretionary access control.
Computations may encapsulate and pass around the results of computations with
different labels. In addition, the LIO monad offers a simple form of labeled
mutable references and exception handling. We give precise semantics and prove
confidentiality and integrity properties of a call-by-name \lambda-calculus and
provide an implementation in Haskell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1469</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1469</id><created>2012-07-05</created><authors><author><keyname>Wang</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Jianshu</forenames></author><author><keyname>Cabric</keyname><forenames>Danijela</forenames></author></authors><title>Cramer-Rao Bounds for Joint RSS/DoA-Based Primary-User Localization in
  Cognitive Radio Networks</title><categories>cs.PF cs.IT cs.NI math.IT</categories><comments>20 pages, 11 figures, 1 table, submitted to IEEE Transactions on
  Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge about the location of licensed primary-users (PU) could enable
several key features in cognitive radio (CR) networks including improved
spatio-temporal sensing, intelligent location-aware routing, as well as aiding
spectrum policy enforcement. In this paper we consider the achievable accuracy
of PU localization algorithms that jointly utilize received-signal-strength
(RSS) and direction-of-arrival (DoA) measurements by evaluating the Cramer-Rao
Bound (CRB). Previous works evaluate the CRB for RSS-only and DoA-only
localization algorithms separately and assume DoA estimation error variance is
a fixed constant or rather independent of RSS. We derive the CRB for joint
RSS/DoA-based PU localization algorithms based on the mathematical model of DoA
estimation error variance as a function of RSS, for a given CR placement. The
bound is compared with practical localization algorithms and the impact of
several key parameters, such as number of nodes, number of antennas and
samples, channel shadowing variance and correlation distance, on the achievable
accuracy are thoroughly analyzed and discussed. We also derive the closed-form
asymptotic CRB for uniform random CR placement, and perform theoretical and
numerical studies on the required number of CRs such that the asymptotic CRB
tightly approximates the numerical integration of the CRB for a given
placement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1473</identifier>
 <datestamp>2013-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1473</id><created>2012-07-05</created><updated>2013-06-21</updated><authors><author><keyname>Ma</keyname><forenames>Xiongfeng</forenames></author><author><keyname>Xu</keyname><forenames>Feihu</forenames></author><author><keyname>Xu</keyname><forenames>He</forenames></author><author><keyname>Tan</keyname><forenames>Xiaoqing</forenames></author><author><keyname>Qi</keyname><forenames>Bing</forenames></author><author><keyname>Lo</keyname><forenames>Hoi-Kwong</forenames></author></authors><title>Postprocessing for quantum random number generators: entropy evaluation
  and randomness extraction</title><categories>quant-ph cs.CR</categories><comments>13 pages, 2 figures</comments><journal-ref>Phys. Rev. A 87, 062327 (2013)</journal-ref><doi>10.1103/PhysRevA.87.062327</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum random-number generators (QRNGs) can offer a means to generate
information-theoretically provable random numbers, in principle. In practice,
unfortunately, the quantum randomness is inevitably mixed with classical
randomness due to classical noises. To distill this quantum randomness, one
needs to quantify the randomness of the source and apply a randomness
extractor. Here, we propose a generic framework for evaluating quantum
randomness of real-life QRNGs by min-entropy, and apply it to two different
existing quantum random-number systems in the literature. Moreover, we provide
a guideline of QRNG data postprocessing for which we implement two
information-theoretically provable randomness extractors: Toeplitz-hashing
extractor and Trevisan's extractor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1493</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1493</id><created>2012-07-05</created><authors><author><keyname>Ruchkin</keyname><forenames>Ivan</forenames></author><author><keyname>Prus</keyname><forenames>Vladimir</forenames></author></authors><title>Single-window Integrated Development Environment</title><categories>cs.SE cs.HC</categories><comments>Proceedings of the 4th Spring/Summer Young Researchers' Colloquium on
  Software Engineering (SYRCoSE) 2010</comments><acm-class>D.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of IDE interface complexity by introducing
single-window graphical user interface. This approach lies in removing
additional child windows from IDE, thus allowing a user to keep only text
editor window open. We describe an abstract model of IDE GUI that is based on
most popular modern integrated environments and has generalized user interface
parts. Then this abstract model is reorganized into single windowed interface
model: access to common IDE functions is provided from the code editing window
while utility windows are removed without loss of IDE functionality. After that
the implementation of single-window GUI on KDevelop 4 is described. And finally
tool views and usability of several well- known IDEs are surveyed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1497</identifier>
 <datestamp>2014-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1497</id><created>2012-07-05</created><updated>2014-01-15</updated><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author><author><keyname>Tartakovsky</keyname><forenames>Alexander G.</forenames></author></authors><title>Hidden Markov models for the activity profile of terrorist groups</title><categories>stat.AP cs.SI physics.data-an physics.soc-ph</categories><comments>Published in at http://dx.doi.org/10.1214/13-AOAS682 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS682</report-no><journal-ref>Annals of Applied Statistics 2013, Vol. 7, No. 4, 2402-2430</journal-ref><doi>10.1214/13-AOAS682</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main focus of this work is on developing models for the activity profile
of a terrorist group, detecting sudden spurts and downfalls in this profile,
and, in general, tracking it over a period of time. Toward this goal, a
$d$-state hidden Markov model (HMM) that captures the latent states underlying
the dynamics of the group and thus its activity profile is developed. The
simplest setting of $d=2$ corresponds to the case where the dynamics are
coarsely quantized as Active and Inactive, respectively. A state estimation
strategy that exploits the underlying HMM structure is then developed for spurt
detection and tracking. This strategy is shown to track even nonpersistent
changes that last only for a short duration at the cost of learning the
underlying model. Case studies with real terrorism data from open-source
databases are provided to illustrate the performance of the proposed
methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1501</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1501</id><created>2012-07-05</created><authors><author><keyname>Kim</keyname><forenames>Gol</forenames></author><author><keyname>Ye</keyname><forenames>Fei</forenames></author></authors><title>Super-Mixed Multiple Attribute Group Decision Making Method Based on
  Hybrid Fuzzy Grey Relation Approach Degree</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The feature of our method different from other fuzzy grey relation method for
supermixed multiple attribute group decision-making is that all of the
subjective and objective weights are obtained by interval grey number and that
the group decisionmaking is performed based on the relative approach degree of
grey TOPSIS, the relative approach degree of grey incidence and the relative
membership degree of grey incidence using 4-dimensional Euclidean distance. The
weighted Borda method is used to obtain final rank by using the results of four
methods. An example shows the applicability of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1512</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1512</id><created>2012-07-05</created><updated>2012-07-09</updated><authors><author><keyname>Xu</keyname><forenames>Xiaoli</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>Detailed Steps of the Fourier-Motzkin Elimination</title><categories>cs.IT math.IT</categories><comments>This is a subplementary file</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This file provide the detailed steps for obtaining the bounds on $R_1$, $R_2$
via the obtained results on $(R_{1c},R_{1p},R_{2c},R_{2p})$. It is
subplementary material for the paper titled &quot;On the Capacity Region of Two-User
Linear Deterministic Interference Channel and Its Application to Multi-Session
Network Coding&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1514</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1514</id><created>2012-07-06</created><authors><author><keyname>Kim</keyname><forenames>Yoora</forenames></author><author><keyname>Lee</keyname><forenames>Kyunghan</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author><author><keyname>Rhee</keyname><forenames>Injong</forenames></author><author><keyname>Chong</keyname><forenames>Song</forenames></author></authors><title>On the Generalized Delay-Capacity Tradeoff of Mobile Networks with
  L\'evy Flight Mobility</title><categories>cs.NI</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the literature, scaling laws for wireless mobile networks have been
characterized under various models of node mobility and several assumptions on
how communication occurs between nodes. To improve the realism in the analysis
of scaling laws, we propose a new analytical framework. The framework is the
first to consider a L\'{e}vy flight mobility pattern, which is known to closely
mimic human mobility patterns. Also, this is the first work that allows nodes
to communicate while being mobile. Under this framework, delays ($\bar{D}$) to
obtain various levels of per-node throughput $(\lambda)$ for L\'evy flight are
suggested as $\bar{D}(\lambda) = O(\sqrt{\min (n^{1+\alpha} \lambda, n^2)})$,
where L\'evy flight is a random walk of a power-law flight distribution with an
exponent $\alpha \in (0,2]$. The same framework presents a new tighter tradeoff
$\bar{D}(\lambda) = O(\sqrt{\max (1,n\lambda^3)})$ for \textit{i.i.d.}
mobility, whose delays are lower than existing results for the same levels of
per-node throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1517</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1517</id><created>2012-07-06</created><updated>2013-03-04</updated><authors><author><keyname>Liu</keyname><forenames>Tingting</forenames></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames></author></authors><title>On the Feasibility of Linear Interference Alignment for MIMO
  Interference Broadcast Channels with Constant Coefficients</title><categories>cs.IT math.IT</categories><comments>14 pages, 3 figures, accepted by IEEE Trans. on Signal Processing</comments><doi>10.1109/TSP.2013.2248005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the feasibility of linear interference alignment
(IA) for multi-input-multi-output (MIMO) interference broadcast channel
(MIMO-IBC) with constant coefficients. We pose and prove the necessary
conditions of linear IA feasibility for general MIMO-IBC. Except for the proper
condition, we find another necessary condition to ensure a kind of irreducible
interference to be eliminated. We then prove the necessary and sufficient
conditions for a special class of MIMO-IBC, where the numbers of antennas are
divisible by the number of data streams per user. Since finding an invertible
Jacobian matrix is crucial for the sufficiency proof, we first analyze the
impact of sparse structure and repeated structure of the Jacobian matrix.
Considering that for the MIMO-IBC the sub-matrices of the Jacobian matrix
corresponding to the transmit and receive matrices have different repeated
structure, we find an invertible Jacobian matrix by constructing the two
sub-matrices separately. We show that for the MIMO-IBC where each user has one
desired data stream, a proper system is feasible. For symmetric MIMO-IBC, we
provide proper but infeasible region of antenna configurations by analyzing the
difference between the necessary conditions and the sufficient conditions of
linear IA feasibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1520</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1520</id><created>2012-07-06</created><authors><author><keyname>Lozev</keyname><forenames>Kamen</forenames></author></authors><title>Algorithms for High-Performance Networking in the Presence of Obstacles</title><categories>cs.NI</categories><comments>5 pages, 1 figure, 1 table. arXiv admin note: substantial text
  overlap with arXiv:1111.6321</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work develops novel algorithms for high-performance networking in the
presence of obstacles based on a method for communicating via ultrasonic rays
reflected at the obstacles. The rays are curves determined by the variable
speed of sound and initial conditions and we develop ultrasonic ray models
based on a system of differential equations. We present new parallel algorithms
and software for shape and trajectory reconstruction of moving obstacles and
show how the reconstructed reflection point of a ray at an obstacle is a
natural router for messages between the ray's transmitter and receiver and
discuss the advantages of the new architecture. We discuss how the new
algorithms and software improve the performance and properties of the network
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1522</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1522</id><created>2012-07-06</created><authors><author><keyname>Masci</keyname><forenames>Jonathan</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael M.</forenames></author><author><keyname>Bronstein</keyname><forenames>Alexander A.</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Multimodal similarity-preserving hashing</title><categories>cs.CV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an efficient computational framework for hashing data belonging
to multiple modalities into a single representation space where they become
mutually comparable. The proposed approach is based on a novel coupled siamese
neural network architecture and allows unified treatment of intra- and
inter-modality similarity learning. Unlike existing cross-modality similarity
learning approaches, our hashing functions are not limited to binarized linear
projections and can assume arbitrarily complex forms. We show experimentally
that our method significantly outperforms state-of-the-art hashing approaches
on multimedia retrieval tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1524</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1524</id><created>2012-07-06</created><authors><author><keyname>Raghavan</keyname><forenames>Vasanthan</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Ensemble Properties of RVQ-Based Limited-Feedback Beamforming Codebooks</title><categories>cs.IT math.IT</categories><comments>47 pages, 6 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ensemble properties of Random Vector Quantization (RVQ) codebooks for
limited-feedback beamforming in multi-input multi-output (MIMO) systems are
studied with the metrics of interest being the received SNR loss and mutual
information loss, both relative to a perfect channel state information (CSI)
benchmark. The simplest case of unskewed codebooks is studied in the correlated
MIMO setting and these loss metrics are computed as a function of the number of
bits of feedback ($B$), transmit antenna dimension ($N_t$), and spatial
correlation. In particular, it is established that: i) the loss metrics are a
product of two components -- a quantization component and a channel-dependent
component; ii) the quantization component, which is also common to analysis of
channels with independent and identically distributed (i.i.d.) fading, decays
as $B$ increases at the rate $2^{-B/(N_t-1)}$; iii) the channel-dependent
component reflects the condition number of the channel. Further, the precise
connection between the received SNR loss and the squared singular values of the
channel is shown to be a Schur-convex majorization relationship. Finally, the
ensemble properties of skewed codebooks that are generated by skewing RVQ
codebooks with an appropriately designed fixed skewing matrix are studied.
Based on an estimate of the loss expression for skewed codebooks, it is
established that the optimal skewing matrix is critically dependent on the
condition numbers of the effective channel (product of the true channel and the
skewing matrix) and the skewing matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1534</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1534</id><created>2012-07-06</created><authors><author><keyname>Kim</keyname><forenames>Gol</forenames></author><author><keyname>Jong</keyname><forenames>Yunchol</forenames></author><author><keyname>Liu</keyname><forenames>Sifeng</forenames></author></authors><title>Generalized Hybrid Grey Relation Method for Multiple Attribute Mixed
  Type Decision Making</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiple attribute mixed type decision making is performed by four
methods, that is, the relative approach degree of grey TOPSIS method, the
relative approach degree of grey incidence, the relative membership degree of
grey incidence and the grey relation relative approach degree method using the
maximum entropy estimation, respectively. In these decision making methods, the
grey incidence degree in four-dimensional Euclidean space is used. The final
arrangement result is obtained by weighted Borda method. An example illustrates
the applicability of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1535</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1535</id><created>2012-07-06</created><authors><author><keyname>Shirwaikar</keyname><forenames>Prof Rudresh</forenames></author><author><keyname>Rajadhyax</keyname><forenames>Nikhil</forenames></author></authors><title>Data Mining on Educational Domain</title><categories>cs.DB</categories><comments>6 pages; http://www.ijascse.in/publications2012. arXiv admin note:
  text overlap with arXiv:1201.3417 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Educational data mining (EDM) is defined as the area of scientific inquiry
centered around the development of methods for making discoveries within the
unique kinds of data that come from educational settings, and using those
methods to better understand students and the settings which they learn in.
Data mining enables organizations to use their current reporting capabilities
to uncover and understand hidden patterns in vast databases. As a result of
this insight, institutions are able to allocate resources and staff more
effectively. In this paper, we present a real-world experiment conducted in
Shree Rayeshwar Institute of Engineering and Information Technology (SRIEIT) in
Goa, India. Here we found the relevant subjects in an undergraduate syllabus
and the strength of their relationship. We have also focused on classification
of students into different categories such as good, average, poor depending on
their marks scored by them by obtaining a decision tree which will predict the
performance of the students and accordingly help the weaker section of students
to improve in their academics. We have also found clusters of students for
helping in analyzing student's performance and also improvising the subject
teaching in that particular subject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1542</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1542</id><created>2012-07-06</created><authors><author><keyname>Patwari</keyname><forenames>Neha</forenames></author><author><keyname>Bhurani</keyname><forenames>Parvati</forenames></author></authors><title>Framework of SQL Injection Attack</title><categories>cs.NI cs.CR</categories><comments>12 pages; http://www.ijascse.in/publications2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the changing demographics of globalization, the emergence and prevalence
of web application have acquired a central and pivotal role in the domains of
technology and advancements. It thus becomes imperative to probe deeply into
the architecture, significance and different facets of usages. Web applications
enclose the functioning between a user and the services provided by the server,
which contains a database as its backend. The user can access the required
information through sending a request in the form of text to the web server,
which is interpreted by the server side script to construct an SQL. The query
is sent to the database which responds in order to generate an HTML page that
is sent back to the user. Since the functioning of web application is a dynamic
and complicated matter, certain threats to the database security have been
registered. One such alarming threat is the prevalence of SQL Injection Attack.
Hence a dynamic algorithm is given in this paper for preventing SQL Injection
Attacks which is based on context free grammars and compiler parsing
techniques. The paper attempts to present the notation of a SQLI Prevent Parser
for the prevention of SQL Injection Attacks. This Parser determines the
structure of queries and compares whether the queries are functionally
equivalent or not. This parser has been used on a sample web application and
the results have come out to be positive majors to prevent SQL Injection
Attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1547</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1547</id><created>2012-07-06</created><authors><author><keyname>Gol</keyname><forenames>Kim</forenames></author><author><keyname>Yun</keyname><forenames>Ri Suk</forenames></author></authors><title>Hybrid Forecasting of Exchange Rate by Using Chaos Wavelet SVM-Markov
  Model and Grey Relation Degree</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an exchange rate forecasting method by using the grey
relative combination approach of chaos wavelet SVM-Markov model. The problem of
short-term forecast of exchange rate by using the comprehensive method of the
phase space reconstitution and SVM method has been researched. We have
suggested a wavelet-SVR-Markov forecasting model to predict the finance time
series and demonstrated that can more improve the forecasting performance by
the rational combination of the forecast results through various combinational
tests. Our test result has been showed that the two-stage combination model is
more excellent than the normal combination model. Also we have comprehensively
estimated the combination forecast methods according to the forecasting
performance indicators.The estimated result have been shown that the
combination forecast methods on the basic of the degree of grey relation and
the optimal grey relation combination have fine forecast performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1550</identifier>
 <datestamp>2013-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1550</id><created>2012-07-06</created><authors><author><keyname>Wu</keyname><forenames>Yuanxin</forenames></author><author><keyname>Pan</keyname><forenames>Xianfei</forenames></author></authors><title>Velocity/Position Integration Formula (I): Application to In-flight
  Coarse Alignment</title><categories>cs.RO</categories><comments>IEEE Trans. on Aerospace and Electronic Systems, in press</comments><journal-ref>IEEE Transactions on Aerospace and Electronic Systems, vol. 49,
  no. 2, pp. 1006-1023, 2013</journal-ref><doi>10.1109/TAES.2013.6494395</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The in-flight alignment is a critical stage for airborne INS/GPS
applications. The alignment task is usually carried out by the Kalman filtering
technique that necessitates a good initial attitude to obtain satisfying
performance. Due to the airborne dynamics, the in-flight alignment is much
difficult than alignment on the ground. This paper proposes an
optimization-based coarse alignment approach using GPS position/velocity as
input, founded on the newly-derived velocity/position integration formulae.
Simulation and flight test results show that, with the GPS lever arm well
handled, it is potentially able to yield the initial heading up to one degree
accuracy in ten seconds. It can serve as a nice coarse in-flight alignment
without any prior attitude information for the subsequent fine Kalman
alignment. The approach can also be applied to other applications that require
aligning the INS on the run.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1551</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1551</id><created>2012-07-06</created><authors><author><keyname>Fekri-Ershad</keyname><forenames>Shervan</forenames></author><author><keyname>Saberi</keyname><forenames>Mohammad</forenames></author><author><keyname>Tajeripour</keyname><forenames>Farshad</forenames></author></authors><title>An Innovative Skin Detection Approach Using Color Based Image Retrieval
  Technique</title><categories>cs.CV</categories><comments>9 Pages, 4 Figures</comments><journal-ref>The International Journal of Multimedia &amp; Its Applications (IJMA)
  Vol.4, No.3, June 2012, 57-65</journal-ref><doi>10.5121/ijma.2012.4305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From The late 90th, &quot;Skin Detection&quot; becomes one of the major problems in
image processing. If &quot;Skin Detection&quot; will be done in high accuracy, it can be
used in many cases as face recognition, Human Tracking and etc. Until now so
many methods were presented for solving this problem. In most of these methods,
color space was used to extract feature vector for classifying pixels, but the
most of them have not good accuracy in detecting types of skin. The proposed
approach in this paper is based on &quot;Color based image retrieval&quot; (CBIR)
technique. In this method, first by means of CBIR method and image tiling and
considering the relation between pixel and its neighbors, a feature vector
would be defined and then with using a training step, detecting the skin in the
test stage. The result shows that the presenting approach, in addition to its
high accuracy in detecting type of skin, has no sensitivity to illumination
intensity and moving face orientation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1553</identifier>
 <datestamp>2013-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1553</id><created>2012-07-06</created><authors><author><keyname>Wu</keyname><forenames>Yuanxin</forenames></author><author><keyname>Pan</keyname><forenames>Xianfei</forenames></author></authors><title>Velocity/Position Integration Formula (II): Application to Inertial
  Navigation Computation</title><categories>cs.RO</categories><comments>IEEE Trans. on Aerospace and Electronic Systems, in press</comments><journal-ref>IEEE Transactions on Aerospace and Electronic Systems, vol. 49,
  no. 2, pp. 1024-1034, 2013</journal-ref><doi>10.1109/TAES.2013.6494396</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inertial navigation applications are usually referenced to a rotating frame.
Consideration of the navigation reference frame rotation in the inertial
navigation algorithm design is an important but so far less seriously treated
issue, especially for ultra-high-speed flying aircraft or the future
ultra-precision navigation system of several meters per hour. This paper
proposes a rigorous approach to tackle the issue of navigation frame rotation
in velocity/position computation by use of the newly-devised velocity/position
integration formulae in the Part I companion paper. The two integration
formulae set a well-founded cornerstone for the velocity/position algorithms
design that makes the comprehension of the inertial navigation computation
principle more accessible to practitioners, and different approximations to the
integrals involved will give birth to various velocity/position update
algorithms. Two-sample velocity and position algorithms are derived to
exemplify the design process. In the context of level-flight airplane examples,
the derived algorithm is analytically and numerically compared to the typical
algorithms existing in the literature. The results throw light on the problems
in existing algorithms and the potential benefits of the derived algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1563</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1563</id><created>2012-07-06</created><authors><author><keyname>Knabe</keyname><forenames>Frederic</forenames></author><author><keyname>Mohamed</keyname><forenames>Omar</forenames></author><author><keyname>Huppert</keyname><forenames>Carolin</forenames></author></authors><title>Achievable Sum-Rates in Gaussian Multiple-Access Channels with
  MIMO-AF-Relay and Direct Links</title><categories>cs.IT math.IT</categories><comments>accepted for Information Theory Workshop (ITW) 2012, Lausanne,
  Switzerland, 5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a single-antenna Gaussian multiple-access channel (MAC) with a
multiple-antenna amplify-and-forward (AF) relay, where, contrary to many
previous works, also the direct links between transmitters and receiver are
taken into account. For this channel, we investigate two transmit schemes:
Sending and relaying all signals jointly or using a time-division
multiple-access (TDMA) structure, where only one transmitter uses the channel
at a time. While the optimal relaying matrices and time slot durations are
found for the latter scheme, we provide upper and lower bounds on the
achievable sum-rate for the former one. These bounds are evaluated by Monte
Carlo simulations, where it turns out that they are very close to each other.
Moreover, these bounds are compared to the sum-rates achieved by the TDMA
scheme. For the asymptotic case of high available transmit power at the relay,
an analytic expression is given, which allows to determine the superior scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1571</identifier>
 <datestamp>2012-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1571</id><created>2012-07-06</created><authors><author><keyname>Tomczak</keyname><forenames>Tadeusz</forenames></author><author><keyname>Zadarnowska</keyname><forenames>Katarzyna</forenames></author><author><keyname>Koza</keyname><forenames>Zbigniew</forenames></author><author><keyname>Matyka</keyname><forenames>Maciej</forenames></author><author><keyname>Miros&#x142;aw</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Complete PISO and SIMPLE solvers on Graphics Processing Units</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We implemented the pressure-implicit with splitting of operators (PISO) and
semi-implicit method for pressure-linked equations (SIMPLE) solvers of the
Navier-Stokes equations on Fermi-class graphics processing units (GPUs) using
the CUDA technology. We also introduced a new format of sparse matrices
optimized for performing elementary CFD operations, like gradient or divergence
discretization, on GPUs. We verified the validity of the implementation on
several standard, steady and unsteady problems. Computational effciency of the
GPU implementation was examined by comparing its double precision run times
with those of essentially the same algorithms implemented in OpenFOAM. The
results show that a GPU (Tesla C2070) can outperform a server-class 6-core,
12-thread CPU (Intel Xeon X5670) by a factor of 4.2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1591</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1591</id><created>2012-07-06</created><authors><author><keyname>Reddy</keyname><forenames>P. Radha Krishna</forenames></author><author><keyname>Roy</keyname><forenames>Ashim</forenames></author><author><keyname>Sireesha</keyname><forenames>G.</forenames></author><author><keyname>Begum</keyname><forenames>Ismatha</forenames></author><author><keyname>Ramaiah</keyname><forenames>S. Siva</forenames></author></authors><title>A Secure Dynamic Job Scheduling on Smart Grid using RSA Algorithm</title><categories>cs.OS</categories><comments>Published; 2277128x 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Grid computing is a computation methodology using group of clusters connected
over high-speed networks that involves coordinating and sharing computational
power, data storage and network resources. Integrating a set of clusters of
workstations into one large computing environment can improve the availability
of computing power. The goal of scheduling is to achieve highest possible
system throughput and to match the application need with the available
computing resources. A secure scheduling model is presented, that performs job
grouping activity at runtime. In a Grid environment, security is necessary
because grid is a dynamic environment and participates are independent bodies
with different policies, objectives and requirements. Authentication should be
verified for Grid resource owners as well as resource requesters before they
are allowed to join in scheduling activities. In order to achieve secure
resource and job scheduling including minimum processing time and maximum
resource utilization, A Secure Resource by using RSA algorithm on Networking
and Job Scheduling model with Job Grouping strategy(JGS) in Grid Computing has
been proposed. The result shows significant improvement in the processing time
of jobs and resource utilization as compared to dynamic job grouping (DJG)
based scheduling on smart grids (SG).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1614</identifier>
 <datestamp>2013-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1614</id><created>2012-07-06</created><updated>2013-01-14</updated><authors><author><keyname>Ausloos</keyname><forenames>Marcel</forenames></author></authors><title>A scientometrics law about co-authors and their ranking. The co-author
  core</title><categories>physics.soc-ph cs.DL</categories><comments>REVISED VERSION : 3 figures, 13 pages, 82 references, 3 tables;
  post-conference paper for COST Action MP-0801, 'Physics of Competition and
  Conflict': In particular &quot;Evaluating Science: Modern Scientometric Methods&quot;,
  in Sofia,May 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rather than &quot;measuring&quot; a scientist impact through the number of citations
which his/her published work can have generated, isn't it more appropriate to
consider his/her value through his/her scientific network performance
illustrated by his/her co-author role, thus focussing on his/her joint
publications, - and their impact through citations? Whence, on one hand, this
paper very briefly examines bibliometric laws, like the $h$-index and
subsequent debate about co-authorship effects, but on the other hand, proposes
a measure of collaborative work through a new index. Based on data about the
publication output of a specific research group, a new bibliometric law is
found.
  Let a co-author $C$ have written $J$ (joint) publications with one or several
colleagues. Rank all the co-authors of that individual according to their
number of joint publications, giving a rank $r$ to each co-author, starting
with $r=1$ for the most prolific.
  It is empirically found that a very simple relationship holds between the
number of joint publications $J$ by coauthors and their rank of importance,
i.e. $J \propto 1/r$. Thereafter, in the same spirit as for the Hirsch core,
one can define a &quot;co-author core&quot;, and introduce indices operating on an
author. It is emphasized that the new index has a quite different
(philosophical) perspective that the $h$-index. In the present case, one
focusses on &quot;relevant&quot; persons rather than on &quot;relevant&quot; publications.
  Although the numerical discussion is based on one case, there is little doubt
that the law can be verified in many other situations. Therefore, variants and
generalizations could be later produced in order to quantify co-author roles,
in a temporary or long lasting stable team(s), and lead to criteria about
funding, career measurements or even induce career strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1619</identifier>
 <datestamp>2013-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1619</id><created>2012-07-06</created><updated>2012-10-01</updated><authors><author><keyname>Duport</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Schneider</keyname><forenames>Bendix</forenames></author><author><keyname>Smerieri</keyname><forenames>Anteo</forenames></author><author><keyname>Haelterman</keyname><forenames>Marc</forenames></author><author><keyname>Massar</keyname><forenames>Serge</forenames></author></authors><title>All-optical Reservoir Computing</title><categories>physics.optics cs.ET</categories><journal-ref>Optics Express, Vol. 20 Issue 20, pp.22783-22795 (2012)</journal-ref><doi>10.1364/OE.20.022783</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reservoir Computing is a novel computing paradigm which uses a nonlinear
recurrent dynamical system to carry out information processing. Recent
electronic and optoelectronic Reservoir Computers based on an architecture with
a single nonlinear node and a delay loop have shown performance on standardized
tasks comparable to state-of-the-art digital implementations. Here we report an
all-optical implementation of a Reservoir Computer, made of off-the-shelf
components for optical telecommunications. It uses the saturation of a
semiconductor optical amplifier as nonlinearity. The present work shows that,
within the Reservoir Computing paradigm, all-optical computing with
state-of-the-art performance is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1631</identifier>
 <datestamp>2013-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1631</id><created>2012-07-06</created><updated>2013-01-14</updated><authors><author><keyname>Thomas</keyname><forenames>Philipp</forenames></author><author><keyname>Matuschek</keyname><forenames>Hannes</forenames></author><author><keyname>Grima</keyname><forenames>Ramon</forenames></author></authors><title>Computation of biochemical pathway fluctuations beyond the linear noise
  approximation using iNA</title><categories>q-bio.QM cs.CE q-bio.MN</categories><comments>5 pages, 2 figures, conference proceeding IEEE International
  Conference on Bioinformatics and Biomedicine (BIBM) 2012</comments><doi>10.1109/BIBM.2012.6392668</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear noise approximation is commonly used to obtain intrinsic noise
statistics for biochemical networks. These estimates are accurate for networks
with large numbers of molecules. However it is well known that many biochemical
networks are characterized by at least one species with a small number of
molecules. We here describe version 0.3 of the software intrinsic Noise
Analyzer (iNA) which allows for accurate computation of noise statistics over
wide ranges of molecule numbers. This is achieved by calculating the next order
corrections to the linear noise approximation's estimates of variance and
covariance of concentration fluctuations. The efficiency of the methods is
significantly improved by automated just-in-time compilation using the LLVM
framework leading to a fluctuation analysis which typically outperforms that
obtained by means of exact stochastic simulations. iNA is hence particularly
well suited for the needs of the computational biology community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1641</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1641</id><created>2012-07-06</created><authors><author><keyname>Del Vescovo</keyname><forenames>Chiara</forenames></author><author><keyname>Klinov</keyname><forenames>Pavel</forenames></author><author><keyname>Parsia</keyname><forenames>Bijan</forenames></author><author><keyname>Sattler</keyname><forenames>Uli</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author><author><keyname>Tsarkov</keyname><forenames>Dmitry</forenames></author></authors><title>Syntactic vs. Semantic Locality: How Good Is a Cheap Approximation?</title><categories>cs.AI cs.LO</categories><msc-class>68T30</msc-class><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extracting a subset of a given OWL ontology that captures all the ontology's
knowledge about a specified set of terms is a well-understood task. This task
can be based, for instance, on locality-based modules (LBMs). These come in two
flavours, syntactic and semantic, and a syntactic LBM is known to contain the
corresponding semantic LBM. For syntactic LBMs, polynomial extraction
algorithms are known, implemented in the OWL API, and being used. In contrast,
extracting semantic LBMs involves reasoning, which is intractable for OWL 2 DL,
and these algorithms had not been implemented yet for expressive ontology
languages. We present the first implementation of semantic LBMs and report on
experiments that compare them with syntactic LBMs extracted from real-life
ontologies. Our study reveals whether semantic LBMs are worth the additional
extraction effort, compared with syntactic LBMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1649</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1649</id><created>2012-07-06</created><authors><author><keyname>da Silva</keyname><forenames>N&#xfa;bia Rosa</forenames></author><author><keyname>Bruno</keyname><forenames>Odemir Martinez</forenames></author></authors><title>Analysis of Multi-Scale Fractal Dimension to Classify Human Motion</title><categories>cs.CV</categories><comments>6 pages, Paper presented on WVC 2012 (Workshop of Computer Vision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years there has been considerable interest in human action
recognition. Several approaches have been developed in order to enhance the
automatic video analysis. Although some developments have been achieved by the
computer vision community, the properly classification of human motion is still
a hard and challenging task. The objective of this study is to investigate the
use of 3D multi-scale fractal dimension to recognize motion patterns in videos.
In order to develop a robust strategy for human motion classification, we
proposed a method where the Fourier transform is used to calculate the
derivative in which all data points are deemed. Our results shown that
different accuracy rates can be found for different databases. We believe that
in specific applications our results are the first step to develop an automatic
monitoring system, which can be applied in security systems, traffic
monitoring, biology, physical therapy, cardiovascular disease among many
others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1655</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1655</id><created>2012-07-06</created><updated>2012-09-17</updated><authors><author><keyname>Granade</keyname><forenames>Christopher E.</forenames></author><author><keyname>Ferrie</keyname><forenames>Christopher</forenames></author><author><keyname>Wiebe</keyname><forenames>Nathan</forenames></author><author><keyname>Cory</keyname><forenames>D. G.</forenames></author></authors><title>Robust Online Hamiltonian Learning</title><categories>quant-ph cs.LG</categories><comments>24 pages, 12 figures; to appear in New Journal of Physics</comments><journal-ref>2012 New J. Phys. 14 103013</journal-ref><doi>10.1088/1367-2630/14/10/103013</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this work we combine two distinct machine learning methodologies,
sequential Monte Carlo and Bayesian experimental design, and apply them to the
problem of inferring the dynamical parameters of a quantum system. We design
the algorithm with practicality in mind by including parameters that control
trade-offs between the requirements on computational and experimental
resources. The algorithm can be implemented online (during experimental data
collection), avoiding the need for storage and post-processing. Most
importantly, our algorithm is capable of learning Hamiltonian parameters even
when the parameters change from experiment-to-experiment, and also when
additional noise processes are present and unknown. The algorithm also
numerically estimates the Cramer-Rao lower bound, certifying its own
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1659</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1659</id><created>2012-07-06</created><authors><author><keyname>Leconte</keyname><forenames>Mathieu</forenames></author><author><keyname>Lelarge</keyname><forenames>Marc</forenames></author><author><keyname>Massouli&#xe9;</keyname><forenames>Laurent</forenames></author></authors><title>Convergence of multivariate belief propagation, with applications to
  cuckoo hashing and load balancing</title><categories>math.PR cs.DM math.CO</categories><comments>10 pages format + proofs in the appendix: total 24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is motivated by two applications, namely i) generalizations of
cuckoo hashing, a computationally simple approach to assigning keys to objects,
and ii) load balancing in content distribution networks, where one is
interested in determining the impact of content replication on performance.
These two problems admit a common abstraction: in both scenarios, performance
is characterized by the maximum weight of a generalization of a matching in a
bipartite graph, featuring node and edge capacities. Our main result is a law
of large numbers characterizing the asymptotic maximum weight matching in the
limit of large bipartite random graphs, when the graphs admit a local weak
limit that is a tree. This result specializes to the two application scenarios,
yielding new results in both contexts. In contrast with previous results, the
key novelty is the ability to handle edge capacities with arbitrary integer
values. An analysis of belief propagation algorithms (BP) with multivariate
belief vectors underlies the proof. In particular, we show convergence of the
corresponding BP by exploiting monotonicity of the belief vectors with respect
to the so-called upshifted likelihood ratio stochastic order. This auxiliary
result can be of independent interest, providing a new set of structural
conditions which ensure convergence of BP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1668</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1668</id><created>2012-07-06</created><authors><author><keyname>Elkin</keyname><forenames>Michael</forenames></author><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>Fast Constructions of Light-Weight Spanners for General Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To our knowledge, there are only two known algorithms for constructing sparse
and light spanners for general graphs. One of them is the greedy algorithm of
Alth$\ddot{o}$fer et al. \cite{ADDJS93}, analyzed by Chandra et al. in SoCG'92.
The greedy algorithm consructs, for every \emph{weighted} undirected $n$-vertex
$m$-edge graph $G = (V,E)$ and any integer $k \ge 1$, a $(2k-1)$-spanner with
$O(n^{1 + 1/k})$ edges and weight $O(k \cdot n^{(1+\eps)/k}) \cdot
\omega(MST(G))$, for any $\eps &gt; 0$. The drawback of the greedy algorithm is
that it requires $O(m \cdot (n^{1 + 1/k} + n \cdot \log n))$ time. The other
algorithm is due to Awerbuch et al. \cite{ABP91}. It constructs $O(k)$-spanners
with $O(k \cdot n^{1 + 1/k} \cdot \Lambda)$ edges, weight $O(k^2 \cdot n^{1/k}
\cdot \Lambda) \cdot \omega(MST(G))$, within time $O(m \cdot k \cdot n^{1/k}
\cdot \Lambda)$, where $\Lambda$ is the logarithm of the aspect ratio of the
graph. The running time of both these algorithms is unsatisfactory. Moreover,
the usually faster algorithm of \cite{ABP91} pays for the speedup by
significantly increasing both the stretch, the sparsity, and the weight of the
resulting spanner.
  In this paper we devise an efficient algorithm for constructing sparse and
light spanners. Specifically, our algorithm constructs $((2k-1) \cdot
(1+\eps))$-spanners with $O(k \cdot n^{1 + 1/k})$ edges and weight $O(k \cdot
n^{1/k}) \cdot \omega(MST(G))$, where $\eps &gt; 0$ is an arbitrarily small
constant. The running time of our algorithm is $O(k \cdot m + \min\{n \cdot
\log n,m \cdot \alpha(n)\})$. Moreover, by slightly increasing the running time
we can reduce the other parameters. These results address an open problem from
the ESA'04 paper by Roditty and Zwick \cite{RZ04}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1683</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1683</id><created>2012-07-06</created><authors><author><keyname>Singh</keyname><forenames>Nungleppam Monoranjan</forenames></author><author><keyname>Sarma</keyname><forenames>Kanak Chandra</forenames></author><author><keyname>Singh</keyname><forenames>Nungleppam Gopil</forenames></author></authors><title>Design and Development of Low Cost Multi-Channel USB Data</title><categories>cs.AR</categories><comments>5 pages,8 figures, published in International Journal of Computer
  Applications (IJCA)</comments><journal-ref>International Journal of Computer Applications 48(18):47-51, June
  2012</journal-ref><doi>10.5120/7452-0633</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the design and development of low cost USB Data
Acquisition System (DAS) for the measurement of physical parameters. Physical
parameters such as temperature, humidity, light intensity etc., which are
generally slowly varying signals are sensed by respective sensors or integrated
sensors and converted into voltages. The DAS is designed using PIC18F4550
microcontroller, communicating with Personal Computer (PC) through USB
(Universal Serial Bus). The designed DAS has been tested with the application
program developed in Visual Basic, which allows online monitoring in graphical
as well as numerical display.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1690</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1690</id><created>2012-07-06</created><updated>2012-12-28</updated><authors><author><keyname>de Freitas</keyname><forenames>Michael Marcondes</forenames></author><author><keyname>Sontag</keyname><forenames>Eduardo D.</forenames></author></authors><title>Remarks on random dynamical systems with inputs and outputs and a
  small-gain theorem for monotone RDS</title><categories>cs.SY math.OC</categories><comments>Revision corrects several small errors and clarifies role of tempered
  convergence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note introduces a new notion of random dynamical system with inputs and
outputs, and sketches a small-gain theorem for monotone systems which
generalizes a similar theorem known for deterministic systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1700</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1700</id><created>2012-07-06</created><authors><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Arshad</keyname><forenames>M. H.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author><author><keyname>Qasim</keyname><forenames>B.</forenames></author></authors><title>Performance Evaluation of Widely used Portknoking Algorithms</title><categories>cs.NI cs.CR</categories><comments>3rd WNM in conjunction with 14th HPCC-2012, Liverpool, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Port knocking is a technique by which only a single packet or special
sequence will permit the firewall to open a port on a machine where all ports
are blocked by default. It is a passive authorization technique which offers
firewall-level authentication to ensure authorized access to potentially
vulnerable network services. In this paper, we present performance evaluation
and analytical comparison of three widely used port knocking (PK) algorithms,
Aldaba, FWKNOP and SIG-2. Comparative analysis is based upon ten selected
parameters; Platforms (Supported OS), Implementation (PK, SPA or both),
Protocols (UDP, TCP, ICMP), Out of Order packet delivery, NAT (Network Address
Translation), Encryption Algorithms, Root privileges (For installation and
operation), Weak Passwords, Replay Attacks and IPv6 compatibility. Based upon
these parameters, relative performance score has been given to each algorithm.
Finally, we deduce that FWKNOP due to compatibility with windows client is the
most efficient among chosen PK implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1701</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1701</id><created>2012-07-06</created><authors><author><keyname>Vinayakray-Jani</keyname><forenames>Preetida</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Security Architecture for Cluster based Ad Hoc Networks</title><categories>cs.CR</categories><comments>5 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad hoc Networks (MANETs) are subject to various kinds of attacks.
Deploying security mechanisms is difficult due to inherent properties of ad hoc
networks, such as the high dynamics of their topology, restricted bandwidth,
and limited resources in end device. With such dynamicity in connectivity and
limited resources it is not possible to deploy centralized security solution
but distribution solution. The paper proposes architectural security concept in
distributed manner where network is divided into clusters with one cluster head
node each. This cluster head node also act as a router providing proactive
hidden routing by using Steganographic methods for inter-cluster security.
Besides cipher method is used to provide intra-cluster security. The proposed
secure architecture specifies operational view of cluster head as a router that
provides trust, anonymity and confidentiality through Steganography and
Cryptography respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1702</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1702</id><created>2012-07-06</created><authors><author><keyname>Rehman</keyname><forenames>Obaid ur</forenames></author><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author><author><keyname>Bibi</keyname><forenames>Ayesha</forenames></author><author><keyname>Khan</keyname><forenames>Zahoor Ali</forenames></author></authors><title>Performance Study of Localization Techniques in Wireless Body Area
  Sensor Networks</title><categories>cs.NI</categories><comments>AUCN in conjunction with 11th IUCC-2012, Liverpool, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major issues in Wireless Body Area Sensor Networks (WBASNs) is
efficient localization. There are various techniques for indoor and outdoor
environments to locate a person. This study evaluating and compares performance
of optimization schemes in indoor environments for optimal placement of
wireless sensors, where patients can perform their daily activities. In indoor
environments, the performance comparison between Distance Vector-Hop algorithm,
Ring Overlapping Based on Comparison Received Signal Strength Indicator
(ROCRSSI), Particle filtering and Kalman filtering based location tracking
techniques, in terms of localization accuracy is estimated. Results show that
particle filtering outperforms all. GPS and several techniques based on
GSMlocation tracking schemes are proposed for outdoor environments. Hidden
Markov GSM based location tracking scheme efficiently performs among all, in
terms of location accuracy and computational overheads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1746</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1746</id><created>2012-07-06</created><authors><author><keyname>Bianco</keyname><forenames>Mauro</forenames></author><author><keyname>Varetto</keyname><forenames>Ugo</forenames></author></authors><title>A Generic Library for Stencil Computations</title><categories>cs.MS cs.DC cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this era of diverse and heterogeneous computer architectures, the
programmability issues, such as productivity and portable efficiency, are
crucial to software development and algorithm design. One way to approach the
problem is to step away from traditional sequential programming languages and
move toward domain specific programming environments to balance between
expressivity and efficiency. In order to demonstrate this principle, we
developed a domain specific C++ generic library for stencil computations, like
PDE solvers. The library features high level constructs to specify computation
and allows the development of parallel stencil computations with very limited
effort. The high abstraction constructs (like do_all and do_reduce) make the
program shorter and cleaner with increased contextual information for better
performance exploitation. The results show good performance from Windows
multicores, to HPC clusters and machines with accelerators, like GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1748</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1748</id><created>2012-07-06</created><authors><author><keyname>Turalska</keyname><forenames>Malgorzata</forenames></author><author><keyname>West</keyname><forenames>Bruce J.</forenames></author><author><keyname>Grigolini</keyname><forenames>Paolo</forenames></author></authors><title>Role of Committed Minorities in Times of Crisis</title><categories>physics.soc-ph cs.SI nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use a Cooperative Decision Making (CDM) model to study the effect of
committed minorities on group behavior in time of crisis. The CDM model has
been shown to generate consensus through a phase-transition process that at
criticality establishes long-range correlations among the individuals within a
model society. In a condition of high consensus, the correlation function
vanishes, thereby making the network recover the ordinary locality condition.
However, this state is not permanent and times of crisis occur when there is an
ambiguity concerning a given social issue. The correlation function within the
cooperative system becomes similarly extended as it is observed at criticality.
This combination of independence (free will) and long-range correlation makes
it possible for very small but committed minorities to produce substantial
changes in social consensus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1760</identifier>
 <datestamp>2013-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1760</id><created>2012-07-07</created><updated>2013-10-03</updated><authors><author><keyname>Tan</keyname><forenames>Jin</forenames></author><author><keyname>Carmon</keyname><forenames>Danielle</forenames></author><author><keyname>Baron</keyname><forenames>Dror</forenames></author></authors><title>Signal Estimation with Additive Error Metrics in Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing typically deals with the estimation of a system input from
its noise-corrupted linear measurements, where the number of measurements is
smaller than the number of input components. The performance of the estimation
process is usually quantified by some standard error metric such as squared
error or support set error. In this correspondence, we consider a noisy
compressed sensing problem with any arbitrary error metric. We propose a
simple, fast, and highly general algorithm that estimates the original signal
by minimizing the error metric defined by the user. We verify that our
algorithm is optimal owing to the decoupling principle, and we describe a
general method to compute the fundamental information-theoretic performance
limit for any error metric. We provide two example metrics --- minimum mean
absolute error and minimum mean support error --- and give the theoretical
performance limits for these two cases. Experimental results show that our
algorithm outperforms methods such as relaxed belief propagation (relaxed BP)
and compressive sampling matching pursuit (CoSaMP), and reaches the suggested
theoretical limits for our two example metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1765</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1765</id><created>2012-07-07</created><authors><author><keyname>Masci</keyname><forenames>Jonathan</forenames></author><author><keyname>Meier</keyname><forenames>Ueli</forenames></author><author><keyname>Fricout</keyname><forenames>Gabriel</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Object Recognition with Multi-Scale Pyramidal Pooling Networks</title><categories>cs.CV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Multi-Scale Pyramidal Pooling Network, featuring a novel
pyramidal pooling layer at multiple scales and a novel encoding layer. Thanks
to the former the network does not require all images of a given classification
task to be of equal size. The encoding layer improves generalisation
performance in comparison to similar neural network architectures, especially
when training data is scarce. We evaluate and compare our system to
convolutional neural networks and state-of-the-art computer vision methods on
various benchmark datasets. We also present results on industrial steel defect
classification, where existing architectures are not applicable because of the
constraint on equally sized input images. The proposed architecture can be seen
as a fully supervised hierarchical bag-of-features extension that is trained
online and can be fine-tuned for any given task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1768</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1768</id><created>2012-07-07</created><authors><author><keyname>Sagar</keyname><forenames>S.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Saqib</keyname><forenames>J.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author><author><keyname>Bouk</keyname><forenames>S. H.</forenames></author></authors><title>Analysis and Modeling Experiment Performance Parameters of Routing
  Protocols in MANETs and VANETs</title><categories>cs.NI</categories><journal-ref>Multicom2012 held in conjunction with 11th IEEE International
  Conference on Ubiquitous Computing and Communications (IUCC-2012) (25 - 27
  June 2012, Liverpool, UK)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a framework for experimental parameters in which Packet
Delivery Ratio (PDR), effect of link duration over End-to-End Delay (E2ED) and
Normalized Routing Overhead (NRO) in terms of control packets is analyzed and
modeled for Mobile Ad-Hoc NETworks (MANETs) and Vehicular Ad-Hoc NETworks
(VANETs) with the assumption that nodes (vehicles) are sparsely moving in two
different road. Moreover, this paper contributes the performance comparison of
one Proactive Routing Protocol; Destination Sequenced Distance vector (DSDV)
and two reactive protocols; DYnamic Source Routing (DSR) and DYnamic MANET
On-Demand (DYMO). A novel contribution of this work is enhancements in default
versions of selected routing protocols. Three performance parameters; PDR, E2ED
and NRO with varying scalabilities are measured to analyze the performance of
selected routing protocols with their original and enhanced versions. From
extensive simulations, it is observed that DSR outperforms among all three
protocols at the cost of delay. NS-2 simulator is used for simulation with
TwoRayGround propagation model to evaluate analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1773</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1773</id><created>2012-07-07</created><authors><author><keyname>Solc&#xe0;</keyname><forenames>Raffaele</forenames></author><author><keyname>Schulthess</keyname><forenames>Thomas C.</forenames></author><author><keyname>Haidar</keyname><forenames>Azzam</forenames></author><author><keyname>Tomov</keyname><forenames>Stanimire</forenames></author><author><keyname>Yamazaki</keyname><forenames>Ichitaro</forenames></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames></author></authors><title>A hybrid Hermitian general eigenvalue solver</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The adoption of hybrid GPU-CPU nodes in traditional supercomputing platforms
opens acceleration opportunities for electronic structure calculations in
materials science and chemistry applications, where medium sized Hermitian
generalized eigenvalue problems must be solved many times. The small size of
the problems limits the scalability on a distributed memory system, hence they
can benefit from the massive computational performance concentrated on a single
node, hybrid GPU-CPU system. However, new algorithms that efficiently exploit
heterogeneity and massive parallelism of not just GPUs, but of multi/many-core
CPUs as well are required. Addressing these demands, we implemented a novel
Hermitian general eigensolver algorithm. This algorithm is based on a standard
eigenvalue solver, and existing algorithms can be used. The resulting
eigensolvers are state-of-the-art in HPC, significantly outperforming existing
libraries. We analyze their performance impact on applications of interest,
when different fractions of eigenvectors are needed by the host electronic
structure code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1777</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1777</id><created>2012-07-07</created><authors><author><keyname>Kumar</keyname><forenames>S.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Yousuf</keyname><forenames>Z.</forenames></author><author><keyname>Kumar</keyname><forenames>H.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author></authors><title>DSDV, DYMO, OLSR: Link Duration and Path Stability</title><categories>cs.NI</categories><journal-ref>Multicom2012 held in conjunction with the 11th IEEE International
  Conference on Ubiquitous Computing and Communications (IUCC-2012) (25 - 27
  June 2012, Liverpool, UK)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we evaluate and compare the impact of link duration and path
stability of routing protocols; Destination Sequence Distance vector (DSDV),
Dynamic MANET On- Demand (DYMO) and Optimized Link State Routing (OLSR) at
different number of connections and node density. In order to improve the
efficiency of selected protocols; we enhance DYMO and OLSR. Simulation and
comparison of both default and enhanced routing protocols is carried out under
the performance parameters; Packet Delivery Ratio (PDR), Average End-to End
Delay (AE2ED) and Normalized Routing Overhead (NRO). From the results, we
observe that DYMO performs better than DSDV, MOD-OLSR and OLSR in terms of PDR,
AE2ED, link duration and path stability at the cost of high value of NRO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1779</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1779</id><created>2012-07-07</created><authors><author><keyname>Briet</keyname><forenames>Jop</forenames></author><author><keyname>Buhrman</keyname><forenames>Harry</forenames></author><author><keyname>Gijswijt</keyname><forenames>Dion</forenames></author></authors><title>Violating the Shannon capacity of metric graphs with entanglement</title><categories>quant-ph cs.IT math.CO math.IT</categories><comments>15 pages, 2 figures</comments><doi>10.1073/pnas.1203857110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shannon capacity of a graph G is the maximum asymptotic rate at which
messages can be sent with zero probability of error through a noisy channel
with confusability graph G. This extensively studied graph parameter disregards
the fact that on atomic scales, Nature behaves in line with quantum mechanics.
Entanglement, arguably the most counterintuitive feature of the theory, turns
out to be a useful resource for communication across noisy channels. Recently,
Leung, Mancinska, Matthews, Ozols and Roy [Comm. Math. Phys. 311, 2012]
presented two examples of graphs whose Shannon capacity is strictly less than
the capacity attainable if the sender and receiver have entangled quantum
systems. Here we give new, possibly infinite, families of graphs for which the
entangled capacity exceeds the Shannon capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1788</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1788</id><created>2012-07-07</created><authors><author><keyname>Epstein</keyname><forenames>Leah</forenames></author><author><keyname>Levin</keyname><forenames>Asaf</forenames></author><author><keyname>Segev</keyname><forenames>Danny</forenames></author><author><keyname>Weimann</keyname><forenames>Oren</forenames></author></authors><title>Improved Bounds for Online Preemptive Matching</title><categories>cs.DS cs.DM</categories><msc-class>05C70, 68R10</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When designing a preemptive online algorithm for the maximum matching
problem, we wish to maintain a valid matching M while edges of the underlying
graph are presented one after the other. When presented with an edge e, the
algorithm should decide whether to augment the matching M by adding e (in which
case e may be removed later on) or to keep M in its current form without adding
e (in which case e is lost for good). The objective is to eventually hold a
matching M with maximum weight.
  The main contribution of this paper is to establish new lower and upper
bounds on the competitive ratio achievable by preemptive online algorithms:
  1. We provide a lower bound of 1+ln 2~1.693 on the competitive ratio of any
randomized algorithm for the maximum cardinality matching problem, thus
improving on the currently best known bound of e/(e-1)~1.581 due to Karp,
Vazirani, and Vazirani [STOC'90].
  2. We devise a randomized algorithm that achieves an expected competitive
ratio of 5.356 for maximum weight matching. This finding demonstrates the power
of randomization in this context, showing how to beat the tight bound of 3
+2\sqrt{2}~5.828 for deterministic algorithms, obtained by combining the 5.828
upper bound of McGregor [APPROX'05] and the recent 5.828 lower bound of
Varadaraja [ICALP'11].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1791</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1791</id><created>2012-07-07</created><updated>2012-11-27</updated><authors><author><keyname>Ruzzenenti</keyname><forenames>Franco</forenames></author><author><keyname>Picciolo</keyname><forenames>Francesco</forenames></author><author><keyname>Basosi</keyname><forenames>Riccardo</forenames></author><author><keyname>Garlaschelli</keyname><forenames>Diego</forenames></author></authors><title>Spatial effects in real networks: measures, null models, and
  applications</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Physical Review E 86, 066110 (2012)</journal-ref><doi>10.1103/PhysRevE.86.066110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatially embedded networks are shaped by a combination of purely topological
(space-independent) and space-dependent formation rules. While it is quite easy
to artificially generate networks where the relative importance of these two
factors can be varied arbitrarily, it is much more difficult to disentangle
these two architectural effects in real networks. Here we propose a solution to
the problem by introducing global and local measures of spatial effects that,
through a comparison with adequate null models, effectively filter out the
spurious contribution of non-spatial constraints. Our filtering allows us to
consistently compare different embedded networks or different historical
snapshots of the same network. As a challenging application we analyse the
World Trade Web, whose topology is expected to depend on geographic distances
but is also strongly determined by non-spatial constraints (degree sequence or
GDP). Remarkably, we are able to detect weak but significant spatial effects
both locally and globally in the network, showing that our method succeeds in
retrieving spatial information even when non-spatial factors dominate. We
finally relate our results to the economic literature on gravity models and
trade globalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1794</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1794</id><created>2012-07-07</created><authors><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author></authors><title>Design, Evaluation and Analysis of Combinatorial Optimization Heuristic
  Algorithms</title><categories>cs.DS cs.AI cs.DM math.OC</categories><comments>202 pages. Ph. D. Thesis. Royal Holloway, University of London. 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combinatorial optimization is widely applied in a number of areas nowadays.
Unfortunately, many combinatorial optimization problems are NP-hard which
usually means that they are unsolvable in practice. However, it is often
unnecessary to have an exact solution. In this case one may use heuristic
approach to obtain a near-optimal solution in some reasonable time.
  We focus on two combinatorial optimization problems, namely the Generalized
Traveling Salesman Problem and the Multidimensional Assignment Problem. The
first problem is an important generalization of the Traveling Salesman Problem;
the second one is a generalization of the Assignment Problem for an arbitrary
number of dimensions. Both problems are NP-hard and have hosts of applications.
  In this work, we discuss different aspects of heuristics design and
evaluation. A broad spectrum of related subjects, covered in this research,
includes test bed generation and analysis, implementation and performance
issues, local search neighborhoods and efficient exploration algorithms,
metaheuristics design and population sizing in memetic algorithm.
  The most important results are obtained in the areas of local search and
memetic algorithms for the considered problems. In both cases we have
significantly advanced the existing knowledge on the local search neighborhoods
and algorithms by systematizing and improving the previous results. We have
proposed a number of efficient heuristics which dominate the existing
algorithms in a wide range of time/quality requirements.
  Several new approaches, introduced in our memetic algorithms, make them the
state-of-the-art metaheuristics for the corresponding problems. Population
sizing is one of the most promising among these approaches; it is expected to
be applicable to virtually any memetic algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1805</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1805</id><created>2012-07-07</created><authors><author><keyname>Yilmaz</keyname><forenames>Ferkan</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>A Novel Ergodic Capacity Analysis of Diversity Combining and Multihop
  Transmission Systems over Generalized Composite Fading Channels</title><categories>cs.IT math.IT math.PR math.ST stat.TH</categories><comments>7 pages, no figure, published in IEEE International Conference on
  Communications (ICC 2012), Ottawa, Canada, 10th-15th June, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ergodic capacity is an important performance measure associated with reliable
communication at the highest rate at which information can be sent over the
channel with a negligible probability of error. In the shadow of this
definition, diversity receivers (such as selection combining, equal-gain
combining and maximal-ratio combining) and transmission techniques (such as
cascaded fading channels, amplify-and-forward multihop transmission) are
deployed in mitigating various performance impairing effects such as fading and
shadowing in digital radio communication links. However, the exact analysis of
ergodic capacity is in general not always possible for all of these forms of
diversity receivers and transmission techniques over generalized composite
fading environments due to it's mathematical intractability. In the literature,
published papers concerning the exact analysis of ergodic capacity have been
therefore scarce (i.e., only [1] and [2]) when compared to those concerning the
exact analysis of average symbol error probability. In addition, they are
essentially targeting to the ergodic capacity of the maximal ratio combining
diversity receivers and are not readily applicable to the capacity analysis of
the other diversity combiners / transmission techniques. In this paper, we
propose a novel moment generating function-based approach for the exact ergodic
capacity analysis of both diversity receivers and transmission techniques over
generalized composite fading environments. As such, we demonstrate how to
simultaneously treat the ergodic capacity analysis of all forms of both
diversity receivers and multihop transmission techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1809</identifier>
 <datestamp>2014-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1809</id><created>2012-07-07</created><updated>2014-02-04</updated><authors><author><keyname>Melnik</keyname><forenames>Sergey</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author><author><keyname>Gleeson</keyname><forenames>James P.</forenames></author></authors><title>Dynamics on Modular Networks with Heterogeneous Correlations</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.SI</categories><comments>12 pages, 13 figures</comments><journal-ref>Chaos 24, 023106 (2014)</journal-ref><doi>10.1063/1.4869983</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new ensemble of modular random graphs in which degree-degree
correlations can be different in each module and the inter-module connections
are defined by the joint degree-degree distribution of nodes for each pair of
modules. We present an analytical approach that allows one to analyze several
types of binary dynamics operating on such networks, and we illustrate our
approach using bond percolation, site percolation, and the Watts threshold
model. The new network ensemble generalizes existing models (e.g., the
well-known configuration model and LFR networks) by allowing a heterogeneous
distribution of degree-degree correlations across modules, which is important
for the consideration of nonidentical interacting networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1811</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1811</id><created>2012-07-07</created><authors><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>The SeqBin Constraint Revisited</title><categories>cs.AI</categories><comments>Longer version of paper accepted at CP 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the SeqBin constraint. This meta-constraint subsumes a number of
important global constraints like Change, Smooth and IncreasingNValue. We show
that the previously proposed filtering algorithm for SeqBin has two drawbacks
even under strong restrictions: it does not detect bounds disentailment and it
is not idempotent. We identify the cause for these problems, and propose a new
propagator that overcomes both issues. Our algorithm is based on a connection
to the problem of finding a path of a given cost in a restricted $n$-partite
graph. Our propagator enforces domain consistency in O(nd^2) and, for special
cases of SeqBin that include Change, Smooth and IncreasingNValue, in O(nd)
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1813</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1813</id><created>2012-07-07</created><authors><author><keyname>Earl</keyname><forenames>Christopher</forenames></author><author><keyname>Sergey</keyname><forenames>Ilya</forenames></author><author><keyname>Might</keyname><forenames>Matthew</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>Introspective Pushdown Analysis of Higher-Order Programs</title><categories>cs.PL</categories><comments>Proceedings of the 17th ACM SIGPLAN International Conference on
  Functional Programming, 2012, ACM</comments><acm-class>D.3.4; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the static analysis of functional programs, pushdown flow analysis and
abstract garbage collection skirt just inside the boundaries of soundness and
decidability. Alone, each method reduces analysis times and boosts precision by
orders of magnitude. This work illuminates and conquers the theoretical
challenges that stand in the way of combining the power of these techniques.
The challenge in marrying these techniques is not subtle: computing the
reachable control states of a pushdown system relies on limiting access during
transition to the top of the stack; abstract garbage collection, on the other
hand, needs full access to the entire stack to compute a root set, just as
concrete collection does. \emph{Introspective} pushdown systems resolve this
conflict. Introspective pushdown systems provide enough access to the stack to
allow abstract garbage collection, but they remain restricted enough to compute
control-state reachability, thereby enabling the sound and precise product of
pushdown analysis and abstract garbage collection. Experiments reveal
synergistic interplay between the techniques, and the fusion demonstrates
&quot;better-than-both-worlds&quot; precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1818</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1818</id><created>2012-07-07</created><authors><author><keyname>Gouveia</keyname><forenames>R&#xfa;ben</forenames></author><author><keyname>Niforatos</keyname><forenames>Evangelos</forenames></author><author><keyname>Karapanos</keyname><forenames>Evangelos</forenames></author></authors><title>Footprint Tracker: reviewing lifelogs and reconstructing daily
  experiences</title><categories>cs.HC</categories><journal-ref>Gouveia, R., Niforatos, E., Karapanos, E. (2012) Footprint
  Tracker: reviewing lifelogs and reconstructing daily experiences, In adjunct
  proceedings of ACM conference on Designing Interactive Systems, DIS'12</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing emphasis on how mobile technologies are experienced in
everyday life, researchers are increasingly emphasizing the use of in-situ
methods such as Experience Sampling and Day Reconstruction. In our line of
research we explore the concept of Technology-Assisted Reconstruction, in which
passively logged behavior data assist in the later reconstruction of daily
experiences. In this paper we introduce Footprint tracker, a web application
that supports participants in reviewing lifelogs and reconstructing their daily
experiences. We focus on three kinds of data: visual (as captured through
Microsoft's sensecam), location, and context (i.e., SMS and calls received and
made). We describe how Footprint Tracker supports the user in reviewing these
lifelogs and outline a field study that attempts to inquire into whether and
how this data support reconstruction from memory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1820</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1820</id><created>2012-07-07</created><authors><author><keyname>Rodrigues</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Gouveia</keyname><forenames>R&#xfa;ben</forenames></author><author><keyname>Lyra</keyname><forenames>Olga</forenames></author><author><keyname>Karapanos</keyname><forenames>Evangelos</forenames></author></authors><title>Sense me: Supporting awareness in parent-child relationships through
  mobile sensing</title><categories>cs.HC</categories><journal-ref>Rodrigues, J., Gouveia, R., Lyra, O., Karapanos, E. (2012) Sense
  me: Supporting awareness in parent-child relationships through mobile
  sensing, In adjunct proceedings of ACM conference on Designing Interactive
  Systems, DIS'12</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Sense{\mu} (pronounced &quot;sense me&quot;), a mobile application that
aims at supporting awareness in parent- child relationships through the sensing
capabilities of mobile devices. We discuss the relevance of three types of
awareness information: physical activity inferred from accelerometers, verbal
activity during class hours inferred from microphones, and social activity
inferred from Bluetooth pair-wise proximity sensing. We describe how we attempt
to contextualize these sensing data with the goal of supporting parents'
awareness of the educational performance and social wellbeing of their
children, as well as motivating and sustaining a two-way communication between
parents and teachers over the long term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1821</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1821</id><created>2012-07-07</created><authors><author><keyname>Karapanos</keyname><forenames>Evangelos</forenames></author></authors><title>Beyond Experience Sampling: Evaluating Personal Informatics with
  Technology-Assisted Reconstruction</title><categories>cs.HC</categories><journal-ref>In adjunct proceedings of the conference on Human factors in
  computing systems (CHI 2012), Workshop on Personal Informatics in Practice:
  Improving Quality of Life Through Data. Austin, Canada</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experience Sampling has been considered the golden standard of in-situ
measurement, yet, at the expense of high burden to participants. In this paper
we propose Technology-Assisted Reconstruction (TAR), a methodological approach
that combines passive logging of users' behaviors with use of these data in
assisting the reconstruction of behaviors and experiences. Through a number of
recent and ongoing projects we will discuss how TAR may be employed for the
evaluation of personal informatics systems, but also, conversely, how ideas
from the field of personal informatics may contribute towards the development
of new methodologies for in-situ evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1824</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1824</id><created>2012-07-07</created><authors><author><keyname>Boppana</keyname><forenames>Meena</forenames></author></authors><title>Lattice Variant of the Sensitivity Conjecture</title><categories>math.CO cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Sensitivity Conjecture, posed in 1994, states that the fundamental
measures known as the sensitivity and block sensitivity of a Boolean function
f, s(f) and bs(f) respectively, are polynomially related. It is known that
bs(f) is polynomially related to important measures in computer science
including the decision-tree depth, polynomial degree, and parallel RAM
computation time of f, but little is known how the sensitivity compares; the
separation between s(f) and bs(f) is at least quadratic and at most
exponential. We analyze a promising variant by Aaronson that implies the
Sensitivity Conjecture, stating that for all two-colorings of the d-dimensional
lattice $\mathbb{Z}^d$, d and the sensitivity s(C) are polynomially related,
where s(C) is the maximum number of differently-colored neighbors of a point.
We construct a coloring with the largest known separation between d and s(C),
in which $d=O(s(C)^2)$, and demonstrate that it is optimal for a large class of
colorings. We also give a reverse reduction from the Lattice Variant to the
Sensitivity Conjecture, and using this prove the first non-constant lower bound
on s(C). These results indicate that the Lattice Variant can help further the
limited progress on the Sensitivity Conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1831</identifier>
 <datestamp>2012-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1831</id><created>2012-07-07</created><updated>2012-11-27</updated><authors><author><keyname>Elkin</keyname><forenames>Michael</forenames></author><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>Optimal Euclidean spanners: really short, thin and lanky</title><categories>cs.DS</categories><comments>A technical report of this paper was available online from April 4,
  2012</comments><report-no>TR CS-12-04, Ben-Gurion University</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a seminal STOC'95 paper, titled &quot;Euclidean spanners: short, thin and
lanky&quot;, Arya et al. devised a construction of Euclidean $(1+\eps)$-spanners
that achieves constant degree, diameter $O(\log n)$, and weight $O(\log^2 n)
\cdot \omega(MST)$, and has running time $O(n \cdot \log n)$. This construction
applies to $n$-point constant-dimensional Euclidean spaces. Moreover, Arya et
al. conjectured that the weight bound can be improved by a logarithmic factor,
without increasing the degree and the diameter of the spanner, and within the
same running time.
  This conjecture of Arya et al. became a central open problem in the area of
Euclidean spanners.
  In this paper we resolve the long-standing conjecture of Arya et al. in the
affirmative. Specifically, we present a construction of spanners with the same
stretch, degree, diameter, and running time, as in Arya et al.'s result, but
with optimal weight $O(\log n) \cdot \omega(MST)$.
  Moreover, our result is more general in three ways. First, we demonstrate
that the conjecture holds true not only in constant-dimensional Euclidean
spaces, but also in doubling metrics. Second, we provide a general tradeoff
between the three involved parameters, which is tight in the entire range.
Third, we devise a transformation that decreases the lightness of spanners in
general metrics, while keeping all their other parameters in check. Our main
result is obtained as a corollary of this transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1832</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1832</id><created>2012-07-07</created><updated>2012-07-09</updated><authors><author><keyname>Saffidine</keyname><forenames>Abdallah</forenames></author></authors><title>Minimal Proof Search for Modal Logic K Model Checking</title><categories>cs.AI cs.LO</categories><comments>Extended version of the JELIA 2012 paper with the same title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most modal logics such as S5, LTL, or ATL are extensions of Modal Logic K.
While the model checking problems for LTL and to a lesser extent ATL have been
very active research areas for the past decades, the model checking problem for
the more basic Multi-agent Modal Logic K (MMLK) has important applications as a
formal framework for perfect information multi-player games on its own.
  We present Minimal Proof Search (MPS), an effort number based algorithm
solving the model checking problem for MMLK. We prove two important properties
for MPS beyond its correctness. The (dis)proof exhibited by MPS is of minimal
cost for a general definition of cost, and MPS is an optimal algorithm for
finding (dis)proofs of minimal cost. Optimality means that any comparable
algorithm either needs to explore a bigger or equal state space than MPS, or is
not guaranteed to find a (dis)proof of minimal cost on every input.
  As such, our work relates to A* and AO* in heuristic search, to Proof Number
Search and DFPN+ in two-player games, and to counterexample minimization in
software model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1836</identifier>
 <datestamp>2012-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1836</id><created>2012-07-07</created><updated>2012-10-16</updated><authors><author><keyname>Halldorsson</keyname><forenames>Magnus M.</forenames></author><author><keyname>Mitra</keyname><forenames>Pradipta</forenames></author></authors><title>Towards Tight Bounds for Local Broadcasting</title><categories>cs.NI cs.DC</categories><comments>15 pages, 1 figure, FOMC 2012, minor edits</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the local broadcasting problem in the SINR model, which is a
basic primitive for gathering initial information among $n$ wireless nodes.
Assuming that nodes can measure received power, we achieve an essentially
optimal constant approximate algorithm (with a $\log^2 n$ additive term). This
improves upon the previous best $O(\log n)$-approximate algorithm. Without
power measurement, our algorithm achieves $O(\log n)$-approximation, matching
the previous best result, but with a simpler approach that works under harsher
conditions, such as arbitrary node failures. We give complementary lower bounds
under reasonable assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1838</identifier>
 <datestamp>2015-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1838</id><created>2012-07-08</created><updated>2015-08-31</updated><authors><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Mao</keyname><forenames>Yaping</forenames></author></authors><title>A survey on the generalized connectivity of graphs</title><categories>math.CO cs.DM</categories><comments>51 pages. arXiv admin note: text overlap with arXiv:1303.3881 by
  other authors</comments><msc-class>05C05, 05C35, 05C40, 05C70, 05C75, 05C76, 05C80, 05C85, 68M10,
  68Q25, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized $k$-connectivity $\kappa_k(G)$ of a graph $G$ was introduced
by Hager before 1985. As its a natural counterpart, we introduced the concept
of generalized edge-connectivity $\lambda_k(G)$, recently. In this paper we
summarize the known results on the generalized connectivity and generalized
edge-connectivity. After an introductory section, the paper is then divided
into nine sections: the generalized (edge-)connectivity of some graph classes,
algorithms and computational complexity, sharp bounds of $\kappa_k(G)$ and
$\lambda_k(G)$, graphs with large generalized (edge-)connectivity,
Nordhaus-Gaddum-type results, graph operations, extremal problems, and some
results for random graphs and multigraphs. It also contains some conjectures
and open problems for further studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1841</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1841</id><created>2012-07-08</created><authors><author><keyname>Andr&#xe9;s</keyname><forenames>C&#xe9;sar</forenames><affiliation>Universidad Complutense de Madrid</affiliation></author><author><keyname>Llana</keyname><forenames>Luis</forenames><affiliation>Universidad Complutense de Madrid</affiliation></author></authors><title>Proceedings 2nd Workshop on Formal Methods in the Development of
  Software</title><categories>cs.SE cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 86, 2012</journal-ref><doi>10.4204/EPTCS.86</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 2nd WorkShop on Formal Methods in
the Development of Software (WS-FMDS 2012). The workshop was held in Paris,
France on August 30th, 2012 as a satellite event to the 18th International
Symposium on Formal Methods (FM-2012).
  The aim of WS-FMDS 2012 is to provide a forum for researchers who are
interested in the application of formal methods on systems which are being
developing with a software methodology. In particular, this workshop is
intended to bring together scientists and practitioners who are active in the
area of formal methods and interested in exchanging their experiences in the
industrial usage of these methods. This workshop also strives to promote
research and development for the improvement of formal methods and tools for
industrial applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1845</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1845</id><created>2012-07-08</created><authors><author><keyname>Choi</keyname><forenames>Sung-Tai</forenames></author><author><keyname>Hong</keyname><forenames>Seokbeom</forenames></author><author><keyname>No</keyname><forenames>Jong-Seon</forenames></author><author><keyname>Chung</keyname><forenames>Habong</forenames></author></authors><title>Differential Spectrum of Some Power Functions With Low Differential
  Uniformity</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, for an odd prime $p$, the differential spectrum of the power
function $x^{\frac{p^k+1}{2}}$ in $\mathbb{F}_{p^n}$ is calculated. For an odd
prime $p$ such that $p\equiv 3\bmod 4$ and odd $n$ with $k|n$, the differential
spectrum of the power function $x^{\frac{p^n+1}{p^k+1}+\frac{p^n-1}{2}}$ in
$\mathbb{F}_{p^n}$ is also derived. From their differential spectrums, the
differential uniformities of these two power functions are determined. We also
find some new power functions having low differential uniformity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1847</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1847</id><created>2012-07-08</created><authors><author><keyname>Dunning</keyname><forenames>Ted</forenames></author></authors><title>Finding Structure in Text, Genome and Other Symbolic Sequences</title><categories>cs.CL cs.IR</categories><comments>~ 176 pages, many figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The statistical methods derived and described in this thesis provide new ways
to elucidate the structural properties of text and other symbolic sequences.
Generically, these methods allow detection of a difference in the frequency of
a single feature, the detection of a difference between the frequencies of an
ensemble of features and the attribution of the source of a text. These three
abstract tasks suffice to solve problems in a wide variety of settings.
Furthermore, the techniques described in this thesis can be extended to provide
a wide range of additional tests beyond the ones described here.
  A variety of applications for these methods are examined in detail. These
applications are drawn from the area of text analysis and genetic sequence
analysis. The textually oriented tasks include finding interesting collocations
and cooccurent phrases, language identification, and information retrieval. The
biologically oriented tasks include species identification and the discovery of
previously unreported long range structure in genes. In the applications
reported here where direct comparison is possible, the performance of these new
methods substantially exceeds the state of the art.
  Overall, the methods described here provide new and effective ways to analyse
text and other symbolic sequences. Their particular strength is that they deal
well with situations where relatively little data are available. Since these
methods are abstract in nature, they can be applied in novel situations with
relative ease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1852</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1852</id><created>2012-07-08</created><updated>2013-05-10</updated><authors><author><keyname>Lenzen</keyname><forenames>Christoph</forenames></author></authors><title>Optimal Deterministic Routing and Sorting on the Congested Clique</title><categories>cs.DC</categories><comments>16 pages, no figures; published at PODC 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a clique of n nodes, where in each synchronous round each pair of
nodes can exchange O(log n) bits. We provide deterministic constant-time
solutions for two problems in this model. The first is a routing problem where
each node is source and destination of n messages of size O(log n). The second
is a sorting problem where each node i is given n keys of size O(log n) and
needs to receive the ith batch of n keys according to the global order of the
keys. The latter result also implies deterministic constant-round solutions for
related problems such as selection or determining modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1855</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1855</id><created>2012-07-08</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Yuanqing</forenames></author><author><keyname>Yu</keyname><forenames>Zhu Liang</forenames></author><author><keyname>Gu</keyname><forenames>Zhenghui</forenames></author></authors><title>Recoverability Analysis for Modified Compressive Sensing with Partially
  Known Support</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently proposed modified-compressive sensing (modified-CS), which
utilizes the partially known support as prior knowledge, significantly improves
the performance of recovering sparse signals. However, modified-CS depends
heavily on the reliability of the known support. An important problem, which
must be studied further, is the recoverability of modified-CS when the known
support contains a number of errors. In this letter, we analyze the
recoverability of modified-CS in a stochastic framework. A sufficient and
necessary condition is established for exact recovery of a sparse signal.
Utilizing this condition, the recovery probability that reflects the
recoverability of modified-CS can be computed explicitly for a sparse signal
with \ell nonzero entries, even though the known support exists some errors.
Simulation experiments have been carried out to validate our theoretical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1860</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1860</id><created>2012-07-08</created><authors><author><keyname>Ho</keyname><forenames>Siu-Wai</forenames></author><author><keyname>Chan</keyname><forenames>Terence H.</forenames></author><author><keyname>Grant</keyname><forenames>Alex</forenames></author><author><keyname>Uduwerelle</keyname><forenames>Chinthani</forenames></author></authors><title>Error Free Perfect Secrecy Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. Info. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shannon's fundamental bound for perfect secrecy says that the entropy of the
secret message cannot be larger than the entropy of the secret key initially
shared by the sender and the legitimate receiver. Massey gave an information
theoretic proof of this result, however this proof does not require
independence of the key and ciphertext. By further assuming independence, we
obtain a tighter lower bound, namely that the key entropy is not less than the
logarithm of the message sample size in any cipher achieving perfect secrecy,
even if the source distribution is fixed. The same bound also applies to the
entropy of the ciphertext. The bounds still hold if the secret message has been
compressed before encryption.
  This paper also illustrates that the lower bound only gives the minimum size
of the pre-shared secret key. When a cipher system is used multiple times, this
is no longer a reasonable measure for the portion of key consumed in each
round. Instead, this paper proposes and justifies a new measure for key
consumption rate. The existence of a fundamental tradeoff between the expected
key consumption and the number of channel uses for conveying a ciphertext is
shown. Optimal and nearly optimal secure codes are designed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1872</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1872</id><created>2012-07-08</created><updated>2013-08-22</updated><authors><author><keyname>Bochkarev</keyname><forenames>Vladimir V.</forenames></author><author><keyname>Lerner</keyname><forenames>Eduard Yu.</forenames></author></authors><title>Zipf and non-Zipf Laws for Homogeneous Markov Chain</title><categories>cs.IT math.IT math.PR</categories><comments>13 pages, 4 figures</comments><msc-class>60J10, 60J20</msc-class><acm-class>G.3; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let us consider a homogeneous Markov chain with discrete time and with a
finite set of states $E_0,\ldots,E_n$ such that the state $E_0$ is absorbing,
states $E_1,\ldots,E_n$ are nonrecurrent. The goal of this work is to study
frequencies of trajectories in this chain, i.e., &quot;words&quot; composed of symbols
$E_1,\ldots,E_n$ ending with the &quot;space&quot; $E_0$.
  Let us order words according to their probabilities; denote by $p(t)$ the
probability of the $t$th word in this list. In this paper we prove that in a
typical case the asymptotics of the function $p(t)$ has a power character, and
define its exponent from the matrix of transition probabilities. If this matrix
is block-diagonal, then with some specific values of transition probabilities
the power asymptotics gets (logarithmic) addends. But if this matrix is rather
sparse, then probabilities quickly decrease; namely, the rate of asymptotics is
greater than that of the power one, but not greater than that of the
exponential one. We also establish necessary and sufficient conditions for the
exponential order of decrease and obtain a formula for determining the exponent
from the transition probability matrix and the initial distribution vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1875</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1875</id><created>2012-07-08</created><authors><author><keyname>Gupta</keyname><forenames>S. K.</forenames></author><author><keyname>Khandelwal</keyname><forenames>Akash</forenames></author></authors><title>Reconstruction Conjecture for Graphs Isomorphic to Cube of a Tree</title><categories>cs.DM</categories><comments>10 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proves the reconstruction conjecture for graphs which are
isomorphic to the cube of a tree. The proof uses the reconstructibility of
trees from their peripheral vertex deleted subgraphs. The main result follows
from (i) characterization of the cube of a tree (ii) recognizability of the
cube of a tree (iii) uniqueness of tree as a cube root of a graph G, except
when G is a complete graph (iv) reconstructibility of trees from their
peripheral vertex deleted subgraphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1878</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1878</id><created>2012-07-08</created><authors><author><keyname>Yun</keyname><forenames>Donggyu</forenames></author><author><keyname>Ok</keyname><forenames>Jungseul</forenames></author><author><keyname>Shin</keyname><forenames>Bongjhin</forenames></author><author><keyname>Park</keyname><forenames>Soobum</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author></authors><title>Embedding of Virtual Network Requests over Static Wireless Multihop
  Networks</title><categories>cs.NI</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network virtualization is a technology of running multiple heterogeneous
network architecture on a shared substrate network. One of the crucial
components in network virtualization is virtual network embedding, which
provides a way to allocate physical network resources (CPU and link bandwidth)
to virtual network requests. Despite significant research efforts on virtual
network embedding in wired and cellular networks, little attention has been
paid to that in wireless multi-hop networks, which is becoming more important
due to its rapid growth and the need to share these networks among different
business sectors and users. In this paper, we first study the root causes of
new challenges of virtual network embedding in wireless multi-hop networks, and
propose a new embedding algorithm that efficiently uses the resources of the
physical substrate network. We examine our algorithm's performance through
extensive simulations under various scenarios. Due to lack of competitive
algorithms, we compare the proposed algorithm to five other algorithms, mainly
borrowed from wired embedding or artificially made by us, partially with or
without the key algorithmic ideas to assess their impacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1885</identifier>
 <datestamp>2012-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1885</id><created>2012-07-08</created><updated>2012-10-15</updated><authors><author><keyname>Clifford</keyname><forenames>Raphael</forenames></author><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author><author><keyname>Sach</keyname><forenames>Benjamin</forenames></author></authors><title>Tight Cell-Probe Bounds for Online Hamming Distance Computation</title><categories>cs.DS cs.CC</categories><comments>19 pages, 3 figures</comments><acm-class>F.2.2; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show tight bounds for online Hamming distance computation in the
cell-probe model with word size w. The task is to output the Hamming distance
between a fixed string of length n and the last n symbols of a stream. We give
a lower bound of Omega((d/w)*log n) time on average per output, where d is the
number of bits needed to represent an input symbol. We argue that this bound is
tight within the model. The lower bound holds under randomisation and
amortisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1893</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1893</id><created>2012-07-08</created><authors><author><keyname>Briat</keyname><forenames>Corentin</forenames></author><author><keyname>Seuret</keyname><forenames>Alexandre</forenames></author></authors><title>A looped-functional approach for robust stability analysis of linear
  impulsive systems</title><categories>math.OC cs.SY math.CA math.DS</categories><comments>13 pages, 2 figures, Accepted at Systems &amp; Control Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new functional-based approach is developed for the stability analysis of
linear impulsive systems. The new method, which introduces looped-functionals,
considers non-monotonic Lyapunov functions and leads to LMIs conditions devoid
of exponential terms. This allows one to easily formulate dwell-times results,
for both certain and uncertain systems. It is also shown that this approach may
be applied to a wider class of impulsive systems than existing methods. Some
examples, notably on sampled-data systems, illustrate the efficiency of the
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1894</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1894</id><created>2012-07-08</created><authors><author><keyname>Cabibihan</keyname><forenames>John-John</forenames></author><author><keyname>So</keyname><forenames>Wing-Chee</forenames></author><author><keyname>Saj</keyname><forenames>Sujin</forenames></author><author><keyname>Zhang</keyname><forenames>Zhengchen</forenames></author></authors><title>Telerobotic Pointing Gestures Shape Human Spatial Cognition</title><categories>cs.HC cs.RO physics.med-ph</categories><comments>27 pages, 7 figures</comments><doi>10.1007/s12369-012-0148-9</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper aimed to explore whether human beings can understand gestures
produced by telepresence robots. If it were the case, they can derive meaning
conveyed in telerobotic gestures when processing spatial information. We
conducted two experiments over Skype in the present study. Participants were
presented with a robotic interface that had arms, which were teleoperated by an
experimenter. The robot could point to virtual locations that represented
certain entities. In Experiment 1, the experimenter described spatial locations
of fictitious objects sequentially in two conditions: speech condition (SO,
verbal descriptions clearly indicated the spatial layout) and speech and
gesture condition (SR, verbal descriptions were ambiguous but accompanied by
robotic pointing gestures). Participants were then asked to recall the objects'
spatial locations. We found that the number of spatial locations recalled in
the SR condition was on par with that in the SO condition, suggesting that
telerobotic pointing gestures compensated ambiguous speech during the process
of spatial information. In Experiment 2, the experimenter described spatial
locations non-sequentially in the SR and SO conditions. Surprisingly, the
number of spatial locations recalled in the SR condition was even higher than
that in the SO condition, suggesting that telerobotic pointing gestures were
more powerful than speech in conveying spatial information when information was
presented in an unpredictable order. The findings provide evidence that human
beings are able to comprehend telerobotic gestures, and importantly, integrate
these gestures with co-occurring speech. This work promotes engaging remote
collaboration among humans through a robot intermediary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1915</identifier>
 <datestamp>2012-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1915</id><created>2012-07-08</created><authors><author><keyname>Gir&#xf3;n</keyname><forenames>Edwin</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>Cribari-Neto</keyname><forenames>Francisco</forenames></author></authors><title>Nonparametric Edge Detection in Speckled Imagery</title><categories>stat.AP cs.CV stat.ML</categories><comments>Accepted for publication in Mathematics and Computers in Simulation</comments><journal-ref>Mathematics and Computers in Simulation, vol. 82, pages 2182-2198,
  2012</journal-ref><doi>10.1016/j.matcom.2012.04.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the issue of edge detection in Synthetic Aperture Radar imagery.
In particular, we propose nonparametric methods for edge detection, and
numerically compare them to an alternative method that has been recently
proposed in the literature. Our results show that some of the proposed methods
display superior results and are computationally simpler than the existing
method. An application to real (not simulated) data is presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1916</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1916</id><created>2012-07-08</created><authors><author><keyname>de Almeida</keyname><forenames>Eliana S.</forenames></author><author><keyname>Medeiros</keyname><forenames>Antonio C.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>How good are MatLab, Octave and Scilab for Computational Modelling?</title><categories>cs.MS stat.CO</categories><comments>Accepted for publication in the Computational and Applied Mathematics
  journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we test the accuracy of three platforms used in computational
modelling: MatLab, Octave and Scilab, running on i386 architecture and three
operating systems (Windows, Ubuntu and Mac OS). We submitted them to numerical
tests using standard data sets and using the functions provided by each
platform. A Monte Carlo study was conducted in some of the datasets in order to
verify the stability of the results with respect to small departures from the
original input. We propose a set of operations which include the computation of
matrix determinants and eigenvalues, whose results are known. We also used data
provided by NIST (National Institute of Standards and Technology), a protocol
which includes the computation of basic univariate statistics (mean, standard
deviation and first-lag correlation), linear regression and extremes of
probability distributions. The assessment was made comparing the results
computed by the platforms with certified values, that is, known results,
computing the number of correct significant digits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1921</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1921</id><created>2012-07-08</created><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>Spreadsheets and Long Term Corporate Survival</title><categories>cs.CY</categories><comments>20 Pages, 21 Tables</comments><proxy>Grenville Croll</proxy><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2012 77-96</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have conducted an empirical investigation into the long term survival
rates of some small but representative samples of the 30,000 largest UK limited
companies. These companies were either a control or known to have used, or been
interested in the use of, spreadsheets, spreadsheet based monte carlo
simulation software, other spreadsheet and decision analysis software and/or
related management training. We show that there is a material and statistically
significant increase in the long term survival rate of all of these groups of
companies compared to the control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1922</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1922</id><created>2012-07-08</created><authors><author><keyname>Al-Wassai</keyname><forenames>Firouz Abdullah</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author><author><keyname>Al-Zaky</keyname><forenames>Ali A.</forenames></author></authors><title>Spatial And Spectral Quality Evaluation Based On Edges Regions Of
  Satellite Image Fusion</title><categories>cs.CV</categories><comments>2nd International Conference on Advanced Computing &amp; Communication
  Technologies (ACCT12),7 -- 8 January 2012</comments><journal-ref>International Journal of Latest Technology in
  Engineering,Management &amp; Applied Science (IJLTEMAS),Vol. I, Issue V, 2012,
  124-138</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Quality of image fusion is an essential determinant of the value of
processing images fusion for many applications. Spatial and spectral qualities
are the two important indexes that used to evaluate the quality of any fused
image. However, the jury is still out of fused image's benefits if it compared
with its original images. In addition, there is a lack of measures for
assessing the objective quality of the spatial resolution for the fusion
methods. Therefore, an objective quality of the spatial resolution assessment
for fusion images is required. Most important details of the image are in edges
regions, but most standards of image estimation do not depend upon specifying
the edges in the image and measuring their edges. However, they depend upon the
general estimation or estimating the uniform region, so this study deals with
new method proposed to estimate the spatial resolution by Contrast Statistical
Analysis (CSA) depending upon calculating the contrast of the edge, non edge
regions and the rate for the edges regions. Specifying the edges in the image
is made by using Soble operator with different threshold values. In addition,
estimating the color distortion added by image fusion based on Histogram
Analysis of the edge brightness values of all RGB-color bands and Lcomponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1927</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1927</id><created>2012-07-08</created><updated>2015-06-19</updated><authors><author><keyname>Brummitt</keyname><forenames>Charles D.</forenames></author><author><keyname>Chatterjee</keyname><forenames>Shirshendu</forenames></author><author><keyname>Dey</keyname><forenames>Partha S.</forenames></author><author><keyname>Sivakoff</keyname><forenames>David</forenames></author></authors><title>Jigsaw percolation: What social networks can collaboratively solve a
  puzzle?</title><categories>math.PR cond-mat.dis-nn cs.SI physics.soc-ph</categories><comments>Published at http://dx.doi.org/10.1214/14-AAP1041 in the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP1041</report-no><journal-ref>Annals of Applied Probability 2015, Vol. 25, No. 4, 2013-2038</journal-ref><doi>10.1214/14-AAP1041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new kind of percolation on finite graphs called jigsaw
percolation. This model attempts to capture networks of people who innovate by
merging ideas and who solve problems by piecing together solutions. Each person
in a social network has a unique piece of a jigsaw puzzle. Acquainted people
with compatible puzzle pieces merge their puzzle pieces. More generally, groups
of people with merged puzzle pieces merge if the groups know one another and
have a pair of compatible puzzle pieces. The social network solves the puzzle
if it eventually merges all the puzzle pieces. For an Erd\H{o}s-R\'{e}nyi
social network with $n$ vertices and edge probability $p_n$, we define the
critical value $p_c(n)$ for a connected puzzle graph to be the $p_n$ for which
the chance of solving the puzzle equals $1/2$. We prove that for the $n$-cycle
(ring) puzzle, $p_c(n)=\Theta(1/\log n)$, and for an arbitrary connected puzzle
graph with bounded maximum degree, $p_c(n)=O(1/\log n)$ and $\omega(1/n^b)$ for
any $b&gt;0$. Surprisingly, with probability tending to 1 as the network size
increases to infinity, social networks with a power-law degree distribution
cannot solve any bounded-degree puzzle. This model suggests a mechanism for
recent empirical claims that innovation increases with social density, and it
might begin to show what social networks stifle creativity and what networks
collectively innovate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1933</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1933</id><created>2012-07-08</created><authors><author><keyname>Kim</keyname><forenames>Gol</forenames><affiliation>Center of Natural Science, University of Sciences, Pyongyang, DPR Korea</affiliation></author><author><keyname>Yun</keyname><forenames>Ri Suk</forenames><affiliation>Foreign Economic General Bureau, Pyongyang, DPR Korea</affiliation></author></authors><title>A Hybrid Forecast of Exchange Rate based on ARFIMA,Discrete Grey-Markov,
  and Fractal Kalman Model</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a hybrid forecast based on extended discrete grey Markov and
variable dimension Kalman model and show that our hybrid model can improve much
more the performance of forecast than traditional grey Markov and Kalman
models. Our simulation results are given to demonstrate that our hybrid
forecast method combined with degree of grey incidence are better than grey
Markov and ARFIMA model or Kalman methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1936</identifier>
 <datestamp>2013-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1936</id><created>2012-07-08</created><updated>2012-09-29</updated><authors><author><keyname>Kurihara</keyname><forenames>Jun</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author></authors><title>New Parameters of Linear Codes Expressing Security Performance of
  Universal Secure Network Coding</title><categories>cs.IT cs.CR math.CO math.IT</categories><comments>IEEEtran.cls, 8 pages, no figure. To appear in Proc. 50th Annual
  Allerton Conference on Communication, Control, and Computing (Allerton 2012).
  Version 2 added an exact expression of the universal error correction
  capability in terms of the relative generalized rank weight</comments><journal-ref>Proceedings of 2012 50th Annual Allerton Conference on
  Communication, Control, and Computing (Allerton), pp.533 -- 540, 1--5 Oct.
  2012</journal-ref><doi>10.1109/Allerton.2012.6483264</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The universal secure network coding presented by Silva et al. realizes secure
and reliable transmission of a secret message over any underlying network code,
by using maximum rank distance codes. Inspired by their result, this paper
considers the secure network coding based on arbitrary linear codes, and
investigates its security performance and error correction capability that are
guaranteed independently of the underlying network code. The security
performance and error correction capability are said to be universal when they
are independent of underlying network codes. This paper introduces new code
parameters, the relative dimension/intersection profile (RDIP) and the relative
generalized rank weight (RGRW) of linear codes. We reveal that the universal
security performance and universal error correction capability of secure
network coding are expressed in terms of the RDIP and RGRW of linear codes. The
security and error correction of existing schemes are also analyzed as
applications of the RDIP and RGRW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1965</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1965</id><created>2012-07-09</created><authors><author><keyname>Devaine</keyname><forenames>Marie</forenames><affiliation>DMA</affiliation></author><author><keyname>Gaillard</keyname><forenames>Pierre</forenames><affiliation>DMA, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Goude</keyname><forenames>Yannig</forenames><affiliation>DMA, INRIA Paris - Rocquencourt, GREGH</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>DMA, INRIA Paris - Rocquencourt, GREGH</affiliation></author></authors><title>Forecasting electricity consumption by aggregating specialized experts</title><categories>stat.ML cs.LG stat.AP</categories><comments>33 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the setting of sequential prediction of arbitrary sequences based
on specialized experts. We first provide a review of the relevant literature
and present two theoretical contributions: a general analysis of the specialist
aggregation rule of Freund et al. (1997) and an adaptation of fixed-share rules
of Herbster and Warmuth (1998) in this setting. We then apply these rules to
the sequential short-term (one-day-ahead) forecasting of electricity
consumption; to do so, we consider two data sets, a Slovakian one and a French
one, respectively concerned with hourly and half-hourly predictions. We follow
a general methodology to perform the stated empirical studies and detail in
particular tuning issues of the learning parameters. The introduced aggregation
rules demonstrate an improved accuracy on the data sets at hand; the
improvements lie in a reduced mean squared error but also in a more robust
behavior with respect to large occasional errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1977</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1977</id><created>2012-07-09</created><authors><author><keyname>Entner</keyname><forenames>Doris</forenames></author><author><keyname>Hoyer</keyname><forenames>Patrik O.</forenames></author></authors><title>Estimating a Causal Order among Groups of Variables in Linear Models</title><categories>stat.ML cs.LG stat.ME</categories><comments>To appear at the International Conference on Artificial Neural
  Networks 2012 (proceedings to be published in LNCS, Springer); To be
  presented at the UAI Workshop on Causal Structure Learning 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The machine learning community has recently devoted much attention to the
problem of inferring causal relationships from statistical data. Most of this
work has focused on uncovering connections among scalar random variables. We
generalize existing methods to apply to collections of multi-dimensional random
vectors, focusing on techniques applicable to linear models. The performance of
the resulting algorithms is evaluated and compared in simulations, which show
that our methods can, in many cases, provide useful information on causal
relationships even for relatively small sample sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1982</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1982</id><created>2012-07-09</created><authors><author><keyname>Brzozowski</keyname><forenames>Janusz</forenames></author><author><keyname>Liu</keyname><forenames>David</forenames></author></authors><title>Universal Witnesses for State Complexity of Boolean Operations and
  Concatenation Combined with Star</title><categories>cs.FL</categories><comments>16 pages, 7 figures, LNCS style</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the state complexity of boolean operations and product
(concatenation, catenation) combined with star. We derive tight upper bounds
for the symmetric differences and differences of two languages, one or both of
which are starred, and for the product of two starred languages. We prove that
the previously discovered bounds for the union and the intersection of
languages with one or two starred arguments, for the product of two languages
one of which is starred, and for the star of the product of two languages can
all be met by the recently introduced universal witnesses and their variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.1986</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.1986</id><created>2012-07-09</created><authors><author><keyname>Xu</keyname><forenames>Xiaoli</forenames></author><author><keyname>Zeng</keyname><forenames>Yong</forenames></author><author><keyname>Guan</keyname><forenames>Yong Liang</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author></authors><title>On the Capacity Region of Two-User Linear Deterministic Interference
  Channel and Its Application to Multi-Session Network Coding</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the capacity of the two-user multiple-input
multiple-output (MIMO) linear deterministic interference channel (IC), with
possible correlations within/between the channel matrices. The capacity region
is characterized in terms of the rank of the channel matrices. It is shown that
\emph{linear precoding} with Han-Kobayashi type of rate-splitting, i.e.,
splitting the information-bearing symbols of each user into common and private
parts, is sufficient to achieve all the rate pairs in the derived capacity
region. The capacity result is applied to obtain an achievable rate region for
the double-unicast networks with random network coding at the intermediate
nodes, which can be modeled by the two-user MIMO linear deterministic IC
studied. It is shown that the newly proposed achievable region is strictly
larger than the existing regions in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2000</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2000</id><created>2012-07-09</created><authors><author><keyname>Riverso</keyname><forenames>S.</forenames></author><author><keyname>Ferrari-Trecate</keyname><forenames>G.</forenames></author></authors><title>Hycon2 Benchmark: Power Network System</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a benchmark exercise for testing software and methods developed in Hycon2
for decentralized and distributed control, we address the problem of designing
the Automatic Generation Control (AGC) layer in power network systems. In
particular, we present three different scenarios and discuss performance levels
that can be reached using Centralized Model Predictive Control (MPC). These
results can be used as a milestone for comparing the performance of alternative
control schemes. Matlab software for simulating the scenarios is also provided
in an accompanying file.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2017</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2017</id><created>2012-07-09</created><authors><author><keyname>Breitner</keyname><forenames>Joachim</forenames></author></authors><title>dup -- Explicit un-sharing in Haskell</title><categories>cs.PL</categories><comments>9 pages, 9 figures</comments><acm-class>D.1.1; D.3.3; E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose two operations to prevent sharing in Haskell that do not require
modifying the data generating code, demonstrate their use and usefulness, and
compare them to other approaches to preventing sharing. Our claims are
supported by a formal semantics and a prototype implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2037</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2037</id><created>2012-07-09</created><authors><author><keyname>Slimane</keyname><forenames>Zohra</forenames></author><author><keyname>Feham</keyname><forenames>Mohamed</forenames></author><author><keyname>Abdelmalek</keyname><forenames>Abdelhafid</forenames></author></authors><title>Seamless Infrastructure independent Multi Homed NEMO Handoff Using
  Effective and Timely IEEE 802.21 MIH triggers</title><categories>cs.NI</categories><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN)Vol. 4,
  No. 3, June 2012, 119-139</journal-ref><doi>10.5121/ijwmn.2012.4308</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handoff performance of NEMO BS protocol with existent improvement proposals
is still not sufficient for real time and QoS-sensitive applications and
further optimizations are needed. When dealing with single homed NEMO, handoff
latency and packet loss become irreducible all optimizations included, so that
it is impossible to meet requirements of the above applications. Then, How to
combine the different Fast handoff approaches remains an open research issue
and needs more investigation. In this paper, we propose a new Infrastructure
independent handoff approach combining multihoming and intelligent
Make-Before-Break Handoff. Based on required Handoff time estimation, L2 and L3
handoffs are initiated using effective and timely MIH triggers, reducing so the
anticipation time and increasing the probability of prediction. We extend MIH
services to provide tunnel establishment and switching before link break. Thus,
the handoff is performed in background with no latency and no packet loss while
pingpong scenario is almost avoided. In addition, our proposal saves cost and
power consumption by optimizing the time of simultaneous use of multiple
interfaces. We provide also NS2 simulation experiments identifying suitable
parameter values used for estimation and validating the proposed model
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2041</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2041</id><created>2012-07-09</created><updated>2013-04-26</updated><authors><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Bai</keyname><forenames>Tianyang</forenames></author></authors><title>Modeling Heterogeneous Network Interference Using Poisson Point
  Processes</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Signal Processing, July 2012,
  Revised December 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cellular systems are becoming more heterogeneous with the introduction of low
power nodes including femtocells, relays, and distributed antennas.
Unfortunately, the resulting interference environment is also becoming more
complicated, making evaluation of different communication strategies
challenging in both analysis and simulation. Leveraging recent applications of
stochastic geometry to analyze cellular systems, this paper proposes to analyze
downlink performance in a fixed-size cell, which is inscribed within a weighted
Voronoi cell in a Poisson field of interferers. A nearest out-of-cell
interferer, out-of-cell interferers outside a guard region, and cross-tier
interference are included in the interference calculations. Bounding the
interference power as a function of distance from the cell center, the total
interference is characterized through its Laplace transform. An equivalent
marked process is proposed for the out-of-cell interference under additional
assumptions. To facilitate simplified calculations, the interference
distribution is approximated using the Gamma distribution with second order
moment matching. The Gamma approximation simplifies calculation of the success
probability and average rate, incorporates small-scale and large-scale fading,
and works with co-tier and cross-tier interference. Simulations show that the
proposed model provides a flexible way to characterize outage probability and
rate as a function of the distance to the cell edge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2060</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2060</id><created>2012-07-09</created><authors><author><keyname>Singh</keyname><forenames>N. Monoranjan</forenames></author><author><keyname>Sarma</keyname><forenames>K. C.</forenames></author></authors><title>Design of PIC12F675 Microcontroller Based Data Acquisition System for
  Slowly Varying Signals</title><categories>cs.AR</categories><comments>Published in the Journal of Instrument Society of India (ISOI)</comments><journal-ref>Journal of Instrum. Soc. of India, Vol. 40 No. 1 March 2010, pp
  15-17</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper describes the design of a cost effective, better resolution
data acquisition system (DAS) which is compatible to most of the PC and
laptops. A low cost DAS has been designed using PIC12F675 having 4-channel
analog input with 10-bit resolution for the monitoring of slowly varying
signals. The DAS so designed is interfaced to the serial port of the PC.
Firmware is written in Basic using Oshonsoft PIC IDE and burn to the
microcontroller by using PICkit2 programmer. An application program is also
developed using Visual Basic 6 which allows to display the waveform of the
signal(s) and simultaneously the data also can be saved into the hard disk of
the computer for future use and analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2079</identifier>
 <datestamp>2013-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2079</id><created>2012-07-09</created><authors><author><keyname>Barbier</keyname><forenames>Jean</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author><author><keyname>M&#xe9;zard</keyname><forenames>Marc</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>Compressed Sensing of Approximately-Sparse Signals: Phase Transitions
  and Optimal Reconstruction</title><categories>cs.IT cond-mat.stat-mech math.IT math.ST stat.TH</categories><comments>8 pages, 10 figures</comments><journal-ref>Communication, Control, and Computing (Allerton), 2012 50th Annual
  Allerton Conference on , pp.800,807, 1-5 Oct. 2012</journal-ref><doi>10.1109/Allerton.2012.6483300</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is designed to measure sparse signals directly in a
compressed form. However, most signals of interest are only &quot;approximately
sparse&quot;, i.e. even though the signal contains only a small fraction of relevant
(large) components the other components are not strictly equal to zero, but are
only close to zero. In this paper we model the approximately sparse signal with
a Gaussian distribution of small components, and we study its compressed
sensing with dense random matrices. We use replica calculations to determine
the mean-squared error of the Bayes-optimal reconstruction for such signals, as
a function of the variance of the small components, the density of large
components and the measurement rate. We then use the G-AMP algorithm and we
quantify the region of parameters for which this algorithm achieves optimality
(for large systems). Finally, we show that in the region where the GAMP for the
homogeneous measurement matrices is not optimal, a special &quot;seeding&quot; design of
a spatially-coupled measurement matrix allows to restore optimality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2080</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2080</id><created>2012-07-09</created><updated>2012-07-20</updated><authors><author><keyname>Harder</keyname><forenames>Malte</forenames></author><author><keyname>Salge</keyname><forenames>Christoph</forenames></author><author><keyname>Polani</keyname><forenames>Daniel</forenames></author></authors><title>A Bivariate Measure of Redundant Information</title><categories>cs.IT math.IT physics.data-an</categories><comments>16 pages, 15 figures, 1 table, added citation to Griffith et al 2012,
  Maurer et al 1999</comments><msc-class>62B10</msc-class><doi>10.1103/PhysRevE.87.012130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a measure of redundant information based on projections in the
space of probability distributions. Redundant information between random
variables is information that is shared between those variables. But in
contrast to mutual information, redundant information denotes information that
is shared about the outcome of a third variable. Formalizing this concept, and
being able to measure it, is required for the non-negative decomposition of
mutual information into redundant and synergistic information. Previous
attempts to formalize redundant or synergistic information struggle to capture
some desired properties. We introduce a new formalism for redundant information
and prove that it satisfies all the properties necessary outlined in earlier
work, as well as an additional criterion that we propose to be necessary to
capture redundancy. We also demonstrate the behaviour of this new measure for
several examples, compare it to previous measures and apply it to the
decomposition of transfer entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2083</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2083</id><created>2012-07-09</created><updated>2013-05-22</updated><authors><author><keyname>Hansen</keyname><forenames>Johan P.</forenames></author></authors><title>Equidistant Linear Network Codes with maximal Error-protection from
  Veronese Varieties</title><categories>cs.IT math.IT</categories><comments>Certain conditions are not explicitely stated</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear network coding transmits information in terms of a basis of a vector
space and the information is received as a basis of a possible altered
vectorspace. Ralf Koetter and Frank R. Kschischang in Coding for errors and
erasures in random network coding (IEEE Transactions on Information Theory,
vol.54, no.8, pp. 3579-3591,2008) introduced a metric on the set af
vector-spaces and showed that a minimal distance decoder for this metric
achieves correct decoding if the dimension of the intersection of the
transmitted and received vector-space is sufficiently large. From the Veronese
varieties we construct explicit families of vector-spaces of constant dimension
where any pair of distinct vector-spaces are equidistant in the above metric.
The parameters of the resulting linear network codes which have maximal
error-protection are determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2092</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2092</id><created>2012-07-09</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Distributed Estimation in Multi-Agent Networks</title><categories>cs.IT math.IT</categories><comments>Alternate title: Interactive Source Coding with Privacy Constraints;
  presented at the IEEE Intl. Symp. Information Theory 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A problem of distributed state estimation at multiple agents that are
physically connected and have competitive interests is mapped to a distributed
source coding problem with additional privacy constraints. The agents interact
to estimate their own states to a desired fidelity from their (sensor)
measurements which are functions of both the local state and the states at the
other agents. For a Gaussian state and measurement model, it is shown that the
sum-rate achieved by a distributed protocol in which the agents broadcast to
one another is a lower bound on that of a centralized protocol in which the
agents broadcast as if to a virtual CEO converging only in the limit of a large
number of agents. The sufficiency of encoding using local measurements is also
proved for both protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2094</identifier>
 <datestamp>2014-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2094</id><created>2012-07-09</created><updated>2014-01-18</updated><authors><author><keyname>Vaezi</keyname><forenames>Mojtaba</forenames></author></authors><title>The Capacity of More Capable Cognitive Interference Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 2 figures, one table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the capacity region for a class of discrete memoryless cognitive
interference channel (DM-CIC) called cognitive-more-capable channel, and we
show that superposition coding is the optimal encoding technique. This is the
largest capacity region for the DM-CIC to date, as the existing capacity
results are explicitly shown to be its subsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2103</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2103</id><created>2012-07-09</created><authors><author><keyname>Yi</keyname><forenames>Xinping</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Precoding Methods for MISO Broadcast Channel with Delayed CSIT</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent information theoretic results suggest that precoding on the multi-user
downlink MIMO channel with delayed channel state information at the transmitter
(CSIT) could lead to data rates much beyond the ones obtained without any CSIT,
even in extreme situations when the delayed channel feedback is made totally
obsolete by a feedback delay exceeding the channel coherence time. This
surprising result is based on the ideas of interference repetition and
alignment which allow the receivers to reconstruct information symbols which
canceling out the interference completely, making it an optimal scheme in the
infinite SNR regime. In this paper, we formulate a similar problem, yet at
finite SNR. We propose a first construction for the precoder which matches the
previous results at infinite SNR yet reaches a useful trade-off between
interference alignment and signal enhancement at finite SNR, allowing for
significant performance improvements in practical settings. We present two
general precoding methods with arbitrary number of users by means of virtual
MMSE and mutual information optimization, achieving good compromise between
signal enhancement and interference alignment. Simulation results show
substantial improvement due to the compromise between those two aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2104</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2104</id><created>2012-07-09</created><authors><author><keyname>Borgohain</keyname><forenames>Rajdeep</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Rule Based Expert System for Diagnosis of Neuromuscular Disorders</title><categories>cs.CY cs.AI</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we discuss the implementation of a rule based expert system
for diagnosing neuromuscular diseases. The proposed system is implemented as a
rule based expert system in JESS for the diagnosis of Cerebral Palsy, Multiple
Sclerosis, Muscular Dystrophy and Parkinson's disease. In the system, the user
is presented with a list of questionnaires about the symptoms of the patients
based on which the disease of the patient is diagnosed and possible treatment
is suggested. The system can aid and support the patients suffering from
neuromuscular diseases to get an idea of their disease and possible treatment
for the disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2125</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2125</id><created>2012-07-09</created><authors><author><keyname>Bogdan</keyname><forenames>Paul</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author><author><keyname>Stauffer</keyname><forenames>Alexandre</forenames></author><author><keyname>Sun</keyname><forenames>He</forenames></author></authors><title>Balls into Bins via Local Search</title><categories>math.PR cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a natural process for allocating n balls into n bins that are
organized as the vertices of an undirected graph G. Each ball first chooses a
vertex u in G uniformly at random. Then the ball performs a local search in G
starting from u until it reaches a vertex with local minimum load, where the
ball is finally placed on. In our main result, we prove that this process
yields a maximum load of only \Theta(\log \log n) on expander graphs. In
addition, we show that for d-dimensional grids the maximum load is
\Theta\Big(\big(\frac{\log n}{\log \log n}\big)^{\frac{1}{d+1}}\Big). Finally,
for almost regular graphs with minimum degree \Omega(\log n), we prove that the
maximum load is constant and also reveal a fundamental difference between
random and arbitrary tie-breaking rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2137</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2137</id><created>2012-07-09</created><authors><author><keyname>Shin</keyname><forenames>Won-Yong</forenames></author><author><keyname>Park</keyname><forenames>Dohyung</forenames></author><author><keyname>Jung</keyname><forenames>Bang Chul</forenames></author></authors><title>Can One Achieve Multiuser Diversity in Uplink Multi-Cell Networks?</title><categories>cs.IT math.IT</categories><comments>11 pages, 3 figures, 2 tables, to appear in IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a distributed opportunistic scheduling (DOS) strategy, based on
two pre-determined thresholds, for uplink $K$-cell networks with time-invariant
channel coefficients. Each base station (BS) opportunistically selects a mobile
station (MS) who has a large signal strength of the desired channel link among
a set of MSs generating a sufficiently small interference to other BSs. Then,
performance on the achievable throughput scaling law is analyzed. As our main
result, it is shown that the achievable sum-rate scales as
$K\log(\text{SNR}\log N)$ in a high signal-to-noise ratio (SNR) regime, if the
total number of users in a cell, $N$, scales faster than
$\text{SNR}^{\frac{K-1}{1-\epsilon}}$ for a constant $\epsilon\in(0,1)$. This
result indicates that the proposed scheme achieves the multiuser diversity gain
as well as the degrees-of-freedom gain even under multi-cell environments.
Simulation results show that the DOS provides a better sum-rate throughput over
conventional schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2169</identifier>
 <datestamp>2012-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2169</id><created>2012-07-09</created><updated>2012-11-10</updated><authors><author><keyname>Fabregat-Traver</keyname><forenames>Diego</forenames><affiliation>AICES, RWTH Aachen</affiliation></author><author><keyname>Aulchenko</keyname><forenames>Yurii S.</forenames><affiliation>Institute of Cytology and Genetics SD RAS</affiliation></author><author><keyname>Bientinesi</keyname><forenames>Paolo</forenames><affiliation>AICES, RWTH Aachen</affiliation></author></authors><title>High-throughput Genome-wide Association Analysis for Single and Multiple
  Phenotypes</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The variance component tests used in genomewide association studies of
thousands of individuals become computationally exhaustive when multiple traits
are analysed in the context of omics studies. We introduce two high-throughput
algorithms -- CLAK-CHOL and CLAK-EIG -- for single and multiple phenotype
genome-wide association studies (GWAS). The algorithms, generated with the help
of an expert system, reduce the computational complexity to the point that
thousands of traits can be analyzed for association with millions of
polymorphisms in a course of days on a standard workstation. By taking
advantage of problem specific knowledge, CLAK-CHOL and CLAK-EIG significantly
outperform the current state-of-the-art tools in both single and multiple trait
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2171</identifier>
 <datestamp>2013-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2171</id><created>2012-07-06</created><updated>2013-04-23</updated><authors><author><keyname>Tazawa</keyname><forenames>Satoshi</forenames></author></authors><title>Relationship between circuit complexity and symmetry</title><categories>cs.CC</categories><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is already shown that a Boolean function for a NP-complete problem can be
computed by a polynomial-sized circuit if its variables have enough number of
automorphisms. Looking at this previous study from the different perspective
gives us the idea that the small number of automorphisms might be a barrier for
a polynomial time solution for NP-complete problems. Here I show that by
interpreting a Boolean circuit as a graph, the small number of graph
automorphisms and the large number of subgraph automorphisms in the circuit
establishes the exponential circuit lower bound for NP-complete problems. As
this strategy violates the largeness condition in Natural proof, this result
shows that P!=NP without any contradictions to the existence of pseudorandom
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2189</identifier>
 <datestamp>2014-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2189</id><created>2012-07-09</created><updated>2014-02-03</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Kaser</keyname><forenames>Owen</forenames></author><author><keyname>Gutarra</keyname><forenames>Eduardo</forenames></author></authors><title>Reordering Rows for Better Compression: Beyond the Lexicographic Order</title><categories>cs.DB</categories><comments>to appear in ACM TODS</comments><acm-class>H.4.0</acm-class><journal-ref>ACM Trans. Database Syst. 37, 3, Article 20 (September 2012)</journal-ref><doi>10.1145/2338626.2338627</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sorting database tables before compressing them improves the compression
rate. Can we do better than the lexicographical order? For minimizing the
number of runs in a run-length encoding compression scheme, the best approaches
to row-ordering are derived from traveling salesman heuristics, although there
is a significant trade-off between running time and compression. A new
heuristic, Multiple Lists, which is a variant on Nearest Neighbor that trades
off compression for a major running-time speedup, is a good option for very
large tables. However, for some compression schemes, it is more important to
generate long runs rather than few runs. For this case, another novel
heuristic, Vortex, is promising. We find that we can improve run-length
encoding up to a factor of 3 whereas we can improve prefix coding by up to 80%:
these gains are on top of the gains due to lexicographically sorting the table.
We prove that the new row reordering is optimal (within 10%) at minimizing the
runs of identical values within columns, in a few cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2211</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2211</id><created>2012-07-09</created><authors><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Not Too Delayed CSIT Achieves the Optimal Degrees of Freedom</title><categories>cs.IT math.IT</categories><comments>8 pages; 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel state information at the transmitter (CSIT) aids interference
management in many communication systems. Due to channel state information
(CSI) feedback delay and time-variation in the wireless channel, perfect CSIT
is not realistic. In this paper, the CSI feedback delay-DoF gain trade-off is
characterized for the multi-user vector broadcast channel. A major insight is
that it is possible to achieve the optimal degrees of freedom (DoF) gain if the
delay is less than a certain fraction of the channel coherence time. This
precisely characterizes the intuition that a small delay should be negligeable.
To show this, a new transmission method called space-time interference
alignment is proposed, which actively exploits both the current and past CSI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2215</identifier>
 <datestamp>2013-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2215</id><created>2012-07-10</created><authors><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author><author><keyname>Xiang</keyname><forenames>Xingyu</forenames></author></authors><title>Constellation Shaping for Bit-Interleaved LDPC Coded APSK</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Communications</comments><journal-ref>IEEE Transactions on Communications, vol. 60, no. 10, pp.
  2960-2970, Oct. 2012</journal-ref><doi>10.1109/TCOMM.2012.070912.110533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An energy-efficient approach is presented for shaping a bit-interleaved
low-density parity-check (LDPC) coded amplitude phase-shift keying (APSK)
system. A subset of the interleaved bits output by a binary LDPC encoder are
passed through a nonlinear shaping encoder whose output is more likely to be a
zero than a one. The &quot;shaping&quot; bits are used to select from among a plurality
of subconstellations, while the unshaped bits are used to select the symbol
within the subconstellation. Because the shaping bits are biased, symbols from
lower-energy subconstellations are selected more frequently than those from
higher-energy subconstellations. An iterative decoder shares information among
the LDPC decoder, APSK demapper, and shaping decoder. Information rates are
computed for a discrete set of APSK ring radii and shaping bit probabilities,
and the optimal combination of these parameters is identified for the additive
white Gaussian noise (AWGN) channel. With the assistance of
extrinsic-information transfer (EXIT) charts, the degree distributions of the
LDPC code are optimized for use with the shaped APSK constellation. Simulation
results show that the combination of shaping, degree-distribution optimization,
and iterative decoding can achieve a gain in excess of 1 dB in AWGN at a rate
of 3 bits/symbol compared with a system that does not use shaping, uses an
unoptimized code from the DVB-S2 standard, and does not iterate between decoder
and demodulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2229</identifier>
 <datestamp>2013-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2229</id><created>2012-07-10</created><updated>2013-05-02</updated><authors><author><keyname>De</keyname><forenames>Anindya</forenames></author><author><keyname>Diakonikolas</keyname><forenames>Ilias</forenames></author><author><keyname>Servedio</keyname><forenames>Rocco A.</forenames></author></authors><title>A robust Khintchine inequality, and algorithms for computing optimal
  constants in Fourier analysis and high-dimensional geometry</title><categories>cs.CC cs.DM math.PR</categories><comments>Extended abstract to appear in ICALP'13</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper makes two contributions towards determining some well-studied
optimal constants in Fourier analysis \newa{of Boolean functions} and
high-dimensional geometry.
  \begin{enumerate}
  \item It has been known since 1994 \cite{GL:94} that every linear threshold
function has squared Fourier mass at least 1/2 on its degree-0 and degree-1
coefficients. Denote the minimum such Fourier mass by $\w^{\leq 1}[\ltf]$,
where the minimum is taken over all $n$-variable linear threshold functions and
all $n \ge 0$. Benjamini, Kalai and Schramm \cite{BKS:99} have conjectured that
the true value of $\w^{\leq 1}[\ltf]$ is $2/\pi$. We make progress on this
conjecture by proving that $\w^{\leq 1}[\ltf] \geq 1/2 + c$ for some absolute
constant $c&gt;0$. The key ingredient in our proof is a &quot;robust&quot; version of the
well-known Khintchine inequality in functional analysis, which we believe may
be of independent interest.
  \item We give an algorithm with the following property: given any $\eta &gt; 0$,
the algorithm runs in time $2^{\poly(1/\eta)}$ and determines the value of
$\w^{\leq 1}[\ltf]$ up to an additive error of $\pm\eta$. We give a similar
$2^{{\poly(1/\eta)}}$-time algorithm to determine \emph{Tomaszewski's constant}
to within an additive error of $\pm \eta$; this is the minimum (over all
origin-centered hyperplanes $H$) fraction of points in $\{-1,1\}^n$ that lie
within Euclidean distance 1 of $H$. Tomaszewski's constant is conjectured to be
1/2; lower bounds on it have been given by Holzman and Kleitman \cite{HK92} and
independently by Ben-Tal, Nemirovski and Roos \cite{BNR02}.
  Our algorithms combine tools from anti-concentration of sums of independent
random variables, Fourier analysis, and Hermite analysis of linear threshold
functions.
  \end{enumerate}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2232</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2232</id><created>2012-07-10</created><authors><author><keyname>Sherimon</keyname><forenames>P. C.</forenames></author><author><keyname>Krishnan</keyname><forenames>Reshmy</forenames></author><author><keyname>Vinu</keyname><forenames>P. V.</forenames></author></authors><title>Effective Enabling of Sharing and Reuse of Knowledge On Semantic Web by
  Ontology in Date Fruit Model</title><categories>cs.AI cs.IR</categories><comments>International Journal of Computer Science Issues, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since Organizations have recognized that knowledge constitutes a valuable
intangible asset for creating and sustaining competitive advantages, knowledge
sharing has a vital role in present society. It is an activity through which
information is exchanged among people through different media. Many problems
face the area of knowledge sharing and knowledge reuse. Currently, knowledge
sharing between entities is achieved in a very ad-hoc fashion, lacking proper
understanding of the meaning of the data. Ontologies can potentially solve
these problems by facilitating knowledge sharing and reuse through formal and
real-world semantics. Ontologies, through formal semantics, are
machine-understandable. A computer can process data, annotated with references
to ontologies, and through the knowledge encapsulated in the ontology, deduce
facts from the original data. The date fruit is the most enduring symbol of the
Sultanate's rich heritage. Creating ontology for dates will enrich the farming
group and research scholars in the agro farm area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2234</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2234</id><created>2012-07-10</created><authors><author><keyname>Nica</keyname><forenames>Simona</forenames><affiliation>Institute for Software Technology, Technische Universit&#xe4;t Graz</affiliation></author><author><keyname>Wotawa</keyname><forenames>Franz</forenames><affiliation>Institute for Software Technology, Technische Universit&#xe4;t Graz</affiliation></author></authors><title>Using Constraints for Equivalent Mutant Detection</title><categories>cs.SE</categories><comments>In Proceedings WS-FMDS 2012, arXiv:1207.1841</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 86, 2012, pp. 1-8</journal-ref><doi>10.4204/EPTCS.86.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In mutation testing the question whether a mutant is equivalent to its
program is important in order to compute the correct mutation score.
Unfortunately, answering this question is not always possible and can hardly be
obtained just by having a look at the program's structure. In this paper we
introduce a method for solving the equivalent mutant problem using a constraint
representation of the program and its mutant. In particularly the approach is
based on distinguishing test cases, i.e., test inputs that force the program
and its mutant to behave in a different way. Beside the foundations of the
approach, in this paper we also present the algorithms and first empirical
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2235</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2235</id><created>2012-07-10</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Debajyoti</forenames></author><author><keyname>Vij</keyname><forenames>Sheetal</forenames></author><author><keyname>Tasare</keyname><forenames>Suyog</forenames></author></authors><title>NAAS: Negotiation Automation Architecture with Buyer's Behavior Pattern
  Prediction Component</title><categories>cs.MA</categories><comments>11 pages, 12 figures</comments><journal-ref>Advances in Computing &amp; Inform. Technology, AISC 176, pp.
  425--434, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this era of &quot;Services&quot; everywhere, with the explosive growth of E-Commerce
and B2B transactions, there is a pressing need for the development of
intelligent negotiation systems which consists of feasible architecture, a
reliable framework and flexible multi agent based protocols developed in
specialized negotiation languages with complete semantics and support for
message passing between the buyers and sellers. This is possible using web
services on the internet. The key issue is negotiation and its automation. In
this paper we review the classical negotiation methods and some of the existing
architectures and frameworks. We are proposing here a new combinatory framework
and architecture, NAAS. The key feature in this framework is a component for
prediction or probabilistic behavior pattern recognition of a buyer, along with
the other classical approaches of negotiation frameworks and architectures.
Negotiation is practically very complex activity to automate without human
intervention so in the future we also intend to develop a new protocol which
will facilitate automation of all the types of negotiation strategies like
bargaining, bidding, auctions, under our NAAS framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2236</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2236</id><created>2012-07-10</created><authors><author><keyname>Spichkova</keyname><forenames>Maria</forenames><affiliation>TU M&#xfc;nchen</affiliation></author><author><keyname>H&#xf6;lzl</keyname><forenames>Florian</forenames><affiliation>fortiss GmbH</affiliation></author><author><keyname>Trachtenherz</keyname><forenames>David</forenames><affiliation>fortiss GmbH</affiliation></author></authors><title>Verified System Development with the AutoFocus Tool Chain</title><categories>cs.SE</categories><comments>In Proceedings WS-FMDS 2012, arXiv:1207.1841</comments><proxy>EPTCS</proxy><acm-class>D.2.1;D.2.2;D.2.4</acm-class><journal-ref>EPTCS 86, 2012, pp. 17-24</journal-ref><doi>10.4204/EPTCS.86.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a model-based development methodology for verified
software systems as well as a tool support for it: an applied AutoFocus tool
chain and its basic principles emphasizing the verification of the system under
development as well as the check mechanisms we used to raise the level of
confidence in the correctness of the implementation of the automatic
generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2237</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2237</id><created>2012-07-10</created><authors><author><keyname>Bollin</keyname><forenames>Andreas</forenames><affiliation>University of Klagenfurt</affiliation></author><author><keyname>Tabareh</keyname><forenames>Abdollah</forenames><affiliation>University of Gothenburg</affiliation></author></authors><title>Predictive Software Measures based on Z Specifications - A Case Study</title><categories>cs.SE</categories><comments>In Proceedings WS-FMDS 2012, arXiv:1207.1841</comments><proxy>EPTCS</proxy><acm-class>D.2.8; D.2.1; D.2.4</acm-class><journal-ref>EPTCS 86, 2012, pp. 33-40</journal-ref><doi>10.4204/EPTCS.86.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating the effort and quality of a system is a critical step at the
beginning of every software project. It is necessary to have reliable ways of
calculating these measures, and, it is even better when the calculation can be
done as early as possible in the development life-cycle.
  Having this in mind, metrics for formal specifications are examined with a
view to correlations to complexity and quality-based code measures. A case
study, based on a Z specification and its implementation in ADA, analyzes the
practicability of these metrics as predictors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2240</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2240</id><created>2012-07-10</created><authors><author><keyname>Khan</keyname><forenames>N. A.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Jaffar</keyname><forenames>M.</forenames></author><author><keyname>Rafiq</keyname><forenames>U.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author></authors><title>Ubiquitous HealthCare in Wireless Body Area Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in wireless communications, system on chip and low power
sensor nodes allow realization of Wireless Body Area Networks (WBANs).WBANs
comprise of tiny sensors, which collect information of a patient's vital signs
and provide a real time feedback. In addition,WBANs also support many
applications including ubiquitous healthcare, entertainment, gaming, military,
etc. Ubiquitous healthcare is required by elderly people to facilitate them
with instant monitoring anywhere they move around. In this paper, we provide a
survey on different architectures used in WBANs for ubiquitous healthcare
monitoring. Different standards and devices used in these architectures are
also discussed in this paper. Finally, path loss in WBANs and its impact on
communication is presented with the help of simulations performed for different
models of In-Body communication and different factors (such as, attenuation,
frequency, distance etc) influencing path loss in On-Body communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2243</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2243</id><created>2012-07-10</created><authors><author><keyname>Uteshev</keyname><forenames>Alexei Yu.</forenames></author><author><keyname>Yashina</keyname><forenames>Marina V.</forenames></author></authors><title>Metric Problems for Quadrics in Multidimensional Space</title><categories>cs.SC math.AG</categories><comments>21 pages, 1 figure</comments><msc-class>68W30, 13P15</msc-class><acm-class>I.3.5; I.1.2; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given the equations of the first and the second order surfaces in
multidimensional space, our goal is to construct a univariate polynomial one of
the zeros of which coincides with the square of the distance between these
surfaces. To achieve this goal we employ Elimination Theory methods. The
proposed approach is also extended for the case of parameter dependent
surfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2253</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2253</id><created>2012-07-10</created><authors><author><keyname>Vaghefinezhad</keyname><forenames>Sayedmohammadreza</forenames></author><author><keyname>Wong</keyname><forenames>Kuan Yew</forenames></author></authors><title>A Genetic Algorithm Approach for Solving a Flexible Job Shop Scheduling
  Problem</title><categories>math.OC cs.NE</categories><comments>6 pages, 8 tables; International Journal of Computer Science Issues,
  May 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Flexible job shop scheduling has been noticed as an effective manufacturing
system to cope with rapid development in today's competitive environment.
Flexible job shop scheduling problem (FJSSP) is known as a NP-hard problem in
the field of optimization. Considering the dynamic state of the real world
makes this problem more and more complicated. Most studies in the field of
FJSSP have only focused on minimizing the total makespan. In this paper, a
mathematical model for FJSSP has been developed. The objective function is
maximizing the total profit while meeting some constraints. Time-varying raw
material costs and selling prices and dissimilar demands for each period, have
been considered to decrease gaps between reality and the model. A manufacturer
that produces various parts of gas valves has been used as a case study. Its
scheduling problem for multi-part, multi-period, and multi-operation with
parallel machines has been solved by using genetic algorithm (GA). The best
obtained answer determines the economic amount of production by different
machines that belong to predefined operations for each part to satisfy customer
demand in each period.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2254</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2254</id><created>2012-07-10</created><authors><author><keyname>Kim</keyname><forenames>Gol</forenames><affiliation>Center of Natural Science, University of Sciences, Pyongyang, DPR Korea</affiliation></author><author><keyname>Yun</keyname><forenames>Ri Suk</forenames><affiliation>Foreign Economic General Bureau, Pyongyang, DPR Korea</affiliation></author></authors><title>A Hybrid Forecast of Exchange Rate based on Discrete Grey-Markov and
  Grey Neural Network Model</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a hybrid forecast model based on discrete grey-fuzzy Markov and
grey neural network model and show that our hybrid model can improve much more
the performance of forecast than traditional grey-Markov model and neural
network models. Our simulation results are shown that our hybrid forecast
method with the combinational weight based on optimal grey relation degree
method is better than the hybrid model with combinational weight based
minimization of error-squared criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2264</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2264</id><created>2012-07-10</created><authors><author><keyname>Banisch</keyname><forenames>Sven</forenames></author><author><keyname>Ara&#xfa;jo</keyname><forenames>Tanya</forenames></author></authors><title>Who Replaces Whom? Local versus Non-local Replacement in Social and
  Evolutionary Dynamics</title><categories>q-bio.PE cs.SI nlin.AO physics.soc-ph</categories><comments>14 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we inspect well-known population genetics and social dynamics
models. In these models, interacting individuals, while participating in a
self-organizing process, give rise to the emergence of complex behaviors and
patterns. While one main focus in population genetics is on the adaptive
behavior of a population, social dynamics is more often concerned with the
splitting of a connected array of individuals into a state of global
polarization, that is, the emergence of speciation. Applying computational and
mathematical tools we show that the way the mechanisms of selection,
interaction and replacement are constrained and combined in the modeling have
an important bearing on both adaptation and the emergence of speciation.
Differently (un)constraining the mechanism of individual replacement provides
the conditions required for either speciation or adaptation, since these
features appear as two opposing phenomena, not achieved by one and the same
model. Even though natural selection, operating as an external, environmental
mechanism, is neither necessary nor sufficient for the creation of speciation,
our modeling exercises highlight the important role played by natural selection
in the interplay of the evolutionary and the self-organization modeling
methodologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2265</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2265</id><created>2012-07-10</created><authors><author><keyname>Clarke</keyname><forenames>Daoud</forenames></author></authors><title>Challenges for Distributional Compositional Semantics</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper summarises the current state-of-the art in the study of
compositionality in distributional semantics, and major challenges for this
area. We single out generalised quantifiers and intensional semantics as areas
on which to focus attention for the development of the theory. Once suitable
theories have been developed, algorithms will be needed to apply the theory to
tasks. Evaluation is a major problem; we single out application to recognising
textual entailment and machine translation for this purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2268</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2268</id><created>2012-07-10</created><authors><author><keyname>Chaabouni</keyname><forenames>Imen</forenames></author><author><keyname>Fourati</keyname><forenames>Wiem</forenames></author><author><keyname>Bouhlel</keyname><forenames>Med Salim</forenames></author></authors><title>Improvement of ISOM by using filter</title><categories>cs.MM cs.CV</categories><comments>6 pages, 3 figures, 2 tables; JCSI (May 2012 issue, Volume 9, Issue
  3) and having paper id IJCSI-2012-9-3-2860</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image compression helps in storing the transmitted data in proficient way by
decreasing its redundancy. This technique helps in transferring more digital or
multimedia data over internet as it increases the storage space. It is
important to maintain the image quality even if it is compressed to certain
extent. Depend upon this the image compression is classified into two
categories : lossy and lossless image compression. There are many lossy digital
image compression techniques exists. Among this Incremental Self Organizing Map
is a familiar one. The good pictures quality can be retrieved if image
denoising technique is used for compression and also provides better
compression ratio. Image denoising is an important pre-processing step for many
image analysis and computer vision system. It refers to the task of recovering
a good estimate of the true image from a degraded observation without altering
and changing useful structure in the image such as discontinuities and edges.
Many approaches have been proposed to remove the noise effectively while
preserving the original image details and features as much as possible. This
paper proposes a technique for image compression using Incremental Self
Organizing Map (ISOM) with Discret Wavelet Transform (DWT) by applying
filtering techniques which play a crucial role in enhancing the quality of a
reconstructed image. The experimental result shows that the proposed technique
obtained better compression ratio value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2280</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2280</id><created>2012-07-10</created><authors><author><keyname>Libbrecht</keyname><forenames>Paul</forenames></author><author><keyname>Rebholz</keyname><forenames>Sandra</forenames></author><author><keyname>Herding</keyname><forenames>Daniel</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Wolfgang</forenames></author><author><keyname>Tscheulin</keyname><forenames>Felix</forenames></author></authors><title>Understanding the Learners' Actions when using Mathematics Learning
  Tools</title><categories>cs.CY</categories><comments>Proceedings of CICM 2012; Intelligent Computer Mathematics 2012;
  http://www.springerlink.com/content/978-3-642-31373-8/</comments><msc-class>97U50, 97C70</msc-class><acm-class>K.3.1; H.3.5</acm-class><doi>10.1007/978-3-642-31374-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of computer-based mathematics tools is widespread in learning.
Depending on the way that these tools assess the learner's solution paths, one
can distinguish between automatic assessment tools and semi-automatic
assessment tools. Automatic assessment tools directly provide all feedback
necessary to the learners, while semi-automatic assessment tools involve the
teachers as part the assessment process. They are provided with as much
information as possible on the learners' interactions with the tool.
  How can the teachers know how the learning tools were used and which
intermediate steps led to a solution? How can the teachers respond to a
learner's question that arises while using a computer tool? Little is available
to answer this beyond interacting directly with the computer and performing a
few manipulations to understand the tools' state.
  This paper presents SMALA, a web-based logging architecture that addresses
these problems by recording, analyzing and representing user actions. While
respecting the learner's privacy, the SMALA architecture supports the teachers
by offering fine-grained representations of the learners' activities as well as
overviews of the progress of a classroom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2291</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2291</id><created>2012-07-10</created><authors><author><keyname>Khan</keyname><forenames>Muhammad Taimoor</forenames></author><author><keyname>Schreiner</keyname><forenames>Wolfgang</forenames></author></authors><title>On Formal Specification of Maple Programs</title><categories>cs.MS cs.AI</categories><msc-class>68Txx</msc-class><acm-class>D.2.4</acm-class><doi>10.1007/978-3-642-31374-5_33</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is an example-based demonstration of our initial results on the
formal specification of programs written in the computer algebra language
MiniMaple (a substantial subset of Maple with slight extensions). The main goal
of this work is to define a verification framework for MiniMaple. Formal
specification of MiniMaple programs is rather complex task as it supports
non-standard types of objects, e.g. symbols and unevaluated expressions, and
additional functions and predicates, e.g. runtime type tests etc. We have used
the specification language to specify various computer algebra concepts
respective objects of the Maple package DifferenceDifferential developed at our
institute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2300</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2300</id><created>2012-07-10</created><authors><author><keyname>Khan</keyname><forenames>Muhammad Taimoor</forenames></author><author><keyname>Schreiner</keyname><forenames>Wolfgang</forenames></author></authors><title>Towards the Formal Specification and Verification of Maple Programs</title><categories>cs.MS cs.LO cs.PL cs.SE</categories><doi>10.1007/978-3-642-31374-5_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present our ongoing work and initial results on the formal
specification and verification of MiniMaple (a substantial subset of Maple with
slight extensions) programs. The main goal of our work is to find behavioral
errors in such programs w.r.t. their specifications by static analysis. This
task is more complex for widely used computer algebra languages like Maple as
these are fundamentally different from classical languages: they support
non-standard types of objects such as symbols, unevaluated expressions and
polynomials and require abstract computer algebraic concepts and objects such
as rings and orderings etc. As a starting point we have defined and formalized
a syntax, semantics, type system and specification language for MiniMaple.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2317</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2317</id><created>2012-07-10</created><authors><author><keyname>Cabello</keyname><forenames>Sergio</forenames></author></authors><title>Stackelberg Shortest Path Tree Game, Revisited</title><categories>cs.DS cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G(V,E)$ be a directed graph with $n$ vertices and $m$ edges. The edges
$E$ of $G$ are divided into two types: $E_F$ and $E_P$. Each edge of $E_F$ has
a fixed price. The edges of $E_P$ are the priceable edges and their price is
not fixed a priori. Let $r$ be a vertex of $G$. For an assignment of prices to
the edges of $E_P$, the revenue is given by the following procedure: select a
shortest path tree $T$ from $r$ with respect to the prices (a tree of cheapest
paths); the revenue is the sum, over all priceable edges $e$, of the product of
the price of $e$ and the number of vertices below $e$ in $T$.
  Assuming that $k=|E_P|\ge 2$ is a constant, we provide a data structure whose
construction takes $O(m+n\log^{k-1} n)$ time and with the property that, when
we assign prices to the edges of $E_P$, the revenue can be computed in
$(\log^{k-1} n)$. Using our data structure, we save almost a linear factor when
computing the optimal strategy in the Stackelberg shortest paths tree game of
[D. Bil{\`o} and L. Gual{\`a} and G. Proietti and P. Widmayer. Computational
aspects of a 2-Player Stackelberg shortest paths tree game. Proc. WINE 2008].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2328</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2328</id><created>2012-07-10</created><updated>2012-07-13</updated><authors><author><keyname>Zhang</keyname><forenames>Pan</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author><author><keyname>Reichardt</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Zdeborov&#xe1;</keyname><forenames>Lenka</forenames></author></authors><title>Comparative Study for Inference of Hidden Classes in Stochastic Block
  Models</title><categories>cs.LG cond-mat.stat-mech physics.data-an stat.ML</categories><comments>8 pages, 5 figures AIGM12</comments><journal-ref>J. Stat. Mech. (2012) P12021</journal-ref><doi>10.1088/1742-5468/2012/12/P12021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inference of hidden classes in stochastic block model is a classical problem
with important applications. Most commonly used methods for this problem
involve na\&quot;{\i}ve mean field approaches or heuristic spectral methods.
Recently, belief propagation was proposed for this problem. In this
contribution we perform a comparative study between the three methods on
synthetically created networks. We show that belief propagation shows much
better performance when compared to na\&quot;{\i}ve mean field and spectral
approaches. This applies to accuracy, computational efficiency and the tendency
to overfit the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2334</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2334</id><created>2012-07-10</created><updated>2012-07-14</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Distinct word length frequencies: distributions and symbol entropies</title><categories>cs.CL physics.data-an</categories><comments>16 pages, 4 figures</comments><journal-ref>Glottometrics 23, 2012, 7-22</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The distribution of frequency counts of distinct words by length in a
language's vocabulary will be analyzed using two methods. The first, will look
at the empirical distributions of several languages and derive a distribution
that reasonably explains the number of distinct words as a function of length.
We will be able to derive the frequency count, mean word length, and variance
of word length based on the marginal probability of letters and spaces. The
second, based on information theory, will demonstrate that the conditional
entropies can also be used to estimate the frequency of distinct words of a
given length in a language. In addition, it will be shown how these techniques
can also be applied to estimate higher order entropies using vocabulary word
length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2335</identifier>
 <datestamp>2012-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2335</id><created>2012-07-10</created><updated>2012-11-14</updated><authors><author><keyname>Bakshi</keyname><forenames>Mayank</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Cai</keyname><forenames>Sheng</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author></authors><title>SHO-FA: Robust compressive sensing with order-optimal complexity,
  measurements, and bits</title><categories>cs.IT cs.DS math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory. A preliminary
  version of this paper was presented at the 50th Annual Allerton Conference on
  Communication, Control and Computing - 2012. A poster based on this work was
  also presented at International Symposium on Information Theory 2012</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose x is any exactly k-sparse vector in R^n. We present a class of sparse
matrices A, and a corresponding algorithm that we call SHO-FA (for Short and
Fast) that, with high probability over A, can reconstruct x from Ax. The SHO-FA
algorithm is related to the Invertible Bloom Lookup Tables recently introduced
by Goodrich et al., with two important distinctions - SHO-FA relies on linear
measurements, and is robust to noise. The SHO-FA algorithm is the first to
simultaneously have the following properties: (a) it requires only O(k)
measurements, (b) the bit-precision of each measurement and each arithmetic
operation is O (log(n) + P) (here 2^{-P} is the desired relative error in the
reconstruction of x), (c) the decoding complexity is O(k) arithmetic operations
and encoding complexity is O(n) arithmetic operations, and (d) if the
reconstruction goal is simply to recover a single component of x instead of all
of x, with significant probability over A this can be done in constant time.
All constants above are independent of all problem parameters other than the
desired success probability. For a wide range of parameters these properties
are information-theoretically order-optimal. In addition, our SHO-FA algorithm
works over fairly general ensembles of &quot;sparse random matrices&quot;, is robust to
random noise, and (random) approximate sparsity for a large range of k. In
particular, suppose the measured vector equals A(x+z)+e, where z and e
correspond respectively to the source tail and measurement noise. Under
reasonable statistical assumptions on z and e our decoding algorithm
reconstructs x with an estimation error of O(||z||_2 +||e||_2). The SHO-FA
algorithm works with high probability over A, z, and e, and still requires only
O(k) steps and O(k) measurements over O(log n)-bit numbers. This is in contrast
to the worst-case z model, where it is known O(k log n/k) measurements are
necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2336</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2336</id><created>2012-07-10</created><authors><author><keyname>Endrullis</keyname><forenames>Joerg</forenames></author><author><keyname>Hendriks</keyname><forenames>Dimitri</forenames></author></authors><title>On Periodically Iterated Morphisms</title><categories>cs.FL math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the computational power of periodically iterated morphisms,
also known as D0L systems with periodic control, PD0L systems for short. These
systems give rise to a class of one-sided infinite sequences, called PD0L
words.
  We construct a PD0L word with exponential subword complexity, thereby
answering a question raised by Lepisto (1993) on the existence of such words.
We solve another open problem concerning the decidability of the first-order
theories of PD0L words; we show it is already undecidable whether a certain
letter occurs in a PD0L word. This stands in sharp contrast to the situation
for D0L words (purely morphic words), which are known to have at most quadratic
subword complexity, and for which the monadic theory is decidable.
  The main result of our paper, leading to these answers, is that every
computable word w over an alphabet Sigma can be embedded in a PD0L word u over
an extended alphabet Gamma in the following two ways: (i) such that every
finite prefix of w is a subword of u, and (ii) such that w is obtained from u
by erasing all letters from Gamma not in Sigma. The PD0L system generating such
a word u is constructed by encoding a Fractran program that computes the word
w; Fractran is a programming language as powerful as Turing Machines.
  As a consequence of (ii), if we allow the application of finite state
transducers to PD0L words, we obtain the set of all computable words. Thus the
set of PD0L words is not closed under finite state transduction, whereas the
set of D0L words is. It moreover follows that equality of PD0L words (given by
their PD0L system) is undecidable. Finally, we show that if erasing morphisms
are admitted, then the question of productivity becomes undecidable, that is,
the question whether a given PD0L system defines an infinite word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2340</identifier>
 <datestamp>2013-11-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2340</id><created>2012-07-10</created><updated>2013-11-05</updated><authors><author><keyname>Amini</keyname><forenames>Arash A.</forenames></author><author><keyname>Chen</keyname><forenames>Aiyou</forenames></author><author><keyname>Bickel</keyname><forenames>Peter J.</forenames></author><author><keyname>Levina</keyname><forenames>Elizaveta</forenames></author></authors><title>Pseudo-likelihood methods for community detection in large sparse
  networks</title><categories>cs.SI cs.LG math.ST physics.soc-ph stat.ML stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/13-AOS1138 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS1138</report-no><journal-ref>Annals of Statistics 2013, Vol. 41, No. 4, 2097-2122</journal-ref><doi>10.1214/13-AOS1138</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many algorithms have been proposed for fitting network models with
communities, but most of them do not scale well to large networks, and often
fail on sparse networks. Here we propose a new fast pseudo-likelihood method
for fitting the stochastic block model for networks, as well as a variant that
allows for an arbitrary degree distribution by conditioning on degrees. We show
that the algorithms perform well under a range of settings, including on very
sparse networks, and illustrate on the example of a network of political blogs.
We also propose spectral clustering with perturbations, a method of independent
interest, which works well on sparse networks where regular spectral clustering
fails, and use it to provide an initial value for pseudo-likelihood. We prove
that pseudo-likelihood provides consistent estimates of the communities under a
mild condition on the starting value, for the case of a block model with two
communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2341</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2341</id><created>2012-07-10</created><authors><author><keyname>Kejlberg-Rasmussen</keyname><forenames>Casper</forenames></author><author><keyname>Tsakalidis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Tsichlas</keyname><forenames>Kostas</forenames></author></authors><title>I/O-Efficient Dynamic Planar Range Skyline Queries</title><categories>cs.DS</categories><comments>Submitted to SODA 2013</comments><acm-class>E.1; F.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present the first fully dynamic worst case I/O-efficient data structures
that support planar orthogonal \textit{3-sided range skyline reporting queries}
in $\bigO (\log_{2B^\epsilon} n + \frac{t}{B^{1-\epsilon}})$ I/Os and updates
in $\bigO (\log_{2B^\epsilon} n)$ I/Os, using $\bigO
(\frac{n}{B^{1-\epsilon}})$ blocks of space, for $n$ input planar points, $t$
reported points, and parameter $0 \leq \epsilon \leq 1$. We obtain the result
by extending Sundar's priority queues with attrition to support the operations
\textsc{DeleteMin} and \textsc{CatenateAndAttrite} in $\bigO (1)$ worst case
I/Os, and in $\bigO(1/B)$ amortized I/Os given that a constant number of blocks
is already loaded in main memory. Finally, we show that any pointer-based
static data structure that supports \textit{dominated maxima reporting
queries}, namely the difficult special case of 4-sided skyline queries, in
$\bigO(\log^{\bigO(1)}n +t)$ worst case time must occupy $\Omega(n \frac{\log
n}{\log \log n})$ space, by adapting a similar lower bounding argument for
planar 4-sided range reporting queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2345</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2345</id><created>2012-07-10</created><authors><author><keyname>Bagdasaryan</keyname><forenames>Armen</forenames></author></authors><title>Some Euler-type formulas for planar graphs</title><categories>cs.DM math.CO</categories><comments>accepted for publication in Int. J. Pure Appl. Math</comments><msc-class>05C10, 05C75</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to derive on the basis of the Euler's formula
several analytical relations which hold for certain classes of planar graphs
and which can be useful in algorithmic graph theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2346</identifier>
 <datestamp>2013-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2346</id><created>2012-07-10</created><updated>2013-07-09</updated><authors><author><keyname>Gonalez-Diaz</keyname><forenames>Rocio</forenames></author><author><keyname>Lamar</keyname><forenames>Javier</forenames></author><author><keyname>Umble</keyname><forenames>Ronald</forenames></author></authors><title>Cups Products in Z2-Cohomology of 3D Polyhedral Complexes</title><categories>cs.CV</categories><msc-class>55-XX,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $I=(\mathbb{Z}^3,26,6,B)$ be a 3D digital image, let $Q(I)$ be the
associated cubical complex and let $\partial Q(I)$ be the subcomplex of $Q(I)$
whose maximal cells are the quadrangles of $Q(I)$ shared by a voxel of $B$ in
the foreground -- the object under study -- and by a voxel of
$\mathbb{Z}^3\smallsetminus B$ in the background -- the ambient space. We show
how to simplify the combinatorial structure of $\partial Q(I)$ and obtain a 3D
polyhedral complex $P(I)$ homeomorphic to $\partial Q(I)$ but with fewer cells.
We introduce an algorithm that computes cup products on
$H^*(P(I);\mathbb{Z}_2)$ directly from the combinatorics. The computational
method introduced here can be effectively applied to any polyhedral complex
embedded in $\mathbb{R}^3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2354</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2354</id><created>2012-07-10</created><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author><author><keyname>Xia</keyname><forenames>Mingji</forenames></author></authors><title>Dichotomy for Holant* Problems with a Function on Domain Size 3</title><categories>cs.CC</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Holant problems are a general framework to study the algorithmic complexity
of counting problems. Both counting constraint satisfaction problems and graph
homomorphisms are special cases. All previous results of Holant problems are
over the Boolean domain. In this paper, we give the first dichotomy theorem for
Holant problems for domain size $&gt;2$. We discover unexpected tractable families
of counting problems, by giving new polynomial time algorithms. This paper also
initiates holographic reductions in domains of size $&gt;2$. This is our main
algorithmic technique, and is used for both tractable families and hardness
reductions. The dichotomy theorem is the following: For any complex-valued
symmetric function ${\bf F}$ with arity 3 on domain size 3, we give an explicit
criterion on ${\bf F}$, such that if ${\bf F}$ satisfies the criterion then the
problem ${\rm Holant}^*({\bf F})$ is computable in polynomial time, otherwise
${\rm Holant}^*({\bf F})$ is #P-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2367</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2367</id><created>2012-07-10</created><updated>2012-07-11</updated><authors><author><keyname>Capuzzo-Dolcetta</keyname><forenames>R.</forenames><affiliation>Dep. of Physics, Sapienza, University of Roma, Roma, Italy</affiliation></author><author><keyname>Spera</keyname><forenames>M.</forenames><affiliation>Dep. of Physics, Sapienza, University of Roma, Roma, Italy</affiliation></author><author><keyname>Punzo</keyname><forenames>D.</forenames><affiliation>Dep. of Physics, Sapienza, University of Roma, Roma, Italy</affiliation></author></authors><title>A fully parallel, high precision, N-body code running on hybrid
  computing platforms</title><categories>astro-ph.IM cs.DC physics.comp-ph</categories><comments>Paper submitted to Journal of Computational Physics consisting in 28
  pages, 9 figures.The previous submitted version was lacking of the
  bibliography, for a Tex problem</comments><doi>10.1016/j.jcp.2012.11.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new implementation of the numerical integration of the
classical, gravitational, N-body problem based on a high order Hermite's
integration scheme with block time steps, with a direct evaluation of the
particle-particle forces. The main innovation of this code (called HiGPUs) is
its full parallelization, exploiting both OpenMP and MPI in the use of the
multicore Central Processing Units as well as either Compute Unified Device
Architecture (CUDA) or OpenCL for the hosted Graphic Processing Units. We
tested both performance and accuracy of the code using up to 256 GPUs in the
supercomputer IBM iDataPlex DX360M3 Linux Infiniband Cluster provided by the
italian supercomputing consortium CINECA, for values of N up to 8 millions. We
were able to follow the evolution of a system of 8 million bodies for few
crossing times, task previously unreached by direct summation codes. The code
is freely available to the scientific community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2373</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2373</id><created>2012-07-10</created><authors><author><keyname>Mohamed</keyname><forenames>Mohamed Achraf Ben</forenames></author><author><keyname>Ghoul</keyname><forenames>Dhaou El</forenames></author><author><keyname>Nahdi</keyname><forenames>Mohamed Amine</forenames></author><author><keyname>Mars</keyname><forenames>Mourad</forenames></author><author><keyname>Zrigui</keyname><forenames>Mounir</forenames></author></authors><title>Arabic CALL system based on pedagogically indexed text</title><categories>cs.AI</categories><comments>The 2011 International Conference on Artificial Intelligence
  (ICAI'11), 2011, WORLDCOMP'11, Las Vegas, Nevada, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces the benefits of using computer as a tool for foreign
language teaching and learning. It describes the effect of using Natural
Language Processing (NLP) tools for learning Arabic. The technique explored in
this particular case is the employment of pedagogically indexed corpora. This
text-based method provides the teacher the advantage of building activities
based on texts adapted to a particular pedagogical situation. This paper also
presents ARAC: a Platform dedicated to language educators allowing them to
create activities within their own pedagogical area of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2375</identifier>
 <datestamp>2013-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2375</id><created>2012-07-10</created><updated>2013-11-26</updated><authors><author><keyname>Aloupis</keyname><forenames>Greg</forenames></author><author><keyname>Barba</keyname><forenames>Luis</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Souvaine</keyname><forenames>Diane L.</forenames></author></authors><title>Bichromatic compatible matchings</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a set $R$ of $n$ red points and a set $B$ of $n$ blue points, a
$BR$-matching is a non-crossing geometric perfect matching where each segment
has one endpoint in $B$ and one in $R$. Two $BR$-matchings are compatible if
their union is also non-crossing. We prove that, for any two distinct
$BR$-matchings $M$ and $M'$, there exists a sequence of $BR$-matchings $M =
M_1, ..., M_k = M'$ such that $M_{i-1} $ is compatible with $M_i$. This implies
the connectivity of the compatible bichromatic matching graph containing one
node for each bichromatic matching and an edge joining each pair of compatible
matchings, thereby answering the open problem posed by Aichholzer et al. in
&quot;Compatible matchings for bichromatic plane straight-line graphs&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2378</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2378</id><created>2012-07-10</created><authors><author><keyname>Cintra</keyname><forenames>Renato J.</forenames></author><author><keyname>Nascimento</keyname><forenames>Abra&#xe3;o D. C.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>Parametric and Nonparametric Tests for Speckled Imagery</title><categories>stat.CO cs.GR</categories><comments>Accepted for publication in the Patter Analysis and Applications
  journal</comments><doi>10.1007/s10044-011-0249-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synthetic aperture radar (SAR) has a pivotal role as a remote imaging method.
Obtained by means of coherent illumination, SAR images are contaminated with
speckle noise. The statistical modeling of such contamination is well described
according with the multiplicative model and its implied G0 distribution. The
understanding of SAR imagery and scene element identification is an important
objective in the field. In particular, reliable image contrast tools are
sought. Aiming the proposition of new tools for evaluating SAR image contrast,
we investigated new methods based on stochastic divergence. We propose several
divergence measures specifically tailored for G0 distributed data. We also
introduce a nonparametric approach based on the Kolmogorov-Smirnov distance for
G0 data. We devised and assessed tests based on such measures, and their
performances were quantified according to their test sizes and powers. Using
Monte Carlo simulation, we present a robustness analysis of test statistics and
of maximum likelihood estimators for several degrees of innovative
contamination. It was identified that the proposed tests based on triangular
and arithmetic-geometric measures outperformed the Kolmogorov-Smirnov
methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2406</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2406</id><created>2012-07-10</created><authors><author><keyname>Joseph</keyname><forenames>Antony</forenames></author><author><keyname>Barron</keyname><forenames>Andrew</forenames></author></authors><title>Fast Sparse Superposition Codes have Exponentially Small Error
  Probability for R &lt; C</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>23 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the additive white Gaussian noise channel with average codeword power
constraint, sparse superposition codes are developed. These codes are based on
the statistical high-dimensional regression framework. The paper [IEEE Trans.
Inform. Theory 55 (2012), 2541 - 2557] investigated decoding using the optimal
maximum-likelihood decoding scheme. Here a fast decoding algorithm, called
adaptive successive decoder, is developed. For any rate R less than the
capacity C communication is shown to be reliable with exponentially small error
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2415</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2415</id><created>2012-07-10</created><updated>2012-12-17</updated><authors><author><keyname>Ulusoy</keyname><forenames>Alphan</forenames></author><author><keyname>Smith</keyname><forenames>Stephen L.</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author></authors><title>Optimal Multi-Robot Path Planning with LTL Constraints: Guaranteeing
  Correctness Through Synchronization</title><categories>cs.RO</categories><comments>Extended version of the DARS 2012 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the automated planning of optimal paths for a
robotic team satisfying a high level mission specification. Each robot in the
team is modeled as a weighted transition system where the weights have
associated deviation values that capture the non-determinism in the traveling
times of the robot during its deployment. The mission is given as a Linear
Temporal Logic (LTL) formula over a set of propositions satisfied at the
regions of the environment. Additionally, we have an optimizing proposition
capturing some particular task that must be repeatedly completed by the team.
The goal is to minimize the maximum time between successive satisfying
instances of the optimizing proposition while guaranteeing that the mission is
satisfied even under non-deterministic traveling times. Our method relies on
the communication capabilities of the robots to guarantee correctness and
maintain performance during deployment. After computing a set of optimal
satisfying paths for the members of the team, we also compute a set of
synchronization sequences for each robot to ensure that the LTL formula is
never violated during deployment. We implement and experimentally evaluate our
method considering a persistent monitoring task in a road network environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2422</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2422</id><created>2012-07-10</created><authors><author><keyname>Wipf</keyname><forenames>David</forenames></author><author><keyname>Wu</keyname><forenames>Yi</forenames></author></authors><title>Dual-Space Analysis of the Sparse Linear Model</title><categories>stat.ML cs.CV cs.IT math.IT</categories><comments>9 pages, 2 figures, submission to NIPS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse linear (or generalized linear) models combine a standard likelihood
function with a sparse prior on the unknown coefficients. These priors can
conveniently be expressed as a maximization over zero-mean Gaussians with
different variance hyperparameters. Standard MAP estimation (Type I) involves
maximizing over both the hyperparameters and coefficients, while an empirical
Bayesian alternative (Type II) first marginalizes the coefficients and then
maximizes over the hyperparameters, leading to a tractable posterior
approximation. The underlying cost functions can be related via a dual-space
framework from Wipf et al. (2011), which allows both the Type I or Type II
objectives to be expressed in either coefficient or hyperparmeter space. This
perspective is useful because some analyses or extensions are more conducive to
development in one space or the other. Herein we consider the estimation of a
trade-off parameter balancing sparsity and data fit. As this parameter is
effectively a variance, natural estimators exist by assessing the problem in
hyperparameter (variance) space, transitioning natural ideas from Type II to
solve what is much less intuitive for Type I. In contrast, for analyses of
update rules and sparsity properties of local and global solutions, as well as
extensions to more general likelihood models, we can leverage coefficient-space
techniques developed for Type I and apply them to Type II. For example, this
allows us to prove that Type II-inspired techniques can be successful
recovering sparse coefficients when unfavorable restricted isometry properties
(RIP) lead to failure of popular L1 reconstructions. It also facilitates the
analysis of Type II when non-Gaussian likelihood models lead to intractable
integrations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2424</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2424</id><created>2012-07-10</created><authors><author><keyname>Jones</keyname><forenames>Daniel C.</forenames></author><author><keyname>Ruzzo</keyname><forenames>Walter L.</forenames></author><author><keyname>Peng</keyname><forenames>Xinxia</forenames></author><author><keyname>Katze</keyname><forenames>Michael G.</forenames></author></authors><title>Compression of next-generation sequencing reads aided by highly
  efficient de novo assembly</title><categories>q-bio.QM cs.DS q-bio.GN</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Quip, a lossless compression algorithm for next-generation
sequencing data in the FASTQ and SAM/BAM formats. In addition to implementing
reference-based compression, we have developed, to our knowledge, the first
assembly-based compressor, using a novel de novo assembly algorithm. A
probabilistic data structure is used to dramatically reduce the memory required
by traditional de Bruijn graph assemblers, allowing millions of reads to be
assembled very efficiently. Read sequences are then stored as positions within
the assembled contigs. This is combined with statistical compression of read
identifiers, quality scores, alignment information, and sequences, effectively
collapsing very large datasets to less than 15% of their original size with no
loss of information.
  Availability: Quip is freely available under the BSD license from
http://cs.washington.edu/homes/dcjones/quip.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2426</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2426</id><created>2012-07-10</created><authors><author><keyname>Qaffou</keyname><forenames>Issam</forenames></author><author><keyname>Sadgal</keyname><forenames>Mohammed</forenames></author><author><keyname>Elfazziki</keyname><forenames>Abdelaziz</forenames></author></authors><title>A Multi-Agents Architecture to Learn Vision Operators and their
  Parameters</title><categories>cs.CV</categories><comments>IJCSI, May 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In a vision system, every task needs that the operators to apply should be
{\guillemotleft} well chosen {\guillemotright} and their parameters should be
also {\guillemotleft} well adjusted {\guillemotright}. The diversity of
operators and the multitude of their parameters constitute a big challenge for
users. As it is very difficult to make the {\guillemotleft} right
{\guillemotright} choice, lack of a specific rule, many disadvantages appear
and affect the computation time and especially the quality of results. In this
paper we present a multi-agent architecture to learn the best operators to
apply and their best parameters for a class of images. Our architecture
consists of three types of agents: User Agent, Operator Agent and Parameter
Agent. The User Agent determines the phases of treatment, a library of
operators and the possible values of their parameters. The Operator Agent
constructs all possible combinations of operators and the Parameter Agent, the
core of the architecture, adjusts the parameters of each combination by
treating a large number of images. Through the reinforcement learning
mechanism, our architecture does not consider only the system opportunities but
also the user preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2440</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2440</id><created>2012-07-10</created><authors><author><keyname>Wipf</keyname><forenames>David</forenames></author></authors><title>Non-Convex Rank Minimization via an Empirical Bayesian Approach</title><categories>stat.ML cs.CV cs.IT math.IT</categories><comments>10 pages, 6 figures, UAI 2012 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications that require matrix solutions of minimal rank, the
underlying cost function is non-convex leading to an intractable, NP-hard
optimization problem. Consequently, the convex nuclear norm is frequently used
as a surrogate penalty term for matrix rank. The problem is that in many
practical scenarios there is no longer any guarantee that we can correctly
estimate generative low-rank matrices of interest, theoretical special cases
notwithstanding. Consequently, this paper proposes an alternative empirical
Bayesian procedure build upon a variational approximation that, unlike the
nuclear norm, retains the same globally minimizing point estimate as the rank
function under many useful constraints. However, locally minimizing solutions
are largely smoothed away via marginalization, allowing the algorithm to
succeed when standard convex relaxations completely fail. While the proposed
methodology is generally applicable to a wide range of low-rank applications,
we focus our attention on the robust principal component analysis problem
(RPCA), which involves estimating an unknown low-rank matrix with unknown
sparse corruptions. Theoretical and empirical evidence are presented to show
that our method is potentially superior to related MAP-based approaches, for
which the convex principle component pursuit (PCP) algorithm (Candes et al.,
2011) can be viewed as a special case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2459</identifier>
 <datestamp>2012-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2459</id><created>2012-07-10</created><authors><author><keyname>Lamine</keyname><forenames>Fradj Ben</forenames><affiliation>sage</affiliation></author><author><keyname>Kalti</keyname><forenames>Karim</forenames><affiliation>sage</affiliation></author><author><keyname>Mahjoub</keyname><forenames>Mohamed Ali</forenames><affiliation>SAGE</affiliation></author></authors><title>Etude de Mod\`eles \`a base de r\'eseaux Bay\'esiens pour l'aide au
  diagnostic de tumeurs c\'er\'ebrales</title><categories>cs.AI</categories><comments>Journ\'ees francophones d'ing\'enierie des connaissances, France
  (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes different models based on Bayesian networks RB
modeling expertise in the diagnosis of brain tumors. Indeed, they are well
adapted to the representation of the uncertainty in the process of diagnosis of
these tumors. In our work, we first tested several structures derived from the
Bayesian network reasoning performed by doctors on the one hand and structures
generated automatically on the other. This step aims to find the best structure
that increases diagnostic accuracy. The machine learning algorithms relate
MWST-EM algorithms, SEM and SEM + T. To estimate the parameters of the Bayesian
network from a database incomplete, we have proposed an extension of the EM
algorithm by adding a priori knowledge in the form of the thresholds calculated
by the first phase of the algorithm RBE . The very encouraging results obtained
are discussed at the end of the paper
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2461</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2461</id><created>2012-07-09</created><authors><author><keyname>Bauer</keyname><forenames>Andreas</forenames></author><author><keyname>Baumgartner</keyname><forenames>Peter</forenames></author><author><keyname>Norrish</keyname><forenames>Michael</forenames></author></authors><title>Reasoning with Data-Centric Business Processes</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an approach to modelling and reasoning about data-centric
business processes and present a form of general model checking. Our technique
extends existing approaches, which explore systems only from concrete initial
states. Specifically, we model business processes in terms of smaller
fragments, whose possible interactions are constrained by first-order logic
formulae. In turn, process fragments are connected graphs annotated with
instructions to modify data. Correctness properties concerning the evolution of
data with respect to processes can be stated in a first-order branching-time
logic over built-in theories, such as linear integer arithmetic, records and
arrays.
  Solving general model checking problems over this logic is considerably
harder than model checking when a concrete initial state is given. To this end,
we present a tableau procedure that reduces these model checking problems to
first-order logic over arithmetic. The resulting proof obligations are passed
on to appropriate &quot;off-the-shelf&quot; theorem provers. We also detail our modelling
approach, describe the reasoning components and report on first experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2462</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2462</id><created>2012-07-10</created><authors><author><keyname>Markovski</keyname><forenames>J.</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Scalable Minimization Algorithm for Partial Bisimulation</title><categories>cs.LO cs.SY</categories><comments>In Proceedings WS-FMDS 2012, arXiv:1207.1841</comments><proxy>EPTCS</proxy><acm-class>D.2.4</acm-class><journal-ref>EPTCS 86, 2012, pp. 9-16</journal-ref><doi>10.4204/EPTCS.86.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an efficient algorithm for computing the partial bisimulation
preorder and equivalence for labeled transitions systems. The partial
bisimulation preorder lies between simulation and bisimulation, as only a part
of the set of actions is bisimulated, whereas the rest of the actions are
simulated. Computing quotients for simulation equivalence is more expensive
than for bisimulation equivalence, as for simulation one has to account for the
so-called little brothers, which represent classes of states that can simulate
other classes. It is known that in the absence of little brother states,
(partial bi)simulation and bisimulation coincide, but still the complexity of
existing minimization algorithms for simulation and bisimulation does not
scale. Therefore, we developed a minimization algorithm and an accompanying
tool that scales with respect to the bisimulated action subset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2479</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2479</id><created>2012-07-05</created><updated>2013-03-05</updated><authors><author><keyname>Jancar</keyname><forenames>Petr</forenames></author></authors><title>Bisimilarity on Basic Process Algebra is in 2-ExpTime (an explicit
  proof)</title><categories>cs.LO cs.FL</categories><comments>Final version accepted to LMCS</comments><proxy>Logical Methods In Computer Science</proxy><acm-class>F.4.2; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 9, Issue 1 (March 13,
  2013) lmcs:873</journal-ref><doi>10.2168/LMCS-9(1:10)2013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Burkart, Caucal, Steffen (1995) showed a procedure deciding bisimulation
equivalence of processes in Basic Process Algebra (BPA), i.e. of sequential
processes generated by context-free grammars. They improved the previous
decidability result of Christensen, H\&quot;uttel, Stirling (1992), since their
procedure has obviously an elementary time complexity and the authors claim
that a close analysis would reveal a double exponential upper bound. Here a
self-contained direct proof of the membership in 2-ExpTime is given. This is
done via a Prover-Refuter game which shows that there is an alternating Turing
machine deciding the problem in exponential space. The proof uses similar
ingredients (size-measures, decompositions, bases) as the previous proofs, but
one new simplifying factor is an explicit addition of infinite regular strings
to the state space. An auxiliary claim also shows an explicit exponential upper
bound on the equivalence level of nonbisimilar normed BPA processes. The
importance of clarifying the 2-ExpTime upper bound for BPA bisimilarity has
recently increased due to the shift of the known lower bound from PSpace (Srba,
2002) to ExpTime (Kiefer, 2012).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2488</identifier>
 <datestamp>2013-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2488</id><created>2012-07-10</created><updated>2013-11-26</updated><authors><author><keyname>Gangeh</keyname><forenames>Mehrdad J.</forenames></author><author><keyname>Ghodsi</keyname><forenames>Ali</forenames></author><author><keyname>Kamel</keyname><forenames>Mohamed S.</forenames></author></authors><title>Kernelized Supervised Dictionary Learning</title><categories>cs.CV cs.LG</categories><comments>This paper has been withdrawn by the author as it has been already
  published by the IEEE Trans. on Signal Processing and is now available online</comments><doi>10.1109/TSP.2013.2274276</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose supervised dictionary learning (SDL) by
incorporating information on class labels into the learning of the dictionary.
To this end, we propose to learn the dictionary in a space where the dependency
between the signals and their corresponding labels is maximized. To maximize
this dependency, the recently introduced Hilbert Schmidt independence criterion
(HSIC) is used. One of the main advantages of this novel approach for SDL is
that it can be easily kernelized by incorporating a kernel, particularly a
data-derived kernel such as normalized compression distance, into the
formulation. The learned dictionary is compact and the proposed approach is
fast. We show that it outperforms other unsupervised and supervised dictionary
learning approaches in the literature, using real-world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2491</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2491</id><created>2012-07-10</created><authors><author><keyname>Boots</keyname><forenames>Byron</forenames></author><author><keyname>Gordon</keyname><forenames>Geoffrey J.</forenames></author></authors><title>A Spectral Learning Approach to Range-Only SLAM</title><categories>cs.LG cs.RO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel spectral learning algorithm for simultaneous localization
and mapping (SLAM) from range data with known correspondences. This algorithm
is an instance of a general spectral system identification framework, from
which it inherits several desirable properties, including statistical
consistency and no local optima. Compared with popular batch optimization or
multiple-hypothesis tracking (MHT) methods for range-only SLAM, our spectral
approach offers guaranteed low computational requirements and good tracking
performance. Compared with popular extended Kalman filter (EKF) or extended
information filter (EIF) approaches, and many MHT ones, our approach does not
need to linearize a transition or measurement model; such linearizations can
cause severe errors in EKFs and EIFs, and to a lesser extent MHT, particularly
for the highly non-Gaussian posteriors encountered in range-only SLAM. We
provide a theoretical analysis of our method, including finite-sample error
bounds. Finally, we demonstrate on a real-world robotic SLAM problem that our
algorithm is not only theoretically justified, but works well in practice: in a
comparison of multiple methods, the lowest errors come from a combination of
our algorithm with batch optimization, but our method alone produces nearly as
good a result at far lower computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2505</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2505</id><created>2012-07-10</created><updated>2013-02-03</updated><authors><author><keyname>Nomura</keyname><forenames>Ryo</forenames></author><author><keyname>Han</keyname><forenames>Te Sun</forenames></author></authors><title>Second-Order Slepian-Wolf Coding Theorems for Non-Mixed and Mixed
  Sources</title><categories>cs.IT math.IT</categories><comments>Title was changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The second-order achievable rate region in Slepian-Wolf source coding systems
is investigated. The concept of second-order achievable rates, which enables us
to make a finer evaluation of achievable rates, has already been introduced and
analyzed for general sources in the single-user source coding problem.
Analogously, in this paper, we first define the second-order achievable rate
region for the Slepian-Wolf coding system to establish the source coding
theorem in the second- order sense. The Slepian-Wolf coding problem for
correlated sources is one of typical problems in the multi-terminal information
theory. In particular, Miyake and Kanaya, and Han have established the
first-order source coding theorems for general correlated sources. On the other
hand, in general, the second-order achievable rate problem for the Slepian-Wolf
coding system with general sources remains still open up to present. In this
paper we present the analysis concerning the second- order achievable rates for
general sources which are based on the information spectrum methods developed
by Han and Verdu. Moreover, we establish the explicit second-order achievable
rate region for i.i.d. correlated sources with countably infinite alphabets and
mixed correlated sources, respectively, using the relevant asymptotic
normality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2506</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2506</id><created>2012-07-10</created><updated>2012-07-12</updated><authors><author><keyname>Dragan</keyname><forenames>Feodor F.</forenames></author><author><keyname>Abu-Ata</keyname><forenames>Muad</forenames></author></authors><title>Collective Additive Tree Spanners of Bounded Tree-Breadth Graphs with
  Generalizations and Consequences</title><categories>cs.DS math.MG</categories><comments>21 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study collective additive tree spanners for families of
graphs enjoying special Robertson-Seymour's tree-decompositions, and
demonstrate interesting consequences of obtained results. We say that a graph
$G$ {\em admits a system of $\mu$ collective additive tree $r$-spanners}
(resp., {\em multiplicative tree $t$-spanners}) if there is a system $\cT(G)$
of at most $\mu$ spanning trees of $G$ such that for any two vertices $x,y$ of
$G$ a spanning tree $T\in \cT(G)$ exists such that $d_T(x,y)\leq d_G(x,y)+r$
(resp., $d_T(x,y)\leq t\cdot d_G(x,y)$). When $\mu=1$ one gets the notion of
{\em additive tree $r$-spanner} (resp., {\em multiplicative tree $t$-spanner}).
It is known that if a graph $G$ has a multiplicative tree $t$-spanner, then $G$
admits a Robertson-Seymour's tree-decomposition with bags of radius at most
$\lceil{t/2}\rceil$ in $G$. We use this to demonstrate that there is a
polynomial time algorithm that, given an $n$-vertex graph $G$ admitting a
multiplicative tree $t$-spanner, constructs a system of at most $\log_2 n$
collective additive tree $O(t\log n)$-spanners of $G$. That is, with a slight
increase in the number of trees and in the stretch, one can &quot;turn&quot; a
multiplicative tree spanner into a small set of collective additive tree
spanners. We extend this result by showing that if a graph $G$ admits a
multiplicative $t$-spanner with tree-width $k-1$, then $G$ admits a
Robertson-Seymour's tree-decomposition each bag of which can be covered with at
most $k$ disks of $G$ of radius at most $\lceil{t/2}\rceil$ each. This is used
to demonstrate that, for every fixed $k$, there is a polynomial time algorithm
that, given an $n$-vertex graph $G$ admitting a multiplicative $t$-spanner with
tree-width $k-1$, constructs a system of at most $k(1+ \log_2 n)$ collective
additive tree $O(t\log n)$-spanners of $G$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2511</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2511</id><created>2012-07-10</created><authors><author><keyname>Quaresma</keyname><forenames>Pedro</forenames></author></authors><title>An XML-Format for Conjectures in Geometry (Work-in-Progress)</title><categories>cs.CG</categories><comments>Conferences on Intelligent Computer Mathematics, CICM 2012, 8.-13.
  July 2012, Jacobs University, Bremen, Germany. 12 pages 2 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With a large number of software tools dedicated to the visualisation and/or
demonstration of properties of geometric constructions and also with the
emerging of repositories of geometric constructions, there is a strong need of
linking them, and making them and their corpora, widely usable. A common
setting for interoperable interactive geometry was already proposed, the i2g
format, but, in this format, the conjectures and proofs counterparts are
missing. A common format capable of linking all the tools in the field of
geometry is missing. In this paper an extension of the i2g format is proposed,
this extension is capable of describing not only the geometric constructions
but also the geometric conjectures. The integration of this format into the
Web-based GeoThms, TGTP and Web Geometry Laboratory systems is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2514</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2514</id><created>2012-07-10</created><updated>2012-10-09</updated><authors><author><keyname>Joseph</keyname><forenames>Vinay</forenames></author><author><keyname>de Veciana</keyname><forenames>Gustavo</forenames></author><author><keyname>Arapostathis</keyname><forenames>Ari</forenames></author></authors><title>Resource Allocation: Realizing Mean-Variability-Fairness Tradeoffs</title><categories>cs.SY cs.NI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1111.3728</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network Utility Maximization (NUM) provides a key conceptual framework to
study reward allocation amongst a collection of users/entities across
disciplines as diverse as economics, law and engineering. In network
engineering, this framework has been particularly insightful towards
understanding how Internet protocols allocate bandwidth, and motivated diverse
research efforts on distributed mechanisms to maximize network utility while
incorporating new relevant constraints, on energy, power, storage, stability,
etc., e.g., for systems ranging from communication networks to the smart-grid.
However when the available resources and/or users' utilities vary over time,
reward allocations will tend to vary, which in turn may have a detrimental
impact on the users' overall satisfaction or quality of experience.
  This paper introduces a generalization of NUM framework which explicitly
incorporates the detrimental impact of temporal variability in a user's
allocated rewards. It explicitly incorporates tradeoffs amongst the mean and
variability in users' reward allocations, as well as fairness. We propose a
simple online algorithm to realize these tradeoffs, which, under stationary
ergodic assumptions, is shown to be asymptotically optimal, i.e., achieves a
long term performance equal to that of an offline algorithm with knowledge of
the future variability in the system. This substantially extends work on NUM to
an interesting class of relevant problems where users/entities are sensitive to
temporal variability in their service or allocated rewards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2515</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2515</id><created>2012-07-10</created><authors><author><keyname>Aswani</keyname><forenames>Anil</forenames></author><author><keyname>Tomlin</keyname><forenames>Claire</forenames></author></authors><title>Incentive Design for Efficient Building Quality of Service</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Buildings are a large consumer of energy, and reducing their energy usage may
provide financial and societal benefits. One challenge in achieving efficient
building operation is the fact that few financial motivations exist for
encouraging low energy configuration and operation of buildings. As a result,
incentive schemes for managers of large buildings are being proposed for the
purpose of saving energy. This paper focuses on incentive design for the
configuration and operation of building-wide heating, ventilation, and
air-conditioning (HVAC) systems, because these systems constitute the largest
portion of energy usage in most buildings. We begin with an empirical model of
a building-wide HVAC system, which describes the tradeoffs between energy
consumption, quality of service (as defined by occupant satisfaction), and the
amount of work required for maintenance and configuration. The model has
significant non-convexities, and so we derive some results regarding
qualitative properties of non-convex optimization problems with certain
partial-ordering features. These results are used to show that &quot;baselining&quot;
incentive schemes suffer from moral hazard problems, and they also encourage
energy reductions at the expense of also decreasing occupant satisfaction. We
propose an alternative incentive scheme that has the interpretation of a
performance-based bonus. A theoretical analysis shows that this encourages
energy and monetary savings and modest gains in occupant satisfaction and
quality of service, which is confirmed by our numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2530</identifier>
 <datestamp>2012-11-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2530</id><created>2012-07-10</created><updated>2012-11-01</updated><authors><author><keyname>Thoppe</keyname><forenames>Gugan</forenames></author></authors><title>Generalized Network Tomography</title><categories>cs.NI cs.DC math.ST stat.TH</categories><comments>8 Pages, Corrected Typos in Lemma 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For successful estimation, the usual network tomography algorithms crucially
require i) end-to-end data generated using multicast probe packets, real or
emulated, and ii) the network to be a tree rooted at a single sender with
destinations at leaves. These requirements, consequently, limit their scope of
application. In this paper, we address successfully a general problem,
henceforth called generalized network tomography, wherein the objective is to
estimate the link performance parameters for networks with arbitrary topologies
using only end-to-end measurements of pure unicast probe packets.
Mathematically, given a binary matrix $A,$ we propose a novel algorithm to
uniquely estimate the distribution of $X,$ a vector of independent non-negative
random variables, given only IID samples of the components of the random vector
$Y = AX.$ This algorithm, in fact, does not even require any prior knowledge of
the unknown distributions. The idea is to approximate the distribution of each
component of $X$ using linear combinations of known exponential bases and
estimate the unknown weights. These weights are obtained by solving a set of
polynomial systems based on the moment generating function of the components of
$Y.$ For unique identifiability, it is only required that every pair of columns
of the matrix $A$ be linearly independent, a property that holds true for the
routing matrices of all multicast tree networks. Matlab based simulations have
been included to illustrate the potential of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2531</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2531</id><created>2012-07-10</created><authors><author><keyname>Hou</keyname><forenames>Ping</forenames></author></authors><title>Quantified Differential Temporal Dynamic Logic for Verifying Properties
  of Distributed Hybrid Systems</title><categories>cs.LO cs.SY</categories><comments>arXiv admin note: substantial text overlap with arXiv:1206.3357 by
  other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We combine quantified differential dynamic logic (QdL) for reasoning about
the possible behavior of distributed hybrid systems with temporal logic for
reasoning about the temporal behavior during their operation. Our logic
supports verification of temporal and non-temporal properties of distributed
hybrid systems and provides a uniform treatment of discrete transitions,
continuous evolution, and dynamic dimensionality-changes. For our combined
logic, we generalize the semantics of dynamic modalities to refer to hybrid
traces instead of final states. Further, we prove that this gives a
conservative extension of QdL for distributed hybrid systems. On this basis, we
provide a modular verification calculus that reduces correctness of temporal
behavior of distributed hybrid systems to non-temporal reasoning, and prove
that we obtain a complete axiomatization relative to the non-temporal base
logic QdL. Using this calculus, we analyze temporal safety properties in a
distributed air traffic control system where aircraft can appear dynamically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2534</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2534</id><created>2012-07-10</created><authors><author><keyname>Hou</keyname><forenames>Ping</forenames></author><author><keyname>Wittocx</keyname><forenames>Johan</forenames></author><author><keyname>Denecker</keyname><forenames>Marc</forenames></author></authors><title>LPC(ID): A Sequent Calculus Proof System for Propositional Logic
  Extended with Inductive Definitions</title><categories>cs.LO cs.AI</categories><comments>Journal paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The logic FO(ID) uses ideas from the field of logic programming to extend
first order logic with non-monotone inductive definitions. Such logic formally
extends logic programming, abductive logic programming and datalog, and thus
formalizes the view on these formalisms as logics of (generalized) inductive
definitions. The goal of this paper is to study a deductive inference method
for PC(ID), which is the propositional fragment of FO(ID). We introduce a
formal proof system based on the sequent calculus (Gentzen-style deductive
system) for this logic. As PC(ID) is an integration of classical propositional
logic and propositional inductive definitions, our sequent calculus proof
system integrates inference rules for propositional calculus and definitions.
We present the soundness and completeness of this proof system with respect to
a slightly restricted fragment of PC(ID). We also provide some complexity
results for PC(ID). By developing the proof system for PC(ID), it helps us to
enhance the understanding of proof-theoretic foundations of FO(ID), and
therefore to investigate useful proof systems for FO(ID).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2537</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2537</id><created>2012-07-10</created><authors><author><keyname>Biswas</keyname><forenames>Sambhunath</forenames></author><author><keyname>Biswas</keyname><forenames>Amrita</forenames></author></authors><title>Face Recognition Algorithms based on Transformed Shape Features</title><categories>cs.CV</categories><comments>7 pages</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 3, No 3, May 2012,pg 445-451</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human face recognition is, indeed, a challenging task, especially under the
illumination and pose variations. We examine in the present paper effectiveness
of two simple algorithms using coiflet packet and Radon transforms to recognize
human faces from some databases of still gray level images, under the
environment of illumination and pose variations. Both the algorithms convert
2-D gray level training face images into their respective depth maps or
physical shape which are subsequently transformed by Coiflet packet and Radon
transforms to compute energy for feature extraction. Experiments show that such
transformed shape features are robust to illumination and pose variations. With
the features extracted, training classes are optimally separated through linear
discriminant analysis (LDA), while classification for test face images is made
through a k-NN classifier, based on L1 norm and Mahalanobis distance measures.
Proposed algorithms are then tested on face images that differ in
illumination,expression or pose separately, obtained from three
databases,namely, ORL, Yale and Essex-Grimace databases. Results, so obtained,
are compared with two different existing algorithms.Performance using
Daubechies wavelets is also examined. It is seen that the proposed Coiflet
packet and Radon transform based algorithms have significant performance,
especially under different illumination conditions and pose variation.
Comparison shows the proposed algorithms are superior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2541</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2541</id><created>2012-07-11</created><updated>2012-07-13</updated><authors><author><keyname>Chen</keyname><forenames>Jianwen</forenames></author><author><keyname>Li</keyname><forenames>Yiping</forenames></author><author><keyname>Feng</keyname><forenames>Ling</forenames></author></authors><title>A New Weighted Spearman's Footrule as A Measure of Distance between
  Rankings</title><categories>cs.DM</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many applications motivate the distance measure between rankings, such as
comparing top-k lists and rank aggregation for voting, and intrigue great
interest to researchers. For example, for a search engine, the use of different
ranking algorithms may return different ranking lists. The effect of a ranking
algorithm can be estimated by computing the distance (similarity) between the
result ranking it returns and the appropriate ranking people expect. People may
be interested in only the first few items of result ranking, therefore the
metric for measuring the distance should emphasize on the items in higher
positions. Besides, in an extreme case, if a result ranking is the total
reverse of the expected ranking, then it is considered to be the worst ranking
with the maximum distance. Therefore, a metric is called for, which can satisfy
both of the two intuitions. To address this problem, we present a weighted
metric based on the classical Spearman's footrule metric to measure the
distance between two permutations of n objects. This metric can be applied in
rank aggregation problem with a polynomial time algorithm, and produces a
2-approximation for adopting the weighted Kendall's tau distance proposed by
Farnoud et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2544</identifier>
 <datestamp>2013-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2544</id><created>2012-07-11</created><updated>2013-02-05</updated><authors><author><keyname>Bindal</keyname><forenames>Sandeep</forenames></author><author><keyname>Bansal</keyname><forenames>Sorav</forenames></author><author><keyname>Lal</keyname><forenames>Akash</forenames></author></authors><title>Variable and Thread Bounding for Systematic Testing of Multithreaded
  Programs</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous approaches to systematic state-space exploration for testing
multi-threaded programs have proposed context-bounding and depth-bounding to be
effective ranking algorithms for testing multithreaded programs. This paper
proposes two new metrics to rank thread schedules for systematic state-space
exploration. Our metrics are based on characterization of a concurrency bug
using v (the minimum number of distinct variables that need to be involved for
the bug to manifest) and t (the minimum number of distinct threads among which
scheduling constraints are required to manifest the bug). Our algorithm is
based on the hypothesis that in practice, most concurrency bugs have low v
(typically 1- 2) and low t (typically 2-4) characteristics. We iteratively
explore the search space of schedules in increasing orders of v and t. We show
qualitatively and empirically that our algorithm finds common bugs in fewer
number of execution runs, compared with previous approaches. We also show that
using v and t improves the lower bounds on the probability of finding bugs
through randomized algorithms.
  Systematic exploration of schedules requires instrumenting each variable
access made by a program, which can be very expensive and severely limits the
applicability of this approach. Previous work [5, 19] has avoided this problem
by interposing only on synchronization operations (and ignoring other variable
accesses). We demonstrate that by using variable bounding (v) and a static
imprecise alias analysis, we can interpose on all variable accesses (and not
just synchronization operations) at 10-100x less overhead than previous
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2546</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2546</id><created>2012-07-11</created><authors><author><keyname>Al-Naffouri</keyname><forenames>Tareq Y.</forenames></author><author><keyname>Dahman</keyname><forenames>Ala</forenames></author><author><keyname>Sohail</keyname><forenames>Muhammad S.</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Low Complexity Blind Equalization for OFDM Systems with General
  Constellations</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2012.2218808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a low-complexity algorithm for blind equalization of data
in OFDM-based wireless systems with general constellations. The proposed
algorithm is able to recover data even when the channel changes on a
symbol-by-symbol basis, making it suitable for fast fading channels. The
proposed algorithm does not require any statistical information of the channel
and thus does not suffer from latency normally associated with blind methods.
We also demonstrate how to reduce the complexity of the algorithm, which
becomes especially low at high SNR. Specifically, we show that in the high SNR
regime, the number of operations is of the order O(LN), where L is the cyclic
prefix length and N is the total number of subcarriers. Simulation results
confirm the favorable performance of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2548</identifier>
 <datestamp>2012-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2548</id><created>2012-07-11</created><updated>2012-10-01</updated><authors><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author></authors><title>Evolution of cooperation driven by zealots</title><categories>physics.soc-ph cs.SI q-bio.PE</categories><comments>5 figures</comments><journal-ref>Scientific Reports, 2, 646 (2012)</journal-ref><doi>10.1038/srep00646</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent experimental results with humans involved in social dilemma games
suggest that cooperation may be a contagious phenomenon and that the selection
pressure operating on evolutionary dynamics (i.e., mimicry) is relatively weak.
I propose an evolutionary dynamics model that links these experimental findings
and evolution of cooperation. By assuming a small fraction of (imperfect)
zealous cooperators, I show that a large fraction of cooperation emerges in
evolutionary dynamics of social dilemma games. Even if defection is more
lucrative than cooperation for most individuals, they often mimic cooperation
of fellows unless the selection pressure is very strong. Then, zealous
cooperators can transform the population to be even fully cooperative under
standard evolutionary dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2556</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2556</id><created>2012-07-11</created><authors><author><keyname>Grech</keyname><forenames>M.</forenames></author><author><keyname>Kisielewicz</keyname><forenames>A.</forenames></author></authors><title>The Cerny conjecture for automata respecting intervals of a directed
  graph</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \v{C}ern\'y's conjecture states that for every synchronizing automaton
with n states there exists a reset word of length not exceeding (n-11)^2. We
prove this conjecture for a class of automata preserving certain properties of
intervals of a directed graph. Our result unifies and generalizes some earlier
results obtained by other authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2564</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2564</id><created>2012-07-11</created><authors><author><keyname>Zayani</keyname><forenames>Mohamed-Haykel</forenames></author><author><keyname>Gauthier</keyname><forenames>Vincent</forenames></author><author><keyname>Zeghlache</keyname><forenames>Djamal</forenames></author></authors><title>Quantifying Spatiotemporal Stability by means of Entropy: Approach and
  Motivations</title><categories>cs.NI</categories><comments>10 pages, Telecom SudParis Research Report</comments><report-no>#RS2M10001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several studies demonstrate that there are critical differences between real
wireless networks and simulation models. This finding has permitted to extract
spatial and temporal properties for links and to provide efficient methods as
biased link sampling to guarantee efficient routing structure. Other works have
focused on computing metrics to improve routing, specially the reuse of the
measure of entropy. From there, rises the idea of formulating a new measure of
entropy that gives an overview of the spatiotemporal stability of a link. This
measure will rely on spatial and temporal properties of links and fed with the
efficiency of biased link sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2566</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2566</id><created>2012-07-11</created><authors><author><keyname>Antonioni</keyname><forenames>Alberto</forenames></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames></author></authors><title>Cooperation on Social Networks and Its Robustness</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we have used computer models of social-like networks to show by
extensive numerical simulations that cooperation in evolutionary games can
emerge and be stable on this class of networks. The amounts of cooperation
reached are at least as much as in scale-free networks but here the population
model is more realistic. Cooperation is robust with respect to different
strategy update rules, population dynamics, and payoff computation. Only when
straight average payoff is used or there is high strategy or network noise does
cooperation decrease in all games and disappear in the Prisoner's Dilemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2567</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2567</id><created>2012-07-11</created><authors><author><keyname>Hayat</keyname><forenames>S.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Shareef</keyname><forenames>A.</forenames></author><author><keyname>Mahmood</keyname><forenames>A.</forenames></author><author><keyname>Bouk</keyname><forenames>S. H.</forenames></author></authors><title>Energy Efficient MAC Protocols</title><categories>cs.NI</categories><journal-ref>5th AHPCN in conjunction with 14th HPCC-2012, Liverpool, UK</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a survey of energy efficiency of Medium Access Control
(MAC) protocols for Wireless Body Area Sensor Networks (WBASNs). We highlight
the features of MAC protocols along with their advantages and limitations in
context of WBASNs. Comparison of Low Power Listening (LPL), Scheduled
Contention and Time Division Multiple Access (TDMA) is also elaborated. MAC
protocols with respect to different approaches and techniques which are used
for energy minimization, traffic control mechanisms for collision avoidance are
discussed.We also present a survey of path loss models for In-body, On-body and
Off-body communications in WBASNs and analytically discuss that path loss is
maximum in In-body communication because of low energy levels to take care of
tissues and organs located inside the body. Survey of Power model for WBANs of
CSMA/CA and beacon mode is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2571</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2571</id><created>2012-07-11</created><authors><author><keyname>Ding</keyname><forenames>Cunsheng</forenames></author></authors><title>Cyclic Codes from Cyclotomic Sequences of Order Four</title><categories>cs.IT cs.DM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyclic codes are an interesting subclass of linear codes and have been used
in consumer electronics, data transmission technologies, broadcast systems, and
computer applications due to their efficient encoding and decoding algorithms.
In this paper, three cyclotomic sequences of order four are employed to
construct a number of classes of cyclic codes over $\gf(q)$ with prime length.
Under certain conditions lower bounds on the minimum weight are developed. Some
of the codes obtained are optimal or almost optimal. In general, the cyclic
codes constructed in this paper are very good. Some of the cyclic codes
obtained in this paper are closely related to almost difference sets and
difference sets. As a byproduct, the $p$-rank of these (almost) difference sets
are computed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2573</identifier>
 <datestamp>2013-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2573</id><created>2012-07-11</created><updated>2013-03-19</updated><authors><author><keyname>Antonioni</keyname><forenames>Alberto</forenames></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames></author></authors><title>Degree Correlations in Random Geometric Graphs</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><doi>10.1103/PhysRevE.86.037101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatially embedded networks are important in several disciplines. The
prototypical spatial net- work we assume is the Random Geometric Graph of which
many properties are known. Here we present new results for the two-point degree
correlation function in terms of the clustering coefficient of the graphs for
two-dimensional space in particular, with extensions to arbitrary finite
dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2577</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2577</id><created>2012-07-11</created><authors><author><keyname>Manzoor</keyname><forenames>B.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author><author><keyname>Tahir</keyname><forenames>M.</forenames></author></authors><title>Noise Filtering, Channel Modeling and Energy Utilization in Wireless
  Body Area Networks</title><categories>cs.NI</categories><journal-ref>3rd ESA in conjunction with 9th ICESS-2012, Liverpool, UK</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant monitoring of patients without disturbing their daily activities can
be achieved through mobile networks. Sensor nodes distributed in a home
environment to provide home assistance gives concept of Wireless Wearable Body
Area Networks. Gathering useful information and its transmission to the
required destination may face several problems. In this paper we figure out
different issues and discuss their possible solutions in order to obtain an
optimized infrastructure for the care of elderly people. Different channel
models along with their characteristics, noise filtering in different
equalization techniques, energy consumption and effect of different impairments
have been discussed in our paper. The novelty of this work is that we
highlighted multiple issues along with their possible solutions that a BAN
infrastructure is still facing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2584</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2584</id><created>2012-07-11</created><authors><author><keyname>Ray</keyname><forenames>Niranjan Kumar</forenames></author><author><keyname>Sharma</keyname><forenames>Harsh Bardhan</forenames></author><author><keyname>Turuk</keyname><forenames>Ashok Kumar</forenames></author></authors><title>Network Lifetime Analysis of AODV, DSR and ZRP at Different Network
  Parameters</title><categories>cs.NI</categories><comments>12 pages, 11 figures</comments><acm-class>C.2.1</acm-class><journal-ref>International Journal of Mobile Network Communications &amp;
  Telematics (IJMNCT) Vol.2, No.3, June 2012</journal-ref><doi>10.5121/ijmnct.2012.2304</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Enhancement of network lifetime is a key design criterion for most of the
energy constrained networks as nodes are battery operated. In multi-hop
wireless network, proper utilization of battery power is very much necessary to
maintain network connectivity. If the battery power of a node drains quickly
then its connectivity in its neighborhood will be lost. So the study of network
lifetime is very much crucial as compared to other network parameters.
Considering this importance we made an attempt to study the behaviour of three
most common routing protocols in ad hoc network. Extensive simulations are done
on AODV, DSR and ZRP to determine the network lifetime at different node
mobility and at different network load. Simulation results suggest that AODV is
the most energy efficient protocol as compared to other
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2592</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2592</id><created>2012-07-11</created><authors><author><keyname>Kim</keyname><forenames>Gol</forenames><affiliation>Center of Natural Science, University of Sciences, Pyongyang, DPR Korea</affiliation></author></authors><title>Novel Grey Interval Weight Determining and Hybrid Grey Interval Relation
  Method in Multiple Attribute Decision-Making</title><categories>cs.AI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1207.1501</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a grey interval relation TOPSIS for the decision making
in which all of the attribute weights and attribute values are given by the
interval grey numbers. The feature of our method different from other grey
relation decision-making is that all of the subjective and objective weights
are obtained by interval grey number and that decisionmaking is performed based
on the relative approach degree of grey TOPSIS, the relative approach degree of
grey incidence and the relative membership degree of grey incidence using
2-dimensional Euclidean distance. The weighted Borda method is used for
combining the results of three methods. An example shows the applicability of
the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2596</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2596</id><created>2012-07-11</created><authors><author><keyname>Isah</keyname><forenames>Haruna</forenames></author></authors><title>Full Data Controlled Web-Based Feed Aggregator</title><categories>cs.SE</categories><comments>14 pages</comments><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 4, No 3, June 2012</journal-ref><doi>10.5121/ijcsit.2012.4307</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feed syndication is analogous to electronic newsletters, both are aimed at
delivering feeds to subscribers; the difference is that while newsletter
subscription requires e-mail and exposed you to spam and security challenges,
feed syndication ensures that you only get what you requested for. This paper
reports a review on the state of the art of feed aggregation technology and the
development of a locally hosted web based feed aggregator as a research tool
using the core features of WordPress; the software was further enhanced with
plugins and widgets for dynamic content publishing, database and object
caching, social web syndication, back-up and maintenance, among others. The
results highlight the current developments in software re-use and describes;
how open source content management systems can be used for both online and
offline publishing, a means whereby feed aggregator users can control and share
feed data, as well as how web developers can focus on extending the features of
built-in software libraries in applications rather than reinventing the wheel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2597</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2597</id><created>2012-07-11</created><authors><author><keyname>Warade</keyname><forenames>Saket</forenames></author><author><keyname>Aghav</keyname><forenames>Jagannath</forenames></author><author><keyname>Claude</keyname><forenames>Petitpierre</forenames></author><author><keyname>Udayagiri</keyname><forenames>Sandeep</forenames></author></authors><title>Automated Training and Maintenance through Kinect</title><categories>cs.CV cs.ET cs.GR cs.HC</categories><comments>14 pages, 5 figures, 1 Algorithm</comments><journal-ref>Warades, S; Aghav, J; Claude, P; Udayagiri, S;,&quot;Automated Training
  and Maintenance through Kinect,&quot;International Journal of Computer Science,
  Engineering and Applications (IJCSEA) Vol.2, No.3, June 2012</journal-ref><doi>10.5121/ijcsea.2012.2315</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have worked on reducing burden on mechanic involving
complex automobile maintenance activities that are performed in centralised
workshops. We have presented a system prototype that combines Augmented Reality
with Kinect. With the use of Kinect, very high quality sensors are available at
considerably low costs, thus reducing overall expenditure for system design.
The system can be operated either in Speech mode or in Gesture mode. The system
can be controlled by various audio commands if user opts for Speech mode. The
same controlling can also be done by using a set of Gestures in Gesture mode.
  Gesture recognition is the task performed by Kinect system. This system,
bundled with RGB and Depth camera, processes the skeletal data by keeping track
of 20 different body joints. Recognizing Gestures is done by verifying user
movements and checking them against predefined condition. Augmented Reality
module captures real-time image data streams from high resolution camera. This
module then generates 3D model that is superimposed on real time data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2598</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2598</id><created>2012-07-11</created><authors><author><keyname>Even</keyname><forenames>Guy</forenames></author><author><keyname>Smorodinsky</keyname><forenames>Shakhar</forenames></author></authors><title>Hitting Sets Online and Unique-Max Coloring</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of hitting sets online. The hypergraph (i.e.,
range-space consisting of points and ranges) is known in advance, and the
ranges to be stabbed are input one-by-one in an online fashion. The online
algorithm must stab each range upon arrival. An online algorithm may add points
to the hitting set but may not remove already chosen points. The goal is to use
the smallest number of points. The best known competitive ratio for hitting
sets online by Alon et al. \cite{alon2009online} is $O(\log n \cdot \log m)$
for general hypergraphs, where $n$ and $m$ denote the number of points and the
number of ranges, respectively. We consider hypergraphs in which the union of
two intersecting ranges is also a range. Our main result for such hypergraphs
is as follows. The competitive ratio of the online hitting set problem is at
most the unique-max number and at least this number minus one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2600</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2600</id><created>2012-07-11</created><authors><author><keyname>Qatawneh</keyname><forenames>Sokyna</forenames></author><author><keyname>Alneaimi</keyname><forenames>Afaf</forenames></author><author><keyname>Rawashdeh</keyname><forenames>Thamer</forenames></author><author><keyname>Muhairat</keyname><forenames>Mmohammad</forenames></author><author><keyname>Qahwaji</keyname><forenames>Rami</forenames></author><author><keyname>Ipson</keyname><forenames>Stan</forenames></author></authors><title>Efficient Prediction of DNA-Binding Proteins Using Machine Learning</title><categories>cs.CV q-bio.QM</categories><journal-ref>S. Qatawneh, A. Alneaimi, Th. Rawashdeh, M. Muhairat, R. Qahwaji
  and S. Ipson,&quot;Efficient Prediction of DNA-Binding Proteins using Machine
  Learning&quot;, International Journal on Bioinformatics &amp; Biosciences (IJBB)
  Vol.2, No.2, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  DNA-binding proteins are a class of proteins which have a specific or general
affinity to DNA and include three important components: transcription factors;
nucleases, and histones. DNA-binding proteins also perform important roles in
many types of cellular activities. In this paper we describe machine learning
systems for the prediction of DNA- binding proteins where a Support Vector
Machine and a Cascade Correlation Neural Network are optimized and then
compared to determine the learning algorithm that achieves the best prediction
performance. The information used for classification is derived from
characteristics that include overall charge, patch size and amino acids
composition. In total 121 DNA- binding proteins and 238 non-binding proteins
are used to build and evaluate the system. For SVM using the ANOVA Kernel with
Jack-knife evaluation, an accuracy of 86.7% has been achieved with 91.1% for
sensitivity and 85.3% for specificity. For CCNN optimized over the entire
dataset with Jack knife evaluation we report an accuracy of 75.4%, while the
values of specificity and sensitivity achieved were 72.3% and 82.6%,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2602</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2602</id><created>2012-07-11</created><authors><author><keyname>Mohammadi</keyname><forenames>Seyed Amir</forenames></author><author><keyname>Mahzoun</keyname><forenames>Mohammad Reza</forenames></author></authors><title>A Novel Approach Coloured Object Tracker with Adaptive Model and
  Bandwidth using Mean Shift Algorithm</title><categories>cs.CV</categories><comments>15 pages,7 figures, 2 graph, 1 tabel, journal</comments><journal-ref>Signal &amp; Image Processing : An International Journal(SIPIJ),
  Volume 3, Number 3, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional color-based mean-shift tracking algorithm is popular among
tracking methods due to its simple and efficient procedure, however, the lack
of dynamism in its target model makes it unsuitable for tracking objects which
have changes in their sizes and shapes. In this paper, we propose a fast novel
threephase colored object tracker algorithm based on mean shift idea while
utilizing adaptive model. The proposed method can improve the mentioned
weaknesses of the original mean-shift algorithm. The experimental results show
that the new method is feasible, robust and has acceptable speed in comparison
with other algorithms.15 page,
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2604</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2604</id><created>2012-07-11</created><authors><author><keyname>Wang</keyname><forenames>Yun</forenames></author><author><keyname>Shi</keyname><forenames>Peizhong</forenames></author><author><keyname>Li</keyname><forenames>Kai</forenames></author><author><keyname>Wu</keyname><forenames>Jie</forenames></author></authors><title>DQSB: A Reliable Broadcast Protocol Based on Distributed
  Quasi-Synchronized Mechanism for Low Duty-Cycled Wireless Sensor Networks</title><categories>cs.NI cs.DC</categories><comments>21 pages with 13 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In duty-cycled wireless sensor networks, deployed sensor nodes are usually
put to sleep for energy efficiency according to sleep scheduling approaches.
Any sleep scheduling scheme with its supporting protocols ensures that data can
always be routed from source to sink. In this paper, we investigate a problem
of multi-hop broadcast and routing in random sleep scheduling scheme, and
propose a novel protocol, called DQSB, by quasi-synchronization mechanism to
achieve reliable broadcast and less latency routing. DQSB neither assumes time
synchronization which requires all neighboring nodes wake up at the same time,
nor assumes duty-cycled awareness which makes it difficult to use in
asynchronous WSNs. Furthermore, the benefit of quasi-synchronized mechanism for
broadcast from sink to other nodes is the less latency routing paths for
reverse data collection to sink because of no or less sleep waiting time.
Simulation results show that DQSB outperforms the existing protocols in
broadcast times performance and keeps relative tolerant broadcast latency
performance, even in the case of unreliable links. The proposed DQSB protocol,
in this paper, can be recognized as a tradeoff between broadcast times and
broadcast latency. We also explore the impact of parameters in the assumption
and the approach to get proper values for supporting DQSB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2606</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2606</id><created>2012-07-11</created><authors><author><keyname>Hasni</keyname><forenames>Neji</forenames></author><author><keyname>Bouallegue</keyname><forenames>Ridha</forenames></author></authors><title>Ontology for Mobile Phone Operating Systems</title><categories>cs.SE</categories><comments>13 pages, 14 figures</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  4, No. 3, June 2012</journal-ref><doi>10.5121/ijwmn.2012.4311</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This ongoing study deals with an important part of a line of research that
constitutes a challenging burden. It is an initial investigation into the
development of a Holistic Framework for Cellular Communication (HFCC). The main
purpose is to establish mechanisms by which existing wireless cellular
communication components and models can work holistically together. It
demonstrates that establishing a mathematical framework that allows existing
cellular communication technologies (and tools supporting those technologies)
to seamlessly interact is technically feasible. The longer-term future goals
are to actually improve the interoperability, the efficiency of mobile
communication, calls quality, and reliability by applying the framework to
specific development efforts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2607</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2607</id><created>2012-07-11</created><authors><author><keyname>Chowdhury</keyname><forenames>Prasun</forenames></author><author><keyname>Kundu</keyname><forenames>Anindita</forenames></author><author><keyname>Misra</keyname><forenames>Iti Saha</forenames></author><author><keyname>Sanyal</keyname><forenames>Salil K</forenames></author></authors><title>Load Balancing with Reduced Unnecessary Handoff in Energy Efficient
  Macro/Femto-cell based BWA Networks</title><categories>cs.NI</categories><comments>14 pages</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  4, No. 3, June 2012</journal-ref><doi>10.5121/ijwmn.2012.4307</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hierarchical macro/femto cell based BWA networks are observed to be quite
promising for mobile operators as it improves their network coverage and
capacity at the outskirt of the macro cell. However, this new technology
introduces increased number of macro/femto handoff and wastage of electrical
energy which in turn may affect the system performance. Users moving with high
velocity or undergoing real-time transmission suffers degraded performance due
to huge number of unnecessary macro/femto handoff. On the other hand, huge
amount of electrical energy is wasted when a femto BS is active in the network
but remains unutilized due to low network load. Our proposed energy efficient
handoff decision algorithm eliminates the unnecessary handoff while balancing
the load of the macro and femto cells at minimal energy consumption. The
performance of the proposed algorithm is analyzed using Continuous Time Markov
Chain (CTMC) Model. In addition, we have also contributed a method to determine
the balanced threshold level of the received signal strength (RSS) from macro
base station (BS). The balanced threshold level provides equal load
distribution of the mobile users to the macro and femto BSs. The balanced
threshold level is evaluated based on the distant location of the femto cells
for small scaled networks. Numerical analysis shows that threshold level above
the balanced threshold results in higher load distribution of the mobile users
to the femto BSs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2608</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2608</id><created>2012-07-11</created><updated>2012-07-14</updated><authors><author><keyname>Luo</keyname><forenames>Yaming</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Training Optimization for Energy Harvesting Communication Systems</title><categories>cs.IT math.IT</categories><comments>6 pages, 5 figures, Globecom 2012</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Energy harvesting (EH) has recently emerged as an effective way to solve the
lifetime challenge of wireless sensor networks, as it can continuously harvest
energy from the environment. Unfortunately, it is challenging to guarantee a
satisfactory short-term performance in EH communication systems because the
harvested energy is sporadic. In this paper, we consider the channel training
optimization problem in EH communication systems, i.e., how to obtain accurate
channel state information to improve the communication performance. In contrast
to conventional communication systems, the optimization of the training power
and training period in EH communication systems is a coupled problem, which
makes such optimization very challenging. We shall formulate the optimal
training design problem for EH communication systems, and propose two solutions
that adaptively adjust the training period and power based on either the
instantaneous energy profile or the average energy harvesting rate. Numerical
and simulation results will show that training optimization is important in EH
communication systems. In particular, it will be shown that for short block
lengths, training optimization is critical. In contrast, for long block
lengths, the optimal training period is not too sensitive to the value of the
block length nor to the energy profile. Therefore, a properly selected fixed
training period value can be used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2609</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2609</id><created>2012-07-11</created><authors><author><keyname>Aslam</keyname><forenames>M.</forenames></author><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Rahim</keyname><forenames>A.</forenames></author><author><keyname>Nazir</keyname><forenames>U.</forenames></author><author><keyname>Bibi</keyname><forenames>A.</forenames></author><author><keyname>Khan</keyname><forenames>Z. A.</forenames></author></authors><title>Survey of Extended LEACH-Based Clustering Routing Protocols for Wireless
  Sensor Networks</title><categories>cs.NI</categories><journal-ref>5th AHPCN in conjunction with 14th HPCC-2012, Liverpool, UK</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An energy efficient routing protocol is the major concern in Wireless Sensor
Networks (WSNs). In this survey paper, we present energy efficient hierarchical
routing protocols, developed from conventional LEACH routing protocol. Main
focus of our study is how these extended protocols work in order to increase
the life time and how quality routing protocol are improved for WSNs.
Furthermore, this paper also highlights some of the issues faced by LEACH and
also explains how these issues are tackled by extended versions of LEACH. We
compare the features and performance issues of the selected hierarchal routing
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2615</identifier>
 <datestamp>2013-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2615</id><created>2012-07-11</created><updated>2013-07-18</updated><authors><author><keyname>Bast</keyname><forenames>Hannah</forenames></author><author><keyname>B&#xe4;urle</keyname><forenames>Florian</forenames></author><author><keyname>Buchhold</keyname><forenames>Bj&#xf6;rn</forenames></author><author><keyname>Haussmann</keyname><forenames>Elmar</forenames></author></authors><title>Broccoli: Semantic Full-Text Search at your Fingertips</title><categories>cs.IR</categories><comments>10 pages, 3 figures, 4 tables</comments><acm-class>H.3.1; H.3.3; H.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present Broccoli, a fast and easy-to-use search engine for what we call
semantic full-text search. Semantic full-text search combines the capabilities
of standard full-text search and ontology search. The search operates on four
kinds of objects: ordinary words (e.g., edible), classes (e.g., plants),
instances (e.g., Broccoli), and relations (e.g., occurs-with or native-to).
Queries are trees, where nodes are arbitrary bags of these objects, and arcs
are relations. The user interface guides the user in incrementally constructing
such trees by instant (search-as-you-type) suggestions of words, classes,
instances, or relations that lead to good hits. Both standard full-text search
and pure ontology search are included as special cases. In this paper, we
describe the query language of Broccoli, the main idea behind a new kind of
index that enables fast processing of queries from that language as well as
fast query suggestion, the natural language processing required, and the user
interface. We evaluated query times and result quality on the full version of
the English Wikipedia (40 GB XML dump) combined with the YAGO ontology (26
million facts). We have implemented a fully functional prototype based on our
ideas and provide a web application to reproduce our quality experiments. Both
are accessible via http://broccoli.informatik.uni-freiburg.de/repro-corr/ .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2617</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2617</id><created>2012-07-11</created><authors><author><keyname>Balachandran</keyname><forenames>Nitish</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>A Review of Techniques to Mitigate Sybil Attacks</title><categories>cs.CR</categories><comments>6 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Any decentralised distributed network is particularly vulnerable to the Sybil
attack wherein a malicious node masquerades as several different nodes, called
Sybil nodes, simultaneously in an attempt to disrupt the proper functioning of
the network. Such attacks may cause damage on a fairly large scale especially
since they are difficult to detect and there has been no universally accepted
scheme to counter them as yet. In this paper, we discuss the different kinds of
Sybil attacks including those occurring in peer-to-peer reputation systems,
self-organising networks and even social network systems. In addition, various
methods that have been suggested over time to decrease or eliminate their risk
completely are also analysed along with their modus operandi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2619</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2619</id><created>2012-07-11</created><authors><author><keyname>Al-Debei</keyname><forenames>Mutaz M.</forenames></author><author><keyname>Asswad</keyname><forenames>Mohammad Mourhaf Al</forenames></author><author><keyname>de Cesare</keyname><forenames>Sergio</forenames></author><author><keyname>Lycett</keyname><forenames>Mark</forenames></author></authors><title>Conceptual Modelling and The Quality of Ontologies: Endurantism Vs.
  Perdurantism</title><categories>cs.AI cs.DB</categories><journal-ref>International Journal of Database Management Systems, 4(3), 2012</journal-ref><doi>10.5121/ijdms.2012.4301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontologies are key enablers for sharing precise and machine-understandable
semantics among different applications and parties. Yet, for ontologies to meet
these expectations, their quality must be of a good standard. The quality of an
ontology is strongly based on the design method employed. This paper addresses
the design problems related to the modelling of ontologies, with specific
concentration on the issues related to the quality of the conceptualisations
produced. The paper aims to demonstrate the impact of the modelling paradigm
adopted on the quality of ontological models and, consequently, the potential
impact that such a decision can have in relation to the development of software
applications. To this aim, an ontology that is conceptualised based on the
Object-Role Modelling (ORM) approach (a representative of endurantism) is
re-engineered into a one modelled on the basis of the Object Paradigm (OP) (a
representative of perdurantism). Next, the two ontologies are analytically
compared using the specified criteria. The conducted comparison highlights that
using the OP for ontology conceptualisation can provide more expressive,
reusable, objective and temporal ontologies than those conceptualised on the
basis of the ORM approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2630</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2630</id><created>2012-07-11</created><authors><author><keyname>Srinivasan</keyname><forenames>Sujatha</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Sivakumar</forenames></author></authors><title>Nugget Discovery with a Multi-objective Cultural Algorithm</title><categories>cs.NE</categories><comments>Published in Computer Science and Engineering: An International
  Journal, 15 pages</comments><acm-class>I.5.2; I.2.0</acm-class><journal-ref>Sujatha Srinivasan &amp; Sivakumar Ramakrishnan, NUGGET DISCOVERY WITH
  A MULTI-OBJECTIVE CULTURAL ALGORITHM , Computer Science &amp; Engineering: An
  International Journal (CSEIJ), Vol.2, No.3, June 2012</journal-ref><doi>10.5121/cseij.2012.2302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partial classification popularly known as nugget discovery comes under
descriptive knowledge discovery. It involves mining rules for a target class of
interest. Classification &quot;If-Then&quot; rules are the most sought out by decision
makers since they are the most comprehensible form of knowledge mined by data
mining techniques. The rules have certain properties namely the rule metrics
which are used to evaluate them. Mining rules with user specified properties
can be considered as a multi-objective optimization problem since the rules
have to satisfy more than one property to be used by the user. Cultural
algorithm (CA) with its knowledge sources have been used in solving many
optimization problems. However research gap exists in using cultural algorithm
for multi-objective optimization of rules. In the current study a
multi-objective cultural algorithm is proposed for partial classification.
Results of experiments on benchmark data sets reveal good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2632</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2632</id><created>2012-07-11</created><updated>2012-11-17</updated><authors><author><keyname>Shah</keyname><forenames>Rahul</forenames></author><author><keyname>Sheng</keyname><forenames>Cheng</forenames></author><author><keyname>Thankachan</keyname><forenames>Sharma V.</forenames></author><author><keyname>Vitter</keyname><forenames>Jeffrey Scott</forenames></author></authors><title>On Optimal Top-K String Retrieval</title><categories>cs.DS</categories><comments>3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let ${\cal{D}}$ = $\{d_1, d_2, d_3, ..., d_D\}$ be a given set of $D$
(string) documents of total length $n$. The top-$k$ document retrieval problem
is to index $\cal{D}$ such that when a pattern $P$ of length $p$, and a
parameter $k$ come as a query, the index returns the $k$ most relevant
documents to the pattern $P$. Hon et. al. \cite{HSV09} gave the first linear
space framework to solve this problem in $O(p + k\log k)$ time. This was
improved by Navarro and Nekrich \cite{NN12} to $O(p + k)$. These results are
powerful enough to support arbitrary relevance functions like frequency,
proximity, PageRank, etc. In many applications like desktop or email search,
the data resides on disk and hence disk-bound indexes are needed. Despite of
continued progress on this problem in terms of theoretical, practical and
compression aspects, any non-trivial bounds in external memory model have so
far been elusive. Internal memory (or RAM) solution to this problem decomposes
the problem into $O(p)$ subproblems and thus incurs the additive factor of
$O(p)$. In external memory, these approaches will lead to $O(p)$ I/Os instead
of optimal $O(p/B)$ I/O term where $B$ is the block-size. We re-interpret the
problem independent of $p$, as interval stabbing with priority over tree-shaped
structure. This leads us to a linear space index in external memory supporting
top-$k$ queries (with unsorted outputs) in near optimal $O(p/B + \log_B n +
\log^{(h)} n + k/B)$ I/Os for any constant $h${$\log^{(1)}n =\log n$ and
$\log^{(h)} n = \log (\log^{(h-1)} n)$}. Then we get $O(n\log^*n)$ space index
with optimal $O(p/B+\log_B n + k/B)$ I/Os.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2639</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2639</id><created>2012-07-11</created><authors><author><keyname>Bandal</keyname><forenames>Amol</forenames></author><author><keyname>Nawale</keyname><forenames>Shankar</forenames></author></authors><title>RFID Security Using Lightweight Mutual Authentication And Ownership
  Transfer Protocol</title><categories>cs.CR</categories><comments>published in IJASUC journal</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.3, No.3, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, radio frequency identification technology has moved into the
mainstream applications that help to speed up handling of manufactured goods
and materials. RFID tags are divided into two classes: active and passive.
Active tag requires a power source that's why its cost is more than passive
tags. However, the low-cost RFID tags are facing new challenges to security and
privacy. Some solutions utilize expensive cryptographic primitives such as hash
or encryption functions, and some lightweight approaches have been reported to
be not secure.
  This paper describes a lightweight Mutual authentication and ownership
transfer protocol utilizing minimalistic cryptography using Physically
Unclonable Functions (PUF) and Linear Feedback Shift Registers (LFSR). PUFs and
LFSRs are very efficient in hardware and particularly suitable for the low-cost
RFID tags. To functioning security in low cost RFID tag minimum gate
requirement is 2000 gates. To implement security protocols using PUF and LFSR
functions need only approx 800 gates. In this paper it is explained how we can
authenticate and transfer ownership of low cost RFID tag securely using LFSR
and PUF as compared to existing solutions based on hash functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2641</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2641</id><created>2012-07-11</created><updated>2012-07-12</updated><authors><author><keyname>Baar</keyname><forenames>Teun</forenames></author><author><keyname>van Houten</keyname><forenames>Wiger</forenames></author><author><keyname>Geradts</keyname><forenames>Zeno</forenames></author></authors><title>Camera identification by grouping images from database, based on shared
  noise patterns</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous research showed that camera specific noise patterns, so-called
PRNU-patterns, are extracted from images and related images could be found. In
this particular research the focus is on grouping images from a database, based
on a shared noise pattern as an identification method for cameras. Using the
method as described in this article, groups of images, created using the same
camera, could be linked from a large database of images. Using MATLAB
programming, relevant image noise patterns are extracted from images much
quicker than common methods by the use of faster noise extraction filters and
improvements to reduce the calculation costs. Relating noise patterns, with a
correlation above a certain threshold value, can quickly be matched. Hereby,
from a database of images, groups of relating images could be linked and the
method could be used to scan a large number of images for suspect noise
patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2675</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2675</id><created>2012-07-11</created><authors><author><keyname>Das</keyname><forenames>Tirtha sankar</forenames></author><author><keyname>Sau</keyname><forenames>Ayan K.</forenames></author><author><keyname>Mankar</keyname><forenames>V. H.</forenames></author><author><keyname>Sarkar</keyname><forenames>Subir K.</forenames></author></authors><title>Multimedia Steganographic Scheme using Multiresolution Analysis</title><categories>cs.CR</categories><comments>3rd International Conference on Computers and Devices for
  Communication (CODEC-06) Institute of Radio Physics and Electronics,
  University of Calcutta, December 18-20, 2006</comments><journal-ref>3rd International Conference on Computers and Devices for
  Communication (CODEC-06), Institute of Radio Physics and Electronics,
  University of Calcutta, December 18-20, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital steganography or data hiding has emerged as a new area of research in
connection to the communication in secured channel as well as intellectual
property protection for multimedia signals. The redundancy in image
representation can be exploited successfully to embed specified characteristic
information with a good quality of imperceptibility. The hidden multimedia
information will be communicated to the authentic user through secured channel
as a part of the data. This article deals with a transform domain, block-based
and signal non-adaptive/adaptive technique for inserting multimedia signals
into an RGB image. The robustness of the proposed method has been tested
compared to the other transform domain techniques. Proposed algorithm also
shows improvement in visual and statistical invisibility of the hidden
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2681</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2681</id><created>2012-07-11</created><authors><author><keyname>Lee</keyname><forenames>Kiryung</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author><author><keyname>Junge</keyname><forenames>Marius</forenames></author></authors><title>Oblique Pursuits for Compressed Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing is a new data acquisition paradigm enabling universal,
simple, and reduced-cost acquisition, by exploiting a sparse signal model. Most
notably, recovery of the signal by computationally efficient algorithms is
guaranteed for certain randomized acquisition systems. However, there is a
discrepancy between the theoretical guarantees and practical applications. In
applications, including Fourier imaging in various modalities, the measurements
are acquired by inner products with vectors selected randomly (sampled) from a
frame. Currently available guarantees are derived using a so-called restricted
isometry property (RIP), which has only been shown to hold under ideal
assumptions. For example, the sampling from the frame needs to be independent
and identically distributed with the uniform distribution, and the frame must
be tight. In practice though, one or more of the ideal assumptions is typically
violated and none of the existing guarantees applies.
  Motivated by this discrepancy, we propose two related changes in the existing
framework: (i) a generalized RIP called the restricted biorthogonality property
(RBOP); and (ii) correspondingly modified versions of existing greedy pursuit
algorithms, which we call oblique pursuits. Oblique pursuits are guaranteed
using the RBOP without requiring ideal assumptions; hence, the guarantees apply
to practical acquisition schemes. Numerical results show that oblique pursuits
also perform competitively with, or sometimes better than their conventional
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2683</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2683</id><created>2012-07-11</created><updated>2012-12-17</updated><authors><author><keyname>Houmansadr</keyname><forenames>Amir</forenames></author><author><keyname>Riedl</keyname><forenames>Thomas</forenames></author><author><keyname>Borisov</keyname><forenames>Nikita</forenames></author><author><keyname>Singer</keyname><forenames>Andrew</forenames></author></authors><title>IP over Voice-over-IP for censorship circumvention</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open communication over the Internet poses a serious threat to countries with
repressive regimes, leading them to develop and deploy network-based censorship
mechanisms within their networks. Existing censorship circumvention systems
face different difficulties in providing unobservable communication with their
clients; this limits their availability and poses threats to their users. To
provide the required unobservability, several recent circumvention systems
suggest modifying Internet routers running outside the censored region to
intercept and redirect packets to censored destinations. However, these
approaches require modifications to ISP networks, and hence requires
cooperation from ISP operators and/or network equipment vendors, presenting a
substantial deployment challenge. In this report we propose a deployable and
unobservable censorship-resistant infrastructure, called FreeWave. FreeWave
works by modulating a client's Internet connections into acoustic signals that
are carried over VoIP connections. Such VoIP connections are targeted to a
server, FreeWave server, that extracts the tunneled traffic of clients and
proxies them to the uncensored Internet. The use of actual VoIP connections, as
opposed to traffic morphing, allows FreeWave to relay its VoIP connections
through oblivious VoIP nodes, hence keeping itself unblockable from censors
that perform IP address blocking. Also, the use of end-to-end encryption
prevents censors from identifying FreeWave's VoIP connections using packet
content filtering technologies, like deep-packet inspection. We prototype the
designed FreeWave system over the popular VoIP system of Skype. We show that
FreeWave is able to reliably achieve communication bandwidths that are
sufficient for web browsing, even when clients are far distanced from the
FreeWave server.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2687</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2687</id><created>2012-07-11</created><authors><author><keyname>Das</keyname><forenames>T. S.</forenames></author><author><keyname>Mankar</keyname><forenames>V. H.</forenames></author><author><keyname>Sarkar</keyname><forenames>S. K.</forenames></author></authors><title>Performance Evaluation of Spread Spectrum Watermarking using Error
  Control Coding</title><categories>cs.CR</categories><comments>IET-UK International Conference on Information and Communication
  Technology in Electrical Sciences (ICTES 2007), Dr. M.G.R. University,
  Chennai, Tamil Nadu, India. Dec. 20-22, 2007. pp. 708-711</comments><journal-ref>IET-UK International Conference on Information and Communication
  Technology in Electrical Sciences (ICTES 2007), Dr. M.G.R. University,
  Chennai, Tamil Nadu, India. Dec. 20-22, 2007. pp. 708-711</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an oblivious watermarking algorithm with blind detection
approach for high volume data hiding in image signals. We present a detection
reliable signal adaptive embedding scheme for multiple messages in selective
sub-bands of wavelet (DWT) coefficients using direct sequence spread spectrum
(DS-SS) modulation technique. Here the impact of volumetric distortion sources
is analyzed on the ability of analytical bounds in order to recover the
watermark messages. In this context, the joint source-channel coding scheme has
been employed to obtain the better control of the system robustness. This
structure prevents the desynchronisation between encoder and decoder due to
selective embedding. The experimental results obtained for Spread Spectrum (SS)
transformed domain watermarking demonstrate the efficiency of the proposed
system. This algorithmic architecture utilizes the existing allocated bandwidth
in the data transmission channel in a more efficient manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2694</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2694</id><created>2012-07-11</created><authors><author><keyname>Mankar</keyname><forenames>V. H.</forenames></author><author><keyname>Das</keyname><forenames>T. S.</forenames></author><author><keyname>Sarkar</keyname><forenames>S. K.</forenames></author></authors><title>Discrete Chaotic Sequence based on Logistic Map in Digital
  Communications</title><categories>cs.DM nlin.CD</categories><comments>National Conference on &quot;Emerging Trends in Electronics Engineering &amp;
  Computing&quot; (E3C 2010)</comments><journal-ref>National Conference on &quot;Emerging Trends in Electronics Engineering
  &amp; Computing&quot; (E3C 2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The chaotic systems have been found applications in diverse fields such as
pseudo random number generator, coding, cryptography, spread spectrum (SS)
communications etc. The inherent capability of generating a large space of PN
sequences due to sensitive dependence on initial conditions has been the main
reason for exploiting chaos in spread spectrum communication systems. This
behaviour suggests that it is straightforward to generate a variety of initial
condition induced PN sequences with nice statistical properties by quantising
the output of an iterated chaotic map. In the present paper the study has been
carried out for the feasibility and usefulness of chaotic sequence in SS based
applications like communication and watermarking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2697</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2697</id><created>2012-07-11</created><authors><author><keyname>lejdel</keyname><forenames>Brahim</forenames></author><author><keyname>kazar</keyname><forenames>Okba</forenames></author></authors><title>Genetic agent approach for improving on-the-fly web map generalization</title><categories>cs.MA cs.CG cs.NE</categories><comments>10 pages, 07 figures, International Journal of Information Technology
  Convergence and Services (IJITCS) Vol.2, No.3, June 2012</comments><journal-ref>ISSN :2231 - 1939</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The utilization of web mapping becomes increasingly important in the domain
of cartography. Users want access to spatial data on the web specific to their
needs. For this reason, different approaches were appeared for generating
on-the-fly the maps demanded by users, but those not suffice for guide a
flexible and efficient process. Thus, new approach must be developed for
improving this process according to the user needs. This work focuses on
defining a new strategy which improves on-the-fly map generalization process
and resolves the spatial conflicts. This approach uses the multiple
representation and cartographic generalization. The map generalization process
is based on the implementation of multi- agent system where each agent was
equipped with a genetic patrimony.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2699</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2699</id><created>2012-07-11</created><authors><author><keyname>Mankar</keyname><forenames>V. H.</forenames></author><author><keyname>Das</keyname><forenames>T. S.</forenames></author><author><keyname>Saha</keyname><forenames>S.</forenames></author><author><keyname>Sarkar</keyname><forenames>S. K.</forenames></author></authors><title>Robust Image Watermarking Under Pixel Wise Masking Framework</title><categories>cs.CR</categories><comments>First International Conference on Emerging Trends in Engineering and
  Technology ICETET 2008</comments><doi>10.1109/ICETET.2008.51</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current paper presents a robust watermarking method for still images,
which uses the similarity of discrete wavelet transform and human visual system
(HVS). The proposed scheme makes the use of pixel wise masking in order to make
binary watermark imperceptible to the HVS. The watermark is embedded in the
perceptually significant, spatially selected detail coefficients using sub band
adaptive threshold scheme. The threshold is computed based on the statistical
analysis of the wavelet coefficients. The watermark is embedded several times
to achieve better robustness. Here, a new type of non-oblivious detection
method is proposed. The improvement in robustness performance against different
types of deliberate and non-intentional image impairments (lossy compression,
scaling, cropping, filtering etc) is supported through experimental results.
The reported result also shows improvement in visual and statistical
invisibility of the hidden data. The proposed method is compared with a state
of the art frequency based watermarking technique, highlighting its
performance. This algorithmic architecture utilizes the existing allocated
bandwidth in the data transmission channel in a more efficient manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2701</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2701</id><created>2012-07-11</created><authors><author><keyname>Das</keyname><forenames>T. S.</forenames></author><author><keyname>Mankar</keyname><forenames>V. H.</forenames></author><author><keyname>Sarkar</keyname><forenames>S. K.</forenames></author></authors><title>Spread Spectrum based Robust Image Watermark Authentication</title><categories>cs.CR</categories><comments>ICACC 2007 International Conference, Madurai, India, 9-10 Feb, 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new approach to Spread Spectrum (SS) watermarking technique
is introduced. This problem is particularly interesting in the field of modern
multimedia applications like internet when copyright protection of digital
image is required. The approach exploits two-predecessor single attractor
(TPSA) cellular automata (CA) suitability to work as efficient authentication
function in wavelet based SS watermarking domain. The scheme is designed from
the analytical study of state transition behaviour of non-group CA and the
basic cryptography/encryption scheme is significantly different from the
conventional SS data hiding approaches. Experimental studies confirm that the
scheme is robust in terms of confidentiality, authentication, non-repudiation
and integrity. The transform domain blind watermarking technique offers better
visual &amp; statistical imperceptibility and resiliency against different types of
intentional &amp; unintentional image degradations. Interleaving and interference
cancellation methods are employed to improve the robustness performance
significantly compared to conventional matched filter detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2704</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2704</id><created>2012-07-11</created><authors><author><keyname>Raj</keyname><forenames>Gaurav</forenames></author><author><keyname>Nischal</keyname><forenames>Ankit</forenames></author></authors><title>Efficient Resource Allocation in Resource provisioning policies over
  Resource Cloud Communication Paradigm</title><categories>cs.DC</categories><comments>8 pages, 4 Figures, International Journal on Cloud Computing:
  Services and Architecture(IJCCSA),Vol.2, No.3, June 2012</comments><doi>10.5121/ijccsa.2012.2302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal resource utilization for executing tasks within the cloud is one of
the biggest challenges. In executing the task over a cloud, the resource
provisioner is responsible for providing the resources to create virtual
machines. To utilize the resources optimally, the resource provisioner has to
take care of the process of allocating resources to Virtual Machine Manager
(VMM). In this paper, an efficient way to utilize the resources, within the
cloud, to create virtual machines has been proposed considering optimum cost
based on performance factor. This performance factor depends upon the overall
cost of the resource, communication channel cost, reliability and popularity
factor. We have proposed a framework for communication between resource owner
and cloud using Resource Cloud Communication Paradigm (RCCP). We extend the
CloudSim[2] adding provisioner policies and Efficient Resource Allocation (ERA)
algorithm in VMM allocation policy as a decision support for resource
provisioner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2706</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2706</id><created>2012-07-11</created><authors><author><keyname>Raj</keyname><forenames>Gaurav</forenames></author><author><keyname>Kaur</keyname><forenames>Kamaljit</forenames></author></authors><title>Secure Cloud Communication for Effective Cost Management System through
  MSBE</title><categories>cs.DC</categories><comments>12 pages, 3 figures, International Journal on Cloud Computing:
  Services and Architecture(IJCCSA),Vol.2, No.3, June 2012</comments><doi>10.5121/ijccsa.2012.2303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Cloud Computing Architecture, Brokers are responsible to provide services
to the end users. An Effective Cost Management System (ECMS) which works over
Secure Cloud Communication Paradigm (SCCP) helps in finding a communication
link with overall minimum cost of links. We propose an improved Broker Cloud
Communication Paradigm (BCCP) with integration of security issues. Two
algorithms are included, first is Secure Optimized Route Cost Finder (S-ORCF)
to find optimum route between broker and cloud on the behalf of cost factor and
second is Secure Optimized Route Management (S-ORM) to maintain optimum route.
These algorithms proposed with cryptographic integrity of the secure route
discovery process in efficient routing approaches between broker and cloud.
There is lack in Dynamic Source Routing Approach to verify whether any
intermediate node has been deleted, inserted or modified with no valid
authentication. We use symmetric cryptographic primitives, which is made
possible due to multisource broadcast encryption scheme. This paper outlines
the use of secure route discovery protocol (SRDP)that employs such a security
paradigm in cloud computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2708</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2708</id><created>2012-07-11</created><authors><author><keyname>Raj</keyname><forenames>Gaurav</forenames></author><author><keyname>Setia</keyname><forenames>Sonika</forenames></author></authors><title>Effective Cost Mechanism for Cloudlet Retransmission and Prioritized VM
  Scheduling Mechanism over Broker Virtual Machine Communication Framework</title><categories>cs.DC</categories><comments>10 pages, 5 figures, International Journal on Cloud Computing:
  Services and Architecture(IJCCSA),Vol.2, No.3, June 2012</comments><doi>10.5121/ijccsa.2012.2305</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In current scenario cloud computing is most widely increasing platform for
task execution. Lot of research is going on to cut down the cost and execution
time. In this paper, we propose an efficient algorithm to have an effective and
fast execution of task assigned by the user. We proposed an effective
communication framework between broker and virtual machine for assigning the
task and fetching the results in optimum time and cost using Broker Virtual
Machine Communication Framework (BVCF). We implement it over cloudsim under VM
scheduling policies by modification based on Virtual Machine Cost. Scheduling
over Virtual Machine as well as over Cloudlets and Retransmission of Cloudlets
are the basic building blocks of the proposed work on which the whole
architecture is dependent. Execution of cloudlets is being analyzed over Round
Robin and FCFS scheduling policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2711</identifier>
 <datestamp>2013-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2711</id><created>2012-07-11</created><updated>2012-08-19</updated><authors><author><keyname>Torrieri</keyname><forenames>Don</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author></authors><title>The Outage Probability of a Finite Ad Hoc Network in Nakagami Fading</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Communications</comments><journal-ref>IEEE Transactions on Communications, vol. 60, no. 11, pp.
  3509-3518, Nov. 2012</journal-ref><doi>10.1109/TCOMM.2012.081512.110530</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An ad hoc network with a finite spatial extent and number of nodes or mobiles
is analyzed. The mobile locations may be drawn from any spatial distribution,
and interference-avoidance protocols or protection against physical collisions
among the mobiles may be modeled by placing an exclusion zone around each
radio. The channel model accounts for the path loss, Nakagami fading, and
shadowing of each received signal. The Nakagami m-parameter can vary among the
mobiles, taking any positive value for each of the interference signals and any
positive integer value for the desired signal. The analysis is governed by a
new exact expression for the outage probability, defined to be the probability
that the signal-to-interference-and-noise ratio (SINR) drops below a threshold,
and is conditioned on the network geometry and shadowing factors, which have
dynamics over much slower timescales than the fading. By averaging over many
network and shadowing realizations, the average outage probability and
transmission capacity are computed. Using the analysis, many aspects of the
network performance are illuminated. For example, one can determine the
influence of the choice of spreading factors, the effect of the receiver
location within the finite network region, and the impact of both the fading
parameters and the attenuation power laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2714</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2714</id><created>2012-07-11</created><authors><author><keyname>Mohamed</keyname><forenames>Mohamed Achraf Ben</forenames></author><author><keyname>Zrigui</keyname><forenames>Mounir</forenames></author><author><keyname>Maraoui</keyname><forenames>Mohsen</forenames></author></authors><title>Clustering based approach extracting collocations</title><categories>cs.CL</categories><journal-ref>4th International Conference on Arabic Language Processing. CITALA
  2012. May 2nd -- 3rd 2012, Rabat, Morocco</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following study presents a collocation extraction approach based on
clustering technique. This study uses a combination of several classical
measures which cover all aspects of a given corpus then it suggests separating
bigrams found in the corpus in several disjoint groups according to the
probability of presence of collocations. This will allow excluding groups where
the presence of collocations is very unlikely and thus reducing in a meaningful
way the search space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2718</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2718</id><created>2012-07-11</created><authors><author><keyname>Singh</keyname><forenames>Roopa</forenames></author><author><keyname>Khan</keyname><forenames>Imran Akhtar</forenames></author></authors><title>An Approach For Integration Testing In Online Retail Applications</title><categories>cs.SE</categories><comments>18 pages</comments><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT) Vol 4, No 3, June 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retail applications has majorly fraud prevention, procurement, shipping and
tax related, pricing, real time bank authentication applications integrated to
make the application run successfully. Integration testing here plays an
important role as it requires that all applications interact with each other
and also interact correctly so that Retailer is at benefit. Different testing
techniques and types are used to test the application. Different testing teams
will perform integration testing but what is the correct approach and how
should you proceed is the major concern of many. Here we propose at what stage
of Software Testing Life Cycle (STLC), integration testing should be initiated.
Also what should be the approach of performing the testing? An example on
Online Retail Application is used to understand the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2732</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2732</id><created>2012-07-11</created><updated>2012-09-11</updated><authors><author><keyname>Kurz</keyname><forenames>Alexander</forenames><affiliation>University of Leicester</affiliation></author><author><keyname>Rosicky</keyname><forenames>Jiri</forenames><affiliation>Masaryk University, Brno, Czech Republic</affiliation></author></authors><title>Strongly Complete Logics for Coalgebras</title><categories>cs.LO math.CT</categories><proxy>LMCS</proxy><acm-class>F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 3 (September
  12, 2012) lmcs:1231</journal-ref><doi>10.2168/LMCS-8(3:14)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalgebras for a functor model different types of transition systems in a
uniform way. This paper focuses on a uniform account of finitary logics for
set-based coalgebras. In particular, a general construction of a logic from an
arbitrary set-functor is given and proven to be strongly complete under
additional assumptions. We proceed in three parts. Part I argues that sifted
colimit preserving functors are those functors that preserve universal
algebraic structure. Our main theorem here states that a functor preserves
sifted colimits if and only if it has a finitary presentation by operations and
equations. Moreover, the presentation of the category of algebras for the
functor is obtained compositionally from the presentations of the underlying
category and of the functor. Part II investigates algebras for a functor over
ind-completions and extends the theorem of J{\'o}nsson and Tarski on canonical
extensions of Boolean algebras with operators to this setting. Part III shows,
based on Part I, how to associate a finitary logic to any finite-sets
preserving functor T. Based on Part II we prove the logic to be strongly
complete under a reasonable condition on T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2734</identifier>
 <datestamp>2013-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2734</id><created>2012-07-11</created><updated>2013-01-27</updated><authors><author><keyname>Lobillo</keyname><forenames>F. J.</forenames></author><author><keyname>Navarro</keyname><forenames>Gabriel</forenames></author><author><keyname>G&#xf3;mez-Torrecillas</keyname><forenames>Jos&#xe9;</forenames></author></authors><title>Information-bit error rate and false positives in an MDS code</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a refinement of the weight distribution in an MDS code is
computed. Concretely, the number of codewords with a fixed amount of nonzero
bits in both information and redundancy parts is obtained. This refinement
improves the theoretical approximation of the information-bit and -symbol error
rate, in terms of the channel bit-error rate, in a block transmission through a
discrete memoryless channel. Since a bounded distance reproducing encoder is
assumed, the computation of the here-called false positive (a decoding failure
with no information-symbol error) is provided. As a consequence, a new
performance analysis of an MDS code is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2736</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2736</id><created>2012-07-10</created><authors><author><keyname>Pardo</keyname><forenames>Ra&#xfa;l</forenames></author><author><keyname>Pelayo</keyname><forenames>Fernando L.</forenames></author></authors><title>ROSA Analyser: An automatized approach to analyse processes of ROSA</title><categories>cs.SE</categories><comments>In Proceedings WS-FMDS 2012, arXiv:1207.1841. Formal model's tool</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 86, 2012, pp. 25-32</journal-ref><doi>10.4204/EPTCS.86.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present the first version of ROSA Analyser, a tool designed
to get closer to a fully automatic process of analysing the behaviour of a
system specified as a process of the Markovian Process Algebra ROSA. In this
first development stage, ROSA Analyser is able to generate the Labelled
Transition System, according to ROSA Operational Semantics.
  ROSA Analyser performance starts with the Syntactic Analysis so generating a
layered structure, suitable to then, apply the Operational Semantics Transition
rules in the easier way. ROSA Analyser is able to recognize some states
identities deeper than the Syntactic ones. This is the very first step in the
way to reduce the size of the LTS and then to avoid the state explosion
problem, so making this task more tractable.
  For the sake of better illustrating the usefulness of ROSA Analyser, a case
study is also provided within this work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2738</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2738</id><created>2012-07-10</created><authors><author><keyname>Mrozek</keyname><forenames>Zbigniew</forenames></author></authors><title>Quality assurance of e-learning processes</title><categories>cs.CY</categories><comments>22-nd EAEEIE Annual Conference, EAEEIE 2011, Maribor, Slovenia, June
  13-15, 2011, Includes 4 pages, 5 figures, 19 citations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A quality assurance system (QA) should ensure that student needs are met. It
also respects accreditation requirements and student perceptions, supports
training and development of teaching staff, controls costs and improves
efficiency of e-learning system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2739</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2739</id><created>2012-07-11</created><authors><author><keyname>Singh</keyname><forenames>N. Monoranjan</forenames></author><author><keyname>Sarma</keyname><forenames>K. C.</forenames></author></authors><title>Low Cost PC Based Real Time Data Logging System Using PCs Parallel Port
  For Slowly Varying Signals</title><categories>cs.AR</categories><comments>Published in the Journal of Assam Science Society, December 2009</comments><journal-ref>J. Assam Sc. Soc. Vol. 50; No. 1,2; 36-41; December 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A low cost PC based real time data logging system can be used in the
laboratories for the measurement, monitoring and storage of the data for slowly
varying signals in science and engineering stream. This can be designed and
interfaced to the PCs Parallel Port, which is common to all desktop computers
or Personal Computers (PCs). By the use of this data logging system one can
monitor, measure and store data for slowly varying signals, which is hard to
visualise the signal waveforms by ordinary CRO (Cathode Ray Oscilloscope) and
DSO (Digital Storage Oscilloscope). The data so stored can be used for further
study and analysis. It can be used for a wide range of applications to monitor
and store data of temperature, humidity, light intensity, ECG signals etc. with
proper signal conditioning circuitry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2741</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2741</id><created>2012-07-10</created><authors><author><keyname>Vyas</keyname><forenames>Shilpan</forenames></author></authors><title>E-banking and E-commerce in India and USA</title><categories>cs.CY</categories><comments>E-commerce and E-banking, Diffusion of Innovation theory, Hofstede's
  dimensions</comments><journal-ref>Published in IJCSI Journal, Volume 9, Issue 3, No 2, May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web based e-banking is becoming an important aspect of worldwide commerce.
The United Nations predicts 17% of purchases by firms and individuals will be
conducted online by 2006. The future of Web-based e-banking in developed areas
appears bright but consumers and merchants in developing countries face in
number of barriers to successful e-banking, including less reliable
telecommunications infrastructure and power supplies, less access to online
payment mechanisms, and relatively high costs for personal computers and
Internet access. How should managers in charge of e-banking prepare for global
implementation? What can they do reach consumers in developing countries? What
factors influence the adoption of consumer-oriented e-banking in various
countries? This research paper will give you the idea on the local conditions
in India, the Hofstede's dimension of culture in India and USA, the Diffusion
of Innovation theory and hence the hypotheses for the innovation
characteristics of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2742</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2742</id><created>2012-07-11</created><authors><author><keyname>Chakir</keyname><forenames>Boutaina</forenames></author><author><keyname>Fredj</keyname><forenames>Mounia</forenames></author><author><keyname>Nassar</keyname><forenames>Mahmoud</forenames></author></authors><title>A model driven method for promoting reuse in SOA-solutions by managing
  variability</title><categories>cs.SE</categories><comments>11 pages, 17 figures</comments><acm-class>D.2.1; D.2.2; D.2.9; D.2.10; D.2.13; D.3.2; D.3.3</acm-class><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 9,
  Issue 3, No 3, May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service Oriented Architecture (SOA) is an architectural paradigm that
describes how organizations, people and systems provide and use services to
achieve their goals and enhance productivity. Moreover, with the evolution of
SOA, the focus in software development has shifted from applications to
reusable services. However, the reuse in SOA is more seen as composition of
fine-grained services rather than reuse of services implementation to build new
services with additional functionalities. This can have some performance
repercussions. Hence, in this paper, we propose a model driven method for
managing Web service's variability based on MDA (Model Driven Architecture) as
a way to promote reuse. In fact, through MDA, the method enables the automation
of Web service's realization regardless of the supported platforms. Moreover,
we present a WSDL extension meta-model called VarWSDL which enhances Web
services by variability notions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2743</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2743</id><created>2012-07-11</created><updated>2013-06-18</updated><authors><author><keyname>Clune</keyname><forenames>Jeff</forenames></author><author><keyname>Mouret</keyname><forenames>Jean-Baptiste</forenames></author><author><keyname>Lipson</keyname><forenames>Hod</forenames></author></authors><title>The evolutionary origins of modularity</title><categories>q-bio.PE cs.NE q-bio.MN q-bio.NC</categories><journal-ref>Clune J, Mouret J-B, Lipson H. 2013 The evolutionary origins of
  modularity. Proceedings of the Royal Society B. 280: 20122863</journal-ref><doi>10.1098/rspb.2012.2863</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A central biological question is how natural organisms are so evolvable
(capable of quickly adapting to new environments). A key driver of evolvability
is the widespread modularity of biological networks--their organization as
functional, sparsely connected subunits--but there is no consensus regarding
why modularity itself evolved. While most hypotheses assume indirect selection
for evolvability, here we demonstrate that the ubiquitous, direct selection
pressure to reduce the cost of connections between network nodes causes the
emergence of modular networks. Experiments with selection pressures to maximize
network performance and minimize connection costs yield networks that are
significantly more modular and more evolvable than control experiments that
only select for performance. These results will catalyze research in numerous
disciplines, including neuroscience, genetics and harnessing evolution for
engineering purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2746</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2746</id><created>2012-07-07</created><updated>2015-06-25</updated><authors><author><keyname>Cunha</keyname><forenames>Alcino</forenames><affiliation>HASlab / INESC TEC and Universidade do Minho</affiliation></author></authors><title>Bounded Model Checking of Temporal Formulas with Alloy</title><categories>cs.SE cs.LO</categories><comments>New version of the ABZ'14 paper that corrects a mistake in the
  encoding of the the U and R temporal operators</comments><acm-class>D.2.4; F.3.1; F.4.3; I.6.4; I.6.5</acm-class><doi>10.1007/978-3-662-43652-3_29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alloy is formal modeling language based on first-order relational logic, with
no specific support for specifying reactive systems. We propose the usage of
temporal logic to specify such systems, and show how bounded model checking can
be performed with the Alloy Analyzer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2754</identifier>
 <datestamp>2012-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2754</id><created>2012-07-08</created><authors><author><keyname>Mazzara</keyname><forenames>Manuel</forenames></author></authors><title>On Methods for the Formal Specification of Fault Tolerant Systems</title><categories>cs.SE cs.FL</categories><comments>Presented and published at DEPEND 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces different views for understanding problems and faults
with the goal of defining a method for the formal specification of systems. The
idea of Layered Fault Tolerant Specification (LFTS) is proposed to make the
method extensible to fault tolerant systems. The principle is layering the
specification in different levels, the first one for the normal behavior and
the others for the abnormal. The abnormal behavior is described in terms of an
Error Injector (EI), which represents a model of the erroneous interference
coming from the environment. This structure has been inspired by the notion of
idealized fault tolerant component but the combination of LFTS and EI using
Rely/Guarantee reasoning to describe their interaction can be considered as a
novel contribution. The progress toward this method and this way to organize
fault tolerant specifications has been made experimenting on case studies and
an example is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2761</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2761</id><created>2012-07-11</created><authors><author><keyname>Yang</keyname><forenames>Daiqin</forenames></author><author><keyname>Zhao</keyname><forenames>Fang</forenames></author><author><keyname>Liu</keyname><forenames>Kai</forenames></author><author><keyname>Lim</keyname><forenames>Hock Beng</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author><author><keyname>Rus</keyname><forenames>Daniela</forenames></author></authors><title>A GPS Pseudorange Based Cooperative Vehicular Distance Measurement
  Technique</title><categories>cs.AI cs.RO</categories><comments>Proc. of the 75th IEEE Vehicular Technology Conference (IEEE
  VTC'12-Spring), Yokohama, Japan, May 6-9, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate vehicular localization is important for various cooperative vehicle
safety (CVS) applications such as collision avoidance, turning assistant, etc.
In this paper, we propose a cooperative vehicular distance measurement
technique based on the sharing of GPS pseudorange measurements and a weighted
least squares method. The classic double difference pseudorange solution, which
was originally designed for high-end survey level GPS systems, is adapted to
low-end navigation level GPS receivers for its wide availability in ground
vehicles. The Carrier to Noise Ratio (CNR) of raw pseudorange measurements are
taken into account for noise mitigation. We present a Dedicated Short Range
Communications (DSRC) based mechanism to implement the exchange of pseudorange
information among neighboring vehicles. As demonstrated in field tests, our
proposed technique increases the accuracy of the distance measurement
significantly compared with the distance obtained from the GPS fixes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2776</identifier>
 <datestamp>2014-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2776</id><created>2012-07-11</created><updated>2014-07-24</updated><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Kountouris</keyname><forenames>Marios</forenames></author><author><keyname>Bengtsson</keyname><forenames>Mats</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Receive Combining vs. Multi-Stream Multiplexing in Downlink Systems with
  Multi-Antenna Users</title><categories>cs.IT math.IT</categories><comments>Published in IEEE Transactions on Signal Processing, 16 pages, 11
  figures. The results can be reproduced using the following Matlab code:
  https://github.com/emilbjornson/one-or-multiple-streams</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 61, no. 13, pp.
  3431-3446, July 2013</journal-ref><doi>10.1109/TSP.2013.2260331</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In downlink multi-antenna systems with many users, the multiplexing gain is
strictly limited by the number of transmit antennas $N$ and the use of these
antennas. Assuming that the total number of receive antennas at the
multi-antenna users is much larger than $N$, the maximal multiplexing gain can
be achieved with many different transmission/reception strategies. For example,
the excess number of receive antennas can be utilized to schedule users with
effective channels that are near-orthogonal, for multi-stream multiplexing to
users with well-conditioned channels, and/or to enable interference-aware
receive combining. In this paper, we try to answer the question if the $N$ data
streams should be divided among few users (many streams per user) or many users
(few streams per user, enabling receive combining). Analytic results are
derived to show how user selection, spatial correlation, heterogeneous user
conditions, and imperfect channel acquisition (quantization or estimation
errors) affect the performance when sending the maximal number of streams or
one stream per scheduled user---the two extremes in data stream allocation.
  While contradicting observations on this topic have been reported in prior
works, we show that selecting many users and allocating one stream per user
(i.e., exploiting receive combining) is the best candidate under realistic
conditions. This is explained by the provably stronger resilience towards
spatial correlation and the larger benefit from multi-user diversity. This
fundamental result has positive implications for the design of downlink systems
as it reduces the hardware requirements at the user devices and simplifies the
throughput optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2788</identifier>
 <datestamp>2013-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2788</id><created>2012-07-11</created><updated>2012-12-03</updated><authors><author><keyname>Gomez</keyname><forenames>Sergio</forenames></author><author><keyname>Diaz-Guilera</keyname><forenames>Albert</forenames></author><author><keyname>Gomez-Garde&#xf1;es</keyname><forenames>Jesus</forenames></author><author><keyname>Perez-Vicente</keyname><forenames>Conrad J.</forenames></author><author><keyname>Moreno</keyname><forenames>Yamir</forenames></author><author><keyname>Arenas</keyname><forenames>Alex</forenames></author></authors><title>Diffusion dynamics on multiplex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>6 Pages including supplemental material. To appear in Physical Review
  Letters</comments><journal-ref>Physical Review Letters 110 (2013) 028701</journal-ref><doi>10.1103/PhysRevLett.110.028701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the time scales associated to diffusion processes that take place on
multiplex networks, i.e. on a set of networks linked through interconnected
layers. To this end, we propose the construction of a supra-Laplacian matrix,
which consists of a dimensional lifting of the Laplacian matrix of each layer
of the multiplex network. We use perturbative analysis to reveal analytically
the structure of eigenvectors and eigenvalues of the complete network in terms
of the spectral properties of the individual layers. The spectrum of the
supra-Laplacian allows us to understand the physics of diffusion-like processes
on top of multiplex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2793</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2793</id><created>2012-07-11</created><authors><author><keyname>Ahmadi</keyname><forenames>Behzad</forenames></author><author><keyname>Choudhuri</keyname><forenames>Chiranjib</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Cascade Source Coding with a Side Information &quot;Vending Machine&quot;</title><categories>cs.IT math.IT</categories><comments>A shorter version has been submitted to ITW 2012 and is available
  online at arXiv:1204.1548</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The model of a side information &quot;vending machine&quot; (VM) accounts for scenarios
in which the measurement of side information sequences can be controlled via
the selection of cost-constrained actions. In this paper, the three-node
cascade source coding problem is studied under the assumption that a side
information VM is available and the intermediate and/or at the end node of the
cascade. A single-letter characterization of the achievable trade-off among the
transmission rates, the distortions in the reconstructions at the intermediate
and at the end node, and the cost for acquiring the side information is derived
for a number of relevant special cases. It is shown that a joint design of the
description of the source and of the control signals used to guide the
selection of the actions at downstream nodes is generally necessary for an
efficient use of the available communication links. In particular, for all the
considered models, layered coding strategies prove to be optimal, whereby the
base layer fulfills two network objectives: determining the actions of
downstream nodes and simultaneously providing a coarse description of the
source. Design of the optimal coding strategy is shown via examples to depend
on both the network topology and the action costs. Examples also illustrate the
involved performance trade-offs across the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2799</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2799</id><created>2012-07-11</created><authors><author><keyname>Gutfraind</keyname><forenames>Alexander</forenames></author><author><keyname>Bradonji&#x107;</keyname><forenames>Milan</forenames></author><author><keyname>Novikoff</keyname><forenames>Tim</forenames></author></authors><title>Optimal recovery of damaged infrastructure network</title><categories>math.OC cs.DM</categories><comments>In review with Optimization Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural disasters or attacks may disrupt infrastructure networks on a vast
scale. Parts of the damaged network are interdependent, making it difficult to
plan and optimally execute the recovery operations. To study how
interdependencies affect the recovery schedule, we introduce a new discrete
optimization problem where the goal is to minimize the total cost of installing
(or recovering) a given network. This cost is determined by the structure of
the network and the sequence in which the nodes are installed. Namely, the cost
of installing a node is a function of the number of its neighbors that have
been installed before it. We analyze the natural case where the cost function
is decreasing and convex, and provide bounds on the cost of the optimal
solution. We also show that all sequences have the same cost when the cost
function is linear and provide an upper bound on the cost of a random solution
for an Erd\H{o}s-R\'enyi random graph. Examining the computational complexity,
we show that the problem is NP-hard when the cost function is arbitrary.
Finally, we provide a formulation as an integer program, an exact dynamic
programming algorithm, and a greedy heuristic which gives high quality
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2802</identifier>
 <datestamp>2015-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2802</id><created>2012-07-11</created><updated>2012-12-02</updated><authors><author><keyname>Zhong</keyname><forenames>Li-Xin</forenames></author><author><keyname>Xu</keyname><forenames>Wen-Juan</forenames></author><author><keyname>Shi</keyname><forenames>Yong-Dong</forenames></author><author><keyname>Qiu</keyname><forenames>Tian</forenames></author></authors><title>Coupled dynamics of mobility and pattern formation in optional public
  goods games</title><categories>physics.soc-ph cs.SI</categories><doi>10.1016/j.chaos.2012.11.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a static environment, optional participation and a local agglomeration of
cooperators are found to be beneficial for the occurrence and maintenance of
cooperation. In the optional public goods game, the rock-scissors-paper cycles
of different strategies yield oscillatory cooperation but not stable
cooperation. In this paper, by incorporating population density and individual
mobility into the spatial optional public goods game, we study the
coevolutionary dynamics of strategy updating and benefit-seeking migration.
With low population density and slow movement, an optimal level of cooperation
is easy to be reached. An increase in population density and speed-up of
free-floating of competitive agents will suppress cooperation. A log-log
relation between the levels of cooperation and the free-floating probability is
found. Theoretical analysis indicates that the decrease of cooperator frequency
in the present model should result from the increased interactions between
different agents, which may originate from the increased cluster size or the
speed-up of random-movement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2807</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2807</id><created>2012-07-11</created><updated>2012-07-19</updated><authors><author><keyname>Goudarzi</keyname><forenames>Hadi</forenames></author><author><keyname>Pakravan</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Practical Power Allocation and Greedy Partner Selection for Cooperative
  Networks</title><categories>cs.SY cs.IT math.IT</categories><comments>6 pages; IFIP wireless days conference 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel algorithm for power allocation in the
Amplify-and-Forward cooperative communication that minimizes the outage
probability with a given value of total power. We present the problem with new
formulation and solve the optimal power allocation for a fixed set of partners.
The proposed solution provides a direct power allocation scheme with a simple
formula that can be also be represented by a simple lookup table which makes it
easy for practical implementation. We present simulation results to demonstrate
that the performances of the proposed algorithms are very close to results of
the previously published iterative optimal power allocation algorithms. We also
consider the issue of partner selection in a cooperative network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2812</identifier>
 <datestamp>2013-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2812</id><created>2012-07-11</created><updated>2013-08-07</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author><author><keyname>Sinha</keyname><forenames>Kaushik</forenames></author></authors><title>Near-Optimal Algorithms for Differentially-Private Principal Components</title><categories>stat.ML cs.CR cs.LG</categories><comments>37 pages, 8 figures; final version to appear in the Journal of
  Machine Learning Research, preliminary version was at NIPS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Principal components analysis (PCA) is a standard tool for identifying good
low-dimensional approximations to data in high dimension. Many data sets of
interest contain private or sensitive information about individuals. Algorithms
which operate on such data should be sensitive to the privacy risks in
publishing their outputs. Differential privacy is a framework for developing
tradeoffs between privacy and the utility of these outputs. In this paper we
investigate the theory and empirical performance of differentially private
approximations to PCA and propose a new method which explicitly optimizes the
utility of the output. We show that the sample complexity of the proposed
method differs from the existing procedure in the scaling with the data
dimension, and that our method is nearly optimal in terms of this scaling. We
furthermore illustrate our results, showing that on real data there is a large
performance gap between the existing method and our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2819</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2819</id><created>2012-07-11</created><updated>2013-07-07</updated><authors><author><keyname>Amarilli</keyname><forenames>Antoine</forenames></author><author><keyname>Jeanmougin</keyname><forenames>Marc</forenames></author></authors><title>A Proof of the Pumping Lemma for Context-Free Languages Through Pushdown
  Automata</title><categories>cs.FL</categories><comments>Corrected a typo in a definition, added related work, added
  acknowledgement, added note about proving Ogden's lemma</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The pumping lemma for context-free languages is a result about pushdown
automata which is strikingly similar to the well-known pumping lemma for
regular languages. However, though the lemma for regular languages is simply
proved by using the pigeonhole principle on deterministic automata, the lemma
for pushdown automata is proven through an equivalence with context-free
languages and through the more powerful Ogden's lemma. We present here a proof
of the pumping lemma for context-free languages which relies on pushdown
automata instead of context-free grammars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2825</identifier>
 <datestamp>2012-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2825</id><created>2012-07-11</created><updated>2012-09-19</updated><authors><author><keyname>Torrieri</keyname><forenames>Don</forenames></author><author><keyname>Valenti</keyname><forenames>Matthew C.</forenames></author></authors><title>Guard Zones and the Near-Far Problem in DS-CDMA Ad Hoc Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>to appear at Milcom-2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The central issue in direct-sequence code-division multiple-access (DS-CDMA)
ad hoc networks is the prevention of a near-far problem. This paper considers
two types of guard zones that may be used to control the near-far problem: a
fundamental exclusion zone and an additional CSMA guard zone that may be
established by the carrier-sense multiple-access (CSMA) protocol. In the
exclusion zone, no mobiles are physically present, modeling the minimum
physical separation among mobiles that is always present in actual networks.
Potentially interfering mobiles beyond a transmitting mobile's exclusion zone,
but within its CSMA guard zone, are deactivated by the protocol. This paper
provides an analysis of DS-CSMA networks with either or both types of guard
zones. A network of finite extent with a finite number of mobiles is modeled as
a uniform clustering process. The analysis uses a closed-form expression for
the outage probability in the presence of Nakagami fading, conditioned on the
network geometry. By using the analysis developed in this paper, the tradeoffs
between exclusion zones and CSMA guard zones are explored for DS-CDMA and
unspread networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2829</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2829</id><created>2012-07-11</created><updated>2013-03-09</updated><authors><author><keyname>Wang</keyname><forenames>Meng</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>Sparse Recovery with Graph Constraints</title><categories>cs.IT cs.NI math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1108.0443</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse recovery can recover sparse signals from a set of underdetermined
linear measurements. Motivated by the need to monitor large-scale networks from
a limited number of measurements, this paper addresses the problem of
recovering sparse signals in the presence of network topological constraints.
Unlike conventional sparse recovery where a measurement can contain any subset
of the unknown variables, we use a graph to characterize the topological
constraints and allow an additive measurement over nodes (unknown variables)
only if they induce a connected subgraph. We provide explicit measurement
constructions for several special graphs, and the number of measurements by our
construction is less than that needed by existing random constructions.
Moreover, our construction for a line network is provably optimal in the sense
that it requires the minimum number of measurements. A measurement construction
algorithm for general graphs is also proposed and evaluated. For any given
graph $G$ with $n$ nodes, we derive bounds of the minimum number of
measurements needed to recover any $k$-sparse vector over $G$ ($M^G_{k,n}$).
Using the Erd\H{o}s-R\'enyi random graph as an example, we characterize the
dependence of $M^G_{k,n}$ on the graph structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2837</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2837</id><created>2012-07-11</created><authors><author><keyname>Mamadolimov</keyname><forenames>Abdurashid</forenames></author></authors><title>Search Algorithms for Conceptual Graph Databases</title><categories>cs.DS cs.DB cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a database composed of a set of conceptual graphs. Using
conceptual graphs and graph homomorphism it is possible to build a basic
query-answering mechanism based on semantic search. Graph homomorphism defines
a partial order over conceptual graphs. Since graph homomorphism checking is an
NP-Complete problem, the main requirement for database organizing and managing
algorithms is to reduce the number of homomorphism checks. Searching is a basic
operation for database manipulating problems. We consider the problem of
searching for an element in a partially ordered set. The goal is to minimize
the number of queries required to find a target element in the worst case.
First we analyse conceptual graph database operations. Then we propose a new
algorithm for a subclass of lattices. Finally, we suggest a parallel search
algorithm for a general poset. Keywords. Conceptual Graph, Graph Homomorphism,
Partial Order, Lattice, Search, Database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2840</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2840</id><created>2012-07-11</created><authors><author><keyname>Sarma</keyname><forenames>Rajkumar</forenames></author><author><keyname>Raju</keyname><forenames>Veerati</forenames></author></authors><title>Design and Performance Analysis of hybrid adders for high speed
  arithmetic circuit</title><categories>cs.AR</categories><comments>12 PAGES, 10 FIGURES</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adder cells using Gate Diffusion Technique (GDI) &amp; PTL-GDI technique are
described in this paper. GDI technique allows reducing power consumption,
propagation delay and low PDP (power delay product) whereas Pass Transistor
Logic (PTL) reduces the count of transistors used to make different logic
gates, by eliminating redundant transistors. Performance comparison with
various Hybrid Adder is been presented. In this paper, we propose two new
designs based on GDI &amp; PTL techniques, which is found to be much more power
efficient in comparison with existing design technique. Only 10 transistors are
used to implement the SUM &amp; CARRY function for both the designs. The SUM and
CARRY cell are implemented in a cascaded way i.e. firstly the XOR cell is
implemented and then using XOR as input SUM as well as CARRY cell is
implemented. For Proposed GDI adder the SUM as well as CARRY cell is designed
using GDI technique. On the other hand in Proposed PTL-GDI adder the SUM cell
is constructed using PTL technique and the CARRY cell is designed using GDI
technique. The advantages of both the designs are discussed. The significance
of these designs is substantiated by the simulation results obtained from
Cadence Virtuoso 180nm environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2847</identifier>
 <datestamp>2012-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2847</id><created>2012-07-12</created><updated>2012-07-20</updated><authors><author><keyname>Liu</keyname><forenames>Kai</forenames></author><author><keyname>Lim</keyname><forenames>Hock Beng</forenames></author></authors><title>Positioning Accuracy Improvement via Distributed Location Estimate in
  Cooperative Vehicular Networks</title><categories>cs.DC cs.DS</categories><comments>To appear in Proc. of the 15th International IEEE Conference on
  Intelligent Transportation Systems (IEEE ITSC'12)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of cooperative vehicle safety (CVS) applications, such as
collision warnings, turning assistants, and speed advisories, etc., has
received great attention in the past few years. Accurate vehicular localization
is essential to enable these applications. In this study, motivated by the
proliferation of the Global Positioning System (GPS) devices, and the
increasing sophistication of wireless communication technologies in vehicular
networks, we propose a distributed location estimate algorithm to improve the
positioning accuracy via cooperative inter-vehicle distance measurement. In
particular, we compute the inter-vehicle distance based on raw GPS pseudorange
measurements, instead of depending on traditional radio-based ranging
techniques, which usually either suffer from high hardware cost or have
inadequate positioning accuracy. In addition, we improve the estimation of the
vehicles' locations only based on the inaccurate GPS fixes, without using any
anchors with known exact locations. The algorithm is decentralized, which
enhances its practicability in highly dynamic vehicular networks. We have
developed a simulation model to evaluate the performance of the proposed
algorithm, and the results demonstrate that the algorithm can significantly
improve the positioning accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2853</identifier>
 <datestamp>2013-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2853</id><created>2012-07-12</created><updated>2013-04-12</updated><authors><author><keyname>Angelini</keyname><forenames>Maria Chiara</forenames></author><author><keyname>Ricci-Tersenghi</keyname><forenames>Federico</forenames></author><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>Compressed sensing with sparse, structured matrices</title><categories>cs.IT cond-mat.dis-nn cond-mat.stat-mech math.IT</categories><comments>7 pages, 6 figures</comments><journal-ref>Proc. Fiftieth Annual Allerton Conference, p. 808 (2012)</journal-ref><doi>10.1109/Allerton.2012.6483301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of the compressed sensing problem, we propose a new ensemble
of sparse random matrices which allow one (i) to acquire and compress a
{\rho}0-sparse signal of length N in a time linear in N and (ii) to perfectly
recover the original signal, compressed at a rate {\alpha}, by using a message
passing algorithm (Expectation Maximization Belief Propagation) that runs in a
time linear in N. In the large N limit, the scheme proposed here closely
approaches the theoretical bound {\rho}0 = {\alpha}, and so it is both optimal
and efficient (linear time complexity). More generally, we show that several
ensembles of dense random matrices can be converted into ensembles of sparse
random matrices, having the same thresholds, but much lower computational
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2860</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2860</id><created>2012-07-12</created><updated>2012-09-20</updated><authors><author><keyname>Shad</keyname><forenames>Shafqat Ali</forenames></author><author><keyname>Chen</keyname><forenames>Enhong</forenames></author><author><keyname>Azeem</keyname><forenames>Faisal Malik Faisal</forenames></author></authors><title>Enterprise Resource Planning - Real blessing or a Blessing in Disguise :
  An Exploration of the Contextual Factors in Public Sector</title><categories>cs.CY</categories><journal-ref>Interdisciplinary Journal of Contemporary Research in Business,
  vol. 2, no. 10, pp. 294-307, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information systems have always been in a prime focus in organizations in
both local (Pakistani) and global environment. Now the race of being the best
through Information Systems has created its importance in public sector
organizations to meet the global challenges. Public sector organizations have
been facing problems in different segments of technology adoption especially in
ERP projects. ERP adoption/implementation projects in public sector
organizations still encounter major setbacks in terms of partly/completely
success/failure. Cultural and other social barriers have been resistant in
technology adoption in Pakistan. Now in the case of big ERP adoptions the
contextual factors must be identified and addressed. The paper investigates the
reasons of success or failure by addressing nature of complexities regarding
different contextual factors. The study includes a sample of Pakistan s four
public sector organizations. The sample of this four organizations includes two
organizations (Type-A) i.e. Oil &amp; Gas Development Company Limited (OGDCL) and
National Database Registration Authority (NADRA) where ERP has been
successfully implemented and other two (Type-B) i.e. Pakistan Telecommunication
Corporation Limited (PTCL), Higher Education Commission (HEC) where ERP
implementation is in progress. The findings address the contextual factors i.e.
cultural, environmental &amp; political changes which have a variable impact on ERP
systems adoption/implementation in addition to Business Process Re-engineering
(BPR). Paper also briefly includes analysis of gaps between pre &amp; post ERP
implementation scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2861</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2861</id><created>2012-07-12</created><authors><author><keyname>Khan</keyname><forenames>Adnan Alam</forenames></author><author><keyname>Soomro</keyname><forenames>Safeeullah</forenames></author><author><keyname>Hyder</keyname><forenames>Irfan</forenames></author></authors><title>Fast Subsequent Color Iris Matching in large Database</title><categories>cs.GT cs.CR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Databases play an important role in cyber world. It provides authenticity
across the globe to the legitimate user. Biometrics is another important tool
which recognizes humans using their physical statistics. Biometrics system
requires speedy recognition that provides instant and accurate results.
Biometric industry is looking for a new algorithm that interacts with biometric
system reduces its recognition time while searching its record in large
database. We propose a method which provides an appropriate solution for the
aforementioned problem. Iris images database could be smart if iris image
histogram ratio is used as its primary key. So, we have developed an algorithm
that converts image histogram into eight byte code which will be used as
primary key of a large database. Second part of this study explains how color
iris image recognition can take place. For this a new and efficient algorithm
is developed that segments the iris image and performs recognition in much less
time. Our research proposes a fast and efficient algorithm that recognizes
color irises from large database. We have already implemented this algorithm in
Matlab. It provides real-time, high confidence recognition of a person's
identity using mathematical analysis of the random patterns that are visible
within the iris of an eye.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2862</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2862</id><created>2012-07-12</created><updated>2012-09-20</updated><authors><author><keyname>Shad</keyname><forenames>Shafqat Ali</forenames></author><author><keyname>Chen</keyname><forenames>Enhong</forenames></author><author><keyname>Azeem</keyname><forenames>Faisal Malik Faisal</forenames></author></authors><title>Performance Enhancement Factors of ERP Projects in a Telecom Public
  Sector Organization of Pakistan : An Exploratory Study</title><categories>cs.CY</categories><journal-ref>Interdisciplinary Journal of Contemporary Research in Business,
  vol. 2, no. 11, pp. 95-109, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Public sector organizations are treated in a different manner, as Information
technology/information system has become necessity in a highly competitive
environment. Importance of information systems is becoming more and more vital
as the global technology adoption is in progress. ERP projects are considered
as one of the most important and critical area of technology especially in
public sector organizations where cost effectiveness and operational efficiency
is prioritized on profits. A lot of research studies have been made on ERP
projects but mostly on critical success factors (CSFs) and other managerial
issues. This ongoing research mainly focuses upon the performance of ERP
software in public sector organizations by thoroughly going through one of the
largest most public sector organizations of Pakistan. Though ERP projects are
handled by experienced consultants in addition to the support of vendor
companies but because of its features and functional complexity and mismatch
with the organizational processes, different managerial and technical issues
arise during and after its implementation. This study investigates the
performance of ERP system in a large public sector organization of Pakistan;
five most critical technical factors, which can lead the whole project towards
success or failure, have been dug out. This exploratory study i.e. extensive
literature review and a case study includes survey and interviews which later
on investigated through their application in a public sector organization in
Pakistan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2863</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2863</id><created>2012-07-12</created><authors><author><keyname>Tournoux</keyname><forenames>Pierre-Ugo</forenames></author><author><keyname>Thai</keyname><forenames>Tuan Tran</forenames></author><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author><author><keyname>Lacan</keyname><forenames>Jerome</forenames></author><author><keyname>Roca</keyname><forenames>Vincent</forenames></author></authors><title>Erasure Coding and Congestion Control for Interactive Real-Time
  Communication</title><categories>cs.NI cs.MM</categories><comments>IAB/IRTF Workshop on Congestion Control for Interactive Real-Time
  Communication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of real-time applications over the Internet is a challenging problem
that the QoS epoch attempted to solve by proposing the DiffServ architecture.
Today, the only existing service provided by the Internet is still best-effort.
As a result, multimedia applications often perform on top of a transport layer
that provides a variable sending rate. In an obvious manner, this variable
sending rate is an issue for these applications with strong delay constraint.
In a real-time context where retransmission can not be used to ensure
reliability, video quality suffers from any packet losses. In this position
paper, we discuss this problem and motivate why we want to bring out a certain
class of erasure coding scheme inside multimedia congestion control protocols
such as TFRC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2867</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2867</id><created>2012-07-12</created><authors><author><keyname>Kumar</keyname><forenames>Ajay</forenames></author><author><keyname>Bawa</keyname><forenames>Seema</forenames></author></authors><title>Distributed and Big Data Storage Management in Grid Computing</title><categories>cs.DC cs.NI</categories><comments>Data, Data Locality, DSSM, GOS, GRID, Virtualization, Web Services,
  Virtual Organization</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Big data storage management is one of the most challenging issues for Grid
computing environments, since large amount of data intensive applications
frequently involve a high degree of data access locality. Grid applications
typically deal with large amounts of data. In traditional approaches
high-performance computing consists dedicated servers that are used to data
storage and data replication. In this paper we present a new mechanism for
distributed and big data storage and resource discovery services. Here we
proposed an architecture named Dynamic and Scalable Storage Management (DSSM)
architecture in grid environments. This allows in grid computing not only
sharing the computational cycles, but also share the storage space. The storage
can be transparently accessed from any grid machine, allowing easy data sharing
among grid users and applications. The concept of virtual ids that, allows the
creation of virtual spaces has been introduced and used. The DSSM divides all
Grid Oriented Storage devices (nodes) into multiple geographically distributed
domains and to facilitate the locality and simplify the intra-domain storage
management. Grid service based storage resources are adopted to stack simple
modular service piece by piece as demand grows. To this end, we propose four
axes that define: DSSM architecture and algorithms description, Storage
resources and resource discovery into Grid service, Evaluate purpose prototype
system, dynamically, scalability, and bandwidth, and Discuss results.
Algorithms at bottom and upper level for standardization dynamic and scalable
storage management, along with higher bandwidths have been designed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1207.2878</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1207.2878</id><created>2012-07-12</created><authors><author><keyname>Soryani</keyname><forenames>Mohsen</forenames></author><author><keyname>Analoui</keyname><forenames>Morteza</forenames></author><author><keyname>Zarrinchian</keyname><forenames>Ghobad</forenames></author></authors><title>A Novel Process Mapping Strategy in Clustered Environments</title><categories>cs.DC</categories><comments>14 pages; International Journal of Grid Computing and Applications
  (IJGCA), 2012</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Nowadays the number of available processing cores within computing nodes
which are used in recent clustered environments, are growing up with a rapid
rate. Despite this trend, the number of available network interfaces in such
computing nodes has almost been remained unchanged. This issue can lead to high
usage of network interface in many workloads, especially in heavy-communicating
workloads. As a result, network interface may raise as a performance bottleneck
and can drastically degrade the performance. The goal of this paper is to
introduce a new process mapping strategy in multi-core clusters aimed at
reducing network interface contention and improving inter-node communication
performance of parallel applications. Performance evaluation of the new mapping
algorithm in synthetic and real workloads indicates that the new strategy can
achieve 5% to 90% performance improvement in heavy communicating workloads,
compared to other well-known methods.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="33000" completeListSize="102538">1122234|34001</resumptionToken>
</ListRecords>
</OAI-PMH>
